/home/yangyutu/anaconda3/bin/python /home/yangyutu/Dropbox/pythonScripts/DeepReinforcementLearning-PyTorch/Example/TDDDPGExample/StabilizerTwoD/TDDDPG_StabilizerTwoDContinuous.py
episode index:0
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.20409236, -0.55874939])}
done in step count: 14
reward sum = 0.2287679245496101
running average episode reward sum: 0.2287679245496101
{'reset': False, 'endBeforeDone': False, 'stepCount': 15, 'initial state': array([-0.20409236, -0.55874939]), 'done_state': array([ 0.39788986, -0.48017777])}
episode index:1
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.89944048, -0.73801048]), 'done_state': array([ 0.39788986, -0.48017777])}
done in step count: 199
reward sum = -1.814496618574919
running average episode reward sum: -0.7928643470126544
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([-1.89944048, -0.73801048]), 'done_state': array([ 0.39788986, -0.48017777])}
episode index:2
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.11242115, -3.38531138]), 'done_state': array([ 0.39788986, -0.48017777])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: -0.28557623134176957
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-3.11242115, -3.38531138]), 'done_state': array([ 0.28465849, -0.05877271])}
episode index:3
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.08921475, -2.18038999]), 'done_state': array([ 0.28465849, -0.05877271])}
done in step count: 14
reward sum = -0.5812320754503899
running average episode reward sum: -0.35949019236892465
{'reset': False, 'endBeforeDone': False, 'stepCount': 15, 'initial state': array([ 3.08921475, -2.18038999]), 'done_state': array([0.39428686, 0.45120218])}
episode index:4
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([3.36905536, 0.42816714]), 'done_state': array([0.39428686, 0.45120218])}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: -0.2248300346771397
{'reset': False, 'endBeforeDone': False, 'stepCount': 12, 'initial state': array([3.36905536, 0.42816714]), 'done_state': array([0.42096861, 0.4354369 ])}
episode index:5
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.87304611, 0.25401234]), 'done_state': array([0.42096861, 0.4354369 ])}
done in step count: 16
reward sum = 0.18530201888518416
running average episode reward sum: -0.15647469241675238
{'reset': False, 'endBeforeDone': False, 'stepCount': 17, 'initial state': array([2.87304611, 0.25401234]), 'done_state': array([0.488714  , 0.33206219])}
episode index:6
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.61348873, -1.68168548]), 'done_state': array([0.488714  , 0.33206219])}
done in step count: 82
reward sum = 0.00017696434542799797
running average episode reward sum: -0.13409588430786948
{'reset': False, 'endBeforeDone': False, 'stepCount': 83, 'initial state': array([-0.61348873, -1.68168548]), 'done_state': array([0.47772263, 0.27740492])}
episode index:7
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([3.30588029, 2.69064731]), 'done_state': array([0.47772263, 0.27740492])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: -0.1173338987693858
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([3.30588029, 2.69064731]), 'done_state': array([0.47772263, 0.27740492])}
episode index:8
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.75202033, -3.30675195]), 'done_state': array([0.47772263, 0.27740492])}
done in step count: 86
reward sum = 0.00011610630703530949
running average episode reward sum: -0.10428389820533901
{'reset': False, 'endBeforeDone': False, 'stepCount': 87, 'initial state': array([ 1.75202033, -3.30675195]), 'done_state': array([0.48147658, 0.09986819])}
episode index:9
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.44647494,  2.78749915]), 'done_state': array([0.48147658, 0.09986819])}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: -0.0460258183848051
{'reset': False, 'endBeforeDone': False, 'stepCount': 8, 'initial state': array([-3.44647494,  2.78749915]), 'done_state': array([0.42619355, 0.01588075])}
episode index:10
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.30546912, 3.53774592]), 'done_state': array([0.42619355, 0.01588075])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.024431074195631734
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([2.30546912, 3.53774592]), 'done_state': array([0.36475562, 0.35088513])}
episode index:11
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.12454507, 0.77818422]), 'done_state': array([0.36475562, 0.35088513])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.08989515134599575
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([2.12454507, 0.77818422]), 'done_state': array([0.30151152, 0.23560291])}
episode index:12
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.13672633, -1.68775333]), 'done_state': array([0.30151152, 0.23560291])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.1522109089347653
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.13672633, -1.68775333]), 'done_state': array([0.47060923, 0.35391145])}
episode index:13
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.48181605, -0.06329557]), 'done_state': array([0.47060923, 0.35391145])}
done in step count: 4
reward sum = 0.6561
running average episode reward sum: 0.18820298686799636
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([-1.48181605, -0.06329557]), 'done_state': array([0.30586203, 0.38830678])}
episode index:14
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.67128929, 2.96999276]), 'done_state': array([0.30586203, 0.38830678])}
done in step count: 5
reward sum = 0.5904900000000001
running average episode reward sum: 0.21502212107679658
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([2.67128929, 2.96999276]), 'done_state': array([0.38281475, 0.43200216])}
episode index:15
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.97171591, -2.78569462]), 'done_state': array([0.38281475, 0.43200216])}
done in step count: 5
reward sum = 0.5904900000000001
running average episode reward sum: 0.2384888635094968
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([-1.97171591, -2.78569462]), 'done_state': array([0.11572697, 0.44570808])}
episode index:16
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.63569298, -0.82103236]), 'done_state': array([0.11572697, 0.44570808])}
done in step count: 8
reward sum = 0.4304672100000001
running average episode reward sum: 0.24978170742070288
{'reset': False, 'endBeforeDone': False, 'stepCount': 9, 'initial state': array([-2.63569298, -0.82103236]), 'done_state': array([0.39206865, 0.42175356])}
episode index:17
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.41534163, 3.32718276]), 'done_state': array([0.39206865, 0.42175356])}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: 0.2574283063973305
{'reset': False, 'endBeforeDone': False, 'stepCount': 10, 'initial state': array([2.41534163, 3.32718276]), 'done_state': array([0.25194762, 0.33149843])}
episode index:18
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.03706999, -0.49109507]), 'done_state': array([0.25194762, 0.33149843])}
done in step count: 13
reward sum = 0.2541865828329001
running average episode reward sum: 0.25725768936762367
{'reset': False, 'endBeforeDone': False, 'stepCount': 14, 'initial state': array([ 3.03706999, -0.49109507]), 'done_state': array([0.16133854, 0.36628804])}
episode index:19
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.81076742,  3.04527496]), 'done_state': array([0.16133854, 0.36628804])}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: 0.2683096498992425
{'reset': False, 'endBeforeDone': False, 'stepCount': 8, 'initial state': array([-2.81076742,  3.04527496]), 'done_state': array([0.25846391, 0.07491527])}
episode index:20
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.54536643,  0.99331837]), 'done_state': array([0.25846391, 0.07491527])}
done in step count: 4
reward sum = 0.6561
running average episode reward sum: 0.2867758570468976
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([-1.54536643,  0.99331837]), 'done_state': array([0.14318123, 0.35620289])}
episode index:21
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.31086561, -1.91219074]), 'done_state': array([0.14318123, 0.35620289])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.3146496817265841
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.31086561, -1.91219074]), 'done_state': array([ 0.45545164, -0.00645643])}
episode index:22
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.97452121,  0.98827376]), 'done_state': array([ 0.45545164, -0.00645643])}
done in step count: 8
reward sum = 0.4304672100000001
running average episode reward sum: 0.3196852264341239
{'reset': False, 'endBeforeDone': False, 'stepCount': 9, 'initial state': array([-3.97452121,  0.98827376]), 'done_state': array([0.33477487, 0.21977265])}
episode index:23
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.60770234, -2.3637893 ]), 'done_state': array([0.33477487, 0.21977265])}
done in step count: 6
reward sum = 0.531441
running average episode reward sum: 0.3285083836660354
{'reset': False, 'endBeforeDone': False, 'stepCount': 7, 'initial state': array([-3.60770234, -2.3637893 ]), 'done_state': array([0.38014989, 0.39849872])}
episode index:24
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.28970153, 2.78590439]), 'done_state': array([0.38014989, 0.39849872])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.34452804831939404
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([0.28970153, 2.78590439]), 'done_state': array([0.21232969, 0.48649711])}
episode index:25
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.47291095, -3.01291219]), 'done_state': array([0.21232969, 0.48649711])}
done in step count: 4
reward sum = 0.6561
running average episode reward sum: 0.3565115849224943
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([ 3.47291095, -3.01291219]), 'done_state': array([0.07901646, 0.16448896])}
episode index:26
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.93351597,  3.30726779]), 'done_state': array([0.07901646, 0.16448896])}
done in step count: 4
reward sum = 0.6561
running average episode reward sum: 0.3676074521475871
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([-0.93351597,  3.30726779]), 'done_state': array([0.45952727, 0.36183098])}
episode index:27
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.78729487, 0.61716781]), 'done_state': array([0.45952727, 0.36183098])}
done in step count: 4
reward sum = 0.6561
running average episode reward sum: 0.37791075742803043
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([1.78729487, 0.61716781]), 'done_state': array([0.40450394, 0.47968346])}
episode index:28
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.55468581, -2.91077429]), 'done_state': array([0.40450394, 0.47968346])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.39001728303396044
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 1.55468581, -2.91077429]), 'done_state': array([0.13260874, 0.43992441])}
episode index:29
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.65652615,  3.51553341]), 'done_state': array([0.13260874, 0.43992441])}
done in step count: 8
reward sum = -1.2795327899999998
running average episode reward sum: 0.33436561393282843
{'reset': False, 'endBeforeDone': False, 'stepCount': 9, 'initial state': array([-3.65652615,  3.51553341]), 'done_state': array([0.29743085, 0.42270018])}
episode index:30
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([3.04298614, 3.28594978]), 'done_state': array([0.29743085, 0.42270018])}
done in step count: 13
reward sum = 0.2541865828329001
running average episode reward sum: 0.33177919357476626
{'reset': False, 'endBeforeDone': False, 'stepCount': 14, 'initial state': array([3.04298614, 3.28594978]), 'done_state': array([0.06009997, 0.46427435])}
episode index:31
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.31718857, -0.45566906]), 'done_state': array([0.06009997, 0.46427435])}
done in step count: 104
reward sum = 1.7426933810146188e-05
running average episode reward sum: 0.3214116383672364
{'reset': False, 'endBeforeDone': False, 'stepCount': 105, 'initial state': array([-0.31718857, -0.45566906]), 'done_state': array([0.0675085 , 0.47282424])}
episode index:32
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.69237928,  0.07851569]), 'done_state': array([0.0675085 , 0.47282424])}
done in step count: 13
reward sum = 0.2541865828329001
running average episode reward sum: 0.31937451547225654
{'reset': False, 'endBeforeDone': False, 'stepCount': 14, 'initial state': array([-3.69237928,  0.07851569]), 'done_state': array([0.4781795 , 0.43593599])}
episode index:33
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.99045295, -1.29770056]), 'done_state': array([0.4781795 , 0.43593599])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.33142232384071957
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 1.99045295, -1.29770056]), 'done_state': array([0.44953982, 0.33705256])}
episode index:34
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.67935601, -3.05451885]), 'done_state': array([0.44953982, 0.33705256])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.3450959717309847
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-0.67935601, -3.05451885]), 'done_state': array([ 0.332347  , -0.30426815])}
episode index:35
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.82003664, -0.19469224]), 'done_state': array([ 0.332347  , -0.30426815])}
done in step count: 6
reward sum = 0.531441
running average episode reward sum: 0.35027222251623513
{'reset': False, 'endBeforeDone': False, 'stepCount': 7, 'initial state': array([-3.82003664, -0.19469224]), 'done_state': array([0.45437371, 0.44239215])}
episode index:36
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.54287557, -0.10435103]), 'done_state': array([0.45437371, 0.44239215])}
done in step count: 4
reward sum = 0.6561
running average episode reward sum: 0.35853783812390444
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([-2.54287557, -0.10435103]), 'done_state': array([0.44804786, 0.19257679])}
episode index:37
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.10589041,  1.2134767 ]), 'done_state': array([0.44804786, 0.19257679])}
done in step count: 6
reward sum = 0.531441
running average episode reward sum: 0.3630879213311701
{'reset': False, 'endBeforeDone': False, 'stepCount': 7, 'initial state': array([-0.10589041,  1.2134767 ]), 'done_state': array([0.40743487, 0.3187666 ])}
episode index:38
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.55327086,  3.40247724]), 'done_state': array([0.40743487, 0.3187666 ])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.37247028232267854
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-3.55327086,  3.40247724]), 'done_state': array([0.31057263, 0.3653283 ])}
episode index:39
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.92923647, -3.66646357]), 'done_state': array([0.31057263, 0.3653283 ])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.38138352526461156
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 2.92923647, -3.66646357]), 'done_state': array([0.25277261, 0.07586157])}
episode index:40
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.39955957, -3.72705904]), 'done_state': array([0.25277261, 0.07586157])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.3898619758679137
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 1.39955957, -3.72705904]), 'done_state': array([0.28277785, 0.03450993])}
episode index:41
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([3.06083989, 2.99434969]), 'done_state': array([0.28277785, 0.03450993])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.39986526215677287
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([3.06083989, 2.99434969]), 'done_state': array([0.15420675, 0.46464405])}
episode index:42
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.04196354,  1.84419911]), 'done_state': array([0.15420675, 0.46464405])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.4114963025717316
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.04196354,  1.84419911]), 'done_state': array([-0.07184423,  0.23153074])}
episode index:43
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.44314671, -3.51306844]), 'done_state': array([-0.07184423,  0.23153074])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.4187122956951013
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-3.44314671, -3.51306844]), 'done_state': array([0.39985351, 0.43299278])}
episode index:44
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.23851375, 1.84981224]), 'done_state': array([0.39985351, 0.43299278])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.42560757801298793
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([0.23851375, 1.84981224]), 'done_state': array([-0.10250826,  0.48495267])}
episode index:45
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.36407039, 0.09385546]), 'done_state': array([-0.10250826,  0.48495267])}
done in step count: 4
reward sum = 0.6561
running average episode reward sum: 0.4306182828387925
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([2.36407039, 0.09385546]), 'done_state': array([-0.10666604,  0.48837973])}
episode index:46
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.69247897, 2.03860891]), 'done_state': array([-0.10666604,  0.48837973])}
done in step count: 4
reward sum = 0.6561
running average episode reward sum: 0.435415766182648
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([1.69247897, 2.03860891]), 'done_state': array([-0.27186368,  0.40377462])}
episode index:47
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.65055797, -0.27644729]), 'done_state': array([-0.27186368,  0.40377462])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.4432196043871761
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-2.65055797, -0.27644729]), 'done_state': array([0.25832789, 0.04817542])}
episode index:48
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.20891097, 2.03333538]), 'done_state': array([0.25832789, 0.04817542])}
done in step count: 5
reward sum = 0.5904900000000001
running average episode reward sum: 0.4462251226649888
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([2.20891097, 2.03333538]), 'done_state': array([0.14002721, 0.33311382])}
episode index:49
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.37594012, -3.03501693]), 'done_state': array([0.14002721, 0.33311382])}
done in step count: 6
reward sum = 0.531441
running average episode reward sum: 0.44792944021168907
{'reset': False, 'endBeforeDone': False, 'stepCount': 7, 'initial state': array([ 2.37594012, -3.03501693]), 'done_state': array([-0.20229357,  0.48753112])}
episode index:50
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.30729672, -0.40921438]), 'done_state': array([-0.20229357,  0.48753112])}
done in step count: 4
reward sum = 0.6561
running average episode reward sum: 0.45201121589381277
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([ 2.30729672, -0.40921438]), 'done_state': array([0.00142255, 0.25697457])}
episode index:51
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.29422006,  3.60137409]), 'done_state': array([0.00142255, 0.25697457])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.45733792328047024
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-2.29422006,  3.60137409]), 'done_state': array([0.16620218, 0.46762803])}
episode index:52
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.53105446, -3.1921815 ]), 'done_state': array([0.16620218, 0.46762803])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.46246362284121606
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-3.53105446, -3.1921815 ]), 'done_state': array([0.44059722, 0.45084751])}
episode index:53
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.59414344, 3.17251559]), 'done_state': array([0.44059722, 0.45084751])}
done in step count: 5
reward sum = 0.5904900000000001
running average episode reward sum: 0.4648344816774898
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([1.59414344, 3.17251559]), 'done_state': array([-0.11821412,  0.24591784])}
episode index:54
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.99858586, 1.65495697]), 'done_state': array([-0.11821412,  0.24591784])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.4711102183742627
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([0.99858586, 1.65495697]), 'done_state': array([0.0962065 , 0.42449219])}
episode index:55
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.95996586, -2.72883125]), 'done_state': array([0.0962065 , 0.42449219])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.47571539304615085
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-1.95996586, -2.72883125]), 'done_state': array([0.28259498, 0.38224894])}
episode index:56
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.57141447, -1.94859603]), 'done_state': array([0.28259498, 0.38224894])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.4801589826418324
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-3.57141447, -1.94859603]), 'done_state': array([ 0.30697586, -0.00340225])}
episode index:57
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.83110384, -3.46956587]), 'done_state': array([ 0.30697586, -0.00340225])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.4858458967342146
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-2.83110384, -3.46956587]), 'done_state': array([-0.02705358, -0.17737354])}
episode index:58
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.87349891, -0.87702549]), 'done_state': array([-0.02705358, -0.17737354])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.48996715272177027
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-3.87349891, -0.87702549]), 'done_state': array([ 0.35108011, -0.05949395])}
episode index:59
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.60515427, 3.76793447]), 'done_state': array([ 0.35108011, -0.05949395])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.49395103350974073
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([1.60515427, 3.76793447]), 'done_state': array([0.22240716, 0.43062082])}
episode index:60
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.23514958, -3.40612187]), 'done_state': array([0.22240716, 0.43062082])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.4978042952554827
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 0.23514958, -3.40612187]), 'done_state': array([ 0.04412508, -0.00718134])}
episode index:61
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.3705517 ,  3.73706427]), 'done_state': array([ 0.04412508, -0.00718134])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.501533258235233
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-0.3705517 ,  3.73706427]), 'done_state': array([0.10927732, 0.34512581])}
episode index:62
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.62082273,  3.77167248]), 'done_state': array([0.10927732, 0.34512581])}
done in step count: 4
reward sum = 0.6561
running average episode reward sum: 0.5039866985807054
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([-3.62082273,  3.77167248]), 'done_state': array([-0.13828607,  0.19573601])}
episode index:63
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.83082645, 2.4906799 ]), 'done_state': array([-0.13828607,  0.19573601])}
done in step count: 4
reward sum = 0.6561
running average episode reward sum: 0.506363468915382
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([1.83082645, 2.4906799 ]), 'done_state': array([-0.12905011,  0.27093539])}
episode index:64
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.56770464, -2.23016564]), 'done_state': array([-0.12905011,  0.27093539])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.5110348001628376
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 2.56770464, -2.23016564]), 'done_state': array([0.0188806 , 0.18727436])}
episode index:65
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.8532375 ,  1.05566664]), 'done_state': array([0.27900964, 0.06213996])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.5184433637967341
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.8532375 ,  1.05566664]), 'done_state': array([0.27900964, 0.06213996])}
episode index:66
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.91000057, -1.04062096]), 'done_state': array([0.27900964, 0.06213996])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.5227949553818575
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-2.91000057, -1.04062096]), 'done_state': array([-0.17697498, -0.13530466])}
episode index:67
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.97851439, -0.37248458]), 'done_state': array([-0.02589024,  0.11391375])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.5298126766262419
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.97851439, -0.37248458]), 'done_state': array([-0.02589024,  0.11391375])}
episode index:68
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.55679601,  1.76789954]), 'done_state': array([-0.02589024,  0.11391375])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.5338733624722385
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-3.55679601,  1.76789954]), 'done_state': array([-0.13890118,  0.00734243])}
episode index:69
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.0804553 ,  3.58542009]), 'done_state': array([-0.13890118,  0.00734243])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.5366608858654922
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-2.0804553 ,  3.58542009]), 'done_state': array([0.22661995, 0.45283752])}
episode index:70
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.52585683, -2.89271981]), 'done_state': array([0.22661995, 0.45283752])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.5393698874730204
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-0.52585683, -2.89271981]), 'done_state': array([0.03745899, 0.02201245])}
episode index:71
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.6687511 , -2.34743143]), 'done_state': array([0.03745899, 0.02201245])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.5431286390358951
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 0.6687511 , -2.34743143]), 'done_state': array([ 0.31394868, -0.11768558])}
episode index:72
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.9341917 , -2.72961152]), 'done_state': array([ 0.31394868, -0.11768558])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.5456748220628007
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 2.9341917 , -2.72961152]), 'done_state': array([0.1900973 , 0.04638764])}
episode index:73
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([3.14661724, 3.00098138]), 'done_state': array([0.1900973 , 0.04638764])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.5481521893322223
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([3.14661724, 3.00098138]), 'done_state': array([0.24179866, 0.25640672])}
episode index:74
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([3.86637617, 0.2533875 ]), 'done_state': array([0.24179866, 0.25640672])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.5505634934744593
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([3.86637617, 0.2533875 ]), 'done_state': array([0.00709767, 0.27226256])}
episode index:75
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.33913941, -1.98321481]), 'done_state': array([0.00709767, 0.27226256])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.5539771317182165
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 0.33913941, -1.98321481]), 'done_state': array([-0.26499833, -0.05754386])}
episode index:76
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.1678842 , -3.10206864]), 'done_state': array([-0.26499833, -0.05754386])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.5562501559816163
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 3.1678842 , -3.10206864]), 'done_state': array([ 0.16783737, -0.1204092 ])}
episode index:77
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.02179961, 2.72126644]), 'done_state': array([ 0.16783737, -0.1204092 ])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.5595033591100571
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([0.02179961, 2.72126644]), 'done_state': array([0.05501199, 0.36128494])}
episode index:78
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.11333096,  3.36722248]), 'done_state': array([0.05501199, 0.36128494])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.5616488862099298
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-1.11333096,  3.36722248]), 'done_state': array([0.32455995, 0.23910605])}
episode index:79
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.03464121, -3.183756  ]), 'done_state': array([0.32455995, 0.23910605])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.5637407751323057
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-1.03464121, -3.183756  ]), 'done_state': array([0.2619961 , 0.11963528])}
episode index:80
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.09169601, -1.59637833]), 'done_state': array([0.2619961 , 0.11963528])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.5667810124763513
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 2.09169601, -1.59637833]), 'done_state': array([0.19702077, 0.27488285])}
episode index:81
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.72732169, 2.57966134]), 'done_state': array([0.19702077, 0.27488285])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.5697470976900544
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([0.72732169, 2.57966134]), 'done_state': array([0.10921417, 0.38675715])}
episode index:82
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.77387284, -3.7296516 ]), 'done_state': array([0.10921417, 0.38675715])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.5716658073564392
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-1.77387284, -3.7296516 ]), 'done_state': array([0.14273403, 0.02987425])}
episode index:83
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.14494291, -0.25175713]), 'done_state': array([-0.24663906,  0.30851506])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.5767650239355293
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.14494291, -0.25175713]), 'done_state': array([-0.24663906,  0.30851506])}
episode index:84
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.98961123, -1.85074513]), 'done_state': array([-0.24663906,  0.30851506])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.5805677883598173
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.98961123, -1.85074513]), 'done_state': array([-0.49563038,  0.37207664])}
episode index:85
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.79554242, -3.81282881]), 'done_state': array([-0.49563038,  0.37207664])}
done in step count: 4
reward sum = 0.6561
running average episode reward sum: 0.5814460698905172
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([ 3.79554242, -3.81282881]), 'done_state': array([0.30839287, 0.15741509])}
episode index:86
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.95094841,  1.78302954]), 'done_state': array([0.30839287, 0.15741509])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.5831420920756837
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-3.95094841,  1.78302954]), 'done_state': array([-0.43434525, -0.0827633 ])}
episode index:87
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.87191851,  1.88926746]), 'done_state': array([-0.43434525, -0.0827633 ])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.5857200228475509
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-2.87191851,  1.88926746]), 'done_state': array([ 0.22555027, -0.37042816])}
episode index:88
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.49021003, -3.80011867]), 'done_state': array([ 0.22555027, -0.37042816])}
done in step count: 4
reward sum = 0.6561
running average episode reward sum: 0.5865108091076907
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([ 0.49021003, -3.80011867]), 'done_state': array([0.06394617, 0.38206696])}
episode index:89
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.96431067, 3.26191763]), 'done_state': array([0.06394617, 0.38206696])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.5880940223398275
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([0.96431067, 3.26191763]), 'done_state': array([0.34545515, 0.32955514])}
episode index:90
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.37536368, -1.68116377]), 'done_state': array([0.34545515, 0.32955514])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.5915215605558735
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 2.37536368, -1.68116377]), 'done_state': array([0.42695175, 0.08947142])}
episode index:91
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.19735518, -1.85297209]), 'done_state': array([0.42695175, 0.08947142])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.5938963262020053
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-3.19735518, -1.85297209]), 'done_state': array([-0.43061156, -0.04931012])}
episode index:92
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([3.66017734, 3.8565442 ]), 'done_state': array([-0.43061156, -0.04931012])}
done in step count: 4
reward sum = 0.6561
running average episode reward sum: 0.5945651829095105
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([3.66017734, 3.8565442 ]), 'done_state': array([0.07442214, 0.24573053])}
episode index:93
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.86112128, -0.44945546]), 'done_state': array([-0.34415631,  0.21438073])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.598878319261537
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.86112128, -0.44945546]), 'done_state': array([-0.34415631,  0.21438073])}
episode index:94
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([3.12383361, 2.43784527]), 'done_state': array([-0.34415631,  0.21438073])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.6002480211640472
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([3.12383361, 2.43784527]), 'done_state': array([0.12382524, 0.22989524])}
episode index:95
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([3.44312049, 1.60229388]), 'done_state': array([0.12382524, 0.22989524])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.601589187610255
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([3.44312049, 1.60229388]), 'done_state': array([0.08521949, 0.20220743])}
episode index:96
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.97645659,  3.15791925]), 'done_state': array([0.08521949, 0.20220743])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.6029027011400462
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-0.97645659,  3.15791925]), 'done_state': array([0.10071298, 0.3706738 ])}
episode index:97
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([3.82293193, 1.9019784 ]), 'done_state': array([0.10071298, 0.3706738 ])}
done in step count: 4
reward sum = 0.6561
running average episode reward sum: 0.6034455307202499
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([3.82293193, 1.9019784 ]), 'done_state': array([0.43590243, 0.19848661])}
episode index:98
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.03298319, -1.36986009]), 'done_state': array([0.43590243, 0.19848661])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.6055319395008534
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-3.03298319, -1.36986009]), 'done_state': array([-0.23234891, -0.0196326 ])}
episode index:99
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([3.22960466, 1.06745282]), 'done_state': array([-0.23234891, -0.0196326 ])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.6075766201058449
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([3.22960466, 1.06745282]), 'done_state': array([0.28833193, 0.44386283])}
episode index:100
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.40910017, -3.81949265]), 'done_state': array([0.28833193, 0.44386283])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.6087788317879652
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 0.40910017, -3.81949265]), 'done_state': array([-0.1906576 , -0.08420546])}
episode index:101
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.55001026,  0.63739025]), 'done_state': array([-0.1906576 , -0.08420546])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.6107515883390636
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-2.55001026,  0.63739025]), 'done_state': array([ 0.09937165, -0.14101027])}
episode index:102
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.27294173, 3.50325343]), 'done_state': array([ 0.09937165, -0.14101027])}
done in step count: 4
reward sum = 0.6561
running average episode reward sum: 0.6111918641804319
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([1.27294173, 3.50325343]), 'done_state': array([-0.07656912,  0.28552421])}
episode index:103
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.0530076, 3.3679338]), 'done_state': array([-0.07656912,  0.28552421])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.6123246347171585
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([0.0530076, 3.3679338]), 'done_state': array([0.24556303, 0.39960259])}
episode index:104
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.82794698,  2.09968021]), 'done_state': array([0.24556303, 0.39960259])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.6142072572436618
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-2.82794698,  2.09968021]), 'done_state': array([ 0.07791905, -0.21523333])}
episode index:105
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.7435107 , -1.11584827]), 'done_state': array([ 0.07791905, -0.21523333])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.6169034151941932
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.7435107 , -1.11584827]), 'done_state': array([-0.07379762, -0.18375254])}
episode index:106
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.00540251, -1.29714962]), 'done_state': array([-0.07379762, -0.18375254])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.619549177669014
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 2.00540251, -1.29714962]), 'done_state': array([0.25592895, 0.07976843])}
episode index:107
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.13795667,  3.21005772]), 'done_state': array([0.25592895, 0.07976843])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.6205626112091157
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-2.13795667,  3.21005772]), 'done_state': array([-0.27246233, -0.12632861])}
episode index:108
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.83393274, 0.6494901 ]), 'done_state': array([-0.27246233, -0.12632861])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.6231262569778394
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.83393274, 0.6494901 ]), 'done_state': array([0.08543321, 0.20936002])}
episode index:109
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.81065286, -3.56316026]), 'done_state': array([0.08543321, 0.20936002])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.6240887455507681
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 3.81065286, -3.56316026]), 'done_state': array([-0.23354404,  0.07770062])}
episode index:110
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.34840435, 0.2077781 ]), 'done_state': array([-0.04548704, -0.0513657 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6274753334286891
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.34840435, 0.2077781 ]), 'done_state': array([-0.04548704, -0.0513657 ])}
episode index:111
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([3.86487326, 3.7914971 ]), 'done_state': array([-0.04548704, -0.0513657 ])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.628381803665933
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([3.86487326, 3.7914971 ]), 'done_state': array([-0.1041097 ,  0.47617899])}
episode index:112
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.66596248, 3.22660814]), 'done_state': array([-0.1041097 ,  0.47617899])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.6299890443414558
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([1.66596248, 3.22660814]), 'done_state': array([0.07302851, 0.45558443])}
episode index:113
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.8999959 , 0.25683687]), 'done_state': array([-0.15428204,  0.11417968])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6332347544788114
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.8999959 , 0.25683687]), 'done_state': array([-0.15428204,  0.11417968])}
episode index:114
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.26347003, -3.8370201 ]), 'done_state': array([-0.15428204,  0.11417968])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.6340674957442131
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-1.26347003, -3.8370201 ]), 'done_state': array([ 0.01968367, -0.03418315])}
episode index:115
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.48125027,  1.52708372]), 'done_state': array([ 0.01968367, -0.03418315])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.6355841552636595
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-3.48125027,  1.52708372]), 'done_state': array([-0.44713872, -0.11959085])}
episode index:116
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.34264919,  0.33441498]), 'done_state': array([0.06155663, 0.06630922])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6386988206032863
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.34264919,  0.33441498]), 'done_state': array([0.06155663, 0.06630922])}
episode index:117
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.16887004, -3.16064663]), 'done_state': array([0.06155663, 0.06630922])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.640150525513428
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-2.16887004, -3.16064663]), 'done_state': array([ 0.0336941 , -0.40405335])}
episode index:118
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.65628745, 0.03307521]), 'done_state': array([ 0.0336941 , -0.40405335])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.6423341345427269
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.65628745, 0.03307521]), 'done_state': array([0.03138197, 0.14747376])}
episode index:119
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.98042778, 1.0006103 ]), 'done_state': array([0.03138197, 0.14747376])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.6437313500882043
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([2.98042778, 1.0006103 ]), 'done_state': array([0.29255732, 0.44935245])}
episode index:120
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.49408098,  1.16674663]), 'done_state': array([0.29255732, 0.44935245])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.6451054711618555
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-2.49408098,  1.16674663]), 'done_state': array([ 0.03538721, -0.2209784 ])}
episode index:121
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.68229371, 2.62197925]), 'done_state': array([ 0.03538721, -0.2209784 ])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.6464570656605289
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([0.68229371, 2.62197925]), 'done_state': array([0.24393829, 0.30928193])}
episode index:122
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.81048481,  2.18259715]), 'done_state': array([0.24393829, 0.30928193])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.6477866830128822
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-0.81048481,  2.18259715]), 'done_state': array([-0.09694858,  0.33105251])}
episode index:123
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.57695463, 3.35579411]), 'done_state': array([-0.09694858,  0.33105251])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.648441629117617
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([1.57695463, 3.35579411]), 'done_state': array([-0.04075778,  0.30436254])}
episode index:124
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.46427054,  0.011421  ]), 'done_state': array([-0.04075778,  0.30436254])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.6490860960846762
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-3.46427054,  0.011421  ]), 'done_state': array([-0.21680477,  0.05937809])}
episode index:125
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.68857519, 3.6046507 ]), 'done_state': array([-0.21680477,  0.05937809])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.6497203334173374
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([2.68857519, 3.6046507 ]), 'done_state': array([0.43888583, 0.42451645])}
episode index:126
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.94655073, -3.96522263]), 'done_state': array([0.43888583, 0.42451645])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.650344582760508
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-2.94655073, -3.96522263]), 'done_state': array([-0.3253257, -0.0403977])}
episode index:127
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.84274861, 0.62450674]), 'done_state': array([-0.3253257, -0.0403977])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.6509590782076915
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([2.84274861, 0.62450674]), 'done_state': array([0.03431231, 0.23578219])}
episode index:128
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.01969996, -2.68843965]), 'done_state': array([0.03431231, 0.23578219])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.6521919535704226
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-2.01969996, -2.68843965]), 'done_state': array([-0.23393989, -0.0648327 ])}
episode index:129
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.10568074, 2.92450401]), 'done_state': array([-0.23393989, -0.0648327 ])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.652782784696804
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([2.10568074, 2.92450401]), 'done_state': array([0.15132068, 0.12015478])}
episode index:130
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.83710201,  0.2666559 ]), 'done_state': array([0.15132068, 0.12015478])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.6546699390120956
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.83710201,  0.2666559 ]), 'done_state': array([-0.03346189, -0.31925477])}
episode index:131
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.97038717, -2.34357855]), 'done_state': array([-0.03346189, -0.31925477])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.6565285000801858
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.97038717, -2.34357855]), 'done_state': array([ 0.06280244, -0.36946405])}
episode index:132
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.50165595,  1.96745339]), 'done_state': array([ 0.06280244, -0.36946405])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.6583591128615378
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.50165595,  1.96745339]), 'done_state': array([-0.47299126,  0.15663355])}
episode index:133
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([3.13977558, 1.82458567]), 'done_state': array([-0.47299126,  0.15663355])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.6594907612730189
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([3.13977558, 1.82458567]), 'done_state': array([0.29162102, 0.41566268])}
episode index:134
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.8032973, -3.8033758]), 'done_state': array([0.29162102, 0.41566268])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.6600056445228484
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 1.8032973, -3.8033758]), 'done_state': array([-0.01012212,  0.04938329])}
episode index:135
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.28597083,  0.89499602]), 'done_state': array([-0.01012212,  0.04938329])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.6611085441954745
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-3.28597083,  0.89499602]), 'done_state': array([-0.44679721, -0.49770352])}
episode index:136
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.58770934,  1.58713808]), 'done_state': array([-0.44679721, -0.49770352])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.6616041022670404
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-2.58770934,  1.58713808]), 'done_state': array([-0.34843458,  0.04591113])}
episode index:137
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.65185278, -2.78919664]), 'done_state': array([-0.34843458,  0.04591113])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.6626794348593082
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 3.65185278, -2.78919664]), 'done_state': array([0.46222918, 0.35130167])}
episode index:138
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.51772161, -1.90773978]), 'done_state': array([0.46222918, 0.35130167])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.6637392950401765
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-2.51772161, -1.90773978]), 'done_state': array([-0.31916259, -0.13483793])}
episode index:139
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.48802999, -3.00911673]), 'done_state': array([-0.31916259, -0.13483793])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.6647840143613181
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 2.48802999, -3.00911673]), 'done_state': array([ 0.11646994, -0.1504823 ])}
episode index:140
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.23127569,  3.75736027]), 'done_state': array([ 0.11646994, -0.1504823 ])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.6652394468835782
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-3.23127569,  3.75736027]), 'done_state': array([0.21913012, 0.0373306 ])}
episode index:141
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.37837199, 0.27274158]), 'done_state': array([-0.0648974 ,  0.13277303])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6675969155674967
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.37837199, 0.27274158]), 'done_state': array([-0.0648974 ,  0.13277303])}
episode index:142
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.8002294 , -1.05184762]), 'done_state': array([-0.0648974 ,  0.13277303])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.6692221119621296
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.8002294 , -1.05184762]), 'done_state': array([0.01853916, 0.09675418])}
episode index:143
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.72942362,  3.9755247 ]), 'done_state': array([0.01853916, 0.09675418])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.6696372361846148
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-0.72942362,  3.9755247 ]), 'done_state': array([0.27524088, 0.25471425])}
episode index:144
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.9649404 , -2.15483139]), 'done_state': array([0.27524088, 0.25471425])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.6706052552454106
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-2.9649404 , -2.15483139]), 'done_state': array([-0.26745701, -0.41011068])}
episode index:145
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.85433276, 3.82857469]), 'done_state': array([-0.26745701, -0.41011068])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.671005219250579
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([2.85433276, 3.82857469]), 'done_state': array([0.24487403, 0.24761279])}
episode index:146
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.81924292,  0.08033778]), 'done_state': array([0.24487403, 0.24761279])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.6725630068747247
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.81924292,  0.08033778]), 'done_state': array([-0.30133719,  0.05144319])}
episode index:147
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.30082575, -1.36063858]), 'done_state': array([-0.30133719,  0.05144319])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.6740997433147604
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.30082575, -1.36063858]), 'done_state': array([-0.19247007,  0.04043072])}
episode index:148
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.74283725,  2.96614764]), 'done_state': array([-0.19247007,  0.04043072])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.6750118255743929
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-2.74283725,  2.96614764]), 'done_state': array([-0.10637901,  0.23082474])}
episode index:149
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.7778597 , -3.62447651]), 'done_state': array([-0.10637901,  0.23082474])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.6753717467372303
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 3.7778597 , -3.62447651]), 'done_state': array([0.06193507, 0.09019062])}
episode index:150
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.72783287, -1.65216163]), 'done_state': array([0.06193507, 0.09019062])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.675726900732348
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-3.72783287, -1.65216163]), 'done_state': array([-0.09879384, -0.05667447])}
episode index:151
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.82779319, -2.28342584]), 'done_state': array([-0.09879384, -0.05667447])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.6766102763854246
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 2.82779319, -2.28342584]), 'done_state': array([0.0079096 , 0.05164584])}
episode index:152
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.5669152 ,  3.32891109]), 'done_state': array([0.0079096 , 0.05164584])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.6769526928796374
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-1.5669152 ,  3.32891109]), 'done_state': array([ 0.10605643, -0.04318154])}
episode index:153
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.972822  , -0.73018551]), 'done_state': array([ 0.10605643, -0.04318154])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.6778166364323671
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 2.972822  , -0.73018551]), 'done_state': array([0.20372373, 0.30199806])}
episode index:154
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.04860142, -2.16916355]), 'done_state': array([0.20372373, 0.30199806])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.6792500774876422
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.04860142, -2.16916355]), 'done_state': array([-0.10217766,  0.03381787])}
episode index:155
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.26011692,  0.31372446]), 'done_state': array([-0.4096744 , -0.03417553])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6813061667345163
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.26011692,  0.31372446]), 'done_state': array([-0.4096744 , -0.03417553])}
episode index:156
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.62520369, -0.57670427]), 'done_state': array([-0.4096744 , -0.03417553])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.6816099491120035
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-3.62520369, -0.57670427]), 'done_state': array([-0.10650717,  0.04961382])}
episode index:157
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([3.1428605 , 1.85852067]), 'done_state': array([-0.10650717,  0.04961382])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.6824225443707882
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([3.1428605 , 1.85852067]), 'done_state': array([0.31147577, 0.23233513])}
episode index:158
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.09142254, -2.21226981]), 'done_state': array([0.31147577, 0.23233513])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.6837909560414123
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.09142254, -2.21226981]), 'done_state': array([-0.49831399,  0.04668535])}
episode index:159
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.33262363, -0.63126797]), 'done_state': array([-0.47723944, -0.20391692])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6857672625661534
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.33262363, -0.63126797]), 'done_state': array([-0.47723944, -0.20391692])}
episode index:160
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([3.55793543, 0.11364143]), 'done_state': array([-0.47723944, -0.20391692])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.6860357888856183
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([3.55793543, 0.11364143]), 'done_state': array([0.08321607, 0.08085093])}
episode index:161
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.64597842,  0.17833107]), 'done_state': array([0.08321607, 0.08085093])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.6868010000653367
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-2.64597842,  0.17833107]), 'done_state': array([-0.32033104, -0.28530692])}
episode index:162
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.12660431, -3.52434581]), 'done_state': array([-0.32033104, -0.28530692])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.687059889635488
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 1.12660431, -3.52434581]), 'done_state': array([-0.31116874, -0.14810209])}
episode index:163
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.69941967,  3.48926932]), 'done_state': array([-0.31116874, -0.14810209])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.6878095244547838
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.69941967,  3.48926932]), 'done_state': array([0.26559778, 0.4777129 ])}
episode index:164
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.30760732, -0.97676822]), 'done_state': array([0.26559778, 0.4777129 ])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.6885500727914216
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-2.30760732, -0.97676822]), 'done_state': array([-0.3844282 ,  0.03751594])}
episode index:165
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.72555131, -0.67235073]), 'done_state': array([-0.3844282 ,  0.03751594])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.6898238675336419
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.72555131, -0.67235073]), 'done_state': array([-0.22249156, -0.29570082])}
episode index:166
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.74603161, -3.51643427]), 'done_state': array([-0.22249156, -0.29570082])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.690058455153201
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-0.74603161, -3.51643427]), 'done_state': array([-0.22065625, -0.08490481])}
episode index:167
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.41096877, -2.43040964]), 'done_state': array([-0.22065625, -0.08490481])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.6913081072058604
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 2.41096877, -2.43040964]), 'done_state': array([ 0.26822698, -0.20237889])}
episode index:168
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([3.35128687, 3.1647825 ]), 'done_state': array([ 0.26822698, -0.20237889])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.6920104260981335
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([3.35128687, 3.1647825 ]), 'done_state': array([0.48009437, 0.46618442])}
episode index:169
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.73665791,  0.05247975]), 'done_state': array([0.48009437, 0.46618442])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.6927044824152032
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.73665791,  0.05247975]), 'done_state': array([-0.06280908, -0.34797127])}
episode index:170
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.20042153, -2.42289941]), 'done_state': array([-0.06280908, -0.34797127])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.6933904211145295
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-0.20042153, -2.42289941]), 'done_state': array([-0.01122527, -0.24847167])}
episode index:171
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([3.76048957, 2.21804856]), 'done_state': array([-0.01122527, -0.24847167])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.6935974535499102
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([3.76048957, 2.21804856]), 'done_state': array([0.01935015, 0.14198508])}
episode index:172
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.27011675, -2.06784808]), 'done_state': array([0.01935015, 0.14198508])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.6947905318530899
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 2.27011675, -2.06784808]), 'done_state': array([ 0.04973867, -0.02518622])}
episode index:173
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.37201333, -2.04724509]), 'done_state': array([ 0.04973867, -0.02518622])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.6954526552332446
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-3.37201333, -2.04724509]), 'done_state': array([-0.09933163, -0.361376  ])}
episode index:174
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.06773316,  1.07735868]), 'done_state': array([0.22360682, 0.19569375])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6971929257747689
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.06773316,  1.07735868]), 'done_state': array([0.22360682, 0.19569375])}
episode index:175
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.73066574, 3.86198328]), 'done_state': array([0.22360682, 0.19569375])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.6973736477874122
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([2.73066574, 3.86198328]), 'done_state': array([0.12273972, 0.26681808])}
episode index:176
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.26496548,  3.4040913 ]), 'done_state': array([0.12273972, 0.26681808])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.6980099548620596
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.26496548,  3.4040913 ]), 'done_state': array([0.21829525, 0.33113338])}
episode index:177
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.4922328 , -2.02838984]), 'done_state': array([0.21829525, 0.33113338])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.6991447303965425
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.4922328 , -2.02838984]), 'done_state': array([-0.35082826, -0.23343174])}
episode index:178
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.17011755,  1.75334692]), 'done_state': array([-0.35082826, -0.23343174])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.700266826874774
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.17011755,  1.75334692]), 'done_state': array([ 0.06138818, -0.00177225])}
episode index:179
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.48474278,  3.90280145]), 'done_state': array([ 0.06138818, -0.00177225])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.7004264556143586
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-1.48474278,  3.90280145]), 'done_state': array([0.02153279, 0.10690098])}
episode index:180
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.17063139, -1.94607381]), 'done_state': array([0.02153279, 0.10690098])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.7015290718816826
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.17063139, -1.94607381]), 'done_state': array([-0.29136017,  0.04236462])}
episode index:181
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.02823351,  1.10607077]), 'done_state': array([-0.29136017,  0.04236462])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.7026195714867284
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.02823351,  1.10607077]), 'done_state': array([-0.20438425, -0.26218282])}
episode index:182
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.18262496, -0.49994942]), 'done_state': array([-0.20438425, -0.26218282])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7032063497846152
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-3.18262496, -0.49994942]), 'done_state': array([-0.29744879, -0.48790774])}
episode index:183
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.06411884,  1.93842467]), 'done_state': array([-0.29744879, -0.48790774])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.7042758804923075
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.06411884,  1.93842467]), 'done_state': array([0.15268713, 0.38079299])}
episode index:184
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([3.74616566, 0.658287  ]), 'done_state': array([0.15268713, 0.38079299])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.7044095243815384
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([3.74616566, 0.658287  ]), 'done_state': array([ 0.17562603, -0.15257597])}
episode index:185
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.74829115,  3.70035802]), 'done_state': array([ 0.17562603, -0.15257597])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.7045417312397022
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-0.74829115,  3.70035802]), 'done_state': array([0.29435786, 0.0390918 ])}
episode index:186
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.7439603 , -0.16234015]), 'done_state': array([0.29435786, 0.0390918 ])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.7055869626234471
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.7439603 , -0.16234015]), 'done_state': array([-0.27927604, -0.02438502])}
episode index:187
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.36669301,  0.77447492]), 'done_state': array([-0.27927604, -0.02438502])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.7066210745243863
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.36669301,  0.77447492]), 'done_state': array([-0.47475079, -0.4116743 ])}
episode index:188
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.13388268, -1.3906752 ]), 'done_state': array([-0.47475079, -0.4116743 ])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.7067394815374848
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-3.13388268, -1.3906752 ]), 'done_state': array([-0.03360934,  0.09643874])}
episode index:189
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.01521586, -0.77172145]), 'done_state': array([-0.19361496, -0.16400821])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.7082829579504454
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.01521586, -0.77172145]), 'done_state': array([-0.19361496, -0.16400821])}
episode index:190
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.87262297, -3.74659777]), 'done_state': array([-0.19361496, -0.16400821])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.7083914241391867
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 1.87262297, -3.74659777]), 'done_state': array([-0.28597692,  0.05289628])}
episode index:191
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.49497516,  2.29834092]), 'done_state': array([-0.28597692,  0.05289628])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7089206354717951
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.49497516,  2.29834092]), 'done_state': array([0.21467652, 0.0121102 ])}
episode index:192
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.3992058 ,  3.93555722]), 'done_state': array([0.21467652, 0.0121102 ])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.7090246736299723
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-2.3992058 ,  3.93555722]), 'done_state': array([0.29681557, 0.10762964])}
episode index:193
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([3.56638261, 0.78579311]), 'done_state': array([0.29681557, 0.10762964])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.7091276392298179
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([3.56638261, 0.78579311]), 'done_state': array([-0.03221096,  0.03162784])}
episode index:194
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.76535291,  1.74281388]), 'done_state': array([-0.03221096,  0.03162784])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7096449333876137
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-3.76535291,  1.74281388]), 'done_state': array([-0.44027546, -0.4396718 ])}
episode index:195
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.76484559, -2.97910519]), 'done_state': array([-0.44027546, -0.4396718 ])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7101569490335953
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-0.76484559, -2.97910519]), 'done_state': array([-0.42847978, -0.13313099])}
episode index:196
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.56321729, -2.70009221]), 'done_state': array([-0.42847978, -0.13313099])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7106637665511912
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-2.56321729, -2.70009221]), 'done_state': array([-0.11795369,  0.08044151])}
episode index:197
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.82257641,  1.32229106]), 'done_state': array([-0.11795369,  0.08044151])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7111654646999226
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-2.82257641,  1.32229106]), 'done_state': array([ 0.03239104, -0.20664417])}
episode index:198
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.0385561 , -1.44709301]), 'done_state': array([ 0.03239104, -0.20664417])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.7121143819627371
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.0385561 , -1.44709301]), 'done_state': array([-0.11982277, -0.00994489])}
episode index:199
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.36592507, -2.61145145]), 'done_state': array([-0.11982277, -0.00994489])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7126038100529235
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.36592507, -2.61145145]), 'done_state': array([ 0.28558123, -0.25303434])}
episode index:200
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.08029999, -2.85396013]), 'done_state': array([ 0.28558123, -0.25303434])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7130883682118642
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.08029999, -2.85396013]), 'done_state': array([-0.18824739, -0.06398829])}
episode index:201
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.68435951, 3.09358721]), 'done_state': array([-0.18824739, -0.06398829])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7135681287652708
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([0.68435951, 3.09358721]), 'done_state': array([0.25744353, 0.25241374])}
episode index:202
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.65895419,  2.25125746]), 'done_state': array([0.25744353, 0.25241374])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.7144865123674123
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.65895419,  2.25125746]), 'done_state': array([0.24404374, 0.32332611])}
episode index:203
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.44244213,  2.76966878]), 'done_state': array([0.24404374, 0.32332611])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7149547157381603
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.44244213,  2.76966878]), 'done_state': array([-0.01939202,  0.1854328 ])}
episode index:204
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.77223432, -0.86415266]), 'done_state': array([-0.01939202,  0.1854328 ])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.7158573756613889
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.77223432, -0.86415266]), 'done_state': array([0.23156544, 0.09740317])}
episode index:205
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.66274531, -2.94307685]), 'done_state': array([0.23156544, 0.09740317])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7163143786921587
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 0.66274531, -2.94307685]), 'done_state': array([-0.10390465, -0.23210607])}
episode index:206
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.99529166,  0.8248251 ]), 'done_state': array([-0.10390465, -0.23210607])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.7172017488434044
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.99529166,  0.8248251 ]), 'done_state': array([-0.11112237, -0.28535921])}
episode index:207
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.92229247, 3.21238725]), 'done_state': array([-0.11112237, -0.28535921])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7176478942816573
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([2.92229247, 3.21238725]), 'done_state': array([0.26253582, 0.45254916])}
episode index:208
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([3.82567404, 3.14221136]), 'done_state': array([0.26253582, 0.45254916])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.7177022105769605
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([3.82567404, 3.14221136]), 'done_state': array([0.04375941, 0.24469483])}
episode index:209
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.41058422, -1.42035922]), 'done_state': array([-0.38824207, -0.43723488])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.7190464857646892
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.41058422, -1.42035922]), 'done_state': array([-0.38824207, -0.43723488])}
episode index:210
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.57875975,  0.57625783]), 'done_state': array([0.17009697, 0.05157194])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.7203780190075105
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.57875975,  0.57625783]), 'done_state': array([0.17009697, 0.05157194])}
episode index:211
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.9069077 , -2.84732124]), 'done_state': array([0.17009697, 0.05157194])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7208007642008714
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 0.9069077 , -2.84732124]), 'done_state': array([-0.02625472, -0.10988804])}
episode index:212
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.41933999, -1.19586735]), 'done_state': array([-0.02625472, -0.10988804])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7212195399557969
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-3.41933999, -1.19586735]), 'done_state': array([-0.28052621, -0.37819448])}
episode index:213
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([3.44480781, 3.73169724]), 'done_state': array([-0.28052621, -0.37819448])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.7212558972457231
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([3.44480781, 3.73169724]), 'done_state': array([0.09336584, 0.22264209])}
episode index:214
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.833521  ,  1.00684022]), 'done_state': array([0.09336584, 0.22264209])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.7212919163283013
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-3.833521  ,  1.00684022]), 'done_state': array([ 0.08630004, -0.07659267])}
episode index:215
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.85504995, -2.92322465]), 'done_state': array([ 0.08630004, -0.07659267])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.7213276019008554
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 3.85504995, -2.92322465]), 'done_state': array([0.20581387, 0.15331531])}
episode index:216
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.67513483,  2.93904888]), 'done_state': array([0.20581387, 0.15331531])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.7213629585741235
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-3.67513483,  2.93904888]), 'done_state': array([ 2.48989065e-04, -2.63682134e-01])}
episode index:217
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([3.32304863, 3.28058951]), 'done_state': array([ 2.48989065e-04, -2.63682134e-01])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.7213979908742422
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([3.32304863, 3.28058951]), 'done_state': array([0.11663   , 0.08559837])}
episode index:218
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.50112912, 2.56191903]), 'done_state': array([0.11663   , 0.08559837])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.7222135251624877
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.50112912, 2.56191903]), 'done_state': array([0.30546865, 0.43362292])}
episode index:219
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.58501991, 2.73705394]), 'done_state': array([0.30546865, 0.43362292])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7226125545935673
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([0.58501991, 2.73705394]), 'done_state': array([0.00766744, 0.10277743])}
episode index:220
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.11339808, -0.20283646]), 'done_state': array([ 0.08129512, -0.06782234])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.7238677014053612
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.11339808, -0.20283646]), 'done_state': array([ 0.08129512, -0.06782234])}
episode index:221
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.03484403, -3.04076361]), 'done_state': array([ 0.08129512, -0.06782234])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.724255684732364
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 0.03484403, -3.04076361]), 'done_state': array([-0.08041933, -0.09717329])}
episode index:222
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.00608933,  0.74396305]), 'done_state': array([-0.05041277, -0.04055224])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.7254922063254924
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.00608933,  0.74396305]), 'done_state': array([-0.05041277, -0.04055224])}
episode index:223
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.50785999, -2.51554725]), 'done_state': array([-0.05041277, -0.04055224])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.7262712589758251
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.50785999, -2.51554725]), 'done_state': array([-0.26554135, -0.29554267])}
episode index:224
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.6664678 ,  0.32401152]), 'done_state': array([-0.26554135, -0.29554267])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.7262833867137104
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-3.6664678 ,  0.32401152]), 'done_state': array([0.09886072, 0.02353522])}
episode index:225
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([3.54204215, 2.11848815]), 'done_state': array([0.09886072, 0.02353522])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.7262954071264817
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([3.54204215, 2.11848815]), 'done_state': array([0.28302779, 0.21928364])}
episode index:226
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.76662701,  2.79889516]), 'done_state': array([0.28302779, 0.21928364])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.726664149826365
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-2.76662701,  2.79889516]), 'done_state': array([-0.02217135,  0.01371692])}
episode index:227
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.39693218, -1.95433186]), 'done_state': array([-0.02217135,  0.01371692])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.7266743947832669
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-3.39693218, -1.95433186]), 'done_state': array([ 0.05292665, -0.19683128])}
episode index:228
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.33035386, -3.64215238]), 'done_state': array([ 0.05292665, -0.19683128])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.7266845502645628
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 3.33035386, -3.64215238]), 'done_state': array([ 0.03108595, -0.08987972])}
episode index:229
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.11529912, -3.1830502 ]), 'done_state': array([ 0.03108595, -0.08987972])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.727046791350369
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 1.11529912, -3.1830502 ]), 'done_state': array([-0.13473644, -0.28468319])}
episode index:230
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.49227074, -2.05836213]), 'done_state': array([-0.13473644, -0.28468319])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.7277955065393285
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.49227074, -2.05836213]), 'done_state': array([-0.43352846, -0.38957968])}
episode index:231
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.1940253 , -3.67473835]), 'done_state': array([-0.43352846, -0.38957968])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.7278006983214866
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-0.1940253 , -3.67473835]), 'done_state': array([ 0.15165311, -0.12450703])}
episode index:232
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.5398295,  2.4573494]), 'done_state': array([ 0.15165311, -0.12450703])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.7285397511183901
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.5398295,  2.4573494]), 'done_state': array([0.19519962, 0.37517688])}
episode index:233
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.78602308, -2.85561537]), 'done_state': array([0.19519962, 0.37517688])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7288878718401064
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 1.78602308, -2.85561537]), 'done_state': array([-0.06638348, -0.10659922])}
episode index:234
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.7600303 , 1.43098288]), 'done_state': array([-0.06638348, -0.10659922])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7292330298322762
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([2.7600303 , 1.43098288]), 'done_state': array([0.3387928 , 0.29815905])}
episode index:235
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.913998 ,  1.8542881]), 'done_state': array([0.3387928 , 0.29815905])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.7299566186889191
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.913998 ,  1.8542881]), 'done_state': array([ 0.08109984, -0.11792613])}
episode index:236
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.28404607,  3.370267  ]), 'done_state': array([ 0.08109984, -0.11792613])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7302943544750419
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.28404607,  3.370267  ]), 'done_state': array([0.28711088, 0.47740478])}
episode index:237
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.42354052, -0.82932867]), 'done_state': array([0.28711088, 0.47740478])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7306292521453148
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-3.42354052, -0.82932867]), 'done_state': array([-0.42638639, -0.46595718])}
episode index:238
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.08036055, 0.58976353]), 'done_state': array([0.43229517, 0.16875677])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.731756326404121
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.08036055, 0.58976353]), 'done_state': array([0.43229517, 0.16875677])}
episode index:239
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.89924902, 1.01942705]), 'done_state': array([0.43229517, 0.16875677])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.7324573417107705
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.89924902, 1.01942705]), 'done_state': array([0.23046437, 0.29323204])}
episode index:240
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.66238134, -2.73531148]), 'done_state': array([0.23046437, 0.29323204])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7327790954796055
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.66238134, -2.73531148]), 'done_state': array([ 0.13889743, -0.07503803])}
episode index:241
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.09799765, 1.50980096]), 'done_state': array([ 0.13889743, -0.07503803])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.7334700909528303
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.09799765, 1.50980096]), 'done_state': array([ 0.08347973, -0.09167199])}
episode index:242
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.70330474,  1.79064346]), 'done_state': array([ 0.08347973, -0.09167199])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7337850288501437
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-2.70330474,  1.79064346]), 'done_state': array([ 0.13850706, -0.01630011])}
episode index:243
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.46713905, 2.14796897]), 'done_state': array([ 0.13850706, -0.01630011])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7340973852892825
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([2.46713905, 2.14796897]), 'done_state': array([0.15965147, 0.05712761])}
episode index:244
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.88590333, 0.22530619]), 'done_state': array([0.15965147, 0.05712761])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7344071918799385
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([2.88590333, 0.22530619]), 'done_state': array([0.35003345, 0.17649509])}
episode index:245
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.87151802, 2.60340898]), 'done_state': array([0.35003345, 0.17649509])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.734714479717825
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([1.87151802, 2.60340898]), 'done_state': array([0.0141714 , 0.22093011])}
episode index:246
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.24796583, 0.57745082]), 'done_state': array([ 0.0525697 , -0.12705427])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.7357885101643115
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.24796583, 0.57745082]), 'done_state': array([ 0.0525697 , -0.12705427])}
episode index:247
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.5781071 , -1.90029254]), 'done_state': array([ 0.0525697 , -0.12705427])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7360877500426812
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-2.5781071 , -1.90029254]), 'done_state': array([ 0.07242151, -0.16470293])}
episode index:248
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.46101817,  0.75719957]), 'done_state': array([ 0.07242151, -0.16470293])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.7367460321710239
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.46101817,  0.75719957]), 'done_state': array([-0.37060547, -0.34272156])}
episode index:249
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.54152664,  0.62217743]), 'done_state': array([-0.05210545,  0.02207478])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.7377990480423398
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.54152664,  0.62217743]), 'done_state': array([-0.05210545,  0.02207478])}
episode index:250
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.12039726, -2.53411207]), 'done_state': array([-0.05210545,  0.02207478])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.738445266974442
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 2.12039726, -2.53411207]), 'done_state': array([ 0.06674451, -0.4362111 ])}
episode index:251
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.37850712, -2.5712835 ]), 'done_state': array([ 0.06674451, -0.4362111 ])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7387292143277181
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 1.37850712, -2.5712835 ]), 'done_state': array([ 0.01104968, -0.12879719])}
episode index:252
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.04023284, -1.0326987 ]), 'done_state': array([ 0.01104968, -0.12879719])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.7393666482631817
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 2.04023284, -1.0326987 ]), 'done_state': array([0.04564627, 0.00128847])}
episode index:253
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.47119624,  0.48176053]), 'done_state': array([-0.1671657 , -0.16627629])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.7403927638212007
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.47119624,  0.48176053]), 'done_state': array([-0.1671657 , -0.16627629])}
episode index:254
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.69930397, 3.7179343 ]), 'done_state': array([-0.1671657 , -0.16627629])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.7403480863160196
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([2.69930397, 3.7179343 ]), 'done_state': array([ 0.23263337, -0.04188427])}
episode index:255
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.96581042, -1.4513405 ]), 'done_state': array([ 0.23263337, -0.04188427])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7406201641038476
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-2.96581042, -1.4513405 ]), 'done_state': array([-0.13027086, -0.01197017])}
episode index:256
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.15299328, -2.98362101]), 'done_state': array([-0.13027086, -0.01197017])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7408901245548054
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-3.15299328, -2.98362101]), 'done_state': array([-0.16041308, -0.27858633])}
episode index:257
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.50096203,  2.44532615]), 'done_state': array([-0.16041308, -0.27858633])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.740844038800717
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-3.50096203,  2.44532615]), 'done_state': array([0.01875973, 0.05544495])}
episode index:258
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.53415501, -3.73650024]), 'done_state': array([0.01875973, 0.05544495])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.7407983089211776
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 3.53415501, -3.73650024]), 'done_state': array([-0.27253236,  0.13309345])}
episode index:259
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.91861411, -3.22348092]), 'done_state': array([-0.27253236,  0.13309345])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7410644692714808
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 2.91861411, -3.22348092]), 'done_state': array([ 0.13135663, -0.25950402])}
episode index:260
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.58724682,  3.29879331]), 'done_state': array([ 0.13135663, -0.25950402])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7413285900788698
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-2.58724682,  3.29879331]), 'done_state': array([0.25244371, 0.35306554])}
episode index:261
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.35469221, -1.31720299]), 'done_state': array([0.25244371, 0.35306554])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7415906946968893
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 3.35469221, -1.31720299]), 'done_state': array([0.21215639, 0.15135171])}
episode index:262
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.70625467, -3.65095594]), 'done_state': array([0.21215639, 0.15135171])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.741542821333023
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 2.70625467, -3.65095594]), 'done_state': array([ 0.05331371, -0.15411601])}
episode index:263
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.07086621,  3.93894874]), 'done_state': array([ 0.05331371, -0.15411601])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.7414953106461555
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-2.07086621,  3.93894874]), 'done_state': array([0.11086522, 0.23212589])}
episode index:264
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.60999121, -3.11756093]), 'done_state': array([0.11086522, 0.23212589])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7417538189078681
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 2.60999121, -3.11756093]), 'done_state': array([-0.41193809, -0.21818282])}
episode index:265
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.34151889, 2.15598402]), 'done_state': array([-0.41193809, -0.21818282])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.7423487293631017
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([2.34151889, 2.15598402]), 'done_state': array([0.48342253, 0.2795131 ])}
episode index:266
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.16655217,  2.77610203]), 'done_state': array([0.48342253, 0.2795131 ])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7426021049085583
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-0.16655217,  2.77610203]), 'done_state': array([0.2704661 , 0.05559963])}
episode index:267
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.61075826,  1.64955432]), 'done_state': array([0.2704661 , 0.05559963])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.7431894104872576
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.61075826,  1.64955432]), 'done_state': array([0.1181874 , 0.03644079])}
episode index:268
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.24784679, 0.01860538]), 'done_state': array([0.06359066, 0.03695207])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.7441440966936247
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.24784679, 0.01860538]), 'done_state': array([0.06359066, 0.03695207])}
episode index:269
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.21552078,  3.03440211]), 'done_state': array([0.06359066, 0.03695207])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7443880074466114
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.21552078,  3.03440211]), 'done_state': array([0.32107412, 0.29737889])}
episode index:270
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.50456647, 1.59083958]), 'done_state': array([0.32107412, 0.29737889])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.7449622214412733
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.50456647, 1.59083958]), 'done_state': array([0.41384954, 0.27285294])}
episode index:271
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.63647658, 0.51714233]), 'done_state': array([0.41384954, 0.27285294])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7452013309212686
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([2.63647658, 0.51714233]), 'done_state': array([0.06536617, 0.24081981])}
episode index:272
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.71244992, -0.7639268 ]), 'done_state': array([-0.18593369,  0.01258572])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.7461346593794325
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.71244992, -0.7639268 ]), 'done_state': array([-0.18593369,  0.01258572])}
episode index:273
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.07855313, -1.45232679]), 'done_state': array([-0.22934734, -0.36576358])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.7470611752211134
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.07855313, -1.45232679]), 'done_state': array([-0.22934734, -0.36576358])}
episode index:274
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.12772399, -0.97864367]), 'done_state': array([ 0.19017653, -0.14484047])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.7479809527657639
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.12772399, -0.97864367]), 'done_state': array([ 0.19017653, -0.14484047])}
episode index:275
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.095991 ,  2.1836342]), 'done_state': array([ 0.19017653, -0.14484047])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7482056594586417
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-3.095991 ,  2.1836342]), 'done_state': array([-0.17233681,  0.07167208])}
episode index:276
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.56977149, -1.63709615]), 'done_state': array([-0.17233681,  0.07167208])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.7487536534678163
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.56977149, -1.63709615]), 'done_state': array([-0.01192933,  0.09333619])}
episode index:277
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.43625297, -1.71568336]), 'done_state': array([-0.01192933,  0.09333619])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7489739640668529
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-3.43625297, -1.71568336]), 'done_state': array([-0.41027781, -0.43983673])}
episode index:278
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.11222213, -1.78248667]), 'done_state': array([-0.41027781, -0.43983673])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7491926953784412
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-3.11222213, -1.78248667]), 'done_state': array([-0.13495749, -0.2092494 ])}
episode index:279
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.0892322 , 2.09824793]), 'done_state': array([-0.13495749, -0.2092494 ])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.7497312928949468
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.0892322 , 2.09824793]), 'done_state': array([0.13192003, 0.26394978])}
episode index:280
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.68443939, 3.59503878]), 'done_state': array([0.13192003, 0.26394978])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7499457722796622
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([2.68443939, 3.59503878]), 'done_state': array([0.27891073, 0.38101099])}
episode index:281
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.83483903, -2.26626387]), 'done_state': array([0.27891073, 0.38101099])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.7504778794701599
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.83483903, -2.26626387]), 'done_state': array([-0.08381203, -0.42789355])}
episode index:282
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.0195356 ,  0.38284472]), 'done_state': array([-0.08381203, -0.42789355])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7506882049843996
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-3.0195356 ,  0.38284472]), 'done_state': array([-0.28194505, -0.20974486])}
episode index:283
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([3.86181686, 3.28012865]), 'done_state': array([-0.28194505, -0.20974486])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.7506118380654405
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([3.86181686, 3.28012865]), 'done_state': array([0.26021846, 0.22836156])}
episode index:284
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.76673479,  0.51980412]), 'done_state': array([0.26021846, 0.22836156])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.7511360070546846
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.76673479,  0.51980412]), 'done_state': array([-0.0962183 , -0.13956247])}
episode index:285
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([3.62143859, 2.73876712]), 'done_state': array([-0.0962183 , -0.13956247])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.7510586084286194
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([3.62143859, 2.73876712]), 'done_state': array([0.32080047, 0.03765557])}
episode index:286
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.3415687 ,  0.83716226]), 'done_state': array([-0.37131066, -0.00679575])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.751926000036882
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.3415687 ,  0.83716226]), 'done_state': array([-0.37131066, -0.00679575])}
episode index:287
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.051894  , -2.03794535]), 'done_state': array([-0.37131066, -0.00679575])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.7524401458700873
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.051894  , -2.03794535]), 'done_state': array([-8.48370708e-05, -1.59786409e-01])}
episode index:288
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.46432247, 3.82906826]), 'done_state': array([-8.48370708e-05, -1.59786409e-01])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.7523590380989107
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([2.46432247, 3.82906826]), 'done_state': array([0.33004968, 0.18379193])}
episode index:289
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.94919552, -0.62301823]), 'done_state': array([0.05429698, 0.05415939])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.7532129724502938
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.94919552, -0.62301823]), 'done_state': array([0.05429698, 0.05415939])}
episode index:290
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.09689227, -1.50278532]), 'done_state': array([0.05429698, 0.05415939])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7534081168748632
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-3.09689227, -1.50278532]), 'done_state': array([-0.21743919, -0.16077786])}
episode index:291
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.46581201, -1.18025838]), 'done_state': array([-0.2553776 , -0.18220637])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.7542526096252917
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.46581201, -1.18025838]), 'done_state': array([-0.2553776 , -0.18220637])}
episode index:292
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.70772056, -1.68393576]), 'done_state': array([-0.2553776 , -0.18220637])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.754166423244318
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 3.70772056, -1.68393576]), 'done_state': array([ 0.27548164, -0.00036062])}
episode index:293
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.24767578,  3.01756583]), 'done_state': array([ 0.27548164, -0.00036062])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7543563333693374
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-2.24767578,  3.01756583]), 'done_state': array([-0.02105589,  0.12218484])}
episode index:294
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.53946942, -0.78002075]), 'done_state': array([-0.02105589,  0.12218484])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.7548500407138481
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.53946942, -0.78002075]), 'done_state': array([0.07620818, 0.07117086])}
episode index:295
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.01254176,  2.84113705]), 'done_state': array([0.07620818, 0.07117086])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7550363581438689
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-2.01254176,  2.84113705]), 'done_state': array([0.25105525, 0.06494542])}
episode index:296
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.99804553, 3.12122986]), 'done_state': array([0.25105525, 0.06494542])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7552214209110613
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([2.99804553, 3.12122986]), 'done_state': array([0.31449315, 0.19645426])}
episode index:297
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.60138433,  2.28483025]), 'done_state': array([0.31449315, 0.19645426])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.7557072550690779
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.60138433,  2.28483025]), 'done_state': array([0.20127516, 0.26030297])}
episode index:298
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.46229689, -1.51770664]), 'done_state': array([0.20127516, 0.26030297])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7558888361558034
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-3.46229689, -1.51770664]), 'done_state': array([-0.46973372, -0.18540151])}
episode index:299
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.17402412, 2.8331099 ]), 'done_state': array([-0.46973372, -0.18540151])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7560692067019507
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([1.17402412, 2.8331099 ]), 'done_state': array([ 0.11171912, -0.02766165])}
episode index:300
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.27079225, 2.68073387]), 'done_state': array([ 0.11171912, -0.02766165])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7562483787727082
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([1.27079225, 2.68073387]), 'done_state': array([0.01009174, 0.10428318])}
episode index:301
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.60987869, -0.7818099 ]), 'done_state': array([0.01009174, 0.10428318])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.7561581523529312
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 3.60987869, -0.7818099 ]), 'done_state': array([0.18476209, 0.10684128])}
episode index:302
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.52300045,  2.2069577 ]), 'done_state': array([0.18476209, 0.10684128])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.7566328779227235
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.52300045,  2.2069577 ]), 'done_state': array([0.21596272, 0.23353101])}
episode index:303
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.04841809,  0.39429164]), 'done_state': array([-0.16688605, -0.11007095])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.7574334276663987
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.04841809,  0.39429164]), 'done_state': array([-0.16688605, -0.11007095])}
episode index:304
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.4463623 , -2.45402377]), 'done_state': array([-0.16688605, -0.11007095])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7576057770838859
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-3.4463623 , -2.45402377]), 'done_state': array([-0.42806861, -0.40991384])}
episode index:305
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.63171657,  0.29448478]), 'done_state': array([ 0.14283956, -0.05239087])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.7583979150672718
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.63171657,  0.29448478]), 'done_state': array([ 0.14283956, -0.05239087])}
episode index:306
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([3.94319331, 1.09088567]), 'done_state': array([ 0.14283956, -0.05239087])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.758302156386271
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([3.94319331, 1.09088567]), 'done_state': array([0.04955818, 0.22591375])}
episode index:307
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.11878507, 2.29268885]), 'done_state': array([0.04955818, 0.22591375])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.7587622143200818
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.11878507, 2.29268885]), 'done_state': array([0.21794738, 0.26227282])}
episode index:308
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.73296074, -1.7472567 ]), 'done_state': array([0.21794738, 0.26227282])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7589280323967159
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 2.73296074, -1.7472567 ]), 'done_state': array([-0.04975144,  0.14145541])}
episode index:309
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.95673382, -2.84924498]), 'done_state': array([-0.04975144,  0.14145541])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7590927806793072
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 1.95673382, -2.84924498]), 'done_state': array([ 0.00111457, -0.08495763])}
episode index:310
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.49923   , -0.78707819]), 'done_state': array([ 0.00111457, -0.08495763])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.7595458585549365
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.49923   , -0.78707819]), 'done_state': array([-0.06212804, -0.04320372])}
episode index:311
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.19244711,  1.72127254]), 'done_state': array([-0.06212804, -0.04320372])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.7599960320852092
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.19244711,  1.72127254]), 'done_state': array([0.3720714 , 0.10580631])}
episode index:312
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.78390686, 1.77361297]), 'done_state': array([0.3720714 , 0.10580631])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.760155789171199
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([2.78390686, 1.77361297]), 'done_state': array([0.147966  , 0.06708891])}
episode index:313
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.6341033 , -3.58310631]), 'done_state': array([0.147966  , 0.06708891])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7603145286961315
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 2.6341033 , -3.58310631]), 'done_state': array([-0.14149178, -0.47219566])}
episode index:314
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.53198661,  0.60553578]), 'done_state': array([-0.14149178, -0.47219566])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.7607579746367786
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.53198661,  0.60553578]), 'done_state': array([-0.00300588, -0.11855622])}
episode index:315
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.96289701,  3.67569892]), 'done_state': array([-0.00300588, -0.11855622])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.760657474717042
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-1.96289701,  3.67569892]), 'done_state': array([0.39232236, 0.12691488])}
episode index:316
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.13354476,  2.16809169]), 'done_state': array([0.39232236, 0.12691488])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.7610970410428558
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.13354476,  2.16809169]), 'done_state': array([-0.11944569,  0.26510761])}
episode index:317
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.04813753,  2.6576145 ]), 'done_state': array([-0.11944569,  0.26510761])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7612508239326582
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-3.04813753,  2.6576145 ]), 'done_state': array([-0.02415099, -0.11693229])}
episode index:318
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.96414847, 1.92424438]), 'done_state': array([-0.02415099, -0.11693229])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.7611497241711138
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([2.96414847, 1.92424438]), 'done_state': array([0.2360272 , 0.10704703])}
episode index:319
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.05731792, 0.29160433]), 'done_state': array([0.33851026, 0.16562087])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.7618961312830791
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.05731792, 0.29160433]), 'done_state': array([0.33851026, 0.16562087])}
episode index:320
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.0423411, 3.1696695]), 'done_state': array([0.33851026, 0.16562087])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7620459875719169
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([1.0423411, 3.1696695]), 'done_state': array([0.19581941, 0.20868671])}
episode index:321
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.20783388, -3.30757335]), 'done_state': array([0.19581941, 0.20868671])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7621949130763519
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 3.20783388, -3.30757335]), 'done_state': array([ 0.10569747, -0.25812563])}
episode index:322
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([3.22455421, 3.37896623]), 'done_state': array([ 0.10569747, -0.25812563])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7623429164414406
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([3.22455421, 3.37896623]), 'done_state': array([0.42395589, 0.28804698])}
episode index:323
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.25195299, -0.50798937]), 'done_state': array([0.42395589, 0.28804698])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.762767783983288
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.25195299, -0.50798937]), 'done_state': array([-0.31283649, -0.14720701])}
episode index:324
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.89066328, 2.40645015]), 'done_state': array([-0.31283649, -0.14720701])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.7631900369556471
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.89066328, 2.40645015]), 'done_state': array([0.06731971, 0.41617003])}
episode index:325
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.30980608, -2.68127463]), 'done_state': array([0.06731971, 0.41617003])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7633336257993414
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 0.30980608, -2.68127463]), 'done_state': array([ 0.00245167, -0.04913507])}
episode index:326
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.20864018, 3.74311169]), 'done_state': array([ 0.00245167, -0.04913507])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.7632286300017899
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([2.20864018, 3.74311169]), 'done_state': array([0.22680513, 0.11088991])}
episode index:327
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([3.79416831, 3.43677965]), 'done_state': array([0.22680513, 0.11088991])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.7631242744225162
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([3.79416831, 3.43677965]), 'done_state': array([0.16631609, 0.27589484])}
episode index:328
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.24606452,  1.17788227]), 'done_state': array([-0.01640043,  0.2799781 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.7638442614303504
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.24606452,  1.17788227]), 'done_state': array([-0.01640043,  0.2799781 ])}
episode index:329
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.79659667, -0.67661459]), 'done_state': array([-0.01640043,  0.2799781 ])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7639841273048039
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-2.79659667, -0.67661459]), 'done_state': array([ 0.03304433, -0.02511278])}
episode index:330
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.81235423, -0.68046939]), 'done_state': array([ 0.03304433, -0.02511278])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7641231480682334
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 2.81235423, -0.68046939]), 'done_state': array([0.28165983, 0.21832167])}
episode index:331
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.71430073, -1.11265501]), 'done_state': array([ 0.05080934, -0.08670642])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.7648336205138111
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.71430073, -1.11265501]), 'done_state': array([ 0.05080934, -0.08670642])}
episode index:332
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.26949719, 1.08788128]), 'done_state': array([0.4359035 , 0.25826525])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.7655398258576135
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.26949719, 1.08788128]), 'done_state': array([0.4359035 , 0.25826525])}
episode index:333
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.71314765, 2.66558104]), 'done_state': array([0.4359035 , 0.25826525])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7656729401514529
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([2.71314765, 2.66558104]), 'done_state': array([0.0889793, 0.1997763])}
episode index:334
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.53162974,  1.72486234]), 'done_state': array([0.0889793, 0.1997763])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.7660739164495083
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.53162974,  1.72486234]), 'done_state': array([0.07540853, 0.02265574])}
episode index:335
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.38447791, -0.88042214]), 'done_state': array([0.07540853, 0.02265574])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.7664725059838847
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 2.38447791, -0.88042214]), 'done_state': array([0.31827518, 0.26824956])}
episode index:336
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.40856051, 0.54481874]), 'done_state': array([0.048298  , 0.15665392])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.7671654659067813
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.40856051, 0.54481874]), 'done_state': array([0.048298  , 0.15665392])}
episode index:337
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.0800512 ,  0.97643396]), 'done_state': array([0.048298  , 0.15665392])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7672921952975895
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-3.0800512 ,  0.97643396]), 'done_state': array([-0.2471666 , -0.16557544])}
episode index:338
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.99348038, -3.62144636]), 'done_state': array([-0.2471666 , -0.16557544])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.7671792389692781
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-2.99348038, -3.62144636]), 'done_state': array([ 0.0006775 , -0.05590143])}
episode index:339
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.91866258,  1.81793943]), 'done_state': array([ 0.0006775 , -0.05590143])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.7675698882664271
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.91866258,  1.81793943]), 'done_state': array([0.10332011, 0.06171903])}
episode index:340
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.96161049,  2.00066407]), 'done_state': array([0.10332011, 0.06171903])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7676943167465843
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-2.96161049,  2.00066407]), 'done_state': array([ 0.00411905, -0.18362221])}
episode index:341
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.87048396, -0.86311752]), 'done_state': array([ 0.00411905, -0.18362221])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.7680811754695474
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.87048396, -0.86311752]), 'done_state': array([-0.1474638 , -0.30276881])}
episode index:342
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.67776627, -1.33381655]), 'done_state': array([-0.1474638 , -0.30276881])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7682033877859628
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-2.67776627, -1.33381655]), 'done_state': array([ 0.10559111, -0.11722766])}
episode index:343
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.5255884 ,  3.35086012]), 'done_state': array([ 0.10559111, -0.11722766])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.7680894244493756
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-2.5255884 ,  3.35086012]), 'done_state': array([0.32280824, 0.19715127])}
episode index:344
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.00821211, -2.34392966]), 'done_state': array([0.32280824, 0.19715127])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7682109043785078
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 0.00821211, -2.34392966]), 'done_state': array([ 0.07335075, -0.08960329])}
episode index:345
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([3.52232792, 1.37846299]), 'done_state': array([ 0.07335075, -0.08960329])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.7680975780652751
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([3.52232792, 1.37846299]), 'done_state': array([0.33998512, 0.31630302])}
episode index:346
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.16564583,  1.21502259]), 'done_state': array([0.25115037, 0.27887229])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.7687658847567297
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.16564583,  1.21502259]), 'done_state': array([0.25115037, 0.27887229])}
episode index:347
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.85554645, 2.19120573]), 'done_state': array([0.25115037, 0.27887229])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7688843735936356
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([2.85554645, 2.19120573]), 'done_state': array([0.15632255, 0.18445393])}
episode index:348
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.23198801,  3.51555639]), 'done_state': array([0.15632255, 0.18445393])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7690021834114189
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-0.23198801,  3.51555639]), 'done_state': array([0.44206585, 0.48462552])}
episode index:349
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.07285081, -1.97564982]), 'done_state': array([0.44206585, 0.48462552])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.7693764628873861
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.07285081, -1.97564982]), 'done_state': array([ 0.23075177, -0.03739162])}
episode index:350
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.8942181 , -1.83742682]), 'done_state': array([ 0.23075177, -0.03739162])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.7697486097167668
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.8942181 , -1.83742682]), 'done_state': array([ 0.02416811, -0.15457507])}
episode index:351
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.83640869, -2.87842367]), 'done_state': array([ 0.02416811, -0.15457507])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.7696328466209805
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 3.83640869, -2.87842367]), 'done_state': array([0.20963881, 0.09883649])}
episode index:352
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.29584377, -1.28865844]), 'done_state': array([0.20963881, 0.09883649])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7697472011631307
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-3.29584377, -1.28865844]), 'done_state': array([-0.44192868, -0.44499315])}
episode index:353
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.02152948, -1.80425308]), 'done_state': array([-0.44192868, -0.44499315])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7698609096344213
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 3.02152948, -1.80425308]), 'done_state': array([0.18707777, 0.0998212 ])}
episode index:354
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.94793794, 2.92809601]), 'done_state': array([0.18707777, 0.0998212 ])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.769973977494606
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([2.94793794, 2.92809601]), 'done_state': array([0.37275436, 0.24146234])}
episode index:355
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.83143156, -3.81540591]), 'done_state': array([0.37275436, 0.24146234])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.7698588820522054
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 1.83143156, -3.81540591]), 'done_state': array([ 0.17021749, -0.09249817])}
episode index:356
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.87737281, -3.88451758]), 'done_state': array([ 0.17021749, -0.09249817])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.7697444314021992
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 2.87737281, -3.88451758]), 'done_state': array([-0.04959598,  0.20713042])}
episode index:357
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.23615319,  1.28879096]), 'done_state': array([-0.28767423,  0.2462875 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.7703876033815227
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.23615319,  1.28879096]), 'done_state': array([-0.28767423,  0.2462875 ])}
episode index:358
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.48924115, -2.97373749]), 'done_state': array([-0.28767423,  0.2462875 ])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.7702723175782314
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-3.48924115, -2.97373749]), 'done_state': array([-0.00443679,  0.14524429])}
episode index:359
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([3.35976692, 3.84378695]), 'done_state': array([-0.00443679,  0.14524429])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.7701576722516252
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([3.35976692, 3.84378695]), 'done_state': array([0.24067095, 0.34841633])}
episode index:360
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.71568033, -0.47247792]), 'done_state': array([0.24067095, 0.34841633])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.770268038810485
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-2.71568033, -0.47247792]), 'done_state': array([-0.09531661, -0.11260456])}
episode index:361
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.06265961, 2.57959176]), 'done_state': array([-0.09531661, -0.11260456])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.7706264143938814
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.06265961, 2.57959176]), 'done_state': array([0.47729319, 0.48018837])}
episode index:362
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.81823996, -1.6209507 ]), 'done_state': array([0.47729319, 0.48018837])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7707348815718597
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-2.81823996, -1.6209507 ]), 'done_state': array([-0.0140948 , -0.22722792])}
episode index:363
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.66459902, -0.79369013]), 'done_state': array([-0.0140948 , -0.22722792])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.770620225303805
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 3.66459902, -0.79369013]), 'done_state': array([0.15983033, 0.15187462])}
episode index:364
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.70380081, -1.96843894]), 'done_state': array([0.15983033, 0.15187462])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.7709746904399589
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.70380081, -1.96843894]), 'done_state': array([ 0.08008965, -0.15777186])}
episode index:365
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.44638758, -1.95020795]), 'done_state': array([ 0.08008965, -0.15777186])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.7713272186081558
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.44638758, -1.95020795]), 'done_state': array([0.03679066, 0.0392718 ])}
episode index:366
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.32175566, -0.81534027]), 'done_state': array([0.01534171, 0.00859199])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.7719503052059536
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.32175566, -0.81534027]), 'done_state': array([0.01534171, 0.00859199])}
episode index:367
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.62304065, -0.96785562]), 'done_state': array([0.01534171, 0.00859199])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.7718335924200679
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 3.62304065, -0.96785562]), 'done_state': array([0.3478945 , 0.35459041])}
episode index:368
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.30558146, -0.18070254]), 'done_state': array([-0.45483661, -0.1273683 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.772451929567981
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.30558146, -0.18070254]), 'done_state': array([-0.45483661, -0.1273683 ])}
episode index:369
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.97104905,  3.44266304]), 'done_state': array([-0.45483661, -0.1273683 ])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7725534108394189
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-0.97104905,  3.44266304]), 'done_state': array([0.18366505, 0.49654989])}
episode index:370
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.42243234, -2.35969046]), 'done_state': array([0.18366505, 0.49654989])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.772654345042008
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 2.42243234, -2.35969046]), 'done_state': array([-0.04482863, -0.067531  ])}
episode index:371
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.62857887, -3.3286384 ]), 'done_state': array([-0.04482863, -0.067531  ])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7727547365875941
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 1.62857887, -3.3286384 ]), 'done_state': array([-0.09478988, -0.36825529])}
episode index:372
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.61212772,  2.90444579]), 'done_state': array([-0.09478988, -0.36825529])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7728545898407104
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-0.61212772,  2.90444579]), 'done_state': array([0.27034736, 0.42945647])}
episode index:373
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.75231234, -2.0471993 ]), 'done_state': array([0.27034736, 0.42945647])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.7731945508304411
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.75231234, -2.0471993 ]), 'done_state': array([-0.09469884, -0.08072902])}
episode index:374
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.05889268, -3.04197884]), 'done_state': array([-0.09469884, -0.08072902])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7732926986948933
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 1.05889268, -3.04197884]), 'done_state': array([ 0.08733967, -0.09885488])}
episode index:375
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.36707958,  1.18866663]), 'done_state': array([ 0.08733967, -0.09885488])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7733903244962367
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-3.36707958,  1.18866663]), 'done_state': array([-0.3793472 , -0.37692505])}
episode index:376
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.4385337 , -2.46509283]), 'done_state': array([-0.3793472 , -0.37692505])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7734874323888196
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 3.4385337 , -2.46509283]), 'done_state': array([0.4652406 , 0.33352034])}
episode index:377
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([3.54309558, 2.82555738]), 'done_state': array([0.4652406 , 0.33352034])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.7733697407687433
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([3.54309558, 2.82555738]), 'done_state': array([0.19744638, 0.32579732])}
episode index:378
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.29768311, -1.67631409]), 'done_state': array([0.19744638, 0.32579732])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.7737038575477175
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.29768311, -1.67631409]), 'done_state': array([ 0.11732146, -0.07061971])}
episode index:379
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.81882406, -0.23228828]), 'done_state': array([ 0.11732146, -0.07061971])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.7735862158173288
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-3.81882406, -0.23228828]), 'done_state': array([-0.20980051, -0.15810318])}
episode index:380
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.94349986, -1.5408516 ]), 'done_state': array([-0.20980051, -0.15810318])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.7739180105264696
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.94349986, -1.5408516 ]), 'done_state': array([-0.14285111, -0.13339458])}
episode index:381
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([3.30899489, 0.86206429]), 'done_state': array([-0.14285111, -0.13339458])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7740124659962956
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([3.30899489, 0.86206429]), 'done_state': array([0.35123928, 0.36302331])}
episode index:382
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.12971028,  0.81249033]), 'done_state': array([0.03781913, 0.1822718 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.7746025117769841
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.12971028,  0.81249033]), 'done_state': array([0.03781913, 0.1822718 ])}
episode index:383
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.32577537, -1.87324051]), 'done_state': array([0.03781913, 0.1822718 ])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.7749290677358981
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.32577537, -1.87324051]), 'done_state': array([ 0.20465755, -0.01480487])}
episode index:384
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.07938685, -0.27662798]), 'done_state': array([-0.1586216 , -0.16719523])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.7755136675599608
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.07938685, -0.27662798]), 'done_state': array([-0.1586216 , -0.16719523])}
episode index:385
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.17278911, 0.68938079]), 'done_state': array([0.2165301 , 0.18187029])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.7760952383693909
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.17278911, 0.68938079]), 'done_state': array([0.2165301 , 0.18187029])}
episode index:386
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.96733757, 0.35031555]), 'done_state': array([0.2165301 , 0.18187029])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7761828475725707
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([2.96733757, 0.35031555]), 'done_state': array([0.28191463, 0.32804014])}
episode index:387
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.29756321, 3.44087608]), 'done_state': array([0.28191463, 0.32804014])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7762700051819198
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([1.29756321, 3.44087608]), 'done_state': array([0.24492119, 0.46183552])}
episode index:388
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.48232904, -0.69936471]), 'done_state': array([0.24492119, 0.46183552])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.776588077148033
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.48232904, -0.69936471]), 'done_state': array([-0.38110909, -0.38434352])}
episode index:389
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.48946674, -3.0060543 ]), 'done_state': array([-0.38110909, -0.38434352])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7766737487450894
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 2.48946674, -3.0060543 ]), 'done_state': array([ 0.00417286, -0.11795207])}
episode index:390
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.09857631, -0.34874958]), 'done_state': array([ 0.00417286, -0.11795207])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.776758982124258
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 3.09857631, -0.34874958]), 'done_state': array([0.17996492, 0.33634357])}
episode index:391
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.38700297, -2.78234774]), 'done_state': array([0.17996492, 0.33634357])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7768437806392471
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-3.38700297, -2.78234774]), 'done_state': array([-0.31164978, -0.3541624 ])}
episode index:392
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.17645256, -0.53272978]), 'done_state': array([-0.31164978, -0.3541624 ])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7769281476096307
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 3.17645256, -0.53272978]), 'done_state': array([0.32110486, 0.33521734])}
episode index:393
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.54244502, -3.69920792]), 'done_state': array([0.32110486, 0.33521734])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.7768065025649362
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 1.54244502, -3.69920792]), 'done_state': array([-0.06127193,  0.01220814])}
episode index:394
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.63205318, -0.64794983]), 'done_state': array([-0.06127193,  0.01220814])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.7771183848369236
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.63205318, -0.64794983]), 'done_state': array([0.12750546, 0.04723844])}
episode index:395
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.64867955, -3.48652089]), 'done_state': array([0.12750546, 0.04723844])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.7769968737641031
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 1.64867955, -3.48652089]), 'done_state': array([ 0.28691106, -0.08792204])}
episode index:396
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.8217798 , -2.94086771]), 'done_state': array([ 0.28691106, -0.08792204])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7770800050644454
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.8217798 , -2.94086771]), 'done_state': array([-0.02557829,  0.03817951])}
episode index:397
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.331783  , -0.59075569]), 'done_state': array([-0.02557829,  0.03817951])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7771627186195599
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 3.331783  , -0.59075569]), 'done_state': array([0.30549957, 0.34650947])}
episode index:398
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.57981237, -2.94420263]), 'done_state': array([0.30549957, 0.34650947])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.777245017570388
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 2.57981237, -2.94420263]), 'done_state': array([-0.0793637 , -0.00190727])}
episode index:399
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.93324748, 0.35895412]), 'done_state': array([-0.0793637 , -0.00190727])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.777551905026462
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.93324748, 0.35895412]), 'done_state': array([0.3305408 , 0.18607494])}
episode index:400
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.45064094, -0.43209   ]), 'done_state': array([0.3305408 , 0.18607494])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7776328229690395
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 2.45064094, -0.43209   ]), 'done_state': array([0.27358931, 0.16593108])}
episode index:401
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.42727288, 1.5755128 ]), 'done_state': array([0.27358931, 0.16593108])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7777133383347881
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([2.42727288, 1.5755128 ]), 'done_state': array([0.20945266, 0.14486155])}
episode index:402
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.74522532, 2.30163612]), 'done_state': array([0.20945266, 0.14486155])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.7780167791825925
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.74522532, 2.30163612]), 'done_state': array([0.28383871, 0.35024403])}
episode index:403
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.15639935, -3.13234923]), 'done_state': array([0.28383871, 0.35024403])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7780959455707545
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.15639935, -3.13234923]), 'done_state': array([ 0.20291714, -0.2358516 ])}
episode index:404
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.2554941 , 0.61265694]), 'done_state': array([0.2510133 , 0.12851434])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.7786438568162587
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.2554941 , 0.61265694]), 'done_state': array([0.2510133 , 0.12851434])}
episode index:405
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.48792378, -0.44723409]), 'done_state': array([0.2510133 , 0.12851434])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.7789427635728688
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.48792378, -0.44723409]), 'done_state': array([-0.42469221, -0.34754798])}
episode index:406
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.35809225, 0.1736701 ]), 'done_state': array([-0.42469221, -0.34754798])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.7792402015002082
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.35809225, 0.1736701 ]), 'done_state': array([0.04470365, 0.18576606])}
episode index:407
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.45000599,  1.43922102]), 'done_state': array([0.04470365, 0.18576606])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7793155931631979
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-2.45000599,  1.43922102]), 'done_state': array([-0.07899804,  0.05318002])}
episode index:408
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.25659773, -1.94202451]), 'done_state': array([-0.07899804,  0.05318002])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.7796106650625544
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.25659773, -1.94202451]), 'done_state': array([-0.12774595,  0.03769188])}
episode index:409
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.7487681 ,  1.02470451]), 'done_state': array([-0.12774595,  0.03769188])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.7799042975867919
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.7487681 ,  1.02470451]), 'done_state': array([ 0.09886454, -0.14590072])}
episode index:410
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.03406742, -1.56060595]), 'done_state': array([ 0.09886454, -0.14590072])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.7801965012422984
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.03406742, -1.56060595]), 'done_state': array([-0.1574177 , -0.12824586])}
episode index:411
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.2195062 ,  3.34849236]), 'done_state': array([-0.1574177 , -0.12824586])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.7800722378897686
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-0.2195062 ,  3.34849236]), 'done_state': array([0.14355856, 0.0643385 ])}
episode index:412
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([3.76156936, 2.64837077]), 'done_state': array([0.14355856, 0.0643385 ])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.7799485762968151
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([3.76156936, 2.64837077]), 'done_state': array([0.18688719, 0.22166522])}
episode index:413
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.11933644, -3.20637628]), 'done_state': array([0.18688719, 0.22166522])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7800211642767745
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.11933644, -3.20637628]), 'done_state': array([-0.01428141, -0.17291273])}
episode index:414
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.36728034,  0.23571378]), 'done_state': array([0.04500085, 0.15380616])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.7805512337604449
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.36728034,  0.23571378]), 'done_state': array([0.04500085, 0.15380616])}
episode index:415
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.27938378, -0.06334322]), 'done_state': array([0.04500085, 0.15380616])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.7808383702177515
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 2.27938378, -0.06334322]), 'done_state': array([0.39699571, 0.0634632 ])}
episode index:416
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.43203309, -2.42863825]), 'done_state': array([0.39699571, 0.0634632 ])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7809083021836561
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.43203309, -2.42863825]), 'done_state': array([-0.03210437,  0.01609613])}
episode index:417
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.09689571,  2.09288308]), 'done_state': array([-0.03210437,  0.01609613])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.7811932105516378
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.09689571,  2.09288308]), 'done_state': array([0.26724484, 0.37287758])}
episode index:418
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.19954323, -1.21480635]), 'done_state': array([-0.11671638, -0.24107597])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.7817154224596291
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.19954323, -1.21480635]), 'done_state': array([-0.11671638, -0.24107597])}
episode index:419
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([3.53459944, 0.02707764]), 'done_state': array([-0.11671638, -0.24107597])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.781589909549011
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([3.53459944, 0.02707764]), 'done_state': array([0.13340438, 0.12430394])}
episode index:420
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.29066148,  1.91564118]), 'done_state': array([0.13340438, 0.12430394])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.7818711686712223
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.29066148,  1.91564118]), 'done_state': array([0.17536454, 0.12945327])}
episode index:421
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.06066726,  3.54848377]), 'done_state': array([0.17536454, 0.12945327])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7819378246696317
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-2.06066726,  3.54848377]), 'done_state': array([0.3151285, 0.3072941])}
episode index:422
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.29464804, 1.59795135]), 'done_state': array([0.3151285, 0.3072941])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.7822169314671029
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.29464804, 1.59795135]), 'done_state': array([0.08288559, 0.12721162])}
episode index:423
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.87455217, -2.24065095]), 'done_state': array([0.08288559, 0.12721162])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.7824947217230767
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.87455217, -2.24065095]), 'done_state': array([ 0.15321216, -0.40245189])}
episode index:424
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.22791407, -1.2088707 ]), 'done_state': array([-0.22407387, -0.32557946])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.7830064988484342
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.22791407, -1.2088707 ]), 'done_state': array([-0.22407387, -0.32557946])}
episode index:425
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.34933735, 1.68724849]), 'done_state': array([-0.22407387, -0.32557946])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7830698638746115
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([2.34933735, 1.68724849]), 'done_state': array([0.22404253, 0.21065047])}
episode index:426
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.94725442, -0.63875736]), 'done_state': array([0.13791007, 0.01111034])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.7835778969802917
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.94725442, -0.63875736]), 'done_state': array([0.13791007, 0.01111034])}
episode index:427
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.82751273,  2.14122498]), 'done_state': array([0.13791007, 0.01111034])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.7838499112396834
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.82751273,  2.14122498]), 'done_state': array([0.01304854, 0.33814601])}
episode index:428
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.24145323, -1.07089093]), 'done_state': array([ 0.14065405, -0.12949349])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.78435375760043
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.24145323, -1.07089093]), 'done_state': array([ 0.14065405, -0.12949349])}
episode index:429
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.88312472, -1.23487038]), 'done_state': array([-0.08671568, -0.1256683 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.7848552604897314
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.88312472, -1.23487038]), 'done_state': array([-0.08671568, -0.1256683 ])}
episode index:430
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.64555418, -3.08295367]), 'done_state': array([-0.08671568, -0.1256683 ])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7849136009526323
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-2.64555418, -3.08295367]), 'done_state': array([ 0.0268935 , -0.07399656])}
episode index:431
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.95726091, 0.46593819]), 'done_state': array([ 0.0268935 , -0.07399656])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7849716713207975
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([2.95726091, 0.46593819]), 'done_state': array([0.35193543, 0.19215708])}
episode index:432
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.24014733, -1.09841991]), 'done_state': array([0.35193543, 0.19215708])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7850294734655532
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 3.24014733, -1.09841991]), 'done_state': array([0.46071419, 0.36473057])}
episode index:433
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.13928106,  1.92697033]), 'done_state': array([0.46071419, 0.36473057])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.7852943825128675
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.13928106,  1.92697033]), 'done_state': array([-0.03692207,  0.03019847])}
episode index:434
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.77898174, 3.50845848]), 'done_state': array([-0.03692207,  0.03019847])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.7851649701392747
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([0.77898174, 3.50845848]), 'done_state': array([ 0.21470248, -0.03015481])}
episode index:435
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.67909327, -3.41153246]), 'done_state': array([ 0.21470248, -0.03015481])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.785036151400423
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 3.67909327, -3.41153246]), 'done_state': array([ 0.14226932, -0.06334781])}
episode index:436
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.69956102, -2.59031497]), 'done_state': array([ 0.14226932, -0.06334781])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7850932769120926
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 0.69956102, -2.59031497]), 'done_state': array([0.15646678, 0.13335597])}
episode index:437
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.34942886, -2.06761307]), 'done_state': array([0.15646678, 0.13335597])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.7853556210287316
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.34942886, -2.06761307]), 'done_state': array([-0.22332239, -0.0250248 ])}
episode index:438
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.19000061, -1.48624752]), 'done_state': array([-0.25289588, -0.41310697])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.785844560388575
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.19000061, -1.48624752]), 'done_state': array([-0.25289588, -0.41310697])}
episode index:439
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.66875267, -0.76946676]), 'done_state': array([0.11736135, 0.10684181])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.7863312772967828
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.66875267, -0.76946676]), 'done_state': array([0.11736135, 0.10684181])}
episode index:440
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.75105857, -2.84868512]), 'done_state': array([0.11736135, 0.10684181])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.786384947869806
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 1.75105857, -2.84868512]), 'done_state': array([ 0.16064621, -0.03931504])}
episode index:441
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.49045473,  3.69437138]), 'done_state': array([ 0.16064621, -0.03931504])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7864383755895575
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-3.49045473,  3.69437138]), 'done_state': array([-0.42432228,  0.38621274])}
episode index:442
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.56337826,  1.00301327]), 'done_state': array([-0.42432228,  0.38621274])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.7866947223715224
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.56337826,  1.00301327]), 'done_state': array([0.0159564 , 0.01029685])}
episode index:443
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.16110032,  0.33364697]), 'done_state': array([0.0159564 , 0.01029685])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7867472117355505
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-3.16110032,  0.33364697]), 'done_state': array([-0.14096178, -0.21537943])}
episode index:444
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([3.46436746, 3.67762117]), 'done_state': array([-0.14096178, -0.21537943])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.7866174427204145
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([3.46436746, 3.67762117]), 'done_state': array([0.24661313, 0.05293742])}
episode index:445
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.73536835, -1.11152188]), 'done_state': array([-0.14018153, -0.25294903])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.7870958789474987
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.73536835, -1.11152188]), 'done_state': array([-0.14018153, -0.25294903])}
episode index:446
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.78853957, -3.8813206 ]), 'done_state': array([-0.14018153, -0.25294903])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.7869659105382201
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 3.78853957, -3.8813206 ]), 'done_state': array([-0.25359644, -0.09450416])}
episode index:447
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.28279126, -3.5576501 ]), 'done_state': array([-0.25359644, -0.09450416])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.787017325916483
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.28279126, -3.5576501 ]), 'done_state': array([ 0.17541372, -0.390477  ])}
episode index:448
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.95830835,  2.47734466]), 'done_state': array([ 0.17541372, -0.390477  ])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.7872689577073149
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.95830835,  2.47734466]), 'done_state': array([-0.02858031,  0.40787062])}
episode index:449
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.33684924, -3.0363044 ]), 'done_state': array([-0.02858031,  0.40787062])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.787319471134632
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-2.33684924, -3.0363044 ]), 'done_state': array([-0.06926433, -0.4920081 ])}
episode index:450
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.24491994, -2.34362814]), 'done_state': array([-0.06926433, -0.4920081 ])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.7875693170966394
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 2.24491994, -2.34362814]), 'done_state': array([ 0.234164  , -0.21174826])}
episode index:451
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.64651105, -2.48473735]), 'done_state': array([ 0.234164  , -0.21174826])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.7878180575455406
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.64651105, -2.48473735]), 'done_state': array([-0.09377018, -0.48340191])}
episode index:452
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.25835697, -2.04396413]), 'done_state': array([-0.09377018, -0.48340191])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.7880656998026143
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.25835697, -2.04396413]), 'done_state': array([-0.04312339,  0.05538785])}
episode index:453
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.32911748,  0.97276108]), 'done_state': array([-0.15270966,  0.16538894])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.7885325154418157
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.32911748,  0.97276108]), 'done_state': array([-0.15270966,  0.16538894])}
episode index:454
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([3.63928688, 2.78106169]), 'done_state': array([-0.15270966,  0.16538894])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.788401674748537
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([3.63928688, 2.78106169]), 'done_state': array([0.28185509, 0.35391573])}
episode index:455
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.30538472, -0.89595621]), 'done_state': array([-0.40514793, -0.03648791])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.788865706163562
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.30538472, -0.89595621]), 'done_state': array([-0.40514793, -0.03648791])}
episode index:456
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.42075042, -2.35334141]), 'done_state': array([-0.40514793, -0.03648791])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.7891088884257862
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.42075042, -2.35334141]), 'done_state': array([ 0.30065362, -0.28699669])}
episode index:457
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([3.84878452, 3.53241338]), 'done_state': array([ 0.30065362, -0.28699669])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.7889776463113193
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([3.84878452, 3.53241338]), 'done_state': array([0.29809737, 0.13537922])}
episode index:458
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.94734768, -0.28708162]), 'done_state': array([ 0.00116295, -0.13179708])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.7894373900012729
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.94734768, -0.28708162]), 'done_state': array([ 0.00116295, -0.13179708])}
episode index:459
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.99462148, -1.63304794]), 'done_state': array([ 0.00116295, -0.13179708])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.7896777435012701
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.99462148, -1.63304794]), 'done_state': array([ 0.04155055, -0.01200603])}
episode index:460
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.97863303, -2.56617854]), 'done_state': array([ 0.04155055, -0.01200603])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7897218264871675
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-2.97863303, -2.56617854]), 'done_state': array([-0.43659749, -0.11310748])}
episode index:461
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.65377315, -1.92310283]), 'done_state': array([-0.43659749, -0.11310748])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.7895903939623035
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-3.65377315, -1.92310283]), 'done_state': array([-0.11979507, -0.06119987])}
episode index:462
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.16734787, -2.70713293]), 'done_state': array([-0.11979507, -0.06119987])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7896344751848471
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-2.16734787, -2.70713293]), 'done_state': array([-0.09162656, -0.08467762])}
episode index:463
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.12264038,  2.45205254]), 'done_state': array([-0.09162656, -0.08467762])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.7898723319193625
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.12264038,  2.45205254]), 'done_state': array([-0.10045179,  0.48434529])}
episode index:464
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.22081782, -1.25105276]), 'done_state': array([-0.03907212, -0.06979275])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.7903242193776004
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.22081782, -1.25105276]), 'done_state': array([-0.03907212, -0.06979275])}
episode index:465
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([3.25812325, 1.50916936]), 'done_state': array([-0.03907212, -0.06979275])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7903664420827987
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([3.25812325, 1.50916936]), 'done_state': array([0.38525042, 0.17825094])}
episode index:466
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.88027359, -1.53453147]), 'done_state': array([0.38525042, 0.17825094])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.7906012034487884
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.88027359, -1.53453147]), 'done_state': array([-0.15427184,  0.00046814])}
episode index:467
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.21357672, -2.43608582]), 'done_state': array([-0.15427184,  0.00046814])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7906426538687696
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-0.21357672, -2.43608582]), 'done_state': array([ 0.05961495, -0.03040521])}
episode index:468
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.66625326, -1.65506554]), 'done_state': array([ 0.05961495, -0.03040521])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7906839275278981
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 2.66625326, -1.65506554]), 'done_state': array([0.17014292, 0.08226836])}
episode index:469
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.99762569,  3.01957617]), 'done_state': array([0.17014292, 0.08226836])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7907250255544345
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-0.99762569,  3.01957617]), 'done_state': array([0.17629861, 0.28324619])}
episode index:470
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.51315253, -3.43113851]), 'done_state': array([0.17629861, 0.28324619])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7907659490670578
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-2.51315253, -3.43113851]), 'done_state': array([ 0.18757025, -0.31710183])}
episode index:471
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.06926906, -1.47351867]), 'done_state': array([ 0.09932278, -0.36921219])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.7912092415478479
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.06926906, -1.47351867]), 'done_state': array([ 0.09932278, -0.36921219])}
episode index:472
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.6401331 , -3.94272295]), 'done_state': array([ 0.09932278, -0.36921219])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.7910777209526092
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 0.6401331 , -3.94272295]), 'done_state': array([-0.03104368, -0.11688852])}
episode index:473
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([3.68457492, 1.78386927]), 'done_state': array([-0.03104368, -0.11688852])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.7909467552965911
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([3.68457492, 1.78386927]), 'done_state': array([0.17298209, 0.15351263])}
episode index:474
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.87859864,  1.77467486]), 'done_state': array([0.17298209, 0.15351263])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.7908163410749139
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-3.87859864,  1.77467486]), 'done_state': array([-0.16602935,  0.04170018])}
episode index:475
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.63144982, -1.76627668]), 'done_state': array([-0.16602935,  0.04170018])}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.7910457185096305
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.63144982, -1.76627668]), 'done_state': array([-0.13454817,  0.19321527])}
episode index:476
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.32541301, -2.37672201]), 'done_state': array([-0.13454817,  0.19321527])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7910854549488137
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 3.32541301, -2.37672201]), 'done_state': array([0.41766736, 0.04717218])}
episode index:477
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.54623151, -3.79904908]), 'done_state': array([0.41766736, 0.04717218])}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.7909555690597994
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-2.54623151, -3.79904908]), 'done_state': array([0.1430514 , 0.00238328])}
episode index:478
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.24966238, 0.95413986]), 'done_state': array([0.27078025, 0.05454725])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.7913919874960003
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.24966238, 0.95413986]), 'done_state': array([0.27078025, 0.05454725])}
episode index:479
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.5916768 , 2.62055023]), 'done_state': array([0.27078025, 0.05454725])}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.7914307541887169
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([0.5916768 , 2.62055023]), 'done_state': array([0.03696595, 0.27878875])}
episode index:480
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.69084873, 1.31407498]), 'done_state': array([0.38124442, 0.21326119])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.7918643700843745
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.69084873, 1.31407498]), 'done_state': array([0.38124442, 0.21326119])}
episode index:481
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.6764781 , -0.78777027]), 'done_state': array([0.38124442, 0.21326119])}
