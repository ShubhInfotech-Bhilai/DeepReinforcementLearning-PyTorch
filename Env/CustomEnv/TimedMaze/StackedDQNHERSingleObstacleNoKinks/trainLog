/home/yangyutu/anaconda3/bin/python /home/yangyutu/Dropbox/pythonScripts/DeepReinforcementLearning-PyTorch/Env/CustomEnv/TimedMaze/StackedDQNHERSingleObstacleNoKinks/StackedDQN_CNNTimedMazeGPU.py
episode index:0
target Thresh 2.999999999999999
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([1.8116664, 9.8455925, 6.147515 ], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 1.0
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([1.8116664, 9.8455925, 6.147515 ], dtype=float32)}
episode index:1
target Thresh 3.059850249687812
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([11.809601 ,  6.035732 ,  3.9172573], dtype=float32)}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.99005
{'scaleFactor': 30, 'timeStep': 3, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([11.846881 ,  4.3968215,  4.846007 ], dtype=float32)}
episode index:2
target Thresh 3.1194019950099827
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([6.9228535, 9.859095 , 0.6925442], dtype=float32)}
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.9584794180862387
{'scaleFactor': 30, 'timeStep': 12, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([10.689148 ,  9.757783 ,  4.8205633], dtype=float32)}
episode index:3
target Thresh 3.178656724763247
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([ 3.9054298, 10.697462 ,  0.5293557], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9688595635646791
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([ 3.9054298, 10.697462 ,  0.5293557], dtype=float32)}
episode index:4
target Thresh 3.237615920318937
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([12.287699 , 11.4994   ,  1.0016071], dtype=float32)}
done in step count: 117
reward sum = 0.30854447063465107
running average episode reward sum: 0.8367965449786734
{'scaleFactor': 30, 'timeStep': 118, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([9.88981  , 8.424538 , 1.8828348], dtype=float32)}
episode index:5
target Thresh 3.2962810556600086
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([5.115116, 9.834333, 5.45285 ], dtype=float32)}
done in step count: 36
reward sum = 0.6964132180495735
running average episode reward sum: 0.8133993238238234
{'scaleFactor': 30, 'timeStep': 37, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([3.8440208, 6.203493 , 3.6990178], dtype=float32)}
episode index:6
target Thresh 3.3546535974179017
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([10.445071 ,  7.9298935,  3.0256035], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.840056563277563
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([10.445071 ,  7.9298935,  3.0256035], dtype=float32)}
episode index:7
target Thresh 3.4127350049092016
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([14.014861 ,  3.2750885,  6.1376877], dtype=float32)}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.8551239941178675
{'scaleFactor': 30, 'timeStep': 5, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([13.845975  ,  3.289568  ,  0.83839655], dtype=float32)}
episode index:8
target Thresh 3.4705267301721214
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([11.888753 ,  4.051178 ,  5.1244135], dtype=float32)}
done in step count: 79
reward sum = 0.45204365026647536
running average episode reward sum: 0.8103372892454906
{'scaleFactor': 30, 'timeStep': 80, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([13.73126  ,  2.6570342,  4.9361935], dtype=float32)}
episode index:9
target Thresh 3.5280302180027996
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([ 2.9954362, 10.210784 ,  3.1348884], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8293035603209414
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([ 2.9954362, 10.210784 ,  3.1348884], dtype=float32)}
episode index:10
target Thresh 3.5852469059914305
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([9.68951  , 2.4822347, 2.9596703], dtype=float32)}
done in step count: 29
reward sum = 0.7471720943315961
running average episode reward sum: 0.8218370634128191
{'scaleFactor': 30, 'timeStep': 30, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([10.330304 ,  3.3487363,  1.573404 ], dtype=float32)}
episode index:11
target Thresh 3.6421782245581937
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([2.1409433, 4.978502 , 2.1212373], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8366839747950842
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([2.1409433, 4.978502 , 2.1212373], dtype=float32)}
episode index:12
target Thresh 3.6988255969890145
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([2.0605698 , 5.7273126 , 0.74671674], dtype=float32)}
done in step count: 399
reward sum = 0.0
running average episode reward sum: 0.7723236690416162
{'scaleFactor': 30, 'timeStep': 400, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([0.0524846, 7.209725 , 3.2482414], dtype=float32)}
episode index:13
target Thresh 3.755190439471159
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([5.8297787, 8.976965 , 1.6438437], dtype=float32)}
done in step count: 399
reward sum = 0.0
running average episode reward sum: 0.7171576926815008
{'scaleFactor': 30, 'timeStep': 400, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([9.68301  , 2.9783297, 4.3496866], dtype=float32)}
episode index:14
target Thresh 3.8112741611286194
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([11.778664 ,  5.15252  ,  3.7354255], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.7353471798360673
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([10.618135 ,  3.4516158,  4.060815 ], dtype=float32)}
episode index:15
target Thresh 3.8670781640573653
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([7.773128 , 9.690693 , 1.7024661], dtype=float32)}
done in step count: 399
reward sum = 0.0
running average episode reward sum: 0.6893879810963132
{'scaleFactor': 30, 'timeStep': 400, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([7.4180546, 7.5387554, 0.5713548], dtype=float32)}
episode index:16
target Thresh 3.92260384336037
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([13.363945 ,  1.4848286,  5.6893454], dtype=float32)}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.7020346925029303
{'scaleFactor': 30, 'timeStep': 11, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([11.753304 ,  4.9086304,  2.0674276], dtype=float32)}
episode index:17
target Thresh 3.9778525871825106
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([10.997833 ,  9.960626 ,  2.1258385], dtype=float32)}
done in step count: 399
reward sum = 0.0
running average episode reward sum: 0.6630327651416564
{'scaleFactor': 30, 'timeStep': 400, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([12.180234  ,  0.14767468,  4.154108  ], dtype=float32)}
episode index:18
target Thresh 4.032825776745261
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([12.306505 ,  6.6744823,  2.0275273], dtype=float32)}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.6762161589491292
{'scaleFactor': 30, 'timeStep': 10, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([11.741143,  5.998613,  6.035422], dtype=float32)}
episode index:19
target Thresh 4.087524786381222
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([2.0898833, 8.04531  , 4.8606615], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6924053510016728
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([2.0898833, 8.04531  , 4.8606615], dtype=float32)}
episode index:20
target Thresh 4.141950983568485
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([1.8975234, 6.8781505, 5.282094 ], dtype=float32)}
done in step count: 141
reward sum = 0.2424166460445802
running average episode reward sum: 0.6709773174322875
{'scaleFactor': 30, 'timeStep': 142, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([4.3325276, 8.479551 , 1.6953077], dtype=float32)}
episode index:21
target Thresh 4.196105728964812
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([6.788987, 8.809506, 4.439695], dtype=float32)}
done in step count: 74
reward sum = 0.47534004200570695
running average episode reward sum: 0.6620847140038065
{'scaleFactor': 30, 'timeStep': 75, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([9.867899 , 7.3594675, 6.193346 ], dtype=float32)}
episode index:22
target Thresh 4.249990376441661
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([9.143167 , 9.024484 , 4.9391227], dtype=float32)}
done in step count: 49
reward sum = 0.611117239532865
running average episode reward sum: 0.659868736852896
{'scaleFactor': 30, 'timeStep': 50, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([10.2510195,  5.2592297,  5.5450635], dtype=float32)}
episode index:23
target Thresh 4.303606273118023
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([2.9188657, 9.0006695, 3.7894053], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.673624206150692
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([3.042026, 8.904873, 4.171842], dtype=float32)}
episode index:24
target Thresh 4.35695475939411
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([9.341287, 9.010589, 5.437459], dtype=float32)}
done in step count: 18
reward sum = 0.8345137614500875
running average episode reward sum: 0.6800597883626678
{'scaleFactor': 30, 'timeStep': 19, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([6.411517 , 7.840193 , 3.1791773], dtype=float32)}
episode index:25
target Thresh 4.410037168984854
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([11.921871 ,  6.1232452,  1.4960595], dtype=float32)}
done in step count: 102
reward sum = 0.3587482976818919
running average episode reward sum: 0.6677016541057148
{'scaleFactor': 30, 'timeStep': 103, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([11.880406 ,  3.905128 ,  4.0570803], dtype=float32)}
episode index:26
target Thresh 4.462854828953264
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([3.7088256, 7.775242 , 0.6335483], dtype=float32)}
done in step count: 399
reward sum = 0.0
running average episode reward sum: 0.6429719632129106
{'scaleFactor': 30, 'timeStep': 400, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([ 6.0827875, 11.825918 ,  2.9886727], dtype=float32)}
episode index:27
target Thresh 4.515409059743587
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([12.142712 ,  7.9281087,  1.6639621], dtype=float32)}
done in step count: 399
reward sum = 0.0
running average episode reward sum: 0.6200086788124495
{'scaleFactor': 30, 'timeStep': 400, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([13.948447 ,  6.4196653,  1.8338802], dtype=float32)}
episode index:28
target Thresh 4.567701175214329
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([1.93041  , 3.9342222, 5.439459 ], dtype=float32)}
done in step count: 61
reward sum = 0.5416850759668536
running average episode reward sum: 0.617307864921222
{'scaleFactor': 30, 'timeStep': 62, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([3.9588935, 8.221246 , 2.6949253], dtype=float32)}
episode index:29
target Thresh 4.619732482671103
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([2.0591195, 3.8810298, 5.9083905], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.630064269423848
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([2.0591195, 3.8810298, 5.9083905], dtype=float32)}
episode index:30
target Thresh 4.671504282899305
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([12.025884 ,  9.022466 ,  2.3139172], dtype=float32)}
done in step count: 31
reward sum = 0.7323033696543975
running average episode reward sum: 0.633362304915156
{'scaleFactor': 30, 'timeStep': 32, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([7.1713576, 8.035944 , 2.9429295], dtype=float32)}
episode index:31
target Thresh 4.723017870196637
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([10.215177,  8.999352,  4.717288], dtype=float32)}
done in step count: 399
reward sum = 0.0
running average episode reward sum: 0.6135697328865574
{'scaleFactor': 30, 'timeStep': 400, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([4.0336733, 4.555496 , 5.54748  ], dtype=float32)}
episode index:32
target Thresh 4.774274532405462
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([0.1981368, 5.8667746, 2.9928408], dtype=float32)}
done in step count: 325
reward sum = 0.03814505489267701
running average episode reward sum: 0.5961326214321974
{'scaleFactor': 30, 'timeStep': 326, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([1.8989446, 8.960332 , 5.9266686], dtype=float32)}
episode index:33
target Thresh 4.82527555094501
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([11.921883 ,  5.796724 ,  1.6388283], dtype=float32)}
done in step count: 399
reward sum = 0.0
running average episode reward sum: 0.5785993090371327
{'scaleFactor': 30, 'timeStep': 400, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([0.48213512, 6.7119703 , 4.6747246 ], dtype=float32)}
episode index:34
target Thresh 4.876022200843394
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([5.9987593, 9.854989 , 2.5588005], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.5906393287789289
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([5.9987593, 9.854989 , 2.5588005], dtype=float32)}
episode index:35
target Thresh 4.926515750769511
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([3.743621 , 8.840763 , 1.3692865], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6020104585350698
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([3.743621 , 8.840763 , 1.3692865], dtype=float32)}
episode index:36
target Thresh 4.976757463064736
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([2.0308146, 9.951891 , 4.605636 ], dtype=float32)}
done in step count: 399
reward sum = 0.0
running average episode reward sum: 0.5857399056016895
{'scaleFactor': 30, 'timeStep': 400, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([3.4540756, 3.2595696, 1.5168422], dtype=float32)}
episode index:37
target Thresh 5.026748593774491
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([1.7917196, 7.105841 , 5.5477476], dtype=float32)}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.5961178028226977
{'scaleFactor': 30, 'timeStep': 3, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([2.0857306, 7.172299 , 4.9393134], dtype=float32)}
episode index:38
target Thresh 5.076490392679651
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([9.843041 , 8.780848 , 3.8448865], dtype=float32)}
done in step count: 340
reward sum = 0.03280697314869742
running average episode reward sum: 0.5816739353951592
{'scaleFactor': 30, 'timeStep': 341, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([7.8198056, 9.770008 , 1.4707808], dtype=float32)}
episode index:39
target Thresh 5.125984103327778
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([12.047581,  4.882366,  6.19121 ], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.5921320870102802
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([12.047581,  4.882366,  6.19121 ], dtype=float32)}
episode index:40
target Thresh 5.175230963064217
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([ 8.111061, 10.071143,  1.989414], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6020800848880783
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([ 8.111061, 10.071143,  1.989414], dtype=float32)}
episode index:41
target Thresh 5.224232203063025
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([1.7364656, 9.190199 , 2.2105744], dtype=float32)}
done in step count: 399
reward sum = 0.0
running average episode reward sum: 0.5877448447716955
{'scaleFactor': 30, 'timeStep': 400, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([ 6.1405067, 11.988588 ,  0.5016706], dtype=float32)}
episode index:42
target Thresh 5.272989048357754
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([9.051045 , 9.329992 , 1.1734235], dtype=float32)}
done in step count: 18
reward sum = 0.8345137614500875
running average episode reward sum: 0.5934836567874721
{'scaleFactor': 30, 'timeStep': 19, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([7.4322   , 8.155914 , 3.8296938], dtype=float32)}
episode index:43
target Thresh 5.321502717872077
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([6.1891418, 7.557887 , 5.292882 ], dtype=float32)}
done in step count: 259
reward sum = 0.07404835256958406
running average episode reward sum: 0.5816783089643383
{'scaleFactor': 30, 'timeStep': 260, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([ 8.574668 , 10.958651 ,  1.9162004], dtype=float32)}
episode index:44
target Thresh 5.369774424450257
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([11.135983, 10.032853,  4.021757], dtype=float32)}
done in step count: 371
reward sum = 0.024024656984952455
running average episode reward sum: 0.5692860055870186
{'scaleFactor': 30, 'timeStep': 372, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([5.9409   , 9.725368 , 1.9307375], dtype=float32)}
episode index:45
target Thresh 5.417805374887475
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([ 7.1114044, 10.275865 ,  5.3302917], dtype=float32)}
done in step count: 24
reward sum = 0.7856781408072188
running average episode reward sum: 0.5739901824396316
{'scaleFactor': 30, 'timeStep': 25, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([13.799519  ,  7.8623605 ,  0.53482085], dtype=float32)}
episode index:46
target Thresh 5.465596769959991
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([9.149161, 8.89741 , 3.408359], dtype=float32)}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.5814104912053398
{'scaleFactor': 30, 'timeStep': 9, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([6.989488 , 8.310762 , 1.6852924], dtype=float32)}
episode index:47
target Thresh 5.513149804455173
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([1.132075 , 8.196177 , 3.6421642], dtype=float32)}
done in step count: 14
reward sum = 0.8687458127689782
running average episode reward sum: 0.5873966437379156
{'scaleFactor': 30, 'timeStep': 15, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([2.7109308, 7.3657827, 4.9478383], dtype=float32)}
episode index:48
target Thresh 5.560465667201358
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([11.134768 ,  8.892282 ,  1.9180464], dtype=float32)}
done in step count: 399
reward sum = 0.0
running average episode reward sum: 0.5754089571310194
{'scaleFactor': 30, 'timeStep': 400, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([14.208688 , 11.951745 ,  2.1962602], dtype=float32)}
episode index:49
target Thresh 5.607545541097582
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([10.001387 ,  8.817942 ,  2.5793393], dtype=float32)}
done in step count: 214
reward sum = 0.11639428152900338
running average episode reward sum: 0.5662286636189791
{'scaleFactor': 30, 'timeStep': 215, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([13.998755 ,  4.7062936,  1.4329765], dtype=float32)}
episode index:50
target Thresh 5.65439060314314
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([9.848916  , 9.105931  , 0.10483924], dtype=float32)}
done in step count: 399
reward sum = 0.0
running average episode reward sum: 0.5551261408029207
{'scaleFactor': 30, 'timeStep': 400, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([-0.00700435,  4.559584  ,  2.4505615 ], dtype=float32)}
episode index:51
target Thresh 5.701002024467027
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([1.7027154, 6.9824734, 4.6392055], dtype=float32)}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5627389082855567
{'scaleFactor': 30, 'timeStep': 6, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([1.067414 , 5.130022 , 4.3966556], dtype=float32)}
episode index:52
target Thresh 5.747380970357204
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([2.1679707, 6.219105 , 3.3418448], dtype=float32)}
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.5690143676435409
{'scaleFactor': 30, 'timeStep': 12, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([3.546152 , 9.010147 , 6.2820587], dtype=float32)}
episode index:53
target Thresh 5.793528600289731
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([10.931986 ,  7.5948424,  2.3410661], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.5769955830575494
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([10.931986 ,  7.5948424,  2.3410661], dtype=float32)}
episode index:54
target Thresh 5.839446067957761
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([11.811825 ,  7.8720145,  4.8472934], dtype=float32)}
done in step count: 105
reward sum = 0.348093114492442
running average episode reward sum: 0.5728337199927293
{'scaleFactor': 30, 'timeStep': 106, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([9.048796 , 8.451671 , 2.6282954], dtype=float32)}
episode index:55
target Thresh 5.885134521300377
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([4.9355397, 9.174976 , 3.7065873], dtype=float32)}
done in step count: 25
reward sum = 0.7778213593991467
running average episode reward sum: 0.5764942135535581
{'scaleFactor': 30, 'timeStep': 26, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([ 8.977473 , 11.189814 ,  5.5087366], dtype=float32)}
episode index:56
target Thresh 5.930595102531293
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([9.145982 , 9.82594  , 1.8299453], dtype=float32)}
done in step count: 102
reward sum = 0.3587482976818919
running average episode reward sum: 0.5726741097663359
{'scaleFactor': 30, 'timeStep': 103, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([12.982841 , 10.382561 ,  4.9583774], dtype=float32)}
episode index:57
target Thresh 5.9758289481674085
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([7.9424567, 7.7105017, 4.2519693], dtype=float32)}
done in step count: 391
reward sum = 0.01964993362138638
running average episode reward sum: 0.5631392101776299
{'scaleFactor': 30, 'timeStep': 392, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([ 5.4516354, 10.951308 ,  2.1935875], dtype=float32)}
episode index:58
target Thresh 6.020837189057217
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([12.387136 , 10.465466 ,  0.9885251], dtype=float32)}
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.5684677154796864
{'scaleFactor': 30, 'timeStep': 14, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([ 6.408919 , 10.648303 ,  3.8810997], dtype=float32)}
episode index:59
target Thresh 6.0656209504090866
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([5.74728  , 9.124346 , 5.3894687], dtype=float32)}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.574843087720025
{'scaleFactor': 30, 'timeStep': 6, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([10.936575,  5.43818 ,  5.486841], dtype=float32)}
episode index:60
target Thresh 6.110181351819385
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([1.929722, 8.101029, 4.17707 ], dtype=float32)}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.580395123125986
{'scaleFactor': 30, 'timeStep': 10, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([0.82581306, 4.9698157 , 4.2302823 ], dtype=float32)}
episode index:61
target Thresh 6.154519507300467
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([7.878256 , 8.410091 , 4.2346873], dtype=float32)}
done in step count: 51
reward sum = 0.598956006466161
running average episode reward sum: 0.5806944922121178
{'scaleFactor': 30, 'timeStep': 52, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([13.888013 ,  4.6547885,  5.081814 ], dtype=float32)}
episode index:62
target Thresh 6.198636525308529
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([1.3388399e+01, 8.9167500e+00, 9.6890293e-03], dtype=float32)}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.5859773930894435
{'scaleFactor': 30, 'timeStep': 10, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([8.676773, 8.543243, 2.62512 ], dtype=float32)}
episode index:63
target Thresh 6.242533508771318
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([11.109706 ,  9.165198 ,  1.1175199], dtype=float32)}
done in step count: 52
reward sum = 0.5929664464014994
running average episode reward sum: 0.5860865970474444
{'scaleFactor': 30, 'timeStep': 53, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([ 8.295343 , 10.10375  ,  2.4995966], dtype=float32)}
episode index:64
target Thresh 6.286211555115708
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([8.109269, 8.940647, 2.802958], dtype=float32)}
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.5908443148506948
{'scaleFactor': 30, 'timeStep': 12, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([0.09425863, 9.990886  , 1.7379308 ], dtype=float32)}
episode index:65
target Thresh 6.3296717562951335
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([ 5.82942  , 10.113006 ,  3.3323543], dtype=float32)}
done in step count: 121
reward sum = 0.296386587399208
running average episode reward sum: 0.5863828341317328
{'scaleFactor': 30, 'timeStep': 122, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([4.604103  , 8.863094  , 0.70152164], dtype=float32)}
episode index:66
target Thresh 6.3729151988168855
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([11.111267 ,  8.954692 ,  0.7866295], dtype=float32)}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.5915422746358411
{'scaleFactor': 30, 'timeStep': 8, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([ 7.8923564, 11.137262 ,  1.8466926], dtype=float32)}
episode index:67
target Thresh 6.415942963769281
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([9.01776 , 9.910822, 5.267788], dtype=float32)}
done in step count: 34
reward sum = 0.7105532272722921
running average episode reward sum: 0.5932924357040242
{'scaleFactor': 30, 'timeStep': 35, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([ 8.792826 , 10.748694 ,  4.0963454], dtype=float32)}
episode index:68
target Thresh 6.458756126848683
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([7.7392335, 9.844271 , 4.5592275], dtype=float32)}
done in step count: 18
reward sum = 0.8345137614500875
running average episode reward sum: 0.5967883969467208
{'scaleFactor': 30, 'timeStep': 19, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([10.335095 ,  6.004516 ,  6.2170815], dtype=float32)}
episode index:69
target Thresh 6.5013557583864
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([1.9806509, 9.958282 , 3.2857037], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6025485627046248
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([1.9806509, 9.958282 , 3.2857037], dtype=float32)}
episode index:70
target Thresh 6.543742923375439
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([0.80851984, 7.4164796 , 2.3898084 ], dtype=float32)}
done in step count: 399
reward sum = 0.0
running average episode reward sum: 0.5940619632299117
{'scaleFactor': 30, 'timeStep': 400, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([12.267392  ,  7.489624  ,  0.09274697], dtype=float32)}
episode index:71
target Thresh 6.585918681497131
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([1.2743794, 4.971235 , 4.107206 ], dtype=float32)}
done in step count: 153
reward sum = 0.2148744477060795
running average episode reward sum: 0.5887954699587473
{'scaleFactor': 30, 'timeStep': 154, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([ 3.0180185, 10.046463 ,  0.7210286], dtype=float32)}
episode index:72
target Thresh 6.627884087147628
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([3.7153974, 3.0109413, 5.7495594], dtype=float32)}
done in step count: 33
reward sum = 0.7177305325982749
running average episode reward sum: 0.5905617036935354
{'scaleFactor': 30, 'timeStep': 34, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([4.4015274, 8.045022 , 1.3101672], dtype=float32)}
episode index:73
target Thresh 6.669640189464253
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([ 5.9527764, 10.207333 ,  3.0944438], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.5960946536436228
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([ 5.9527764, 10.207333 ,  3.0944438], dtype=float32)}
episode index:74
target Thresh 6.711188032351744
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([7.310868 , 8.807384 , 6.0409846], dtype=float32)}
done in step count: 102
reward sum = 0.3587482976818919
running average episode reward sum: 0.592930035564133
{'scaleFactor': 30, 'timeStep': 103, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([2.9685426, 9.393242 , 4.0723524], dtype=float32)}
episode index:75
target Thresh 6.752528654508334
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([8.068402, 9.160864, 3.925073], dtype=float32)}
done in step count: 294
reward sum = 0.05208914293358933
running average episode reward sum: 0.5858137080295206
{'scaleFactor': 30, 'timeStep': 295, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([10.41059  ,  9.113513 ,  0.9250969], dtype=float32)}
episode index:76
target Thresh 6.79366308945173
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([8.892952  , 9.791627  , 0.52264184], dtype=float32)}
done in step count: 72
reward sum = 0.48499137027416284
running average episode reward sum: 0.5845043270197108
{'scaleFactor': 30, 'timeStep': 73, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([3.5782661, 9.271753 , 3.5958142], dtype=float32)}
episode index:77
target Thresh 6.834592365544948
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([11.824201  ,  2.1655278 ,  0.01406553], dtype=float32)}
done in step count: 17
reward sum = 0.8429431933839268
running average episode reward sum: 0.587817645819252
{'scaleFactor': 30, 'timeStep': 18, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([13.756423 ,  5.023565 ,  1.3666443], dtype=float32)}
episode index:78
target Thresh 6.875317506022024
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([ 3.3778305, 11.381845 ,  0.8301211], dtype=float32)}
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.5914847771759573
{'scaleFactor': 30, 'timeStep': 14, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([3.1431718, 6.4232807, 4.5227356], dtype=float32)}
episode index:79
target Thresh 6.915839529013587
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([1.8260765, 5.764651 , 2.0909293], dtype=float32)}
done in step count: 33
reward sum = 0.7177305325982749
running average episode reward sum: 0.5930628491187362
{'scaleFactor': 30, 'timeStep': 34, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([0.94269204, 3.5094705 , 5.531407  ], dtype=float32)}
episode index:80
target Thresh 6.956159447572327
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([11.072605 ,  9.900702 ,  2.7548282], dtype=float32)}
done in step count: 106
reward sum = 0.3446121833475176
running average episode reward sum: 0.5899955569487211
{'scaleFactor': 30, 'timeStep': 107, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([12.887571 ,  4.952005 ,  4.1966696], dtype=float32)}
episode index:81
target Thresh 6.9962782696983075
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([ 8.2582035, 10.679697 ,  1.0853212], dtype=float32)}
done in step count: 23
reward sum = 0.7936142836436554
running average episode reward sum: 0.5924787121523178
{'scaleFactor': 30, 'timeStep': 24, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([13.863    ,  9.474923 ,  5.3574347], dtype=float32)}
episode index:82
target Thresh 7.036196998364168
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([4.7395945, 8.875852 , 1.11354  ], dtype=float32)}
done in step count: 30
reward sum = 0.7397003733882802
running average episode reward sum: 0.594252467106968
{'scaleFactor': 30, 'timeStep': 31, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([ 9.079872, 11.850529,  2.462226], dtype=float32)}
episode index:83
target Thresh 7.075916631540206
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([1.8936974, 3.7409801, 4.622655 ], dtype=float32)}
done in step count: 151
reward sum = 0.2192372693664723
running average episode reward sum: 0.5897880004672003
{'scaleFactor': 30, 'timeStep': 152, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([9.505312 , 9.447602 , 2.3284373], dtype=float32)}
episode index:84
target Thresh 7.115438162219318
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([ 8.434194, 11.054565,  0.956288], dtype=float32)}
done in step count: 104
reward sum = 0.35160920655802225
running average episode reward sum: 0.5869858970094453
{'scaleFactor': 30, 'timeStep': 105, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([10.246087  ,  9.964509  ,  0.08296698], dtype=float32)}
episode index:85
target Thresh 7.154762578441833
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([3.654567 , 4.7924376, 5.3771887], dtype=float32)}
done in step count: 32
reward sum = 0.7249803359578534
running average episode reward sum: 0.5885904835088454
{'scaleFactor': 30, 'timeStep': 33, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([2.2995555, 8.127942 , 2.4576864], dtype=float32)}
episode index:86
target Thresh 7.193890863320202
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([2.3139377, 2.9707277, 5.682468 ], dtype=float32)}
done in step count: 97
reward sum = 0.37723664692350417
running average episode reward sum: 0.5861611290653357
{'scaleFactor': 30, 'timeStep': 98, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([1.0995474, 4.73147  , 1.669605 ], dtype=float32)}
episode index:87
target Thresh 7.232823995063584
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([2.0341384, 7.069083 , 4.228404 ], dtype=float32)}
done in step count: 257
reward sum = 0.07555183406752786
running average episode reward sum: 0.5803587507130878
{'scaleFactor': 30, 'timeStep': 258, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([ 6.5469   , 10.685702 ,  5.4620814], dtype=float32)}
episode index:88
target Thresh 7.271562947002303
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([6.1286845, 8.915008 , 3.5773642], dtype=float32)}
done in step count: 35
reward sum = 0.7034476949995692
running average episode reward sum: 0.5817417725590034
{'scaleFactor': 30, 'timeStep': 36, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([0.10690349, 5.217082  , 3.130785  ], dtype=float32)}
episode index:89
target Thresh 7.310108687612175
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([10.804578,  8.047633,  5.700605], dtype=float32)}
done in step count: 179
reward sum = 0.16546259566473476
running average episode reward sum: 0.5771164483712893
{'scaleFactor': 30, 'timeStep': 180, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([5.4285717, 9.186161 , 3.4815862], dtype=float32)}
episode index:90
target Thresh 7.348462180538719
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([7.7594943, 7.157235 , 5.025476 ], dtype=float32)}
done in step count: 205
reward sum = 0.1274133376787588
running average episode reward sum: 0.5721746559460966
{'scaleFactor': 30, 'timeStep': 206, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([ 4.277866 , 11.982105 ,  3.3094356], dtype=float32)}
episode index:91
target Thresh 7.3866243846212605
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([4.7638702, 9.137708 , 6.227536 ], dtype=float32)}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.5765020944684217
{'scaleFactor': 30, 'timeStep': 4, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([10.350778  , 10.425945  ,  0.45101723], dtype=float32)}
episode index:92
target Thresh 7.424596253916889
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([0.7327765, 3.2412848, 2.171211 ], dtype=float32)}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.5808418568934924
{'scaleFactor': 30, 'timeStep': 3, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([0.04478985, 4.919861  , 2.357079  ], dtype=float32)}
episode index:93
target Thresh 7.46237873772431
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([2.4225683, 7.216032 , 4.22462  ], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.5853009860754766
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([2.4225683, 7.216032 , 4.22462  ], dtype=float32)}
episode index:94
target Thresh 7.49997278060759
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([12.048709 ,  9.718043 ,  1.7319502], dtype=float32)}
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.588376986464145
{'scaleFactor': 30, 'timeStep': 14, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([11.285801 , 11.607545 ,  3.1345441], dtype=float32)}
episode index:95
target Thresh 7.537379322419757
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([2.029536, 8.418463, 4.400839], dtype=float32)}
done in step count: 270
reward sum = 0.06629832272038531
running average episode reward sum: 0.5829386670501475
{'scaleFactor': 30, 'timeStep': 271, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([ 8.256398, 10.912393,  5.633084], dtype=float32)}
episode index:96
target Thresh 7.57459929832631
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([ 5.9022493, 12.110859 ,  1.6067376], dtype=float32)}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5866349709919089
{'scaleFactor': 30, 'timeStep': 7, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([ 9.500537  , 11.635601  ,  0.31198043], dtype=float32)}
episode index:97
target Thresh 7.611633638828578
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([ 2.9849648, 11.486456 ,  1.7543923], dtype=float32)}
done in step count: 155
reward sum = 0.21059844619672852
running average episode reward sum: 0.5827978635960396
{'scaleFactor': 30, 'timeStep': 156, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([11.147951, 11.20303 ,  5.510158], dtype=float32)}
episode index:98
target Thresh 7.648483269787006
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([12.167195 ,  7.8989716,  1.3296671], dtype=float32)}
done in step count: 63
reward sum = 0.5309055429551132
running average episode reward sum: 0.5822736987410807
{'scaleFactor': 30, 'timeStep': 64, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([ 4.434641 , 10.550844 ,  3.5243876], dtype=float32)}
episode index:99
target Thresh 7.6851491124442886
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([ 8.394012 , 10.907055 ,  2.6622958], dtype=float32)}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.5856784086979491
{'scaleFactor': 30, 'timeStep': 9, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([ 5.131089 , 11.424946 ,  3.4849372], dtype=float32)}
episode index:100
target Thresh 7.721632083448398
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([ 4.1943035, 10.548164 ,  0.0584603], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.5897806026712367
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([ 4.1943035, 10.548164 ,  0.0584603], dtype=float32)}
episode index:101
target Thresh 7.757933094875514
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([1.8836013, 7.1580405, 5.838744 ], dtype=float32)}
done in step count: 25
reward sum = 0.7778213593991467
running average episode reward sum: 0.5916241395019025
{'scaleFactor': 30, 'timeStep': 26, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([0.3298002, 2.9813907, 4.5646405], dtype=float32)}
episode index:102
target Thresh 7.794053054252808
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([2.2112532, 7.7208023, 1.706714 ], dtype=float32)}
done in step count: 68
reward sum = 0.5048858887870696
running average episode reward sum: 0.5907820205629236
{'scaleFactor': 30, 'timeStep': 69, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([ 7.0342665, 11.245306 ,  3.838622 ], dtype=float32)}
episode index:103
target Thresh 7.829992864581151
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([6.210012 , 7.1021333, 4.156765 ], dtype=float32)}
done in step count: 67
reward sum = 0.5099857462495653
running average episode reward sum: 0.5900051333099106
{'scaleFactor': 30, 'timeStep': 68, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([ 9.211022, 10.503053,  5.741563], dtype=float32)}
episode index:104
target Thresh 7.865753424357667
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([10.955932 ,  9.272121 ,  1.2795537], dtype=float32)}
done in step count: 399
reward sum = 0.0
running average episode reward sum: 0.5843860368021971
{'scaleFactor': 30, 'timeStep': 400, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([13.9204645, 11.380683 ,  5.6350684], dtype=float32)}
episode index:105
target Thresh 7.901335627598219
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([14.068117  ,  2.0938742 ,  0.09780043], dtype=float32)}
done in step count: 144
reward sum = 0.23521662924041012
running average episode reward sum: 0.5810919857874633
{'scaleFactor': 30, 'timeStep': 145, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([12.297737 ,  8.953088 ,  5.2669935], dtype=float32)}
episode index:106
target Thresh 7.936740363859737
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([5.362084, 8.040696, 3.673184], dtype=float32)}
done in step count: 399
reward sum = 0.0
running average episode reward sum: 0.5756612195651506
{'scaleFactor': 30, 'timeStep': 400, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([ 9.816851 , 11.472355 ,  1.0066528], dtype=float32)}
episode index:107
target Thresh 7.971968518262474
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([3.9025092 , 9.8169365 , 0.13079423], dtype=float32)}
done in step count: 38
reward sum = 0.682554595010387
running average episode reward sum: 0.5766509730414954
{'scaleFactor': 30, 'timeStep': 39, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([2.8530922, 3.9907787, 3.7057998], dtype=float32)}
episode index:108
target Thresh 8.007020971512125
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([12.2321825,  4.7384605,  5.219454 ], dtype=float32)}
done in step count: 64
reward sum = 0.525596487525562
running average episode reward sum: 0.5761825832661198
{'scaleFactor': 30, 'timeStep': 65, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([ 7.484019 , 10.583094 ,  3.2581449], dtype=float32)}
episode index:109
target Thresh 8.041898599921844
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([ 3.7481518, 10.443012 ,  1.2289908], dtype=float32)}
done in step count: 72
reward sum = 0.48499137027416284
running average episode reward sum: 0.5753535722389203
{'scaleFactor': 30, 'timeStep': 73, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([6.6388955, 8.3639   , 5.9298143], dtype=float32)}
episode index:110
target Thresh 8.07660227543416
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([12.107165 , 10.369606 ,  6.1723824], dtype=float32)}
done in step count: 80
reward sum = 0.4475232137638106
running average episode reward sum: 0.5742019473877932
{'scaleFactor': 30, 'timeStep': 81, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([ 6.6636  , 11.015383,  3.644891], dtype=float32)}
episode index:111
target Thresh 8.111132865642768
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([6.6517467, 9.271473 , 5.848696 ], dtype=float32)}
done in step count: 21
reward sum = 0.8097278682212584
running average episode reward sum: 0.5763048573952348
{'scaleFactor': 30, 'timeStep': 22, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([4.385661, 9.103714, 2.801107], dtype=float32)}
episode index:112
target Thresh 8.145491233814221
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([11.915051  ,  3.2986436 ,  0.36601037], dtype=float32)}
done in step count: 73
reward sum = 0.4801414565714212
running average episode reward sum: 0.5754538538481214
{'scaleFactor': 30, 'timeStep': 74, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([ 6.0639997, 11.994817 ,  2.3170593], dtype=float32)}
episode index:113
target Thresh 8.179678238909514
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([8.717052 , 8.648025 , 6.1131763], dtype=float32)}
done in step count: 308
reward sum = 0.04525222481428054
running average episode reward sum: 0.5708029623653683
{'scaleFactor': 30, 'timeStep': 309, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([3.8242521, 9.055417 , 4.0422506], dtype=float32)}
episode index:114
target Thresh 8.213694735605555
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([8.079471 , 9.959141 , 5.2309914], dtype=float32)}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.5738633252528688
{'scaleFactor': 30, 'timeStep': 9, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([9.6277685 , 8.432733  , 0.13025016], dtype=float32)}
episode index:115
target Thresh 8.24754157431653
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([ 6.1763525, 10.05197  ,  5.0308647], dtype=float32)}
done in step count: 82
reward sum = 0.43861750180991077
running average episode reward sum: 0.5726974129818089
{'scaleFactor': 30, 'timeStep': 83, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([13.393712,  9.321084,  4.670069], dtype=float32)}
episode index:116
target Thresh 8.281219601215176
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([7.4662557, 8.315083 , 4.929629 ], dtype=float32)}
done in step count: 43
reward sum = 0.6491026283684022
running average episode reward sum: 0.573350449010754
{'scaleFactor': 30, 'timeStep': 44, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([2.430688 , 7.877915 , 3.4862032], dtype=float32)}
episode index:117
target Thresh 8.314729658253913
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([8.296085, 8.265164, 4.3383  ], dtype=float32)}
done in step count: 135
reward sum = 0.25748460676394874
running average episode reward sum: 0.570673619839171
{'scaleFactor': 30, 'timeStep': 136, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([10.4225445,  1.4603038,  5.23737  ], dtype=float32)}
episode index:118
target Thresh 8.348072583185914
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([9.283719, 7.950673, 4.667404], dtype=float32)}
done in step count: 16
reward sum = 0.8514577710948755
running average episode reward sum: 0.573033150521992
{'scaleFactor': 30, 'timeStep': 17, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([11.138554 ,  4.87749  ,  5.5685296], dtype=float32)}
episode index:119
target Thresh 8.381249209586041
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([6.10241  , 9.914082 , 2.9760864], dtype=float32)}
done in step count: 190
reward sum = 0.14814499154757946
running average episode reward sum: 0.5694924158638719
{'scaleFactor': 30, 'timeStep': 191, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([12.738873 ,  3.4725692,  5.33888  ], dtype=float32)}
episode index:120
target Thresh 8.414260366871682
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([7.2651343, 9.627416 , 2.358789 ], dtype=float32)}
done in step count: 184
reward sum = 0.15735328210778962
running average episode reward sum: 0.5660863073204332
{'scaleFactor': 30, 'timeStep': 185, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([11.841972 ,  4.1610117,  4.20837  ], dtype=float32)}
episode index:121
target Thresh 8.447106880323487
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([4.639596 , 7.318944 , 3.8399658], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.569561009719446
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([3.2382293, 5.835284 , 4.1606846], dtype=float32)}
episode index:122
target Thresh 8.479789571106002
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([ 7.7965617 , 10.282884  ,  0.06462575], dtype=float32)}
done in step count: 95
reward sum = 0.38489607889348454
running average episode reward sum: 0.568059668818422
{'scaleFactor': 30, 'timeStep': 96, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([12.875819 , 10.1608925,  4.0442367], dtype=float32)}
episode index:123
target Thresh 8.5123092562882
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([9.931623 , 7.82198  , 2.8607914], dtype=float32)}
done in step count: 24
reward sum = 0.7856781408072188
running average episode reward sum: 0.569814656495751
{'scaleFactor': 30, 'timeStep': 25, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([11.996342 ,  6.6839304,  4.849422 ], dtype=float32)}
episode index:124
target Thresh 8.544666748863905
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([2.1020918 , 3.0258524 , 0.84478694], dtype=float32)}
done in step count: 60
reward sum = 0.5471566423907612
running average episode reward sum: 0.5696333923829111
{'scaleFactor': 30, 'timeStep': 61, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([ 7.6299615, 10.312768 ,  3.4330497], dtype=float32)}
episode index:125
target Thresh 8.576862857772117
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([ 5.2122183, 10.023365 ,  4.0446568], dtype=float32)}
done in step count: 155
reward sum = 0.21059844619672852
running average episode reward sum: 0.5667839086830208
{'scaleFactor': 30, 'timeStep': 156, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([9.035001 , 7.6817384, 4.0927567], dtype=float32)}
episode index:126
target Thresh 8.608898387917232
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([6.016802 , 7.933243 , 3.8440742], dtype=float32)}
done in step count: 162
reward sum = 0.19629151402302528
running average episode reward sum: 0.5638666457329421
{'scaleFactor': 30, 'timeStep': 163, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([3.3641534, 7.7011657, 2.125901 ], dtype=float32)}
episode index:127
target Thresh 8.640774140189176
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([13.593543 ,  3.3750453,  5.5140705], dtype=float32)}
done in step count: 47
reward sum = 0.6235253948912
running average episode reward sum: 0.564332729710741
{'scaleFactor': 30, 'timeStep': 48, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([8.765362, 8.070559, 2.508652], dtype=float32)}
episode index:128
target Thresh 8.672490911483418
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([12.577047,  4.048991,  5.033592], dtype=float32)}
done in step count: 100
reward sum = 0.3660323412732292
running average episode reward sum: 0.5627955173972718
{'scaleFactor': 30, 'timeStep': 101, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([10.190208 ,  7.5311074,  2.5280266], dtype=float32)}
episode index:129
target Thresh 8.704049494720886
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([2.2199008, 4.808343 , 5.4001803], dtype=float32)}
done in step count: 36
reward sum = 0.6964132180495735
running average episode reward sum: 0.563823345863828
{'scaleFactor': 30, 'timeStep': 37, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([2.9375286, 7.3616753, 2.1661525], dtype=float32)}
episode index:130
target Thresh 8.735450678867807
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([12.086813 , 10.329905 ,  1.6184908], dtype=float32)}
done in step count: 57
reward sum = 0.5639051904523875
running average episode reward sum: 0.5638239706316797
{'scaleFactor': 30, 'timeStep': 58, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([11.558414 ,  8.641133 ,  4.3068805], dtype=float32)}
episode index:131
target Thresh 8.76669524895542
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([ 5.2516913, 11.918498 ,  1.4721026], dtype=float32)}
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.566335442477339
{'scaleFactor': 30, 'timeStep': 12, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([ 9.08354  , 11.661078 ,  5.7796006], dtype=float32)}
episode index:132
target Thresh 8.79778398609961
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([8.160365 , 9.924714 , 4.6352086], dtype=float32)}
done in step count: 211
reward sum = 0.11995712819347787
running average episode reward sum: 0.5629792145503927
{'scaleFactor': 30, 'timeStep': 212, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([13.854538 ,  6.1367016,  4.8122935], dtype=float32)}
episode index:133
target Thresh 8.828717667520417
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([ 6.8836107, 10.008889 ,  5.6060305], dtype=float32)}
done in step count: 196
reward sum = 0.139475568775225
running average episode reward sum: 0.5598187395819213
{'scaleFactor': 30, 'timeStep': 197, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([3.2866502, 6.9496255, 4.761832 ], dtype=float32)}
episode index:134
target Thresh 8.859497066561492
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([4.0984445, 9.987953 , 4.4366508], dtype=float32)}
done in step count: 179
reward sum = 0.16546259566473476
running average episode reward sum: 0.5568975829603124
{'scaleFactor': 30, 'timeStep': 180, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([11.035827  ,  9.621703  ,  0.37486476], dtype=float32)}
episode index:135
target Thresh 8.89012295270941
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([8.9823656e+00, 9.0260801e+00, 5.3908187e-03], dtype=float32)}
done in step count: 24
reward sum = 0.7856781408072188
running average episode reward sum: 0.5585797929444808
{'scaleFactor': 30, 'timeStep': 25, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([0.35606432, 7.8659863 , 2.0024405 ], dtype=float32)}
episode index:136
target Thresh 8.920596091612925
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([5.46359 , 8.110648, 5.824942], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.5618018382514555
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([5.46359 , 8.110648, 5.824942], dtype=float32)}
episode index:137
target Thresh 8.950917245102092
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([10.230634 ,  9.8141775,  0.5237729], dtype=float32)}
done in step count: 89
reward sum = 0.40882017442254925
running average episode reward sum: 0.5606932754700865
{'scaleFactor': 30, 'timeStep': 90, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([ 4.8072386, 10.70409  ,  3.997013 ], dtype=float32)}
episode index:138
target Thresh 8.981087171207333
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([ 7.2080636, 10.192245 ,  4.3486085], dtype=float32)}
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.5631007933030983
{'scaleFactor': 30, 'timeStep': 12, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([3.621965 , 6.846819 , 2.7834134], dtype=float32)}
episode index:139
target Thresh 9.011106624178367
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([ 5.1830606, 11.533464 ,  0.1912942], dtype=float32)}
done in step count: 153
reward sum = 0.2148744477060795
running average episode reward sum: 0.5606134622631196
{'scaleFactor': 30, 'timeStep': 154, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([ 7.120739 , 10.064664 ,  6.2633867], dtype=float32)}
episode index:140
target Thresh 9.040976354503087
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([3.7645633, 9.978907 , 2.8066888], dtype=float32)}
done in step count: 51
reward sum = 0.598956006466161
running average episode reward sum: 0.5608853952007298
{'scaleFactor': 30, 'timeStep': 52, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([ 4.6099825, 10.453557 ,  5.6691766], dtype=float32)}
episode index:141
target Thresh 9.0706971089263
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([4.1298747, 9.763455 , 5.3043337], dtype=float32)}
done in step count: 212
reward sum = 0.11875755691154309
running average episode reward sum: 0.5577718188747497
{'scaleFactor': 30, 'timeStep': 213, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([8.532779  , 8.609846  , 0.20477074], dtype=float32)}
episode index:142
target Thresh 9.10026963046842
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([ 8.641948 , 10.5393095,  2.4942415], dtype=float32)}
done in step count: 47
reward sum = 0.6235253948912
running average episode reward sum: 0.5582316340916479
{'scaleFactor': 30, 'timeStep': 48, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([13.806909 , 11.988293 ,  1.1085091], dtype=float32)}
episode index:143
target Thresh 9.12969465844402
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([11.917181 ,  3.1727357,  3.0695367], dtype=float32)}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.5607629747884276
{'scaleFactor': 30, 'timeStep': 9, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([13.222259  ,  8.518847  ,  0.04765981], dtype=float32)}
episode index:144
target Thresh 9.15897292848034
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([7.4920297, 6.9661727, 4.1331744], dtype=float32)}
done in step count: 180
reward sum = 0.16380796970808742
running average episode reward sum: 0.5580253540637355
{'scaleFactor': 30, 'timeStep': 181, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([0.31166095, 6.765701  , 4.5825624 ], dtype=float32)}
episode index:145
target Thresh 9.188105172535652
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([2.1472096, 2.2366395, 4.771364 ], dtype=float32)}
done in step count: 204
reward sum = 0.12870034108965533
running average episode reward sum: 0.5550847717830912
{'scaleFactor': 30, 'timeStep': 205, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([7.966726 , 8.009673 , 2.7050793], dtype=float32)}
episode index:146
target Thresh 9.217092118917572
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([5.174272 , 9.946564 , 4.9755373], dtype=float32)}
done in step count: 66
reward sum = 0.5151371174238033
running average episode reward sum: 0.5548130190323478
{'scaleFactor': 30, 'timeStep': 67, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([13.486898,  9.589177,  2.167273], dtype=float32)}
episode index:147
target Thresh 9.24593449230127
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([5.777776 , 9.045848 , 1.6606072], dtype=float32)}
done in step count: 105
reward sum = 0.348093114492442
running average episode reward sum: 0.5534162629205918
{'scaleFactor': 30, 'timeStep': 106, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([10.555808 , 10.452429 ,  1.1805527], dtype=float32)}
episode index:148
target Thresh 9.274633013747588
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([10.33392  ,  3.1928124,  2.946727 ], dtype=float32)}
done in step count: 33
reward sum = 0.7177305325982749
running average episode reward sum: 0.554519043253999
{'scaleFactor': 30, 'timeStep': 34, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([4.736209 , 9.868328 , 3.0886946], dtype=float32)}
episode index:149
target Thresh 9.303188400721051
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([7.159383 , 8.950403 , 4.5709224], dtype=float32)}
done in step count: 33
reward sum = 0.7177305325982749
running average episode reward sum: 0.5556071198496276
{'scaleFactor': 30, 'timeStep': 34, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([10.095621 , 10.362536 ,  0.6676528], dtype=float32)}
episode index:150
target Thresh 9.331601367107822
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([1.768261 , 6.999025 , 1.1418449], dtype=float32)}
done in step count: 153
reward sum = 0.2148744477060795
running average episode reward sum: 0.5533506120870876
{'scaleFactor': 30, 'timeStep': 154, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([1.0796088, 3.8648372, 4.9422393], dtype=float32)}
episode index:151
target Thresh 9.359872623233544
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([1.3094175, 2.2732213, 4.232491 ], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.556289094902304
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([1.3094175, 2.2732213, 4.232491 ], dtype=float32)}
episode index:152
target Thresh 9.388002875881089
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([ 6.076887 , 10.015227 ,  2.9421105], dtype=float32)}
done in step count: 41
reward sum = 0.6622820409839835
running average episode reward sum: 0.5569818592557791
{'scaleFactor': 30, 'timeStep': 42, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([0.31909767, 6.017337  , 4.6524234 ], dtype=float32)}
episode index:153
target Thresh 9.415992828308239
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([11.011928  ,  9.326432  ,  0.92617345], dtype=float32)}
done in step count: 62
reward sum = 0.536268225207185
running average episode reward sum: 0.5568473551385804
{'scaleFactor': 30, 'timeStep': 63, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([11.333062 ,  6.4515047,  3.7903655], dtype=float32)}
episode index:154
target Thresh 9.443843180265263
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([12.653309 ,  8.969255 ,  5.8278456], dtype=float32)}
done in step count: 96
reward sum = 0.38104711810454966
running average episode reward sum: 0.5557131600609415
{'scaleFactor': 30, 'timeStep': 97, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([ 8.210454  , 11.350232  ,  0.36998278], dtype=float32)}
episode index:155
target Thresh 9.47155462801241
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([2.1306899 , 4.9160905 , 0.33331263], dtype=float32)}
done in step count: 58
reward sum = 0.5582661385478637
running average episode reward sum: 0.5557295253076525
{'scaleFactor': 30, 'timeStep': 59, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([3.7373018, 5.962989 , 3.6926272], dtype=float32)}
episode index:156
target Thresh 9.499127864337318
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([11.186888 , 10.707502 ,  1.5299053], dtype=float32)}
done in step count: 233
reward sum = 0.09616130339314856
running average episode reward sum: 0.5528023391808086
{'scaleFactor': 30, 'timeStep': 234, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([4.0238266, 9.347315 , 5.451874 ], dtype=float32)}
episode index:157
target Thresh 9.52656357857233
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([ 4.913926 , 11.591987 ,  1.4213586], dtype=float32)}
done in step count: 63
reward sum = 0.5309055429551132
running average episode reward sum: 0.5526637518629244
{'scaleFactor': 30, 'timeStep': 64, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([13.001317,  8.126707,  1.815996], dtype=float32)}
episode index:158
target Thresh 9.55386245661173
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([ 6.016815, 10.265429,  6.175666], dtype=float32)}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.5549332707033062
{'scaleFactor': 30, 'timeStep': 10, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([13.991029  ,  4.7388535 ,  0.16981477], dtype=float32)}
episode index:159
target Thresh 9.581025180928894
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([ 3.527303 , 10.910244 ,  1.3697925], dtype=float32)}
done in step count: 14
reward sum = 0.8687458127689782
running average episode reward sum: 0.5568945990912166
{'scaleFactor': 30, 'timeStep': 15, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([ 6.329453 , 11.284089 ,  5.5996394], dtype=float32)}
episode index:160
target Thresh 9.608052430593341
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([1.9215993, 4.1436033, 0.5869307], dtype=float32)}
done in step count: 38
reward sum = 0.682554595010387
running average episode reward sum: 0.5576750959602798
{'scaleFactor': 30, 'timeStep': 39, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([3.6050086, 9.245899 , 3.7305858], dtype=float32)}
episode index:161
target Thresh 9.634944881287723
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([13.090324, 10.599842,  6.135129], dtype=float32)}
done in step count: 141
reward sum = 0.2424166460445802
running average episode reward sum: 0.5557290561459853
{'scaleFactor': 30, 'timeStep': 142, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([7.785512 , 9.775196 , 2.6874118], dtype=float32)}
episode index:162
target Thresh 9.661703205324706
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([6.7818193, 9.478712 , 6.210999 ], dtype=float32)}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.5582724300346603
{'scaleFactor': 30, 'timeStep': 4, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([10.799779 ,  8.419162 ,  6.2741795], dtype=float32)}
episode index:163
target Thresh 9.688328071663786
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([2.8330727 , 9.094144  , 0.02727094], dtype=float32)}
done in step count: 175
reward sum = 0.1722499301915014
running average episode reward sum: 0.5559186343039093
{'scaleFactor': 30, 'timeStep': 176, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([0.10600448, 5.354094  , 3.4681876 ], dtype=float32)}
episode index:164
target Thresh 9.714820145928007
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([ 6.4448824, 11.350372 ,  2.7841115], dtype=float32)}
done in step count: 217
reward sum = 0.11293725497331045
running average episode reward sum: 0.5532338986716026
{'scaleFactor': 30, 'timeStep': 218, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([5.025764 , 9.506503 , 2.8089676], dtype=float32)}
episode index:165
target Thresh 9.74118009042061
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([10.860253 , 10.196657 ,  0.3953863], dtype=float32)}
done in step count: 136
reward sum = 0.2549097606963093
running average episode reward sum: 0.5514367653103056
{'scaleFactor': 30, 'timeStep': 137, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([2.770482 , 9.967833 , 2.9481142], dtype=float32)}
episode index:166
target Thresh 9.767408564141572
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([12.135412 ,  8.105571 ,  2.1692927], dtype=float32)}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5538292999485673
{'scaleFactor': 30, 'timeStep': 6, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([4.4347124, 9.857264 , 3.173706 ], dtype=float32)}
episode index:167
target Thresh 9.793506222804108
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([6.9706326, 8.764488 , 5.9537163], dtype=float32)}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.5559159236096402
{'scaleFactor': 30, 'timeStep': 11, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([2.3792486, 6.6450286, 3.4412975], dtype=float32)}
episode index:168
target Thresh 9.819473718851043
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([1.5425972, 7.4994187, 4.260723 ], dtype=float32)}
done in step count: 40
reward sum = 0.6689717585696803
running average episode reward sum: 0.5565848930472735
{'scaleFactor': 30, 'timeStep': 41, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([ 6.2664886, 10.352809 ,  1.004623 ], dtype=float32)}
episode index:169
target Thresh 9.845311701471129
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([9.896907 , 7.6998205, 3.6574345], dtype=float32)}
done in step count: 196
reward sum = 0.139475568775225
running average episode reward sum: 0.5541313087868497
{'scaleFactor': 30, 'timeStep': 197, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([1.7000413, 6.8406086, 4.987611 ], dtype=float32)}
episode index:170
target Thresh 9.87102081661528
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([4.029396 , 6.1177545, 5.9596386], dtype=float32)}
done in step count: 34
reward sum = 0.7105532272722921
running average episode reward sum: 0.555046056848168
{'scaleFactor': 30, 'timeStep': 35, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([1.7156118, 9.58788  , 2.207193 ], dtype=float32)}
episode index:171
target Thresh 9.89660170701271
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([6.1056304, 9.858541 , 4.586937 ], dtype=float32)}
done in step count: 253
reward sum = 0.07865099717364833
running average episode reward sum: 0.5522763181291301
{'scaleFactor': 30, 'timeStep': 254, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([11.067793 ,  6.5949664,  0.2658555], dtype=float32)}
episode index:172
target Thresh 9.922055012187014
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([2.4186296, 8.01844  , 1.662271 ], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.5548643162902334
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([2.4186296, 8.01844  , 1.662271 ], dtype=float32)}
episode index:173
target Thresh 9.947381368472145
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([2.2534866, 3.0262306, 4.323393 ], dtype=float32)}
done in step count: 16
reward sum = 0.8514577710948755
running average episode reward sum: 0.5565688763753175
{'scaleFactor': 30, 'timeStep': 17, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([2.160915  , 8.784941  , 0.87730336], dtype=float32)}
episode index:174
target Thresh 9.972581409028333
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([11.680651,  9.848549,  5.873537], dtype=float32)}
done in step count: 61
reward sum = 0.5416850759668536
running average episode reward sum: 0.5564838260872691
{'scaleFactor': 30, 'timeStep': 62, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([8.0819   , 8.467039 , 3.7879443], dtype=float32)}
episode index:175
target Thresh 9.9976557638579
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([ 3.7758772, 10.24849  ,  1.4659158], dtype=float32)}
done in step count: 216
reward sum = 0.1140780353265762
running average episode reward sum: 0.5539701568215833
{'scaleFactor': 30, 'timeStep': 217, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([13.907334 ,  5.4215403,  4.661296 ], dtype=float32)}
episode index:176
target Thresh 10.022605059821023
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([6.776347 , 8.200737 , 6.1488166], dtype=float32)}
done in step count: 121
reward sum = 0.296386587399208
running average episode reward sum: 0.5525148824180671
{'scaleFactor': 30, 'timeStep': 122, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([13.589258,  3.375691,  4.305422], dtype=float32)}
episode index:177
target Thresh 10.047429920651405
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([5.1532474, 8.085461 , 4.3353434], dtype=float32)}
done in step count: 399
reward sum = 0.0
running average episode reward sum: 0.5494108662247071
{'scaleFactor': 30, 'timeStep': 400, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([11.792834  ,  8.413586  ,  0.28254288], dtype=float32)}
episode index:178
target Thresh 10.072130966971853
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([ 7.222534 , 10.078979 ,  2.5740654], dtype=float32)}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.5518169507709378
{'scaleFactor': 30, 'timeStep': 3, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([ 3.5060701, 10.944296 ,  3.251124 ], dtype=float32)}
episode index:179
target Thresh 10.096708816309818
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([11.917289 ,  5.0707746,  4.739847 ], dtype=float32)}
done in step count: 38
reward sum = 0.682554595010387
running average episode reward sum: 0.5525432710167125
{'scaleFactor': 30, 'timeStep': 39, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([ 8.938951 , 11.037    ,  2.8918223], dtype=float32)}
episode index:180
target Thresh 10.121164083112811
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([2.1858687, 6.9814057, 1.045897 ], dtype=float32)}
done in step count: 20
reward sum = 0.8179069375972308
running average episode reward sum: 0.5540093686221298
{'scaleFactor': 30, 'timeStep': 21, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([13.918109 ,  5.1960244,  3.9085097], dtype=float32)}
episode index:181
target Thresh 10.145497378763773
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([0.05791569, 1.860703  , 2.8696935 ], dtype=float32)}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.5560865992775411
{'scaleFactor': 30, 'timeStep': 8, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([0.5085741, 5.465227 , 1.5779086], dtype=float32)}
episode index:182
target Thresh 10.169709311596367
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([10.172724 ,  8.446462 ,  2.7345467], dtype=float32)}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.558403612396243
{'scaleFactor': 30, 'timeStep': 3, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([ 7.028333 , 11.389875 ,  2.6930263], dtype=float32)}
episode index:183
target Thresh 10.193800486910174
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([7.046528, 8.216648, 4.916272], dtype=float32)}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.5606421742853939
{'scaleFactor': 30, 'timeStep': 4, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([11.387951 ,  4.027663 ,  5.4115744], dtype=float32)}
episode index:184
target Thresh 10.21777150698583
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([8.183536, 9.804869, 5.718064], dtype=float32)}
done in step count: 28
reward sum = 0.7547192872036326
running average episode reward sum: 0.5616912397606275
{'scaleFactor': 30, 'timeStep': 29, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([5.7074842, 7.8843307, 2.427015 ], dtype=float32)}
episode index:185
target Thresh 10.241622971100085
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([8.90564  , 8.380023 , 3.3386145], dtype=float32)}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5637842441162155
{'scaleFactor': 30, 'timeStep': 6, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([2.3661833, 4.6678853, 3.9719787], dtype=float32)}
episode index:186
target Thresh 10.265355475540787
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([10.073388 ,  7.70435  ,  3.7247195], dtype=float32)}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5658040083155994
{'scaleFactor': 30, 'timeStep': 7, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([6.068688 , 8.597379 , 1.6829972], dtype=float32)}
episode index:187
target Thresh 10.288969613621779
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([ 4.3985314, 11.958277 ,  1.189213 ], dtype=float32)}
done in step count: 23
reward sum = 0.7936142836436554
running average episode reward sum: 0.5670157650992592
{'scaleFactor': 30, 'timeStep': 24, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([0.12320733, 8.304992  , 2.5726886 ], dtype=float32)}
episode index:188
target Thresh 10.312465975697746
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([1.2034097, 8.435685 , 4.2705564], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.5692537769241308
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([1.2946755, 6.6879535, 4.866945 ], dtype=float32)}
episode index:189
target Thresh 10.335845149178963
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([ 9.444169, 10.229001,  2.535446], dtype=float32)}
done in step count: 77
reward sum = 0.46122196741809546
running average episode reward sum: 0.5686851884530464
{'scaleFactor': 30, 'timeStep': 78, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([ 5.2647095, 11.952875 ,  6.0767083], dtype=float32)}
episode index:190
target Thresh 10.359107718545985
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([14.008856 ,  3.592517 ,  0.1883514], dtype=float32)}
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.5703954139284687
{'scaleFactor': 30, 'timeStep': 12, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([11.719516 , 10.286347 ,  2.1888416], dtype=float32)}
episode index:191
target Thresh 10.382254265364256
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([ 5.153889, 10.267841,  6.219285], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.572632937814258
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([ 5.153889, 10.267841,  6.219285], dtype=float32)}
episode index:192
target Thresh 10.405285368298655
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([1.9625189, 4.123284 , 2.7455418], dtype=float32)}
done in step count: 399
reward sum = 0.0
running average episode reward sum: 0.5696659277737696
{'scaleFactor': 30, 'timeStep': 400, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([0.3284037, 1.5782562, 4.9096394], dtype=float32)}
episode index:193
target Thresh 10.428201603127953
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([1.9105272, 2.8027105, 4.436149 ], dtype=float32)}
done in step count: 78
reward sum = 0.4566097477439145
running average episode reward sum: 0.5690831639591827
{'scaleFactor': 30, 'timeStep': 79, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([1.2215251, 8.868711 , 0.7422497], dtype=float32)}
episode index:194
target Thresh 10.451003542759214
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([11.898923  ,  0.19837546,  4.45479   ], dtype=float32)}
done in step count: 136
reward sum = 0.2549097606963093
running average episode reward sum: 0.5674720183014244
{'scaleFactor': 30, 'timeStep': 137, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([11.0006485,  8.865436 ,  4.3403244], dtype=float32)}
episode index:195
target Thresh 10.473691757242117
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([10.190107 ,  2.8005729,  2.7743251], dtype=float32)}
done in step count: 160
reward sum = 0.2002770268574893
running average episode reward sum: 0.5655985744675267
{'scaleFactor': 30, 'timeStep': 161, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([0.9021249, 9.369256 , 3.1236124], dtype=float32)}
episode index:196
target Thresh 10.496266813783205
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([9.930443 , 8.634927 , 3.4440284], dtype=float32)}
done in step count: 149
reward sum = 0.2236886739786474
running average episode reward sum: 0.5638629912163141
{'scaleFactor': 30, 'timeStep': 150, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([3.0042238, 3.9231424, 3.5951698], dtype=float32)}
episode index:197
target Thresh 10.518729276760068
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([13.909305 ,  9.285825 ,  6.1941304], dtype=float32)}
done in step count: 71
reward sum = 0.4898902730042049
running average episode reward sum: 0.5634893916293843
{'scaleFactor': 30, 'timeStep': 72, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([8.055088 , 8.851233 , 3.1416426], dtype=float32)}
episode index:198
target Thresh 10.54107970773545
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([11.915787 ,  8.8724165,  3.496384 ], dtype=float32)}
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.5650674400282263
{'scaleFactor': 30, 'timeStep': 14, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([2.0778809, 7.101262 , 3.5764992], dtype=float32)}
episode index:199
target Thresh 10.563318665471293
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([11.877579  ,  5.854282  ,  0.20653123], dtype=float32)}
done in step count: 15
reward sum = 0.8600583546412884
running average episode reward sum: 0.5665423946012915
{'scaleFactor': 30, 'timeStep': 16, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([6.660501, 7.120014, 3.516875], dtype=float32)}
episode index:200
target Thresh 10.585446705942692
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([9.961576 , 9.019212 , 1.8382835], dtype=float32)}
done in step count: 212
reward sum = 0.11875755691154309
running average episode reward sum: 0.5643146093391536
{'scaleFactor': 30, 'timeStep': 213, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([12.627648 ,  8.646906 ,  5.6225877], dtype=float32)}
episode index:201
target Thresh 10.607464382351814
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([11.203814 ,  8.262668 ,  4.7968388], dtype=float32)}
done in step count: 89
reward sum = 0.40882017442254925
running average episode reward sum: 0.5635448349088733
{'scaleFactor': 30, 'timeStep': 90, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([2.4608455, 5.045438 , 3.651883 ], dtype=float32)}
episode index:202
target Thresh 10.62937224514172
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([1.9780203, 7.8322906, 5.544797 ], dtype=float32)}
done in step count: 159
reward sum = 0.2023000271287771
running average episode reward sum: 0.5617653038360649
{'scaleFactor': 30, 'timeStep': 160, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([10.899776,  4.690497,  5.294195], dtype=float32)}
episode index:203
target Thresh 10.651170842010115
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([13.995104 ,  5.0349073,  5.7959785], dtype=float32)}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.5634895780696315
{'scaleFactor': 30, 'timeStep': 10, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([13.84337  ,  3.1232471,  4.252428 ], dtype=float32)}
episode index:204
target Thresh 10.67286071792306
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([13.480187 ,  4.4658337,  0.6171603], dtype=float32)}
done in step count: 16
reward sum = 0.8514577710948755
running average episode reward sum: 0.5648943009624375
{'scaleFactor': 30, 'timeStep': 17, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([13.843674  ,  8.177865  ,  0.18355933], dtype=float32)}
episode index:205
target Thresh 10.69444241512858
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([1.7528791, 2.9814496, 5.504569 ], dtype=float32)}
done in step count: 18
reward sum = 0.8345137614500875
running average episode reward sum: 0.5662031332949018
{'scaleFactor': 30, 'timeStep': 19, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([7.9374948 , 9.3896265 , 0.70330465], dtype=float32)}
episode index:206
target Thresh 10.715916473170232
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([2.0553012, 3.910138 , 6.001529 ], dtype=float32)}
done in step count: 168
reward sum = 0.1848045639485463
running average episode reward sum: 0.5643606281289774
{'scaleFactor': 30, 'timeStep': 169, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([10.8555155,  8.074307 ,  5.693539 ], dtype=float32)}
episode index:207
target Thresh 10.737283428900582
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([11.972307,  2.114561,  6.239311], dtype=float32)}
done in step count: 21
reward sum = 0.8097278682212584
running average episode reward sum: 0.5655402783217287
{'scaleFactor': 30, 'timeStep': 22, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([7.8512287, 7.785304 , 2.4615328], dtype=float32)}
episode index:208
target Thresh 10.758543816494637
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([1.9915932, 6.900443 , 2.1394439], dtype=float32)}
done in step count: 189
reward sum = 0.14964140560361563
running average episode reward sum: 0.5635503315623119
{'scaleFactor': 30, 'timeStep': 190, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([6.6600113, 9.262315 , 0.7577274], dtype=float32)}
episode index:209
target Thresh 10.779698167463197
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([ 9.917764, 10.148741,  3.648494], dtype=float32)}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.5654872299834437
{'scaleFactor': 30, 'timeStep': 4, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([7.437549 , 8.173248 , 3.7649307], dtype=float32)}
episode index:210
target Thresh 10.800747010666136
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([ 5.8314176, 10.027854 ,  1.414654 ], dtype=float32)}
done in step count: 336
reward sum = 0.03415272685621234
running average episode reward sum: 0.5629690569828406
{'scaleFactor': 30, 'timeStep': 337, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([1.852644 , 0.4251803, 6.151186 ], dtype=float32)}
episode index:211
target Thresh 10.821690872325629
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([8.977788 , 9.183881 , 0.6680576], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.5650305236951857
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([8.977788 , 9.183881 , 0.6680576], dtype=float32)}
episode index:212
target Thresh 10.84253027603931
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([2.0834966, 9.059135 , 3.0383246], dtype=float32)}
done in step count: 93
reward sum = 0.39271102835780486
running average episode reward sum: 0.5642215119799867
{'scaleFactor': 30, 'timeStep': 94, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([11.080709 ,  6.7707396,  5.2894325], dtype=float32)}
episode index:213
target Thresh 10.863265742793356
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([7.7478666, 8.202427 , 5.1908584], dtype=float32)}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.5661190703352205
{'scaleFactor': 30, 'timeStep': 4, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([8.146889, 8.356273, 4.71348 ], dtype=float32)}
episode index:214
target Thresh 10.883897790975519
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([11.997226 ,  9.925202 ,  2.9041502], dtype=float32)}
done in step count: 133
reward sum = 0.2627125872502283
running average episode reward sum: 0.5647078773906391
{'scaleFactor': 30, 'timeStep': 134, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([13.831559 ,  5.7904706,  4.247903 ], dtype=float32)}
episode index:215
target Thresh 10.904426936388074
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([2.1777267, 3.0047402, 1.7138381], dtype=float32)}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.5665856140693861
{'scaleFactor': 30, 'timeStep': 4, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([3.1331992, 8.536677 , 1.9361253], dtype=float32)}
episode index:216
target Thresh 10.924853692260731
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([8.779756 , 8.87689  , 3.8430576], dtype=float32)}
done in step count: 105
reward sum = 0.348093114492442
running average episode reward sum: 0.5655787361911514
{'scaleFactor': 30, 'timeStep': 106, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([0.36951184, 1.0266474 , 5.1163297 ], dtype=float32)}
episode index:217
target Thresh 10.945178569263444
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([ 4.064571 , 10.357196 ,  4.3929186], dtype=float32)}
done in step count: 48
reward sum = 0.617290140942288
running average episode reward sum: 0.5658159444698263
{'scaleFactor': 30, 'timeStep': 49, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([10.028652 , 10.222379 ,  1.0497155], dtype=float32)}
episode index:218
target Thresh 10.9654020755192
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([10.058579 , 10.077648 ,  0.5315361], dtype=float32)}
done in step count: 261
reward sum = 0.07257479035344933
running average episode reward sum: 0.5635637017569661
{'scaleFactor': 30, 'timeStep': 262, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([2.126656 , 6.736226 , 4.1880536], dtype=float32)}
episode index:219
target Thresh 10.985524716616709
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([ 4.159064  , 10.238164  ,  0.99467677], dtype=float32)}
done in step count: 101
reward sum = 0.3623720178604969
running average episode reward sum: 0.5626491941028913
{'scaleFactor': 30, 'timeStep': 102, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([0.02540651, 0.99435663, 4.3661566 ], dtype=float32)}
episode index:220
target Thresh 11.005546995623044
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([10.067487 ,  9.068131 ,  2.7059646], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.5646281570255026
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([10.067487 ,  9.068131 ,  2.7059646], dtype=float32)}
episode index:221
target Thresh 11.025469413096229
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([11.949422 ,  7.602718 ,  4.0976195], dtype=float32)}
done in step count: 17
reward sum = 0.8429431933839268
running average episode reward sum: 0.5658818283604505
{'scaleFactor': 30, 'timeStep': 18, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([1.3331782, 4.5269127, 4.2346687], dtype=float32)}
episode index:222
target Thresh 11.045292467097731
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([2.1485748, 9.850692 , 3.0029557], dtype=float32)}
done in step count: 39
reward sum = 0.6757290490602831
running average episode reward sum: 0.5663744167940821
{'scaleFactor': 30, 'timeStep': 40, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([9.959996 , 9.179594 , 6.1796117], dtype=float32)}
episode index:223
target Thresh 11.065016653204937
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([2.8893828, 9.182954 , 5.2320395], dtype=float32)}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5680489959575058
{'scaleFactor': 30, 'timeStep': 7, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([2.5533772, 6.624312 , 3.7200336], dtype=float32)}
episode index:224
target Thresh 11.084642464523526
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([2.0150244, 3.0021691, 5.7789025], dtype=float32)}
done in step count: 86
reward sum = 0.421334222154768
running average episode reward sum: 0.5673969302961603
{'scaleFactor': 30, 'timeStep': 87, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([10.064397  ,  7.3408494 ,  0.08869999], dtype=float32)}
episode index:225
target Thresh 11.104170391699803
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([11.92281 ,  4.89711 ,  4.693972], dtype=float32)}
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.5687691607948454
{'scaleFactor': 30, 'timeStep': 14, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([10.5155735,  8.670699 ,  1.4499937], dtype=float32)}
episode index:226
target Thresh 11.123600922932965
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([12.211232 ,  2.7179272,  2.25789  ], dtype=float32)}
done in step count: 399
reward sum = 0.0
running average episode reward sum: 0.566263569778128
{'scaleFactor': 30, 'timeStep': 400, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([12.414964 ,  4.8754425,  1.7955557], dtype=float32)}
episode index:227
target Thresh 11.142934543987304
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([ 5.999719 , 10.201168 ,  3.0960553], dtype=float32)}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.5679930980247151
{'scaleFactor': 30, 'timeStep': 5, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([ 6.1543612, 10.707451 ,  4.246556 ], dtype=float32)}
episode index:228
target Thresh 11.162171738204352
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([9.035963, 9.007957, 6.25197 ], dtype=float32)}
done in step count: 33
reward sum = 0.7177305325982749
running average episode reward sum: 0.5686469732848616
{'scaleFactor': 30, 'timeStep': 34, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([0.09714451, 5.153666  , 3.564581  ], dtype=float32)}
episode index:229
target Thresh 11.18131298651497
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([11.843976 ,  8.375051 ,  4.6001725], dtype=float32)}
done in step count: 35
reward sum = 0.7034476949995692
running average episode reward sum: 0.5692330633792734
{'scaleFactor': 30, 'timeStep': 36, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([7.79355 , 7.012352, 2.598727], dtype=float32)}
episode index:230
target Thresh 11.200358767451359
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([11.994471  , 10.053039  ,  0.18943544], dtype=float32)}
done in step count: 158
reward sum = 0.2043434617462395
running average episode reward sum: 0.5676534547141954
{'scaleFactor': 30, 'timeStep': 159, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([2.7994905, 7.22374  , 2.6276689], dtype=float32)}
episode index:231
target Thresh 11.21930955715904
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([12.128062,  8.224548,  4.068822], dtype=float32)}
done in step count: 37
reward sum = 0.6894490858690777
running average episode reward sum: 0.5681784358829665
{'scaleFactor': 30, 'timeStep': 38, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([4.7494526, 9.761029 , 2.950127 ], dtype=float32)}
episode index:232
target Thresh 11.238165829408736
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([10.133373  , 10.330597  ,  0.23425722], dtype=float32)}
done in step count: 84
reward sum = 0.4298890135238935
running average episode reward sum: 0.5675849190488074
{'scaleFactor': 30, 'timeStep': 85, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([7.3752666, 8.045987 , 3.8240201], dtype=float32)}
episode index:233
target Thresh 11.256928055608238
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([10.028505 ,  9.855185 ,  1.5861015], dtype=float32)}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.5691026958666668
{'scaleFactor': 30, 'timeStep': 9, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([ 9.005345 , 10.769179 ,  3.4150443], dtype=float32)}
episode index:234
target Thresh 11.27559670481418
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([2.1258297, 7.7855763, 5.918138 ], dtype=float32)}
done in step count: 297
reward sum = 0.050542043299318794
running average episode reward sum: 0.5668960547919122
{'scaleFactor': 30, 'timeStep': 298, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([9.318308, 9.748772, 5.592541], dtype=float32)}
episode index:235
target Thresh 11.29417224374376
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([4.965414, 7.746693, 4.140356], dtype=float32)}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.5686469189665228
{'scaleFactor': 30, 'timeStep': 3, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([3.5865326, 4.0776124, 4.425255 ], dtype=float32)}
episode index:236
target Thresh 11.312655136786425
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([3.919664, 8.975028, 1.447645], dtype=float32)}
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.569950185228263
{'scaleFactor': 30, 'timeStep': 14, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([0.10268441, 5.8473005 , 4.7812867 ], dtype=float32)}
episode index:237
target Thresh 11.331045846015458
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([ 5.105327, 11.727115,  2.264554], dtype=float32)}
done in step count: 43
reward sum = 0.6491026283684022
running average episode reward sum: 0.5702827585187678
{'scaleFactor': 30, 'timeStep': 44, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([ 1.6424729, 10.316147 ,  4.696849 ], dtype=float32)}
episode index:238
target Thresh 11.34934483119955
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([3.428404 , 4.518194 , 0.7091272], dtype=float32)}
done in step count: 46
reward sum = 0.6298236312032323
running average episode reward sum: 0.5705318835090794
{'scaleFactor': 30, 'timeStep': 47, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([0.317445 , 5.0854626, 2.747604 ], dtype=float32)}
episode index:239
target Thresh 11.367552549814285
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([6.540022 , 7.614017 , 5.3776813], dtype=float32)}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.5719994368879079
{'scaleFactor': 30, 'timeStep': 9, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([11.326855,  6.570242,  5.936795], dtype=float32)}
episode index:240
target Thresh 11.385669457053574
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([12.089744,  2.964741,  6.183713], dtype=float32)}
done in step count: 220
reward sum = 0.10958290556334815
running average episode reward sum: 0.5700806960940301
{'scaleFactor': 30, 'timeStep': 221, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([0.21738814, 3.4104304 , 4.5032735 ], dtype=float32)}
episode index:241
target Thresh 11.403696005841045
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([12.466153 ,  5.0303288,  0.671847 ], dtype=float32)}
done in step count: 183
reward sum = 0.1589427091997875
running average episode reward sum: 0.5683817787928142
{'scaleFactor': 30, 'timeStep': 184, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([0.07187606, 7.8000517 , 4.643632  ], dtype=float32)}
episode index:242
target Thresh 11.421632646841353
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([2.2194178, 2.6881084, 4.695067 ], dtype=float32)}
done in step count: 181
reward sum = 0.16216989001100654
running average episode reward sum: 0.5667101249295146
{'scaleFactor': 30, 'timeStep': 182, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([4.8815236, 8.270332 , 1.0709345], dtype=float32)}
episode index:243
target Thresh 11.439479828471457
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([9.140121 , 9.342794 , 1.1379974], dtype=float32)}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.5684043457289837
{'scaleFactor': 30, 'timeStep': 3, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([10.8873415 ,  9.926535  ,  0.98575056], dtype=float32)}
episode index:244
target Thresh 11.457237996911829
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([ 6.17171  , 10.685744 ,  2.4973063], dtype=float32)}
done in step count: 360
reward sum = 0.026833050939885684
running average episode reward sum: 0.5661938506482119
{'scaleFactor': 30, 'timeStep': 361, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([3.7618349, 5.788996 , 4.3057027], dtype=float32)}
episode index:245
target Thresh 11.474907596117607
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([9.129971, 9.048741, 0.130157], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.5679166398732192
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([10.64627  , 10.159353 ,  0.2076607], dtype=float32)}
episode index:246
target Thresh 11.492489067829688
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([5.0304313, 9.053692 , 4.434564 ], dtype=float32)}
done in step count: 147
reward sum = 0.22823046013534068
running average episode reward sum: 0.5665413921819727
{'scaleFactor': 30, 'timeStep': 148, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([13.713047 ,  7.1549845,  4.518422 ], dtype=float32)}
episode index:247
target Thresh 11.50998285158578
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([11.152421 ,  9.14267  ,  1.3280859], dtype=float32)}
done in step count: 46
reward sum = 0.6298236312032323
running average episode reward sum: 0.5667965625006068
{'scaleFactor': 30, 'timeStep': 47, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([8.652216, 8.576971, 2.670232], dtype=float32)}
episode index:248
target Thresh 11.527389384731393
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([3.7062616, 7.3617053, 5.642383 ], dtype=float32)}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.5682260730705961
{'scaleFactor': 30, 'timeStep': 9, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([2.5296988, 4.2537537, 3.309829 ], dtype=float32)}
episode index:249
target Thresh 11.544709102430758
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([2.0509923, 6.0950246, 3.89614  ], dtype=float32)}
done in step count: 59
reward sum = 0.5526834771623851
running average episode reward sum: 0.5681639026869633
{'scaleFactor': 30, 'timeStep': 60, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([3.7455482, 7.0824237, 2.9896126], dtype=float32)}
episode index:250
target Thresh 11.561942437677718
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([10.773824 ,  8.97201  ,  2.3140686], dtype=float32)}
done in step count: 22
reward sum = 0.8016305895390459
running average episode reward sum: 0.5690940488497207
{'scaleFactor': 30, 'timeStep': 23, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([ 5.5500884, 11.994076 ,  1.9484056], dtype=float32)}
episode index:251
target Thresh 11.579089821306557
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([ 5.412314 , 10.922979 ,  2.7243142], dtype=float32)}
done in step count: 36
reward sum = 0.6964132180495735
running average episode reward sum: 0.5695992836481327
{'scaleFactor': 30, 'timeStep': 37, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([ 1.2294412, 11.469255 ,  3.2254882], dtype=float32)}
episode index:252
target Thresh 11.596151682002755
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([11.917899 ,  6.9289947,  0.7984085], dtype=float32)}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.5712218161238318
{'scaleFactor': 30, 'timeStep': 3, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([12.996554 ,  8.326114 ,  0.6607009], dtype=float32)}
episode index:253
target Thresh 11.61312844631372
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([12.460448 ,  5.85407  ,  1.0184921], dtype=float32)}
done in step count: 36
reward sum = 0.6964132180495735
running average episode reward sum: 0.5717146956589725
{'scaleFactor': 30, 'timeStep': 37, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([10.869139, 10.183475,  3.604749], dtype=float32)}
episode index:254
target Thresh 11.630020538659442
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([12.030306 ,  4.9733353,  4.1272454], dtype=float32)}
done in step count: 21
reward sum = 0.8097278682212584
running average episode reward sum: 0.5726480806494127
{'scaleFactor': 30, 'timeStep': 22, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([10.777941 ,  9.043016 ,  1.1764526], dtype=float32)}
episode index:255
target Thresh 11.646828381343113
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([10.619401 , 11.085011 ,  1.9222543], dtype=float32)}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.5740156455469851
{'scaleFactor': 30, 'timeStep': 9, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([ 4.350149 , 10.642437 ,  4.1949024], dtype=float32)}
episode index:256
target Thresh 11.66355239456167
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([-0.07139349,  6.9520125 ,  2.8380785 ], dtype=float32)}
done in step count: 399
reward sum = 0.0
running average episode reward sum: 0.5717821216343509
{'scaleFactor': 30, 'timeStep': 400, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([3.321068 , 6.3524847, 2.3643036], dtype=float32)}
episode index:257
target Thresh 11.68019299641632
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([ 6.648595 , 10.297119 ,  0.0604089], dtype=float32)}
done in step count: 88
reward sum = 0.41294967113388814
running average episode reward sum: 0.5711664919812485
{'scaleFactor': 30, 'timeStep': 89, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([4.1139636, 9.606695 , 2.870563 ], dtype=float32)}
episode index:258
target Thresh 11.696750602922972
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([ 6.6999984 , 10.682933  ,  0.94134015], dtype=float32)}
done in step count: 15
reward sum = 0.8600583546412884
running average episode reward sum: 0.5722819045783915
{'scaleFactor': 30, 'timeStep': 16, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([11.427392 , 11.73259  ,  6.0153184], dtype=float32)}
episode index:259
target Thresh 11.713225628022652
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([10.095295 ,  8.131799 ,  3.3275452], dtype=float32)}
done in step count: 26
reward sum = 0.7700431458051551
running average episode reward sum: 0.5730425247369559
{'scaleFactor': 30, 'timeStep': 27, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([10.332608 ,  3.5345721,  4.7060347], dtype=float32)}
episode index:260
target Thresh 11.729618483591848
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([3.9944081, 3.2225099, 5.828286 ], dtype=float32)}
done in step count: 19
reward sum = 0.8261686238355866
running average episode reward sum: 0.5740123565342687
{'scaleFactor': 30, 'timeStep': 20, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([0.49248806, 6.4071646 , 1.8448457 ], dtype=float32)}
episode index:261
target Thresh 11.745929579452802
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([2.1220584, 9.164705 , 2.9486485], dtype=float32)}
done in step count: 370
reward sum = 0.024267330287830763
running average episode reward sum: 0.5719140930753129
{'scaleFactor': 30, 'timeStep': 371, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([4.184739 , 8.176174 , 6.0986443], dtype=float32)}
episode index:262
target Thresh 11.762159323383758
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([12.376059 , 10.267913 ,  6.1016803], dtype=float32)}
done in step count: 135
reward sum = 0.25748460676394874
running average episode reward sum: 0.5707185436977031
{'scaleFactor': 30, 'timeStep': 136, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([ 5.1059637, 11.742702 ,  3.2699213], dtype=float32)}
episode index:263
target Thresh 11.778308121129161
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([12.106282,  8.863988,  3.381408], dtype=float32)}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5721589660696815
{'scaleFactor': 30, 'timeStep': 6, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([ 4.198926 , 10.54393  ,  2.2865589], dtype=float32)}
episode index:264
target Thresh 11.794376376409796
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([11.759446 ,  3.974265 ,  5.8846693], dtype=float32)}
done in step count: 27
reward sum = 0.7623427143471035
running average episode reward sum: 0.5728766405914832
{'scaleFactor': 30, 'timeStep': 28, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([ 6.1871357, 10.194914 ,  4.311123 ], dtype=float32)}
episode index:265
target Thresh 11.81036449093288
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([2.0545666, 7.1640882, 1.1058301], dtype=float32)}
done in step count: 69
reward sum = 0.4998370298991989
running average episode reward sum: 0.5726020555888807
{'scaleFactor': 30, 'timeStep': 70, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([13.9784   ,  6.6610675,  5.207732 ], dtype=float32)}
episode index:266
target Thresh 11.826272864402114
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([4.2680655, 9.840713 , 2.5733683], dtype=float32)}
done in step count: 120
reward sum = 0.2993803913123313
running average episode reward sum: 0.5715787534754853
{'scaleFactor': 30, 'timeStep': 121, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([0.02279844, 5.5589557 , 3.0930462 ], dtype=float32)}
episode index:267
target Thresh 11.842101894527655
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([1.7964506, 3.9027529, 0.3604554], dtype=float32)}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.573103086484905
{'scaleFactor': 30, 'timeStep': 3, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([2.3972416, 5.387225 , 1.3501638], dtype=float32)}
episode index:268
target Thresh 11.857851977036088
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([10.113943,  8.366399,  3.233902], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.5746900638585671
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([10.113943,  8.366399,  3.233902], dtype=float32)}
episode index:269
target Thresh 11.873523505680293
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([12.080191 ,  1.9711915,  4.0900903], dtype=float32)}
done in step count: 216
reward sum = 0.1140780353265762
running average episode reward sum: 0.5729840933825228
{'scaleFactor': 30, 'timeStep': 217, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([3.7290368, 6.236962 , 3.1816359], dtype=float32)}
episode index:270
target Thresh 11.889116872249302
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([ 4.5450983, 11.7285185,  1.1429945], dtype=float32)}
done in step count: 61
reward sum = 0.5416850759668536
running average episode reward sum: 0.5728685988533136
{'scaleFactor': 30, 'timeStep': 62, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([8.376729 , 8.633627 , 1.9793582], dtype=float32)}
episode index:271
target Thresh 11.904632466578091
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([10.238934 ,  2.0250933,  3.72197  ], dtype=float32)}
done in step count: 57
reward sum = 0.5639051904523875
running average episode reward sum: 0.5728356451459572
{'scaleFactor': 30, 'timeStep': 58, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([10.127453,  8.72794 ,  2.482434], dtype=float32)}
episode index:272
target Thresh 11.92007067655733
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([6.0645256, 9.114259 , 0.4393578], dtype=float32)}
done in step count: 66
reward sum = 0.5151371174238033
running average episode reward sum: 0.572624295227561
{'scaleFactor': 30, 'timeStep': 67, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([11.901579 ,  4.870324 ,  5.2148447], dtype=float32)}
episode index:273
target Thresh 11.935431888143068
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([3.8320494, 9.91841  , 6.077824 ], dtype=float32)}
done in step count: 53
reward sum = 0.5870367819374844
running average episode reward sum: 0.5726768955440206
{'scaleFactor': 30, 'timeStep': 54, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([ 7.82971   , 10.692084  ,  0.19332522], dtype=float32)}
episode index:274
target Thresh 11.950716485366396
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([ 9.032276  , 11.346006  ,  0.68087155], dtype=float32)}
done in step count: 33
reward sum = 0.7177305325982749
running average episode reward sum: 0.5732043633151269
{'scaleFactor': 30, 'timeStep': 34, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([ 5.3818417, 11.925344 ,  2.9044173], dtype=float32)}
episode index:275
target Thresh 11.965924850343042
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([ 2.9798539, 10.190204 ,  0.7800518], dtype=float32)}
done in step count: 399
reward sum = 0.0
running average episode reward sum: 0.5711275359118112
{'scaleFactor': 30, 'timeStep': 400, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([-0.4875855,  1.4497542,  3.410398 ], dtype=float32)}
episode index:276
target Thresh 11.981057363282922
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([11.192681 ,  9.107027 ,  1.1759248], dtype=float32)}
done in step count: 155
reward sum = 0.21059844619672852
running average episode reward sum: 0.569825986851468
{'scaleFactor': 30, 'timeStep': 156, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([ 2.0901957, 11.828199 ,  2.8656943], dtype=float32)}
episode index:277
target Thresh 11.996114402499646
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([12.072533 ,  2.0255976,  3.5136166], dtype=float32)}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.5710294260175016
{'scaleFactor': 30, 'timeStep': 11, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([4.109596, 8.484619, 2.939704], dtype=float32)}
episode index:278
target Thresh 12.01109634441998
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([12.003551 ,  2.7726924,  5.929149 ], dtype=float32)}
done in step count: 205
reward sum = 0.1274133376787588
running average episode reward sum: 0.569439404195499
{'scaleFactor': 30, 'timeStep': 206, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([ 6.4043994, 10.03306  ,  1.2635686], dtype=float32)}
episode index:279
target Thresh 12.026003563593255
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([ 9.305277 , 10.160776 ,  1.9280161], dtype=float32)}
done in step count: 124
reward sum = 0.2875836093668641
running average episode reward sum: 0.5684327763568252
{'scaleFactor': 30, 'timeStep': 125, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([11.721344 ,  5.780667 ,  0.3459503], dtype=float32)}
episode index:280
target Thresh 12.040836432700722
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([8.08037   , 9.18957   , 0.27812174], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.5699686027754842
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([8.08037   , 9.18957   , 0.27812174], dtype=float32)}
episode index:281
target Thresh 12.055595322564884
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([10.871145 ,  9.90563  ,  1.5590078], dtype=float32)}
done in step count: 333
reward sum = 0.035198147020879485
running average episode reward sum: 0.5680722536416026
{'scaleFactor': 30, 'timeStep': 334, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([10.198076 ,  3.7227373,  4.805168 ], dtype=float32)}
episode index:282
target Thresh 12.070280602158755
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([10.002891 ,  9.642893 ,  2.7129707], dtype=float32)}
done in step count: 399
reward sum = 0.0
running average episode reward sum: 0.5660649311905722
{'scaleFactor': 30, 'timeStep': 400, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([ 3.1827438, 12.180631 ,  2.6582518], dtype=float32)}
episode index:283
target Thresh 12.084892638615091
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([3.7576911, 3.817309 , 5.507701 ], dtype=float32)}
done in step count: 33
reward sum = 0.7177305325982749
running average episode reward sum: 0.5665989649983458
{'scaleFactor': 30, 'timeStep': 34, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([5.1900773, 9.441943 , 5.3106136], dtype=float32)}
episode index:284
target Thresh 12.099431797235562
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([1.3769069, 8.8542185, 1.7521521], dtype=float32)}
done in step count: 93
reward sum = 0.39271102835780486
running average episode reward sum: 0.5659888318873264
{'scaleFactor': 30, 'timeStep': 94, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([4.1643486, 7.9747257, 0.6901451], dtype=float32)}
episode index:285
target Thresh 12.113898441499895
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([13.473268  ,  3.1966362 ,  0.41647804], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.5675063534541539
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([13.473268  ,  3.1966362 ,  0.41647804], dtype=float32)}
episode index:286
target Thresh 12.128292933074945
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([2.152638 , 6.1517935, 3.784937 ], dtype=float32)}
done in step count: 304
reward sum = 0.04710848717170972
running average episode reward sum: 0.5656931204705914
{'scaleFactor': 30, 'timeStep': 305, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([11.851456 ,  7.3732195,  6.015832 ], dtype=float32)}
episode index:287
target Thresh 12.142615631823755
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([1.8181226, 9.291358 , 3.918267 ], dtype=float32)}
done in step count: 246
reward sum = 0.08438356532646984
running average episode reward sum: 0.5640219067374521
{'scaleFactor': 30, 'timeStep': 247, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([ 5.594398 , 11.164126 ,  5.1970634], dtype=float32)}
episode index:288
target Thresh 12.156866895814538
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([1.7736104, 9.097958 , 3.504207 ], dtype=float32)}
done in step count: 37
reward sum = 0.6894490858690777
running average episode reward sum: 0.5644559108174924
{'scaleFactor': 30, 'timeStep': 38, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([ 7.807268  , 11.586968  ,  0.33375233], dtype=float32)}
episode index:289
target Thresh 12.171047081329636
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([ 2.0061467, 10.074323 ,  2.498035 ], dtype=float32)}
done in step count: 77
reward sum = 0.46122196741809546
running average episode reward sum: 0.564099931702322
{'scaleFactor': 30, 'timeStep': 78, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([ 4.2219367, 10.635527 ,  3.8754668], dtype=float32)}
episode index:290
target Thresh 12.185156542874429
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([11.890628 ,  2.1476505,  6.180162 ], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.5655978700813518
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([11.890628 ,  2.1476505,  6.180162 ], dtype=float32)}
episode index:291
target Thresh 12.199195633186184
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([1.8953124, 3.0821676, 4.2859597], dtype=float32)}
done in step count: 71
reward sum = 0.4898902730042049
running average episode reward sum: 0.5653385974886218
{'scaleFactor': 30, 'timeStep': 72, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([ 2.0141127, 10.210695 ,  1.2945392], dtype=float32)}
episode index:292
target Thresh 12.213164703242894
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([12.0538435,  6.12623  ,  3.1889691], dtype=float32)}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5666223570514627
{'scaleFactor': 30, 'timeStep': 7, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([4.479595, 9.208531, 1.973917], dtype=float32)}
episode index:293
target Thresh 12.227064102272038
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([12.048118 ,  2.6092567,  5.632962 ], dtype=float32)}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.5677711996295489
{'scaleFactor': 30, 'timeStep': 11, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([13.904904 ,  9.579626 ,  1.7023466], dtype=float32)}
episode index:294
target Thresh 12.240894177759314
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([ 8.951406 , 10.055908 ,  5.7538986], dtype=float32)}
done in step count: 16
reward sum = 0.8514577710948755
running average episode reward sum: 0.5687328490243466
{'scaleFactor': 30, 'timeStep': 17, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([0.7930908, 3.800652 , 3.9486432], dtype=float32)}
episode index:295
target Thresh 12.254655275457331
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([5.886984, 8.144289, 4.855851], dtype=float32)}
done in step count: 24
reward sum = 0.7856781408072188
running average episode reward sum: 0.5694657723073969
{'scaleFactor': 30, 'timeStep': 25, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([10.692703, 10.307788,  6.207894], dtype=float32)}
episode index:296
target Thresh 12.268347739394247
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([4.8365374, 9.6425085, 1.5646876], dtype=float32)}
done in step count: 399
reward sum = 0.0
running average episode reward sum: 0.5675483791346447
{'scaleFactor': 30, 'timeStep': 400, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([3.8200564, 6.137985 , 4.928559 ], dtype=float32)}
episode index:297
target Thresh 12.281971911882374
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([9.840013 , 9.075683 , 1.7521613], dtype=float32)}
done in step count: 199
reward sum = 0.13533300490703204
running average episode reward sum: 0.5660979919728071
{'scaleFactor': 30, 'timeStep': 200, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([12.489805 ,  6.751312 ,  6.0198016], dtype=float32)}
episode index:298
target Thresh 12.295528133526735
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([13.806004  ,  3.8019805 ,  0.35256234], dtype=float32)}
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.5671395405715568
{'scaleFactor': 30, 'timeStep': 14, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([13.564843 ,  5.474246 ,  1.5023875], dtype=float32)}
episode index:299
target Thresh 12.309016743233576
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([5.4137588, 8.912442 , 3.836454 ], dtype=float32)}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5683873426009882
{'scaleFactor': 30, 'timeStep': 7, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([3.9456596, 7.44753  , 2.921851 ], dtype=float32)}
episode index:300
target Thresh 12.322438078218843
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([11.878145  ,  7.931326  ,  0.17610377], dtype=float32)}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.5695646095505793
{'scaleFactor': 30, 'timeStep': 9, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([5.91775  , 9.743108 , 2.6314578], dtype=float32)}
episode index:301
target Thresh 12.335792474016605
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([1.9783587, 5.861006 , 5.321404 ], dtype=float32)}
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.5706433302284207
{'scaleFactor': 30, 'timeStep': 12, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([3.3700795, 9.533739 , 1.9202727], dtype=float32)}
episode index:302
target Thresh 12.349080264487462
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([ 9.901535 , 10.65784  ,  1.3344967], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.5720603489405381
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([ 9.901535 , 10.65784  ,  1.3344967], dtype=float32)}
episode index:303
target Thresh 12.362301781826858
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([3.8677793, 8.866404 , 5.568362 ], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.5734680451611285
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([3.8677793, 8.866404 , 5.568362 ], dtype=float32)}
episode index:304
target Thresh 12.375457356573422
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([4.021183 , 9.057258 , 3.0313878], dtype=float32)}
done in step count: 41
reward sum = 0.6622820409839835
running average episode reward sum: 0.5737592385900558
{'scaleFactor': 30, 'timeStep': 42, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([11.389322 ,  7.9159966,  5.1566515], dtype=float32)}
episode index:305
target Thresh 12.388547317617206
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([3.8401513 , 8.601768  , 0.38547206], dtype=float32)}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.5750551201632911
{'scaleFactor': 30, 'timeStep': 4, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([7.4738474 , 9.758965  , 0.22273034], dtype=float32)}
episode index:306
target Thresh 12.401571992207915
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([1.9227815, 6.0939136, 2.8630397], dtype=float32)}
done in step count: 149
reward sum = 0.2236886739786474
running average episode reward sum: 0.5739106040519405
{'scaleFactor': 30, 'timeStep': 150, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([10.502078 ,  4.0318317,  3.8558736], dtype=float32)}
episode index:307
target Thresh 12.414531705963094
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([ 3.2790222, 11.719438 ,  1.1927686], dtype=float32)}
done in step count: 114
reward sum = 0.3179890638191435
running average episode reward sum: 0.5730796899602756
{'scaleFactor': 30, 'timeStep': 115, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([ 8.793697 , 10.099707 ,  1.9368662], dtype=float32)}
episode index:308
target Thresh 12.427426782876264
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([11.795806 ,  4.922532 ,  4.7256203], dtype=float32)}
done in step count: 399
reward sum = 0.0
running average episode reward sum: 0.5712250631319251
{'scaleFactor': 30, 'timeStep': 400, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([13.988142 ,  6.0384574,  4.6662045], dtype=float32)}
episode index:309
target Thresh 12.440257545325016
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([3.5190933, 4.718714 , 5.7899585], dtype=float32)}
done in step count: 19
reward sum = 0.8261686238355866
running average episode reward sum: 0.5720474617148402
{'scaleFactor': 30, 'timeStep': 20, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([7.636301  , 8.697907  , 0.57306373], dtype=float32)}
episode index:310
target Thresh 12.453024314079084
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([11.867285,  7.938954,  6.141045], dtype=float32)}
done in step count: 50
reward sum = 0.6050060671375364
running average episode reward sum: 0.5721534379380643
{'scaleFactor': 30, 'timeStep': 51, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([ 4.5596905, 10.732126 ,  2.9261303], dtype=float32)}
episode index:311
target Thresh 12.465727408308345
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([2.8623424, 8.903886 , 2.9476562], dtype=float32)}
done in step count: 37
reward sum = 0.6894490858690777
running average episode reward sum: 0.5725293855275868
{'scaleFactor': 30, 'timeStep': 38, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([11.543683,  9.101259,  5.341721], dtype=float32)}
episode index:312
target Thresh 12.478367145590823
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([5.1062317, 9.111684 , 1.0508051], dtype=float32)}
done in step count: 30
reward sum = 0.7397003733882802
running average episode reward sum: 0.5730634781405602
{'scaleFactor': 30, 'timeStep': 31, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([11.334656 ,  4.99402  ,  5.8239746], dtype=float32)}
episode index:313
target Thresh 12.490943841920604
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([5.901712 , 8.785903 , 3.5175252], dtype=float32)}
done in step count: 27
reward sum = 0.7623427143471035
running average episode reward sum: 0.5736662782558678
{'scaleFactor': 30, 'timeStep': 28, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([2.8407128, 5.179002 , 4.5769234], dtype=float32)}
episode index:314
target Thresh 12.503457811715753
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([3.1186235, 9.079812 , 3.5173542], dtype=float32)}
done in step count: 294
reward sum = 0.05208914293358933
running average episode reward sum: 0.5720104778262732
{'scaleFactor': 30, 'timeStep': 295, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([11.918888 ,  6.404703 ,  6.1854124], dtype=float32)}
episode index:315
target Thresh 12.515909367826168
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([1.7568965, 9.668897 , 2.6987724], dtype=float32)}
done in step count: 38
reward sum = 0.682554595010387
running average episode reward sum: 0.5723603009819191
{'scaleFactor': 30, 'timeStep': 39, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([10.968882,  9.902749,  6.008786], dtype=float32)}
episode index:316
target Thresh 12.528298821541398
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([1.9048898, 9.066451 , 2.6829236], dtype=float32)}
done in step count: 58
reward sum = 0.5582661385478637
running average episode reward sum: 0.5723158399016854
{'scaleFactor': 30, 'timeStep': 59, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([10.8445215,  9.445337 ,  0.8101493], dtype=float32)}
episode index:317
target Thresh 12.540626482598432
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([ 1.9328676, 10.021113 ,  2.1672502], dtype=float32)}
done in step count: 30
reward sum = 0.7397003733882802
running average episode reward sum: 0.5728422063591905
{'scaleFactor': 30, 'timeStep': 31, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([5.6272135, 8.02914  , 1.5630906], dtype=float32)}
episode index:318
target Thresh 12.552892659189439
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([10.239967 ,  3.2051897,  2.856325 ], dtype=float32)}
done in step count: 116
reward sum = 0.3116610814491425
running average episode reward sum: 0.5720234567513219
{'scaleFactor': 30, 'timeStep': 117, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([3.32939  , 9.228698 , 3.5176616], dtype=float32)}
episode index:319
target Thresh 12.56509765796947
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([2.2068462, 1.8848078, 5.342828 ], dtype=float32)}
done in step count: 46
reward sum = 0.6298236312032323
running average episode reward sum: 0.5722040822964842
{'scaleFactor': 30, 'timeStep': 47, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([10.739957, 10.681508,  5.575707], dtype=float32)}
episode index:320
target Thresh 12.577241784064135
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([6.235545 , 7.867384 , 3.6423762], dtype=float32)}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.5734140259964952
{'scaleFactor': 30, 'timeStep': 5, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([ 3.6548643, 10.656451 ,  2.0503008], dtype=float32)}
episode index:321
target Thresh 12.589325341077215
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([ 6.7928686, 10.125692 ,  5.1885467], dtype=float32)}
done in step count: 181
reward sum = 0.16216989001100654
running average episode reward sum: 0.5721368702946769
{'scaleFactor': 30, 'timeStep': 182, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([4.54268  , 7.6295376, 2.6229515], dtype=float32)}
episode index:322
target Thresh 12.601348631098267
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([1.8944217, 2.1417377, 4.71246  ], dtype=float32)}
done in step count: 46
reward sum = 0.6298236312032323
running average episode reward sum: 0.5723154670776756
{'scaleFactor': 30, 'timeStep': 47, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([ 7.410873 , 11.659206 ,  6.2801123], dtype=float32)}
episode index:323
target Thresh 12.613311954710163
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([11.577995 ,  4.72085  ,  1.9770255], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.5736354810681765
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([11.577995 ,  4.72085  ,  1.9770255], dtype=float32)}
episode index:324
target Thresh 12.625215610996623
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([6.093861, 8.981277, 3.502077], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.574947371895659
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([6.093861, 8.981277, 3.502077], dtype=float32)}
episode index:325
target Thresh 12.63705989754967
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([2.645885  , 9.030622  , 0.57345843], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.5762512143131571
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([2.645885  , 9.030622  , 0.57345843], dtype=float32)}
episode index:326
target Thresh 12.648845110477088
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([5.1511497, 8.982342 , 3.070308 ], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.5775165011195389
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([3.5590706, 8.834134 , 3.8081973], dtype=float32)}
episode index:327
target Thresh 12.660571544409809
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([12.135718 ,  9.032725 ,  2.4412901], dtype=float32)}
done in step count: 87
reward sum = 0.41712087993322033
running average episode reward sum: 0.5770274900793367
{'scaleFactor': 30, 'timeStep': 88, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([ 2.4227538 , 10.184362  ,  0.46992475], dtype=float32)}
episode index:328
target Thresh 12.672239492509297
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([2.0085769, 8.288107 , 3.7715404], dtype=float32)}
done in step count: 126
reward sum = 0.2818606955404635
running average episode reward sum: 0.5761303265701
{'scaleFactor': 30, 'timeStep': 127, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([10.087454 ,  9.471585 ,  5.9721355], dtype=float32)}
episode index:329
target Thresh 12.683849246474859
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([5.0002384, 7.55918  , 4.13956  ], dtype=float32)}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5772662651256452
{'scaleFactor': 30, 'timeStep': 6, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([3.7624552, 4.0352154, 4.2321496], dtype=float32)}
episode index:330
target Thresh 12.69540109655095
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([0.37074375, 7.947245  , 3.6366205 ], dtype=float32)}
done in step count: 89
reward sum = 0.40882017442254925
running average episode reward sum: 0.5767573645495029
{'scaleFactor': 30, 'timeStep': 90, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([2.5241618, 2.236878 , 5.28976  ], dtype=float32)}
episode index:331
target Thresh 12.706895331534424
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([11.014827 ,  8.658012 ,  4.2227974], dtype=float32)}
done in step count: 20
reward sum = 0.8179069375972308
running average episode reward sum: 0.5774837186851888
{'scaleFactor': 30, 'timeStep': 21, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([ 3.4718518, 11.958939 ,  2.93274  ], dtype=float32)}
episode index:332
target Thresh 12.718332238781752
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([1.913611, 4.152249, 5.674994], dtype=float32)}
done in step count: 116
reward sum = 0.3116610814491425
running average episode reward sum: 0.5766854525073027
{'scaleFactor': 30, 'timeStep': 117, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([ 3.6876202 , 10.917871  ,  0.27250314], dtype=float32)}
episode index:333
target Thresh 12.729712104216215
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([10.128155 ,  9.889245 ,  5.5023913], dtype=float32)}
done in step count: 31
reward sum = 0.7323033696543975
running average episode reward sum: 0.5771513744149288
{'scaleFactor': 30, 'timeStep': 32, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([2.862132 , 5.0690317, 4.044365 ], dtype=float32)}
episode index:334
target Thresh 12.741035212335039
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([12.136635 ,  4.1942043,  2.8785515], dtype=float32)}
done in step count: 112
reward sum = 0.3244455298634257
running average episode reward sum: 0.5763970286102975
{'scaleFactor': 30, 'timeStep': 113, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([4.0538373, 8.5881405, 1.7765868], dtype=float32)}
episode index:335
target Thresh 12.752301846216517
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([11.923269 , 10.129052 ,  2.4247584], dtype=float32)}
done in step count: 102
reward sum = 0.3587482976818919
running average episode reward sum: 0.5757492645301534
{'scaleFactor': 30, 'timeStep': 103, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([2.9768229, 7.7642612, 2.036341 ], dtype=float32)}
episode index:336
target Thresh 12.76351228752708
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([1.9159681, 4.9545074, 1.5802771], dtype=float32)}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.5769200352585505
{'scaleFactor': 30, 'timeStep': 4, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([ 3.6028228 , 10.013126  ,  0.88342404], dtype=float32)}
episode index:337
target Thresh 12.774666816528349
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([6.1800303, 9.042293 , 5.2382064], dtype=float32)}
done in step count: 116
reward sum = 0.3116610814491425
running average episode reward sum: 0.5761352454543806
{'scaleFactor': 30, 'timeStep': 117, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([ 1.6056548, 10.169013 ,  4.706322 ], dtype=float32)}
episode index:338
target Thresh 12.78576571208413
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([11.730192 ,  2.8327258,  5.8140807], dtype=float32)}
done in step count: 85
reward sum = 0.4255901233886546
running average episode reward sum: 0.5756911595485819
{'scaleFactor': 30, 'timeStep': 86, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([6.675263 , 8.478422 , 0.8834517], dtype=float32)}
episode index:339
target Thresh 12.796809251667385
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([11.216185 ,  9.846778 ,  2.4403608], dtype=float32)}
done in step count: 154
reward sum = 0.2127257032290187
running average episode reward sum: 0.5746236140888185
{'scaleFactor': 30, 'timeStep': 155, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([ 7.855311 , 10.92674  ,  2.1022382], dtype=float32)}
episode index:340
target Thresh 12.807797711367183
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([4.091278, 9.874312, 2.310025], dtype=float32)}
done in step count: 134
reward sum = 0.26008546137772603
running average episode reward sum: 0.5737012148140058
{'scaleFactor': 30, 'timeStep': 135, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([2.3871655, 6.837289 , 5.2098765], dtype=float32)}
episode index:341
target Thresh 12.818731365895589
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([12.186223 ,  3.1055121,  5.9449015], dtype=float32)}
done in step count: 161
reward sum = 0.19827425658891443
running average episode reward sum: 0.5726034751700728
{'scaleFactor': 30, 'timeStep': 162, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([3.7110314, 9.54018  , 2.2055433], dtype=float32)}
episode index:342
target Thresh 12.829610488594534
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([7.3695245, 7.553513 , 3.946275 ], dtype=float32)}
done in step count: 106
reward sum = 0.3446121833475176
running average episode reward sum: 0.5719387775262753
{'scaleFactor': 30, 'timeStep': 107, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([ 8.114022, 10.117515,  6.279246], dtype=float32)}
episode index:343
target Thresh 12.840435351442654
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([0.7344016, 8.437197 , 2.7183235], dtype=float32)}
done in step count: 24
reward sum = 0.7856781408072188
running average episode reward sum: 0.5725601128846501
{'scaleFactor': 30, 'timeStep': 25, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([3.2068706 , 8.022306  , 0.16442317], dtype=float32)}
episode index:344
target Thresh 12.85120622506208
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([1.033288 , 7.0934367, 1.84302  ], dtype=float32)}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5736570112528107
{'scaleFactor': 30, 'timeStep': 6, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([ 5.36752   , 10.455587  ,  0.62845755], dtype=float32)}
episode index:345
target Thresh 12.86192337872522
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([2.2360575, 3.9993567, 1.9447339], dtype=float32)}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.5746659351926232
{'scaleFactor': 30, 'timeStep': 9, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([ 3.300974, 10.864196,  1.218682], dtype=float32)}
episode index:346
target Thresh 12.872587080361466
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([11.982847 ,  9.416787 ,  1.4094329], dtype=float32)}
done in step count: 214
reward sum = 0.11639428152900338
running average episode reward sum: 0.5733452676028145
{'scaleFactor': 30, 'timeStep': 215, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([10.264168 ,  3.1660225,  4.7203894], dtype=float32)}
episode index:347
target Thresh 12.88319759656392
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([6.730824 , 8.8464365, 6.264554 ], dtype=float32)}
done in step count: 152
reward sum = 0.21704489667280757
running average episode reward sum: 0.572321415962211
{'scaleFactor': 30, 'timeStep': 153, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([1.9866738, 3.4697642, 4.3630714], dtype=float32)}
episode index:348
target Thresh 12.893755192596037
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([1.9713054, 4.027329 , 2.1199226], dtype=float32)}
done in step count: 138
reward sum = 0.2498370564584527
running average episode reward sum: 0.5713973920094783
{'scaleFactor': 30, 'timeStep': 139, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([5.0300016 , 9.246226  , 0.27995944], dtype=float32)}
episode index:349
target Thresh 12.904260132398269
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([3.4618173, 5.4669056, 1.0107173], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.5725933994608798
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([4.5287724, 7.0241227, 0.527051 ], dtype=float32)}
episode index:350
target Thresh 12.91471267859466
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([6.0557156, 8.795243 , 0.6581582], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.5737825920550084
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([5.6426315, 8.814353 , 1.3238661], dtype=float32)}
episode index:351
target Thresh 12.925113092499403
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([2.0094817, 7.129325 , 5.394935 ], dtype=float32)}
done in step count: 50
reward sum = 0.6050060671375364
running average episode reward sum: 0.5738712951092201
{'scaleFactor': 30, 'timeStep': 51, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([ 4.341861, 10.71297 ,  5.970467], dtype=float32)}
episode index:352
target Thresh 12.935461634123394
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([11.843569  ,  8.986789  ,  0.86029977], dtype=float32)}
done in step count: 17
reward sum = 0.8429431933839268
running average episode reward sum: 0.5746335384471087
{'scaleFactor': 30, 'timeStep': 18, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([5.4227967, 7.900517 , 4.029492 ], dtype=float32)}
episode index:353
target Thresh 12.945758562180709
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([1.8635337, 3.2079782, 4.996254 ], dtype=float32)}
done in step count: 134
reward sum = 0.26008546137772603
running average episode reward sum: 0.5737449845570822
{'scaleFactor': 30, 'timeStep': 135, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([4.249977 , 7.2843256, 1.1506368], dtype=float32)}
episode index:354
target Thresh 12.956004134095087
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([7.123881  , 8.829431  , 0.16529626], dtype=float32)}
done in step count: 136
reward sum = 0.2549097606963093
running average episode reward sum: 0.5728468571659251
{'scaleFactor': 30, 'timeStep': 137, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([3.0380318, 7.4891424, 2.484117 ], dtype=float32)}
episode index:355
target Thresh 12.966198606006358
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([6.5525656, 8.27403  , 3.9081511], dtype=float32)}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.573778135867731
{'scaleFactor': 30, 'timeStep': 11, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([1.7674603, 8.1549835, 3.6791825], dtype=float32)}
episode index:356
target Thresh 12.976342232776855
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([10.249987 ,  9.128246 ,  3.4537282], dtype=float32)}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5748347518734237
{'scaleFactor': 30, 'timeStep': 6, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([10.267506 ,  6.8065066,  5.9332695], dtype=float32)}
episode index:357
target Thresh 12.986435267997768
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([4.0469165, 8.404088 , 4.831709 ], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.5759944313374644
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([3.8948927, 6.426559 , 4.92142  ], dtype=float32)}
episode index:358
target Thresh 12.996477963995511
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([ 7.207485 , 10.767861 ,  1.2742105], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.5771755053448809
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([ 7.207485 , 10.767861 ,  1.2742105], dtype=float32)}
episode index:359
target Thresh 13.006470571838003
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([10.133442 ,  5.766386 ,  3.4509878], dtype=float32)}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.5781354197590005
{'scaleFactor': 30, 'timeStep': 9, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([4.171519 , 8.209426 , 2.8090296], dtype=float32)}
episode index:360
target Thresh 13.01641334134096
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([2.030919 , 6.887443 , 6.1903586], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.5792763188732415
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([3.8687692, 7.2748213, 0.5278513], dtype=float32)}
episode index:361
target Thresh 13.02630652107414
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([11.984166 ,  8.759181 ,  3.9546556], dtype=float32)}
done in step count: 21
reward sum = 0.8097278682212584
running average episode reward sum: 0.5799129253631531
{'scaleFactor': 30, 'timeStep': 22, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([6.2822857, 8.61257  , 3.628674 ], dtype=float32)}
episode index:362
target Thresh 13.036150358367552
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([11.777972 ,  2.0201259,  3.6990025], dtype=float32)}
done in step count: 27
reward sum = 0.7623427143471035
running average episode reward sum: 0.5804154867653127
{'scaleFactor': 30, 'timeStep': 28, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([10.057346 ,  4.4269238,  1.4656879], dtype=float32)}
episode index:363
target Thresh 13.045945099317636
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([2.04841  , 1.8139048, 3.9701133], dtype=float32)}
done in step count: 100
reward sum = 0.3660323412732292
running average episode reward sum: 0.5798265220798949
{'scaleFactor': 30, 'timeStep': 101, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([9.503945  , 9.282254  , 0.42282295], dtype=float32)}
episode index:364
target Thresh 13.055690988793431
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([11.834023 ,  6.0713663,  0.7297165], dtype=float32)}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.5807407432453847
{'scaleFactor': 30, 'timeStep': 10, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([12.235275 ,  7.3776197,  1.3256791], dtype=float32)}
episode index:365
target Thresh 13.065388270442678
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([3.1123688, 8.31127  , 4.8492594], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.5818862603403427
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([3.1123688, 8.31127  , 4.8492594], dtype=float32)}
episode index:366
target Thresh 13.075037186697926
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([4.981815 , 8.860518 , 1.4064589], dtype=float32)}
done in step count: 331
reward sum = 0.0359128119792669
running average episode reward sum: 0.5803985942685141
{'scaleFactor': 30, 'timeStep': 332, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([11.388998 ,  3.993019 ,  4.8159857], dtype=float32)}
episode index:367
target Thresh 13.084637978782585
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([1.8976564, 6.163252 , 3.8691335], dtype=float32)}
done in step count: 188
reward sum = 0.1511529349531471
running average episode reward sum: 0.5792321658464615
{'scaleFactor': 30, 'timeStep': 189, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([10.520425 ,  7.6056685,  1.4007112], dtype=float32)}
episode index:368
target Thresh 13.094190886716952
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([2.366571, 4.305188, 4.513342], dtype=float32)}
done in step count: 41
reward sum = 0.6622820409839835
running average episode reward sum: 0.5794572332587583
{'scaleFactor': 30, 'timeStep': 42, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([3.0610752, 7.5329723, 1.4977663], dtype=float32)}
episode index:369
target Thresh 13.103696149324225
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([3.4877596, 8.960646 , 5.7064443], dtype=float32)}
done in step count: 399
reward sum = 0.0
running average episode reward sum: 0.5778911326283293
{'scaleFactor': 30, 'timeStep': 400, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([3.4173884, 8.251541 , 3.2395546], dtype=float32)}
episode index:370
target Thresh 13.113154004236469
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([1.8374912, 3.9008515, 1.8969333], dtype=float32)}
done in step count: 145
reward sum = 0.232864462948006
running average episode reward sum: 0.5769611416049322
{'scaleFactor': 30, 'timeStep': 146, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([10.946335 ,  3.9420617,  4.148343 ], dtype=float32)}
episode index:371
target Thresh 13.122564687900542
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([ 9.05615  , 10.032901 ,  1.7547846], dtype=float32)}
done in step count: 173
reward sum = 0.1757473014911758
running average episode reward sum: 0.5758826097766694
{'scaleFactor': 30, 'timeStep': 174, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([13.601301 ,  6.6541386,  5.294336 ], dtype=float32)}
episode index:372
target Thresh 13.131928435584033
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([10.165769,  2.574393,  3.10694 ], dtype=float32)}
done in step count: 399
reward sum = 0.0
running average episode reward sum: 0.5743386885708338
{'scaleFactor': 30, 'timeStep': 400, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([10.097553 ,  1.1700985,  4.928912 ], dtype=float32)}
episode index:373
target Thresh 13.141245481381116
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([6.1380935, 8.302884 , 5.5688934], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.5754768204195749
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([6.1380935, 8.302884 , 5.5688934], dtype=float32)}
episode index:374
target Thresh 13.150516058218422
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([11.752456,  8.240363,  5.034348], dtype=float32)}
done in step count: 33
reward sum = 0.7177305325982749
running average episode reward sum: 0.5758561636520515
{'scaleFactor': 30, 'timeStep': 34, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([7.2195263, 8.614817 , 1.9878927], dtype=float32)}
episode index:375
target Thresh 13.159740397860858
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([11.18645   ,  9.972944  ,  0.22728471], dtype=float32)}
done in step count: 18
reward sum = 0.8345137614500875
running average episode reward sum: 0.5765440827951314
{'scaleFactor': 30, 'timeStep': 19, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([9.639389 , 8.133005 , 1.3315091], dtype=float32)}
episode index:376
target Thresh 13.168918730917394
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([9.817441, 9.85077 , 4.164452], dtype=float32)}
done in step count: 42
reward sum = 0.6556592205741436
running average episode reward sum: 0.5767539372719988
{'scaleFactor': 30, 'timeStep': 43, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([2.4485984, 9.32656  , 2.0662885], dtype=float32)}
episode index:377
target Thresh 13.178051286846834
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([7.94544  , 9.010386 , 2.7793977], dtype=float32)}
done in step count: 37
reward sum = 0.6894490858690777
running average episode reward sum: 0.5770520725857476
{'scaleFactor': 30, 'timeStep': 38, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([3.5204344, 6.970119 , 2.306322 ], dtype=float32)}
episode index:378
target Thresh 13.18713829396355
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([5.839334 , 9.066202 , 5.7136264], dtype=float32)}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.5779157401383151
{'scaleFactor': 30, 'timeStep': 11, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([3.5695572, 3.628031 , 4.0909176], dtype=float32)}
episode index:379
target Thresh 13.196179979443196
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([4.1616416, 5.907886 , 6.0966926], dtype=float32)}
done in step count: 165
reward sum = 0.1904614597650274
running average episode reward sum: 0.576896123611017
{'scaleFactor': 30, 'timeStep': 166, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([ 5.926536  , 11.881411  ,  0.92424667], dtype=float32)}
episode index:380
target Thresh 13.20517656932838
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([10.087817 ,  9.940788 ,  1.2653188], dtype=float32)}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5778530370645341
{'scaleFactor': 30, 'timeStep': 7, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([ 8.918247 , 11.1465435,  2.2457469], dtype=float32)}
episode index:381
target Thresh 13.214128288534315
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([ 2.7876897, 10.104567 ,  5.1254506], dtype=float32)}
done in step count: 70
reward sum = 0.49483865960020695
running average episode reward sum: 0.5776357219402819
{'scaleFactor': 30, 'timeStep': 71, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([ 5.6360216, 10.257967 ,  4.294219 ], dtype=float32)}
episode index:382
target Thresh 13.22303536085445
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([ 5.2146344, 10.067052 ,  1.0158752], dtype=float32)}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.5785367897535656
{'scaleFactor': 30, 'timeStep': 9, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([ 9.639154  , 10.862271  ,  0.28215432], dtype=float32)}
episode index:383
target Thresh 13.231898008966056
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([12.078486,  5.970659,  5.855485], dtype=float32)}
done in step count: 59
reward sum = 0.5526834771623851
running average episode reward sum: 0.5784694634186928
{'scaleFactor': 30, 'timeStep': 60, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([13.937958  ,  3.0537236 ,  0.94946605], dtype=float32)}
episode index:384
target Thresh 13.240716454435798
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([1.2615044, 4.67662  , 2.2021332], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.5795643479292936
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([1.2615044, 4.67662  , 2.2021332], dtype=float32)}
episode index:385
target Thresh 13.249490917725272
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([ 9.076332, 10.198797,  5.025776], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.5806276527274042
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([10.224825 ,  8.578199 ,  4.9263024], dtype=float32)}
episode index:386
target Thresh 13.258221618196515
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([11.892164 ,  1.631746 ,  3.5629725], dtype=float32)}
done in step count: 20
reward sum = 0.8179069375972308
running average episode reward sum: 0.5812407774945098
{'scaleFactor': 30, 'timeStep': 21, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([8.892339  , 9.218071  , 0.65136737], dtype=float32)}
episode index:387
target Thresh 13.266908774117496
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([3.347672, 8.113178, 4.506265], dtype=float32)}
done in step count: 16
reward sum = 0.8514577710948755
running average episode reward sum: 0.5819372130450262
{'scaleFactor': 30, 'timeStep': 17, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([8.426051  , 8.303003  , 0.33034772], dtype=float32)}
episode index:388
target Thresh 13.275552602667565
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([9.212784 , 9.02665  , 3.4359648], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.5830119245796148
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([9.212784 , 9.02665  , 3.4359648], dtype=float32)}
episode index:389
target Thresh 13.284153319942886
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([10.403702 ,  3.1762943,  3.9655323], dtype=float32)}
done in step count: 63
reward sum = 0.5309055429551132
running average episode reward sum: 0.5828783184728853
{'scaleFactor': 30, 'timeStep': 64, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([ 7.367511, 10.460756,  2.299745], dtype=float32)}
episode index:390
target Thresh 13.292711140961837
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([3.0216773, 9.016369 , 5.4678645], dtype=float32)}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.5838691642056912
{'scaleFactor': 30, 'timeStep': 4, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([8.640248  , 9.019859  , 0.58954114], dtype=float32)}
episode index:391
target Thresh 13.301226279670392
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([11.882676,  9.059135,  4.954454], dtype=float32)}
done in step count: 15
reward sum = 0.8600583546412884
running average episode reward sum: 0.5845737284670066
{'scaleFactor': 30, 'timeStep': 16, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([7.2737274, 7.8841214, 2.291915 ], dtype=float32)}
episode index:392
target Thresh 13.30969894894746
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([10.487616 ,  7.6971555,  4.24087  ], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.5856307927711618
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([10.487616 ,  7.6971555,  4.24087  ], dtype=float32)}
episode index:393
target Thresh 13.318129360610216
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([2.2263331 , 8.135597  , 0.70431584], dtype=float32)}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5865339637270751
{'scaleFactor': 30, 'timeStep': 7, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([9.62516   , 8.622898  , 0.16520311], dtype=float32)}
episode index:394
target Thresh 13.326517725419388
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([1.9495659, 6.618245 , 5.4071245], dtype=float32)}
done in step count: 116
reward sum = 0.3116610814491425
running average episode reward sum: 0.5858380830124474
{'scaleFactor': 30, 'timeStep': 117, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([ 5.5972934, 10.071388 ,  0.2598151], dtype=float32)}
episode index:395
target Thresh 13.334864253084536
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([1.9228354, 8.055305 , 1.9819868], dtype=float32)}
done in step count: 57
reward sum = 0.5639051904523875
running average episode reward sum: 0.585782696920124
{'scaleFactor': 30, 'timeStep': 58, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([2.595872 , 2.665566 , 4.4575515], dtype=float32)}
episode index:396
target Thresh 13.343169152269287
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([2.2642133, 2.1164372, 5.990673 ], dtype=float32)}
done in step count: 70
reward sum = 0.49483865960020695
running average episode reward sum: 0.5855536187404768
{'scaleFactor': 30, 'timeStep': 71, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([0.07176627, 4.770381  , 2.2439625 ], dtype=float32)}
episode index:397
target Thresh 13.351432630596548
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([7.99125 , 9.257116, 6.044232], dtype=float32)}
done in step count: 341
reward sum = 0.03247890341721044
running average episode reward sum: 0.584163983777353
{'scaleFactor': 30, 'timeStep': 342, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([0.21176343, 8.371528  , 4.6863737 ], dtype=float32)}
episode index:398
target Thresh 13.359654894653714
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([1.7353225, 5.1544433, 4.534131 ], dtype=float32)}
done in step count: 81
reward sum = 0.4430479816261725
running average episode reward sum: 0.5838103095864979
{'scaleFactor': 30, 'timeStep': 82, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([8.510014 , 9.477917 , 5.8239894], dtype=float32)}
episode index:399
target Thresh 13.36783614999781
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([11.883618 ,  6.7831326,  1.7588732], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.5848257838125317
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([10.85015  ,  8.488624 ,  2.3808658], dtype=float32)}
episode index:400
target Thresh 13.375976601160648
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([ 5.89634  , 10.242053 ,  1.3576567], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.585861130985069
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([ 5.89634  , 10.242053 ,  1.3576567], dtype=float32)}
episode index:401
target Thresh 13.384076451653929
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([ 8.097744 , 10.025946 ,  2.8950984], dtype=float32)}
done in step count: 112
reward sum = 0.3244455298634257
running average episode reward sum: 0.5852108434200898
{'scaleFactor': 30, 'timeStep': 113, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([13.149791 ,  6.423348 ,  3.8195503], dtype=float32)}
episode index:402
target Thresh 13.39213590397434
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([ 9.597839 , 10.162318 ,  3.1741734], dtype=float32)}
done in step count: 60
reward sum = 0.5471566423907612
running average episode reward sum: 0.5851164161222503
{'scaleFactor': 30, 'timeStep': 61, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([2.6088629, 7.6020617, 5.978179 ], dtype=float32)}
episode index:403
target Thresh 13.400155159608607
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([9.257777, 8.92872 , 5.043187], dtype=float32)}
done in step count: 26
reward sum = 0.7700431458051551
running average episode reward sum: 0.5855741555521585
{'scaleFactor': 30, 'timeStep': 27, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([3.6044006, 6.89909  , 3.379352 ], dtype=float32)}
episode index:404
target Thresh 13.40813441903854
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([10.69219  ,  6.7519894,  4.2014875], dtype=float32)}
done in step count: 34
reward sum = 0.7105532272722921
running average episode reward sum: 0.5858827458527021
{'scaleFactor': 30, 'timeStep': 35, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([2.1227126, 6.4088774, 3.0154786], dtype=float32)}
episode index:405
target Thresh 13.416073881746037
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([2.2880094, 9.046544 , 3.9953399], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.5869027390895181
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([2.2880094, 9.046544 , 3.9953399], dtype=float32)}
episode index:406
target Thresh 13.423973746218081
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([12.025418 ,  1.8719915,  5.1885476], dtype=float32)}
done in step count: 35
reward sum = 0.7034476949995692
running average episode reward sum: 0.5871890903325403
{'scaleFactor': 30, 'timeStep': 36, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([10.291127 ,  7.953518 ,  2.3134027], dtype=float32)}
episode index:407
target Thresh 13.431834209951699
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([2.1452994, 5.028767 , 5.5605335], dtype=float32)}
done in step count: 17
reward sum = 0.8429431933839268
running average episode reward sum: 0.5878159386243329
{'scaleFactor': 30, 'timeStep': 18, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([0.30272126, 7.606884  , 1.8584269 ], dtype=float32)}
episode index:408
target Thresh 13.439655469458888
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([ 4.908155, 10.15614 ,  5.640818], dtype=float32)}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.5886576242216011
{'scaleFactor': 30, 'timeStep': 8, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([9.448921  , 8.948946  , 0.06706636], dtype=float32)}
episode index:409
target Thresh 13.447437720271546
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([ 7.9729695, 11.968534 ,  1.2544471], dtype=float32)}
done in step count: 30
reward sum = 0.7397003733882802
running average episode reward sum: 0.5890260211707881
{'scaleFactor': 30, 'timeStep': 31, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([1.6510506, 2.5326803, 4.1286902], dtype=float32)}
episode index:410
target Thresh 13.455181156946349
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([12.096891, 10.62572 ,  1.221644], dtype=float32)}
done in step count: 327
reward sum = 0.03738596830031274
running average episode reward sum: 0.5876838312611274
{'scaleFactor': 30, 'timeStep': 328, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([1.6634473, 6.6648946, 4.203094 ], dtype=float32)}
episode index:411
target Thresh 13.462885973069616
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([9.978465 , 9.066806 , 4.9110494], dtype=float32)}
done in step count: 146
reward sum = 0.23053581831852593
running average episode reward sum: 0.5868169671520435
{'scaleFactor': 30, 'timeStep': 147, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([5.5825763, 7.19659  , 2.8600976], dtype=float32)}
episode index:412
target Thresh 13.47055236126215
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([11.957034 ,  1.9518375,  4.5300455], dtype=float32)}
done in step count: 122
reward sum = 0.2934227215252159
running average episode reward sum: 0.5861065694628744
{'scaleFactor': 30, 'timeStep': 123, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([3.7917538, 3.2188668, 4.6999645], dtype=float32)}
episode index:413
target Thresh 13.478180513184059
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([1.9563572, 7.979059 , 3.8102396], dtype=float32)}
done in step count: 40
reward sum = 0.6689717585696803
running average episode reward sum: 0.586306726924485
{'scaleFactor': 30, 'timeStep': 41, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([ 6.681253 , 11.007259 ,  2.2301319], dtype=float32)}
episode index:414
target Thresh 13.485770619539535
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([12.016222  ,  5.8955994 ,  0.20465773], dtype=float32)}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.587073173546375
{'scaleFactor': 30, 'timeStep': 11, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([12.905315,  8.620301,  6.214385], dtype=float32)}
episode index:415
target Thresh 13.493322870081633
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([4.986501 , 9.9465475, 2.488061 ], dtype=float32)}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.5879024816578188
{'scaleFactor': 30, 'timeStep': 8, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([1.3350185, 9.232527 , 4.8747716], dtype=float32)}
episode index:416
target Thresh 13.500837453617011
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([8.901987 , 9.104231 , 1.1887789], dtype=float32)}
done in step count: 20
reward sum = 0.8179069375972308
running average episode reward sum: 0.5884540510965224
{'scaleFactor': 30, 'timeStep': 21, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([3.2911055, 8.9686775, 2.6245017], dtype=float32)}
episode index:417
target Thresh 13.508314558010646
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([10.052273 ,  6.4715676,  3.128884 ], dtype=float32)}
done in step count: 51
reward sum = 0.598956006466161
running average episode reward sum: 0.588479175391665
{'scaleFactor': 30, 'timeStep': 52, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([0.17988661, 2.9330173 , 4.8388376 ], dtype=float32)}
episode index:418
target Thresh 13.51575437019054
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([9.99708  , 8.264175 , 3.3805592], dtype=float32)}
done in step count: 43
reward sum = 0.6491026283684022
running average episode reward sum: 0.5886238614369557
{'scaleFactor': 30, 'timeStep': 44, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([3.4200525, 7.609035 , 4.043074 ], dtype=float32)}
episode index:419
target Thresh 13.523157076152387
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([1.8887327, 5.9444313, 1.0768211], dtype=float32)}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.5893756667073649
{'scaleFactor': 30, 'timeStep': 11, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([7.193106 , 9.723541 , 5.4050574], dtype=float32)}
episode index:420
target Thresh 13.530522860964217
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([2.1340885, 8.195172 , 5.6574697], dtype=float32)}
done in step count: 83
reward sum = 0.43423132679181164
running average episode reward sum: 0.5890071528358315
{'scaleFactor': 30, 'timeStep': 84, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([13.9286175,  6.9564657,  2.2153373], dtype=float32)}
episode index:421
target Thresh 13.537851908771035
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([ 2.2189858, 10.708202 ,  1.2199979], dtype=float32)}
done in step count: 21
reward sum = 0.8097278682212584
running average episode reward sum: 0.5895301877064131
{'scaleFactor': 30, 'timeStep': 22, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([0.08047295, 8.469604  , 4.7898297 ], dtype=float32)}
episode index:422
target Thresh 13.54514440279942
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([12.210632,  9.98402 ,  6.06562 ], dtype=float32)}
done in step count: 170
reward sum = 0.18112695312597024
running average episode reward sum: 0.588564695426081
{'scaleFactor': 30, 'timeStep': 171, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([9.330629 , 9.865562 , 3.6682863], dtype=float32)}
episode index:423
target Thresh 13.552400525362101
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([2.0453777, 4.978441 , 4.392794 ], dtype=float32)}
done in step count: 101
reward sum = 0.3623720178604969
running average episode reward sum: 0.5880312221299357
{'scaleFactor': 30, 'timeStep': 102, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([6.2926702 , 8.340077  , 0.34786534], dtype=float32)}
episode index:424
target Thresh 13.55962045786252
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([10.262561 ,  9.236486 ,  3.2318258], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.5890005604308065
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([10.262561 ,  9.236486 ,  3.2318258], dtype=float32)}
episode index:425
target Thresh 13.566804380799365
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([ 5.219655 , 10.1008835,  5.9165835], dtype=float32)}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.5897408926246516
{'scaleFactor': 30, 'timeStep': 11, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([11.085912,  4.998355,  5.726928], dtype=float32)}
episode index:426
target Thresh 13.573952473771085
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([11.247185,  9.995204,  6.232605], dtype=float32)}
done in step count: 21
reward sum = 0.8097278682212584
running average episode reward sum: 0.5902560846049715
{'scaleFactor': 30, 'timeStep': 22, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([ 2.8348784, 11.258398 ,  4.0588923], dtype=float32)}
episode index:427
target Thresh 13.581064915480374
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([4.0085983 , 7.8002753 , 0.08136528], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.5912134302016888
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([4.0085983 , 7.8002753 , 0.08136528], dtype=float32)}
episode index:428
target Thresh 13.58814188373865
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([10.11063   ,  8.829021  ,  0.95780003], dtype=float32)}
done in step count: 51
reward sum = 0.598956006466161
running average episode reward sum: 0.5912314781650092
{'scaleFactor': 30, 'timeStep': 52, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([ 1.6817508, 10.309959 ,  3.572095 ], dtype=float32)}
episode index:429
target Thresh 13.595183555470483
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([10.843242  ,  8.907132  ,  0.50392437], dtype=float32)}
done in step count: 380
reward sum = 0.021946938520632394
running average episode reward sum: 0.5899075606309525
{'scaleFactor': 30, 'timeStep': 381, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([1.1638432, 6.9740486, 3.995919 ], dtype=float32)}
episode index:430
target Thresh 13.602190106718037
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([2.1456687, 5.9793   , 1.2013121], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.590859051209535
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([2.1456687, 5.9793   , 1.2013121], dtype=float32)}
episode index:431
target Thresh 13.609161712645454
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([4.832962, 8.970196, 2.635688], dtype=float32)}
done in step count: 55
reward sum = 0.5753547499769285
running average episode reward sum: 0.5908231616233484
{'scaleFactor': 30, 'timeStep': 56, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([13.738163,  8.007938,  4.888371], dtype=float32)}
episode index:432
target Thresh 13.61609854754325
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([2.0657659, 9.175827 , 2.3118997], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.5917681427743338
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([2.0657659, 9.175827 , 2.3118997], dtype=float32)}
episode index:433
target Thresh 13.623000784832653
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([11.563244 ,  9.14803  ,  1.9652706], dtype=float32)}
done in step count: 16
reward sum = 0.8514577710948755
running average episode reward sum: 0.592366505973229
{'scaleFactor': 30, 'timeStep': 17, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([6.4477677, 7.028015 , 5.820748 ], dtype=float32)}
episode index:434
target Thresh 13.629868597069962
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([2.1467092, 8.0457115, 3.5709083], dtype=float32)}
done in step count: 72
reward sum = 0.48499137027416284
running average episode reward sum: 0.5921196665808174
{'scaleFactor': 30, 'timeStep': 73, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([10.065658 ,  5.681507 ,  5.7931414], dtype=float32)}
episode index:435
target Thresh 13.636702155950834
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([2.124887 , 5.828149 , 3.3103647], dtype=float32)}
done in step count: 58
reward sum = 0.5582661385478637
running average episode reward sum: 0.5920420208743198
{'scaleFactor': 30, 'timeStep': 59, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([6.1076403, 8.331867 , 0.6056311], dtype=float32)}
episode index:436
target Thresh 13.643501632314601
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([1.9796901, 4.9111214, 6.249829 ], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.5929526798654541
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([3.5906758, 3.6369128, 5.7874503], dtype=float32)}
episode index:437
target Thresh 13.650267196148526
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([12.005767 ,  6.8286552,  0.171229 ], dtype=float32)}
done in step count: 16
reward sum = 0.8514577710948755
running average episode reward sum: 0.5935428741376674
{'scaleFactor': 30, 'timeStep': 17, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([13.111577 ,  2.8048286,  3.5735023], dtype=float32)}
episode index:438
target Thresh 13.656999016592053
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([ 5.9709454, 10.105154 ,  2.0429072], dtype=float32)}
done in step count: 38
reward sum = 0.682554595010387
running average episode reward sum: 0.5937456343218878
{'scaleFactor': 30, 'timeStep': 39, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([9.77647   , 8.941721  , 0.06853645], dtype=float32)}
episode index:439
target Thresh 13.66369726194105
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([12.15127  ,  6.1710944,  3.978984 ], dtype=float32)}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5945575534482016
{'scaleFactor': 30, 'timeStep': 6, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([8.618197 , 8.541267 , 2.4150372], dtype=float32)}
episode index:440
target Thresh 13.670362099651992
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([9.31517  , 8.845636 , 3.2778013], dtype=float32)}
done in step count: 57
reward sum = 0.5639051904523875
running average episode reward sum: 0.5944880469561477
{'scaleFactor': 30, 'timeStep': 58, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([10.035142,  5.743143,  5.954159], dtype=float32)}
episode index:441
target Thresh 13.676993696346177
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([11.914367,  9.984664,  3.962203], dtype=float32)}
done in step count: 72
reward sum = 0.48499137027416284
running average episode reward sum: 0.5942403169184055
{'scaleFactor': 30, 'timeStep': 73, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([12.831309,  4.739715,  6.140915], dtype=float32)}
episode index:442
target Thresh 13.683592217813864
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([7.9101353, 8.744774 , 5.873535 ], dtype=float32)}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.59500290163847
{'scaleFactor': 30, 'timeStep': 8, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([10.866435  ,  8.93376   ,  0.43931252], dtype=float32)}
episode index:443
target Thresh 13.69015782901843
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([1.9356167, 7.592858 , 3.8361363], dtype=float32)}
done in step count: 122
reward sum = 0.2934227215252159
running average episode reward sum: 0.5943236669985752
{'scaleFactor': 30, 'timeStep': 123, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([1.1632606e+01, 8.1576719e+00, 3.9932090e-03], dtype=float32)}
episode index:444
target Thresh 13.696690694100504
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([12.167189 ,  4.7929535,  3.5207593], dtype=float32)}
done in step count: 23
reward sum = 0.7936142836436554
running average episode reward sum: 0.5947715110809237
{'scaleFactor': 30, 'timeStep': 24, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([4.0960646, 8.6523075, 1.785169 ], dtype=float32)}
episode index:445
target Thresh 13.703190976382048
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([12.13245  ,  5.354776 ,  1.5782089], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.5956576736121324
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([11.847595 ,  7.1230826,  1.5539817], dtype=float32)}
episode index:446
target Thresh 13.70965883837046
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([2.763794 , 8.911466 , 2.7023337], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.5965398712103156
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([3.0616908, 9.060672 , 3.3101242], dtype=float32)}
episode index:447
target Thresh 13.716094441762625
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([7.878179, 8.879702, 5.274158], dtype=float32)}
done in step count: 156
reward sum = 0.20849246173476124
running average episode reward sum: 0.595673693957022
{'scaleFactor': 30, 'timeStep': 157, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([ 3.0616302, 10.767589 ,  3.2996593], dtype=float32)}
episode index:448
target Thresh 13.722497947448966
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([7.152722, 9.990233, 1.439173], dtype=float32)}
done in step count: 19
reward sum = 0.8261686238355866
running average episode reward sum: 0.5961870456939453
{'scaleFactor': 30, 'timeStep': 20, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([ 9.850375  , 10.438029  ,  0.08709257], dtype=float32)}
episode index:449
target Thresh 13.728869515517456
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([ 3.352683, 10.28792 ,  2.243002], dtype=float32)}
done in step count: 88
reward sum = 0.41294967113388814
running average episode reward sum: 0.5957798515282563
{'scaleFactor': 30, 'timeStep': 89, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([12.148844 ,  3.3086271,  5.14711  ], dtype=float32)}
episode index:450
target Thresh 13.735209305257628
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([11.213074 , 10.034468 ,  0.5937243], dtype=float32)}
done in step count: 211
reward sum = 0.11995712819347787
running average episode reward sum: 0.5947248122303965
{'scaleFactor': 30, 'timeStep': 212, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([ 3.27404  , 11.815864 ,  2.7805176], dtype=float32)}
episode index:451
target Thresh 13.741517475164557
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([ 9.010607, 10.835649,  3.258167], dtype=float32)}
done in step count: 131
reward sum = 0.2680467169168741
running average episode reward sum: 0.5940020730814729
{'scaleFactor': 30, 'timeStep': 132, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([10.050138 ,  6.581357 ,  6.0115047], dtype=float32)}
episode index:452
target Thresh 13.747794182942819
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([6.1470356, 8.691767 , 6.0768538], dtype=float32)}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.5948543863859288
{'scaleFactor': 30, 'timeStep': 3, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([10.131204,  9.555303,  5.753087], dtype=float32)}
episode index:453
target Thresh 13.754039585510437
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([2.8661513 , 8.979393  , 0.17204216], dtype=float32)}
done in step count: 38
reward sum = 0.682554595010387
running average episode reward sum: 0.5950475586516214
{'scaleFactor': 30, 'timeStep': 39, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([0.04168662, 4.1172366 , 2.6169636 ], dtype=float32)}
episode index:454
target Thresh 13.760253839002797
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([10.069491,  5.662372,  3.477084], dtype=float32)}
done in step count: 20
reward sum = 0.8179069375972308
running average episode reward sum: 0.595537359484469
{'scaleFactor': 30, 'timeStep': 21, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([ 8.475513, 10.819683,  2.069258], dtype=float32)}
episode index:455
target Thresh 13.766437098776564
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([8.935429, 7.237078, 5.417171], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.5964243389592837
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([8.935429, 7.237078, 5.417171], dtype=float32)}
episode index:456
target Thresh 13.77258951941355
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([12.209978 ,  3.1467993,  0.4447462], dtype=float32)}
done in step count: 69
reward sum = 0.4998370298991989
running average episode reward sum: 0.5962129881735942
{'scaleFactor': 30, 'timeStep': 70, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([12.920752 , 11.883491 ,  1.7158624], dtype=float32)}
episode index:457
target Thresh 13.778711254724595
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([9.888232 , 9.994297 , 5.0698028], dtype=float32)}
done in step count: 85
reward sum = 0.4255901233886546
running average episode reward sum: 0.5958404491675136
{'scaleFactor': 30, 'timeStep': 86, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([5.325804 , 9.356646 , 4.7984347], dtype=float32)}
episode index:458
target Thresh 13.7848024577534
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([2.1422832, 8.057683 , 5.579842 ], dtype=float32)}
done in step count: 320
reward sum = 0.040110887486875496
running average episode reward sum: 0.594629709381717
{'scaleFactor': 30, 'timeStep': 321, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([11.467483,  5.220129,  3.956733], dtype=float32)}
episode index:459
target Thresh 13.790863280780354
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([6.2073975, 8.860891 , 1.9946678], dtype=float32)}
done in step count: 20
reward sum = 0.8179069375972308
running average episode reward sum: 0.5951150946604463
{'scaleFactor': 30, 'timeStep': 21, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([11.542969 , 11.17282  ,  6.2134366], dtype=float32)}
episode index:460
target Thresh 13.796893875326356
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([11.949345 ,  3.7641134,  5.47995  ], dtype=float32)}
done in step count: 243
reward sum = 0.08696655909824688
running average episode reward sum: 0.5940128201798341
{'scaleFactor': 30, 'timeStep': 244, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([3.3860443, 8.292513 , 2.4669182], dtype=float32)}
episode index:461
target Thresh 13.802894392156576
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([ 5.1727943, 10.158046 ,  2.7345722], dtype=float32)}
done in step count: 65
reward sum = 0.5203405226503064
running average episode reward sum: 0.5938533563323677
{'scaleFactor': 30, 'timeStep': 66, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([11.197318  ,  8.828603  ,  0.92956746], dtype=float32)}
episode index:462
target Thresh 13.808864981284252
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([11.942057 ,  2.9883554,  6.2145085], dtype=float32)}
done in step count: 37
reward sum = 0.6894490858690777
running average episode reward sum: 0.5940598265905462
{'scaleFactor': 30, 'timeStep': 38, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([13.504877 ,  5.652451 ,  0.9004251], dtype=float32)}
episode index:463
target Thresh 13.814805791974422
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([11.880539 ,  3.894815 ,  5.7823625], dtype=float32)}
done in step count: 149
reward sum = 0.2236886739786474
running average episode reward sum: 0.5932616128995724
{'scaleFactor': 30, 'timeStep': 150, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([0.47380126, 3.5471356 , 4.1254563 ], dtype=float32)}
episode index:464
target Thresh 13.820716972747661
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([2.8495078, 7.008601 , 4.3019466], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.5941363191083905
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([2.8495078, 7.008601 , 4.3019466], dtype=float32)}
episode index:465
target Thresh 13.826598671383799
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([7.8881574, 9.750159 , 0.9552181], dtype=float32)}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.594943535161806
{'scaleFactor': 30, 'timeStep': 4, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([9.636024, 9.948268, 6.185062], dtype=float32)}
episode index:466
target Thresh 13.832451034925606
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([12.094977 ,  8.992642 ,  2.8616278], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.59581089375889
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([12.094977 ,  8.992642 ,  2.8616278], dtype=float32)}
episode index:467
target Thresh 13.838274209682476
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([1.1108754, 4.719778 , 2.0109746], dtype=float32)}
done in step count: 96
reward sum = 0.38104711810454966
running average episode reward sum: 0.5953519968023636
{'scaleFactor': 30, 'timeStep': 97, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([2.655151 , 8.956109 , 1.6522627], dtype=float32)}
episode index:468
target Thresh 13.844068341234083
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([3.9339054, 4.0777087, 6.19726  ], dtype=float32)}
done in step count: 70
reward sum = 0.49483865960020695
running average episode reward sum: 0.5951376826505466
{'scaleFactor': 30, 'timeStep': 71, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([11.783815 ,  6.9685183,  4.8102098], dtype=float32)}
episode index:469
target Thresh 13.849833574434017
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([5.1126413, 9.416773 , 2.5105462], dtype=float32)}
done in step count: 74
reward sum = 0.47534004200570695
running average episode reward sum: 0.5948827940534299
{'scaleFactor': 30, 'timeStep': 75, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([11.306402 ,  7.6986966,  0.1019213], dtype=float32)}
episode index:470
target Thresh 13.855570053413405
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([1.799585, 5.945921, 1.724205], dtype=float32)}
done in step count: 29
reward sum = 0.7471720943315961
running average episode reward sum: 0.5952061259011542
{'scaleFactor': 30, 'timeStep': 30, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([ 7.4340363, 10.437769 ,  5.4589586], dtype=float32)}
episode index:471
target Thresh 13.861277921584522
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([3.2844567, 9.480798 , 0.6713624], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.5960637400411941
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([3.2844567, 9.480798 , 0.6713624], dtype=float32)}
episode index:472
target Thresh 13.866957321644373
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([6.0192533, 9.838124 , 6.0368943], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.5968965862567519
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([7.721868 , 9.074973 , 5.5669446], dtype=float32)}
episode index:473
target Thresh 13.872608395578249
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([6.9266973, 9.0214815, 2.689679 ], dtype=float32)}
done in step count: 16
reward sum = 0.8514577710948755
running average episode reward sum: 0.5974336351699124
{'scaleFactor': 30, 'timeStep': 17, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([11.160494  , 11.851342  ,  0.17784578], dtype=float32)}
episode index:474
target Thresh 13.878231284663299
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([ 5.0787506 , 10.579054  ,  0.76441944], dtype=float32)}
done in step count: 68
reward sum = 0.5048858887870696
running average episode reward sum: 0.5972387978091065
{'scaleFactor': 30, 'timeStep': 69, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([7.8103113, 9.000782 , 0.55406  ], dtype=float32)}
episode index:475
target Thresh 13.883826129472038
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([12.091577 ,  4.0560727,  5.2124095], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.5980849347884991
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([12.091577 ,  4.0560727,  5.2124095], dtype=float32)}
episode index:476
target Thresh 13.889393069875881
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([12.346512,  3.99807 ,  5.815636], dtype=float32)}
done in step count: 126
reward sum = 0.2818606955404635
running average episode reward sum: 0.5974219908907045
{'scaleFactor': 30, 'timeStep': 127, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([2.8937092, 8.442818 , 2.5722046], dtype=float32)}
episode index:477
target Thresh 13.894932245048626
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([12.130371  ,  3.2693784 ,  0.47125715], dtype=float32)}
done in step count: 399
reward sum = 0.0
running average episode reward sum: 0.5961721540896778
{'scaleFactor': 30, 'timeStep': 400, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([9.840863 , 4.5238104, 1.4577475], dtype=float32)}
episode index:478
target Thresh 13.900443793469943
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([12.164653 ,  4.998751 ,  0.7182091], dtype=float32)}
done in step count: 157
reward sum = 0.2064075371174136
running average episode reward sum: 0.595358449252575
{'scaleFactor': 30, 'timeStep': 158, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([ 3.77695 , 10.98805 ,  4.382042], dtype=float32)}
episode index:479
target Thresh 13.905927852928826
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([11.735603 ,  8.340799 ,  6.0841484], dtype=float32)}
done in step count: 101
reward sum = 0.3623720178604969
running average episode reward sum: 0.5948730608538414
{'scaleFactor': 30, 'timeStep': 102, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([3.9770722, 8.165948 , 4.210169 ], dtype=float32)}
episode index:480
target Thresh 13.911384560527049
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([11.991522  ,  7.3328743 ,  0.65706664], dtype=float32)}
done in step count: 157
reward sum = 0.2064075371174136
running average episode reward sum: 0.5940654402223727
{'scaleFactor': 30, 'timeStep': 158, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([9.098979 , 9.166203 , 1.4889165], dtype=float32)}
episode index:481
target Thresh 13.91681405268259
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([6.93611   , 8.905315  , 0.45117453], dtype=float32)}
done in step count: 34
reward sum = 0.7105532272722921
running average episode reward sum: 0.5943071161291152
{'scaleFactor': 30, 'timeStep': 35, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([3.8021915, 8.634813 , 3.195099 ], dtype=float32)}
episode index:482
target Thresh 13.92221646513303
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([5.3133774, 9.06494  , 2.971921 ], dtype=float32)}
done in step count: 38
reward sum = 0.682554595010387
running average episode reward sum: 0.5944898231247286
{'scaleFactor': 30, 'timeStep': 39, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([10.400606, 10.752187,  5.755246], dtype=float32)}
episode index:483
target Thresh 13.927591932938961
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([4.9989004, 8.872072 , 3.0790904], dtype=float32)}
done in step count: 54
reward sum = 0.5811664141181095
running average episode reward sum: 0.5944622954201696
{'scaleFactor': 30, 'timeStep': 55, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([11.664008 ,  5.493083 ,  4.7949014], dtype=float32)}
episode index:484
target Thresh 13.932940590487362
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([ 2.1955678, 10.202255 ,  2.4833524], dtype=float32)}
done in step count: 17
reward sum = 0.8429431933839268
running average episode reward sum: 0.5949746271685484
{'scaleFactor': 30, 'timeStep': 18, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([1.9463778, 7.6952734, 4.4819193], dtype=float32)}
episode index:485
target Thresh 13.938262571494953
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([12.366512 ,  7.070305 ,  1.1540822], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.5958080127093539
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([12.366512 ,  7.070305 ,  1.1540822], dtype=float32)}
episode index:486
target Thresh 13.943558009011529
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([2.1147249, 6.6757565, 1.3133919], dtype=float32)}
done in step count: 51
reward sum = 0.598956006466161
running average episode reward sum: 0.5958144767622426
{'scaleFactor': 30, 'timeStep': 52, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([11.317997,  6.395029,  5.750451], dtype=float32)}
episode index:487
target Thresh 13.948827035423308
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([9.73421   , 9.098686  , 0.16912961], dtype=float32)}
done in step count: 160
reward sum = 0.2002770268574893
running average episode reward sum: 0.5950039492009623
{'scaleFactor': 30, 'timeStep': 161, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([0.87608564, 3.9410334 , 3.489056  ], dtype=float32)}
episode index:488
target Thresh 13.954069782456223
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([12.164908 ,  4.2427025,  2.213055 ], dtype=float32)}
done in step count: 199
reward sum = 0.13533300490703204
running average episode reward sum: 0.5940639268199931
{'scaleFactor': 30, 'timeStep': 200, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([ 4.515264, 10.150998,  5.109791], dtype=float32)}
episode index:489
target Thresh 13.959286381179226
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([ 3.2232418 , 10.071546  ,  0.50627166], dtype=float32)}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.5946972291632355
{'scaleFactor': 30, 'timeStep': 11, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([ 9.974915  , 11.367234  ,  0.46271688], dtype=float32)}
episode index:490
target Thresh 13.964476962007554
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([10.414883,  9.737838,  2.646472], dtype=float32)}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.5953465571027884
{'scaleFactor': 30, 'timeStep': 10, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([2.7094767, 6.5761547, 3.409378 ], dtype=float32)}
episode index:491
target Thresh 13.969641654705999
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([1.919261 , 8.417514 , 5.0970697], dtype=float32)}
done in step count: 68
reward sum = 0.5048858887870696
running average episode reward sum: 0.5951626939558051
{'scaleFactor': 30, 'timeStep': 69, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([11.735483, 11.453421,  1.842325], dtype=float32)}
episode index:492
target Thresh 13.974780588392145
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([11.8475485,  2.0416682,  3.35318  ], dtype=float32)}
done in step count: 125
reward sum = 0.28470777327319546
running average episode reward sum: 0.5945329679503637
{'scaleFactor': 30, 'timeStep': 126, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([4.152387 , 9.4204035, 2.1517048], dtype=float32)}
episode index:493
target Thresh 13.979893891539605
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([3.2142642, 8.822115 , 2.3492117], dtype=float32)}
done in step count: 192
reward sum = 0.14519690621578263
running average episode reward sum: 0.5936233807808605
{'scaleFactor': 30, 'timeStep': 193, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([ 6.132466 , 11.956756 ,  5.9141154], dtype=float32)}
episode index:494
target Thresh 13.984981691981224
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([10.257563 ,  7.02063  ,  2.6425965], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.5944241416277679
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([8.989589 , 8.491121 , 2.0821314], dtype=float32)}
episode index:495
target Thresh 13.990044116912276
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([11.362242 ,  7.994601 ,  1.9344039], dtype=float32)}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.595181953842228
{'scaleFactor': 30, 'timeStep': 4, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([ 9.32502  , 10.967901 ,  2.6105905], dtype=float32)}
episode index:496
target Thresh 13.99508129289365
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([7.0492625, 8.962023 , 1.8742785], dtype=float32)}
done in step count: 130
reward sum = 0.27075425951199406
running average episode reward sum: 0.5945291818214429
{'scaleFactor': 30, 'timeStep': 131, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([0.64202684, 2.9824257 , 5.013835  ], dtype=float32)}
episode index:497
target Thresh 14.000093345855005
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([8.7497  , 8.980748, 5.786118], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.5953433802515202
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([8.7497  , 8.980748, 5.786118], dtype=float32)}
episode index:498
target Thresh 14.005080401097928
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([4.564887 , 8.707813 , 3.4192176], dtype=float32)}
done in step count: 32
reward sum = 0.7249803359578534
running average episode reward sum: 0.5956031737499298
{'scaleFactor': 30, 'timeStep': 33, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([11.834977, 10.458067,  5.603948], dtype=float32)}
episode index:499
target Thresh 14.01004258329906
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([7.215438 , 9.218218 , 0.6281604], dtype=float32)}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.59635256540243
{'scaleFactor': 30, 'timeStep': 4, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([11.134526 ,  9.923588 ,  5.7414017], dtype=float32)}
episode index:500
target Thresh 14.014980016513215
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([12.085141 ,  7.911586 ,  5.7365594], dtype=float32)}
done in step count: 60
reward sum = 0.5471566423907612
running average episode reward sum: 0.5962543699473168
{'scaleFactor': 30, 'timeStep': 61, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([7.614423 , 9.387522 , 2.3613806], dtype=float32)}
episode index:501
target Thresh 14.019892824176479
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([ 9.071149 , 11.135946 ,  2.9241385], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.5970586441107684
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([ 9.071149 , 11.135946 ,  2.9241385], dtype=float32)}
episode index:502
target Thresh 14.0247811291093
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([10.330734 ,  5.5341053,  2.898434 ], dtype=float32)}
done in step count: 56
reward sum = 0.5696012024771592
running average episode reward sum: 0.5970040567516558
{'scaleFactor': 30, 'timeStep': 57, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([ 5.7593617, 10.941659 ,  2.5246048], dtype=float32)}
episode index:503
target Thresh 14.029645053519555
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([3.9561126, 7.735036 , 5.4123406], dtype=float32)}
done in step count: 38
reward sum = 0.682554595010387
running average episode reward sum: 0.5971737998831216
{'scaleFactor': 30, 'timeStep': 39, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([ 6.538122 , 10.999946 ,  0.9428812], dtype=float32)}
episode index:504
target Thresh 14.03448471900561
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([11.918952 ,  2.9077952,  3.3847327], dtype=float32)}
done in step count: 27
reward sum = 0.7623427143471035
running average episode reward sum: 0.5975008670404759
{'scaleFactor': 30, 'timeStep': 28, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([11.187705 ,  8.417049 ,  1.8132324], dtype=float32)}
episode index:505
target Thresh 14.039300246559353
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([10.035686,  9.466524,  6.162695], dtype=float32)}
done in step count: 37
reward sum = 0.6894490858690777
running average episode reward sum: 0.5976825828879633
{'scaleFactor': 30, 'timeStep': 38, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([6.7169538, 8.290043 , 2.7155766], dtype=float32)}
episode index:506
target Thresh 14.044091756569223
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([4.902325, 9.839732, 4.465965], dtype=float32)}
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.598234532473981
{'scaleFactor': 30, 'timeStep': 14, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([0.05859788, 8.146164  , 3.5562642 ], dtype=float32)}
episode index:507
target Thresh 14.048859368823221
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([10.580382,  4.069462,  2.537486], dtype=float32)}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.5989669428431267
{'scaleFactor': 30, 'timeStep': 4, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([9.810509 , 8.09038  , 1.3756217], dtype=float32)}
episode index:508
target Thresh 14.053603202511901
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([4.976929 , 9.9736   , 3.5863037], dtype=float32)}
done in step count: 14
reward sum = 0.8687458127689782
running average episode reward sum: 0.5994969602693072
{'scaleFactor': 30, 'timeStep': 15, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([10.213256,  6.631902,  6.045765], dtype=float32)}
episode index:509
target Thresh 14.058323376231352
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([ 3.0500886, 10.082481 ,  3.5695233], dtype=float32)}
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.6000594855858695
{'scaleFactor': 30, 'timeStep': 13, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([ 7.710701 , 11.426876 ,  0.2980553], dtype=float32)}
episode index:510
target Thresh 14.063020007986161
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([11.822145,  8.715358,  5.521764], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6008421480406917
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([11.822145,  8.715358,  5.521764], dtype=float32)}
episode index:511
target Thresh 14.06769321519237
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([9.340948 , 8.762721 , 3.6655765], dtype=float32)}
done in step count: 64
reward sum = 0.525596487525562
running average episode reward sum: 0.6006951838599981
{'scaleFactor': 30, 'timeStep': 65, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([ 4.211982, 10.556202,  4.262742], dtype=float32)}
episode index:512
target Thresh 14.072343114680404
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([2.2467587, 5.0676045, 0.3981611], dtype=float32)}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.6013967449245985
{'scaleFactor': 30, 'timeStep': 5, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([9.300286 , 8.157057 , 0.3197112], dtype=float32)}
episode index:513
target Thresh 14.076969822697986
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([1.8565346, 4.8876944, 2.798563 ], dtype=float32)}
done in step count: 68
reward sum = 0.5048858887870696
running average episode reward sum: 0.6012089806130468
{'scaleFactor': 30, 'timeStep': 69, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([13.417026 ,  5.173011 ,  3.7676628], dtype=float32)}
episode index:514
target Thresh 14.081573454913062
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([11.866398 ,  3.8479974,  0.9711865], dtype=float32)}
done in step count: 150
reward sum = 0.22145178723886091
running average episode reward sum: 0.6004715880045532
{'scaleFactor': 30, 'timeStep': 151, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([0.6969321, 6.711363 , 0.107714 ], dtype=float32)}
episode index:515
target Thresh 14.086154126416677
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([11.214813 ,  9.121282 ,  0.4481662], dtype=float32)}
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.6010256835156222
{'scaleFactor': 30, 'timeStep': 13, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([1.9875953, 5.6426654, 4.0499897], dtype=float32)}
episode index:516
target Thresh 14.090711951725854
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([13.7300415,  9.709107 ,  5.9789257], dtype=float32)}
done in step count: 20
reward sum = 0.8179069375972308
running average episode reward sum: 0.601445183039958
{'scaleFactor': 30, 'timeStep': 21, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([13.815299,  4.673409,  4.440366], dtype=float32)}
episode index:517
target Thresh 14.095247044786468
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([1.7787294, 8.101957 , 4.0499234], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.6021952888642051
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([1.7294579, 7.9588795, 4.1580744], dtype=float32)}
episode index:518
target Thresh 14.099759518976077
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([ 8.116323 , 10.041771 ,  2.9288247], dtype=float32)}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.6029234289627328
{'scaleFactor': 30, 'timeStep': 3, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([5.8026915, 9.729344 , 3.2195652], dtype=float32)}
episode index:519
target Thresh 14.104249487106772
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([7.8685493, 9.5850935, 3.3919063], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.603687037753189
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([7.8685493, 9.5850935, 3.3919063], dtype=float32)}
episode index:520
target Thresh 14.108717061427994
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([ 3.08121 , 10.114257,  4.152071], dtype=float32)}
done in step count: 52
reward sum = 0.5929664464014994
running average episode reward sum: 0.6036664608024179
{'scaleFactor': 30, 'timeStep': 53, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([9.031562 , 8.448338 , 5.0246077], dtype=float32)}
episode index:521
target Thresh 14.113162353629328
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([1.9580373, 2.994088 , 4.2374573], dtype=float32)}
done in step count: 30
reward sum = 0.7397003733882802
running average episode reward sum: 0.603927062167525
{'scaleFactor': 30, 'timeStep': 31, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([6.198884  , 9.967093  , 0.61953735], dtype=float32)}
episode index:522
target Thresh 14.117585474843315
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([ 4.1166024, 10.062077 ,  2.98699  ], dtype=float32)}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.6045190128086648
{'scaleFactor': 30, 'timeStep': 10, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([5.531022, 9.047969, 5.073403], dtype=float32)}
episode index:523
target Thresh 14.121986535648213
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([3.0309641, 9.848207 , 1.769828 ], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6052737475170452
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([3.0309641, 9.848207 , 1.769828 ], dtype=float32)}
episode index:524
target Thresh 14.126365646070772
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([1.9864247, 3.980584 , 3.3049533], dtype=float32)}
done in step count: 113
reward sum = 0.3212010745647914
running average episode reward sum: 0.6047326567114218
{'scaleFactor': 30, 'timeStep': 114, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([6.9055877, 7.6416125, 5.580077 ], dtype=float32)}
episode index:525
target Thresh 14.130722915588981
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([10.130653 , 10.056457 ,  5.8926454], dtype=float32)}
done in step count: 23
reward sum = 0.7936142836436554
running average episode reward sum: 0.6050917472569204
{'scaleFactor': 30, 'timeStep': 24, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([3.968308 , 7.6937466, 1.9959037], dtype=float32)}
episode index:526
target Thresh 14.135058453134807
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([12.241332,  4.142976,  5.360924], dtype=float32)}
done in step count: 48
reward sum = 0.617290140942288
running average episode reward sum: 0.6051148941140084
{'scaleFactor': 30, 'timeStep': 49, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([2.1746645, 7.5563574, 3.8704276], dtype=float32)}
episode index:527
target Thresh 14.139372367096911
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([8.013737, 9.120331, 4.711121], dtype=float32)}
done in step count: 24
reward sum = 0.7856781408072188
running average episode reward sum: 0.6054568699600182
{'scaleFactor': 30, 'timeStep': 25, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([1.274817 , 4.72898  , 3.6348822], dtype=float32)}
episode index:528
target Thresh 14.143664765323368
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([10.455477 , 10.688221 ,  2.1021202], dtype=float32)}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6060920746470523
{'scaleFactor': 30, 'timeStep': 7, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([4.8606195, 8.952462 , 3.2096074], dtype=float32)}
episode index:529
target Thresh 14.147935755124356
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([ 8.500887 , 11.215181 ,  0.9850256], dtype=float32)}
done in step count: 20
reward sum = 0.8179069375972308
running average episode reward sum: 0.6064917253318639
{'scaleFactor': 30, 'timeStep': 21, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([8.961639 , 7.8647165, 0.0796892], dtype=float32)}
episode index:530
target Thresh 14.152185443274844
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([1.840097, 2.813158, 5.287663], dtype=float32)}
done in step count: 112
reward sum = 0.3244455298634257
running average episode reward sum: 0.6059605648884205
{'scaleFactor': 30, 'timeStep': 113, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([3.572185 , 8.878285 , 2.0553792], dtype=float32)}
episode index:531
target Thresh 14.156413936017259
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([5.150811 , 9.751009 , 1.1418552], dtype=float32)}
done in step count: 37
reward sum = 0.6894490858690777
running average episode reward sum: 0.6061174981985346
{'scaleFactor': 30, 'timeStep': 38, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([9.744817 , 8.974866 , 5.5806923], dtype=float32)}
episode index:532
target Thresh 14.160621339064136
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([11.770857 ,  9.18038  ,  1.3264316], dtype=float32)}
done in step count: 206
reward sum = 0.12613920430197118
running average episode reward sum: 0.6052169760711489
{'scaleFactor': 30, 'timeStep': 207, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([ 7.2119074, 11.423254 ,  3.034366 ], dtype=float32)}
episode index:533
target Thresh 14.164807757600773
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([10.482966,  8.066634,  4.668401], dtype=float32)}
done in step count: 72
reward sum = 0.48499137027416284
running average episode reward sum: 0.6049918344872594
{'scaleFactor': 30, 'timeStep': 73, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([12.53804  ,  3.9148588,  5.6342034], dtype=float32)}
episode index:534
target Thresh 14.168973296287849
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([11.926471  ,  8.135943  ,  0.07318562], dtype=float32)}
done in step count: 257
reward sum = 0.07555183406752786
running average episode reward sum: 0.6040022270098393
{'scaleFactor': 30, 'timeStep': 258, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([5.7126245, 8.102372 , 2.0929143], dtype=float32)}
episode index:535
target Thresh 14.173118059264048
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([1.8439552, 6.9447446, 4.7342014], dtype=float32)}
done in step count: 38
reward sum = 0.682554595010387
running average episode reward sum: 0.6041487799352135
{'scaleFactor': 30, 'timeStep': 39, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([7.105279  , 7.8328786 , 0.83765996], dtype=float32)}
episode index:536
target Thresh 14.177242150148665
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([3.1155033, 8.374004 , 1.2880981], dtype=float32)}
done in step count: 204
reward sum = 0.12870034108965533
running average episode reward sum: 0.6032634010919257
{'scaleFactor': 30, 'timeStep': 205, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([11.786169 , 11.325657 ,  6.1349936], dtype=float32)}
episode index:537
target Thresh 14.181345672044182
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([11.890862  ,  3.0632374 ,  0.72913027], dtype=float32)}
done in step count: 38
reward sum = 0.682554595010387
running average episode reward sum: 0.6034107824932612
{'scaleFactor': 30, 'timeStep': 39, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([13.661307,  8.506371,  0.886288], dtype=float32)}
episode index:538
target Thresh 14.185428727538863
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([ 5.5443487 , 10.304962  ,  0.83096254], dtype=float32)}
done in step count: 355
reward sum = 0.02821591134702963
running average episode reward sum: 0.6023436305987413
{'scaleFactor': 30, 'timeStep': 356, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([10.756228  ,  0.88501596,  5.4656587 ], dtype=float32)}
episode index:539
target Thresh 14.189491418709306
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([12.067955 ,  9.900135 ,  2.1987228], dtype=float32)}
done in step count: 17
reward sum = 0.8429431933839268
running average episode reward sum: 0.6027891853446398
{'scaleFactor': 30, 'timeStep': 18, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([ 8.6516075, 11.704056 ,  3.7041025], dtype=float32)}
episode index:540
target Thresh 14.193533847123003
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([1.2738906, 9.582313 , 2.7628927], dtype=float32)}
done in step count: 97
reward sum = 0.37723664692350417
running average episode reward sum: 0.6023722675287042
{'scaleFactor': 30, 'timeStep': 98, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([3.6510131, 1.4032195, 4.2300406], dtype=float32)}
episode index:541
target Thresh 14.197556113840873
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([11.954516 ,  7.8782897,  5.835657 ], dtype=float32)}
done in step count: 14
reward sum = 0.8687458127689782
running average episode reward sum: 0.6028637316343135
{'scaleFactor': 30, 'timeStep': 15, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([11.521055 ,  8.149184 ,  5.4849863], dtype=float32)}
episode index:542
target Thresh 14.201558319419798
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([3.4525344, 9.270864 , 0.6595261], dtype=float32)}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.6035225387767919
{'scaleFactor': 30, 'timeStep': 5, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([10.001529 ,  8.454397 ,  0.4517433], dtype=float32)}
episode index:543
target Thresh 14.205540563915122
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([6.3251104, 8.958315 , 2.7089446], dtype=float32)}
done in step count: 399
reward sum = 0.0
running average episode reward sum: 0.6024131223452168
{'scaleFactor': 30, 'timeStep': 400, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([9.416422 , 6.6756363, 4.5759797], dtype=float32)}
episode index:544
target Thresh 14.209502946883164
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([6.8269424, 9.990461 , 3.9048128], dtype=float32)}
done in step count: 68
reward sum = 0.5048858887870696
running average episode reward sum: 0.6022341732928165
{'scaleFactor': 30, 'timeStep': 69, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([10.801405, 10.512595,  4.930888], dtype=float32)}
episode index:545
target Thresh 14.213445567383708
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([ 5.818233 , 10.066703 ,  3.4523053], dtype=float32)}
done in step count: 77
reward sum = 0.46122196741809546
running average episode reward sum: 0.6019759091794928
{'scaleFactor': 30, 'timeStep': 78, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([7.5727015 , 7.7981043 , 0.42969245], dtype=float32)}
episode index:546
target Thresh 14.21736852398247
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([11.950715 ,  1.1038438,  4.8068776], dtype=float32)}
done in step count: 228
reward sum = 0.10111704470857531
running average episode reward sum: 0.6010602622608989
{'scaleFactor': 30, 'timeStep': 229, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([0.04828814, 0.9240237 , 4.311706  ], dtype=float32)}
episode index:547
target Thresh 14.221271914753569
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([ 4.1910405, 10.030115 ,  2.2999377], dtype=float32)}
done in step count: 44
reward sum = 0.6426116020847181
running average episode reward sum: 0.6011360858737161
{'scaleFactor': 30, 'timeStep': 45, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([9.206438  , 7.2348914 , 0.39420837], dtype=float32)}
episode index:548
target Thresh 14.225155837281978
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([13.969486 ,  7.37331  ,  0.6339842], dtype=float32)}
done in step count: 378
reward sum = 0.022392550271025807
running average episode reward sum: 0.6000819082132377
{'scaleFactor': 30, 'timeStep': 379, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([2.820748 , 7.9661384, 3.0604968], dtype=float32)}
episode index:549
target Thresh 14.229020388665964
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([2.2266228, 4.7504983, 6.0971704], dtype=float32)}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.6006685678245371
{'scaleFactor': 30, 'timeStep': 9, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([8.332855  , 8.994965  , 0.37855464], dtype=float32)}
episode index:550
target Thresh 14.232865665519508
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([3.7769394 , 6.0669484 , 0.42011833], dtype=float32)}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.6012363512721943
{'scaleFactor': 30, 'timeStep': 10, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([7.0274563, 8.400405 , 1.1830406], dtype=float32)}
episode index:551
target Thresh 14.236691763974738
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([ 7.8340425, 10.826522 ,  1.9484795], dtype=float32)}
done in step count: 38
reward sum = 0.682554595010387
running average episode reward sum: 0.6013836669311403
{'scaleFactor': 30, 'timeStep': 39, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([3.19047 , 9.389379, 4.844507], dtype=float32)}
episode index:552
target Thresh 14.240498779684312
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([1.7958077, 9.171274 , 3.5105293], dtype=float32)}
done in step count: 399
reward sum = 0.0
running average episode reward sum: 0.6002961738625487
{'scaleFactor': 30, 'timeStep': 400, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([ 4.484261 , -0.3732127,  5.393584 ], dtype=float32)}
episode index:553
target Thresh 14.24428680782382
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([ 8.077621 , 10.041769 ,  2.5063314], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6010176609133383
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([ 8.077621 , 10.041769 ,  2.5063314], dtype=float32)}
episode index:554
target Thresh 14.248055943094162
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([10.552194 ,  8.673916 ,  3.7891712], dtype=float32)}
done in step count: 172
reward sum = 0.17752252675876343
running average episode reward sum: 0.6002546066175642
{'scaleFactor': 30, 'timeStep': 173, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([2.5653076, 6.061738 , 3.383093 ], dtype=float32)}
episode index:555
target Thresh 14.251806279723919
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([5.0038147, 9.179108 , 3.537563 ], dtype=float32)}
done in step count: 22
reward sum = 0.8016305895390459
running average episode reward sum: 0.6006167936372072
{'scaleFactor': 30, 'timeStep': 23, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([ 9.128485  , 10.165045  ,  0.35570157], dtype=float32)}
episode index:556
target Thresh 14.2555379114717
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([ 5.8640203, 10.00766  ,  4.92716  ], dtype=float32)}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.60116215320879
{'scaleFactor': 30, 'timeStep': 11, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([ 7.157234 , 10.836619 ,  0.3051666], dtype=float32)}
episode index:557
target Thresh 14.259250931628495
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([6.9777904, 9.109315 , 2.2779672], dtype=float32)}
done in step count: 54
reward sum = 0.5811664141181095
running average episode reward sum: 0.6011263185509214
{'scaleFactor': 30, 'timeStep': 55, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([0.08422419, 3.2011585 , 5.128764  ], dtype=float32)}
episode index:558
target Thresh 14.262945433019999
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([10.769461 ,  7.46214  ,  2.0470688], dtype=float32)}
done in step count: 67
reward sum = 0.5099857462495653
running average episode reward sum: 0.6009632763822249
{'scaleFactor': 30, 'timeStep': 68, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([13.628745 ,  4.074164 ,  5.6965976], dtype=float32)}
episode index:559
target Thresh 14.26662150800894
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([ 4.981696  , 10.876428  ,  0.78544986], dtype=float32)}
done in step count: 115
reward sum = 0.31480917318095203
running average episode reward sum: 0.6004522869122226
{'scaleFactor': 30, 'timeStep': 116, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([2.716903, 6.43219 , 4.119095], dtype=float32)}
episode index:560
target Thresh 14.270279248497385
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([1.749452 , 9.512479 , 3.1544774], dtype=float32)}
done in step count: 63
reward sum = 0.5309055429551132
running average episode reward sum: 0.6003283176716574
{'scaleFactor': 30, 'timeStep': 64, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([11.2255125,  6.4486227,  6.1919327], dtype=float32)}
episode index:561
target Thresh 14.273918745929034
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([6.0376754, 9.996896 , 1.7094033], dtype=float32)}
done in step count: 34
reward sum = 0.7105532272722921
running average episode reward sum: 0.6005244474040428
{'scaleFactor': 30, 'timeStep': 35, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([12.954091,  7.460827,  5.767993], dtype=float32)}
episode index:562
target Thresh 14.277540091291518
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([11.900578 ,  5.943461 ,  1.0135175], dtype=float32)}
done in step count: 46
reward sum = 0.6298236312032323
running average episode reward sum: 0.6005764885830822
{'scaleFactor': 30, 'timeStep': 47, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([3.939224 , 8.186111 , 5.3442936], dtype=float32)}
episode index:563
target Thresh 14.281143375118653
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([7.251602  , 8.726958  , 0.91520685], dtype=float32)}
done in step count: 22
reward sum = 0.8016305895390459
running average episode reward sum: 0.6009329674854864
{'scaleFactor': 30, 'timeStep': 23, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([ 3.9675746, 10.151891 ,  4.2085724], dtype=float32)}
episode index:564
target Thresh 14.284728687492729
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([1.899082 , 4.0687656, 0.8383153], dtype=float32)}
done in step count: 109
reward sum = 0.334376856889913
running average episode reward sum: 0.6004611867587686
{'scaleFactor': 30, 'timeStep': 110, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([9.152367 , 7.2854743, 5.3163095], dtype=float32)}
episode index:565
target Thresh 14.288296118046734
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([12.080599 ,  6.1855745,  1.1970227], dtype=float32)}
done in step count: 166
reward sum = 0.1885568451673771
running average episode reward sum: 0.5997334405722113
{'scaleFactor': 30, 'timeStep': 167, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([0.17337817, 5.952816  , 3.8104298 ], dtype=float32)}
episode index:566
target Thresh 14.291845755966627
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([2.094871 , 6.106661 , 5.5522995], dtype=float32)}
done in step count: 183
reward sum = 0.1589427091997875
running average episode reward sum: 0.5989560318749055
{'scaleFactor': 30, 'timeStep': 184, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([8.3487625e+00, 7.3638539e+00, 8.7278686e-04], dtype=float32)}
episode index:567
target Thresh 14.295377689993533
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([10.600222 ,  9.191342 ,  1.5863851], dtype=float32)}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.5994937537818313
{'scaleFactor': 30, 'timeStep': 11, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([2.701262 , 6.4490714, 3.9105697], dtype=float32)}
episode index:568
target Thresh 14.298892008425991
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([9.19615  , 8.889718 , 1.8643249], dtype=float32)}
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.599982378156554
{'scaleFactor': 30, 'timeStep': 14, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([4.22176  , 8.450301 , 4.0626454], dtype=float32)}
episode index:569
target Thresh 14.302388799122143
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([11.846855,  4.968925,  5.75324 ], dtype=float32)}
done in step count: 104
reward sum = 0.35160920655802225
running average episode reward sum: 0.5995466357502407
{'scaleFactor': 30, 'timeStep': 105, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([0.42201447, 5.616122  , 4.4440084 ], dtype=float32)}
episode index:570
target Thresh 14.305868149501938
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([6.6190243, 7.890462 , 5.1477003], dtype=float32)}
done in step count: 162
reward sum = 0.19629151402302528
running average episode reward sum: 0.5988404096176186
{'scaleFactor': 30, 'timeStep': 163, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([10.663366 ,  6.7505813,  1.7332333], dtype=float32)}
episode index:571
target Thresh 14.30933014654932
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([11.989727  ,  7.1545053 ,  0.07986944], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.5995417375728326
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([11.989727  ,  7.1545053 ,  0.07986944], dtype=float32)}
episode index:572
target Thresh 14.312774876814393
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([1.8678154, 4.9580035, 4.4113703], dtype=float32)}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6001220580097159
{'scaleFactor': 30, 'timeStep': 8, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([0.9657097, 6.0828648, 4.3323107], dtype=float32)}
episode index:573
target Thresh 14.316202426415591
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([9.793745 , 9.78219  , 5.6700745], dtype=float32)}
done in step count: 52
reward sum = 0.5929664464014994
running average episode reward sum: 0.6001095917874019
{'scaleFactor': 30, 'timeStep': 53, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([ 4.5591974, 11.831458 ,  2.8735561], dtype=float32)}
episode index:574
target Thresh 14.319612881041838
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([8.717311, 9.068204, 3.124557], dtype=float32)}
done in step count: 64
reward sum = 0.525596487525562
running average episode reward sum: 0.59998000377999
{'scaleFactor': 30, 'timeStep': 65, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([12.295903 ,  9.978426 ,  3.7005382], dtype=float32)}
episode index:575
target Thresh 14.32300632595467
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([6.0102015, 9.995222 , 4.4993715], dtype=float32)}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.6006060732352331
{'scaleFactor': 30, 'timeStep': 5, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([3.7007792, 6.6020594, 3.9159167], dtype=float32)}
episode index:576
target Thresh 14.326382845990397
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([2.1364532, 4.206119 , 2.7198453], dtype=float32)}
done in step count: 48
reward sum = 0.617290140942288
running average episode reward sum: 0.600634988430566
{'scaleFactor': 30, 'timeStep': 49, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([12.044235, 10.661275,  5.857522], dtype=float32)}
episode index:577
target Thresh 14.329742525562184
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([5.073399, 9.194337, 5.430187], dtype=float32)}
done in step count: 119
reward sum = 0.30240443566902153
running average episode reward sum: 0.6001190186160996
{'scaleFactor': 30, 'timeStep': 120, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([1.6558661, 6.485939 , 3.2828486], dtype=float32)}
episode index:578
target Thresh 14.333085448662203
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([11.857336 ,  1.7866764,  5.5477896], dtype=float32)}
done in step count: 52
reward sum = 0.5929664464014994
running average episode reward sum: 0.6001066652962125
{'scaleFactor': 30, 'timeStep': 53, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([8.841261 , 8.911269 , 1.1039126], dtype=float32)}
episode index:579
target Thresh 14.336411698863703
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([3.0100813, 9.919524 , 5.8960166], dtype=float32)}
done in step count: 40
reward sum = 0.6689717585696803
running average episode reward sum: 0.6002253982156496
{'scaleFactor': 30, 'timeStep': 41, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([10.408915 ,  2.68491  ,  5.1735516], dtype=float32)}
episode index:580
target Thresh 14.339721359323113
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([2.2558377, 5.8714824, 3.9454937], dtype=float32)}
done in step count: 336
reward sum = 0.03415272685621234
running average episode reward sum: 0.5992510906917952
{'scaleFactor': 30, 'timeStep': 337, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([9.438828, 9.802663, 6.004099], dtype=float32)}
episode index:581
target Thresh 14.343014512782117
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([1.843469, 9.903134, 3.048226], dtype=float32)}
done in step count: 60
reward sum = 0.5471566423907612
running average episode reward sum: 0.5991615813304532
{'scaleFactor': 30, 'timeStep': 61, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([12.497168 ,  6.5787454,  6.0013223], dtype=float32)}
episode index:582
target Thresh 14.346291241569721
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([1.8001704, 7.1080017, 1.5263292], dtype=float32)}
done in step count: 31
reward sum = 0.7323033696543975
running average episode reward sum: 0.5993899548953312
{'scaleFactor': 30, 'timeStep': 32, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([10.520284 ,  7.2351475,  5.212333 ], dtype=float32)}
episode index:583
target Thresh 14.349551627604319
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([ 6.9164333, 10.266101 ,  3.8351512], dtype=float32)}
done in step count: 35
reward sum = 0.7034476949995692
running average episode reward sum: 0.5995681359571535
{'scaleFactor': 30, 'timeStep': 36, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([1.9020534, 8.151543 , 2.9504986], dtype=float32)}
episode index:584
target Thresh 14.352795752395728
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([6.000647  , 9.997732  , 0.76570636], dtype=float32)}
done in step count: 239
reward sum = 0.0905339582851764
running average episode reward sum: 0.5986979920636971
{'scaleFactor': 30, 'timeStep': 240, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([11.227688 ,  7.9053245,  5.7183385], dtype=float32)}
episode index:585
target Thresh 14.356023697047238
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([9.9016075, 8.945837 , 3.6197605], dtype=float32)}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.5992668783364672
{'scaleFactor': 30, 'timeStep': 8, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([10.391521 ,  6.9864416,  5.174955 ], dtype=float32)}
episode index:586
target Thresh 14.359235542257636
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([7.7661242 , 9.839608  , 0.38494876], dtype=float32)}
done in step count: 18
reward sum = 0.8345137614500875
running average episode reward sum: 0.5996676396364904
{'scaleFactor': 30, 'timeStep': 19, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([13.382516 ,  3.6597736,  5.35176  ], dtype=float32)}
episode index:587
target Thresh 14.362431368323215
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([11.9802  ,  7.955393,  5.380028], dtype=float32)}
done in step count: 399
reward sum = 0.0
running average episode reward sum: 0.5986477967119385
{'scaleFactor': 30, 'timeStep': 400, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([13.558023  , -0.40833348,  3.5316796 ], dtype=float32)}
episode index:588
target Thresh 14.365611255139795
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([5.256504 , 9.976133 , 1.7748514], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.5993292096207467
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([5.256504 , 9.976133 , 1.7748514], dtype=float32)}
episode index:589
target Thresh 14.368775282204714
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([4.9571753, 8.957173 , 5.8325906], dtype=float32)}
done in step count: 62
reward sum = 0.536268225207185
running average episode reward sum: 0.5992223265963169
{'scaleFactor': 30, 'timeStep': 63, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([3.9647112, 6.5462933, 3.182239 ], dtype=float32)}
episode index:590
target Thresh 14.371923528618812
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([7.4124274, 9.8187475, 4.7490516], dtype=float32)}
done in step count: 143
reward sum = 0.23759255478829303
running average episode reward sum: 0.598610431889366
{'scaleFactor': 30, 'timeStep': 144, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([3.0110888, 5.567319 , 4.9174147], dtype=float32)}
episode index:591
target Thresh 14.37505607308841
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([10.029144 ,  8.885951 ,  1.8159761], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.5992884548084718
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([10.029144 ,  8.885951 ,  1.8159761], dtype=float32)}
episode index:592
target Thresh 14.37817299392729
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([2.0137126, 4.8229866, 1.6138898], dtype=float32)}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.5999306327936177
{'scaleFactor': 30, 'timeStep': 3, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([0.7999261, 8.863331 , 2.0009184], dtype=float32)}
episode index:593
target Thresh 14.381274369058628
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([8.262088 , 9.239275 , 5.3252683], dtype=float32)}
done in step count: 36
reward sum = 0.6964132180495735
running average episode reward sum: 0.6000930613883247
{'scaleFactor': 30, 'timeStep': 37, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([2.4118497, 6.83677  , 3.2516823], dtype=float32)}
episode index:594
target Thresh 14.38436027601697
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([7.779564 , 9.878702 , 5.2228847], dtype=float32)}
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.6005892717965103
{'scaleFactor': 30, 'timeStep': 12, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([11.587746 ,  8.131547 ,  5.0714216], dtype=float32)}
episode index:595
target Thresh 14.387430791950147
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([12.001903 ,  8.999539 ,  1.6592028], dtype=float32)}
done in step count: 399
reward sum = 0.0
running average episode reward sum: 0.5995815716760464
{'scaleFactor': 30, 'timeStep': 400, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([14.078257  ,  6.8481154 ,  0.29378292], dtype=float32)}
episode index:596
target Thresh 14.390485993621217
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([6.9787188, 9.966078 , 4.0415087], dtype=float32)}
done in step count: 15
reward sum = 0.8600583546412884
running average episode reward sum: 0.6000178811952512
{'scaleFactor': 30, 'timeStep': 16, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([2.323197, 4.779105, 3.30611 ], dtype=float32)}
episode index:597
target Thresh 14.393525957410382
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([3.7106745, 8.086806 , 4.763464 ], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6006867476146571
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([3.7106745, 8.086806 , 4.763464 ], dtype=float32)}
episode index:598
target Thresh 14.396550759316899
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([2.0286398, 2.8722987, 3.1861472], dtype=float32)}
done in step count: 107
reward sum = 0.34116606151404244
running average episode reward sum: 0.6002534910435376
{'scaleFactor': 30, 'timeStep': 108, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([11.996934,  8.734524,  5.847325], dtype=float32)}
episode index:599
target Thresh 14.399560474960966
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([2.086124, 2.144217, 3.779683], dtype=float32)}
done in step count: 262
reward sum = 0.07184904244991483
running average episode reward sum: 0.5993728169625482
{'scaleFactor': 30, 'timeStep': 263, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([ 8.062221, 10.090038,  4.911361], dtype=float32)}
episode index:600
target Thresh 14.402555179585633
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([2.0695348, 4.9698853, 2.193206 ], dtype=float32)}
done in step count: 20
reward sum = 0.8179069375972308
running average episode reward sum: 0.5997364344677639
{'scaleFactor': 30, 'timeStep': 21, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([10.986125 ,  6.3479424,  5.4992733], dtype=float32)}
episode index:601
target Thresh 14.405534948058673
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([8.117665 , 9.031041 , 5.7095637], dtype=float32)}
done in step count: 38
reward sum = 0.682554595010387
running average episode reward sum: 0.5998740061630174
{'scaleFactor': 30, 'timeStep': 39, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([4.916961 , 7.2263722, 2.865466 ], dtype=float32)}
episode index:602
target Thresh 14.408499854874453
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([ 1.9640467 , 10.048952  ,  0.85106444], dtype=float32)}
done in step count: 399
reward sum = 0.0
running average episode reward sum: 0.5988791902323989
{'scaleFactor': 30, 'timeStep': 400, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([ 0.17181493, 11.468942  ,  0.81102043], dtype=float32)}
episode index:603
target Thresh 14.411449974155799
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([11.969022 ,  9.887921 ,  2.7434187], dtype=float32)}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.5994941236922791
{'scaleFactor': 30, 'timeStep': 4, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([ 5.9803853, 11.366297 ,  2.7899952], dtype=float32)}
episode index:604
target Thresh 14.414385379655846
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([1.823021 , 3.0145383, 2.0233748], dtype=float32)}
done in step count: 73
reward sum = 0.4801414565714212
running average episode reward sum: 0.599296846556542
{'scaleFactor': 30, 'timeStep': 74, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([7.1259475, 8.554501 , 0.99854  ], dtype=float32)}
episode index:605
target Thresh 14.41730614475988
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([-0.06616759,  4.7301774 ,  3.4507108 ], dtype=float32)}
done in step count: 172
reward sum = 0.17752252675876343
running average episode reward sum: 0.5986008493291529
{'scaleFactor': 30, 'timeStep': 173, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([ 7.7345695, 10.02792  ,  6.026257 ], dtype=float32)}
episode index:606
target Thresh 14.420212342487186
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([2.4055436, 3.1053948, 0.6593894], dtype=float32)}
done in step count: 25
reward sum = 0.7778213593991467
running average episode reward sum: 0.5988961055236669
{'scaleFactor': 30, 'timeStep': 26, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([11.148954,  4.82716 ,  4.915233], dtype=float32)}
episode index:607
target Thresh 14.423104045492858
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([11.984432 ,  7.94125  ,  1.3885105], dtype=float32)}
done in step count: 36
reward sum = 0.6964132180495735
running average episode reward sum: 0.5990564955113741
{'scaleFactor': 30, 'timeStep': 37, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([8.21356  , 8.540916 , 3.1038718], dtype=float32)}
episode index:608
target Thresh 14.42598132606962
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([2.7655323, 9.830948 , 3.8620343], dtype=float32)}
done in step count: 27
reward sum = 0.7623427143471035
running average episode reward sum: 0.5993246173813834
{'scaleFactor': 30, 'timeStep': 28, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([7.568291 , 7.9323416, 0.7202422], dtype=float32)}
episode index:609
target Thresh 14.428844256149636
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([ 8.908946  , 10.647114  ,  0.23380238], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.5999814622709222
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([ 8.908946  , 10.647114  ,  0.23380238], dtype=float32)}
episode index:610
target Thresh 14.431692907306308
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([ 6.7551885, 10.1111765,  2.2652087], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6006361570953561
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([ 6.7551885, 10.1111765,  2.2652087], dtype=float32)}
episode index:611
target Thresh 14.434527350756065
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([ 6.9118767, 10.150028 ,  1.2613666], dtype=float32)}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.6012243267896448
{'scaleFactor': 30, 'timeStep': 5, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([ 8.835338  , 10.863808  ,  0.13612081], dtype=float32)}
episode index:612
target Thresh 14.437347657360139
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([11.889234 ,  6.158037 ,  6.2471237], dtype=float32)}
done in step count: 87
reward sum = 0.41712087993322033
running average episode reward sum: 0.6009239949024402
{'scaleFactor': 30, 'timeStep': 88, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([1.3139497, 8.577838 , 3.101378 ], dtype=float32)}
episode index:613
target Thresh 14.440153897626342
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([ 9.172267 , 10.061528 ,  2.0595202], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6015739558227945
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([ 9.172267 , 10.061528 ,  2.0595202], dtype=float32)}
episode index:614
target Thresh 14.442946141710825
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([12.267418  ,  2.985179  ,  0.68123657], dtype=float32)}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.6020961846660549
{'scaleFactor': 30, 'timeStep': 9, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([13.763952 ,  7.250065 ,  1.4833757], dtype=float32)}
episode index:615
target Thresh 14.44572445941984
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([ 4.843589 , 10.152884 ,  6.2676644], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6027421324182204
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([ 4.843589 , 10.152884 ,  6.2676644], dtype=float32)}
episode index:616
target Thresh 14.448488920211469
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([2.781403, 9.349798, 3.384268], dtype=float32)}
done in step count: 16
reward sum = 0.8514577710948755
running average episode reward sum: 0.6031452371810675
{'scaleFactor': 30, 'timeStep': 17, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([0.01962638, 8.424291  , 3.5905447 ], dtype=float32)}
episode index:617
target Thresh 14.45123959319738
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([2.0900435, 3.9413254, 3.2537656], dtype=float32)}
done in step count: 23
reward sum = 0.7936142836436554
running average episode reward sum: 0.6034534395216218
{'scaleFactor': 30, 'timeStep': 24, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([5.283616 , 9.347022 , 0.6260712], dtype=float32)}
episode index:618
target Thresh 14.45397654714454
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([3.1511002, 9.167245 , 2.0700684], dtype=float32)}
done in step count: 54
reward sum = 0.5811664141181095
running average episode reward sum: 0.6034174346340556
{'scaleFactor': 30, 'timeStep': 55, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([11.130713 ,  7.6686087,  0.4185828], dtype=float32)}
episode index:619
target Thresh 14.45669985047694
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([4.0057354, 9.129715 , 1.775336 ], dtype=float32)}
done in step count: 227
reward sum = 0.10213842899856092
running average episode reward sum: 0.602608920108837
{'scaleFactor': 30, 'timeStep': 228, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([10.238336 ,  4.690116 ,  1.5902884], dtype=float32)}
episode index:620
target Thresh 14.459409571277305
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([11.757679 ,  7.9503856,  5.2021117], dtype=float32)}
done in step count: 67
reward sum = 0.5099857462495653
running average episode reward sum: 0.6024597684601104
{'scaleFactor': 30, 'timeStep': 68, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([ 5.1198645, 10.856592 ,  3.835775 ], dtype=float32)}
episode index:621
target Thresh 14.462105777288798
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([ 9.239454 , 10.2793045,  1.9074094], dtype=float32)}
done in step count: 101
reward sum = 0.3623720178604969
running average episode reward sum: 0.6020737752919437
{'scaleFactor': 30, 'timeStep': 102, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([13.770231,  8.663909,  5.492928], dtype=float32)}
episode index:622
target Thresh 14.464788535916705
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([7.8943377, 7.9434915, 3.3438122], dtype=float32)}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.602588495868406
{'scaleFactor': 30, 'timeStep': 9, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([4.45324  , 8.208552 , 3.8262577], dtype=float32)}
episode index:623
target Thresh 14.467457914230136
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([10.9652   ,  7.141138 ,  2.0811973], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.6032093476378477
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([9.294544, 8.013729, 2.522386], dtype=float32)}
episode index:624
target Thresh 14.470113978963685
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([12.006569,  7.520938,  5.495556], dtype=float32)}
done in step count: 36
reward sum = 0.6964132180495735
running average episode reward sum: 0.6033584738305064
{'scaleFactor': 30, 'timeStep': 37, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([2.8260798, 9.382005 , 1.0771036], dtype=float32)}
episode index:625
target Thresh 14.47275679651911
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([2.1612918, 5.8356266, 2.9682178], dtype=float32)}
done in step count: 42
reward sum = 0.6556592205741436
running average episode reward sum: 0.6034420213492662
{'scaleFactor': 30, 'timeStep': 43, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([10.913681 ,  9.752672 ,  5.1223803], dtype=float32)}
episode index:626
target Thresh 14.475386432966989
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([4.0417857, 9.134257 , 4.967081 ], dtype=float32)}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.6039365591899909
{'scaleFactor': 30, 'timeStep': 10, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([11.712496 ,  7.9684916,  6.228327 ], dtype=float32)}
episode index:627
target Thresh 14.478002954048367
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([11.967546 ,  7.062453 ,  1.6159433], dtype=float32)}
done in step count: 160
reward sum = 0.2002770268574893
running average episode reward sum: 0.6032937892340474
{'scaleFactor': 30, 'timeStep': 161, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([2.657336 , 6.635763 , 3.0429192], dtype=float32)}
episode index:628
target Thresh 14.48060642517641
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([5.0112424, 9.680338 , 3.2700305], dtype=float32)}
done in step count: 48
reward sum = 0.617290140942288
running average episode reward sum: 0.6033160409855709
{'scaleFactor': 30, 'timeStep': 49, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([0.3267135, 7.9460726, 3.2210991], dtype=float32)}
episode index:629
target Thresh 14.483196911438029
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([12.205169 ,  3.9042993,  4.316369 ], dtype=float32)}
done in step count: 310
reward sum = 0.044351705540476356
running average episode reward sum: 0.6024287960086739
{'scaleFactor': 30, 'timeStep': 311, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([4.211646 , 9.63767  , 2.7672577], dtype=float32)}
episode index:630
target Thresh 14.485774477595518
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([1.9919815, 4.267619 , 4.38926  ], dtype=float32)}
done in step count: 327
reward sum = 0.03738596830031274
running average episode reward sum: 0.6015333240154753
{'scaleFactor': 30, 'timeStep': 328, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([10.868932,  4.618491,  5.175048], dtype=float32)}
episode index:631
target Thresh 14.488339188088165
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([11.840684  ,  2.9473903 ,  0.20546217], dtype=float32)}
done in step count: 70
reward sum = 0.49483865960020695
running average episode reward sum: 0.6013645033439321
{'scaleFactor': 30, 'timeStep': 71, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([6.6227026, 9.713817 , 5.1807494], dtype=float32)}
episode index:632
target Thresh 14.490891107033864
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([11.873456 ,  5.2630534,  5.0933695], dtype=float32)}
done in step count: 188
reward sum = 0.1511529349531471
running average episode reward sum: 0.6006532686387334
{'scaleFactor': 30, 'timeStep': 189, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([11.081912 ,  7.2270722,  5.8674116], dtype=float32)}
episode index:633
target Thresh 14.493430298230724
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([2.154682, 8.835171, 3.639921], dtype=float32)}
done in step count: 21
reward sum = 0.8097278682212584
running average episode reward sum: 0.6009830393005355
{'scaleFactor': 30, 'timeStep': 22, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([6.3102117 , 8.340853  , 0.51570916], dtype=float32)}
episode index:634
target Thresh 14.495956825158654
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([1.9618958, 3.8607001, 3.9472098], dtype=float32)}
done in step count: 178
reward sum = 0.1671339350148836
running average episode reward sum: 0.6002998123646526
{'scaleFactor': 30, 'timeStep': 179, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([7.4288974 , 9.307124  , 0.64007115], dtype=float32)}
episode index:635
target Thresh 14.498470750980962
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([3.8161483, 1.2705462, 6.0068793], dtype=float32)}
done in step count: 123
reward sum = 0.29048849430996376
running average episode reward sum: 0.59981268765073
{'scaleFactor': 30, 'timeStep': 124, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([13.3768215,  4.1825747,  3.4691775], dtype=float32)}
episode index:636
target Thresh 14.500972138545922
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([10.79351  ,  9.070225 ,  5.8523545], dtype=float32)}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.6003051594872024
{'scaleFactor': 30, 'timeStep': 10, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([ 9.994178 , 10.457964 ,  2.3377597], dtype=float32)}
episode index:637
target Thresh 14.503461050388356
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([10.880158,  9.099979,  4.765258], dtype=float32)}
done in step count: 95
reward sum = 0.38489607889348454
running average episode reward sum: 0.599967527699438
{'scaleFactor': 30, 'timeStep': 96, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([4.820726, 8.397411, 2.110684], dtype=float32)}
episode index:638
target Thresh 14.505937548731186
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([5.936145 , 8.847845 , 1.7063344], dtype=float32)}
done in step count: 176
reward sum = 0.17052743088958636
running average episode reward sum: 0.5992954774696886
{'scaleFactor': 30, 'timeStep': 177, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([9.034585, 8.441894, 2.183824], dtype=float32)}
episode index:639
target Thresh 14.508401695487004
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([5.8413005, 9.04674  , 1.4888325], dtype=float32)}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.5998751704736422
{'scaleFactor': 30, 'timeStep': 4, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([4.093986, 9.590695, 3.296877], dtype=float32)}
episode index:640
target Thresh 14.510853552259606
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([3.904352  , 9.224672  , 0.08921489], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.6004837895524665
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([6.0780544, 8.971519 , 6.1653833], dtype=float32)}
episode index:641
target Thresh 14.513293180345537
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([12.186045 ,  5.2811565,  3.4296463], dtype=float32)}
done in step count: 25
reward sum = 0.7778213593991467
running average episode reward sum: 0.600760016296776
{'scaleFactor': 30, 'timeStep': 26, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([13.49374 , 11.889779,  6.156666], dtype=float32)}
episode index:642
target Thresh 14.515720640735626
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([3.8798137 , 8.850421  , 0.91958237], dtype=float32)}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.6013499696151324
{'scaleFactor': 30, 'timeStep': 3, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([5.414175, 9.666597, 1.024319], dtype=float32)}
episode index:643
target Thresh 14.518135994116511
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([11.725933 ,  4.810274 ,  5.9238086], dtype=float32)}
done in step count: 151
reward sum = 0.2192372693664723
running average episode reward sum: 0.600756626912883
{'scaleFactor': 30, 'timeStep': 152, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([2.9272263, 6.12975  , 3.4424307], dtype=float32)}
episode index:644
target Thresh 14.520539300872153
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([12.044301 ,  3.0734355,  2.6311553], dtype=float32)}
done in step count: 140
reward sum = 0.24486529903492948
running average episode reward sum: 0.600204857412297
{'scaleFactor': 30, 'timeStep': 141, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([ 9.36625  , 11.9071245,  2.767257 ], dtype=float32)}
episode index:645
target Thresh 14.522930621085344
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([3.193271, 8.769721, 5.406872], dtype=float32)}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.6007627384534545
{'scaleFactor': 30, 'timeStep': 5, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([8.443467  , 8.418021  , 0.20468147], dtype=float32)}
episode index:646
target Thresh 14.525310014539215
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([10.75866 ,  9.910428,  5.364422], dtype=float32)}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6012747981280349
{'scaleFactor': 30, 'timeStep': 8, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([ 7.726709 , 11.979263 ,  1.8702933], dtype=float32)}
episode index:647
target Thresh 14.527677540718727
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([1.9984913, 9.0553   , 4.64577  ], dtype=float32)}
done in step count: 16
reward sum = 0.8514577710948755
running average episode reward sum: 0.6016608829628602
{'scaleFactor': 30, 'timeStep': 17, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([6.9179506 , 9.889716  , 0.77835023], dtype=float32)}
episode index:648
target Thresh 14.530033258812155
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([10.150596  , 10.049     ,  0.39386353], dtype=float32)}
done in step count: 110
reward sum = 0.33103308832101386
running average episode reward sum: 0.6012438909834429
{'scaleFactor': 30, 'timeStep': 111, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([3.013996, 6.708976, 4.356003], dtype=float32)}
episode index:649
target Thresh 14.532377227712576
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([2.0864527, 7.9589553, 4.4639287], dtype=float32)}
done in step count: 34
reward sum = 0.7105532272722921
running average episode reward sum: 0.601412059193118
{'scaleFactor': 30, 'timeStep': 35, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([5.289671 , 7.8501687, 0.5376024], dtype=float32)}
episode index:650
target Thresh 14.534709506019336
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([6.157621, 9.706874, 6.262421], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6020243294554942
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([6.157621, 9.706874, 6.262421], dtype=float32)}
episode index:651
target Thresh 14.537030152039511
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([11.972043 ,  2.2557101,  2.3523202], dtype=float32)}
done in step count: 64
reward sum = 0.525596487525562
running average episode reward sum: 0.6019071088390373
{'scaleFactor': 30, 'timeStep': 65, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([3.209792 , 9.806172 , 4.5895233], dtype=float32)}
episode index:652
target Thresh 14.539339223789376
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([ 3.5934873, 10.162138 ,  4.6227994], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6025167457320862
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([ 3.5934873, 10.162138 ,  4.6227994], dtype=float32)}
episode index:653
target Thresh 14.54163677899584
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([2.31387  , 6.1914797, 2.2545483], dtype=float32)}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.6030791039190403
{'scaleFactor': 30, 'timeStep': 4, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([2.0445213, 5.996468 , 2.6604488], dtype=float32)}
episode index:654
target Thresh 14.543922875097909
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([3.0371902, 8.946634 , 2.710768 ], dtype=float32)}
done in step count: 195
reward sum = 0.14088441290426768
running average episode reward sum: 0.6023734631693994
{'scaleFactor': 30, 'timeStep': 196, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([2.6704519, 2.375564 , 4.955087 ], dtype=float32)}
episode index:655
target Thresh 14.546197569248099
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([8.244735 , 7.8957014, 3.7928243], dtype=float32)}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.6029343252682265
{'scaleFactor': 30, 'timeStep': 4, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([6.571066 , 7.010372 , 2.6955504], dtype=float32)}
episode index:656
target Thresh 14.548460918313886
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([6.158242 , 9.069153 , 5.4189196], dtype=float32)}
done in step count: 134
reward sum = 0.26008546137772603
running average episode reward sum: 0.6024124852927463
{'scaleFactor': 30, 'timeStep': 135, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([3.5883217, 3.8933234, 5.37615  ], dtype=float32)}
episode index:657
target Thresh 14.550712978879112
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([ 7.1572065 , 10.220124  ,  0.04701126], dtype=float32)}
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.6028305833743666
{'scaleFactor': 30, 'timeStep': 14, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([12.493038 ,  7.881319 ,  4.2717433], dtype=float32)}
episode index:658
target Thresh 14.552953807245409
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([8.073698 , 8.650127 , 6.0636144], dtype=float32)}
done in step count: 125
reward sum = 0.28470777327319546
running average episode reward sum: 0.6023478476989474
{'scaleFactor': 30, 'timeStep': 126, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([6.321828 , 7.2273216, 2.992201 ], dtype=float32)}
episode index:659
target Thresh 14.555183459433605
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([10.929661  ,  8.913346  ,  0.89548564], dtype=float32)}
done in step count: 43
reward sum = 0.6491026283684022
running average episode reward sum: 0.6024186882757193
{'scaleFactor': 30, 'timeStep': 44, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([1.1612858, 4.828361 , 4.3933053], dtype=float32)}
episode index:660
target Thresh 14.55740199118512
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([6.9751363, 9.472924 , 0.8163065], dtype=float32)}
done in step count: 50
reward sum = 0.6050060671375364
running average episode reward sum: 0.6024226026159036
{'scaleFactor': 30, 'timeStep': 51, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([2.997129 , 7.039992 , 3.4289925], dtype=float32)}
episode index:661
target Thresh 14.559609457963361
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([7.9004054, 9.016859 , 6.062646 ], dtype=float32)}
done in step count: 191
reward sum = 0.14666354163210368
running average episode reward sum: 0.6017341448198557
{'scaleFactor': 30, 'timeStep': 192, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([13.224034,  3.902654,  1.303705], dtype=float32)}
episode index:662
target Thresh 14.561805914955116
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([5.048593, 9.955843, 4.661962], dtype=float32)}
done in step count: 20
reward sum = 0.8179069375972308
running average episode reward sum: 0.6020601972976496
{'scaleFactor': 30, 'timeStep': 21, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([3.8986945, 9.712337 , 2.9368012], dtype=float32)}
episode index:663
target Thresh 14.56399141707192
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([11.89925  ,  3.007263 ,  3.3439069], dtype=float32)}
done in step count: 101
reward sum = 0.3623720178604969
running average episode reward sum: 0.6016992211237984
{'scaleFactor': 30, 'timeStep': 102, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([9.96175, 9.98298, 3.02534], dtype=float32)}
episode index:664
target Thresh 14.566166018951442
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([11.057668  ,  9.929701  ,  0.01677697], dtype=float32)}
done in step count: 33
reward sum = 0.7177305325982749
running average episode reward sum: 0.601873704298948
{'scaleFactor': 30, 'timeStep': 34, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([6.2127438, 9.147107 , 2.9747362], dtype=float32)}
episode index:665
target Thresh 14.568329774958844
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([9.825828, 8.843183, 5.128542], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6024714915297303
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([9.825828, 8.843183, 5.128542], dtype=float32)}
episode index:666
target Thresh 14.570482739188137
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([6.4841566, 8.535328 , 4.1427894], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.603067486295053
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([6.4841566, 8.535328 , 4.1427894], dtype=float32)}
episode index:667
target Thresh 14.572624965463538
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([ 4.1289473, 10.134877 ,  2.5315433], dtype=float32)}
done in step count: 35
reward sum = 0.7034476949995692
running average episode reward sum: 0.6032177560685628
{'scaleFactor': 30, 'timeStep': 36, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([12.808911 ,  6.9520173,  3.8161397], dtype=float32)}
episode index:668
target Thresh 14.574756507340817
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([1.9839427, 9.124454 , 1.651177 ], dtype=float32)}
done in step count: 57
reward sum = 0.5639051904523875
running average episode reward sum: 0.6031589928912591
{'scaleFactor': 30, 'timeStep': 58, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([10.072356  , 10.620797  ,  0.63592786], dtype=float32)}
episode index:669
target Thresh 14.57687741810863
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([12.084103 ,  5.0954556,  4.253788 ], dtype=float32)}
done in step count: 45
reward sum = 0.6361854860638709
running average episode reward sum: 0.603208286164651
{'scaleFactor': 30, 'timeStep': 46, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([11.65518  , 10.090912 ,  2.7463021], dtype=float32)}
episode index:670
target Thresh 14.57898775078986
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([10.526753  ,  9.962312  ,  0.05778855], dtype=float32)}
done in step count: 56
reward sum = 0.5696012024771592
running average episode reward sum: 0.6031582010920914
{'scaleFactor': 30, 'timeStep': 57, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([4.2479405, 9.751219 , 5.0756335], dtype=float32)}
episode index:671
target Thresh 14.581087558142931
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([9.896608, 7.003596, 3.265592], dtype=float32)}
done in step count: 116
reward sum = 0.3116610814491425
running average episode reward sum: 0.6027244256164322
{'scaleFactor': 30, 'timeStep': 117, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([6.0301886, 8.845214 , 3.2246451], dtype=float32)}
episode index:672
target Thresh 14.583176892663136
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([ 9.393156, 10.345559,  2.374921], dtype=float32)}
done in step count: 28
reward sum = 0.7547192872036326
running average episode reward sum: 0.6029502723647044
{'scaleFactor': 30, 'timeStep': 29, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([13.682524 ,  2.6197023,  4.821734 ], dtype=float32)}
episode index:673
target Thresh 14.585255806583952
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([4.0448723, 8.57409  , 6.158642 ], dtype=float32)}
done in step count: 190
reward sum = 0.14814499154757946
running average episode reward sum: 0.602275487081593
{'scaleFactor': 30, 'timeStep': 191, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([13.275115 ,  3.0011888,  5.4639797], dtype=float32)}
episode index:674
target Thresh 14.587324351878328
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([2.0992332, 8.18042  , 5.660101 ], dtype=float32)}
done in step count: 399
reward sum = 0.0
running average episode reward sum: 0.6013832271007313
{'scaleFactor': 30, 'timeStep': 400, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([-0.46828973,  5.854593  ,  3.4602635 ], dtype=float32)}
episode index:675
target Thresh 14.589382580260008
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([4.8547177 , 9.206737  , 0.87653106], dtype=float32)}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6019003969569432
{'scaleFactor': 30, 'timeStep': 6, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([ 3.7292142, 10.374289 ,  2.682425 ], dtype=float32)}
episode index:676
target Thresh 14.591430543184808
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([10.953857 ,  8.3887   ,  3.7862298], dtype=float32)}
done in step count: 235
reward sum = 0.0942476934556249
running average episode reward sum: 0.6011505406740756
{'scaleFactor': 30, 'timeStep': 236, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([0.8350304, 5.561677 , 4.963277 ], dtype=float32)}
episode index:677
target Thresh 14.593468291851908
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([1.9952635, 8.40091  , 1.5147116], dtype=float32)}
done in step count: 161
reward sum = 0.19827425658891443
running average episode reward sum: 0.6005563278656904
{'scaleFactor': 30, 'timeStep': 162, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([12.7826395,  5.7516623,  3.988162 ], dtype=float32)}
episode index:678
target Thresh 14.595495877205131
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([11.930721 ,  5.2353396,  1.0186496], dtype=float32)}
done in step count: 118
reward sum = 0.3054590259283046
running average episode reward sum: 0.6001217221190963
{'scaleFactor': 30, 'timeStep': 119, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([1.7144407, 6.5295076, 3.5121436], dtype=float32)}
episode index:679
target Thresh 14.597513349934216
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([12.021073  ,  4.0795555 ,  0.24215287], dtype=float32)}
done in step count: 357
reward sum = 0.027654414711223742
running average episode reward sum: 0.5992798584317317
{'scaleFactor': 30, 'timeStep': 358, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([3.7451189, 2.381473 , 4.5093327], dtype=float32)}
episode index:680
target Thresh 14.599520760476087
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([10.406428  ,  0.60008514,  3.49396   ], dtype=float32)}
done in step count: 194
reward sum = 0.14230748778208857
running average episode reward sum: 0.5986088270504547
{'scaleFactor': 30, 'timeStep': 195, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([8.887027 , 8.60599  , 3.1905265], dtype=float32)}
episode index:681
target Thresh 14.601518159016111
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([1.8419088, 5.0656815, 3.2775836], dtype=float32)}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.5990571749213615
{'scaleFactor': 30, 'timeStep': 11, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([ 4.7374983 , 10.27277   ,  0.33368772], dtype=float32)}
episode index:682
target Thresh 14.603505595489358
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([2.7715933, 7.5904903, 3.9876761], dtype=float32)}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.5996150707121061
{'scaleFactor': 30, 'timeStep': 3, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([2.6670356, 3.604579 , 4.5290375], dtype=float32)}
episode index:683
target Thresh 14.605483119581839
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([6.121617, 8.988837, 4.990307], dtype=float32)}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.6001713352286088
{'scaleFactor': 30, 'timeStep': 3, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([5.971658 , 9.195061 , 4.8368287], dtype=float32)}
episode index:684
target Thresh 14.607450780731762
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([6.1705065, 8.783487 , 5.292828 ], dtype=float32)}
done in step count: 134
reward sum = 0.26008546137772603
running average episode reward sum: 0.5996748595003594
{'scaleFactor': 30, 'timeStep': 135, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([12.152212 ,  6.0126905,  1.4303298], dtype=float32)}
episode index:685
target Thresh 14.609408628130758
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([12.150814 ,  9.072487 ,  6.1972084], dtype=float32)}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6001731179404478
{'scaleFactor': 30, 'timeStep': 7, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([13.183643,  5.128123,  5.090839], dtype=float32)}
episode index:686
target Thresh 14.611356710725115
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([11.932444 ,  6.964675 ,  4.7960596], dtype=float32)}
done in step count: 24
reward sum = 0.7856781408072188
running average episode reward sum: 0.600443139807794
{'scaleFactor': 30, 'timeStep': 25, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([7.687546, 7.309006, 3.278267], dtype=float32)}
episode index:687
target Thresh 14.613295077216998
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([2.0930152 , 4.910785  , 0.62948716], dtype=float32)}
done in step count: 49
reward sum = 0.611117239532865
running average episode reward sum: 0.6004586544876269
{'scaleFactor': 30, 'timeStep': 50, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([1.0202303, 3.258519 , 5.374685 ], dtype=float32)}
episode index:688
target Thresh 14.61522377606567
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([6.735564 , 9.0588045, 2.4710956], dtype=float32)}
done in step count: 67
reward sum = 0.5099857462495653
running average episode reward sum: 0.600327344025743
{'scaleFactor': 30, 'timeStep': 68, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([10.071901,  9.247879,  5.433165], dtype=float32)}
episode index:689
target Thresh 14.617142855488703
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([12.258986 ,  3.9524543,  0.5732156], dtype=float32)}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6008217683813593
{'scaleFactor': 30, 'timeStep': 7, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([8.140576 , 8.008101 , 3.0974042], dtype=float32)}
episode index:690
target Thresh 14.619052363463185
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([12.018597 ,  2.0753212,  3.2366498], dtype=float32)}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.6012742944003207
{'scaleFactor': 30, 'timeStep': 10, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([12.138571 ,  4.3639092,  1.6494564], dtype=float32)}
episode index:691
target Thresh 14.620952347726911
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([5.046082  , 9.873551  , 0.23496321], dtype=float32)}
done in step count: 37
reward sum = 0.6894490858690777
running average episode reward sum: 0.6014017146192061
{'scaleFactor': 30, 'timeStep': 38, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([11.191163  ,  8.258455  ,  0.75092566], dtype=float32)}
episode index:692
target Thresh 14.622842855779586
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([5.148895 , 8.886121 , 3.6370075], dtype=float32)}
done in step count: 245
reward sum = 0.08523592457219176
running average episode reward sum: 0.6006568866393402
{'scaleFactor': 30, 'timeStep': 246, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([0.3002906, 5.0987287, 4.5457673], dtype=float32)}
episode index:693
target Thresh 14.624723934884015
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([2.386149 , 7.6444592, 3.350444 ], dtype=float32)}
done in step count: 26
reward sum = 0.7700431458051551
running average episode reward sum: 0.6009009590588876
{'scaleFactor': 30, 'timeStep': 27, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([9.381095 , 8.262512 , 1.1708772], dtype=float32)}
episode index:694
target Thresh 14.62659563206727
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([11.925392 ,  4.0735803,  5.0481453], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6014752022832633
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([11.925392 ,  4.0735803,  5.0481453], dtype=float32)}
episode index:695
target Thresh 14.628457994121877
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([ 8.003884, 10.001697,  5.033973], dtype=float32)}
done in step count: 399
reward sum = 0.0
running average episode reward sum: 0.6006110137742356
{'scaleFactor': 30, 'timeStep': 400, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([10.328862 ,  6.990842 ,  1.0292257], dtype=float32)}
episode index:696
target Thresh 14.630311067606987
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([1.7774311, 3.8453393, 5.2560773], dtype=float32)}
done in step count: 315
reward sum = 0.04217803066508771
running average episode reward sum: 0.5998098186765181
{'scaleFactor': 30, 'timeStep': 316, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([12.563469 ,  3.5993538,  4.458185 ], dtype=float32)}
episode index:697
target Thresh 14.632154898849533
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([10.047956  ,  9.131909  ,  0.05586022], dtype=float32)}
done in step count: 32
reward sum = 0.7249803359578534
running average episode reward sum: 0.5999891460651733
{'scaleFactor': 30, 'timeStep': 33, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([5.1963577, 8.3786545, 3.0014603], dtype=float32)}
episode index:698
target Thresh 14.63398953394539
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([12.010867 ,  2.971548 ,  6.1046853], dtype=float32)}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.6004508850470942
{'scaleFactor': 30, 'timeStep': 9, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([13.972395 ,  7.931265 ,  2.1154034], dtype=float32)}
episode index:699
target Thresh 14.635815018760534
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([2.9629264, 9.850131 , 2.537929 ], dtype=float32)}
done in step count: 136
reward sum = 0.2549097606963093
running average episode reward sum: 0.5999572548694503
{'scaleFactor': 30, 'timeStep': 137, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([11.350378,  6.276087,  5.237338], dtype=float32)}
episode index:700
target Thresh 14.637631398932179
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([7.0711837 , 9.068842  , 0.05563962], dtype=float32)}
done in step count: 14
reward sum = 0.8687458127689782
running average episode reward sum: 0.6003406907580373
{'scaleFactor': 30, 'timeStep': 15, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([5.46447  , 9.1774025, 2.7887957], dtype=float32)}
episode index:701
target Thresh 14.639438719869922
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([12.045698 ,  2.8803523,  3.845945 ], dtype=float32)}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.60079995572053
{'scaleFactor': 30, 'timeStep': 9, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([12.691684 ,  7.590655 ,  1.3885258], dtype=float32)}
episode index:702
target Thresh 14.641237026756885
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([12.04759  ,  6.1362324,  4.4162498], dtype=float32)}
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.6012189291181661
{'scaleFactor': 30, 'timeStep': 12, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([9.304933 , 7.2841134, 2.9539108], dtype=float32)}
episode index:703
target Thresh 14.64302636455083
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([ 6.9479117, 10.242294 ,  3.1634223], dtype=float32)}
done in step count: 106
reward sum = 0.3446121833475176
running average episode reward sum: 0.6008544308997419
{'scaleFactor': 30, 'timeStep': 107, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([13.869811 ,  1.6566807,  4.598635 ], dtype=float32)}
episode index:704
target Thresh 14.644806777985297
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([4.3211718, 9.177578 , 5.874883 ], dtype=float32)}
done in step count: 140
reward sum = 0.24486529903492948
running average episode reward sum: 0.6003494817765294
{'scaleFactor': 30, 'timeStep': 141, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([13.925963,  7.844791,  5.0174  ], dtype=float32)}
episode index:705
target Thresh 14.646578311570712
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([12.589683 ,  9.190622 ,  5.9281964], dtype=float32)}
done in step count: 83
reward sum = 0.43423132679181164
running average episode reward sum: 0.6001141869394405
{'scaleFactor': 30, 'timeStep': 84, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([2.8380554, 7.5761514, 2.7514954], dtype=float32)}
episode index:706
target Thresh 14.64834100959551
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([12.575426 ,  8.0585   ,  4.9542184], dtype=float32)}
done in step count: 54
reward sum = 0.5811664141181095
running average episode reward sum: 0.6000873866949974
{'scaleFactor': 30, 'timeStep': 55, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([2.7914016, 9.87089  , 5.765365 ], dtype=float32)}
episode index:707
target Thresh 14.650094916127234
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([ 9.999275  , 10.431025  ,  0.32068366], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.6006381107250892
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([12.052549 , 10.36688  ,  6.1378417], dtype=float32)}
episode index:708
target Thresh 14.651840075013634
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([12.029283 ,  6.844941 ,  1.9719414], dtype=float32)}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.6011458087494544
{'scaleFactor': 30, 'timeStep': 5, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([ 7.2595906, 10.118402 ,  2.1342342], dtype=float32)}
episode index:709
target Thresh 14.653576529883779
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([1.8992218, 4.8537254, 1.9261769], dtype=float32)}
done in step count: 135
reward sum = 0.25748460676394874
running average episode reward sum: 0.600661778887503
{'scaleFactor': 30, 'timeStep': 136, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([ 8.536417  , 10.354277  ,  0.71133685], dtype=float32)}
episode index:710
target Thresh 14.655304324149126
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([9.149465, 8.841813, 3.638258], dtype=float32)}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.6011680154994756
{'scaleFactor': 30, 'timeStep': 5, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([5.257248 , 9.066878 , 3.6872053], dtype=float32)}
episode index:711
target Thresh 14.657023501004625
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([1.6311414, 4.3105516, 2.8239083], dtype=float32)}
done in step count: 42
reward sum = 0.6556592205741436
running average episode reward sum: 0.6012445480908726
{'scaleFactor': 30, 'timeStep': 43, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([10.233734 ,  9.076855 ,  5.9897676], dtype=float32)}
episode index:712
target Thresh 14.658734103429786
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([ 2.1681206, 10.196254 ,  2.0809994], dtype=float32)}
done in step count: 159
reward sum = 0.2023000271287771
running average episode reward sum: 0.6006850186084574
{'scaleFactor': 30, 'timeStep': 160, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([5.373723 , 7.3424377, 6.032052 ], dtype=float32)}
episode index:713
target Thresh 14.660436174189757
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([2.0117056, 3.919926 , 3.7544193], dtype=float32)}
done in step count: 65
reward sum = 0.5203405226503064
running average episode reward sum: 0.6005724913031938
{'scaleFactor': 30, 'timeStep': 66, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([4.2528405, 7.0137405, 3.2098951], dtype=float32)}
episode index:714
target Thresh 14.6621297558364
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([3.463251 , 7.9923153, 5.340528 ], dtype=float32)}
done in step count: 121
reward sum = 0.296386587399208
running average episode reward sum: 0.6001470564725587
{'scaleFactor': 30, 'timeStep': 122, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([13.526899  ,  8.186857  ,  0.42583317], dtype=float32)}
episode index:715
target Thresh 14.663814890709338
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([4.753114, 8.996299, 5.191122], dtype=float32)}
done in step count: 48
reward sum = 0.617290140942288
running average episode reward sum: 0.6001709993279634
{'scaleFactor': 30, 'timeStep': 49, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([9.9476271e+00, 1.0323334e+01, 2.8709173e-03], dtype=float32)}
episode index:716
target Thresh 14.665491620937035
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([2.0785635, 4.7926626, 5.284951 ], dtype=float32)}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.6006872169021225
{'scaleFactor': 30, 'timeStep': 4, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([2.2730706, 5.1829205, 4.914264 ], dtype=float32)}
episode index:717
target Thresh 14.667159988437835
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([2.6641514, 8.922156 , 5.3837404], dtype=float32)}
done in step count: 20
reward sum = 0.8179069375972308
running average episode reward sum: 0.6009897513320599
{'scaleFactor': 30, 'timeStep': 21, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([11.10324   ,  8.951418  ,  0.86330104], dtype=float32)}
episode index:718
target Thresh 14.668820034921008
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([3.1796803, 9.924432 , 2.5992746], dtype=float32)}
done in step count: 63
reward sum = 0.5309055429551132
running average episode reward sum: 0.6008922767724257
{'scaleFactor': 30, 'timeStep': 64, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([ 9.036009 , 10.868737 ,  1.3940637], dtype=float32)}
episode index:719
target Thresh 14.670471801887807
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([2.0985332, 5.0496664, 1.5411253], dtype=float32)}
done in step count: 296
reward sum = 0.0510525689892109
running average episode reward sum: 0.6001286105116157
{'scaleFactor': 30, 'timeStep': 297, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([13.919236 ,  3.2365642,  4.211447 ], dtype=float32)}
episode index:720
target Thresh 14.672115330632488
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([2.0738392, 9.772289 , 2.2215292], dtype=float32)}
done in step count: 69
reward sum = 0.4998370298991989
running average episode reward sum: 0.5999895098450243
{'scaleFactor': 30, 'timeStep': 70, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([13.2752905,  6.9972897,  5.6148944], dtype=float32)}
episode index:721
target Thresh 14.673750662243359
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([11.801587,  8.05311 ,  3.647676], dtype=float32)}
done in step count: 204
reward sum = 0.12870034108965533
running average episode reward sum: 0.5993367547636457
{'scaleFactor': 30, 'timeStep': 205, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([1.7020042, 5.786907 , 4.6564946], dtype=float32)}
episode index:722
target Thresh 14.675377837603795
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([3.0478714, 8.977087 , 3.7937903], dtype=float32)}
done in step count: 77
reward sum = 0.46122196741809546
running average episode reward sum: 0.5991457246290045
{'scaleFactor': 30, 'timeStep': 78, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([10.132752 , 10.710837 ,  5.4029083], dtype=float32)}
episode index:723
target Thresh 14.676996897393263
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([4.837864 , 8.991449 , 4.5662937], dtype=float32)}
done in step count: 114
reward sum = 0.3179890638191435
running average episode reward sum: 0.5987573866997091
{'scaleFactor': 30, 'timeStep': 115, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([ 8.236868  , 11.108764  ,  0.49756083], dtype=float32)}
episode index:724
target Thresh 14.678607882088341
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([12.034863,  5.135272,  3.672705], dtype=float32)}
done in step count: 42
reward sum = 0.6556592205741436
running average episode reward sum: 0.5988358719878119
{'scaleFactor': 30, 'timeStep': 43, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([8.14867  , 9.024328 , 1.9692619], dtype=float32)}
episode index:725
target Thresh 14.680210831963734
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([11.995601,  5.984531,  6.06784 ], dtype=float32)}
done in step count: 17
reward sum = 0.8429431933839268
running average episode reward sum: 0.5991721079676963
{'scaleFactor': 30, 'timeStep': 18, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([9.449951 , 7.547766 , 2.5632696], dtype=float32)}
episode index:726
target Thresh 14.68180578709327
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([11.992054 ,  8.912859 ,  1.1074319], dtype=float32)}
done in step count: 49
reward sum = 0.611117239532865
running average episode reward sum: 0.5991885386851173
{'scaleFactor': 30, 'timeStep': 50, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([9.779371 , 8.811687 , 1.7758269], dtype=float32)}
episode index:727
target Thresh 14.68339278735091
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([7.033408, 8.72113 , 0.762759], dtype=float32)}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5996717825192037
{'scaleFactor': 30, 'timeStep': 6, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([9.226282 , 9.015216 , 5.7706685], dtype=float32)}
episode index:728
target Thresh 14.684971872411744
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([3.070145 , 9.971285 , 2.0461593], dtype=float32)}
done in step count: 213
reward sum = 0.11756998134242766
running average episode reward sum: 0.5990104631760258
{'scaleFactor': 30, 'timeStep': 214, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([2.0335827, 5.1573772, 3.5985096], dtype=float32)}
episode index:729
target Thresh 14.686543081752982
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([1.9789095 , 4.159804  , 0.69686174], dtype=float32)}
done in step count: 125
reward sum = 0.28470777327319546
running average episode reward sum: 0.5985799115460219
{'scaleFactor': 30, 'timeStep': 126, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([ 5.0149646, 10.252819 ,  1.616538 ], dtype=float32)}
episode index:730
target Thresh 14.688106454654935
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([11.032527,  8.957416,  2.694316], dtype=float32)}
done in step count: 23
reward sum = 0.7936142836436554
running average episode reward sum: 0.5988467164326123
{'scaleFactor': 30, 'timeStep': 24, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([11.993524 ,  6.2035947,  5.1056447], dtype=float32)}
episode index:731
target Thresh 14.689662030202014
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([10.434402 ,  8.477009 ,  2.0360367], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.5993947400440433
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([10.434402 ,  8.477009 ,  2.0360367], dtype=float32)}
episode index:732
target Thresh 14.69120984728368
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([11.994609 ,  8.186654 ,  4.0572057], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.5999412683659476
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([11.994609 ,  8.186654 ,  4.0572057], dtype=float32)}
episode index:733
target Thresh 14.692749944595448
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([1.8981954, 7.962884 , 4.9107404], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.6004726835316616
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([2.0264244, 8.054505 , 4.364879 ], dtype=float32)}
episode index:734
target Thresh 14.694282360639829
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([2.0535023, 8.43796  , 3.249837 ], dtype=float32)}
done in step count: 41
reward sum = 0.6622820409839835
running average episode reward sum: 0.6005567778955423
{'scaleFactor': 30, 'timeStep': 42, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([ 6.0811877, 10.225826 ,  3.4867954], dtype=float32)}
episode index:735
target Thresh 14.695807133727302
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([11.823894,  8.860609,  2.513986], dtype=float32)}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6010329100585918
{'scaleFactor': 30, 'timeStep': 6, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([ 2.3925877, 10.898421 ,  3.0425198], dtype=float32)}
episode index:736
target Thresh 14.697324301977272
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([13.658464,  4.893315,  5.196588], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6015742493936548
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([13.658464,  4.893315,  5.196588], dtype=float32)}
episode index:737
target Thresh 14.69883390331903
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([12.185164 ,  8.285544 ,  3.2784085], dtype=float32)}
done in step count: 57
reward sum = 0.5639051904523875
running average episode reward sum: 0.6015232073083685
{'scaleFactor': 30, 'timeStep': 58, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([13.231194 ,  4.9874463,  6.162673 ], dtype=float32)}
episode index:738
target Thresh 14.700335975492687
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([ 2.8245647, 10.039342 ,  4.7373548], dtype=float32)}
done in step count: 57
reward sum = 0.5639051904523875
running average episode reward sum: 0.6014723033613374
{'scaleFactor': 30, 'timeStep': 58, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([13.165487 ,  3.5482001,  4.924851 ], dtype=float32)}
episode index:739
target Thresh 14.701830556050123
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([7.209666 , 9.697211 , 3.6615307], dtype=float32)}
done in step count: 18
reward sum = 0.8345137614500875
running average episode reward sum: 0.6017872242506465
{'scaleFactor': 30, 'timeStep': 19, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([1.2447724, 5.983402 , 4.0619583], dtype=float32)}
episode index:740
target Thresh 14.703317682355927
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([3.9233742, 9.908007 , 1.1175666], dtype=float32)}
done in step count: 56
reward sum = 0.5696012024771592
running average episode reward sum: 0.6017437883238267
{'scaleFactor': 30, 'timeStep': 57, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([12.97939  ,  7.7595873,  4.8395634], dtype=float32)}
episode index:741
target Thresh 14.704797391588341
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([10.998389,  8.998241,  5.103699], dtype=float32)}
done in step count: 51
reward sum = 0.598956006466161
running average episode reward sum: 0.6017400312054202
{'scaleFactor': 30, 'timeStep': 52, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([3.3395133, 7.3665943, 4.0474124], dtype=float32)}
episode index:742
target Thresh 14.706269720740169
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([11.876113 ,  9.070597 ,  6.1330724], dtype=float32)}
done in step count: 33
reward sum = 0.7177305325982749
running average episode reward sum: 0.6018961422436341
{'scaleFactor': 30, 'timeStep': 34, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([ 3.919936 , 10.856789 ,  0.8505951], dtype=float32)}
episode index:743
target Thresh 14.707734706619714
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([13.056505 ,  2.0917275,  4.869625 ], dtype=float32)}
done in step count: 199
reward sum = 0.13533300490703204
running average episode reward sum: 0.6012690412525902
{'scaleFactor': 30, 'timeStep': 200, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([3.9465964, 5.951115 , 4.805034 ], dtype=float32)}
episode index:744
target Thresh 14.709192385851706
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([2.063828 , 5.8446326, 5.5513864], dtype=float32)}
done in step count: 51
reward sum = 0.598956006466161
running average episode reward sum: 0.6012659365079104
{'scaleFactor': 30, 'timeStep': 52, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([7.5122175, 7.0752015, 5.82588  ], dtype=float32)}
episode index:745
target Thresh 14.710642794878197
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([3.0134845, 8.940951 , 3.0200098], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6018004325715727
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([3.0134845, 8.940951 , 3.0200098], dtype=float32)}
episode index:746
target Thresh 14.712085969959489
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([13.868443 ,  5.508952 ,  6.2780194], dtype=float32)}
done in step count: 331
reward sum = 0.0359128119792669
running average episode reward sum: 0.6010428855560541
{'scaleFactor': 30, 'timeStep': 332, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([1.5170108, 5.942042 , 5.277929 ], dtype=float32)}
episode index:747
target Thresh 14.713521947175035
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([5.4275327, 8.945438 , 3.4745505], dtype=float32)}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.6015496464042411
{'scaleFactor': 30, 'timeStep': 3, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([3.3003438, 9.525808 , 2.8302693], dtype=float32)}
episode index:748
target Thresh 14.71495076242434
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([9.159969 , 8.769733 , 1.9479764], dtype=float32)}
done in step count: 22
reward sum = 0.8016305895390459
running average episode reward sum: 0.6018167771694412
{'scaleFactor': 30, 'timeStep': 23, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([0.17842948, 7.1253567 , 4.3273644 ], dtype=float32)}
episode index:749
target Thresh 14.716372451427858
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([ 8.403352 , 10.891459 ,  2.4568124], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6023476881332153
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([ 8.403352 , 10.891459 ,  2.4568124], dtype=float32)}
episode index:750
target Thresh 14.71778704972789
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([12.037542 ,  2.0167074,  5.4636765], dtype=float32)}
done in step count: 295
reward sum = 0.05156825150425344
running average episode reward sum: 0.6016142934106734
{'scaleFactor': 30, 'timeStep': 296, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([3.3293786, 7.7339153, 4.051431 ], dtype=float32)}
episode index:751
target Thresh 14.719194592689467
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([5.840741, 9.29793 , 5.983546], dtype=float32)}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.6021045656268826
{'scaleFactor': 30, 'timeStep': 4, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([11.232403 ,  6.8016105,  5.2959523], dtype=float32)}
episode index:752
target Thresh 14.720595115501236
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([12.028842 ,  9.7790985,  1.7003212], dtype=float32)}
done in step count: 86
reward sum = 0.421334222154768
running average episode reward sum: 0.601864498769682
{'scaleFactor': 30, 'timeStep': 87, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([8.483361 , 9.255548 , 3.9690976], dtype=float32)}
episode index:753
target Thresh 14.72198865317634
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([ 2.9346352 , 10.087362  ,  0.27170193], dtype=float32)}
done in step count: 22
reward sum = 0.8016305895390459
running average episode reward sum: 0.6021294405346281
{'scaleFactor': 30, 'timeStep': 23, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([1.6676772, 4.744154 , 4.0530043], dtype=float32)}
episode index:754
target Thresh 14.723375240553294
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([13.572762  ,  3.038012  ,  0.48228502], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6026564214080922
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([13.572762  ,  3.038012  ,  0.48228502], dtype=float32)}
episode index:755
target Thresh 14.724754912296852
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([4.106865, 9.075464, 3.006704], dtype=float32)}
done in step count: 16
reward sum = 0.8514577710948755
running average episode reward sum: 0.6029855237224927
{'scaleFactor': 30, 'timeStep': 17, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([8.192629 , 8.053677 , 0.1989538], dtype=float32)}
episode index:756
target Thresh 14.726127702898884
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([5.1551094, 9.790075 , 3.5956306], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6035099814190283
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([5.1551094, 9.790075 , 3.5956306], dtype=float32)}
episode index:757
target Thresh 14.727493646679225
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([11.923765  , 10.259568  ,  0.65660924], dtype=float32)}
done in step count: 399
reward sum = 0.0
running average episode reward sum: 0.6027137941084492
{'scaleFactor': 30, 'timeStep': 400, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([10.694764  ,  5.711931  ,  0.45985666], dtype=float32)}
episode index:758
target Thresh 14.728852777786537
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([1.5350031, 2.0045633, 2.4686182], dtype=float32)}
done in step count: 208
reward sum = 0.12362903413636196
running average episode reward sum: 0.6020825888910947
{'scaleFactor': 30, 'timeStep': 209, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([10.4637375,  3.3355181,  4.817546 ], dtype=float32)}
episode index:759
target Thresh 14.730205130199174
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([12.158813 ,  9.9123   ,  1.7608804], dtype=float32)}
done in step count: 41
reward sum = 0.6622820409839835
running average episode reward sum: 0.6021617986964801
{'scaleFactor': 30, 'timeStep': 42, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([11.429039 ,  7.9309516,  5.8504972], dtype=float32)}
episode index:760
target Thresh 14.731550737726014
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([2.2687492, 1.9809165, 5.4487014], dtype=float32)}
done in step count: 222
reward sum = 0.10740220574263752
running average episode reward sum: 0.6015116546847142
{'scaleFactor': 30, 'timeStep': 223, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([9.4546204e+00, 1.1734124e+01, 6.0394416e-03], dtype=float32)}
episode index:761
target Thresh 14.732889634007313
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([12.084505 ,  5.9062214,  3.6122007], dtype=float32)}
done in step count: 31
reward sum = 0.7323033696543975
running average episode reward sum: 0.6016832973552781
{'scaleFactor': 30, 'timeStep': 32, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([9.534573 , 8.542495 , 1.9167892], dtype=float32)}
episode index:762
target Thresh 14.734221852515553
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([2.0931234, 6.9581203, 4.3453965], dtype=float32)}
done in step count: 86
reward sum = 0.421334222154768
running average episode reward sum: 0.6014469289736262
{'scaleFactor': 30, 'timeStep': 87, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([6.48336   , 8.562282  , 0.04471796], dtype=float32)}
episode index:763
target Thresh 14.735547426556261
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([7.873777 , 8.801689 , 2.3168364], dtype=float32)}
done in step count: 95
reward sum = 0.38489607889348454
running average episode reward sum: 0.6011634854525789
{'scaleFactor': 30, 'timeStep': 96, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([9.200368 , 7.1459637, 5.7163754], dtype=float32)}
episode index:764
target Thresh 14.73686638926886
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([6.926991 , 8.960969 , 4.2414846], dtype=float32)}
done in step count: 52
reward sum = 0.5929664464014994
running average episode reward sum: 0.6011527703688521
{'scaleFactor': 30, 'timeStep': 53, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([11.279562 ,  4.577438 ,  4.0888577], dtype=float32)}
episode index:765
target Thresh 14.738178773627487
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([ 8.186538 , 10.443881 ,  2.7129483], dtype=float32)}
done in step count: 37
reward sum = 0.6894490858690777
running average episode reward sum: 0.6012680397102361
{'scaleFactor': 30, 'timeStep': 38, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([0.20850351, 8.961092  , 4.513031  ], dtype=float32)}
episode index:766
target Thresh 14.739484612441817
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([10.027736, 10.078694,  4.219735], dtype=float32)}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6017240006100923
{'scaleFactor': 30, 'timeStep': 6, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([6.899987 , 8.748851 , 3.0161045], dtype=float32)}
episode index:767
target Thresh 14.74078393835789
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([1.9685204, 8.878045 , 2.795559 ], dtype=float32)}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6021663914288305
{'scaleFactor': 30, 'timeStep': 7, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([0.4722649, 7.339005 , 3.5332131], dtype=float32)}
episode index:768
target Thresh 14.742076783858922
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([2.169302 , 2.0126858, 4.4380527], dtype=float32)}
done in step count: 117
reward sum = 0.30854447063465107
running average episode reward sum: 0.6017845683848849
{'scaleFactor': 30, 'timeStep': 118, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([12.390277 ,  7.503795 ,  5.0940175], dtype=float32)}
episode index:769
target Thresh 14.743363181266114
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([ 5.096442 , 10.031583 ,  3.0500946], dtype=float32)}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.6022758871272422
{'scaleFactor': 30, 'timeStep': 3, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([3.6184578, 9.022614 , 3.4794984], dtype=float32)}
episode index:770
target Thresh 14.744643162739475
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([0.43752754, 9.238393  , 2.3141842 ], dtype=float32)}
done in step count: 18
reward sum = 0.8345137614500875
running average episode reward sum: 0.6025771035660527
{'scaleFactor': 30, 'timeStep': 19, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([3.324842, 8.373321, 5.854101], dtype=float32)}
episode index:771
target Thresh 14.745916760278602
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([7.7067285, 7.1104374, 4.9493246], dtype=float32)}
done in step count: 103
reward sum = 0.355160814705073
running average episode reward sum: 0.6022566161452483
{'scaleFactor': 30, 'timeStep': 104, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([9.389623 , 8.497149 , 0.7392129], dtype=float32)}
episode index:772
target Thresh 14.747184005723502
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([10.070443 ,  5.524475 ,  3.4415343], dtype=float32)}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.6026474640868571
{'scaleFactor': 30, 'timeStep': 11, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([3.9574761, 7.3680973, 3.450407 ], dtype=float32)}
episode index:773
target Thresh 14.74844493075538
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([6.3686457, 9.811377 , 2.3246932], dtype=float32)}
done in step count: 34
reward sum = 0.7105532272722921
running average episode reward sum: 0.6027868772175876
{'scaleFactor': 30, 'timeStep': 35, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([10.174622 , 11.263086 ,  6.1155596], dtype=float32)}
episode index:774
target Thresh 14.749699566897423
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([ 7.1460238, 11.851465 ,  1.7907426], dtype=float32)}
done in step count: 41
reward sum = 0.6622820409839835
running average episode reward sum: 0.6028636451708346
{'scaleFactor': 30, 'timeStep': 42, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([11.640546 ,  2.0132542,  4.500285 ], dtype=float32)}
episode index:775
target Thresh 14.750947945515604
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([ 9.546211 , 11.101337 ,  2.1479175], dtype=float32)}
done in step count: 89
reward sum = 0.40882017442254925
running average episode reward sum: 0.602613589151829
{'scaleFactor': 30, 'timeStep': 90, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([4.516815 , 7.327849 , 1.1884704], dtype=float32)}
episode index:776
target Thresh 14.75219009781945
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([12.014116 ,  2.7119956,  2.8145282], dtype=float32)}
done in step count: 15
reward sum = 0.8600583546412884
running average episode reward sum: 0.6029449208963457
{'scaleFactor': 30, 'timeStep': 16, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([10.537222 ,  5.500924 ,  1.2678025], dtype=float32)}
episode index:777
target Thresh 14.753426054862834
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([11.339873 ,  9.921    ,  3.5036163], dtype=float32)}
done in step count: 22
reward sum = 0.8016305895390459
running average episode reward sum: 0.6032003009331615
{'scaleFactor': 30, 'timeStep': 23, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([10.910293 ,  4.7442265,  5.151437 ], dtype=float32)}
episode index:778
target Thresh 14.754655847544749
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([10.402472 ,  7.167715 ,  3.7735598], dtype=float32)}
done in step count: 185
reward sum = 0.15577974928671173
running average episode reward sum: 0.6026259484920236
{'scaleFactor': 30, 'timeStep': 186, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([ 3.9326823, 10.06962  ,  2.9444337], dtype=float32)}
episode index:779
target Thresh 14.755879506610073
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([3.1718392, 3.4424233, 1.2960954], dtype=float32)}
done in step count: 62
reward sum = 0.536268225207185
running average episode reward sum: 0.6025408744878122
{'scaleFactor': 30, 'timeStep': 63, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([ 9.755697 , 10.050088 ,  5.6919227], dtype=float32)}
episode index:780
target Thresh 14.757097062650347
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([6.973252, 8.949095, 4.40653 ], dtype=float32)}
done in step count: 23
reward sum = 0.7936142836436554
running average episode reward sum: 0.6027855267402524
{'scaleFactor': 30, 'timeStep': 24, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([3.0453372, 8.513495 , 1.4785714], dtype=float32)}
episode index:781
target Thresh 14.758308546104537
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([3.9827127 , 7.405009  , 0.12699969], dtype=float32)}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.6032430849029887
{'scaleFactor': 30, 'timeStep': 5, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([11.685908  ,  9.25606   ,  0.33660156], dtype=float32)}
episode index:782
target Thresh 14.759513987259792
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([10.932075 ,  4.815712 ,  1.9017054], dtype=float32)}
done in step count: 121
reward sum = 0.296386587399208
running average episode reward sum: 0.6028511864387438
{'scaleFactor': 30, 'timeStep': 122, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([2.9733129, 8.945405 , 3.5138752], dtype=float32)}
episode index:783
target Thresh 14.760713416252202
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([1.8207589, 4.927186 , 4.673228 ], dtype=float32)}
done in step count: 295
reward sum = 0.05156825150425344
running average episode reward sum: 0.6021480194298987
{'scaleFactor': 30, 'timeStep': 296, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([12.161841 ,  3.5891583,  4.762666 ], dtype=float32)}
episode index:784
target Thresh 14.761906863067557
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([1.8989251, 9.050659 , 2.4313939], dtype=float32)}
done in step count: 37
reward sum = 0.6894490858690777
running average episode reward sum: 0.6022592309795027
{'scaleFactor': 30, 'timeStep': 38, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([ 7.246917 , 11.934177 ,  2.6205058], dtype=float32)}
episode index:785
target Thresh 14.763094357542085
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([7.925869 , 8.901274 , 0.3390595], dtype=float32)}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.60270290886617
{'scaleFactor': 30, 'timeStep': 6, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([11.7765875,  4.913966 ,  5.076278 ], dtype=float32)}
episode index:786
target Thresh 14.764275929363215
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([ 8.846528, 10.137841,  2.571549], dtype=float32)}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.6031699941153871
{'scaleFactor': 30, 'timeStep': 4, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([7.150721 , 9.75149  , 3.4049098], dtype=float32)}
episode index:787
target Thresh 14.765451608070302
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([8.341624 , 9.049218 , 3.9639654], dtype=float32)}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6035993217236175
{'scaleFactor': 30, 'timeStep': 7, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([10.932058 ,  7.1810184,  6.218326 ], dtype=float32)}
episode index:788
target Thresh 14.766621423055376
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([2.0155575, 8.824071 , 4.8830686], dtype=float32)}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.6039805419432439
{'scaleFactor': 30, 'timeStep': 11, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([10.79434  ,  9.567816 ,  0.6194421], dtype=float32)}
episode index:789
target Thresh 14.76778540356387
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([8.769957, 9.980147, 6.192955], dtype=float32)}
done in step count: 75
reward sum = 0.4705866415856499
running average episode reward sum: 0.6038116889048166
{'scaleFactor': 30, 'timeStep': 76, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([ 6.603915 , 11.071635 ,  3.9196143], dtype=float32)}
episode index:790
target Thresh 14.768943578695357
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([3.8676279 , 6.113727  , 0.43636847], dtype=float32)}
done in step count: 37
reward sum = 0.6894490858690777
running average episode reward sum: 0.603919953629171
{'scaleFactor': 30, 'timeStep': 38, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([ 9.640744 , 11.5801115,  6.0974092], dtype=float32)}
episode index:791
target Thresh 14.770095977404278
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([3.8016448 , 4.68607   , 0.34370947], dtype=float32)}
done in step count: 83
reward sum = 0.43423132679181164
running average episode reward sum: 0.6037057003124571
{'scaleFactor': 30, 'timeStep': 84, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([3.8429165 , 9.553418  , 0.10304087], dtype=float32)}
episode index:792
target Thresh 14.77124262850066
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([2.1187932, 2.1156795, 6.0480638], dtype=float32)}
done in step count: 319
reward sum = 0.0405160479665409
running average episode reward sum: 0.602995498985413
{'scaleFactor': 30, 'timeStep': 320, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([13.369033,  4.349086,  4.214021], dtype=float32)}
episode index:793
target Thresh 14.772383560650841
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([11.806342 ,  1.9605703,  4.8540072], dtype=float32)}
done in step count: 39
reward sum = 0.6757290490602831
running average episode reward sum: 0.6030871029527618
{'scaleFactor': 30, 'timeStep': 40, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([12.568149 ,  9.92441  ,  1.7738491], dtype=float32)}
episode index:794
target Thresh 14.773518802378183
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([2.0150113, 7.9118695, 2.5494227], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6035863644584816
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([2.0150113, 7.9118695, 2.5494227], dtype=float32)}
episode index:795
target Thresh 14.774648382063788
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([ 3.2030714, 10.122287 ,  1.0064772], dtype=float32)}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.6040348690383076
{'scaleFactor': 30, 'timeStep': 5, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([ 8.022027  , 11.987895  ,  0.44940728], dtype=float32)}
episode index:796
target Thresh 14.775772327947207
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([12.814989 ,  6.788432 ,  0.9535993], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.6045191414736423
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([13.833197  ,  8.75555   ,  0.70959294], dtype=float32)}
episode index:797
target Thresh 14.776890668127146
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([1.896005 , 4.076396 , 5.8991513], dtype=float32)}
done in step count: 37
reward sum = 0.6894490858690777
running average episode reward sum: 0.604625569975391
{'scaleFactor': 30, 'timeStep': 38, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([2.369473 , 8.769526 , 1.6812432], dtype=float32)}
episode index:798
target Thresh 14.778003430562169
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([1.8934522, 9.911633 , 1.891418 ], dtype=float32)}
done in step count: 140
reward sum = 0.24486529903492948
running average episode reward sum: 0.6041753068077559
{'scaleFactor': 30, 'timeStep': 141, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([1.5525818, 3.7776747, 4.818254 ], dtype=float32)}
episode index:799
target Thresh 14.779110643071395
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([8.993514  , 9.2642355 , 0.38436478], dtype=float32)}
done in step count: 59
reward sum = 0.5526834771623851
running average episode reward sum: 0.6041109420206991
{'scaleFactor': 30, 'timeStep': 60, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([0.17009778, 3.605497  , 5.038881  ], dtype=float32)}
episode index:800
target Thresh 14.780212333335191
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([ 3.9936752, 10.118534 ,  5.9859986], dtype=float32)}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.6045681056386509
{'scaleFactor': 30, 'timeStep': 4, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([ 9.231667  , 10.049571  ,  0.88633084], dtype=float32)}
episode index:801
target Thresh 14.781308528895872
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([2.0382404, 6.2376184, 2.8183994], dtype=float32)}
done in step count: 42
reward sum = 0.6556592205741436
running average episode reward sum: 0.6046318102707401
{'scaleFactor': 30, 'timeStep': 43, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([3.832358 , 8.438031 , 0.7365239], dtype=float32)}
episode index:802
target Thresh 14.782399257158387
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([4.0396514, 9.131873 , 4.740566 ], dtype=float32)}
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.6049826858142586
{'scaleFactor': 30, 'timeStep': 13, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([3.9409428, 3.1038513, 3.9135964], dtype=float32)}
episode index:803
target Thresh 14.783484545390998
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([3.9997559, 9.653662 , 6.0890756], dtype=float32)}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.6054370593393653
{'scaleFactor': 30, 'timeStep': 4, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([9.655758  , 9.37391   , 0.07418676], dtype=float32)}
episode index:804
target Thresh 14.784564420725966
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([4.426704, 8.596423, 5.863173], dtype=float32)}
done in step count: 44
reward sum = 0.6426116020847181
running average episode reward sum: 0.6054832388955708
{'scaleFactor': 30, 'timeStep': 45, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([ 7.639146  , 11.01301   ,  0.38266325], dtype=float32)}
episode index:805
target Thresh 14.785638910160232
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([8.95739   , 9.682671  , 0.35590476], dtype=float32)}
done in step count: 90
reward sum = 0.4047319726783238
running average episode reward sum: 0.6052341678456734
{'scaleFactor': 30, 'timeStep': 91, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([11.10592  ,  5.434278 ,  3.8457284], dtype=float32)}
episode index:806
target Thresh 14.786708040556087
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([2.095631 , 8.940812 , 1.1260478], dtype=float32)}
done in step count: 25
reward sum = 0.7778213593991467
running average episode reward sum: 0.6054480305365699
{'scaleFactor': 30, 'timeStep': 26, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([0.53176874, 4.908081  , 4.51637   ], dtype=float32)}
episode index:807
target Thresh 14.787771838641847
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([11.902175 ,  2.1327674,  1.3351245], dtype=float32)}
done in step count: 240
reward sum = 0.08962861870232462
running average episode reward sum: 0.6048096401753889
{'scaleFactor': 30, 'timeStep': 241, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([7.1669545, 9.045627 , 3.7562847], dtype=float32)}
episode index:808
target Thresh 14.788830331012518
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([1.9678367, 4.5867333, 4.390319 ], dtype=float32)}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6052141589735738
{'scaleFactor': 30, 'timeStep': 8, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([4.93236  , 7.6577325, 0.8494222], dtype=float32)}
episode index:809
target Thresh 14.789883544130468
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([2.0820308, 8.837178 , 3.8156016], dtype=float32)}
done in step count: 71
reward sum = 0.4898902730042049
running average episode reward sum: 0.6050717838057104
{'scaleFactor': 30, 'timeStep': 72, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([4.540156 , 8.065165 , 1.1538984], dtype=float32)}
episode index:810
target Thresh 14.790931504326078
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([7.9461517, 9.261042 , 4.542767 ], dtype=float32)}
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.6054296956065155
{'scaleFactor': 30, 'timeStep': 12, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([11.685156 ,  7.456865 ,  6.2204757], dtype=float32)}
episode index:811
target Thresh 14.791974237798406
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([6.072121 , 9.050996 , 3.5549896], dtype=float32)}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.6058790420404977
{'scaleFactor': 30, 'timeStep': 4, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([3.947962 , 7.8833027, 3.5214293], dtype=float32)}
episode index:812
target Thresh 14.793011770615845
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([2.0828247, 7.0824227, 4.705678 ], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.606351515543523
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([2.0226023, 4.884516 , 4.950025 ], dtype=float32)}
episode index:813
target Thresh 14.794044128716768
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([10.162323 , 10.104329 ,  3.0488849], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.6068228281779904
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([ 8.306388 , 10.014709 ,  3.5816274], dtype=float32)}
episode index:814
target Thresh 14.795071337910182
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([11.4180975,  9.999182 ,  2.0096276], dtype=float32)}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.6072688112109008
{'scaleFactor': 30, 'timeStep': 4, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([ 9.179918 , 10.554168 ,  2.7800443], dtype=float32)}
episode index:815
target Thresh 14.796093423876371
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([11.257867 ,  9.80579  ,  3.1191592], dtype=float32)}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.6077257121775541
{'scaleFactor': 30, 'timeStep': 3, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([7.4356265, 9.941059 , 3.3625262], dtype=float32)}
episode index:816
target Thresh 14.797110412167536
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([ 9.806911 , 10.593456 ,  0.6302902], dtype=float32)}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.6081576219668106
{'scaleFactor': 30, 'timeStep': 5, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([11.179053 , 11.827486 ,  0.4965952], dtype=float32)}
episode index:817
target Thresh 14.79812232820844
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([11.019579,  8.944467,  3.202116], dtype=float32)}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.6086123192504698
{'scaleFactor': 30, 'timeStep': 3, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([7.3385906, 8.025724 , 3.634911 ], dtype=float32)}
episode index:818
target Thresh 14.799129197297033
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([12.062797 ,  9.75892  ,  1.6872127], dtype=float32)}
done in step count: 115
reward sum = 0.31480917318095203
running average episode reward sum: 0.6082535852503849
{'scaleFactor': 30, 'timeStep': 116, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([4.2641015, 8.350804 , 2.6263566], dtype=float32)}
episode index:819
target Thresh 14.800131044605095
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([11.720463 ,  2.0545127,  4.3940487], dtype=float32)}
done in step count: 133
reward sum = 0.2627125872502283
running average episode reward sum: 0.607832193789409
{'scaleFactor': 30, 'timeStep': 134, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([ 9.78771  , 10.664487 ,  2.9457085], dtype=float32)}
episode index:820
target Thresh 14.801127895178864
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([2.1124094, 9.778532 , 4.9962387], dtype=float32)}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.6082736880722477
{'scaleFactor': 30, 'timeStep': 4, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([3.8802686, 6.265884 , 5.657705 ], dtype=float32)}
episode index:821
target Thresh 14.802119773939655
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([11.808497 ,  5.8287096,  0.648588 ], dtype=float32)}
done in step count: 17
reward sum = 0.8429431933839268
running average episode reward sum: 0.6085591740884418
{'scaleFactor': 30, 'timeStep': 18, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([8.226903 , 9.163315 , 2.5815043], dtype=float32)}
episode index:822
target Thresh 14.803106705684488
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([9.179275 , 8.925328 , 2.4210796], dtype=float32)}
done in step count: 204
reward sum = 0.12870034108965533
running average episode reward sum: 0.6079761135380181
{'scaleFactor': 30, 'timeStep': 205, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([11.220988,  5.366893,  4.654381], dtype=float32)}
episode index:823
target Thresh 14.804088715086708
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([ 7.9892683, 10.006265 ,  1.2799642], dtype=float32)}
done in step count: 109
reward sum = 0.334376856889913
running average episode reward sum: 0.6076440756051926
{'scaleFactor': 30, 'timeStep': 110, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([ 4.9839196, 10.680903 ,  2.351105 ], dtype=float32)}
episode index:824
target Thresh 14.805065826696602
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([ 1.8210135, 10.045466 ,  2.3235939], dtype=float32)}
done in step count: 121
reward sum = 0.296386587399208
running average episode reward sum: 0.6072667938013065
{'scaleFactor': 30, 'timeStep': 122, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([13.910911 ,  7.5021563,  4.6738887], dtype=float32)}
episode index:825
target Thresh 14.80603806494201
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([2.1393669, 8.835201 , 5.827674 ], dtype=float32)}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.6076945531429515
{'scaleFactor': 30, 'timeStep': 5, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([4.6876297, 8.580844 , 6.151811 ], dtype=float32)}
episode index:826
target Thresh 14.807005454128937
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([10.821512 , 10.032207 ,  1.9498583], dtype=float32)}
done in step count: 48
reward sum = 0.617290140942288
running average episode reward sum: 0.6077061560302542
{'scaleFactor': 30, 'timeStep': 49, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([ 6.4909534, 11.88132  ,  2.735843 ], dtype=float32)}
episode index:827
target Thresh 14.80796801844217
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([2.096367  , 9.881522  , 0.07047001], dtype=float32)}
done in step count: 76
reward sum = 0.46588077516979337
running average episode reward sum: 0.6075348693383937
{'scaleFactor': 30, 'timeStep': 77, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([12.598739 ,  3.5505607,  4.557168 ], dtype=float32)}
episode index:828
target Thresh 14.80892578194586
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([1.8838477, 9.830005 , 2.9497972], dtype=float32)}
done in step count: 16
reward sum = 0.8514577710948755
running average episode reward sum: 0.6078291068555909
{'scaleFactor': 30, 'timeStep': 17, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([6.538769 , 7.8758516, 5.3907485], dtype=float32)}
episode index:829
target Thresh 14.809878768584147
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([4.963827  , 8.980875  , 0.50710535], dtype=float32)}
done in step count: 29
reward sum = 0.7471720943315961
running average episode reward sum: 0.6079969899730318
{'scaleFactor': 30, 'timeStep': 30, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([11.19319  ,  4.410586 ,  5.2691813], dtype=float32)}
episode index:830
target Thresh 14.810827002181746
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([6.9108396, 9.560738 , 2.6981366], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6084687144134974
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([6.9108396, 9.560738 , 2.6981366], dtype=float32)}
episode index:831
target Thresh 14.811770506444548
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([6.8187175, 9.75922  , 0.3151207], dtype=float32)}
done in step count: 301
reward sum = 0.04855048513057287
running average episode reward sum: 0.6077957357725323
{'scaleFactor': 30, 'timeStep': 302, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([3.7360659, 6.8463993, 4.152653 ], dtype=float32)}
episode index:832
target Thresh 14.812709304960206
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([12.018861 ,  2.025993 ,  3.1197207], dtype=float32)}
done in step count: 91
reward sum = 0.40068465295154054
running average episode reward sum: 0.6075471030200461
{'scaleFactor': 30, 'timeStep': 92, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([1.7604597, 7.7206593, 5.7478795], dtype=float32)}
episode index:833
target Thresh 14.813643421198734
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([6.9922137, 9.885886 , 4.0836596], dtype=float32)}
done in step count: 43
reward sum = 0.6491026283684022
running average episode reward sum: 0.6075969297890489
{'scaleFactor': 30, 'timeStep': 44, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([10.87734   , 10.1367445 ,  0.95064986], dtype=float32)}
episode index:834
target Thresh 14.814572878513086
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([12.071923 , 10.14448  ,  3.1504245], dtype=float32)}
done in step count: 399
reward sum = 0.0
running average episode reward sum: 0.6068692687952896
{'scaleFactor': 30, 'timeStep': 400, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([ 5.0499864, 11.409278 ,  5.8867064], dtype=float32)}
episode index:835
target Thresh 14.815497700139742
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([13.140002 ,  7.179635 ,  5.3535376], dtype=float32)}
done in step count: 26
reward sum = 0.7700431458051551
running average episode reward sum: 0.6070644528586986
{'scaleFactor': 30, 'timeStep': 27, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([10.277883 ,  8.639286 ,  1.6284002], dtype=float32)}
episode index:836
target Thresh 14.816417909199293
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([10.275567 ,  2.619297 ,  3.4976282], dtype=float32)}
done in step count: 23
reward sum = 0.7936142836436554
running average episode reward sum: 0.607287331987474
{'scaleFactor': 30, 'timeStep': 24, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([1.0505787, 7.798709 , 3.3669627], dtype=float32)}
episode index:837
target Thresh 14.817333528697013
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([1.9755474, 9.87096  , 2.3390331], dtype=float32)}
done in step count: 58
reward sum = 0.5582661385478637
running average episode reward sum: 0.607228834143274
{'scaleFactor': 30, 'timeStep': 59, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([ 7.9475965, 11.866257 ,  2.6987486], dtype=float32)}
episode index:838
target Thresh 14.818244581523436
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([4.0523243, 9.042966 , 3.0764358], dtype=float32)}
done in step count: 51
reward sum = 0.598956006466161
running average episode reward sum: 0.607218973800393
{'scaleFactor': 30, 'timeStep': 52, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([10.3608885 , 10.806092  ,  0.42798463], dtype=float32)}
episode index:839
target Thresh 14.81915109045493
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([2.655829 , 8.546134 , 1.2094989], dtype=float32)}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.6075836146023968
{'scaleFactor': 30, 'timeStep': 10, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([8.2455015, 9.314101 , 6.2774854], dtype=float32)}
episode index:840
target Thresh 14.820053078154269
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([2.0994189, 1.9075129, 1.0762827], dtype=float32)}
done in step count: 209
reward sum = 0.12239274379499834
running average episode reward sum: 0.607006693234017
{'scaleFactor': 30, 'timeStep': 210, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([10.269949 ,  6.9107914,  5.5942907], dtype=float32)}
episode index:841
target Thresh 14.820950567171186
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([2.0718555, 1.8411337, 3.5184705], dtype=float32)}
done in step count: 47
reward sum = 0.6235253948912
running average episode reward sum: 0.6070263116445362
{'scaleFactor': 30, 'timeStep': 48, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([1.7648828, 4.993007 , 1.8091874], dtype=float32)}
episode index:842
target Thresh 14.821843579942957
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([ 5.048402 , 10.094694 ,  1.0765725], dtype=float32)}
done in step count: 17
reward sum = 0.8429431933839268
running average episode reward sum: 0.6073061655967775
{'scaleFactor': 30, 'timeStep': 18, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([ 9.171    , 11.5592785,  5.779072 ], dtype=float32)}
episode index:843
target Thresh 14.822732138794949
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([1.8506985, 6.807699 , 1.7687697], dtype=float32)}
done in step count: 48
reward sum = 0.617290140942288
running average episode reward sum: 0.6073179949514523
{'scaleFactor': 30, 'timeStep': 49, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([13.997145 ,  7.8669486,  5.401543 ], dtype=float32)}
episode index:844
target Thresh 14.82361626594118
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([6.4711933, 7.279941 , 3.9843783], dtype=float32)}
done in step count: 65
reward sum = 0.5203405226503064
running average episode reward sum: 0.6072150630315692
{'scaleFactor': 30, 'timeStep': 66, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([11.45983   ,  8.742924  ,  0.06850378], dtype=float32)}
episode index:845
target Thresh 14.82449598348487
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([ 9.0569315 , 10.070391  ,  0.48742315], dtype=float32)}
done in step count: 59
reward sum = 0.5526834771623851
running average episode reward sum: 0.607150604892244
{'scaleFactor': 30, 'timeStep': 60, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([3.9504945, 6.200496 , 4.1684003], dtype=float32)}
episode index:846
target Thresh 14.825371313419007
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([11.821684 ,  2.7757611,  2.8229895], dtype=float32)}
done in step count: 80
reward sum = 0.4475232137638106
running average episode reward sum: 0.6069621428011833
{'scaleFactor': 30, 'timeStep': 81, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([12.4565   ,  4.4937162,  1.0177069], dtype=float32)}
episode index:847
target Thresh 14.826242277626884
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([2.912064 , 9.157098 , 3.8839674], dtype=float32)}
done in step count: 235
reward sum = 0.0942476934556249
running average episode reward sum: 0.6063575267052569
{'scaleFactor': 30, 'timeStep': 236, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([12.873648 , 11.617752 ,  6.1326118], dtype=float32)}
episode index:848
target Thresh 14.827108897882653
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([9.688145 , 9.885313 , 6.0839458], dtype=float32)}
done in step count: 112
reward sum = 0.3244455298634257
running average episode reward sum: 0.6060254748832995
{'scaleFactor': 30, 'timeStep': 113, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([5.677265, 9.44508 , 2.760894], dtype=float32)}
episode index:849
target Thresh 14.827971195851863
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([5.8437963, 7.2710505, 4.4008656], dtype=float32)}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.6064426166893192
{'scaleFactor': 30, 'timeStep': 5, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([3.2848501, 4.98558  , 4.7449737], dtype=float32)}
episode index:850
target Thresh 14.828829193092009
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([5.025441, 9.280209, 3.041721], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.606905081299555
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([5.025441, 9.280209, 3.041721], dtype=float32)}
episode index:851
target Thresh 14.829682911053068
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([ 8.067891  , 10.223719  ,  0.97312415], dtype=float32)}
done in step count: 34
reward sum = 0.7105532272722921
running average episode reward sum: 0.6070267340530441
{'scaleFactor': 30, 'timeStep': 35, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([ 6.75414   , 11.971598  ,  0.68022925], dtype=float32)}
episode index:852
target Thresh 14.830532371078032
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([8.822066 , 8.629434 , 3.7685995], dtype=float32)}
done in step count: 33
reward sum = 0.7177305325982749
running average episode reward sum: 0.6071565157629447
{'scaleFactor': 30, 'timeStep': 34, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([ 3.575336, 11.115879,  1.787873], dtype=float32)}
episode index:853
target Thresh 14.831377594403449
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([4.99955  , 9.088344 , 1.7253573], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.607604810240974
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([5.0565434, 8.991565 , 2.099587 ], dtype=float32)}
episode index:854
target Thresh 14.83221860215994
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([3.1667316, 8.756341 , 2.0457373], dtype=float32)}
done in step count: 131
reward sum = 0.2680467169168741
running average episode reward sum: 0.6072076662721738
{'scaleFactor': 30, 'timeStep': 132, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([2.196888 , 2.9185362, 3.7428904], dtype=float32)}
episode index:855
target Thresh 14.83305541537275
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([2.0989053, 2.9213436, 5.1314054], dtype=float32)}
done in step count: 36
reward sum = 0.6964132180495735
running average episode reward sum: 0.6073118783653717
{'scaleFactor': 30, 'timeStep': 37, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([3.5151446, 6.792379 , 1.5147398], dtype=float32)}
episode index:856
target Thresh 14.833888054962244
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([7.652852, 9.149132, 5.840918], dtype=float32)}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6077129030696129
{'scaleFactor': 30, 'timeStep': 6, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([10.779112,  8.360337,  6.235261], dtype=float32)}
episode index:857
target Thresh 14.834716541744465
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([9.741033 , 8.571246 , 3.5228593], dtype=float32)}
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.6080273647478522
{'scaleFactor': 30, 'timeStep': 14, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([7.097806 , 7.695541 , 2.7221043], dtype=float32)}
episode index:858
target Thresh 14.83554089643162
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([1.7285651, 6.1233253, 5.3534822], dtype=float32)}
done in step count: 17
reward sum = 0.8429431933839268
running average episode reward sum: 0.6083008406834006
{'scaleFactor': 30, 'timeStep': 18, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([6.175947 , 9.076359 , 1.1711124], dtype=float32)}
episode index:859
target Thresh 14.83636113963262
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([11.101799  ,  9.045202  ,  0.43955123], dtype=float32)}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6086882584842349
{'scaleFactor': 30, 'timeStep': 7, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([13.023065,  4.303374,  4.905968], dtype=float32)}
episode index:860
target Thresh 14.837177291853589
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([0.00514197, 4.0798635 , 3.0580947 ], dtype=float32)}
done in step count: 51
reward sum = 0.598956006466161
running average episode reward sum: 0.6086769550556426
{'scaleFactor': 30, 'timeStep': 52, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([ 7.3493595, 11.906258 ,  6.0670695], dtype=float32)}
episode index:861
target Thresh 14.837989373498372
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([12.191492 ,  8.12791  ,  6.0032315], dtype=float32)}
done in step count: 52
reward sum = 0.5929664464014994
running average episode reward sum: 0.608658729407552
{'scaleFactor': 30, 'timeStep': 53, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([10.338962 , 11.934481 ,  2.8360724], dtype=float32)}
episode index:862
target Thresh 14.838797404869057
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([5.059677 , 9.709507 , 2.5638084], dtype=float32)}
done in step count: 99
reward sum = 0.36972963764972644
running average episode reward sum: 0.608381870668551
{'scaleFactor': 30, 'timeStep': 100, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([13.987839 ,  3.3447177,  4.701118 ], dtype=float32)}
episode index:863
target Thresh 14.839601406166466
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([6.8577843, 8.695436 , 5.525431 ], dtype=float32)}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.6087457165293836
{'scaleFactor': 30, 'timeStep': 9, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([8.3521385, 8.009065 , 4.195559 ], dtype=float32)}
episode index:864
target Thresh 14.840401397490675
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([9.041059 , 8.819212 , 1.0176438], dtype=float32)}
done in step count: 37
reward sum = 0.6894490858690777
running average episode reward sum: 0.6088390152222619
{'scaleFactor': 30, 'timeStep': 38, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([11.826799 ,  5.1771107,  5.1571975], dtype=float32)}
episode index:865
target Thresh 14.841197398841508
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([11.947716 ,  5.119639 ,  4.8420515], dtype=float32)}
done in step count: 30
reward sum = 0.7397003733882802
running average episode reward sum: 0.6089901253356176
{'scaleFactor': 30, 'timeStep': 31, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([11.365071 ,  8.390548 ,  1.9109983], dtype=float32)}
episode index:866
target Thresh 14.841989430119044
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([11.851141 ,  8.947654 ,  3.9513319], dtype=float32)}
done in step count: 14
reward sum = 0.8687458127689782
running average episode reward sum: 0.6092897282046296
{'scaleFactor': 30, 'timeStep': 15, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([9.897601 , 7.9280043, 2.6217916], dtype=float32)}
episode index:867
target Thresh 14.842777511124101
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([2.832917, 9.806502, 6.211727], dtype=float32)}
done in step count: 202
reward sum = 0.13131347932828827
running average episode reward sum: 0.6087390643234356
{'scaleFactor': 30, 'timeStep': 203, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([0.72844434, 4.1164827 , 4.2745132 ], dtype=float32)}
episode index:868
target Thresh 14.843561661558748
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([2.169346 , 8.855895 , 2.2037945], dtype=float32)}
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.6090688677640975
{'scaleFactor': 30, 'timeStep': 12, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([ 8.759612 , 10.624847 ,  5.2572584], dtype=float32)}
episode index:869
target Thresh 14.844341901026786
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([1.3926136, 5.150729 , 1.4263071], dtype=float32)}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.609495340329886
{'scaleFactor': 30, 'timeStep': 3, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([3.1641812, 8.640566 , 0.5368545], dtype=float32)}
episode index:870
target Thresh 14.845118249034241
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([4.944989, 8.988031, 2.590166], dtype=float32)}
done in step count: 15
reward sum = 0.8600583546412884
running average episode reward sum: 0.6097830131362136
{'scaleFactor': 30, 'timeStep': 16, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([7.0999327, 9.145362 , 6.2060666], dtype=float32)}
episode index:871
target Thresh 14.845890724989857
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([8.201334 , 9.788549 , 3.0678594], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6102305096807822
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([8.201334 , 9.788549 , 3.0678594], dtype=float32)}
episode index:872
target Thresh 14.84665934820557
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([11.916038 ,  3.7652361,  2.2302892], dtype=float32)}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.6105674530545829
{'scaleFactor': 30, 'timeStep': 11, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([10.070301 ,  4.565836 ,  2.9035692], dtype=float32)}
episode index:873
target Thresh 14.847424137897004
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([12.046467 ,  7.861587 ,  4.8857775], dtype=float32)}
done in step count: 18
reward sum = 0.8345137614500875
running average episode reward sum: 0.6108236845287197
{'scaleFactor': 30, 'timeStep': 19, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([2.749986 , 6.0736547, 3.283117 ], dtype=float32)}
episode index:874
target Thresh 14.848185113183936
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([12.380706  ,  1.8318474 ,  0.39519107], dtype=float32)}
done in step count: 123
reward sum = 0.29048849430996376
running average episode reward sum: 0.6104575871684698
{'scaleFactor': 30, 'timeStep': 124, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([ 4.4521194, 10.110909 ,  1.8881822], dtype=float32)}
episode index:875
target Thresh 14.848942293090792
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([4.0371656, 9.1974325, 2.743253 ], dtype=float32)}
done in step count: 138
reward sum = 0.2498370564584527
running average episode reward sum: 0.6100459198959697
{'scaleFactor': 30, 'timeStep': 139, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([12.16505  ,  2.7684734,  4.892305 ], dtype=float32)}
episode index:876
target Thresh 14.849695696547107
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([10.334099 ,  8.172208 ,  2.7302907], dtype=float32)}
done in step count: 25
reward sum = 0.7778213593991467
running average episode reward sum: 0.6102372259843427
{'scaleFactor': 30, 'timeStep': 26, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([1.4837203, 7.490591 , 3.3340688], dtype=float32)}
episode index:877
target Thresh 14.850445342388008
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([10.697631  ,  9.0730915 ,  0.42852086], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.610681147139258
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([10.697631  ,  9.0730915 ,  0.42852086], dtype=float32)}
episode index:878
target Thresh 14.85119124935468
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([3.0130422, 8.723927 , 5.457137 ], dtype=float32)}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6110574827504772
{'scaleFactor': 30, 'timeStep': 7, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([3.9530754, 7.438294 , 5.4237957], dtype=float32)}
episode index:879
target Thresh 14.851933436094834
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([11.996799 ,  4.9695234,  4.1628485], dtype=float32)}
done in step count: 18
reward sum = 0.8345137614500875
running average episode reward sum: 0.6113114103399087
{'scaleFactor': 30, 'timeStep': 19, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([6.6674566, 8.153706 , 2.243132 ], dtype=float32)}
episode index:880
target Thresh 14.852671921163179
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([12.183101 ,  4.936566 ,  0.8048148], dtype=float32)}
done in step count: 56
reward sum = 0.5696012024771592
running average episode reward sum: 0.6112640661766139
{'scaleFactor': 30, 'timeStep': 57, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([8.31942 , 9.626577, 2.178146], dtype=float32)}
episode index:881
target Thresh 14.85340672302188
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([6.9482126, 9.0191965, 6.11112  ], dtype=float32)}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6116277864506847
{'scaleFactor': 30, 'timeStep': 8, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([5.8160477, 9.621156 , 6.2693686], dtype=float32)}
episode index:882
target Thresh 14.854137860041021
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([11.664492 ,  2.3330166,  3.3167396], dtype=float32)}
done in step count: 44
reward sum = 0.6426116020847181
running average episode reward sum: 0.6116628757096133
{'scaleFactor': 30, 'timeStep': 45, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([2.4454372, 8.716761 , 3.2213187], dtype=float32)}
episode index:883
target Thresh 14.854865350499066
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([6.2230773, 9.049072 , 5.5917974], dtype=float32)}
done in step count: 77
reward sum = 0.46122196741809546
running average episode reward sum: 0.611492693686659
{'scaleFactor': 30, 'timeStep': 78, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([13.542259,  9.418148,  4.878966], dtype=float32)}
episode index:884
target Thresh 14.855589212583315
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([1.9537762, 6.156413 , 5.749808 ], dtype=float32)}
done in step count: 63
reward sum = 0.5309055429551132
running average episode reward sum: 0.6114016347592788
{'scaleFactor': 30, 'timeStep': 64, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([3.8022504 , 9.700941  , 0.85523766], dtype=float32)}
episode index:885
target Thresh 14.856309464390357
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([2.311042 , 7.249419 , 1.2318377], dtype=float32)}
done in step count: 31
reward sum = 0.7323033696543975
running average episode reward sum: 0.611538092699341
{'scaleFactor': 30, 'timeStep': 32, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([11.801571 ,  5.277734 ,  4.8440742], dtype=float32)}
episode index:886
target Thresh 14.857026123926524
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([1.9841933, 5.1069336, 2.1764433], dtype=float32)}
done in step count: 70
reward sum = 0.49483865960020695
running average episode reward sum: 0.6114065262584174
{'scaleFactor': 30, 'timeStep': 71, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([ 7.5599804 , 10.831898  ,  0.27418828], dtype=float32)}
episode index:887
target Thresh 14.857739209108344
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([12.056603 ,  3.2506287,  5.259179 ], dtype=float32)}
done in step count: 226
reward sum = 0.10317013030157669
running average episode reward sum: 0.6108341879746823
{'scaleFactor': 30, 'timeStep': 227, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([0.26422197, 3.4764194 , 3.8672833 ], dtype=float32)}
episode index:888
target Thresh 14.858448737762982
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([ 7.721244 , 10.13629  ,  1.4902852], dtype=float32)}
done in step count: 75
reward sum = 0.4705866415856499
running average episode reward sum: 0.6106764292048409
{'scaleFactor': 30, 'timeStep': 76, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([ 6.2575984, 10.88931  ,  1.7189388], dtype=float32)}
episode index:889
target Thresh 14.85915472762869
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([1.8314465, 7.9576693, 1.4995532], dtype=float32)}
done in step count: 118
reward sum = 0.3054590259283046
running average episode reward sum: 0.610333488302283
{'scaleFactor': 30, 'timeStep': 119, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([10.1546545,  9.87257  ,  6.060697 ], dtype=float32)}
episode index:890
target Thresh 14.859857196355254
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([3.5346432, 8.607418 , 3.8780112], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.6107596011100245
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([2.3377256, 6.9139395, 4.058858 ], dtype=float32)}
episode index:891
target Thresh 14.860556161504428
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([5.6631236, 7.5667324, 5.7519193], dtype=float32)}
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.6110786354745409
{'scaleFactor': 30, 'timeStep': 12, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([10.026065 ,  6.627111 ,  5.8781805], dtype=float32)}
episode index:892
target Thresh 14.861251640550378
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([3.3087893, 9.928042 , 5.4121046], dtype=float32)}
done in step count: 29
reward sum = 0.7471720943315961
running average episode reward sum: 0.6112310357644145
{'scaleFactor': 30, 'timeStep': 30, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([1.7954547, 3.223349 , 3.851679 ], dtype=float32)}
episode index:893
target Thresh 14.861943650880113
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([10.915351  , 10.264822  ,  0.20840329], dtype=float32)}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.6116218243261993
{'scaleFactor': 30, 'timeStep': 5, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([13.127204 ,  7.149175 ,  4.5727224], dtype=float32)}
episode index:894
target Thresh 14.862632209793931
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([5.8407507, 9.08849  , 5.474255 ], dtype=float32)}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6119798617827142
{'scaleFactor': 30, 'timeStep': 8, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([2.338889 , 4.5900226, 4.15705  ], dtype=float32)}
episode index:895
target Thresh 14.86331733450584
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([10.87083  ,  8.9578905,  3.701476 ], dtype=float32)}
done in step count: 74
reward sum = 0.47534004200570695
running average episode reward sum: 0.6118273619838559
{'scaleFactor': 30, 'timeStep': 75, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([12.983464 ,  7.9181757,  4.2318544], dtype=float32)}
episode index:896
target Thresh 14.863999042143993
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([ 3.9862797, 10.003952 ,  1.7747585], dtype=float32)}
done in step count: 165
reward sum = 0.1904614597650274
running average episode reward sum: 0.6113576118141583
{'scaleFactor': 30, 'timeStep': 166, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([10.897687 ,  2.8573222,  4.812613 ], dtype=float32)}
episode index:897
target Thresh 14.864677349751114
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([ 8.527215  , 10.25339   ,  0.39545658], dtype=float32)}
done in step count: 399
reward sum = 0.0
running average episode reward sum: 0.6106768126918707
{'scaleFactor': 30, 'timeStep': 400, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([12.372436 , -0.1264408,  2.8286498], dtype=float32)}
episode index:898
target Thresh 14.86535227428493
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([2.0317533, 9.686096 , 3.9094033], dtype=float32)}
done in step count: 159
reward sum = 0.2023000271287771
running average episode reward sum: 0.6102225559782299
{'scaleFactor': 30, 'timeStep': 160, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([11.434932  ,  9.477078  ,  0.38741177], dtype=float32)}
episode index:899
target Thresh 14.866023832618593
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([ 9.555939  , 11.313577  ,  0.22680283], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.610655642027143
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([ 9.555939  , 11.313577  ,  0.22680283], dtype=float32)}
episode index:900
target Thresh 14.866692041541093
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([11.73551  ,  1.7989061,  1.0141027], dtype=float32)}
done in step count: 273
reward sum = 0.06432919623726716
running average episode reward sum: 0.6100492863714384
{'scaleFactor': 30, 'timeStep': 274, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([3.78756  , 9.513406 , 2.6461735], dtype=float32)}
episode index:901
target Thresh 14.867356917757688
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([2.0481758, 1.9808679, 0.2046234], dtype=float32)}
done in step count: 175
reward sum = 0.1722499301915014
running average episode reward sum: 0.6095639212315492
{'scaleFactor': 30, 'timeStep': 176, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([0.63906926, 4.1914616 , 0.7025602 ], dtype=float32)}
episode index:902
target Thresh 14.868018477890317
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([3.550474, 8.764311, 5.588805], dtype=float32)}
done in step count: 167
reward sum = 0.18667127671570335
running average episode reward sum: 0.6090956015809227
{'scaleFactor': 30, 'timeStep': 168, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([10.070558 ,  4.2466826,  4.2258034], dtype=float32)}
episode index:903
target Thresh 14.86867673847802
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([2.1886506, 3.8083131, 2.5880775], dtype=float32)}
done in step count: 287
reward sum = 0.05588571986991975
running average episode reward sum: 0.6084836437471716
{'scaleFactor': 30, 'timeStep': 288, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([13.0287075,  4.659832 ,  5.4922976], dtype=float32)}
episode index:904
target Thresh 14.869331715977346
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([11.896843 ,  4.291482 ,  1.7604263], dtype=float32)}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.6088834397209316
{'scaleFactor': 30, 'timeStep': 4, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([10.404201 ,  7.9685254,  2.0807571], dtype=float32)}
episode index:905
target Thresh 14.869983426762767
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([12.008523,  6.084048,  4.578294], dtype=float32)}
done in step count: 118
reward sum = 0.3054590259283046
running average episode reward sum: 0.6085485341869441
{'scaleFactor': 30, 'timeStep': 119, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([11.799714  ,  9.471089  ,  0.68527126], dtype=float32)}
episode index:906
target Thresh 14.870631887127084
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([2.0177975, 4.0682716, 4.256398 ], dtype=float32)}
done in step count: 107
reward sum = 0.34116606151404244
running average episode reward sum: 0.6082537354298626
{'scaleFactor': 30, 'timeStep': 108, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([10.550254 ,  8.610479 ,  4.2901845], dtype=float32)}
episode index:907
target Thresh 14.87127711328184
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([11.880967 ,  1.8970057,  6.280964 ], dtype=float32)}
done in step count: 33
reward sum = 0.7177305325982749
running average episode reward sum: 0.6083743045897397
{'scaleFactor': 30, 'timeStep': 34, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([ 8.015457, 11.875623,  2.846965], dtype=float32)}
episode index:908
target Thresh 14.871919121357726
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([6.0611057 , 9.610022  , 0.13111776], dtype=float32)}
done in step count: 15
reward sum = 0.8600583546412884
running average episode reward sum: 0.6086511847328107
{'scaleFactor': 30, 'timeStep': 16, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([10.197126 , 10.551133 ,  5.8673954], dtype=float32)}
episode index:909
target Thresh 14.872557927404973
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([12.115552,  9.105808,  5.057252], dtype=float32)}
done in step count: 78
reward sum = 0.4566097477439145
running average episode reward sum: 0.6084841062306251
{'scaleFactor': 30, 'timeStep': 79, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([6.398075, 8.437174, 3.417414], dtype=float32)}
episode index:910
target Thresh 14.873193547393768
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([10.832811 ,  9.883357 ,  1.6683147], dtype=float32)}
done in step count: 54
reward sum = 0.5811664141181095
running average episode reward sum: 0.6084541197409297
{'scaleFactor': 30, 'timeStep': 55, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([13.805673 ,  4.6721897,  6.25417  ], dtype=float32)}
episode index:911
target Thresh 14.873825997214643
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([4.930687 , 9.268166 , 2.6135056], dtype=float32)}
done in step count: 55
reward sum = 0.5753547499769285
running average episode reward sum: 0.6084178265723288
{'scaleFactor': 30, 'timeStep': 56, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([11.552843 ,  3.7972379,  5.299409 ], dtype=float32)}
episode index:912
target Thresh 14.874455292678878
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([3.1399899, 8.9853735, 2.6206684], dtype=float32)}
done in step count: 30
reward sum = 0.7397003733882802
running average episode reward sum: 0.6085616190661031
{'scaleFactor': 30, 'timeStep': 31, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([4.2688394, 7.796018 , 4.0447273], dtype=float32)}
episode index:913
target Thresh 14.875081449518891
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([12.062717 ,  4.1940694,  0.5537029], dtype=float32)}
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.6088753790608433
{'scaleFactor': 30, 'timeStep': 12, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([5.3804154, 9.340808 , 2.7741704], dtype=float32)}
episode index:914
target Thresh 14.875704483388635
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([ 9.555952 , 10.330333 ,  0.6366312], dtype=float32)}
done in step count: 154
reward sum = 0.2127257032290187
running average episode reward sum: 0.6084424285954533
{'scaleFactor': 30, 'timeStep': 155, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([10.08174 ,  6.933543,  3.362094], dtype=float32)}
episode index:915
target Thresh 14.87632440986399
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([12.076809 ,  2.9515572,  4.5226455], dtype=float32)}
done in step count: 88
reward sum = 0.41294967113388814
running average episode reward sum: 0.6082290085545564
{'scaleFactor': 30, 'timeStep': 89, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([10.811024 ,  7.116722 ,  2.0972466], dtype=float32)}
episode index:916
target Thresh 14.876941244443152
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([11.944337  ,  9.997778  ,  0.56818163], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6086562397338863
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([11.944337  ,  9.997778  ,  0.56818163], dtype=float32)}
episode index:917
target Thresh 14.877555002547014
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([9.041475 , 9.952147 , 1.5000386], dtype=float32)}
done in step count: 50
reward sum = 0.6050060671375364
running average episode reward sum: 0.6086522635110144
{'scaleFactor': 30, 'timeStep': 51, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([ 6.1102443, 11.996002 ,  2.3985903], dtype=float32)}
episode index:918
target Thresh 14.878165699519561
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([10.056022 ,  6.8866525,  2.538805 ], dtype=float32)}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.609045785531133
{'scaleFactor': 30, 'timeStep': 4, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([4.695914 , 9.314621 , 2.1053176], dtype=float32)}
episode index:919
target Thresh 14.878773350628254
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([ 3.9908686, 10.084386 ,  2.0705557], dtype=float32)}
done in step count: 20
reward sum = 0.8179069375972308
running average episode reward sum: 0.6092728085225092
{'scaleFactor': 30, 'timeStep': 21, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([ 7.7582617, 11.846844 ,  0.6760408], dtype=float32)}
episode index:920
target Thresh 14.879377971064397
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([7.060262, 9.93404 , 4.623391], dtype=float32)}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6096335113899125
{'scaleFactor': 30, 'timeStep': 7, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([9.527699, 9.305969, 5.754049], dtype=float32)}
episode index:921
target Thresh 14.879979575943533
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([11.019095 ,  9.070313 ,  2.4858344], dtype=float32)}
done in step count: 39
reward sum = 0.6757290490602831
running average episode reward sum: 0.6097051985240451
{'scaleFactor': 30, 'timeStep': 40, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([10.022348 ,  6.1673527,  5.49586  ], dtype=float32)}
episode index:922
target Thresh 14.880578180305818
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([12.185008  ,  8.08453   ,  0.09980839], dtype=float32)}
done in step count: 113
reward sum = 0.3212010745647914
running average episode reward sum: 0.6093926263420741
{'scaleFactor': 30, 'timeStep': 114, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([2.9735546, 5.4248815, 3.9873898], dtype=float32)}
episode index:923
target Thresh 14.881173799116391
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([11.825703 ,  6.226503 ,  4.6261787], dtype=float32)}
done in step count: 81
reward sum = 0.4430479816261725
running average episode reward sum: 0.6092125996703036
{'scaleFactor': 30, 'timeStep': 82, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([ 3.4483812, 11.994216 ,  1.7987182], dtype=float32)}
episode index:924
target Thresh 14.881766447265752
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([4.9843893, 8.90805  , 3.0589437], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.609635072535525
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([4.9843893, 8.90805  , 3.0589437], dtype=float32)}
episode index:925
target Thresh 14.882356139570138
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([12.05507   ,  7.8970294 ,  0.24958897], dtype=float32)}
done in step count: 67
reward sum = 0.5099857462495653
running average episode reward sum: 0.6095274598721492
{'scaleFactor': 30, 'timeStep': 68, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([8.59782  , 9.445253 , 2.9563298], dtype=float32)}
episode index:926
target Thresh 14.882942890771885
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([ 4.608914 , 11.126121 ,  0.4332094], dtype=float32)}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.6099166416845847
{'scaleFactor': 30, 'timeStep': 4, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([ 8.337038, 10.451514,  5.71501 ], dtype=float32)}
episode index:927
target Thresh 14.883526715539805
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([2.042576 , 9.023169 , 1.0095327], dtype=float32)}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.6102537408793512
{'scaleFactor': 30, 'timeStep': 9, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([ 6.407737, 10.511234,  5.256829], dtype=float32)}
episode index:928
target Thresh 14.884107628469547
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([3.3165922 , 6.3753076 , 0.58845544], dtype=float32)}
done in step count: 141
reward sum = 0.2424166460445802
running average episode reward sum: 0.6098577913693031
{'scaleFactor': 30, 'timeStep': 142, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([0.16586202, 7.475518  , 1.0497309 ], dtype=float32)}
episode index:929
target Thresh 14.884685644083964
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([9.859321, 9.257478, 5.034065], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6102772991205189
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([9.859321, 9.257478, 5.034065], dtype=float32)}
episode index:930
target Thresh 14.885260776833478
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([1.9443294, 6.006749 , 2.4411974], dtype=float32)}
done in step count: 218
reward sum = 0.11180788242357734
running average episode reward sum: 0.6097418862132182
{'scaleFactor': 30, 'timeStep': 219, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([11.27229  ,  6.324049 ,  5.1289196], dtype=float32)}
episode index:931
target Thresh 14.885833041096436
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([3.8199055, 6.2815604, 6.224541 ], dtype=float32)}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.6100678254420492
{'scaleFactor': 30, 'timeStep': 10, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([12.251194 ,  9.888963 ,  5.9055424], dtype=float32)}
episode index:932
target Thresh 14.886402451179476
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([11.8205595,  9.997295 ,  5.3038197], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.610485759176838
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([11.8205595,  9.997295 ,  5.3038197], dtype=float32)}
episode index:933
target Thresh 14.88696902131788
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([2.103262 , 5.884533 , 1.5878768], dtype=float32)}
done in step count: 335
reward sum = 0.03449770389516398
running average episode reward sum: 0.6098690696101552
{'scaleFactor': 30, 'timeStep': 336, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([10.17498  ,  3.2641754,  3.36298  ], dtype=float32)}
episode index:934
target Thresh 14.887532765675926
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([9.254898  , 8.790736  , 0.76030314], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.610286321942123
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([9.254898  , 8.790736  , 0.76030314], dtype=float32)}
episode index:935
target Thresh 14.88809369834726
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([ 5.0391746, 10.068539 ,  3.3843837], dtype=float32)}
done in step count: 18
reward sum = 0.8345137614500875
running average episode reward sum: 0.6105258811723666
{'scaleFactor': 30, 'timeStep': 19, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([0.09911057, 7.5883703 , 3.2199574 ], dtype=float32)}
episode index:936
target Thresh 14.888651833355222
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([7.1075387 , 8.862146  , 0.97793686], dtype=float32)}
done in step count: 42
reward sum = 0.6556592205741436
running average episode reward sum: 0.6105740490906183
{'scaleFactor': 30, 'timeStep': 43, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([3.5034614, 9.648607 , 2.2305143], dtype=float32)}
episode index:937
target Thresh 14.889207184653221
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([3.3746266, 9.673354 , 4.6299815], dtype=float32)}
done in step count: 32
reward sum = 0.7249803359578534
running average episode reward sum: 0.6106960174135044
{'scaleFactor': 30, 'timeStep': 33, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([11.753815  ,  7.779444  ,  0.25834945], dtype=float32)}
episode index:938
target Thresh 14.889759766125064
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([2.1438167, 8.961083 , 2.9122474], dtype=float32)}
done in step count: 88
reward sum = 0.41294967113388814
running average episode reward sum: 0.6104854249254538
{'scaleFactor': 30, 'timeStep': 89, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([5.6324415, 8.485317 , 1.2503672], dtype=float32)}
episode index:939
target Thresh 14.890309591585318
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([10.921909,  8.918892,  4.766801], dtype=float32)}
done in step count: 17
reward sum = 0.8429431933839268
running average episode reward sum: 0.6107327204238139
{'scaleFactor': 30, 'timeStep': 18, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([1.7247026, 6.374609 , 3.466022 ], dtype=float32)}
episode index:940
target Thresh 14.89085667477965
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([1.9125264 , 3.1186025 , 0.47262016], dtype=float32)}
done in step count: 155
reward sum = 0.21059844619672852
running average episode reward sum: 0.6103074980282484
{'scaleFactor': 30, 'timeStep': 156, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([11.552139 ,  5.389107 ,  5.2703753], dtype=float32)}
episode index:941
target Thresh 14.891401029385166
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([8.211689 , 7.9087477, 3.8309095], dtype=float32)}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.6106793541980698
{'scaleFactor': 30, 'timeStep': 5, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([3.7526183, 7.5965314, 3.6645694], dtype=float32)}
episode index:942
target Thresh 14.891942669010762
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([4.049809  , 9.188017  , 0.33435684], dtype=float32)}
done in step count: 52
reward sum = 0.5929664464014994
running average episode reward sum: 0.6106605706267055
{'scaleFactor': 30, 'timeStep': 53, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([3.9569426, 8.058858 , 5.817001 ], dtype=float32)}
episode index:943
target Thresh 14.892481607197453
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([2.2021947, 4.8210278, 6.1670866], dtype=float32)}
done in step count: 59
reward sum = 0.5526834771623851
running average episode reward sum: 0.6105991542141374
{'scaleFactor': 30, 'timeStep': 60, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([10.498661 ,  7.1304893,  5.389831 ], dtype=float32)}
episode index:944
target Thresh 14.893017857418725
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([2.2322576 , 9.067331  , 0.23883694], dtype=float32)}
done in step count: 36
reward sum = 0.6964132180495735
running average episode reward sum: 0.6106899627472966
{'scaleFactor': 30, 'timeStep': 37, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([ 7.180003 , 11.425537 ,  3.6688175], dtype=float32)}
episode index:945
target Thresh 14.89355143308086
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([4.9771433, 8.982257 , 2.7792697], dtype=float32)}
done in step count: 17
reward sum = 0.8429431933839268
running average episode reward sum: 0.610935473561923
{'scaleFactor': 30, 'timeStep': 18, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([1.7284764, 6.945911 , 4.751049 ], dtype=float32)}
episode index:946
target Thresh 14.894082347523279
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([ 9.859859, 10.232415,  0.985693], dtype=float32)}
done in step count: 23
reward sum = 0.7936142836436554
running average episode reward sum: 0.6111283762124845
{'scaleFactor': 30, 'timeStep': 24, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([ 5.5998645, 10.580195 ,  3.9646392], dtype=float32)}
episode index:947
target Thresh 14.89461061401887
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([11.977049 ,  2.3224103,  6.1419635], dtype=float32)}
done in step count: 184
reward sum = 0.15735328210778962
running average episode reward sum: 0.6106497105014037
{'scaleFactor': 30, 'timeStep': 185, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([2.6433654, 7.991894 , 2.8079603], dtype=float32)}
episode index:948
target Thresh 14.89513624577432
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([2.2853398, 4.275867 , 1.5300581], dtype=float32)}
done in step count: 81
reward sum = 0.4430479816261725
running average episode reward sum: 0.6104731017249282
{'scaleFactor': 30, 'timeStep': 82, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([11.227357 ,  4.5454516,  5.2395496], dtype=float32)}
episode index:949
target Thresh 14.895659255930454
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([1.9163013, 1.9809028, 5.500485 ], dtype=float32)}
done in step count: 133
reward sum = 0.2627125872502283
running average episode reward sum: 0.610107038025481
{'scaleFactor': 30, 'timeStep': 134, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([8.800144 , 9.112617 , 5.9223175], dtype=float32)}
episode index:950
target Thresh 14.896179657562552
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([9.223458  , 8.981122  , 0.73188186], dtype=float32)}
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.6104069656976506
{'scaleFactor': 30, 'timeStep': 12, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([ 4.9611626, 10.078665 ,  3.9667208], dtype=float32)}
episode index:951
target Thresh 14.896697463680681
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([12.246436 ,  5.1720943,  4.736156 ], dtype=float32)}
done in step count: 87
reward sum = 0.41712087993322033
running average episode reward sum: 0.610203934094957
{'scaleFactor': 30, 'timeStep': 88, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([7.8907866, 9.037907 , 2.8546715], dtype=float32)}
episode index:952
target Thresh 14.897212687230022
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([5.0285225, 8.880684 , 2.3704674], dtype=float32)}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.6105126204967554
{'scaleFactor': 30, 'timeStep': 11, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([10.356937 ,  7.8862376,  5.5761385], dtype=float32)}
episode index:953
target Thresh 14.897725341091192
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([1.933727 , 7.075605 , 2.8080592], dtype=float32)}
done in step count: 35
reward sum = 0.7034476949995692
running average episode reward sum: 0.6106100367174082
{'scaleFactor': 30, 'timeStep': 36, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([7.8780093, 7.9056787, 6.14338  ], dtype=float32)}
episode index:954
target Thresh 14.898235438080562
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([10.845067 ,  8.940285 ,  4.4497757], dtype=float32)}
done in step count: 16
reward sum = 0.8514577710948755
running average episode reward sum: 0.6108622332979081
{'scaleFactor': 30, 'timeStep': 17, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([9.992743 , 8.098898 , 4.4147625], dtype=float32)}
episode index:955
target Thresh 14.898742990950582
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([13.917618 ,  9.40336  ,  6.2815742], dtype=float32)}
done in step count: 27
reward sum = 0.7623427143471035
running average episode reward sum: 0.6110206856839429
{'scaleFactor': 30, 'timeStep': 28, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([3.0733418, 9.833991 , 3.011343 ], dtype=float32)}
episode index:956
target Thresh 14.899248012390103
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([ 6.7638593, 10.119041 ,  4.860798 ], dtype=float32)}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.6113961071200097
{'scaleFactor': 30, 'timeStep': 4, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([10.393868  ,  8.485791  ,  0.26638335], dtype=float32)}
episode index:957
target Thresh 14.899750515024685
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([ 5.720235, 10.005812,  4.708939], dtype=float32)}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.6117114736548361
{'scaleFactor': 30, 'timeStep': 10, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([4.0845466, 9.162176 , 3.4674323], dtype=float32)}
episode index:958
target Thresh 14.900250511416923
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([12.024059 ,  4.1449833,  3.2567847], dtype=float32)}
done in step count: 92
reward sum = 0.3966778064220251
running average episode reward sum: 0.611487246681705
{'scaleFactor': 30, 'timeStep': 93, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([10.637782 ,  6.307077 ,  5.6645346], dtype=float32)}
episode index:959
target Thresh 14.90074801406675
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([5.074698, 8.777136, 3.408786], dtype=float32)}
done in step count: 32
reward sum = 0.7249803359578534
running average episode reward sum: 0.611605468649701
{'scaleFactor': 30, 'timeStep': 33, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([13.865549  ,  0.70502424,  6.000085  ], dtype=float32)}
episode index:960
target Thresh 14.90124303541176
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([9.746381 , 9.061208 , 0.2430808], dtype=float32)}
done in step count: 39
reward sum = 0.6757290490602831
running average episode reward sum: 0.6116721945398265
{'scaleFactor': 30, 'timeStep': 40, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([13.679296 ,  6.134657 ,  4.7744064], dtype=float32)}
episode index:961
target Thresh 14.90173558782751
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([4.8721914, 9.038534 , 0.9322635], dtype=float32)}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.6120551756265833
{'scaleFactor': 30, 'timeStep': 3, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([6.580009, 8.775687, 5.939197], dtype=float32)}
episode index:962
target Thresh 14.90222568362784
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([3.5332057, 5.276784 , 0.7734148], dtype=float32)}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6124071329207407
{'scaleFactor': 30, 'timeStep': 6, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([11.961344 ,  8.095744 ,  5.9385505], dtype=float32)}
episode index:963
target Thresh 14.902713335065167
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([ 4.6088634 , 10.03176   ,  0.61960906], dtype=float32)}
done in step count: 398
reward sum = 0.018315022217166757
running average episode reward sum: 0.6117908547976041
{'scaleFactor': 30, 'timeStep': 399, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([13.800026 ,  3.9383411,  5.000098 ], dtype=float32)}
episode index:964
target Thresh 14.903198554330805
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([ 8.085154, 10.140213,  6.17404 ], dtype=float32)}
done in step count: 48
reward sum = 0.617290140942288
running average episode reward sum: 0.611796553539723
{'scaleFactor': 30, 'timeStep': 49, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([ 6.5313654, 10.588    ,  2.8939803], dtype=float32)}
episode index:965
target Thresh 14.903681353555259
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([6.442966, 8.257847, 4.508211], dtype=float32)}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.6121184460251144
{'scaleFactor': 30, 'timeStep': 9, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([8.010956 , 7.578568 , 5.6163454], dtype=float32)}
episode index:966
target Thresh 14.904161744808533
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([ 4.74505  , 10.238724 ,  5.7214084], dtype=float32)}
done in step count: 56
reward sum = 0.5696012024771592
running average episode reward sum: 0.6120744778311663
{'scaleFactor': 30, 'timeStep': 57, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([2.5400507, 5.4194975, 3.0870273], dtype=float32)}
episode index:967
target Thresh 14.90463974010044
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([2.326236 , 4.2195864, 1.5751429], dtype=float32)}
done in step count: 69
reward sum = 0.4998370298991989
running average episode reward sum: 0.6119585300543771
{'scaleFactor': 30, 'timeStep': 70, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([6.0165277, 8.391657 , 2.025999 ], dtype=float32)}
episode index:968
target Thresh 14.905115351380879
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([10.941256 ,  8.852626 ,  3.0304165], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6123589856477163
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([10.941256 ,  8.852626 ,  3.0304165], dtype=float32)}
episode index:969
target Thresh 14.90558859054016
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([3.7269616 , 3.5101285 , 0.81444347], dtype=float32)}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.6126600403790163
{'scaleFactor': 30, 'timeStep': 11, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([4.736351 , 8.160992 , 1.9542997], dtype=float32)}
episode index:970
target Thresh 14.906059469409291
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([5.944702  , 8.987112  , 0.42766118], dtype=float32)}
done in step count: 73
reward sum = 0.4801414565714212
running average episode reward sum: 0.6125235639796265
{'scaleFactor': 30, 'timeStep': 74, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([13.301292 ,  0.9008328,  4.528443 ], dtype=float32)}
episode index:971
target Thresh 14.906527999760263
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([5.180948 , 9.89248  , 2.0497155], dtype=float32)}
done in step count: 15
reward sum = 0.8600583546412884
running average episode reward sum: 0.6127782294021179
{'scaleFactor': 30, 'timeStep': 16, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([ 3.3536124, 10.60207  ,  4.0446696], dtype=float32)}
episode index:972
target Thresh 14.906994193306359
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([2.0384135 , 4.9041243 , 0.65185237], dtype=float32)}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.6131456710985186
{'scaleFactor': 30, 'timeStep': 4, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([7.362762  , 7.063248  , 0.08892761], dtype=float32)}
episode index:973
target Thresh 14.907458061702446
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([2.4601154, 8.9428425, 2.3051872], dtype=float32)}
done in step count: 39
reward sum = 0.6757290490602831
running average episode reward sum: 0.6132099250799987
{'scaleFactor': 30, 'timeStep': 40, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([7.9880986, 8.917612 , 5.49076  ], dtype=float32)}
episode index:974
target Thresh 14.907919616545254
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([2.104985 , 5.1928463, 3.264439 ], dtype=float32)}
done in step count: 58
reward sum = 0.5582661385478637
running average episode reward sum: 0.6131535724784274
{'scaleFactor': 30, 'timeStep': 59, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([ 6.094385 , 11.942306 ,  1.0051657], dtype=float32)}
episode index:975
target Thresh 14.908378869373681
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([7.073458 , 9.891747 , 6.0759425], dtype=float32)}
done in step count: 50
reward sum = 0.6050060671375364
running average episode reward sum: 0.6131452246245945
{'scaleFactor': 30, 'timeStep': 51, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([2.2954986, 8.379135 , 3.8256474], dtype=float32)}
episode index:976
target Thresh 14.90883583166907
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([3.541779  , 6.084853  , 0.08597332], dtype=float32)}
done in step count: 61
reward sum = 0.5416850759668536
running average episode reward sum: 0.6130720822001751
{'scaleFactor': 30, 'timeStep': 62, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([10.831956  , 11.205507  ,  0.10869052], dtype=float32)}
episode index:977
target Thresh 14.909290514855503
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([ 5.88731  , 10.000278 ,  2.8086593], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6134677140179663
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([ 5.88731  , 10.000278 ,  2.8086593], dtype=float32)}
episode index:978
target Thresh 14.909742930300082
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([10.942011 ,  9.002476 ,  0.6231494], dtype=float32)}
done in step count: 50
reward sum = 0.6050060671375364
running average episode reward sum: 0.6134590708648708
{'scaleFactor': 30, 'timeStep': 51, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([3.0453162, 6.3209906, 3.6559887], dtype=float32)}
episode index:979
target Thresh 14.910193089313216
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([ 4.434134 , 10.060407 ,  4.5221024], dtype=float32)}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6137841793108323
{'scaleFactor': 30, 'timeStep': 8, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([10.301498,  5.650438,  4.905478], dtype=float32)}
episode index:980
target Thresh 14.910641003148909
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([11.799854 ,  2.117865 ,  0.6771816], dtype=float32)}
done in step count: 268
reward sum = 0.0676444472200646
running average episode reward sum: 0.6132274619488641
{'scaleFactor': 30, 'timeStep': 269, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([3.7581446, 9.734393 , 3.9122505], dtype=float32)}
episode index:981
target Thresh 14.911086683005024
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([2.1370306, 5.0832443, 4.458009 ], dtype=float32)}
done in step count: 81
reward sum = 0.4430479816261725
running average episode reward sum: 0.613054163089065
{'scaleFactor': 30, 'timeStep': 82, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([3.9655027, 9.329845 , 0.7740969], dtype=float32)}
episode index:982
target Thresh 14.911530140023583
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([9.899575 , 7.8711004, 3.4193182], dtype=float32)}
done in step count: 75
reward sum = 0.4705866415856499
running average episode reward sum: 0.6129092317345346
{'scaleFactor': 30, 'timeStep': 76, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([2.2483213, 3.9299712, 3.6934648], dtype=float32)}
episode index:983
target Thresh 14.911971385291038
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([3.927115 , 7.6423526, 5.567091 ], dtype=float32)}
done in step count: 399
reward sum = 0.0
running average episode reward sum: 0.6122863564990321
{'scaleFactor': 30, 'timeStep': 400, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([0.93929356, 5.880108  , 0.92721313], dtype=float32)}
episode index:984
target Thresh 14.912410429838538
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([4.036389, 8.323301, 5.565448], dtype=float32)}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.6126597713655305
{'scaleFactor': 30, 'timeStep': 3, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([6.4306326 , 8.775474  , 0.07150672], dtype=float32)}
episode index:985
target Thresh 14.912847284642222
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([8.46439 , 9.757003, 2.704066], dtype=float32)}
done in step count: 139
reward sum = 0.24733868589386818
running average episode reward sum: 0.612289263165255
{'scaleFactor': 30, 'timeStep': 140, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([12.435411 ,  4.364074 ,  3.8575602], dtype=float32)}
episode index:986
target Thresh 14.913281960623483
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([8.672782 , 7.9590187, 5.745054 ], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.6126719488155434
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([10.688865  ,  7.425908  ,  0.08922785], dtype=float32)}
episode index:987
target Thresh 14.913714468649243
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([2.066154 , 3.1635127, 4.80688  ], dtype=float32)}
done in step count: 27
reward sum = 0.7623427143471035
running average episode reward sum: 0.612823437444624
{'scaleFactor': 30, 'timeStep': 28, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([ 3.08889 , 10.495157,  0.332344], dtype=float32)}
episode index:988
target Thresh 14.914144819532225
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([ 3.4574358, 10.998386 ,  2.489454 ], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6132149203187953
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([ 3.4574358, 10.998386 ,  2.489454 ], dtype=float32)}
episode index:989
target Thresh 14.914573024031224
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([8.183888 , 9.811964 , 3.2708716], dtype=float32)}
done in step count: 62
reward sum = 0.536268225207185
running average episode reward sum: 0.6131371963843392
{'scaleFactor': 30, 'timeStep': 63, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([10.690413  ,  8.20991   ,  0.06027338], dtype=float32)}
episode index:990
target Thresh 14.914999092851374
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([5.773385 , 9.918431 , 1.6099644], dtype=float32)}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.6134878107270391
{'scaleFactor': 30, 'timeStep': 5, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([ 4.6737027, 11.75228  ,  2.0201817], dtype=float32)}
episode index:991
target Thresh 14.91542303664442
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([4.856338 , 8.250874 , 6.0156717], dtype=float32)}
done in step count: 69
reward sum = 0.4998370298991989
running average episode reward sum: 0.6133732434076563
{'scaleFactor': 30, 'timeStep': 70, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([3.9597292, 6.8887033, 3.015812 ], dtype=float32)}
episode index:992
target Thresh 14.915844866008975
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([8.300787 , 8.780237 , 2.4739702], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6137625956298036
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([8.300787 , 8.780237 , 2.4739702], dtype=float32)}
episode index:993
target Thresh 14.916264591490798
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([12.04114   ,  7.126779  ,  0.06910989], dtype=float32)}
done in step count: 81
reward sum = 0.4430479816261725
running average episode reward sum: 0.6135908505452929
{'scaleFactor': 30, 'timeStep': 82, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([3.3319612, 2.078387 , 4.807291 ], dtype=float32)}
episode index:994
target Thresh 14.916682223583047
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([11.623915 ,  6.9547157,  4.9111156], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6139792014492675
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([11.623915 ,  6.9547157,  4.9111156], dtype=float32)}
episode index:995
target Thresh 14.917097772726546
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([7.0605564, 8.356658 , 3.2133946], dtype=float32)}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.614346792612471
{'scaleFactor': 30, 'timeStep': 3, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([2.9148319, 7.9151955, 3.5604506], dtype=float32)}
episode index:996
target Thresh 14.917511249310044
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([ 6.567761 , 10.934604 ,  0.6069228], dtype=float32)}
done in step count: 66
reward sum = 0.5151371174238033
running average episode reward sum: 0.6142472844126831
{'scaleFactor': 30, 'timeStep': 67, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([11.123969 ,  6.1613464,  5.3505316], dtype=float32)}
episode index:997
target Thresh 14.917922663670481
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([3.862525 , 9.222968 , 3.2134013], dtype=float32)}
done in step count: 37
reward sum = 0.6894490858690777
running average episode reward sum: 0.6143226369191523
{'scaleFactor': 30, 'timeStep': 38, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([ 7.5117826, 11.239283 ,  5.993519 ], dtype=float32)}
episode index:998
target Thresh 14.918332026093234
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([12.058109 , 10.256592 ,  6.0746136], dtype=float32)}
done in step count: 24
reward sum = 0.7856781408072188
running average episode reward sum: 0.6144941639500714
{'scaleFactor': 30, 'timeStep': 25, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([ 9.995139, 11.835036,  2.25918 ], dtype=float32)}
episode index:999
target Thresh 14.918739346812385
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([12.079716 ,  2.7716746,  5.3538723], dtype=float32)}
done in step count: 195
reward sum = 0.14088441290426768
running average episode reward sum: 0.6140205541990256
{'scaleFactor': 30, 'timeStep': 196, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([0.04577586, 3.3043578 , 4.2663536 ], dtype=float32)}
episode index:1000
target Thresh 14.919144636010973
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([2.9516249, 9.119108 , 3.4056168], dtype=float32)}
done in step count: 37
reward sum = 0.6894490858690777
running average episode reward sum: 0.6140959073775172
{'scaleFactor': 30, 'timeStep': 38, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([1.3342881, 4.4043155, 4.3346634], dtype=float32)}
episode index:1001
target Thresh 14.919547903821254
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([12.26722   ,  9.912728  ,  0.15484892], dtype=float32)}
done in step count: 118
reward sum = 0.3054590259283046
running average episode reward sum: 0.6137878865377474
{'scaleFactor': 30, 'timeStep': 119, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([ 3.833881, 10.032287,  3.003862], dtype=float32)}
episode index:1002
target Thresh 14.919949160324938
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([ 8.172038 , 10.211344 ,  4.6502876], dtype=float32)}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.6141433313168723
{'scaleFactor': 30, 'timeStep': 4, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([11.871254 ,  8.66472  ,  6.1348724], dtype=float32)}
episode index:1003
target Thresh 14.920348415553459
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([12.060446 ,  5.164027 ,  4.7260475], dtype=float32)}
done in step count: 27
reward sum = 0.7623427143471035
running average episode reward sum: 0.6142909402641136
{'scaleFactor': 30, 'timeStep': 28, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([12.293115 ,  6.016632 ,  3.9052274], dtype=float32)}
episode index:1004
target Thresh 14.920745679488222
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([5.1944017, 9.157787 , 5.438946 ], dtype=float32)}
done in step count: 198
reward sum = 0.136700004956598
running average episode reward sum: 0.6138157254031111
{'scaleFactor': 30, 'timeStep': 199, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([12.627748 ,  3.2681246,  3.935192 ], dtype=float32)}
episode index:1005
target Thresh 14.921140962060845
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([4.0891747, 8.827676 , 4.478724 ], dtype=float32)}
done in step count: 34
reward sum = 0.7105532272722921
running average episode reward sum: 0.6139118859417485
{'scaleFactor': 30, 'timeStep': 35, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([12.506514 ,  2.3019922,  4.227206 ], dtype=float32)}
episode index:1006
target Thresh 14.92153427315341
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([5.1003404, 9.157039 , 3.1259136], dtype=float32)}
done in step count: 399
reward sum = 0.0
running average episode reward sum: 0.613302241566434
{'scaleFactor': 30, 'timeStep': 400, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([4.3431716 , 3.6836622 , 0.97109795], dtype=float32)}
episode index:1007
target Thresh 14.921925622598721
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([9.16013  , 9.793167 , 5.7204437], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.6136759496601181
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([10.992998,  9.410669,  6.123766], dtype=float32)}
episode index:1008
target Thresh 14.922315020180527
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([ 9.080602 , 10.060861 ,  3.7502656], dtype=float32)}
done in step count: 44
reward sum = 0.6426116020847181
running average episode reward sum: 0.6137046272145527
{'scaleFactor': 30, 'timeStep': 45, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([10.698364 ,  3.6457083,  5.3077173], dtype=float32)}
episode index:1009
target Thresh 14.922702475633793
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([5.0848985, 9.967644 , 3.714732 ], dtype=float32)}
done in step count: 98
reward sum = 0.37346428045426916
running average episode reward sum: 0.613466765485087
{'scaleFactor': 30, 'timeStep': 99, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([12.296649,  2.822393,  5.08816 ], dtype=float32)}
episode index:1010
target Thresh 14.923087998644922
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([1.9681683, 9.69191  , 5.3136525], dtype=float32)}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.6137726783722709
{'scaleFactor': 30, 'timeStep': 9, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([7.8667994, 8.055142 , 4.6784396], dtype=float32)}
episode index:1011
target Thresh 14.923471598852014
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([2.0526645, 2.0111022, 6.236252 ], dtype=float32)}
done in step count: 104
reward sum = 0.35160920655802225
running average episode reward sum: 0.6135136235582253
{'scaleFactor': 30, 'timeStep': 105, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([6.2680535 , 9.228472  , 0.69612473], dtype=float32)}
episode index:1012
target Thresh 14.923853285845091
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([1.8947649 , 8.928482  , 0.29817888], dtype=float32)}
done in step count: 24
reward sum = 0.7856781408072188
running average episode reward sum: 0.613683578659162
{'scaleFactor': 30, 'timeStep': 25, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([1.6143525, 5.945055 , 3.3898954], dtype=float32)}
episode index:1013
target Thresh 14.924233069166347
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([10.106603 ,  8.926891 ,  2.3616211], dtype=float32)}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.6140449360766579
{'scaleFactor': 30, 'timeStep': 3, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([9.998481, 8.77656 , 1.763643], dtype=float32)}
episode index:1014
target Thresh 14.924610958310387
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([7.9121037, 9.231658 , 5.899377 ], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6144251873711637
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([7.9121037, 9.231658 , 5.899377 ], dtype=float32)}
episode index:1015
target Thresh 14.924986962724457
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([6.025295 , 9.096058 , 6.1222415], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6148046901394991
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([6.025295 , 9.096058 , 6.1222415], dtype=float32)}
episode index:1016
target Thresh 14.92536109180869
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([11.368615 ,  4.638953 ,  2.1097174], dtype=float32)}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6151166475217681
{'scaleFactor': 30, 'timeStep': 8, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([11.378571 ,  7.732642 ,  0.3795948], dtype=float32)}
episode index:1017
target Thresh 14.925733354916328
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([1.8276368, 6.15559  , 2.681347 ], dtype=float32)}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.6154751773375621
{'scaleFactor': 30, 'timeStep': 3, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([1.0068315, 8.052673 , 1.6488854], dtype=float32)}
episode index:1018
target Thresh 14.926103761353973
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([ 9.05852  , 10.0038   ,  0.7011789], dtype=float32)}
done in step count: 47
reward sum = 0.6235253948912
running average episode reward sum: 0.6154830774529239
{'scaleFactor': 30, 'timeStep': 48, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([3.159805, 8.554163, 1.60216 ], dtype=float32)}
episode index:1019
target Thresh 14.926472320381801
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([12.105069 ,  7.167238 ,  3.0654225], dtype=float32)}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.615821423465225
{'scaleFactor': 30, 'timeStep': 5, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([6.8669424, 9.2634   , 3.459325 ], dtype=float32)}
episode index:1020
target Thresh 14.926839041213812
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([0.8345245, 4.6769943, 2.322312 ], dtype=float32)}
done in step count: 244
reward sum = 0.0860968935072644
running average episode reward sum: 0.6153025943467548
{'scaleFactor': 30, 'timeStep': 245, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([12.368285,  9.688632,  6.211638], dtype=float32)}
episode index:1021
target Thresh 14.927203933018042
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([2.9297855, 9.977216 , 2.8334603], dtype=float32)}
done in step count: 82
reward sum = 0.43861750180991077
running average episode reward sum: 0.6151297126515133
{'scaleFactor': 30, 'timeStep': 83, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([2.2013557, 2.859968 , 4.428613 ], dtype=float32)}
episode index:1022
target Thresh 14.927567004916805
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([3.8768816 , 9.120052  , 0.24686205], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.6154961547701334
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([5.4908843 , 9.930225  , 0.65407133], dtype=float32)}
episode index:1023
target Thresh 14.927928265986917
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([11.741571 ,  4.0996056,  4.969455 ], dtype=float32)}
done in step count: 123
reward sum = 0.29048849430996376
running average episode reward sum: 0.6151787644767154
{'scaleFactor': 30, 'timeStep': 124, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([ 3.8446546, 10.891883 ,  2.6554337], dtype=float32)}
episode index:1024
target Thresh 14.92828772525993
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([ 9.135272 , 10.0665   ,  5.0699296], dtype=float32)}
done in step count: 21
reward sum = 0.8097278682212584
running average episode reward sum: 0.6153685684803686
{'scaleFactor': 30, 'timeStep': 22, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([0.89411676, 7.887442  , 3.5059762 ], dtype=float32)}
episode index:1025
target Thresh 14.928645391722334
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([4.838161 , 8.804174 , 3.3221905], dtype=float32)}
done in step count: 16
reward sum = 0.8514577710948755
running average episode reward sum: 0.6155986749156653
{'scaleFactor': 30, 'timeStep': 17, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([9.4582615, 9.28581  , 6.0139728], dtype=float32)}
episode index:1026
target Thresh 14.929001274315818
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([12.285236 ,  2.9010305,  1.0318453], dtype=float32)}
done in step count: 399
reward sum = 0.0
running average episode reward sum: 0.6149992604318136
{'scaleFactor': 30, 'timeStep': 400, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([10.419502 ,  5.2876105,  2.8868804], dtype=float32)}
episode index:1027
target Thresh 14.92935538193746
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([9.999413 , 5.3698263, 3.0808346], dtype=float32)}
done in step count: 25
reward sum = 0.7778213593991467
running average episode reward sum: 0.6151576476876184
{'scaleFactor': 30, 'timeStep': 26, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([11.614308 ,  2.6134121,  5.125988 ], dtype=float32)}
episode index:1028
target Thresh 14.929707723439973
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([11.073853 ,  4.692283 ,  1.6165586], dtype=float32)}
done in step count: 121
reward sum = 0.296386587399208
running average episode reward sum: 0.6148478604570174
{'scaleFactor': 30, 'timeStep': 122, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([2.2952633, 8.339012 , 3.193732 ], dtype=float32)}
episode index:1029
target Thresh 14.930058307631908
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([12.044066 ,  1.8284628,  5.2425904], dtype=float32)}
done in step count: 102
reward sum = 0.3587482976818919
running average episode reward sum: 0.6145992201048086
{'scaleFactor': 30, 'timeStep': 103, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([ 3.6462808, 11.436905 ,  2.8261929], dtype=float32)}
episode index:1030
target Thresh 14.930407143277895
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([6.9111867, 8.864467 , 3.3141136], dtype=float32)}
done in step count: 139
reward sum = 0.24733868589386818
running average episode reward sum: 0.6142430023218688
{'scaleFactor': 30, 'timeStep': 140, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([10.173716 ,  7.4210787,  5.2472143], dtype=float32)}
episode index:1031
target Thresh 14.930754239098837
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([2.080757 , 3.8174524, 2.2849607], dtype=float32)}
done in step count: 55
reward sum = 0.5753547499769285
running average episode reward sum: 0.6142053199068058
{'scaleFactor': 30, 'timeStep': 56, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([13.904276 ,  7.409211 ,  5.6230474], dtype=float32)}
episode index:1032
target Thresh 14.93109960377215
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([8.435493, 8.944362, 5.275457], dtype=float32)}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.6145595257926656
{'scaleFactor': 30, 'timeStep': 3, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([11.514431,  6.077221,  5.654029], dtype=float32)}
episode index:1033
target Thresh 14.93144324593197
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([4.2025743, 7.093089 , 6.1261578], dtype=float32)}
done in step count: 17
reward sum = 0.8429431933839268
running average episode reward sum: 0.6147803997458486
{'scaleFactor': 30, 'timeStep': 18, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([10.994842,  9.41443 ,  0.071675], dtype=float32)}
episode index:1034
target Thresh 14.931785174169365
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([12.053384,  8.080438,  6.000975], dtype=float32)}
done in step count: 39
reward sum = 0.6757290490602831
running average episode reward sum: 0.6148392873297273
{'scaleFactor': 30, 'timeStep': 40, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([4.589172 , 8.571075 , 1.9433771], dtype=float32)}
episode index:1035
target Thresh 14.932125397032564
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([4.396059 , 8.455708 , 5.5638423], dtype=float32)}
done in step count: 58
reward sum = 0.5582661385478637
running average episode reward sum: 0.6147846800432583
{'scaleFactor': 30, 'timeStep': 59, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([8.350042 , 8.178666 , 1.2417974], dtype=float32)}
episode index:1036
target Thresh 14.932463923027152
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([2.2862842, 7.9302387, 2.9031982], dtype=float32)}
done in step count: 80
reward sum = 0.4475232137638106
running average episode reward sum: 0.6146233864402887
{'scaleFactor': 30, 'timeStep': 81, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([7.0342565, 8.8396015, 6.183265 ], dtype=float32)}
episode index:1037
target Thresh 14.932800760616297
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([11.830824,  8.018498,  1.664736], dtype=float32)}
done in step count: 306
reward sum = 0.046171028276992696
running average episode reward sum: 0.6140757444767402
{'scaleFactor': 30, 'timeStep': 307, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([10.289103 ,  6.0191336,  3.8724308], dtype=float32)}
episode index:1038
target Thresh 14.93313591822096
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([1.9196368, 1.9769008, 0.7945092], dtype=float32)}
done in step count: 399
reward sum = 0.0
running average episode reward sum: 0.6134847187361466
{'scaleFactor': 30, 'timeStep': 400, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([5.406207, 6.841281, 4.698639], dtype=float32)}
episode index:1039
target Thresh 14.933469404220096
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([12.080244 ,  9.262745 ,  3.9291325], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.6138467526604389
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([11.179665 ,  7.5314765,  4.0395074], dtype=float32)}
episode index:1040
target Thresh 14.93380122695087
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([6.8458652, 9.040949 , 1.469676 ], dtype=float32)}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.6141346205709318
{'scaleFactor': 30, 'timeStep': 10, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([2.795787 , 9.418308 , 2.7160523], dtype=float32)}
episode index:1041
target Thresh 14.934131394708873
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([2.1238618, 7.0748024, 2.1445746], dtype=float32)}
done in step count: 72
reward sum = 0.48499137027416284
running average episode reward sum: 0.6140106827107622
{'scaleFactor': 30, 'timeStep': 73, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([7.2107763, 7.2628493, 6.0651565], dtype=float32)}
episode index:1042
target Thresh 14.934459915748311
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([2.2031648, 9.176084 , 2.9706194], dtype=float32)}
done in step count: 100
reward sum = 0.3660323412732292
running average episode reward sum: 0.6137729278292305
{'scaleFactor': 30, 'timeStep': 101, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([7.022903, 8.820421, 2.147013], dtype=float32)}
episode index:1043
target Thresh 14.934786798282229
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([10.296742,  9.533282,  2.759802], dtype=float32)}
done in step count: 90
reward sum = 0.4047319726783238
running average episode reward sum: 0.6135726970292776
{'scaleFactor': 30, 'timeStep': 91, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([12.14731   ,  5.3143954 ,  0.41526002], dtype=float32)}
episode index:1044
target Thresh 14.935112050482708
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([2.1361153, 4.0903034, 0.5670004], dtype=float32)}
done in step count: 270
reward sum = 0.06629832272038531
running average episode reward sum: 0.6130489894940537
{'scaleFactor': 30, 'timeStep': 271, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([11.533809 ,  5.080283 ,  3.9612849], dtype=float32)}
episode index:1045
target Thresh 14.935435680481069
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([1.7819631, 6.124978 , 4.0480123], dtype=float32)}
done in step count: 25
reward sum = 0.7778213593991467
running average episode reward sum: 0.613206515660311
{'scaleFactor': 30, 'timeStep': 26, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([10.204605 ,  9.364429 ,  5.6601305], dtype=float32)}
episode index:1046
target Thresh 14.935757696368082
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([10.290174 ,  8.985626 ,  4.9375634], dtype=float32)}
done in step count: 32
reward sum = 0.7249803359578534
running average episode reward sum: 0.6133132719356669
{'scaleFactor': 30, 'timeStep': 33, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([5.758683 , 9.196924 , 3.3810296], dtype=float32)}
episode index:1047
target Thresh 14.936078106194156
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([1.9034251, 9.819107 , 2.5624893], dtype=float32)}
done in step count: 111
reward sum = 0.3277227574378037
running average episode reward sum: 0.613040761902749
{'scaleFactor': 30, 'timeStep': 112, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([11.769645,  7.413706,  5.902848], dtype=float32)}
episode index:1048
target Thresh 14.936396917969555
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([8.785903 , 9.922841 , 1.7059424], dtype=float32)}
done in step count: 16
reward sum = 0.8514577710948755
running average episode reward sum: 0.6132680421784326
{'scaleFactor': 30, 'timeStep': 17, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([ 7.2463493, 11.871111 ,  1.8404598], dtype=float32)}
episode index:1049
target Thresh 14.936714139664591
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([2.1415164, 9.8878765, 1.7765481], dtype=float32)}
done in step count: 25
reward sum = 0.7778213593991467
running average episode reward sum: 0.6134247596234047
{'scaleFactor': 30, 'timeStep': 26, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([10.007715 ,  5.381622 ,  4.5372386], dtype=float32)}
episode index:1050
target Thresh 14.937029779209823
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([6.170674 , 9.938827 , 0.6265191], dtype=float32)}
done in step count: 27
reward sum = 0.7623427143471035
running average episode reward sum: 0.6135664513024948
{'scaleFactor': 30, 'timeStep': 28, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([ 1.9622116, 11.732722 ,  3.4340258], dtype=float32)}
episode index:1051
target Thresh 14.937343844496256
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([13.632338 ,  1.7412122,  5.46173  ], dtype=float32)}
done in step count: 78
reward sum = 0.4566097477439145
running average episode reward sum: 0.6134172529150816
{'scaleFactor': 30, 'timeStep': 79, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([12.551265 ,  7.013442 ,  2.1128361], dtype=float32)}
episode index:1052
target Thresh 14.937656343375538
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([10.852506 ,  9.979549 ,  6.1104984], dtype=float32)}
done in step count: 51
reward sum = 0.598956006466161
running average episode reward sum: 0.6134035195376374
{'scaleFactor': 30, 'timeStep': 52, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([3.019752, 9.449249, 2.447921], dtype=float32)}
episode index:1053
target Thresh 14.937967283660157
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([10.520049,  9.083807,  2.775965], dtype=float32)}
done in step count: 89
reward sum = 0.40882017442254925
running average episode reward sum: 0.6132094176921771
{'scaleFactor': 30, 'timeStep': 90, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([10.558059 ,  3.6539905,  5.4179897], dtype=float32)}
episode index:1054
target Thresh 14.938276673123635
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([2.066887 , 9.15187  , 5.3402824], dtype=float32)}
done in step count: 73
reward sum = 0.4801414565714212
running average episode reward sum: 0.6130832869233424
{'scaleFactor': 30, 'timeStep': 74, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([ 9.638856, 10.121378,  3.92521 ], dtype=float32)}
episode index:1055
target Thresh 14.93858451950073
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([10.737173 ,  9.962008 ,  6.0647206], dtype=float32)}
done in step count: 100
reward sum = 0.3660323412732292
running average episode reward sum: 0.612849337164204
{'scaleFactor': 30, 'timeStep': 101, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([6.89153  , 7.0929694, 5.158489 ], dtype=float32)}
episode index:1056
target Thresh 14.93889083048761
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([2.7496727, 5.9802027, 0.9916048], dtype=float32)}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.6131875109227998
{'scaleFactor': 30, 'timeStep': 4, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([ 6.613096  , 10.14638   ,  0.05428445], dtype=float32)}
episode index:1057
target Thresh 14.939195613742072
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([6.2699075, 9.045318 , 1.6491628], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6135531181903585
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([6.2699075, 9.045318 , 1.6491628], dtype=float32)}
episode index:1058
target Thresh 14.93949887688371
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([9.402296  , 8.926108  , 0.84194344], dtype=float32)}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.6138277442119057
{'scaleFactor': 30, 'timeStep': 11, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([7.3437476, 9.640672 , 2.8788495], dtype=float32)}
episode index:1059
target Thresh 14.939800627494117
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([11.589601 , 10.268901 ,  4.5995617], dtype=float32)}
done in step count: 34
reward sum = 0.7105532272722921
running average episode reward sum: 0.613918994667623
{'scaleFactor': 30, 'timeStep': 35, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([3.707418 , 9.689941 , 2.4697237], dtype=float32)}
episode index:1060
target Thresh 14.940100873117078
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([ 7.0391417 , 10.172562  ,  0.29536402], dtype=float32)}
done in step count: 70
reward sum = 0.49483865960020695
running average episode reward sum: 0.6138067606100666
{'scaleFactor': 30, 'timeStep': 71, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([10.20846  ,  1.2967489,  4.491256 ], dtype=float32)}
episode index:1061
target Thresh 14.940399621258745
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([11.911623 ,  3.9430282,  4.817423 ], dtype=float32)}
done in step count: 47
reward sum = 0.6235253948912
running average episode reward sum: 0.6138159118664518
{'scaleFactor': 30, 'timeStep': 48, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([10.282952,  8.357621,  2.797394], dtype=float32)}
episode index:1062
target Thresh 14.940696879387843
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([0.48162246, 3.684719  , 4.142173  ], dtype=float32)}
done in step count: 73
reward sum = 0.4801414565714212
running average episode reward sum: 0.6136901597918563
{'scaleFactor': 30, 'timeStep': 74, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([2.2628613, 8.967005 , 1.7231611], dtype=float32)}
episode index:1063
target Thresh 14.940992654935835
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([ 6.053523, 10.184009,  4.808239], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.614043834453706
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([ 5.740915, 10.212995,  4.934455], dtype=float32)}
episode index:1064
target Thresh 14.941286955297125
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([2.070192 , 3.0495791, 1.8473917], dtype=float32)}
done in step count: 71
reward sum = 0.4898902730042049
running average episode reward sum: 0.613927258339669
{'scaleFactor': 30, 'timeStep': 72, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([11.625479 ,  5.227574 ,  5.8673778], dtype=float32)}
episode index:1065
target Thresh 14.941579787829243
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([7.0692396, 9.036599 , 1.4037979], dtype=float32)}
done in step count: 164
reward sum = 0.19238531289396707
running average episode reward sum: 0.6135318156141102
{'scaleFactor': 30, 'timeStep': 165, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([2.3493924, 4.4357862, 3.438965 ], dtype=float32)}
episode index:1066
target Thresh 14.941871159853012
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([6.139176 , 9.1940155, 3.0878172], dtype=float32)}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.613875365927499
{'scaleFactor': 30, 'timeStep': 3, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([4.1722164, 8.197986 , 3.324556 ], dtype=float32)}
episode index:1067
target Thresh 14.94216107865275
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([ 5.024826 , 10.016265 ,  3.0748954], dtype=float32)}
done in step count: 109
reward sum = 0.334376856889913
running average episode reward sum: 0.613613663203681
{'scaleFactor': 30, 'timeStep': 110, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([10.48145  ,  5.1146116,  4.042976 ], dtype=float32)}
episode index:1068
target Thresh 14.942449551476443
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([4.11004  , 9.88939  , 4.0572553], dtype=float32)}
done in step count: 22
reward sum = 0.8016305895390459
running average episode reward sum: 0.6137895443321519
{'scaleFactor': 30, 'timeStep': 23, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([ 8.488115 , 10.301032 ,  6.2478666], dtype=float32)}
episode index:1069
target Thresh 14.942736585535926
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([ 6.101118, 10.076286,  5.732133], dtype=float32)}
done in step count: 399
reward sum = 0.0
running average episode reward sum: 0.613215909243991
{'scaleFactor': 30, 'timeStep': 400, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([-0.4707047, 11.991423 ,  1.6395167], dtype=float32)}
episode index:1070
target Thresh 14.943022188007063
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([0.2452352, 2.6330032, 3.8493354], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6135770521858734
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([0.2452352, 2.6330032, 3.8493354], dtype=float32)}
episode index:1071
target Thresh 14.943306366029933
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([5.905091, 8.976161, 4.067497], dtype=float32)}
done in step count: 223
reward sum = 0.10632818368521114
running average episode reward sum: 0.6131038722712273
{'scaleFactor': 30, 'timeStep': 224, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([11.6567955 ,  6.7190094 ,  0.36911076], dtype=float32)}
episode index:1072
target Thresh 14.943589126709002
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([9.93939  , 9.930524 , 2.4146914], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6134644464815989
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([9.93939  , 9.930524 , 2.4146914], dtype=float32)}
episode index:1073
target Thresh 14.943870477113299
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([3.992755, 8.763065, 4.453658], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.6138150382446514
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([4.0864735, 8.681926 , 3.9183223], dtype=float32)}
episode index:1074
target Thresh 14.9441504242766
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([1.7813331, 7.9458575, 5.927963 ], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6141742800695401
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([1.7813331, 7.9458575, 5.927963 ], dtype=float32)}
episode index:1075
target Thresh 14.944428975197601
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([8.867964 , 9.77439  , 3.5898304], dtype=float32)}
done in step count: 35
reward sum = 0.7034476949995692
running average episode reward sum: 0.6142572479272818
{'scaleFactor': 30, 'timeStep': 36, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([13.350411 ,  3.8055925,  6.0002084], dtype=float32)}
episode index:1076
target Thresh 14.944706136840086
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([12.278246,  8.230369,  2.095281], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.6146061269914161
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([11.728782 ,  9.992681 ,  2.0254936], dtype=float32)}
episode index:1077
target Thresh 14.944981916133115
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([1.9022864, 1.871626 , 5.056518 ], dtype=float32)}
done in step count: 164
reward sum = 0.19238531289396707
running average episode reward sum: 0.614214456477411
{'scaleFactor': 30, 'timeStep': 165, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([9.566007 , 7.7529006, 5.0286374], dtype=float32)}
episode index:1078
target Thresh 14.945256319971179
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([4.3124766, 7.887123 , 4.1063943], dtype=float32)}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.6145535533666813
{'scaleFactor': 30, 'timeStep': 3, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([2.8228369, 6.605598 , 3.498915 ], dtype=float32)}
episode index:1079
target Thresh 14.945529355214392
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([13.785448 ,  1.2327578,  5.394225 ], dtype=float32)}
done in step count: 212
reward sum = 0.11875755691154309
running average episode reward sum: 0.6140944829995932
{'scaleFactor': 30, 'timeStep': 213, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([3.689911 , 5.1932044, 4.4430094], dtype=float32)}
episode index:1080
target Thresh 14.945801028688647
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([2.8663278, 9.938119 , 6.09058  ], dtype=float32)}
done in step count: 17
reward sum = 0.8429431933839268
running average episode reward sum: 0.6143061839342688
{'scaleFactor': 30, 'timeStep': 18, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([2.8942895, 2.8767426, 4.24405  ], dtype=float32)}
episode index:1081
target Thresh 14.946071347185798
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([12.481505 ,  6.5854564,  0.9078789], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.6146534055757343
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([13.208728,  8.233785,  1.237341], dtype=float32)}
episode index:1082
target Thresh 14.94634031746382
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([9.83999  , 9.208185 , 2.7968118], dtype=float32)}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.6149209297395691
{'scaleFactor': 30, 'timeStep': 11, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([10.612069,  5.660182,  5.611783], dtype=float32)}
episode index:1083
target Thresh 14.946607946246983
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([12.0502   ,  9.111553 ,  2.1350749], dtype=float32)}
done in step count: 270
reward sum = 0.06629832272038531
running average episode reward sum: 0.6144148203234998
{'scaleFactor': 30, 'timeStep': 271, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([2.0968785, 7.6923504, 4.526028 ], dtype=float32)}
episode index:1084
target Thresh 14.946874240226022
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([ 7.000926, 10.052629,  2.632285], dtype=float32)}
done in step count: 165
reward sum = 0.1904614597650274
running average episode reward sum: 0.614024079899022
{'scaleFactor': 30, 'timeStep': 166, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([10.662083 ,  4.7173038,  4.5344677], dtype=float32)}
episode index:1085
target Thresh 14.9471392060583
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([2.34894  , 3.0898113, 4.8563166], dtype=float32)}
done in step count: 146
reward sum = 0.23053581831852593
running average episode reward sum: 0.6136709599528153
{'scaleFactor': 30, 'timeStep': 147, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([10.449142,  9.710071,  5.927857], dtype=float32)}
episode index:1086
target Thresh 14.947402850367975
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([4.021446 , 9.93651  , 6.1212287], dtype=float32)}
done in step count: 17
reward sum = 0.8429431933839268
running average episode reward sum: 0.6138818819706912
{'scaleFactor': 30, 'timeStep': 18, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([3.9767516, 6.352155 , 6.151781 ], dtype=float32)}
episode index:1087
target Thresh 14.94766517974617
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([2.4021015, 5.922171 , 1.0312302], dtype=float32)}
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.6141405734893383
{'scaleFactor': 30, 'timeStep': 12, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([6.195364  , 9.749069  , 0.02575415], dtype=float32)}
episode index:1088
target Thresh 14.947926200751134
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([3.852872, 9.877148, 2.326991], dtype=float32)}
done in step count: 48
reward sum = 0.617290140942288
running average episode reward sum: 0.6141434656541251
{'scaleFactor': 30, 'timeStep': 49, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([11.420792 ,  5.4004035,  5.552748 ], dtype=float32)}
episode index:1089
target Thresh 14.948185919908402
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([9.8972845, 9.984942 , 0.8634497], dtype=float32)}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6144351371057334
{'scaleFactor': 30, 'timeStep': 8, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([ 4.556388 , 10.533604 ,  2.8725686], dtype=float32)}
episode index:1090
target Thresh 14.948444343710971
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([9.842278 , 9.881485 , 2.9383051], dtype=float32)}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.6147524247985787
{'scaleFactor': 30, 'timeStep': 5, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([ 4.3837028, 10.551914 ,  2.3300416], dtype=float32)}
episode index:1091
target Thresh 14.94870147861945
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([6.88266 , 9.999325, 5.463535], dtype=float32)}
done in step count: 34
reward sum = 0.7105532272722921
running average episode reward sum: 0.6148401544711737
{'scaleFactor': 30, 'timeStep': 35, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([3.5776558, 5.265335 , 4.6345677], dtype=float32)}
episode index:1092
target Thresh 14.94895733106222
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([12.053989, 10.225888,  5.600836], dtype=float32)}
done in step count: 42
reward sum = 0.6556592205741436
running average episode reward sum: 0.6148775003687976
{'scaleFactor': 30, 'timeStep': 43, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([6.4500985, 8.029393 , 2.5582287], dtype=float32)}
episode index:1093
target Thresh 14.949211907435606
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([9.009872, 8.482357, 5.606912], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6152295319041096
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([9.009872, 8.482357, 5.606912], dtype=float32)}
episode index:1094
target Thresh 14.949465214104036
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([8.480295 , 7.6220665, 3.6465938], dtype=float32)}
done in step count: 188
reward sum = 0.1511529349531471
running average episode reward sum: 0.6148057176603188
{'scaleFactor': 30, 'timeStep': 189, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([2.2233984, 3.5321734, 4.863942 ], dtype=float32)}
episode index:1095
target Thresh 14.949717257400186
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([12.101223  ,  9.195114  ,  0.28380376], dtype=float32)}
done in step count: 89
reward sum = 0.40882017442254925
running average episode reward sum: 0.6146177746464156
{'scaleFactor': 30, 'timeStep': 90, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([11.338721 ,  5.3230014,  5.40548  ], dtype=float32)}
episode index:1096
target Thresh 14.949968043625152
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([ 2.9669898, 10.008007 ,  2.300391 ], dtype=float32)}
done in step count: 70
reward sum = 0.49483865960020695
running average episode reward sum: 0.6145085867566743
{'scaleFactor': 30, 'timeStep': 71, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([10.358792 ,  7.974924 ,  0.4495204], dtype=float32)}
episode index:1097
target Thresh 14.9502175790486
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([8.337734 , 8.216825 , 6.1081696], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.6148505643643641
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([10.067547,  8.167035,  6.223985], dtype=float32)}
episode index:1098
target Thresh 14.950465869908935
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([5.1981773, 9.103638 , 1.4974153], dtype=float32)}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.615130722808462
{'scaleFactor': 30, 'timeStep': 9, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([ 7.6084337, 11.743479 ,  0.4550095], dtype=float32)}
episode index:1099
target Thresh 14.950712922413436
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([1.7670147 , 2.8754685 , 0.24360117], dtype=float32)}
done in step count: 130
reward sum = 0.27075425951199406
running average episode reward sum: 0.6148176532963744
{'scaleFactor': 30, 'timeStep': 131, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([11.306044 ,  5.26065  ,  5.9286084], dtype=float32)}
episode index:1100
target Thresh 14.950958742738433
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([1.8121235, 9.00378  , 3.6968405], dtype=float32)}
done in step count: 72
reward sum = 0.48499137027416284
running average episode reward sum: 0.6146997365997149
{'scaleFactor': 30, 'timeStep': 73, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([ 9.66247 , 10.754145,  5.166568], dtype=float32)}
episode index:1101
target Thresh 14.95120333702944
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([1.7621841, 8.257678 , 2.8482263], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6150493738623285
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([1.7621841, 8.257678 , 2.8482263], dtype=float32)}
episode index:1102
target Thresh 14.951446711401333
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([ 4.2608404, 10.079493 ,  2.3900414], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6153983771498513
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([ 4.2608404, 10.079493 ,  2.3900414], dtype=float32)}
episode index:1103
target Thresh 14.951688871938483
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([4.8796806, 7.7386265, 5.577516 ], dtype=float32)}
done in step count: 152
reward sum = 0.21704489667280757
running average episode reward sum: 0.6150375497218831
{'scaleFactor': 30, 'timeStep': 153, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([10.159742,  2.271772,  5.37285 ], dtype=float32)}
episode index:1104
target Thresh 14.951929824694915
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([12.269229 ,  8.043957 ,  6.2201695], dtype=float32)}
done in step count: 35
reward sum = 0.7034476949995692
running average episode reward sum: 0.6151175589031298
{'scaleFactor': 30, 'timeStep': 36, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([5.6562867, 7.931075 , 2.6122203], dtype=float32)}
episode index:1105
target Thresh 14.95216957569446
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([6.956457 , 8.812935 , 2.0434124], dtype=float32)}
done in step count: 42
reward sum = 0.6556592205741436
running average episode reward sum: 0.6151542150167565
{'scaleFactor': 30, 'timeStep': 43, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([8.895839 , 8.753171 , 5.2601967], dtype=float32)}
episode index:1106
target Thresh 14.952408130930907
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([1.3651574, 7.7479153, 1.6736273], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.6154928290953321
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([1.2677342, 9.596803 , 1.344833 ], dtype=float32)}
episode index:1107
target Thresh 14.952645496368149
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([ 2.8077276, 10.845065 ,  1.122116 ], dtype=float32)}
done in step count: 238
reward sum = 0.09144844271229938
running average episode reward sum: 0.6150198648476939
{'scaleFactor': 30, 'timeStep': 239, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([12.456647 ,  6.78322  ,  4.3047605], dtype=float32)}
episode index:1108
target Thresh 14.952881677940331
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([ 4.1377344, 10.079811 ,  4.8214626], dtype=float32)}
done in step count: 35
reward sum = 0.7034476949995692
running average episode reward sum: 0.6150996013942691
{'scaleFactor': 30, 'timeStep': 36, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([ 9.965513, 10.61794 ,  5.678584], dtype=float32)}
episode index:1109
target Thresh 14.953116681552011
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([1.8012137, 4.906542 , 4.6209393], dtype=float32)}
done in step count: 104
reward sum = 0.35160920655802225
running average episode reward sum: 0.6148622226601823
{'scaleFactor': 30, 'timeStep': 105, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([10.399326 ,  7.6812153,  6.219003 ], dtype=float32)}
episode index:1110
target Thresh 14.953350513078286
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([ 8.0392065, 10.09074  ,  6.0180583], dtype=float32)}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.615173414187941
{'scaleFactor': 30, 'timeStep': 5, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([11.252978 ,  3.4367158,  4.4963126], dtype=float32)}
episode index:1111
target Thresh 14.953583178364958
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([2.0726874 , 4.988976  , 0.49229467], dtype=float32)}
done in step count: 80
reward sum = 0.4475232137638106
running average episode reward sum: 0.6150226496192144
{'scaleFactor': 30, 'timeStep': 81, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([11.831814 ,  2.0842783,  4.7074423], dtype=float32)}
episode index:1112
target Thresh 14.953814683228673
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([8.849447 , 9.089607 , 1.3336458], dtype=float32)}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6153075037955735
{'scaleFactor': 30, 'timeStep': 8, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([10.558358 , 10.236667 ,  0.9829492], dtype=float32)}
episode index:1113
target Thresh 14.954045033457064
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([2.0995183, 2.1937833, 4.5488415], dtype=float32)}
done in step count: 42
reward sum = 0.6556592205741436
running average episode reward sum: 0.6153437261625203
{'scaleFactor': 30, 'timeStep': 43, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([5.654168 , 7.4080667, 0.5245473], dtype=float32)}
episode index:1114
target Thresh 14.954274234808894
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([9.893837, 9.063234, 4.085512], dtype=float32)}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6156362251968148
{'scaleFactor': 30, 'timeStep': 7, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([10.03185  ,  7.1038265,  4.225186 ], dtype=float32)}
episode index:1115
target Thresh 14.954502293014217
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([ 9.020497  , 10.060172  ,  0.03756809], dtype=float32)}
done in step count: 104
reward sum = 0.35160920655802225
running average episode reward sum: 0.6153996418467801
{'scaleFactor': 30, 'timeStep': 105, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([6.5243154, 8.055524 , 4.8445826], dtype=float32)}
episode index:1116
target Thresh 14.954729213774494
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([6.799073, 8.02694 , 5.875281], dtype=float32)}
done in step count: 51
reward sum = 0.598956006466161
running average episode reward sum: 0.6153849205975584
{'scaleFactor': 30, 'timeStep': 52, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([ 9.884287  , 10.19012   ,  0.04708579], dtype=float32)}
episode index:1117
target Thresh 14.954955002762757
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([10.047381  ,  9.153068  ,  0.04833191], dtype=float32)}
done in step count: 57
reward sum = 0.5639051904523875
running average episode reward sum: 0.6153388743273033
{'scaleFactor': 30, 'timeStep': 58, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([6.951997 , 8.490858 , 3.0056322], dtype=float32)}
episode index:1118
target Thresh 14.955179665623744
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([ 6.2529454, 10.082534 ,  2.5204463], dtype=float32)}
done in step count: 118
reward sum = 0.3054590259283046
running average episode reward sum: 0.6150619486361513
{'scaleFactor': 30, 'timeStep': 119, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([1.4288054, 7.620294 , 3.6493044], dtype=float32)}
episode index:1119
target Thresh 14.955403207974035
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([ 9.196132 , 11.800541 ,  2.3228738], dtype=float32)}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6153533934582627
{'scaleFactor': 30, 'timeStep': 7, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([5.566326 , 9.940929 , 3.6176376], dtype=float32)}
episode index:1120
target Thresh 14.955625635402205
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([5.9622374, 9.666128 , 2.384556 ], dtype=float32)}
done in step count: 67
reward sum = 0.5099857462495653
running average episode reward sum: 0.6152593991253379
{'scaleFactor': 30, 'timeStep': 68, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([ 8.310726 , 10.995884 ,  1.0063968], dtype=float32)}
episode index:1121
target Thresh 14.955846953468948
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([1.7239522, 7.0829506, 4.7802277], dtype=float32)}
done in step count: 91
reward sum = 0.40068465295154054
running average episode reward sum: 0.6150681560360564
{'scaleFactor': 30, 'timeStep': 92, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([ 7.3836727, 11.562075 ,  6.2043924], dtype=float32)}
episode index:1122
target Thresh 14.956067167707229
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([8.001059 , 8.95462  , 3.3184295], dtype=float32)}
done in step count: 41
reward sum = 0.6622820409839835
running average episode reward sum: 0.6151101986762593
{'scaleFactor': 30, 'timeStep': 42, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([1.7791476, 3.8130627, 6.0397425], dtype=float32)}
episode index:1123
target Thresh 14.956286283622413
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([2.2536993, 4.098396 , 5.2456837], dtype=float32)}
done in step count: 209
reward sum = 0.12239274379499834
running average episode reward sum: 0.614671837951276
{'scaleFactor': 30, 'timeStep': 210, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([10.52087   ,  8.514465  ,  0.31370515], dtype=float32)}
episode index:1124
target Thresh 14.95650430669241
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([ 7.9887033, 10.061372 ,  1.4316411], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6150143518730972
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([ 7.9887033, 10.061372 ,  1.4316411], dtype=float32)}
episode index:1125
target Thresh 14.956721242367811
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([3.2186508, 7.141947 , 4.1894283], dtype=float32)}
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.6152553558871673
{'scaleFactor': 30, 'timeStep': 13, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([ 6.1833363 , 10.167748  ,  0.51615405], dtype=float32)}
episode index:1126
target Thresh 14.956937096072016
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([10.333122,  7.941616,  4.107319], dtype=float32)}
done in step count: 21
reward sum = 0.8097278682212584
running average episode reward sum: 0.6154279135733555
{'scaleFactor': 30, 'timeStep': 22, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([6.4922   , 8.6434555, 2.3833952], dtype=float32)}
episode index:1127
target Thresh 14.957151873201381
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([10.889323,  9.989446,  2.716359], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6157688462740883
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([10.889323,  9.989446,  2.716359], dtype=float32)}
episode index:1128
target Thresh 14.957365579125344
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([ 5.9477735, 10.215231 ,  1.079073 ], dtype=float32)}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.6160915488017463
{'scaleFactor': 30, 'timeStep': 3, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([ 6.0451136, 10.59527  ,  1.3228538], dtype=float32)}
episode index:1129
target Thresh 14.957578219186564
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([10.856721 ,  9.91965  ,  3.3388138], dtype=float32)}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6163795033155509
{'scaleFactor': 30, 'timeStep': 7, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([11.518505 ,  6.8725586,  5.4761114], dtype=float32)}
episode index:1130
target Thresh 14.957789798701054
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([9.017603  , 8.864144  , 0.09294432], dtype=float32)}
done in step count: 16
reward sum = 0.8514577710948755
running average episode reward sum: 0.6165873532428535
{'scaleFactor': 30, 'timeStep': 17, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([13.652106,  8.927512,  5.791488], dtype=float32)}
episode index:1131
target Thresh 14.958000322958314
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([2.2124631, 3.8475618, 1.4202348], dtype=float32)}
done in step count: 184
reward sum = 0.15735328210778962
running average episode reward sum: 0.6161816694344303
{'scaleFactor': 30, 'timeStep': 185, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([12.93008  ,  4.830367 ,  4.6735787], dtype=float32)}
episode index:1132
target Thresh 14.95820979722146
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([10.951767 , 10.247291 ,  4.3038554], dtype=float32)}
done in step count: 19
reward sum = 0.8261686238355866
running average episode reward sum: 0.6163670065521718
{'scaleFactor': 30, 'timeStep': 20, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([2.1720912, 8.022473 , 3.9645457], dtype=float32)}
episode index:1133
target Thresh 14.95841822672736
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([9.955088, 8.873872, 5.193931], dtype=float32)}
done in step count: 321
reward sum = 0.03970977861200674
running average episode reward sum: 0.6158584904781504
{'scaleFactor': 30, 'timeStep': 322, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([2.826625 , 5.07296  , 4.0108547], dtype=float32)}
episode index:1134
target Thresh 14.958625616686762
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([11.802299 ,  6.0843034,  6.14158  ], dtype=float32)}
done in step count: 118
reward sum = 0.3054590259283046
running average episode reward sum: 0.6155850107737012
{'scaleFactor': 30, 'timeStep': 119, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([7.7505445, 7.7617106, 3.005207 ], dtype=float32)}
episode index:1135
target Thresh 14.958831972284427
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([11.834563,  9.122746,  4.284006], dtype=float32)}
done in step count: 35
reward sum = 0.7034476949995692
running average episode reward sum: 0.6156623546858718
{'scaleFactor': 30, 'timeStep': 36, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([0.24811386, 4.331841  , 4.8158894 ], dtype=float32)}
episode index:1136
target Thresh 14.959037298679254
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([3.1125798, 9.024664 , 4.876443 ], dtype=float32)}
done in step count: 95
reward sum = 0.38489607889348454
running average episode reward sum: 0.6154593940211468
{'scaleFactor': 30, 'timeStep': 96, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([9.891564 , 9.036032 , 1.2858186], dtype=float32)}
episode index:1137
target Thresh 14.959241601004415
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([8.900375 , 9.239433 , 4.6596346], dtype=float32)}
done in step count: 45
reward sum = 0.6361854860638709
running average episode reward sum: 0.6154776067558064
{'scaleFactor': 30, 'timeStep': 46, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([1.7435322, 3.5182638, 5.8170877], dtype=float32)}
episode index:1138
target Thresh 14.95944488436748
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([10.668586,  7.766455,  4.155237], dtype=float32)}
done in step count: 263
reward sum = 0.07113055202541568
running average episode reward sum: 0.6149996901142522
{'scaleFactor': 30, 'timeStep': 264, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([ 2.4843435, 10.446982 ,  3.7767467], dtype=float32)}
episode index:1139
target Thresh 14.95964715385054
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([3.5911608, 5.397878 , 0.9173681], dtype=float32)}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6152944185000291
{'scaleFactor': 30, 'timeStep': 6, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([4.4564137, 8.806071 , 1.7462503], dtype=float32)}
episode index:1140
target Thresh 14.959848414510345
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([10.735226 ,  8.310354 ,  2.0934112], dtype=float32)}
done in step count: 69
reward sum = 0.4998370298991989
running average episode reward sum: 0.6151932288518251
{'scaleFactor': 30, 'timeStep': 70, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([4.3974223, 9.243345 , 5.2485967], dtype=float32)}
episode index:1141
target Thresh 14.960048671378422
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([1.9246161, 3.8739   , 3.6189225], dtype=float32)}
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.6154229379535301
{'scaleFactor': 30, 'timeStep': 14, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([5.98559  , 7.657705 , 0.2231406], dtype=float32)}
episode index:1142
target Thresh 14.9602479294612
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([12.129055 ,  2.6697073,  5.4841313], dtype=float32)}
done in step count: 286
reward sum = 0.05645022209082803
running average episode reward sum: 0.6149338979571498
{'scaleFactor': 30, 'timeStep': 287, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([2.5593038, 8.999767 , 2.4312017], dtype=float32)}
episode index:1143
target Thresh 14.960446193740147
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([12.004393 ,  4.806224 ,  1.4144446], dtype=float32)}
done in step count: 39
reward sum = 0.6757290490602831
running average episode reward sum: 0.6149870405717504
{'scaleFactor': 30, 'timeStep': 40, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([10.739287 ,  3.7846117,  4.0992236], dtype=float32)}
episode index:1144
target Thresh 14.960643469171877
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([6.2199683, 9.070279 , 1.1617978], dtype=float32)}
done in step count: 103
reward sum = 0.355160814705073
running average episode reward sum: 0.6147601181037445
{'scaleFactor': 30, 'timeStep': 104, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([12.244502 ,  2.8067307,  5.420198 ], dtype=float32)}
episode index:1145
target Thresh 14.960839760688286
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([12.06411  ,  9.201997 ,  5.1739016], dtype=float32)}
done in step count: 86
reward sum = 0.421334222154768
running average episode reward sum: 0.614591334599426
{'scaleFactor': 30, 'timeStep': 87, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([ 5.3138294, 10.93154  ,  2.8913193], dtype=float32)}
episode index:1146
target Thresh 14.961035073196673
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([1.8819312, 2.8205876, 3.1455803], dtype=float32)}
done in step count: 131
reward sum = 0.2680467169168741
running average episode reward sum: 0.6142892032849687
{'scaleFactor': 30, 'timeStep': 132, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([ 8.14525  , 11.856639 ,  1.1232158], dtype=float32)}
episode index:1147
target Thresh 14.961229411579861
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([11.96488 ,  6.098079,  6.201876], dtype=float32)}
done in step count: 232
reward sum = 0.09713262969004904
running average episode reward sum: 0.613838718464764
{'scaleFactor': 30, 'timeStep': 233, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([3.6853232, 8.130183 , 1.4489205], dtype=float32)}
episode index:1148
target Thresh 14.961422780696317
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([11.24083  ,  7.505974 ,  5.3700523], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6141748031310261
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([11.24083  ,  7.505974 ,  5.3700523], dtype=float32)}
episode index:1149
target Thresh 14.961615185380284
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([11.728502 ,  5.8601723,  5.8045545], dtype=float32)}
done in step count: 133
reward sum = 0.2627125872502283
running average episode reward sum: 0.6138691838128689
{'scaleFactor': 30, 'timeStep': 134, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([ 4.9740486, 11.026047 ,  1.3998052], dtype=float32)}
episode index:1150
target Thresh 14.961806630441883
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([10.226164 ,  7.4281178,  2.7645001], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.6141959699259768
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([8.33463  , 8.30674  , 3.0195062], dtype=float32)}
episode index:1151
target Thresh 14.961997120667258
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([7.0014358, 8.858615 , 5.4562936], dtype=float32)}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.6144478675866389
{'scaleFactor': 30, 'timeStep': 11, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([9.718164  , 7.5644    , 0.02004832], dtype=float32)}
episode index:1152
target Thresh 14.962186660818666
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([1.8923882, 7.9799438, 4.0689282], dtype=float32)}
done in step count: 14
reward sum = 0.8687458127689782
running average episode reward sum: 0.6146684208782108
{'scaleFactor': 30, 'timeStep': 15, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([11.543685 , 10.761313 ,  0.3435411], dtype=float32)}
episode index:1153
target Thresh 14.962375255634628
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([11.728357 ,  2.1001399,  4.6942563], dtype=float32)}
done in step count: 94
reward sum = 0.3887839180742268
running average episode reward sum: 0.6144726804078434
{'scaleFactor': 30, 'timeStep': 95, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([3.1843865, 6.5427985, 3.9961674], dtype=float32)}
episode index:1154
target Thresh 14.96256290983002
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([8.894661 , 8.996002 , 3.9534843], dtype=float32)}
done in step count: 149
reward sum = 0.2236886739786474
running average episode reward sum: 0.6141343392767359
{'scaleFactor': 30, 'timeStep': 150, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([9.322363 , 8.247212 , 5.7306037], dtype=float32)}
episode index:1155
target Thresh 14.962749628096208
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([10.159803 ,  7.176471 ,  3.3563957], dtype=float32)}
done in step count: 34
reward sum = 0.7105532272722921
running average episode reward sum: 0.6142177466192926
{'scaleFactor': 30, 'timeStep': 35, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([3.5874238, 8.213666 , 1.0619382], dtype=float32)}
episode index:1156
target Thresh 14.962935415101159
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([11.664422 ,  4.9959836,  1.5041236], dtype=float32)}
done in step count: 211
reward sum = 0.11995712819347787
running average episode reward sum: 0.6137905550735486
{'scaleFactor': 30, 'timeStep': 212, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([ 7.7019453, 11.897536 ,  3.1001167], dtype=float32)}
episode index:1157
target Thresh 14.963120275489556
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([2.495031 , 5.070266 , 5.3708043], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6141240692746941
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([2.495031 , 5.070266 , 5.3708043], dtype=float32)}
episode index:1158
target Thresh 14.963304213882921
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([4.1368713 , 6.225397  , 0.28174275], dtype=float32)}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6144147215444312
{'scaleFactor': 30, 'timeStep': 6, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([9.70294  , 9.616794 , 0.5149375], dtype=float32)}
episode index:1159
target Thresh 14.96348723487972
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([2.085212, 8.908684, 5.185384], dtype=float32)}
done in step count: 50
reward sum = 0.6050060671375364
running average episode reward sum: 0.6144066106354598
{'scaleFactor': 30, 'timeStep': 51, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([10.245823 , 10.761304 ,  1.6493952], dtype=float32)}
episode index:1160
target Thresh 14.963669343055491
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([ 8.016787  , 10.028014  ,  0.23575167], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6147387324178581
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([ 8.016787  , 10.028014  ,  0.23575167], dtype=float32)}
episode index:1161
target Thresh 14.963850542962945
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([2.1511054, 6.9961414, 4.2619443], dtype=float32)}
done in step count: 253
reward sum = 0.07865099717364833
running average episode reward sum: 0.6142773832481128
{'scaleFactor': 30, 'timeStep': 254, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([12.168176 ,  6.0234604,  5.562546 ], dtype=float32)}
episode index:1162
target Thresh 14.964030839132091
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([12.401067 , 10.44034  ,  6.0566363], dtype=float32)}
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.6145190520967891
{'scaleFactor': 30, 'timeStep': 12, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([5.5455675, 9.378318 , 3.4969926], dtype=float32)}
episode index:1163
target Thresh 14.96421023607034
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([11.881345 ,  1.9134314,  6.173871 ], dtype=float32)}
done in step count: 65
reward sum = 0.5203405226503064
running average episode reward sum: 0.6144381427072302
{'scaleFactor': 30, 'timeStep': 66, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([3.244911 , 7.108858 , 2.3030934], dtype=float32)}
episode index:1164
target Thresh 14.96438873826263
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([9.130409  , 9.170439  , 0.98836213], dtype=float32)}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.6147436026705716
{'scaleFactor': 30, 'timeStep': 4, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([ 7.6115427, 10.53626  ,  2.5437624], dtype=float32)}
episode index:1165
target Thresh 14.96456635017152
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([ 6.0859    , 10.305199  ,  0.33916935], dtype=float32)}
done in step count: 30
reward sum = 0.7397003733882802
running average episode reward sum: 0.6148507697123535
{'scaleFactor': 30, 'timeStep': 31, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([1.5272236, 4.3284473, 3.9566019], dtype=float32)}
episode index:1166
target Thresh 14.964743076237317
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([9.159958 , 9.192698 , 6.2677574], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6151808033287097
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([9.159958 , 9.192698 , 6.2677574], dtype=float32)}
episode index:1167
target Thresh 14.964918920878185
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([12.065516 ,  4.9613304,  1.0629921], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.615501710175175
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([13.18629  ,  6.918334 ,  1.0330356], dtype=float32)}
episode index:1168
target Thresh 14.96509388849025
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([9.026183, 8.898532, 3.705159], dtype=float32)}
done in step count: 46
reward sum = 0.6298236312032323
running average episode reward sum: 0.6155139616046258
{'scaleFactor': 30, 'timeStep': 47, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([1.5748293, 8.326326 , 0.6151288], dtype=float32)}
episode index:1169
target Thresh 14.965267983447706
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([10.250334, 10.868208,  2.579035], dtype=float32)}
done in step count: 76
reward sum = 0.46588077516979337
running average episode reward sum: 0.6153860699922884
{'scaleFactor': 30, 'timeStep': 77, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([4.9619517, 8.399452 , 5.4060698], dtype=float32)}
episode index:1170
target Thresh 14.965441210102941
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([10.496105,  8.877939,  3.723353], dtype=float32)}
done in step count: 176
reward sum = 0.17052743088958636
running average episode reward sum: 0.615006173630971
{'scaleFactor': 30, 'timeStep': 177, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([11.112384 ,  4.8599157,  5.0988493], dtype=float32)}
episode index:1171
target Thresh 14.96561357278663
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([ 7.962885, 10.088218,  4.09521 ], dtype=float32)}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6152767019366673
{'scaleFactor': 30, 'timeStep': 8, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([6.9720125, 8.404956 , 3.321131 ], dtype=float32)}
episode index:1172
target Thresh 14.965785075807844
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([11.911361 ,  2.0707848,  2.1376302], dtype=float32)}
done in step count: 36
reward sum = 0.6964132180495735
running average episode reward sum: 0.6153458720271301
{'scaleFactor': 30, 'timeStep': 37, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([3.7617362, 6.895681 , 2.8990054], dtype=float32)}
episode index:1173
target Thresh 14.965955723454174
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([11.702389 ,  3.1298046,  5.945302 ], dtype=float32)}
done in step count: 91
reward sum = 0.40068465295154054
running average episode reward sum: 0.6151630260142888
{'scaleFactor': 30, 'timeStep': 92, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([10.474156 ,  8.470285 ,  1.2665372], dtype=float32)}
episode index:1174
target Thresh 14.966125519991817
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([ 4.9503536, 10.10216  ,  4.4404907], dtype=float32)}
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.6153938531170139
{'scaleFactor': 30, 'timeStep': 13, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([10.461786 ,  5.1054325,  5.1150784], dtype=float32)}
episode index:1175
target Thresh 14.966294469665694
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([11.821882 ,  6.1245346,  2.3248754], dtype=float32)}
done in step count: 168
reward sum = 0.1848045639485463
running average episode reward sum: 0.6150277057622787
{'scaleFactor': 30, 'timeStep': 169, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([11.02987 , 11.626727,  5.502991], dtype=float32)}
episode index:1176
target Thresh 14.96646257669956
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([ 3.8889523, 11.640803 ,  2.0133662], dtype=float32)}
done in step count: 212
reward sum = 0.11875755691154309
running average episode reward sum: 0.6146060658737055
{'scaleFactor': 30, 'timeStep': 213, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([2.2309284, 3.8699174, 1.5147889], dtype=float32)}
episode index:1177
target Thresh 14.966629845296092
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([4.7887387, 9.901201 , 3.7532315], dtype=float32)}
done in step count: 176
reward sum = 0.17052743088958636
running average episode reward sum: 0.6142290891037699
{'scaleFactor': 30, 'timeStep': 177, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([ 6.3027477, 10.528172 ,  5.990094 ], dtype=float32)}
episode index:1178
target Thresh 14.966796279637022
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([ 3.9641552 , 10.285223  ,  0.59114736], dtype=float32)}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.6145310992063112
{'scaleFactor': 30, 'timeStep': 4, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([10.0237255, 10.395811 ,  6.0170903], dtype=float32)}
episode index:1179
target Thresh 14.966961883883213
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([5.946358 , 9.387777 , 6.2652526], dtype=float32)}
done in step count: 74
reward sum = 0.47534004200570695
running average episode reward sum: 0.6144131406832598
{'scaleFactor': 30, 'timeStep': 75, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([9.636131 , 8.267014 , 3.1973944], dtype=float32)}
episode index:1180
target Thresh 14.96712666217478
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([2.0712175, 4.139762 , 4.678611 ], dtype=float32)}
done in step count: 40
reward sum = 0.6689717585696803
running average episode reward sum: 0.6144593376501407
{'scaleFactor': 30, 'timeStep': 41, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([13.062443 , 11.849837 ,  5.4712296], dtype=float32)}
episode index:1181
target Thresh 14.96729061863119
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([ 8.052828 , 10.066854 ,  3.0902169], dtype=float32)}
done in step count: 196
reward sum = 0.139475568775225
running average episode reward sum: 0.6140574901299419
{'scaleFactor': 30, 'timeStep': 197, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([0.07068449, 7.7969975 , 4.119717  ], dtype=float32)}
episode index:1182
target Thresh 14.96745375735136
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([2.124996 , 7.781631 , 1.3602992], dtype=float32)}
done in step count: 91
reward sum = 0.40068465295154054
running average episode reward sum: 0.6138771242489796
{'scaleFactor': 30, 'timeStep': 92, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([10.332846 ,  5.5130997,  4.9691586], dtype=float32)}
episode index:1183
target Thresh 14.96761608241377
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([3.0600305, 9.870197 , 3.5841038], dtype=float32)}
done in step count: 22
reward sum = 0.8016305895390459
running average episode reward sum: 0.6140356998108799
{'scaleFactor': 30, 'timeStep': 23, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([5.0842037, 8.88216  , 5.682135 ], dtype=float32)}
episode index:1184
target Thresh 14.967777597876553
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([ 2.0575888, 11.775109 ,  2.081361 ], dtype=float32)}
done in step count: 34
reward sum = 0.7105532272722921
running average episode reward sum: 0.6141171492011427
{'scaleFactor': 30, 'timeStep': 35, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([6.056821 , 7.349709 , 5.6076703], dtype=float32)}
episode index:1185
target Thresh 14.967938307777606
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([ 4.6562524 , 10.681613  ,  0.23412272], dtype=float32)}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6143852336857176
{'scaleFactor': 30, 'timeStep': 8, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([11.038695, 10.922705,  5.276363], dtype=float32)}
episode index:1186
target Thresh 14.968098216134683
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([3.0997982 , 8.925477  , 0.62489605], dtype=float32)}
done in step count: 157
reward sum = 0.2064075371174136
running average episode reward sum: 0.6140415288023409
{'scaleFactor': 30, 'timeStep': 158, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([13.242857 ,  4.4032063,  4.947521 ], dtype=float32)}
episode index:1187
target Thresh 14.968257326945501
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([3.4496279, 9.047737 , 1.807917 ], dtype=float32)}
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.6142707740404838
{'scaleFactor': 30, 'timeStep': 13, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([10.699942 ,  9.416126 ,  5.9033594], dtype=float32)}
episode index:1188
target Thresh 14.968415644187841
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([9.129758 , 9.167854 , 3.3376777], dtype=float32)}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.614562048418919
{'scaleFactor': 30, 'timeStep': 5, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([3.6986213, 8.425325 , 2.5865166], dtype=float32)}
episode index:1189
target Thresh 14.96857317181964
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([12.025792,  9.199588,  5.062923], dtype=float32)}
done in step count: 44
reward sum = 0.6426116020847181
running average episode reward sum: 0.6145856194724196
{'scaleFactor': 30, 'timeStep': 45, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([10.93605  , 10.2413435,  1.627712 ], dtype=float32)}
episode index:1190
target Thresh 14.968729913779098
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([5.7773566, 9.861597 , 1.9927118], dtype=float32)}
done in step count: 106
reward sum = 0.3446121833475176
running average episode reward sum: 0.6143589415243719
{'scaleFactor': 30, 'timeStep': 107, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([ 3.2592185, 10.925571 ,  3.6868355], dtype=float32)}
episode index:1191
target Thresh 14.968885873984771
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([8.989014 , 8.53741  , 3.5322735], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.6146740766405427
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([7.8395243, 7.076553 , 4.203467 ], dtype=float32)}
episode index:1192
target Thresh 14.969041056335675
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([ 1.895211 , 10.066382 ,  6.2654104], dtype=float32)}
done in step count: 57
reward sum = 0.5639051904523875
running average episode reward sum: 0.6146315209941151
{'scaleFactor': 30, 'timeStep': 58, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([1.307029 , 2.4082491, 5.0362725], dtype=float32)}
episode index:1193
target Thresh 14.969195464711373
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([12.083926  , 11.544125  ,  0.92413074], dtype=float32)}
done in step count: 148
reward sum = 0.22594815553398728
running average episode reward sum: 0.6143059905372809
{'scaleFactor': 30, 'timeStep': 149, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([ 3.875478 , 10.12202  ,  4.5777025], dtype=float32)}
episode index:1194
target Thresh 14.969349102972084
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([12.042887  ,  2.70719   ,  0.98734605], dtype=float32)}
done in step count: 186
reward sum = 0.1542219517938446
running average episode reward sum: 0.6139209829734787
{'scaleFactor': 30, 'timeStep': 187, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([1.5995855, 4.8948064, 4.9605193], dtype=float32)}
episode index:1195
target Thresh 14.969501974958773
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([ 8.957019 , 10.2242775,  1.8627275], dtype=float32)}
done in step count: 21
reward sum = 0.8097278682212584
running average episode reward sum: 0.6140847011049568
{'scaleFactor': 30, 'timeStep': 22, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([ 6.863819 , 10.602063 ,  2.0140994], dtype=float32)}
episode index:1196
target Thresh 14.96965408449325
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([11.876285,  9.138569,  4.604216], dtype=float32)}
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.6143047815743754
{'scaleFactor': 30, 'timeStep': 14, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([3.2557368, 6.6990123, 3.7926846], dtype=float32)}
episode index:1197
target Thresh 14.969805435378255
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([10.897746 ,  8.729813 ,  2.2012873], dtype=float32)}
done in step count: 31
reward sum = 0.7323033696543975
running average episode reward sum: 0.6144032778916375
{'scaleFactor': 30, 'timeStep': 32, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([1.4648348, 8.575021 , 4.53059  ], dtype=float32)}
episode index:1198
target Thresh 14.969956031397574
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([12.23944  ,  4.9199996,  1.2704984], dtype=float32)}
done in step count: 36
reward sum = 0.6964132180495735
running average episode reward sum: 0.6144716765072822
{'scaleFactor': 30, 'timeStep': 37, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([11.179966 , 11.949776 ,  1.9792385], dtype=float32)}
episode index:1199
target Thresh 14.970105876316115
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([8.504899 , 7.5015593, 3.6620579], dtype=float32)}
done in step count: 36
reward sum = 0.6964132180495735
running average episode reward sum: 0.614539961125234
{'scaleFactor': 30, 'timeStep': 37, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([3.086605 , 6.935398 , 2.8665094], dtype=float32)}
episode index:1200
target Thresh 14.970254973880005
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([11.91786  ,  6.0390887,  3.1575372], dtype=float32)}
done in step count: 342
reward sum = 0.03215411438303834
running average episode reward sum: 0.6140550436841498
{'scaleFactor': 30, 'timeStep': 343, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([ 2.2354808, 10.241795 ,  3.8863761], dtype=float32)}
episode index:1201
target Thresh 14.970403327816692
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([2.1529653, 7.0141973, 3.6624246], dtype=float32)}
done in step count: 50
reward sum = 0.6050060671375364
running average episode reward sum: 0.614047515417472
{'scaleFactor': 30, 'timeStep': 51, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([12.632046,  7.400599,  5.56573 ], dtype=float32)}
episode index:1202
target Thresh 14.970550941835034
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([9.887383, 9.702441, 3.395425], dtype=float32)}
done in step count: 145
reward sum = 0.232864462948006
running average episode reward sum: 0.6137306550247293
{'scaleFactor': 30, 'timeStep': 146, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([0.886055 , 3.5932746, 3.8653185], dtype=float32)}
episode index:1203
target Thresh 14.970697819625387
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([1.8828468, 1.9460492, 4.577143 ], dtype=float32)}
done in step count: 174
reward sum = 0.173989828476264
running average episode reward sum: 0.6133654217800878
{'scaleFactor': 30, 'timeStep': 175, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([ 4.4426026, 10.009806 ,  1.1878667], dtype=float32)}
episode index:1204
target Thresh 14.970843964859705
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([2.706317 , 8.988647 , 2.6929398], dtype=float32)}
done in step count: 35
reward sum = 0.7034476949995692
running average episode reward sum: 0.6134401788532989
{'scaleFactor': 30, 'timeStep': 36, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([12.218703,  3.48669 ,  5.372352], dtype=float32)}
episode index:1205
target Thresh 14.970989381191625
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([4.188753, 9.303498, 3.413528], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6137607093849297
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([4.188753, 9.303498, 3.413528], dtype=float32)}
episode index:1206
target Thresh 14.971134072256566
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([1.781298 , 1.7351444, 5.372829 ], dtype=float32)}
done in step count: 46
reward sum = 0.6298236312032323
running average episode reward sum: 0.6137740175223102
{'scaleFactor': 30, 'timeStep': 47, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([3.7325768, 5.9947166, 1.3560681], dtype=float32)}
episode index:1207
target Thresh 14.971278041671809
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([7.5056767, 8.507574 , 5.592675 ], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6140937410177387
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([7.5056767, 8.507574 , 5.592675 ], dtype=float32)}
episode index:1208
target Thresh 14.971421293036599
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([11.054666,  9.165812,  5.174162], dtype=float32)}
done in step count: 62
reward sum = 0.536268225207185
running average episode reward sum: 0.6140293692097896
{'scaleFactor': 30, 'timeStep': 63, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([3.7374334, 9.963829 , 2.7053647], dtype=float32)}
episode index:1209
target Thresh 14.971563829932224
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([12.019072,  8.939702,  4.531646], dtype=float32)}
done in step count: 154
reward sum = 0.2127257032290187
running average episode reward sum: 0.6136977132874915
{'scaleFactor': 30, 'timeStep': 155, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([2.5347729, 8.34656  , 4.846946 ], dtype=float32)}
episode index:1210
target Thresh 14.971705655922117
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([3.161601, 8.962879, 2.721938], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6140167077439014
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([3.161601, 8.962879, 2.721938], dtype=float32)}
episode index:1211
target Thresh 14.971846774551935
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([11.905084 , 10.050268 ,  5.0549855], dtype=float32)}
done in step count: 15
reward sum = 0.8600583546412884
running average episode reward sum: 0.6142197124030577
{'scaleFactor': 30, 'timeStep': 16, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([2.5295672, 5.058287 , 3.1518903], dtype=float32)}
episode index:1212
target Thresh 14.971987189349651
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([1.6951079, 8.8868265, 1.4120775], dtype=float32)}
done in step count: 81
reward sum = 0.4430479816261725
running average episode reward sum: 0.614078598033085
{'scaleFactor': 30, 'timeStep': 82, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([8.062032, 8.867234, 5.528652], dtype=float32)}
episode index:1213
target Thresh 14.972126903825641
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([2.1350498, 1.8951596, 6.0978312], dtype=float32)}
done in step count: 73
reward sum = 0.4801414565714212
running average episode reward sum: 0.6139682708984379
{'scaleFactor': 30, 'timeStep': 74, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([1.5229408, 7.999422 , 2.457297 ], dtype=float32)}
episode index:1214
target Thresh 14.972265921472776
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([ 6.888553 , 10.719703 ,  1.1441165], dtype=float32)}
done in step count: 59
reward sum = 0.5526834771623851
running average episode reward sum: 0.6139178307389843
{'scaleFactor': 30, 'timeStep': 60, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([1.7375047, 4.624125 , 4.509119 ], dtype=float32)}
episode index:1215
target Thresh 14.972404245766501
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([6.884057 , 9.935353 , 1.2924834], dtype=float32)}
done in step count: 63
reward sum = 0.5309055429551132
running average episode reward sum: 0.6138495640549515
{'scaleFactor': 30, 'timeStep': 64, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([ 4.1177473, 10.037134 ,  2.2521482], dtype=float32)}
episode index:1216
target Thresh 14.972541880164934
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([11.920072  ,  1.6097474 ,  0.26491213], dtype=float32)}
done in step count: 21
reward sum = 0.8097278682212584
running average episode reward sum: 0.6140105158250142
{'scaleFactor': 30, 'timeStep': 22, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([11.914278 , 10.324159 ,  2.2232423], dtype=float32)}
episode index:1217
target Thresh 14.97267882810894
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([10.973093,  9.016912,  2.368472], dtype=float32)}
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.6142341400909347
{'scaleFactor': 30, 'timeStep': 13, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([3.883544 , 6.8489475, 4.233247 ], dtype=float32)}
episode index:1218
target Thresh 14.972815093022229
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([11.885834 ,  6.984341 ,  1.9060732], dtype=float32)}
done in step count: 399
reward sum = 0.0
running average episode reward sum: 0.6137302564649373
{'scaleFactor': 30, 'timeStep': 400, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([2.6264982, 5.466326 , 3.5936363], dtype=float32)}
episode index:1219
target Thresh 14.972950678311424
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([1.8064555, 7.7027392, 5.458822 ], dtype=float32)}
done in step count: 97
reward sum = 0.37723664692350417
running average episode reward sum: 0.6135364092440017
{'scaleFactor': 30, 'timeStep': 98, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([10.541281  ,  7.0611258 ,  0.05596977], dtype=float32)}
episode index:1220
target Thresh 14.973085587366171
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([12.030361,  3.187413,  4.262239], dtype=float32)}
done in step count: 127
reward sum = 0.27904208858505886
running average episode reward sum: 0.6132624581214308
{'scaleFactor': 30, 'timeStep': 128, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([ 4.07075 , 10.870698,  2.584799], dtype=float32)}
episode index:1221
target Thresh 14.973219823559198
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([ 1.8029953, 10.059679 ,  0.6390337], dtype=float32)}
done in step count: 179
reward sum = 0.16546259566473476
running average episode reward sum: 0.6128960097888148
{'scaleFactor': 30, 'timeStep': 180, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([10.397665  ,  8.530097  ,  0.30881304], dtype=float32)}
episode index:1222
target Thresh 14.973353390246421
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([3.4255364, 5.9730687, 5.3207397], dtype=float32)}
done in step count: 20
reward sum = 0.8179069375972308
running average episode reward sum: 0.6130636393291324
{'scaleFactor': 30, 'timeStep': 21, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([10.42463  ,  7.922116 ,  5.9312854], dtype=float32)}
episode index:1223
target Thresh 14.97348629076701
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([ 8.011373 , 10.205046 ,  3.7129333], dtype=float32)}
done in step count: 31
reward sum = 0.7323033696543975
running average episode reward sum: 0.6131610574094635
{'scaleFactor': 30, 'timeStep': 32, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([11.042616 ,  5.8940773,  4.955121 ], dtype=float32)}
episode index:1224
target Thresh 14.97361852844349
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([11.989653 ,  7.0189543,  4.2258244], dtype=float32)}
done in step count: 210
reward sum = 0.12116881635704835
running average episode reward sum: 0.612759431090237
{'scaleFactor': 30, 'timeStep': 211, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([1.111081, 4.409129, 4.221664], dtype=float32)}
episode index:1225
target Thresh 14.973750106581804
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([2.0063627, 6.003095 , 4.286966 ], dtype=float32)}
done in step count: 198
reward sum = 0.136700004956598
running average episode reward sum: 0.6123711281325424
{'scaleFactor': 30, 'timeStep': 199, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([4.8753204, 8.169183 , 5.760318 ], dtype=float32)}
episode index:1226
target Thresh 14.97388102847142
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([3.1525369, 9.201166 , 5.202003 ], dtype=float32)}
done in step count: 58
reward sum = 0.5582661385478637
running average episode reward sum: 0.6123270327865076
{'scaleFactor': 30, 'timeStep': 59, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([9.101614  , 9.6199465 , 0.92393607], dtype=float32)}
episode index:1227
target Thresh 14.974011297385383
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([6.9417   , 8.591302 , 6.2056513], dtype=float32)}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.612602817002398
{'scaleFactor': 30, 'timeStep': 6, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([10.298066  ,  7.923491  ,  0.09323652], dtype=float32)}
episode index:1228
target Thresh 14.97414091658043
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([11.9704275,  7.9750338,  5.2324085], dtype=float32)}
done in step count: 23
reward sum = 0.7936142836436554
running average episode reward sum: 0.6127501005391282
{'scaleFactor': 30, 'timeStep': 24, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([13.881947 ,  4.630468 ,  1.1922648], dtype=float32)}
episode index:1229
target Thresh 14.974269889297043
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([ 6.1681404, 10.256427 ,  4.913663 ], dtype=float32)}
done in step count: 17
reward sum = 0.8429431933839268
running average episode reward sum: 0.6129372493950995
{'scaleFactor': 30, 'timeStep': 18, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([9.436001 , 8.784177 , 0.6741831], dtype=float32)}
episode index:1230
target Thresh 14.974398218759546
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([11.924388 ,  7.3638945,  5.410387 ], dtype=float32)}
done in step count: 118
reward sum = 0.3054590259283046
running average episode reward sum: 0.6126874701721371
{'scaleFactor': 30, 'timeStep': 119, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([3.9204507, 7.019593 , 4.800799 ], dtype=float32)}
episode index:1231
target Thresh 14.974525908176188
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([10.982744 , 10.050961 ,  0.8778248], dtype=float32)}
done in step count: 54
reward sum = 0.5811664141181095
running average episode reward sum: 0.6126618848993659
{'scaleFactor': 30, 'timeStep': 55, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([6.8822565, 8.324184 , 2.545392 ], dtype=float32)}
episode index:1232
target Thresh 14.974652960739208
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([10.247841 ,  5.0416822,  3.7306058], dtype=float32)}
done in step count: 144
reward sum = 0.23521662924041012
running average episode reward sum: 0.6123557654706077
{'scaleFactor': 30, 'timeStep': 145, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([7.0406914, 8.236113 , 2.1295147], dtype=float32)}
episode index:1233
target Thresh 14.974779379624923
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([11.665315 ,  5.887759 ,  1.4358296], dtype=float32)}
done in step count: 75
reward sum = 0.4705866415856499
running average episode reward sum: 0.6122408796327755
{'scaleFactor': 30, 'timeStep': 76, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([ 9.480206 , 10.773329 ,  3.3149734], dtype=float32)}
episode index:1234
target Thresh 14.974905167993818
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([1.8972526, 9.880217 , 3.2086306], dtype=float32)}
done in step count: 132
reward sum = 0.26536624974770534
running average episode reward sum: 0.6119600094871195
{'scaleFactor': 30, 'timeStep': 133, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([11.270922,  8.181334,  1.053285], dtype=float32)}
episode index:1235
target Thresh 14.975030328990606
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([ 9.435267, 11.204218,  2.199246], dtype=float32)}
done in step count: 239
reward sum = 0.0905339582851764
running average episode reward sum: 0.6115381437499011
{'scaleFactor': 30, 'timeStep': 240, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([5.8792334, 7.823022 , 4.5440807], dtype=float32)}
episode index:1236
target Thresh 14.975154865744317
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([9.018416 , 8.915418 , 2.7244482], dtype=float32)}
done in step count: 52
reward sum = 0.5929664464014994
running average episode reward sum: 0.6115231302516405
{'scaleFactor': 30, 'timeStep': 53, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([13.977315 ,  2.7487402,  5.6149874], dtype=float32)}
episode index:1237
target Thresh 14.975278781368377
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([2.1403325, 6.083168 , 3.3231635], dtype=float32)}
done in step count: 48
reward sum = 0.617290140942288
running average episode reward sum: 0.6115277885801467
{'scaleFactor': 30, 'timeStep': 49, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([11.953522, 10.320368,  6.165882], dtype=float32)}
episode index:1238
target Thresh 14.975402078960686
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([4.161842 , 8.852765 , 3.2838497], dtype=float32)}
done in step count: 71
reward sum = 0.4898902730042049
running average episode reward sum: 0.6114296146369861
{'scaleFactor': 30, 'timeStep': 72, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([7.685082, 9.387726, 0.91689 ], dtype=float32)}
episode index:1239
target Thresh 14.975524761603685
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([8.672837 , 8.640666 , 3.4638357], dtype=float32)}
done in step count: 40
reward sum = 0.6689717585696803
running average episode reward sum: 0.6114760195917706
{'scaleFactor': 30, 'timeStep': 41, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([10.966622 ,  5.7798347,  2.0523937], dtype=float32)}
episode index:1240
target Thresh 14.975646832364452
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([6.0597987 , 9.779253  , 0.26864976], dtype=float32)}
done in step count: 70
reward sum = 0.49483865960020695
running average episode reward sum: 0.6113820330003188
{'scaleFactor': 30, 'timeStep': 71, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([ 3.8960721, 10.859458 ,  3.2469819], dtype=float32)}
episode index:1241
target Thresh 14.975768294294756
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([11.963444,  9.984779,  5.621252], dtype=float32)}
done in step count: 173
reward sum = 0.1757473014911758
running average episode reward sum: 0.6110312803984596
{'scaleFactor': 30, 'timeStep': 174, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([4.784528 , 9.996267 , 4.4954596], dtype=float32)}
episode index:1242
target Thresh 14.975889150431158
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([7.8462553, 7.133022 , 4.864435 ], dtype=float32)}
done in step count: 132
reward sum = 0.26536624974770534
running average episode reward sum: 0.6107531910737204
{'scaleFactor': 30, 'timeStep': 133, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([10.940785 ,  4.3180842,  5.6629815], dtype=float32)}
episode index:1243
target Thresh 14.976009403795064
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([13.499265 ,  7.629555 ,  0.6945069], dtype=float32)}
done in step count: 173
reward sum = 0.1757473014911758
running average episode reward sum: 0.6104035078827376
{'scaleFactor': 30, 'timeStep': 174, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([10.930814 ,  6.747852 ,  3.8452115], dtype=float32)}
episode index:1244
target Thresh 14.976129057392818
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([11.1399145,  8.749512 ,  3.2152877], dtype=float32)}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.6106469727338226
{'scaleFactor': 30, 'timeStep': 10, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([10.3212   ,  7.678631 ,  4.1507187], dtype=float32)}
episode index:1245
target Thresh 14.976248114215762
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([0.65256023, 0.5429629 , 4.1997232 ], dtype=float32)}
done in step count: 399
reward sum = 0.0
running average episode reward sum: 0.6101568868809062
{'scaleFactor': 30, 'timeStep': 400, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([2.8411145, 8.688619 , 3.0042791], dtype=float32)}
episode index:1246
target Thresh 14.976366577240324
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([9.400437 , 9.232098 , 3.6731315], dtype=float32)}
done in step count: 41
reward sum = 0.6622820409839835
running average episode reward sum: 0.6101986873252551
{'scaleFactor': 30, 'timeStep': 42, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([3.8237464, 6.0431004, 3.5720904], dtype=float32)}
episode index:1247
target Thresh 14.976484449428085
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([12.000689 ,  4.6747847,  4.8416796], dtype=float32)}
done in step count: 24
reward sum = 0.7856781408072188
running average episode reward sum: 0.610339295861699
{'scaleFactor': 30, 'timeStep': 25, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([8.369995 , 8.896899 , 4.0266767], dtype=float32)}
episode index:1248
target Thresh 14.976601733725857
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([10.306815 ,  5.555824 ,  3.1955116], dtype=float32)}
done in step count: 60
reward sum = 0.5471566423907612
running average episode reward sum: 0.6102887092696485
{'scaleFactor': 30, 'timeStep': 61, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([10.4419365,  6.1262693,  2.5823731], dtype=float32)}
episode index:1249
target Thresh 14.976718433065756
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([ 3.9301782, 10.1118355,  6.2552876], dtype=float32)}
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.6105024951206319
{'scaleFactor': 30, 'timeStep': 14, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([10.235926,  5.219131,  5.614894], dtype=float32)}
episode index:1250
target Thresh 14.976834550365266
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([11.670907 ,  3.2549417,  4.526455 ], dtype=float32)}
done in step count: 96
reward sum = 0.38104711810454966
running average episode reward sum: 0.6103190775530731
{'scaleFactor': 30, 'timeStep': 97, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([3.3965435, 5.619058 , 3.9006844], dtype=float32)}
episode index:1251
target Thresh 14.976950088527332
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([4.765236 , 9.995435 , 5.5836964], dtype=float32)}
done in step count: 33
reward sum = 0.7177305325982749
running average episode reward sum: 0.610404869450074
{'scaleFactor': 30, 'timeStep': 34, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([12.007683, 11.501122,  5.904556], dtype=float32)}
episode index:1252
target Thresh 14.977065050440409
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([10.451223 ,  5.3105783,  2.52386  ], dtype=float32)}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6106615817233836
{'scaleFactor': 30, 'timeStep': 8, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([3.9718783, 8.16163  , 3.6067295], dtype=float32)}
episode index:1253
target Thresh 14.977179438978553
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([2.8518004, 8.975163 , 5.9532228], dtype=float32)}
done in step count: 36
reward sum = 0.6964132180495735
running average episode reward sum: 0.6107299642084921
{'scaleFactor': 30, 'timeStep': 37, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([6.6531453 , 8.598062  , 0.64382356], dtype=float32)}
episode index:1254
target Thresh 14.97729325700148
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([10.884239 ,  8.809949 ,  4.2025895], dtype=float32)}
done in step count: 45
reward sum = 0.6361854860638709
running average episode reward sum: 0.610750247492839
{'scaleFactor': 30, 'timeStep': 46, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([2.0491693, 9.950685 , 4.9447618], dtype=float32)}
episode index:1255
target Thresh 14.977406507354653
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([11.743804  ,  5.9529343 ,  0.26730636], dtype=float32)}
done in step count: 15
reward sum = 0.8600583546412884
running average episode reward sum: 0.6109487412087216
{'scaleFactor': 30, 'timeStep': 16, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([13.789051 ,  2.4573193,  4.3330545], dtype=float32)}
episode index:1256
target Thresh 14.977519192869332
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([ 7.01797 , 10.115435,  2.028813], dtype=float32)}
done in step count: 147
reward sum = 0.22823046013534068
running average episode reward sum: 0.6106442716135956
{'scaleFactor': 30, 'timeStep': 148, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([1.6596743, 6.9418106, 2.937382 ], dtype=float32)}
episode index:1257
target Thresh 14.977631316362661
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([6.980432 , 9.786369 , 2.1750991], dtype=float32)}
done in step count: 15
reward sum = 0.8600583546412884
running average episode reward sum: 0.6108425340007401
{'scaleFactor': 30, 'timeStep': 16, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([3.8540285, 9.748079 , 3.3653083], dtype=float32)}
episode index:1258
target Thresh 14.977742880637734
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([8.798217 , 8.9007015, 1.8022667], dtype=float32)}
done in step count: 196
reward sum = 0.139475568775225
running average episode reward sum: 0.6104681360934918
{'scaleFactor': 30, 'timeStep': 197, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([13.740288 ,  2.9994624,  5.2664165], dtype=float32)}
episode index:1259
target Thresh 14.977853888483665
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([5.380174, 9.252796, 5.01423 ], dtype=float32)}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.6107460153584969
{'scaleFactor': 30, 'timeStep': 5, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([10.461135 ,  5.6052036,  5.4839864], dtype=float32)}
episode index:1260
target Thresh 14.977964342675653
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([ 9.605489  , 10.17882   ,  0.34848422], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6110547021028597
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([ 9.605489  , 10.17882   ,  0.34848422], dtype=float32)}
episode index:1261
target Thresh 14.97807424597506
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([2.1419265, 7.128567 , 3.3010201], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6113628996447751
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([2.1419265, 7.128567 , 3.3010201], dtype=float32)}
episode index:1262
target Thresh 14.978183601129476
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([12.163917 ,  5.951441 ,  3.3138018], dtype=float32)}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.6116470929150484
{'scaleFactor': 30, 'timeStep': 4, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([11.42915 ,  4.399903,  3.765791], dtype=float32)}
episode index:1263
target Thresh 14.978292410872784
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([9.639225 , 9.263689 , 5.8986807], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.6119464227466029
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([11.299996 ,  8.052038 ,  5.3595486], dtype=float32)}
episode index:1264
target Thresh 14.978400677925233
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([7.231024, 9.2615  , 6.259644], dtype=float32)}
done in step count: 47
reward sum = 0.6235253948912
running average episode reward sum: 0.6119555760842667
{'scaleFactor': 30, 'timeStep': 48, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([13.332652 ,  8.881327 ,  3.9300938], dtype=float32)}
episode index:1265
target Thresh 14.978508404993505
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([ 6.8152695, 10.353917 ,  2.3606088], dtype=float32)}
done in step count: 96
reward sum = 0.38104711810454966
running average episode reward sum: 0.6117731839373632
{'scaleFactor': 30, 'timeStep': 97, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([11.272278 ,  5.0644436,  5.6323924], dtype=float32)}
episode index:1266
target Thresh 14.978615594770783
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([2.1913347, 4.0533867, 5.7131166], dtype=float32)}
done in step count: 16
reward sum = 0.8514577710948755
running average episode reward sum: 0.6119623588285689
{'scaleFactor': 30, 'timeStep': 17, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([10.024708  ,  8.197222  ,  0.07316753], dtype=float32)}
episode index:1267
target Thresh 14.978722249936816
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([2.1696184, 3.9443743, 5.6240625], dtype=float32)}
done in step count: 195
reward sum = 0.14088441290426768
running average episode reward sum: 0.6115908462529187
{'scaleFactor': 30, 'timeStep': 196, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([8.038577  , 9.501035  , 0.05687922], dtype=float32)}
episode index:1268
target Thresh 14.978828373157988
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([ 2.964359 , 10.323666 ,  3.3367875], dtype=float32)}
done in step count: 184
reward sum = 0.15735328210778962
running average episode reward sum: 0.6112328970297941
{'scaleFactor': 30, 'timeStep': 185, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([ 9.515021  , 11.622014  ,  0.15609998], dtype=float32)}
episode index:1269
target Thresh 14.978933967087388
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([1.370264 , 6.0299816, 4.262653 ], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6115390128589044
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([1.370264 , 6.0299816, 4.262653 ], dtype=float32)}
episode index:1270
target Thresh 14.979039034364867
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([1.6332321, 7.993282 , 3.050782 ], dtype=float32)}
done in step count: 51
reward sum = 0.598956006466161
running average episode reward sum: 0.6115291127751966
{'scaleFactor': 30, 'timeStep': 52, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([7.7012067 , 8.0470295 , 0.26102406], dtype=float32)}
episode index:1271
target Thresh 14.979143577617112
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([9.889285  , 8.986466  , 0.77301866], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.6118266527808764
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([10.848385 , 10.304527 ,  0.7071331], dtype=float32)}
episode index:1272
target Thresh 14.979247599457715
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([ 6.3769593, 10.599078 ,  3.3794718], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6121315807834052
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([ 6.3769593, 10.599078 ,  3.3794718], dtype=float32)}
episode index:1273
target Thresh 14.979351102487222
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([2.2676673, 8.79465  , 2.7410774], dtype=float32)}
done in step count: 33
reward sum = 0.7177305325982749
running average episode reward sum: 0.6122144685006854
{'scaleFactor': 30, 'timeStep': 34, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([6.1931586, 8.380568 , 0.2642242], dtype=float32)}
episode index:1274
target Thresh 14.979454089293215
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([10.796654 ,  8.7761   ,  2.0193686], dtype=float32)}
done in step count: 46
reward sum = 0.6298236312032323
running average episode reward sum: 0.6122282796086874
{'scaleFactor': 30, 'timeStep': 47, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([3.6424046, 7.118794 , 2.8335948], dtype=float32)}
episode index:1275
target Thresh 14.97955656245037
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([1.7380967, 1.891753 , 2.933819 ], dtype=float32)}
done in step count: 177
reward sum = 0.1688221565806905
running average episode reward sum: 0.6118807826470668
{'scaleFactor': 30, 'timeStep': 178, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([10.975369,  7.789256,  4.202831], dtype=float32)}
episode index:1276
target Thresh 14.979658524520522
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([ 8.109592 , 10.077049 ,  3.9805562], dtype=float32)}
done in step count: 399
reward sum = 0.0
running average episode reward sum: 0.6114016277663722
{'scaleFactor': 30, 'timeStep': 400, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([ 0.47737914, 11.538337  ,  2.492191  ], dtype=float32)}
episode index:1277
target Thresh 14.979759978052726
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([12.125463 ,  3.9914293,  4.63919  ], dtype=float32)}
done in step count: 98
reward sum = 0.37346428045426916
running average episode reward sum: 0.6112154483083815
{'scaleFactor': 30, 'timeStep': 99, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([9.236948, 8.688498, 1.501136], dtype=float32)}
episode index:1278
target Thresh 14.97986092558333
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([11.979309,  1.912458,  5.612931], dtype=float32)}
done in step count: 186
reward sum = 0.1542219517938446
running average episode reward sum: 0.6108581429944531
{'scaleFactor': 30, 'timeStep': 187, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([ 8.811981 , 11.726584 ,  2.4603574], dtype=float32)}
episode index:1279
target Thresh 14.979961369636023
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([2.1061995, 3.9677784, 1.921619 ], dtype=float32)}
done in step count: 21
reward sum = 0.8097278682212584
running average episode reward sum: 0.6110135099672865
{'scaleFactor': 30, 'timeStep': 22, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([11.1037   , 11.992929 ,  0.2910487], dtype=float32)}
episode index:1280
target Thresh 14.980061312721913
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([7.8212147, 9.606677 , 3.4871714], dtype=float32)}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.6112568598380599
{'scaleFactor': 30, 'timeStep': 9, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([2.0063946, 7.5634556, 2.7781029], dtype=float32)}
episode index:1281
target Thresh 14.980160757339583
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([2.8159723, 8.958926 , 2.2962208], dtype=float32)}
done in step count: 28
reward sum = 0.7547192872036326
running average episode reward sum: 0.6113687650076118
{'scaleFactor': 30, 'timeStep': 29, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([ 4.1350293, 10.698021 ,  3.6741183], dtype=float32)}
episode index:1282
target Thresh 14.980259705975152
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([1.9009796, 8.054174 , 5.1819143], dtype=float32)}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.6116042665527998
{'scaleFactor': 30, 'timeStep': 10, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([7.3146586 , 9.272599  , 0.10715389], dtype=float32)}
episode index:1283
target Thresh 14.980358161102345
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([10.237047,  9.922117,  6.0399  ], dtype=float32)}
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.6118252431787389
{'scaleFactor': 30, 'timeStep': 12, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([3.0163758, 8.083467 , 2.5244849], dtype=float32)}
episode index:1284
target Thresh 14.980456125182542
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([ 2.033374 , 10.110654 ,  1.0714029], dtype=float32)}
done in step count: 43
reward sum = 0.6491026283684022
running average episode reward sum: 0.6118542528170188
{'scaleFactor': 30, 'timeStep': 44, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([10.997392 ,  6.4709845,  5.2538614], dtype=float32)}
episode index:1285
target Thresh 14.980553600664848
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([2.2166905, 3.9498072, 1.3474694], dtype=float32)}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.6121254361429775
{'scaleFactor': 30, 'timeStep': 5, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([4.126678 , 9.114695 , 1.1156043], dtype=float32)}
episode index:1286
target Thresh 14.98065058998616
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([2.0380433, 7.992492 , 0.0133566], dtype=float32)}
done in step count: 89
reward sum = 0.40882017442254925
running average episode reward sum: 0.6119674677966525
{'scaleFactor': 30, 'timeStep': 90, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([0.24979782, 5.029998  , 4.7203975 ], dtype=float32)}
episode index:1287
target Thresh 14.980747095571212
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([3.7588315, 6.727235 , 5.891019 ], dtype=float32)}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.6122087544632916
{'scaleFactor': 30, 'timeStep': 9, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([5.321968  , 8.060171  , 0.70357656], dtype=float32)}
episode index:1288
target Thresh 14.980843119832654
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([2.936049 , 4.0353   , 1.4227376], dtype=float32)}
done in step count: 63
reward sum = 0.5309055429551132
running average episode reward sum: 0.6121456798228663
{'scaleFactor': 30, 'timeStep': 64, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([10.5340605, 10.973766 ,  0.7032138], dtype=float32)}
episode index:1289
target Thresh 14.980938665171092
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([10.054394,  9.783413,  5.822369], dtype=float32)}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.6124309157299803
{'scaleFactor': 30, 'timeStep': 3, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([ 9.983818 , 10.198808 ,  5.5908046], dtype=float32)}
episode index:1290
target Thresh 14.981033733975165
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([4.089881 , 7.3560557, 5.1863027], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6127311241608634
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([4.089881 , 7.3560557, 5.1863027], dtype=float32)}
episode index:1291
target Thresh 14.981128328621601
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([12.9018135,  3.5214157,  1.0380139], dtype=float32)}
done in step count: 144
reward sum = 0.23521662924041012
running average episode reward sum: 0.612438930279346
{'scaleFactor': 30, 'timeStep': 145, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([5.6526995, 9.102104 , 3.2019083], dtype=float32)}
episode index:1292
target Thresh 14.98122245147527
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([9.1289835, 9.974867 , 0.8725369], dtype=float32)}
done in step count: 85
reward sum = 0.4255901233886546
running average episode reward sum: 0.6122944223080462
{'scaleFactor': 30, 'timeStep': 86, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([ 7.967408 , 11.435711 ,  1.4386086], dtype=float32)}
episode index:1293
target Thresh 14.981316104889247
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([8.863096  , 8.964727  , 0.25980917], dtype=float32)}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6125415404885709
{'scaleFactor': 30, 'timeStep': 8, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([12.9936075,  3.766596 ,  4.845958 ], dtype=float32)}
episode index:1294
target Thresh 14.981409291204873
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([3.0958302, 9.084464 , 3.180779 ], dtype=float32)}
done in step count: 29
reward sum = 0.7471720943315961
running average episode reward sum: 0.6126455023062104
{'scaleFactor': 30, 'timeStep': 30, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([6.3540936, 9.779804 , 0.5736876], dtype=float32)}
episode index:1295
target Thresh 14.981502012751813
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([ 7.1026173, 10.1421995,  6.115476 ], dtype=float32)}
done in step count: 83
reward sum = 0.43423132679181164
running average episode reward sum: 0.6125078370473258
{'scaleFactor': 30, 'timeStep': 84, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([ 5.528335 , 10.058946 ,  3.5323105], dtype=float32)}
episode index:1296
target Thresh 14.981594271848106
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([7.006214 , 7.199256 , 3.7512984], dtype=float32)}
done in step count: 50
reward sum = 0.6050060671375364
running average episode reward sum: 0.6125020531075341
{'scaleFactor': 30, 'timeStep': 51, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([2.6655703, 8.879431 , 2.4003167], dtype=float32)}
episode index:1297
target Thresh 14.981686070800238
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([2.2229996, 7.0281873, 1.994439 ], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.6127928835750939
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([2.347752, 6.968168, 2.631322], dtype=float32)}
episode index:1298
target Thresh 14.981777411903186
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([12.259662 ,  4.012626 ,  1.2538244], dtype=float32)}
done in step count: 143
reward sum = 0.23759255478829303
running average episode reward sum: 0.6125040457546267
{'scaleFactor': 30, 'timeStep': 144, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([ 7.7085037, 11.878734 ,  6.1431785], dtype=float32)}
episode index:1299
target Thresh 14.981868297440482
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([2.054208, 2.016589, 4.530592], dtype=float32)}
done in step count: 263
reward sum = 0.07113055202541568
running average episode reward sum: 0.6120876046056042
{'scaleFactor': 30, 'timeStep': 264, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([ 8.4146805, 11.919662 ,  6.2736197], dtype=float32)}
episode index:1300
target Thresh 14.98195872968427
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([11.698467 ,  9.054687 ,  1.2163417], dtype=float32)}
done in step count: 399
reward sum = 0.0
running average episode reward sum: 0.611617129890304
{'scaleFactor': 30, 'timeStep': 400, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([14.248503  , 10.468926  ,  0.97145724], dtype=float32)}
episode index:1301
target Thresh 14.98204871089536
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([11.844971, 10.351096,  4.291995], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6119154270255649
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([11.844971, 10.351096,  4.291995], dtype=float32)}
episode index:1302
target Thresh 14.982138243323288
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([8.735758 , 8.921034 , 0.8649163], dtype=float32)}
done in step count: 19
reward sum = 0.8261686238355866
running average episode reward sum: 0.612079857721505
{'scaleFactor': 30, 'timeStep': 20, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([ 4.592042 , 10.473124 ,  2.9658244], dtype=float32)}
episode index:1303
target Thresh 14.982227329206367
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([5.752207, 8.970301, 3.360756], dtype=float32)}
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.6122834168973312
{'scaleFactor': 30, 'timeStep': 14, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([11.346603 ,  9.111914 ,  0.3795864], dtype=float32)}
episode index:1304
target Thresh 14.982315970771753
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([6.8938303, 9.020316 , 4.7640076], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6125805177272949
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([6.8938303, 9.020316 , 4.7640076], dtype=float32)}
episode index:1305
target Thresh 14.982404170235485
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([1.7569809, 4.9487476, 4.648719 ], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6128771635789586
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([1.7569809, 4.9487476, 4.648719 ], dtype=float32)}
episode index:1306
target Thresh 14.982491929802558
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([12.150289 ,  9.061784 ,  1.3906723], dtype=float32)}
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.6130864273189258
{'scaleFactor': 30, 'timeStep': 13, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([2.7332983, 9.696581 , 3.2723703], dtype=float32)}
episode index:1307
target Thresh 14.982579251666964
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([9.0466585, 9.002964 , 4.42243  ], dtype=float32)}
done in step count: 72
reward sum = 0.48499137027416284
running average episode reward sum: 0.612988495318127
{'scaleFactor': 30, 'timeStep': 73, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([ 1.037787 , 10.987825 ,  4.5096645], dtype=float32)}
episode index:1308
target Thresh 14.982666138011753
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([11.875915  ,  2.985841  ,  0.18543123], dtype=float32)}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.6132111030948197
{'scaleFactor': 30, 'timeStep': 11, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([13.230606 ,  5.2198176,  4.9672217], dtype=float32)}
episode index:1309
target Thresh 14.98275259100909
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([1.8738042, 8.927995 , 2.3847322], dtype=float32)}
done in step count: 143
reward sum = 0.23759255478829303
running average episode reward sum: 0.6129243713785553
{'scaleFactor': 30, 'timeStep': 144, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([0.44240978, 2.2884643 , 5.1497583 ], dtype=float32)}
episode index:1310
target Thresh 14.982838612820306
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([9.371081 , 9.9547205, 6.2640967], dtype=float32)}
done in step count: 49
reward sum = 0.611117239532865
running average episode reward sum: 0.6129229929408393
{'scaleFactor': 30, 'timeStep': 50, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([2.4614325, 5.702169 , 3.8614259], dtype=float32)}
episode index:1311
target Thresh 14.982924205595948
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([12.085332 ,  6.313445 ,  5.4685783], dtype=float32)}
done in step count: 53
reward sum = 0.5870367819374844
running average episode reward sum: 0.6129032625970867
{'scaleFactor': 30, 'timeStep': 54, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([9.905516 , 8.2659025, 3.8661797], dtype=float32)}
episode index:1312
target Thresh 14.98300937147584
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([2.183609 , 6.9480977, 2.98779  ], dtype=float32)}
done in step count: 62
reward sum = 0.536268225207185
running average episode reward sum: 0.6128448962319765
{'scaleFactor': 30, 'timeStep': 63, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([11.542832,  4.688014,  5.554429], dtype=float32)}
episode index:1313
target Thresh 14.983094112589132
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([ 7.123594 , 10.180304 ,  0.8984531], dtype=float32)}
done in step count: 20
reward sum = 0.8179069375972308
running average episode reward sum: 0.6130009556241875
{'scaleFactor': 30, 'timeStep': 21, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([0.40518248, 3.511034  , 4.071163  ], dtype=float32)}
episode index:1314
target Thresh 14.98317843105436
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([2.9595258, 9.231602 , 1.1748862], dtype=float32)}
done in step count: 26
reward sum = 0.7700431458051551
running average episode reward sum: 0.6131203793429564
{'scaleFactor': 30, 'timeStep': 27, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([3.8374765, 4.9821253, 4.715081 ], dtype=float32)}
episode index:1315
target Thresh 14.983262328979487
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([2.9344385 , 9.183471  , 0.80271274], dtype=float32)}
done in step count: 32
reward sum = 0.7249803359578534
running average episode reward sum: 0.613205379309989
{'scaleFactor': 30, 'timeStep': 33, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([10.180711  ,  7.162904  ,  0.56897944], dtype=float32)}
episode index:1316
target Thresh 14.98334580846197
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([8.020807 , 9.137365 , 2.1604218], dtype=float32)}
done in step count: 90
reward sum = 0.4047319726783238
running average episode reward sum: 0.6130470851515746
{'scaleFactor': 30, 'timeStep': 91, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([ 3.0575695, 11.846675 ,  2.869692 ], dtype=float32)}
episode index:1317
target Thresh 14.983428871588794
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([10.967674 ,  7.2584596,  2.0076814], dtype=float32)}
done in step count: 45
reward sum = 0.6361854860638709
running average episode reward sum: 0.6130646408427068
{'scaleFactor': 30, 'timeStep': 46, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([ 5.095748 , 10.7269945,  3.8929286], dtype=float32)}
episode index:1318
target Thresh 14.983511520436545
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([1.7431324, 7.135741 , 2.639626 ], dtype=float32)}
done in step count: 14
reward sum = 0.8687458127689782
running average episode reward sum: 0.6132584855522795
{'scaleFactor': 30, 'timeStep': 15, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([7.291772 , 9.328826 , 1.0292494], dtype=float32)}
episode index:1319
target Thresh 14.98359375707145
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([11.104633 ,  8.999586 ,  3.0263648], dtype=float32)}
done in step count: 48
reward sum = 0.617290140942288
running average episode reward sum: 0.6132615398366658
{'scaleFactor': 30, 'timeStep': 49, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([10.350857 ,  2.590162 ,  4.5828366], dtype=float32)}
episode index:1320
target Thresh 14.983675583549426
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([12.254075 ,  7.2034316,  0.0415109], dtype=float32)}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.6135244728193783
{'scaleFactor': 30, 'timeStep': 5, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([12.395518  ,  8.028936  ,  0.76529145], dtype=float32)}
episode index:1321
target Thresh 14.98375700191614
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([1.8818747, 7.816839 , 4.9015164], dtype=float32)}
done in step count: 15
reward sum = 0.8600583546412884
running average episode reward sum: 0.6137109583578214
{'scaleFactor': 30, 'timeStep': 16, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([9.021485  , 9.937523  , 0.73287153], dtype=float32)}
episode index:1322
target Thresh 14.983838014207056
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([12.154733 ,  5.355676 ,  5.9732027], dtype=float32)}
done in step count: 52
reward sum = 0.5929664464014994
running average episode reward sum: 0.6136952784546043
{'scaleFactor': 30, 'timeStep': 53, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([4.859021 , 8.27252  , 3.9585905], dtype=float32)}
episode index:1323
target Thresh 14.983918622447487
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([1.9855989, 8.068799 , 5.544607 ], dtype=float32)}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.6139286994636475
{'scaleFactor': 30, 'timeStep': 9, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([3.43149  , 2.5439787, 4.7353063], dtype=float32)}
episode index:1324
target Thresh 14.98399882865264
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([11.929375,  5.31212 ,  5.272419], dtype=float32)}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6141688025945482
{'scaleFactor': 30, 'timeStep': 8, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([12.018826 ,  6.0878706,  5.7401466], dtype=float32)}
episode index:1325
target Thresh 14.984078634827677
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([2.1986399, 5.0066376, 4.2501683], dtype=float32)}
done in step count: 28
reward sum = 0.7547192872036326
running average episode reward sum: 0.6142747984351282
{'scaleFactor': 30, 'timeStep': 29, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([6.2873116, 8.352252 , 0.7650429], dtype=float32)}
episode index:1326
target Thresh 14.984158042967755
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([2.7456949, 6.83474  , 0.8959508], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.6145579372456519
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([3.1753047, 8.606049 , 1.108976 ], dtype=float32)}
episode index:1327
target Thresh 14.984237055058081
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([11.872958  ,  6.9594364 ,  0.26790416], dtype=float32)}
done in step count: 38
reward sum = 0.682554595010387
running average episode reward sum: 0.6146091395481855
{'scaleFactor': 30, 'timeStep': 39, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([9.88349  , 9.214537 , 2.5493329], dtype=float32)}
episode index:1328
target Thresh 14.984315673073963
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([12.176238 ,  6.9302797,  1.8780978], dtype=float32)}
done in step count: 41
reward sum = 0.6622820409839835
running average episode reward sum: 0.6146450108058499
{'scaleFactor': 30, 'timeStep': 42, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([2.5331898, 5.924635 , 4.130853 ], dtype=float32)}
episode index:1329
target Thresh 14.984393898980857
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([2.1138852, 9.162475 , 4.064893 ], dtype=float32)}
done in step count: 171
reward sum = 0.17931568359471053
running average episode reward sum: 0.6143176955222325
{'scaleFactor': 30, 'timeStep': 172, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([10.169594  ,  8.339298  ,  0.65686566], dtype=float32)}
episode index:1330
target Thresh 14.98447173473441
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([1.683945 , 5.8985324, 3.9430563], dtype=float32)}
done in step count: 253
reward sum = 0.07865099717364833
running average episode reward sum: 0.6139152412034131
{'scaleFactor': 30, 'timeStep': 254, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([ 5.502282 , 11.46799  ,  0.1871303], dtype=float32)}
episode index:1331
target Thresh 14.984549182280523
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([12.186839, 10.285166,  6.077449], dtype=float32)}
done in step count: 15
reward sum = 0.8600583546412884
running average episode reward sum: 0.6141000333306187
{'scaleFactor': 30, 'timeStep': 16, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([13.396278 ,  8.334417 ,  5.1840024], dtype=float32)}
episode index:1332
target Thresh 14.98462624355539
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([5.967962 , 9.903944 , 1.1737484], dtype=float32)}
done in step count: 36
reward sum = 0.6964132180495735
running average episode reward sum: 0.6141617836567395
{'scaleFactor': 30, 'timeStep': 37, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([ 9.795828 , 10.190205 ,  6.1937747], dtype=float32)}
episode index:1333
target Thresh 14.984702920485542
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([ 6.0558934, 10.441494 ,  0.8263371], dtype=float32)}
done in step count: 49
reward sum = 0.611117239532865
running average episode reward sum: 0.61415950138978
{'scaleFactor': 30, 'timeStep': 50, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([0.48360163, 6.0684175 , 5.5084515 ], dtype=float32)}
episode index:1334
target Thresh 14.984779214987913
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([2.2793055, 4.965594 , 3.9036705], dtype=float32)}
done in step count: 19
reward sum = 0.8261686238355866
running average episode reward sum: 0.6143183097212
{'scaleFactor': 30, 'timeStep': 20, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([5.8290110e+00, 7.1382694e+00, 4.9757510e-03], dtype=float32)}
episode index:1335
target Thresh 14.984855128969864
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([9.981285 , 6.8501654, 3.2332008], dtype=float32)}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6145703095267231
{'scaleFactor': 30, 'timeStep': 6, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([9.319682 , 8.243525 , 1.6627047], dtype=float32)}
episode index:1336
target Thresh 14.984930664329251
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([8.692627 , 8.767049 , 2.8823397], dtype=float32)}
done in step count: 44
reward sum = 0.6426116020847181
running average episode reward sum: 0.6145912828195862
{'scaleFactor': 30, 'timeStep': 45, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([10.065051,  5.742997,  3.224696], dtype=float32)}
episode index:1337
target Thresh 14.985005822954461
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([1.9583879, 3.0669005, 4.4038696], dtype=float32)}
done in step count: 94
reward sum = 0.3887839180742268
running average episode reward sum: 0.6144225179729903
{'scaleFactor': 30, 'timeStep': 95, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([10.002813  ,  6.878345  ,  0.68557894], dtype=float32)}
episode index:1338
target Thresh 14.985080606724464
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([2.0842412, 9.178922 , 1.8573115], dtype=float32)}
done in step count: 167
reward sum = 0.18667127671570335
running average episode reward sum: 0.6141030622289595
{'scaleFactor': 30, 'timeStep': 168, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([7.0120606, 9.668844 , 6.199366 ], dtype=float32)}
episode index:1339
target Thresh 14.985155017508859
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([8.695472, 9.096263, 5.474437], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6143910450183409
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([8.695472, 9.096263, 5.474437], dtype=float32)}
episode index:1340
target Thresh 14.985229057167919
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([9.985079 , 9.074752 , 3.5065808], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6146785983031892
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([9.985079 , 9.074752 , 3.5065808], dtype=float32)}
episode index:1341
target Thresh 14.985302727552638
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([6.6311197, 9.157392 , 5.9999776], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.6149582714788202
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([8.78321   , 9.238537  , 0.10218876], dtype=float32)}
episode index:1342
target Thresh 14.98537603050478
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([11.936013  ,  3.0426886 ,  0.33820894], dtype=float32)}
done in step count: 27
reward sum = 0.7623427143471035
running average episode reward sum: 0.6150680141764139
{'scaleFactor': 30, 'timeStep': 28, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([2.446279 , 6.5824533, 3.014473 ], dtype=float32)}
episode index:1343
target Thresh 14.985448967856922
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([ 8.800317, 10.067056,  1.651186], dtype=float32)}
done in step count: 91
reward sum = 0.40068465295154054
running average episode reward sum: 0.6149085027469311
{'scaleFactor': 30, 'timeStep': 92, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([3.771159 , 2.7296543, 4.5844026], dtype=float32)}
episode index:1344
target Thresh 14.985521541432503
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([3.2623644, 6.7828145, 1.1028979], dtype=float32)}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.6151373772388873
{'scaleFactor': 30, 'timeStep': 9, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([ 6.523681 , 10.97226  ,  1.7293433], dtype=float32)}
episode index:1345
target Thresh 14.985593753045867
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([11.674753 ,  5.0387063,  3.6308975], dtype=float32)}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6153868963121868
{'scaleFactor': 30, 'timeStep': 6, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([11.635555,  7.009716,  1.55267 ], dtype=float32)}
episode index:1346
target Thresh 14.985665604502307
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([6.135718 , 8.140756 , 4.1353674], dtype=float32)}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.6156150758208102
{'scaleFactor': 30, 'timeStep': 9, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([5.617666 , 8.626461 , 5.2052546], dtype=float32)}
episode index:1347
target Thresh 14.985737097598111
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([2.1288729, 8.745668 , 4.31434  ], dtype=float32)}
done in step count: 48
reward sum = 0.617290140942288
running average episode reward sum: 0.6156163184507223
{'scaleFactor': 30, 'timeStep': 49, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([4.243794  , 9.477033  , 0.27034736], dtype=float32)}
episode index:1348
target Thresh 14.985808234120613
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([5.7818027, 8.936184 , 6.0402718], dtype=float32)}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6158649275919005
{'scaleFactor': 30, 'timeStep': 6, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([11.230844 ,  4.3374066,  6.1990347], dtype=float32)}
episode index:1349
target Thresh 14.98587901584823
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([10.960117 ,  8.778261 ,  4.1517677], dtype=float32)}
done in step count: 80
reward sum = 0.4475232137638106
running average episode reward sum: 0.6157402300261019
{'scaleFactor': 30, 'timeStep': 81, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([2.8908033, 6.9236546, 1.4961591], dtype=float32)}
episode index:1350
target Thresh 14.985949444550506
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([ 8.599742, 10.111823,  2.970484], dtype=float32)}
done in step count: 74
reward sum = 0.47534004200570695
running average episode reward sum: 0.6156363068669454
{'scaleFactor': 30, 'timeStep': 75, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([0.74965173, 5.698865  , 3.5243776 ], dtype=float32)}
episode index:1351
target Thresh 14.986019521988164
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([4.1770687, 9.050109 , 5.362006 ], dtype=float32)}
done in step count: 61
reward sum = 0.5416850759668536
running average episode reward sum: 0.6155816092109542
{'scaleFactor': 30, 'timeStep': 62, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([1.3897798, 8.196346 , 4.603298 ], dtype=float32)}
episode index:1352
target Thresh 14.986089249913144
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([8.061896 , 9.086126 , 2.1009398], dtype=float32)}
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.6157752081864073
{'scaleFactor': 30, 'timeStep': 14, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([10.055238,  8.869652,  6.172258], dtype=float32)}
episode index:1353
target Thresh 14.98615863006865
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([4.5984387, 7.4943   , 3.7327805], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.6160515928184706
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([2.6891274, 6.4955015, 3.6713288], dtype=float32)}
episode index:1354
target Thresh 14.986227664189183
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([11.845097 ,  6.819734 ,  4.8003902], dtype=float32)}
done in step count: 25
reward sum = 0.7778213593991467
running average episode reward sum: 0.6161709801000799
{'scaleFactor': 30, 'timeStep': 26, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([5.123149 , 8.277663 , 2.9684923], dtype=float32)}
episode index:1355
target Thresh 14.986296354000604
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([1.7048762, 3.0744872, 5.772148 ], dtype=float32)}
done in step count: 340
reward sum = 0.03280697314869742
running average episode reward sum: 0.6157407706554254
{'scaleFactor': 30, 'timeStep': 341, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([9.282541, 9.9448  , 5.413583], dtype=float32)}
episode index:1356
target Thresh 14.986364701220163
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([2.1739092, 7.1599646, 5.90597  ], dtype=float32)}
done in step count: 138
reward sum = 0.2498370564584527
running average episode reward sum: 0.6154711290090017
{'scaleFactor': 30, 'timeStep': 139, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([10.288555 , 11.662647 ,  5.4795284], dtype=float32)}
episode index:1357
target Thresh 14.98643270755654
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([1.9396774, 9.01495  , 1.7902548], dtype=float32)}
done in step count: 42
reward sum = 0.6556592205741436
running average episode reward sum: 0.6155007225963104
{'scaleFactor': 30, 'timeStep': 43, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([3.0030007, 6.820493 , 4.5050316], dtype=float32)}
episode index:1358
target Thresh 14.986500374709902
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([4.817876 , 8.944009 , 1.8161747], dtype=float32)}
done in step count: 43
reward sum = 0.6491026283684022
running average episode reward sum: 0.6155254480604546
{'scaleFactor': 30, 'timeStep': 44, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([8.029635, 8.557192, 6.007601], dtype=float32)}
episode index:1359
target Thresh 14.986567704371927
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([12.071983 ,  6.1562977,  5.190149 ], dtype=float32)}
done in step count: 119
reward sum = 0.30240443566902153
running average episode reward sum: 0.6152952120219315
{'scaleFactor': 30, 'timeStep': 120, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([0.3021909, 7.431614 , 4.3001275], dtype=float32)}
episode index:1360
target Thresh 14.986634698225863
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([1.9195032, 2.8003764, 2.9652574], dtype=float32)}
done in step count: 53
reward sum = 0.5870367819374844
running average episode reward sum: 0.6152744490314213
{'scaleFactor': 30, 'timeStep': 54, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([10.906981 ,  6.711433 ,  5.5014634], dtype=float32)}
episode index:1361
target Thresh 14.986701357946556
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([8.070046 , 9.15946  , 2.7594645], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.6155495779234688
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([ 6.556625 , 10.357409 ,  2.2941394], dtype=float32)}
episode index:1362
target Thresh 14.986767685200507
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([9.872304 , 8.870972 , 5.3163304], dtype=float32)}
done in step count: 21
reward sum = 0.8097278682212584
running average episode reward sum: 0.6156920418195053
{'scaleFactor': 30, 'timeStep': 22, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([2.3180094, 7.0936327, 2.8172276], dtype=float32)}
episode index:1363
target Thresh 14.9868336816459
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([ 6.09505  , 10.014642 ,  4.0478544], dtype=float32)}
done in step count: 140
reward sum = 0.24486529903492948
running average episode reward sum: 0.6154201747060268
{'scaleFactor': 30, 'timeStep': 141, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([9.2430725, 8.082158 , 1.8042428], dtype=float32)}
episode index:1364
target Thresh 14.986899348932646
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([10.229301 ,  9.7676935,  1.7685949], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6157019181677806
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([10.229301 ,  9.7676935,  1.7685949], dtype=float32)}
episode index:1365
target Thresh 14.986964688702434
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([ 8.105321 , 10.141496 ,  0.7450019], dtype=float32)}
done in step count: 84
reward sum = 0.4298890135238935
running average episode reward sum: 0.6155658911512037
{'scaleFactor': 30, 'timeStep': 85, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([12.03112  ,  5.727589 ,  3.4106064], dtype=float32)}
episode index:1366
target Thresh 14.98702970258876
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([3.783057 , 8.838833 , 5.6662507], dtype=float32)}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6158043068485335
{'scaleFactor': 30, 'timeStep': 7, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([5.8256364, 8.838952 , 6.2244844], dtype=float32)}
episode index:1367
target Thresh 14.987094392216976
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([11.979059 ,  2.157417 ,  1.6128281], dtype=float32)}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6160493256665536
{'scaleFactor': 30, 'timeStep': 6, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([8.446291 , 9.370284 , 2.2877126], dtype=float32)}
episode index:1368
target Thresh 14.987158759204323
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([ 4.1344995, 10.05755  ,  2.5871048], dtype=float32)}
done in step count: 29
reward sum = 0.7471720943315961
running average episode reward sum: 0.6161451056290554
{'scaleFactor': 30, 'timeStep': 30, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([5.0532374 , 9.971726  , 0.57135737], dtype=float32)}
episode index:1369
target Thresh 14.987222805159984
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([10.310974,  4.798149,  2.963783], dtype=float32)}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.6163621655866136
{'scaleFactor': 30, 'timeStep': 10, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([9.782967 , 8.219578 , 1.8686352], dtype=float32)}
episode index:1370
target Thresh 14.987286531685108
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([2.183196 , 6.874613 , 3.9616592], dtype=float32)}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.6166203252032536
{'scaleFactor': 30, 'timeStep': 4, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([2.2697892, 7.016534 , 2.7559419], dtype=float32)}
episode index:1371
target Thresh 14.987349940372862
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([0.18616486, 3.994345  , 2.4884691 ], dtype=float32)}
done in step count: 178
reward sum = 0.1671339350148836
running average episode reward sum: 0.6162927112162359
{'scaleFactor': 30, 'timeStep': 179, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([ 7.770899 , 10.699579 ,  5.8296766], dtype=float32)}
episode index:1372
target Thresh 14.987413032808467
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([12.08468  ,  4.8809743,  1.4655458], dtype=float32)}
done in step count: 27
reward sum = 0.7623427143471035
running average episode reward sum: 0.6163990841245613
{'scaleFactor': 30, 'timeStep': 28, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([10.657974 ,  8.7232485,  2.9215906], dtype=float32)}
episode index:1373
target Thresh 14.987475810569235
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([2.3177445, 6.017075 , 2.8792496], dtype=float32)}
done in step count: 92
reward sum = 0.3966778064220251
running average episode reward sum: 0.6162391705308914
{'scaleFactor': 30, 'timeStep': 93, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([0.11348724, 3.9034562 , 3.883274  ], dtype=float32)}
episode index:1374
target Thresh 14.987538275224615
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([7.0484934, 8.822055 , 1.4116603], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.6165109965886871
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([6.775948 , 8.696018 , 1.7836547], dtype=float32)}
episode index:1375
target Thresh 14.98760042833623
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([5.9293494, 9.300198 , 1.5995581], dtype=float32)}
done in step count: 16
reward sum = 0.8514577710948755
running average episode reward sum: 0.6166817427910899
{'scaleFactor': 30, 'timeStep': 17, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([ 9.099476, 11.92041 ,  5.784596], dtype=float32)}
episode index:1376
target Thresh 14.987662271457904
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([3.8106892e+00, 8.9065180e+00, 8.8636242e-03], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6169601148006825
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([3.8106892e+00, 8.9065180e+00, 8.8636242e-03], dtype=float32)}
episode index:1377
target Thresh 14.987723806135723
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([13.624924,  8.849006,  5.963574], dtype=float32)}
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.6171621308670526
{'scaleFactor': 30, 'timeStep': 12, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([12.895656 ,  3.2554479,  4.2292104], dtype=float32)}
episode index:1378
target Thresh 14.987785033908054
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([ 8.068633 , 10.558892 ,  1.1419622], dtype=float32)}
done in step count: 17
reward sum = 0.8429431933839268
running average episode reward sum: 0.617325858976202
{'scaleFactor': 30, 'timeStep': 18, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([9.209394 , 7.91456  , 5.1780114], dtype=float32)}
episode index:1379
target Thresh 14.9878459563056
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([10.025001,  8.804635,  1.382955], dtype=float32)}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6175607533895532
{'scaleFactor': 30, 'timeStep': 7, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([9.912895 , 9.162393 , 1.5264909], dtype=float32)}
episode index:1380
target Thresh 14.987906574851417
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([11.087998  , 10.5279045 ,  0.29254884], dtype=float32)}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.6177684444262073
{'scaleFactor': 30, 'timeStep': 11, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([11.861233,  8.089918,  4.942503], dtype=float32)}
episode index:1381
target Thresh 14.987966891060978
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([10.033559,  9.04591 ,  5.008981], dtype=float32)}
done in step count: 15
reward sum = 0.8600583546412884
running average episode reward sum: 0.6179437627404005
{'scaleFactor': 30, 'timeStep': 16, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([3.117356 , 7.3091083, 3.1680021], dtype=float32)}
episode index:1382
target Thresh 14.988026906442188
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([3.0812833, 8.8069515, 1.5145472], dtype=float32)}
done in step count: 65
reward sum = 0.5203405226503064
running average episode reward sum: 0.617873189175621
{'scaleFactor': 30, 'timeStep': 66, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([ 8.292757 , 10.71745  ,  6.0608234], dtype=float32)}
episode index:1383
target Thresh 14.988086622495436
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([3.234261 , 9.246661 , 2.6899009], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6181492923626328
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([3.234261 , 9.246661 , 2.6899009], dtype=float32)}
episode index:1384
target Thresh 14.988146040713625
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([1.6221824, 5.1729126, 5.507098 ], dtype=float32)}
done in step count: 20
reward sum = 0.8179069375972308
running average episode reward sum: 0.6182935217093726
{'scaleFactor': 30, 'timeStep': 21, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([3.229749  , 6.088416  , 0.96200854], dtype=float32)}
episode index:1385
target Thresh 14.988205162582215
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([ 8.30818 , 10.193853,  5.287593], dtype=float32)}
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.6184805545385859
{'scaleFactor': 30, 'timeStep': 14, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([10.015815 ,  9.296073 ,  5.9742017], dtype=float32)}
episode index:1386
target Thresh 14.988263989579254
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([2.3903015, 2.9323776, 2.0344944], dtype=float32)}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.6186932702508751
{'scaleFactor': 30, 'timeStep': 10, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([0.9811427, 5.0131683, 2.5644577], dtype=float32)}
episode index:1387
target Thresh 14.988322523175423
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([3.870112 , 9.10915  , 5.5929394], dtype=float32)}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.6189395978731728
{'scaleFactor': 30, 'timeStep': 5, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([9.448097 , 8.100712 , 6.2600417], dtype=float32)}
episode index:1388
target Thresh 14.988380764834064
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([2.4501708, 8.128429 , 5.221491 ], dtype=float32)}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.6191925564060214
{'scaleFactor': 30, 'timeStep': 4, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([2.2727675, 5.595666 , 4.6500363], dtype=float32)}
episode index:1389
target Thresh 14.988438716011217
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([2.756146, 8.419215, 3.634873], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6194665185956574
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([2.756146, 8.419215, 3.634873], dtype=float32)}
episode index:1390
target Thresh 14.988496378155672
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([10.0704565,  9.955848 ,  5.257444 ], dtype=float32)}
done in step count: 51
reward sum = 0.598956006466161
running average episode reward sum: 0.6194517734395614
{'scaleFactor': 30, 'timeStep': 52, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([6.536893 , 8.958972 , 2.8905106], dtype=float32)}
episode index:1391
target Thresh 14.988553752708981
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([1.9904754 , 4.9240837 , 0.10425013], dtype=float32)}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.6196968483221479
{'scaleFactor': 30, 'timeStep': 5, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([6.5994673 , 8.047383  , 0.63497174], dtype=float32)}
episode index:1392
target Thresh 14.98861084110551
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([12.09571  ,  6.0452175,  6.138822 ], dtype=float32)}
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.6198882970108729
{'scaleFactor': 30, 'timeStep': 13, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([12.365236 ,  7.5441933,  2.197693 ], dtype=float32)}
episode index:1393
target Thresh 14.988667644772473
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([ 8.969012 , 11.840124 ,  1.6731257], dtype=float32)}
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.6200731124527582
{'scaleFactor': 30, 'timeStep': 14, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([ 3.6366856, 10.883195 ,  2.965113 ], dtype=float32)}
episode index:1394
target Thresh 14.988724165129966
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([ 6.977355 , 10.087723 ,  1.5582947], dtype=float32)}
done in step count: 53
reward sum = 0.5870367819374844
running average episode reward sum: 0.6200494304953996
{'scaleFactor': 30, 'timeStep': 54, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([2.895687 , 3.942656 , 4.2971587], dtype=float32)}
episode index:1395
target Thresh 14.988780403591
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([3.590933, 9.12684 , 6.220528], dtype=float32)}
done in step count: 56
reward sum = 0.5696012024771592
running average episode reward sum: 0.6200132927962462
{'scaleFactor': 30, 'timeStep': 57, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([1.1491783, 5.4819283, 5.3383946], dtype=float32)}
episode index:1396
target Thresh 14.98883636156154
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([12.211806 ,  3.2685206,  3.0575743], dtype=float32)}
done in step count: 32
reward sum = 0.7249803359578534
running average episode reward sum: 0.6200884302645079
{'scaleFactor': 30, 'timeStep': 33, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([13.131725 ,  7.5717607,  1.5193118], dtype=float32)}
episode index:1397
target Thresh 14.988892040440538
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([12.074078  ,  5.916005  ,  0.52118844], dtype=float32)}
done in step count: 72
reward sum = 0.48499137027416284
running average episode reward sum: 0.6199917943131558
{'scaleFactor': 30, 'timeStep': 73, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([1.8641573, 6.8362303, 4.598623 ], dtype=float32)}
episode index:1398
target Thresh 14.988947441619969
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([2.9017437, 9.024932 , 4.1230397], dtype=float32)}
done in step count: 66
reward sum = 0.5151371174238033
running average episode reward sum: 0.6199168445798539
{'scaleFactor': 30, 'timeStep': 67, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([6.311489 , 9.423637 , 0.7620511], dtype=float32)}
episode index:1399
target Thresh 14.989002566484862
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([12.1178255,  6.4709673,  3.9128609], dtype=float32)}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6201398077965161
{'scaleFactor': 30, 'timeStep': 8, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([11.022142 ,  4.0398035,  4.8707166], dtype=float32)}
episode index:1400
target Thresh 14.989057416413345
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([6.8258247, 9.121112 , 3.3371706], dtype=float32)}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.6203967386974465
{'scaleFactor': 30, 'timeStep': 3, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([3.0839639, 8.039237 , 3.700323 ], dtype=float32)}
episode index:1401
target Thresh 14.989111992776671
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([12.068543  ,  7.9426107 ,  0.90942264], dtype=float32)}
done in step count: 35
reward sum = 0.7034476949995692
running average episode reward sum: 0.62045597618411
{'scaleFactor': 30, 'timeStep': 36, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([11.696841,  4.874527,  3.992467], dtype=float32)}
episode index:1402
target Thresh 14.989166296939247
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([12.191935 ,  5.1481776,  0.5981214], dtype=float32)}
done in step count: 44
reward sum = 0.6426116020847181
running average episode reward sum: 0.620471767792022
{'scaleFactor': 30, 'timeStep': 45, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([ 7.9582458 , 10.903624  ,  0.88284314], dtype=float32)}
episode index:1403
target Thresh 14.989220330258682
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([7.9448643, 9.456217 , 3.0363326], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6207420870457313
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([7.9448643, 9.456217 , 3.0363326], dtype=float32)}
episode index:1404
target Thresh 14.989274094085813
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([10.0511875, 10.040684 ,  1.3630475], dtype=float32)}
done in step count: 21
reward sum = 0.8097278682212584
running average episode reward sum: 0.6208765964985252
{'scaleFactor': 30, 'timeStep': 22, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([13.492015,  3.342536,  3.898534], dtype=float32)}
episode index:1405
target Thresh 14.989327589764738
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([1.7036557, 8.106611 , 1.8536712], dtype=float32)}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.6211251188338748
{'scaleFactor': 30, 'timeStep': 4, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([3.1224103, 9.940247 , 0.938867 ], dtype=float32)}
episode index:1406
target Thresh 14.989380818632851
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([12.059688 ,  2.3110514,  4.5022845], dtype=float32)}
done in step count: 60
reward sum = 0.5471566423907612
running average episode reward sum: 0.62107254706668
{'scaleFactor': 30, 'timeStep': 61, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([13.276626 ,  4.182267 ,  1.8770496], dtype=float32)}
episode index:1407
target Thresh 14.989433782020877
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([11.911138,  9.327809,  5.010569], dtype=float32)}
done in step count: 88
reward sum = 0.41294967113388814
running average episode reward sum: 0.6209247325241142
{'scaleFactor': 30, 'timeStep': 89, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([3.2950737, 8.860262 , 2.5669942], dtype=float32)}
episode index:1408
target Thresh 14.989486481252902
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([2.1251354, 4.547545 , 3.3898187], dtype=float32)}
done in step count: 127
reward sum = 0.27904208858505886
running average episode reward sum: 0.6206820904773157
{'scaleFactor': 30, 'timeStep': 128, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([10.5064535,  5.5135756,  6.2066617], dtype=float32)}
episode index:1409
target Thresh 14.98953891764641
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([ 9.031926, 10.480849,  0.508314], dtype=float32)}
done in step count: 28
reward sum = 0.7547192872036326
running average episode reward sum: 0.6207771523189657
{'scaleFactor': 30, 'timeStep': 29, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([12.790601 ,  9.233938 ,  4.4523516], dtype=float32)}
episode index:1410
target Thresh 14.989591092512317
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([5.880693 , 8.942359 , 2.9249606], dtype=float32)}
done in step count: 250
reward sum = 0.08105851616218128
running average episode reward sum: 0.6203946444265797
{'scaleFactor': 30, 'timeStep': 251, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([12.271348 ,  4.732883 ,  4.7414074], dtype=float32)}
episode index:1411
target Thresh 14.989643007154992
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([10.82142  , 10.106518 ,  0.6722648], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6206634867463908
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([10.82142  , 10.106518 ,  0.6722648], dtype=float32)}
episode index:1412
target Thresh 14.989694662872308
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([1.8057224, 9.834795 , 2.0264378], dtype=float32)}
done in step count: 73
reward sum = 0.4801414565714212
running average episode reward sum: 0.6205640373265926
{'scaleFactor': 30, 'timeStep': 74, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([2.9448938, 6.2067165, 4.7548823], dtype=float32)}
episode index:1413
target Thresh 14.989746060955659
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([11.071914,  9.821161,  1.087513], dtype=float32)}
done in step count: 53
reward sum = 0.5870367819374844
running average episode reward sum: 0.6205403263963316
{'scaleFactor': 30, 'timeStep': 54, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([3.9889238, 8.583201 , 4.179329 ], dtype=float32)}
episode index:1414
target Thresh 14.98979720269
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([11.792332 ,  8.194013 ,  1.6720989], dtype=float32)}
done in step count: 20
reward sum = 0.8179069375972308
running average episode reward sum: 0.6206798081003605
{'scaleFactor': 30, 'timeStep': 21, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([3.5721674, 6.1223474, 3.826219 ], dtype=float32)}
episode index:1415
target Thresh 14.989848089353876
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([12.054725  ,  7.925005  ,  0.56832385], dtype=float32)}
done in step count: 30
reward sum = 0.7397003733882802
running average episode reward sum: 0.6207638621718915
{'scaleFactor': 30, 'timeStep': 31, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([10.052923 ,  5.215228 ,  3.8619194], dtype=float32)}
episode index:1416
target Thresh 14.989898722219458
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([9.070503, 8.990512, 4.777215], dtype=float32)}
done in step count: 29
reward sum = 0.7471720943315961
running average episode reward sum: 0.6208530705220395
{'scaleFactor': 30, 'timeStep': 30, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([1.8900797, 3.2982907, 3.7928874], dtype=float32)}
episode index:1417
target Thresh 14.989949102552568
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([ 2.0709758, 10.337679 ,  3.0016057], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6211204519955783
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([ 2.0709758, 10.337679 ,  3.0016057], dtype=float32)}
episode index:1418
target Thresh 14.98999923161272
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([1.9046103, 4.121936 , 5.9851966], dtype=float32)}
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.6213136992135228
{'scaleFactor': 30, 'timeStep': 12, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([6.898405, 9.725219, 6.256271], dtype=float32)}
episode index:1419
target Thresh 14.99004911065314
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([1.9851505e+00, 4.0592260e+00, 2.9577389e-03], dtype=float32)}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6215391685446406
{'scaleFactor': 30, 'timeStep': 7, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([3.6277142, 7.677578 , 1.0129182], dtype=float32)}
episode index:1420
target Thresh 14.990098740920809
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([12.177838 ,  4.817412 ,  1.0243841], dtype=float32)}
done in step count: 153
reward sum = 0.2148744477060795
running average episode reward sum: 0.621252986475085
{'scaleFactor': 30, 'timeStep': 154, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([2.8510761, 8.475751 , 3.9370687], dtype=float32)}
episode index:1421
target Thresh 14.990148123656486
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([10.853495 ,  9.903064 ,  2.2946665], dtype=float32)}
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.6214457327956079
{'scaleFactor': 30, 'timeStep': 12, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([ 7.891567 , 10.246545 ,  3.7332203], dtype=float32)}
episode index:1422
target Thresh 14.990197260094739
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([ 8.08899  , 10.081005 ,  5.4303756], dtype=float32)}
done in step count: 139
reward sum = 0.24733868589386818
running average episode reward sum: 0.6211828325518259
{'scaleFactor': 30, 'timeStep': 140, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([0.06016278, 3.0166147 , 5.135376  ], dtype=float32)}
episode index:1423
target Thresh 14.990246151463985
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([ 3.9887133, 10.005679 ,  1.7552367], dtype=float32)}
done in step count: 44
reward sum = 0.6426116020847181
running average episode reward sum: 0.6211978808450372
{'scaleFactor': 30, 'timeStep': 45, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([ 8.308581 , 10.419688 ,  3.6352735], dtype=float32)}
episode index:1424
target Thresh 14.99029479898651
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([7.0998254, 9.718721 , 3.027994 ], dtype=float32)}
done in step count: 14
reward sum = 0.8687458127689782
running average episode reward sum: 0.6213715986920014
{'scaleFactor': 30, 'timeStep': 15, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([8.11708  , 9.631865 , 1.8273633], dtype=float32)}
episode index:1425
target Thresh 14.990343203878504
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([2.193878, 9.682581, 5.520549], dtype=float32)}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.6216094839734235
{'scaleFactor': 30, 'timeStep': 5, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([ 8.22512  , 10.001156 ,  6.0683823], dtype=float32)}
episode index:1426
target Thresh 14.990391367350092
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([10.398191 ,  7.9546037,  2.6185493], dtype=float32)}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.6218140444243767
{'scaleFactor': 30, 'timeStep': 10, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([ 3.8534055, 11.445454 ,  4.061764 ], dtype=float32)}
episode index:1427
target Thresh 14.990439290605364
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([10.571083 ,  7.332881 ,  2.0932148], dtype=float32)}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6220445598343737
{'scaleFactor': 30, 'timeStep': 6, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([ 5.944295, 10.923845,  2.525512], dtype=float32)}
episode index:1428
target Thresh 14.990486974842401
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([12.140598 ,  6.969626 ,  5.7341104], dtype=float32)}
done in step count: 252
reward sum = 0.07944545169055386
running average episode reward sum: 0.6216648543703122
{'scaleFactor': 30, 'timeStep': 253, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([1.0498871, 5.909731 , 1.7390313], dtype=float32)}
episode index:1429
target Thresh 14.990534421253317
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([13.156113,  8.019481,  5.396332], dtype=float32)}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6218819176525057
{'scaleFactor': 30, 'timeStep': 8, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([13.008174,  4.769635,  4.756262], dtype=float32)}
episode index:1430
target Thresh 14.99058163102427
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([11.664273 ,  9.386664 ,  5.9765406], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6221461511132655
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([11.664273 ,  9.386664 ,  5.9765406], dtype=float32)}
episode index:1431
target Thresh 14.990628605335507
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([3.3873162, 6.065128 , 0.8224416], dtype=float32)}
done in step count: 59
reward sum = 0.5526834771623851
running average episode reward sum: 0.6220976436593892
{'scaleFactor': 30, 'timeStep': 60, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([12.70892 , 10.944964,  5.932631], dtype=float32)}
episode index:1432
target Thresh 14.990675345361389
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([3.9860866, 8.984335 , 3.430575 ], dtype=float32)}
done in step count: 28
reward sum = 0.7547192872036326
running average episode reward sum: 0.6221901919102925
{'scaleFactor': 30, 'timeStep': 29, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([11.558343 ,  6.02848  ,  6.0579495], dtype=float32)}
episode index:1433
target Thresh 14.99072185227042
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([10.031628,  8.569164,  3.078196], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6224536576063103
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([10.031628,  8.569164,  3.078196], dtype=float32)}
episode index:1434
target Thresh 14.990768127225275
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([1.9388692, 4.180303 , 2.3874822], dtype=float32)}
done in step count: 43
reward sum = 0.6491026283684022
running average episode reward sum: 0.6224722283176428
{'scaleFactor': 30, 'timeStep': 44, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([5.8162246 , 7.773405  , 0.04966538], dtype=float32)}
episode index:1435
target Thresh 14.990814171382828
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([2.027172 , 7.0111294, 5.6912327], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.622735130665611
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([2.027172 , 7.0111294, 5.6912327], dtype=float32)}
episode index:1436
target Thresh 14.99085998589419
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([1.764796 , 3.9296744, 5.1410913], dtype=float32)}
done in step count: 88
reward sum = 0.41294967113388814
running average episode reward sum: 0.6225891421760273
{'scaleFactor': 30, 'timeStep': 89, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([ 2.1246164, 11.743525 ,  2.781605 ], dtype=float32)}
episode index:1437
target Thresh 14.99090557190472
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([3.6906128, 1.5513599, 5.5621843], dtype=float32)}
done in step count: 127
reward sum = 0.27904208858505886
running average episode reward sum: 0.6223502360191491
{'scaleFactor': 30, 'timeStep': 128, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([8.104635 , 9.646284 , 6.1234136], dtype=float32)}
episode index:1438
target Thresh 14.990950930554078
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([1.7084452, 8.082003 , 3.080954 ], dtype=float32)}
done in step count: 282
reward sum = 0.05876583027950327
running average episode reward sum: 0.6219585859804141
{'scaleFactor': 30, 'timeStep': 283, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([11.10184   ,  7.108491  ,  0.49348846], dtype=float32)}
episode index:1439
target Thresh 14.990996062976226
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([8.199253 , 9.029865 , 2.0359719], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.62222111474015
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([8.199253 , 9.029865 , 2.0359719], dtype=float32)}
episode index:1440
target Thresh 14.99104097029948
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([2.0120802, 7.0381374, 4.0815964], dtype=float32)}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.6224296668426398
{'scaleFactor': 30, 'timeStep': 9, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([5.467884  , 8.361843  , 0.14756936], dtype=float32)}
episode index:1441
target Thresh 14.991085653646525
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([8.915688 , 9.949014 , 5.3780274], dtype=float32)}
done in step count: 36
reward sum = 0.6964132180495735
running average episode reward sum: 0.6224809730501342
{'scaleFactor': 30, 'timeStep': 37, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([5.795247 , 9.340744 , 2.7686346], dtype=float32)}
episode index:1442
target Thresh 14.991130114134446
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([2.0517423, 7.960707 , 3.1199195], dtype=float32)}
done in step count: 44
reward sum = 0.6426116020847181
running average episode reward sum: 0.6224949235900057
{'scaleFactor': 30, 'timeStep': 45, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([11.232433 ,  8.4170685,  5.3086386], dtype=float32)}
episode index:1443
target Thresh 14.991174352874758
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([11.399384 ,  6.112752 ,  1.8806256], dtype=float32)}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.6227290656166055
{'scaleFactor': 30, 'timeStep': 5, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([9.760708 , 9.599907 , 2.3964553], dtype=float32)}
episode index:1444
target Thresh 14.991218370973435
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([3.0241234, 9.382855 , 2.971542 ], dtype=float32)}
done in step count: 18
reward sum = 0.8345137614500875
running average episode reward sum: 0.6228756294199504
{'scaleFactor': 30, 'timeStep': 19, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([0.25521815, 7.185966  , 4.2121444 ], dtype=float32)}
episode index:1445
target Thresh 14.991262169530927
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([ 8.888676 , 10.145749 ,  3.9868617], dtype=float32)}
done in step count: 143
reward sum = 0.23759255478829303
running average episode reward sum: 0.6226091819271208
{'scaleFactor': 30, 'timeStep': 144, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([10.23521  ,  5.597711 ,  5.6170917], dtype=float32)}
episode index:1446
target Thresh 14.991305749642201
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([ 6.002615, 10.079023,  4.00258 ], dtype=float32)}
done in step count: 57
reward sum = 0.5639051904523875
running average episode reward sum: 0.6225686124789696
{'scaleFactor': 30, 'timeStep': 58, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([ 9.05895  , 10.007716 ,  5.6418705], dtype=float32)}
episode index:1447
target Thresh 14.991349112396765
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([1.8574752, 8.775188 , 2.522781 ], dtype=float32)}
done in step count: 56
reward sum = 0.5696012024771592
running average episode reward sum: 0.6225320327759297
{'scaleFactor': 30, 'timeStep': 57, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([13.833915 ,  1.6099564,  4.1206446], dtype=float32)}
episode index:1448
target Thresh 14.991392258878689
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([12.21243  ,  4.1117363,  1.7738323], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.622792535168769
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([12.21243  ,  4.1117363,  1.7738323], dtype=float32)}
episode index:1449
target Thresh 14.991435190166634
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([2.123959 , 2.9591765, 3.506773 ], dtype=float32)}
done in step count: 25
reward sum = 0.7778213593991467
running average episode reward sum: 0.6228994515992727
{'scaleFactor': 30, 'timeStep': 26, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([4.2955823, 8.558399 , 1.4051753], dtype=float32)}
episode index:1450
target Thresh 14.99147790733389
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([2.03455  , 4.76045  , 4.5786433], dtype=float32)}
done in step count: 29
reward sum = 0.7471720943315961
running average episode reward sum: 0.6229850978037746
{'scaleFactor': 30, 'timeStep': 30, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([10.213577 ,  8.120812 ,  1.8327308], dtype=float32)}
episode index:1451
target Thresh 14.991520411448384
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([6.186763 , 8.728399 , 0.7171507], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6232447499402735
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([6.186763 , 8.728399 , 0.7171507], dtype=float32)}
episode index:1452
target Thresh 14.991562703572722
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([2.0355344, 3.9377487, 5.204238 ], dtype=float32)}
done in step count: 157
reward sum = 0.2064075371174136
running average episode reward sum: 0.6229578695460389
{'scaleFactor': 30, 'timeStep': 158, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([10.385589 ,  3.445199 ,  3.5004258], dtype=float32)}
episode index:1453
target Thresh 14.991604784764212
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([3.7154007, 7.5592422, 6.1708856], dtype=float32)}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.6232034968709729
{'scaleFactor': 30, 'timeStep': 3, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([7.83654  , 8.003106 , 0.3342245], dtype=float32)}
episode index:1454
target Thresh 14.991646656074881
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([1.8943796, 2.886699 , 4.4772735], dtype=float32)}
done in step count: 286
reward sum = 0.05645022209082803
running average episode reward sum: 0.6228139757199213
{'scaleFactor': 30, 'timeStep': 287, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([11.967115,  6.686692,  6.082277], dtype=float32)}
episode index:1455
target Thresh 14.99168831855152
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([12.060384,  9.840679,  5.941926], dtype=float32)}
done in step count: 56
reward sum = 0.5696012024771592
running average episode reward sum: 0.6227774284855513
{'scaleFactor': 30, 'timeStep': 57, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([ 8.981395 , 11.941002 ,  2.2168503], dtype=float32)}
episode index:1456
target Thresh 14.991729773235686
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([7.03788 , 9.064451, 3.979237], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.623036332103612
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([7.03788 , 9.064451, 3.979237], dtype=float32)}
episode index:1457
target Thresh 14.991771021163753
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([12.786365 ,  3.8342688,  0.8395696], dtype=float32)}
done in step count: 26
reward sum = 0.7700431458051551
running average episode reward sum: 0.6231371598222001
{'scaleFactor': 30, 'timeStep': 27, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([11.148588,  9.59215 ,  2.42166 ], dtype=float32)}
episode index:1458
target Thresh 14.991812063366924
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([3.38413  , 8.700772 , 3.9159877], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6233954619744809
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([3.38413  , 8.700772 , 3.9159877], dtype=float32)}
episode index:1459
target Thresh 14.99185290087125
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([10.746178 ,  9.126376 ,  2.1339288], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.623653410288197
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([10.746178 ,  9.126376 ,  2.1339288], dtype=float32)}
episode index:1460
target Thresh 14.991893534697674
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([2.0492482, 6.6243615, 1.6133691], dtype=float32)}
done in step count: 96
reward sum = 0.38104711810454966
running average episode reward sum: 0.6234873553311924
{'scaleFactor': 30, 'timeStep': 97, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([ 7.607587 , 10.823156 ,  2.3821573], dtype=float32)}
episode index:1461
target Thresh 14.991933965862042
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([ 3.515544 , 11.003621 ,  2.6985502], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6237448879198851
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([ 3.515544 , 11.003621 ,  2.6985502], dtype=float32)}
episode index:1462
target Thresh 14.991974195375139
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([ 3.9081402, 10.094881 ,  4.3996773], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6240020684476227
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([ 3.9081402, 10.094881 ,  4.3996773], dtype=float32)}
episode index:1463
target Thresh 14.992014224242702
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([9.103373, 9.795526, 3.642603], dtype=float32)}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.6242319823421257
{'scaleFactor': 30, 'timeStep': 5, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([5.9769783, 7.963209 , 2.9041898], dtype=float32)}
episode index:1464
target Thresh 14.992054053465452
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([11.008728,  9.924847,  5.361113], dtype=float32)}
done in step count: 40
reward sum = 0.6689717585696803
running average episode reward sum: 0.6242625214385268
{'scaleFactor': 30, 'timeStep': 41, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([ 3.7095277, 11.859642 ,  3.2778473], dtype=float32)}
episode index:1465
target Thresh 14.992093684039126
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([10.404329 ,  5.9840817,  2.8560116], dtype=float32)}
done in step count: 92
reward sum = 0.3966778064220251
running average episode reward sum: 0.6241072794773969
{'scaleFactor': 30, 'timeStep': 93, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([ 9.106734 , 10.207237 ,  2.3015933], dtype=float32)}
episode index:1466
target Thresh 14.992133116954491
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([3.1928139, 8.986643 , 2.2287586], dtype=float32)}
done in step count: 32
reward sum = 0.7249803359578534
running average episode reward sum: 0.6241760409337571
{'scaleFactor': 30, 'timeStep': 33, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([ 9.20153   , 10.978907  ,  0.24551243], dtype=float32)}
episode index:1467
target Thresh 14.99217235319737
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([1.8520229, 1.9039911, 5.8817706], dtype=float32)}
done in step count: 51
reward sum = 0.598956006466161
running average episode reward sum: 0.6241588610737656
{'scaleFactor': 30, 'timeStep': 52, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([9.090593 , 8.868078 , 1.2002335], dtype=float32)}
episode index:1468
target Thresh 14.99221139374867
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([ 6.312991 , 10.266399 ,  4.8628125], dtype=float32)}
done in step count: 21
reward sum = 0.8097278682212584
running average episode reward sum: 0.6242851844278483
{'scaleFactor': 30, 'timeStep': 22, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([0.62118846, 3.847569  , 3.3687463 ], dtype=float32)}
episode index:1469
target Thresh 14.992250239584408
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([2.1550424, 8.882516 , 2.093796 ], dtype=float32)}
done in step count: 48
reward sum = 0.617290140942288
running average episode reward sum: 0.624280425894865
{'scaleFactor': 30, 'timeStep': 49, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([ 9.154738, 11.04715 ,  6.172501], dtype=float32)}
episode index:1470
target Thresh 14.992288891675734
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([11.858951 ,  8.043586 ,  3.3855948], dtype=float32)}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.6245156526617618
{'scaleFactor': 30, 'timeStep': 4, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([5.9441915, 8.520609 , 3.3311625], dtype=float32)}
episode index:1471
target Thresh 14.992327350988948
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([9.659724 , 9.76505  , 1.2792766], dtype=float32)}
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.6246935529464455
{'scaleFactor': 30, 'timeStep': 13, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([3.9917612, 7.9698973, 4.3643394], dtype=float32)}
episode index:1472
target Thresh 14.992365618485538
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([12.217309 ,  6.7421484,  1.5132487], dtype=float32)}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6249086151300535
{'scaleFactor': 30, 'timeStep': 7, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([6.8801045, 9.29973  , 3.0426567], dtype=float32)}
episode index:1473
target Thresh 14.992403695122192
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([10.015155 ,  9.1014185,  3.7597563], dtype=float32)}
done in step count: 255
reward sum = 0.07708584232989273
running average episode reward sum: 0.6245369578893477
{'scaleFactor': 30, 'timeStep': 256, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([2.994606 , 8.707992 , 1.1847658], dtype=float32)}
episode index:1474
target Thresh 14.99244158185083
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([8.710871 , 9.875612 , 4.1796384], dtype=float32)}
done in step count: 18
reward sum = 0.8345137614500875
running average episode reward sum: 0.6246793150443042
{'scaleFactor': 30, 'timeStep': 19, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([5.4946527, 7.3756647, 3.0234869], dtype=float32)}
episode index:1475
target Thresh 14.99247927961862
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([12.028839 ,  7.195257 ,  1.0265244], dtype=float32)}
done in step count: 33
reward sum = 0.7177305325982749
running average episode reward sum: 0.6247423578746253
{'scaleFactor': 30, 'timeStep': 34, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([8.847675 , 9.8511915, 2.1030178], dtype=float32)}
episode index:1476
target Thresh 14.992516789368008
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([12.210138 ,  7.11483  ,  5.7978625], dtype=float32)}
done in step count: 307
reward sum = 0.045709317994222766
running average episode reward sum: 0.6243503246722689
{'scaleFactor': 30, 'timeStep': 308, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([0.08260691, 3.4330883 , 4.8991165 ], dtype=float32)}
episode index:1477
target Thresh 14.99255411203674
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([ 8.877985 , 10.10656  ,  2.5148695], dtype=float32)}
done in step count: 84
reward sum = 0.4298890135238935
running average episode reward sum: 0.6242187540963904
{'scaleFactor': 30, 'timeStep': 85, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([11.758953 , 10.387798 ,  4.9799676], dtype=float32)}
episode index:1478
target Thresh 14.992591248557886
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([10.4013405,  1.7331303,  3.713624 ], dtype=float32)}
done in step count: 107
reward sum = 0.34116606151404244
running average episode reward sum: 0.624027372965503
{'scaleFactor': 30, 'timeStep': 108, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([3.5180397, 6.9823575, 0.8516359], dtype=float32)}
episode index:1479
target Thresh 14.992628199859858
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([8.004555 , 8.264957 , 5.7536983], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6242814085243101
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([8.004555 , 8.264957 , 5.7536983], dtype=float32)}
episode index:1480
target Thresh 14.992664966866444
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([7.911065 , 9.434671 , 5.9679213], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.6245283488291553
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([9.743338, 8.820088, 6.17272 ], dtype=float32)}
episode index:1481
target Thresh 14.992701550496822
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([10.033049 , 11.652879 ,  0.9994904], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.624781703519554
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([10.033049 , 11.652879 ,  0.9994904], dtype=float32)}
episode index:1482
target Thresh 14.992737951665578
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([ 1.9182343, 10.094549 ,  1.395852 ], dtype=float32)}
done in step count: 49
reward sum = 0.611117239532865
running average episode reward sum: 0.6247724894507835
{'scaleFactor': 30, 'timeStep': 50, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([5.493778, 8.398672, 5.784548], dtype=float32)}
episode index:1483
target Thresh 14.99277417128275
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([10.958313 ,  8.892918 ,  2.7891903], dtype=float32)}
done in step count: 208
reward sum = 0.12362903413636196
running average episode reward sum: 0.6244347917046147
{'scaleFactor': 30, 'timeStep': 209, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([0.08288354, 4.7516055 , 4.6597204 ], dtype=float32)}
episode index:1484
target Thresh 14.992810210253829
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([9.361529 , 8.791144 , 1.4413044], dtype=float32)}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.624661162895386
{'scaleFactor': 30, 'timeStep': 5, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([8.983729 , 8.617585 , 0.8685394], dtype=float32)}
episode index:1485
target Thresh 14.992846069479787
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([1.9743032, 5.1795163, 4.8732734], dtype=float32)}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6248680297762822
{'scaleFactor': 30, 'timeStep': 8, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([7.346298  , 7.9349246 , 0.31941247], dtype=float32)}
episode index:1486
target Thresh 14.992881749857112
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([3.1587067, 7.0019326, 5.258569 ], dtype=float32)}
done in step count: 28
reward sum = 0.7547192872036326
running average episode reward sum: 0.6249553540919698
{'scaleFactor': 30, 'timeStep': 29, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([3.941647 , 3.2728627, 4.2630897], dtype=float32)}
episode index:1487
target Thresh 14.992917252277811
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([12.367468  ,  5.209879  ,  0.69960403], dtype=float32)}
done in step count: 27
reward sum = 0.7623427143471035
running average episode reward sum: 0.625047684307195
{'scaleFactor': 30, 'timeStep': 28, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([10.249819,  7.923238,  1.799774], dtype=float32)}
episode index:1488
target Thresh 14.992952577629449
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([11.967244,  9.030117,  4.701082], dtype=float32)}
done in step count: 399
reward sum = 0.0
running average episode reward sum: 0.6246279074876468
{'scaleFactor': 30, 'timeStep': 400, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([10.232042 ,  7.390763 ,  5.3863945], dtype=float32)}
episode index:1489
target Thresh 14.99298772679516
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([11.84257 ,  3.047669,  4.583687], dtype=float32)}
done in step count: 144
reward sum = 0.23521662924041012
running average episode reward sum: 0.6243665576364742
{'scaleFactor': 30, 'timeStep': 145, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([ 1.4191571, 10.858116 ,  3.8019722], dtype=float32)}
episode index:1490
target Thresh 14.993022700653674
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([2.1872935 , 9.848084  , 0.26683176], dtype=float32)}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.6246051447876234
{'scaleFactor': 30, 'timeStep': 3, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([6.205168 , 9.957013 , 6.2236915], dtype=float32)}
episode index:1491
target Thresh 14.993057500079344
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([2.032444 , 9.232808 , 4.4260554], dtype=float32)}
done in step count: 46
reward sum = 0.6298236312032323
running average episode reward sum: 0.624608642432674
{'scaleFactor': 30, 'timeStep': 47, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([ 9.69139   , 10.346584  ,  0.34780812], dtype=float32)}
episode index:1492
target Thresh 14.993092125942152
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([7.9388185, 8.937789 , 2.2677817], dtype=float32)}
done in step count: 161
reward sum = 0.19827425658891443
running average episode reward sum: 0.6243230869163687
{'scaleFactor': 30, 'timeStep': 162, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([10.720139 ,  9.132154 ,  5.7909145], dtype=float32)}
episode index:1493
target Thresh 14.99312657910775
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([3.0040913, 4.6574993, 0.8970087], dtype=float32)}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6245290723654924
{'scaleFactor': 30, 'timeStep': 8, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([9.485017 , 7.6295547, 6.133615 ], dtype=float32)}
episode index:1494
target Thresh 14.993160860437468
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([1.8933152, 4.869033 , 1.7250972], dtype=float32)}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.6247669124508666
{'scaleFactor': 30, 'timeStep': 3, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([0.7574096, 8.925772 , 1.3703041], dtype=float32)}
episode index:1495
target Thresh 14.99319497078834
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([4.034289 , 9.116562 , 1.8148863], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6250177367072497
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([4.034289 , 9.116562 , 1.8148863], dtype=float32)}
episode index:1496
target Thresh 14.993228911013126
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([ 6.9142094, 10.048193 ,  0.4329186], dtype=float32)}
done in step count: 57
reward sum = 0.5639051904523875
running average episode reward sum: 0.624976913363058
{'scaleFactor': 30, 'timeStep': 58, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([2.836945 , 9.235401 , 3.4596155], dtype=float32)}
episode index:1497
target Thresh 14.993262681960339
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([10.318375 ,  7.9080963,  2.984612 ], dtype=float32)}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6251945456304392
{'scaleFactor': 30, 'timeStep': 6, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([4.74269 , 9.819136, 2.520791], dtype=float32)}
episode index:1498
target Thresh 14.993296284474246
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([1.8317091, 4.023054 , 2.5242815], dtype=float32)}
done in step count: 146
reward sum = 0.23053581831852593
running average episode reward sum: 0.6249312642913385
{'scaleFactor': 30, 'timeStep': 147, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([4.3358326, 8.84287  , 1.6798577], dtype=float32)}
episode index:1499
target Thresh 14.993329719394918
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([1.9219513, 9.876973 , 1.6854963], dtype=float32)}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.6251615094484776
{'scaleFactor': 30, 'timeStep': 4, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([ 4.1015654 , 10.701928  ,  0.34605205], dtype=float32)}
episode index:1500
target Thresh 14.993362987558225
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([10.005736 , 10.180436 ,  4.6666822], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.6254045730664334
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([10.341156,  8.237666,  5.132781], dtype=float32)}
episode index:1501
target Thresh 14.993396089795878
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([12.074752 ,  2.5957603,  3.3618257], dtype=float32)}
done in step count: 35
reward sum = 0.7034476949995692
running average episode reward sum: 0.6254565325350973
{'scaleFactor': 30, 'timeStep': 36, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([10.183263 ,  7.9390397,  1.8227694], dtype=float32)}
episode index:1502
target Thresh 14.99342902693543
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([2.1253083, 3.0808372, 2.3460097], dtype=float32)}
done in step count: 386
reward sum = 0.020662606957299545
running average episode reward sum: 0.6250541413670482
{'scaleFactor': 30, 'timeStep': 387, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([11.454358,  8.99396 ,  5.62367 ], dtype=float32)}
episode index:1503
target Thresh 14.993461799800315
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([2.9440167, 4.7757845, 0.9668772], dtype=float32)}
done in step count: 31
reward sum = 0.7323033696543975
running average episode reward sum: 0.6251254506943669
{'scaleFactor': 30, 'timeStep': 32, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([13.208568 ,  8.761547 ,  5.4351397], dtype=float32)}
episode index:1504
target Thresh 14.993494409209854
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([10.972632 ,  7.114052 ,  3.6589315], dtype=float32)}
done in step count: 27
reward sum = 0.7623427143471035
running average episode reward sum: 0.6252166249559302
{'scaleFactor': 30, 'timeStep': 28, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([8.271566 , 7.4754577, 2.949334 ], dtype=float32)}
episode index:1505
target Thresh 14.993526855979283
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([12.078104 ,  5.382821 ,  0.5036155], dtype=float32)}
done in step count: 150
reward sum = 0.22145178723886091
running average episode reward sum: 0.6249485208140197
{'scaleFactor': 30, 'timeStep': 151, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([3.9787173 , 8.839888  , 0.46209466], dtype=float32)}
episode index:1506
target Thresh 14.993559140919773
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([2.200223, 8.830643, 5.709779], dtype=float32)}
done in step count: 77
reward sum = 0.46122196741809546
running average episode reward sum: 0.6248398767838964
{'scaleFactor': 30, 'timeStep': 78, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([1.4170687, 3.3456907, 4.2222075], dtype=float32)}
episode index:1507
target Thresh 14.993591264838454
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([2.0608575, 6.011085 , 4.9629827], dtype=float32)}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.6250374263977188
{'scaleFactor': 30, 'timeStep': 9, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([7.268754  , 7.41459   , 0.45903018], dtype=float32)}
episode index:1508
target Thresh 14.993623228538421
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([12.167118  ,  3.9046617 ,  0.14440882], dtype=float32)}
done in step count: 29
reward sum = 0.7471720943315961
running average episode reward sum: 0.6251183638847525
{'scaleFactor': 30, 'timeStep': 30, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([ 5.0262694, 10.94647  ,  3.2767713], dtype=float32)}
episode index:1509
target Thresh 14.993655032818769
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([11.980982 ,  2.9709072,  5.0608463], dtype=float32)}
done in step count: 292
reward sum = 0.0531467635277924
running average episode reward sum: 0.6247395747454433
{'scaleFactor': 30, 'timeStep': 293, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([3.6113043, 5.073694 , 4.7799206], dtype=float32)}
episode index:1510
target Thresh 14.993686678474608
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([11.908907 ,  9.068022 ,  3.6204133], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.6249813089779083
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([10.249734,  8.104029,  4.036784], dtype=float32)}
episode index:1511
target Thresh 14.993718166297079
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([3.9132233, 5.4450808, 0.5891921], dtype=float32)}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.6251660978443307
{'scaleFactor': 30, 'timeStep': 11, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([10.422759,  6.916386,  5.931712], dtype=float32)}
episode index:1512
target Thresh 14.993749497073381
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([1.7961537, 7.3203044, 4.300919 ], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6254138400136339
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([1.7961537, 7.3203044, 4.300919 ], dtype=float32)}
episode index:1513
target Thresh 14.993780671586784
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([10.190388 ,  9.9614525,  3.364193 ], dtype=float32)}
done in step count: 15
reward sum = 0.8600583546412884
running average episode reward sum: 0.6255688231804949
{'scaleFactor': 30, 'timeStep': 16, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([10.141712 ,  3.1076539,  4.723596 ], dtype=float32)}
episode index:1514
target Thresh 14.993811690616651
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([3.1234264, 8.837242 , 1.3494853], dtype=float32)}
done in step count: 15
reward sum = 0.8600583546412884
running average episode reward sum: 0.6257236017491159
{'scaleFactor': 30, 'timeStep': 16, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([3.6671019, 7.9333615, 5.328108 ], dtype=float32)}
episode index:1515
target Thresh 14.993842554938462
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([2.1562717, 8.874034 , 0.8864237], dtype=float32)}
done in step count: 230
reward sum = 0.09910481551887466
running average episode reward sum: 0.6253762278795709
{'scaleFactor': 30, 'timeStep': 231, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([10.61216  ,  5.527831 ,  4.3607073], dtype=float32)}
episode index:1516
target Thresh 14.993873265323828
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([7.997464, 9.992925, 2.092093], dtype=float32)}
done in step count: 41
reward sum = 0.6622820409839835
running average episode reward sum: 0.6254005560358692
{'scaleFactor': 30, 'timeStep': 42, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([3.189352 , 3.2067509, 4.296956 ], dtype=float32)}
episode index:1517
target Thresh 14.993903822540506
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([5.3458786, 9.305252 , 3.413696 ], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6256473277380853
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([5.3458786, 9.305252 , 3.413696 ], dtype=float32)}
episode index:1518
target Thresh 14.99393422735243
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([7.916571 , 9.954648 , 2.2751162], dtype=float32)}
done in step count: 82
reward sum = 0.43861750180991077
running average episode reward sum: 0.625524200795407
{'scaleFactor': 30, 'timeStep': 83, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([1.5607308, 5.9274845, 2.8329117], dtype=float32)}
episode index:1519
target Thresh 14.993964480519722
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([11.700993 ,  1.9939507,  1.1205916], dtype=float32)}
done in step count: 34
reward sum = 0.7105532272722921
running average episode reward sum: 0.625580140944405
{'scaleFactor': 30, 'timeStep': 35, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([6.6645517, 9.407681 , 2.5200863], dtype=float32)}
episode index:1520
target Thresh 14.993994582798713
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([8.392794 , 7.9411545, 3.9307   ], dtype=float32)}
done in step count: 329
reward sum = 0.03664198753113651
running average episode reward sum: 0.6251929363727986
{'scaleFactor': 30, 'timeStep': 330, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([1.5268279, 5.328696 , 4.1985984], dtype=float32)}
episode index:1521
target Thresh 14.99402453494196
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([3.1888037, 9.976429 , 5.589465 ], dtype=float32)}
done in step count: 34
reward sum = 0.7105532272722921
running average episode reward sum: 0.625249020663797
{'scaleFactor': 30, 'timeStep': 35, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([2.0413847, 6.9286923, 4.2052665], dtype=float32)}
episode index:1522
target Thresh 14.994054337698271
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([2.0714376, 2.9975986, 5.851568 ], dtype=float32)}
done in step count: 46
reward sum = 0.6298236312032323
running average episode reward sum: 0.6252520243476705
{'scaleFactor': 30, 'timeStep': 47, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([6.696344 , 7.4805083, 6.106721 ], dtype=float32)}
episode index:1523
target Thresh 14.994083991812714
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([10.191474 ,  8.8795185,  4.6279597], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6254979219694895
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([10.191474 ,  8.8795185,  4.6279597], dtype=float32)}
episode index:1524
target Thresh 14.994113498026644
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([12.010835 ,  6.0382123,  5.4751945], dtype=float32)}
done in step count: 43
reward sum = 0.6491026283684022
running average episode reward sum: 0.6255134004654888
{'scaleFactor': 30, 'timeStep': 44, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([9.742531 , 9.2050905, 2.2737968], dtype=float32)}
episode index:1525
target Thresh 14.994142857077719
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([11.108704,  9.030802,  5.658983], dtype=float32)}
done in step count: 72
reward sum = 0.48499137027416284
running average episode reward sum: 0.6254213152556648
{'scaleFactor': 30, 'timeStep': 73, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([7.4040003, 7.4526715, 3.091041 ], dtype=float32)}
episode index:1526
target Thresh 14.994172069699916
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([2.0452888, 4.0479507, 3.6605291], dtype=float32)}
done in step count: 87
reward sum = 0.41712087993322033
running average episode reward sum: 0.6252849037066651
{'scaleFactor': 30, 'timeStep': 88, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([6.08322   , 7.046445  , 0.01268261], dtype=float32)}
episode index:1527
target Thresh 14.99420113662355
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([1.7533287, 9.157411 , 3.3258922], dtype=float32)}
done in step count: 163
reward sum = 0.19432859888279502
running average episode reward sum: 0.6250028642401574
{'scaleFactor': 30, 'timeStep': 164, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([13.695361 ,  6.4399557,  4.3801746], dtype=float32)}
episode index:1528
target Thresh 14.9942300585753
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([12.033544  ,  9.8425665 ,  0.08474176], dtype=float32)}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.6252351056631528
{'scaleFactor': 30, 'timeStep': 3, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([11.946083  ,  9.621256  ,  0.45141417], dtype=float32)}
episode index:1529
target Thresh 14.994258836278211
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([12.209935 ,  3.9960802,  0.8766945], dtype=float32)}
done in step count: 93
reward sum = 0.39271102835780486
running average episode reward sum: 0.6250831291420382
{'scaleFactor': 30, 'timeStep': 94, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([2.7172945, 8.878042 , 2.036229 ], dtype=float32)}
episode index:1530
target Thresh 14.994287470451733
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([11.961134,  9.297737,  5.152562], dtype=float32)}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.6252655582379669
{'scaleFactor': 30, 'timeStep': 11, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([6.117125 , 8.426181 , 3.7673643], dtype=float32)}
episode index:1531
target Thresh 14.994315961811717
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([3.9463696, 2.830426 , 0.6929778], dtype=float32)}
done in step count: 47
reward sum = 0.6235253948912
running average episode reward sum: 0.6252644223611087
{'scaleFactor': 30, 'timeStep': 48, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([ 4.1063004, 11.111341 ,  4.6553435], dtype=float32)}
episode index:1532
target Thresh 14.994344311070451
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([9.159037 , 9.360549 , 3.9407635], dtype=float32)}
done in step count: 107
reward sum = 0.34116606151404244
running average episode reward sum: 0.6250791005340721
{'scaleFactor': 30, 'timeStep': 108, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([ 1.0114694, 11.533108 ,  1.3362218], dtype=float32)}
episode index:1533
target Thresh 14.994372518936666
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([7.0442185, 9.008912 , 2.5139894], dtype=float32)}
done in step count: 262
reward sum = 0.07184904244991483
running average episode reward sum: 0.6247184551246301
{'scaleFactor': 30, 'timeStep': 263, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([0.7885307, 6.348426 , 4.126979 ], dtype=float32)}
episode index:1534
target Thresh 14.994400586115562
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([ 7.330267, 11.192035,  2.076434], dtype=float32)}
done in step count: 67
reward sum = 0.5099857462495653
running average episode reward sum: 0.6246437106888808
{'scaleFactor': 30, 'timeStep': 68, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([ 5.24947  , 10.214395 ,  3.6643047], dtype=float32)}
episode index:1535
target Thresh 14.99442851330882
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([2.092753, 7.768627, 4.488867], dtype=float32)}
done in step count: 44
reward sum = 0.6426116020847181
running average episode reward sum: 0.6246554085348416
{'scaleFactor': 30, 'timeStep': 45, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([11.491437 ,  4.466802 ,  5.7462993], dtype=float32)}
episode index:1536
target Thresh 14.99445630121462
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([ 4.4176903, 10.187894 ,  1.043965 ], dtype=float32)}
done in step count: 67
reward sum = 0.5099857462495653
running average episode reward sum: 0.6245808023785075
{'scaleFactor': 30, 'timeStep': 68, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([10.759977  ,  8.965151  ,  0.27222213], dtype=float32)}
episode index:1537
target Thresh 14.99448395052766
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([ 3.876184 , 10.064877 ,  3.6958766], dtype=float32)}
done in step count: 25
reward sum = 0.7778213593991467
running average episode reward sum: 0.6246804386314468
{'scaleFactor': 30, 'timeStep': 26, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([ 9.071084 , 10.906376 ,  0.6971977], dtype=float32)}
episode index:1538
target Thresh 14.99451146193918
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([4.296643 , 8.8613205, 4.883501 ], dtype=float32)}
done in step count: 30
reward sum = 0.7397003733882802
running average episode reward sum: 0.6247551754311589
{'scaleFactor': 30, 'timeStep': 31, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([10.196746 ,  5.8777847,  4.7484026], dtype=float32)}
episode index:1539
target Thresh 14.99453883613696
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([10.954722 ,  7.15689  ,  2.8751225], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6249988409016581
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([10.954722 ,  7.15689  ,  2.8751225], dtype=float32)}
episode index:1540
target Thresh 14.994566073805357
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([3.8988585, 3.8196368, 0.4999414], dtype=float32)}
done in step count: 161
reward sum = 0.19827425658891443
running average episode reward sum: 0.624721926830073
{'scaleFactor': 30, 'timeStep': 162, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([11.4321785, 11.197558 ,  5.364042 ], dtype=float32)}
episode index:1541
target Thresh 14.994593175625319
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([3.8381586 , 2.6494532 , 0.11126524], dtype=float32)}
done in step count: 399
reward sum = 0.0
running average episode reward sum: 0.624316789393737
{'scaleFactor': 30, 'timeStep': 400, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([8.269099 , 7.2289805, 4.4221663], dtype=float32)}
episode index:1542
target Thresh 14.994620142274389
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([ 8.939508 , 10.35957  ,  0.5336806], dtype=float32)}
done in step count: 24
reward sum = 0.7856781408072188
running average episode reward sum: 0.6244213657718404
{'scaleFactor': 30, 'timeStep': 25, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([13.656833 ,  6.906228 ,  0.5570872], dtype=float32)}
episode index:1543
target Thresh 14.994646974426736
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([1.9796596, 5.0831156, 3.2485805], dtype=float32)}
done in step count: 25
reward sum = 0.7778213593991467
running average episode reward sum: 0.6245207180993192
{'scaleFactor': 30, 'timeStep': 26, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([ 2.4774961, 10.670543 ,  1.0809686], dtype=float32)}
episode index:1544
target Thresh 14.994673672753166
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([2.179741, 5.231456, 5.065649], dtype=float32)}
done in step count: 50
reward sum = 0.6050060671375364
running average episode reward sum: 0.6245080872572728
{'scaleFactor': 30, 'timeStep': 51, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([4.0314403, 7.6599903, 1.381213 ], dtype=float32)}
episode index:1545
target Thresh 14.994700237921137
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([7.7715626, 8.719442 , 4.519834 ], dtype=float32)}
done in step count: 123
reward sum = 0.29048849430996376
running average episode reward sum: 0.6242920331868024
{'scaleFactor': 30, 'timeStep': 124, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([4.3362966, 7.1322694, 2.9116242], dtype=float32)}
episode index:1546
target Thresh 14.994726670594778
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([ 9.973635 , 10.098768 ,  1.4702504], dtype=float32)}
done in step count: 94
reward sum = 0.3887839180742268
running average episode reward sum: 0.6241397978182744
{'scaleFactor': 30, 'timeStep': 95, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([0.01873103, 5.539428  , 5.10614   ], dtype=float32)}
episode index:1547
target Thresh 14.99475297143491
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([4.61314 , 8.430805, 4.41357 ], dtype=float32)}
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.6243092067807408
{'scaleFactor': 30, 'timeStep': 13, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([6.7425718e+00, 7.9304023e+00, 1.3603568e-03], dtype=float32)}
episode index:1548
target Thresh 14.994779141099054
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([8.07303  , 8.805239 , 5.7326536], dtype=float32)}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.6245263060726834
{'scaleFactor': 30, 'timeStep': 5, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([10.085779,  8.058513,  5.756034], dtype=float32)}
episode index:1549
target Thresh 14.994805180241455
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([ 5.481329 , 10.318859 ,  2.2538624], dtype=float32)}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6247307924232178
{'scaleFactor': 30, 'timeStep': 7, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([2.2428708, 8.132365 , 3.2985616], dtype=float32)}
episode index:1550
target Thresh 14.994831089513092
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([ 5.9012027, 10.069097 ,  4.809435 ], dtype=float32)}
done in step count: 37
reward sum = 0.6894490858690777
running average episode reward sum: 0.6247725192403977
{'scaleFactor': 30, 'timeStep': 38, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([9.439461, 9.567612, 5.670508], dtype=float32)}
episode index:1551
target Thresh 14.994856869561696
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([11.790871 ,  4.992018 ,  0.3963739], dtype=float32)}
done in step count: 37
reward sum = 0.6894490858690777
running average episode reward sum: 0.6248141922859058
{'scaleFactor': 30, 'timeStep': 38, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([10.589135 ,  8.276647 ,  1.1573541], dtype=float32)}
episode index:1552
target Thresh 14.994882521031773
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([10.932374 ,  4.821959 ,  1.9618573], dtype=float32)}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.6250429661479239
{'scaleFactor': 30, 'timeStep': 3, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([11.599125 ,  8.380151 ,  0.7344022], dtype=float32)}
episode index:1553
target Thresh 14.994908044564607
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([12.064704 ,  2.989411 ,  5.8975015], dtype=float32)}
done in step count: 228
reward sum = 0.10111704470857531
running average episode reward sum: 0.624705819480331
{'scaleFactor': 30, 'timeStep': 229, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([2.395417, 7.251485, 3.183247], dtype=float32)}
episode index:1554
target Thresh 14.99493344079829
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([ 7.891255 , 10.167527 ,  4.0213027], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.6249407353520479
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([6.5620146, 8.536697 , 3.888197 ], dtype=float32)}
episode index:1555
target Thresh 14.994958710367731
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([ 8.864009 , 10.300156 ,  0.7394342], dtype=float32)}
done in step count: 47
reward sum = 0.6235253948912
running average episode reward sum: 0.6249398257502093
{'scaleFactor': 30, 'timeStep': 48, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([12.448344,  6.306826,  4.733546], dtype=float32)}
episode index:1556
target Thresh 14.994983853904667
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([12.16804 ,  4.014055,  0.981707], dtype=float32)}
done in step count: 135
reward sum = 0.25748460676394874
running average episode reward sum: 0.6247038236827808
{'scaleFactor': 30, 'timeStep': 136, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([2.4443002, 6.9713326, 3.8426044], dtype=float32)}
episode index:1557
target Thresh 14.99500887203769
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([ 1.7901137, 10.034628 ,  1.2617654], dtype=float32)}
done in step count: 52
reward sum = 0.5929664464014994
running average episode reward sum: 0.6246834530940252
{'scaleFactor': 30, 'timeStep': 53, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([0.6045903, 5.7094746, 4.268749 ], dtype=float32)}
episode index:1558
target Thresh 14.995033765392254
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([1.9854966, 8.083141 , 0.7140366], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.6249177805776083
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([2.0022476, 8.076878 , 0.7246103], dtype=float32)}
episode index:1559
target Thresh 14.995058534590695
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([ 1.880521 , 10.052077 ,  1.7449856], dtype=float32)}
done in step count: 56
reward sum = 0.5696012024771592
running average episode reward sum: 0.6248823212326721
{'scaleFactor': 30, 'timeStep': 57, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([7.930084  , 8.809906  , 0.36389524], dtype=float32)}
episode index:1560
target Thresh 14.995083180252243
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([7.896282, 9.937765, 5.820545], dtype=float32)}
done in step count: 47
reward sum = 0.6235253948912
running average episode reward sum: 0.6248814519653169
{'scaleFactor': 30, 'timeStep': 48, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([3.5179605, 6.273694 , 5.1955204], dtype=float32)}
episode index:1561
target Thresh 14.995107702993039
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([1.9965619, 9.792336 , 4.2232027], dtype=float32)}
done in step count: 22
reward sum = 0.8016305895390459
running average episode reward sum: 0.6249946076231746
{'scaleFactor': 30, 'timeStep': 23, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([ 5.553664, 11.182992,  6.031007], dtype=float32)}
episode index:1562
target Thresh 14.995132103426158
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([1.8507332, 4.1338453, 3.083385 ], dtype=float32)}
done in step count: 145
reward sum = 0.232864462948006
running average episode reward sum: 0.6247437246131456
{'scaleFactor': 30, 'timeStep': 146, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([13.946137 ,  7.53816  ,  4.9235015], dtype=float32)}
episode index:1563
target Thresh 14.995156382161607
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([9.121906 , 8.936157 , 5.9694247], dtype=float32)}
done in step count: 175
reward sum = 0.1722499301915014
running average episode reward sum: 0.6244544063302674
{'scaleFactor': 30, 'timeStep': 176, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([2.2702832, 6.786962 , 1.8617933], dtype=float32)}
episode index:1564
target Thresh 14.995180539806361
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([12.267499 ,  7.735099 ,  1.8469678], dtype=float32)}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.6246332738501897
{'scaleFactor': 30, 'timeStep': 11, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([ 9.12686  , 10.428904 ,  2.8687851], dtype=float32)}
episode index:1565
target Thresh 14.995204576964356
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([5.112222 , 9.880593 , 2.1589363], dtype=float32)}
done in step count: 119
reward sum = 0.30240443566902153
running average episode reward sum: 0.6244275083085671
{'scaleFactor': 30, 'timeStep': 120, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([ 9.039701  , 11.013045  ,  0.16173035], dtype=float32)}
episode index:1566
target Thresh 14.995228494236525
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([9.007357 , 9.92779  , 1.1370088], dtype=float32)}
done in step count: 21
reward sum = 0.8097278682212584
running average episode reward sum: 0.6245457599741143
{'scaleFactor': 30, 'timeStep': 22, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([13.987419, 10.694475,  5.339433], dtype=float32)}
episode index:1567
target Thresh 14.995252292220803
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([7.057447 , 9.962972 , 1.7891912], dtype=float32)}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.6247725165047431
{'scaleFactor': 30, 'timeStep': 3, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([ 5.9636054, 11.712013 ,  2.2865043], dtype=float32)}
episode index:1568
target Thresh 14.99527597151214
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([11.962173,  8.150072,  4.22699 ], dtype=float32)}
done in step count: 48
reward sum = 0.617290140942288
running average episode reward sum: 0.6247677476229314
{'scaleFactor': 30, 'timeStep': 49, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([13.884054 ,  2.6455286,  5.058068 ], dtype=float32)}
episode index:1569
target Thresh 14.995299532702516
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([8.884321  , 8.541303  , 0.19668978], dtype=float32)}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.624969475267376
{'scaleFactor': 30, 'timeStep': 7, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([12.437383 ,  3.5175223,  5.432666 ], dtype=float32)}
episode index:1570
target Thresh 14.995322976380967
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([12.086618 ,  6.807872 ,  4.5965233], dtype=float32)}
done in step count: 100
reward sum = 0.3660323412732292
running average episode reward sum: 0.6248046521394357
{'scaleFactor': 30, 'timeStep': 101, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([ 9.587279 , 11.829927 ,  3.0101473], dtype=float32)}
episode index:1571
target Thresh 14.995346303133584
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([11.907911 ,  7.1411734,  1.3364198], dtype=float32)}
done in step count: 61
reward sum = 0.5416850759668536
running average episode reward sum: 0.6247517770909798
{'scaleFactor': 30, 'timeStep': 62, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([2.0155396, 5.6513925, 3.4741647], dtype=float32)}
episode index:1572
target Thresh 14.995369513543535
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([10.002775,  6.866566,  3.188871], dtype=float32)}
done in step count: 25
reward sum = 0.7778213593991467
running average episode reward sum: 0.6248490876963887
{'scaleFactor': 30, 'timeStep': 26, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([0.8379512, 2.359124 , 4.391283 ], dtype=float32)}
episode index:1573
target Thresh 14.995392608191086
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([11.944805,  6.012311,  4.068588], dtype=float32)}
done in step count: 33
reward sum = 0.7177305325982749
running average episode reward sum: 0.6249080975089057
{'scaleFactor': 30, 'timeStep': 34, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([3.1459415, 7.4391527, 3.054317 ], dtype=float32)}
episode index:1574
target Thresh 14.9954155876536
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([7.5780935, 8.715678 , 3.5782223], dtype=float32)}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.625133616177154
{'scaleFactor': 30, 'timeStep': 3, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([3.207536 , 8.129782 , 3.1605341], dtype=float32)}
episode index:1575
target Thresh 14.995438452505566
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([11.845362 ,  8.018666 ,  5.6184225], dtype=float32)}
done in step count: 61
reward sum = 0.5416850759668536
running average episode reward sum: 0.6250806665958023
{'scaleFactor': 30, 'timeStep': 62, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([ 5.707295 , 10.344562 ,  3.2915366], dtype=float32)}
episode index:1576
target Thresh 14.995461203318609
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([9.994995, 9.790602, 4.529784], dtype=float32)}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.6253057898256084
{'scaleFactor': 30, 'timeStep': 3, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([10.211273 ,  9.973214 ,  4.0422783], dtype=float32)}
episode index:1577
target Thresh 14.995483840661496
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([8.010966 , 8.971567 , 5.1403346], dtype=float32)}
done in step count: 31
reward sum = 0.7323033696543975
running average episode reward sum: 0.6253735956429903
{'scaleFactor': 30, 'timeStep': 32, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([ 5.6019173, 10.386102 ,  2.2400737], dtype=float32)}
episode index:1578
target Thresh 14.995506365100168
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([12.038307 ,  9.192604 ,  4.5538774], dtype=float32)}
done in step count: 32
reward sum = 0.7249803359578534
running average episode reward sum: 0.6254366778091176
{'scaleFactor': 30, 'timeStep': 33, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([1.6126853, 6.8175783, 5.0093026], dtype=float32)}
episode index:1579
target Thresh 14.99552877719773
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([ 3.4166527, 10.283762 ,  0.7165553], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6256737432029092
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([ 3.4166527, 10.283762 ,  0.7165553], dtype=float32)}
episode index:1580
target Thresh 14.99555107751449
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([10.90935  ,  7.7844067,  4.5001035], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6259105087037297
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([10.90935  ,  7.7844067,  4.5001035], dtype=float32)}
episode index:1581
target Thresh 14.995573266607957
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([10.093725,  5.263158,  3.579307], dtype=float32)}
done in step count: 25
reward sum = 0.7778213593991467
running average episode reward sum: 0.6260065332616914
{'scaleFactor': 30, 'timeStep': 26, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([10.049091 ,  8.891587 ,  2.1139903], dtype=float32)}
episode index:1582
target Thresh 14.995595345032859
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([12.122599,  8.161136,  4.115042], dtype=float32)}
done in step count: 62
reward sum = 0.536268225207185
running average episode reward sum: 0.6259498445010758
{'scaleFactor': 30, 'timeStep': 63, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([3.4687085 , 7.15411   , 0.07031363], dtype=float32)}
episode index:1583
target Thresh 14.995617313341157
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([6.831215, 8.921528, 5.425186], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.6261796741446989
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([7.0270877, 8.958862 , 5.230241 ], dtype=float32)}
episode index:1584
target Thresh 14.99563917208206
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([ 3.801973 , 10.024727 ,  4.3459272], dtype=float32)}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.6264029677256802
{'scaleFactor': 30, 'timeStep': 3, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([3.6471786, 7.9093885, 4.2329764], dtype=float32)}
episode index:1585
target Thresh 14.995660921802038
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([4.9978056, 8.841778 , 1.4479737], dtype=float32)}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.6265782382851273
{'scaleFactor': 30, 'timeStep': 11, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([9.475947, 9.342933, 5.702217], dtype=float32)}
episode index:1586
target Thresh 14.995682563044834
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([8.907383 , 8.886541 , 5.1410275], dtype=float32)}
done in step count: 65
reward sum = 0.5203405226503064
running average episode reward sum: 0.626511295805206
{'scaleFactor': 30, 'timeStep': 66, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([3.8980646, 8.873333 , 3.1087897], dtype=float32)}
episode index:1587
target Thresh 14.995704096351483
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([1.856466, 7.944269, 0.86946 ], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.6267401929740944
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([3.1137533 , 8.891316  , 0.15231961], dtype=float32)}
episode index:1588
target Thresh 14.995725522260315
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([11.610177 ,  5.9248343,  2.2313516], dtype=float32)}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.6269625717072762
{'scaleFactor': 30, 'timeStep': 3, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([8.219448 , 8.359266 , 2.1637576], dtype=float32)}
episode index:1589
target Thresh 14.995746841306984
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([1.8069607, 7.943107 , 4.20265  ], dtype=float32)}
done in step count: 130
reward sum = 0.27075425951199406
running average episode reward sum: 0.6267385413222478
{'scaleFactor': 30, 'timeStep': 131, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([2.6028693, 8.59275  , 1.071875 ], dtype=float32)}
episode index:1590
target Thresh 14.995768054024461
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([ 6.1447945, 10.131309 ,  0.5209181], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6269731494043834
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([ 6.1447945, 10.131309 ,  0.5209181], dtype=float32)}
episode index:1591
target Thresh 14.995789160943069
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([3.5249877, 8.580516 , 3.9207191], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.6272011813457123
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([2.0524006, 7.6263247, 3.1905172], dtype=float32)}
episode index:1592
target Thresh 14.995810162590482
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([12.131811 ,  5.9868855,  0.9793807], dtype=float32)}
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.627363882971808
{'scaleFactor': 30, 'timeStep': 13, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([ 7.3711853, 10.658415 ,  3.02663  ], dtype=float32)}
episode index:1593
target Thresh 14.99583105949174
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([2.0497632, 5.842154 , 1.6945034], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6275976571983
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([2.0497632, 5.842154 , 1.6945034], dtype=float32)}
episode index:1594
target Thresh 14.99585185216927
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([11.948551 ,  9.783375 ,  1.6757917], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6278311382909656
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([11.948551 ,  9.783375 ,  1.6757917], dtype=float32)}
episode index:1595
target Thresh 14.995872541142889
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([4.764778, 8.856507, 6.153284], dtype=float32)}
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.6279931393770716
{'scaleFactor': 30, 'timeStep': 13, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([2.4126797, 8.263255 , 3.7712953], dtype=float32)}
episode index:1596
target Thresh 14.99589312692982
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([1.9976941, 7.9737906, 5.1416874], dtype=float32)}
done in step count: 57
reward sum = 0.5639051904523875
running average episode reward sum: 0.6279530091648458
{'scaleFactor': 30, 'timeStep': 58, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([10.542165, 10.886289,  6.249456], dtype=float32)}
episode index:1597
target Thresh 14.99591361004471
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([ 9.984275 , 10.06343  ,  1.4345672], dtype=float32)}
done in step count: 31
reward sum = 0.7323033696543975
running average episode reward sum: 0.628018309765903
{'scaleFactor': 30, 'timeStep': 32, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([10.109991 ,  7.540933 ,  4.9725585], dtype=float32)}
episode index:1598
target Thresh 14.995933990999639
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([12.029654 ,  6.042089 ,  4.7540803], dtype=float32)}
done in step count: 59
reward sum = 0.5526834771623851
running average episode reward sum: 0.6279711960494531
{'scaleFactor': 30, 'timeStep': 60, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([0.40082026, 9.004848  , 4.0453315 ], dtype=float32)}
episode index:1599
target Thresh 14.99595427030413
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([13.836481  ,  3.32165   ,  0.10593086], dtype=float32)}
done in step count: 45
reward sum = 0.6361854860638709
running average episode reward sum: 0.627976329980712
{'scaleFactor': 30, 'timeStep': 46, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([13.269298 ,  9.141275 ,  1.9722704], dtype=float32)}
episode index:1600
target Thresh 14.99597444846517
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([10.068189 ,  9.759228 ,  5.9285274], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.6282024534473074
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([11.755714 ,  8.988314 ,  5.8419666], dtype=float32)}
episode index:1601
target Thresh 14.99599452598721
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([1.9239553, 4.9135385, 4.012076 ], dtype=float32)}
done in step count: 29
reward sum = 0.7471720943315961
running average episode reward sum: 0.6282767166438644
{'scaleFactor': 30, 'timeStep': 30, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([3.0839877 , 8.625955  , 0.41102347], dtype=float32)}
episode index:1602
target Thresh 14.996014503372193
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([ 7.049909  , 10.292364  ,  0.21735853], dtype=float32)}
done in step count: 79
reward sum = 0.45204365026647536
running average episode reward sum: 0.628166777113997
{'scaleFactor': 30, 'timeStep': 80, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([3.0138373, 8.697102 , 1.9099147], dtype=float32)}
episode index:1603
target Thresh 14.996034381119552
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([12.034778 ,  2.8404837,  1.607621 ], dtype=float32)}
done in step count: 66
reward sum = 0.5151371174238033
running average episode reward sum: 0.6280963097451129
{'scaleFactor': 30, 'timeStep': 67, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([3.6829467, 7.941887 , 2.9338562], dtype=float32)}
episode index:1604
target Thresh 14.996054159726231
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([1.7844617, 1.982804 , 3.3207223], dtype=float32)}
done in step count: 22
reward sum = 0.8016305895390459
running average episode reward sum: 0.6282044307917135
{'scaleFactor': 30, 'timeStep': 23, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([ 6.558296 , 10.255414 ,  1.0240207], dtype=float32)}
episode index:1605
target Thresh 14.996073839686698
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([2.1101453, 9.133825 , 2.4601624], dtype=float32)}
done in step count: 32
reward sum = 0.7249803359578534
running average episode reward sum: 0.6282646897613063
{'scaleFactor': 30, 'timeStep': 33, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([8.294905, 8.113722, 6.2419  ], dtype=float32)}
episode index:1606
target Thresh 14.996093421492954
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([7.8258257, 9.235444 , 4.045882 ], dtype=float32)}
done in step count: 23
reward sum = 0.7936142836436554
running average episode reward sum: 0.6283675830991299
{'scaleFactor': 30, 'timeStep': 24, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([8.822423 , 9.855703 , 5.7966495], dtype=float32)}
episode index:1607
target Thresh 14.996112905634543
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([8.729807 , 9.689805 , 5.9388847], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.6285924788807846
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([10.064433 ,  8.481905 ,  5.0825243], dtype=float32)}
episode index:1608
target Thresh 14.99613229259857
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([1.7622535, 5.01396  , 4.512896 ], dtype=float32)}
done in step count: 128
reward sum = 0.2762516676992083
running average episode reward sum: 0.6283734976432572
{'scaleFactor': 30, 'timeStep': 129, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([8.028716 , 8.44605  , 1.3664753], dtype=float32)}
episode index:1609
target Thresh 14.996151582869713
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([2.952848  , 3.3872256 , 0.31981087], dtype=float32)}
done in step count: 125
reward sum = 0.28470777327319546
running average episode reward sum: 0.6281600406715988
{'scaleFactor': 30, 'timeStep': 126, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([ 3.7903724, 11.13868  ,  1.1092092], dtype=float32)}
episode index:1610
target Thresh 14.996170776930226
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([14.270723  ,  6.136946  ,  0.03897709], dtype=float32)}
done in step count: 56
reward sum = 0.5696012024771592
running average episode reward sum: 0.6281236912996594
{'scaleFactor': 30, 'timeStep': 57, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([11.3467455 , 10.116578  ,  0.55502266], dtype=float32)}
episode index:1611
target Thresh 14.996189875259962
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([3.9145856, 3.9007354, 0.5441385], dtype=float32)}
done in step count: 24
reward sum = 0.7856781408072188
running average episode reward sum: 0.6282214297919098
{'scaleFactor': 30, 'timeStep': 25, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([ 7.219301 , 11.661994 ,  3.4639747], dtype=float32)}
episode index:1612
target Thresh 14.99620887833638
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([5.423406, 8.567502, 6.21179 ], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6284519186761057
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([5.423406, 8.567502, 6.21179 ], dtype=float32)}
episode index:1613
target Thresh 14.996227786634561
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([11.847111 ,  7.1648936,  4.025027 ], dtype=float32)}
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.6286117284363535
{'scaleFactor': 30, 'timeStep': 13, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([ 5.789452 , 10.568695 ,  2.0629382], dtype=float32)}
episode index:1614
target Thresh 14.996246600627213
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([ 9.14184  , 10.188813 ,  1.2991254], dtype=float32)}
done in step count: 74
reward sum = 0.47534004200570695
running average episode reward sum: 0.6285168233673561
{'scaleFactor': 30, 'timeStep': 75, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([ 4.0142627, 11.170703 ,  3.1800642], dtype=float32)}
episode index:1615
target Thresh 14.996265320784682
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([1.8654733, 7.1997128, 1.7093475], dtype=float32)}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.6287223179135397
{'scaleFactor': 30, 'timeStep': 5, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([3.309195  , 7.9781737 , 0.48836622], dtype=float32)}
episode index:1616
target Thresh 14.996283947574977
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([12.008552 ,  9.957886 ,  4.1496387], dtype=float32)}
done in step count: 28
reward sum = 0.7547192872036326
running average episode reward sum: 0.6288002381171823
{'scaleFactor': 30, 'timeStep': 29, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([3.907521 , 7.2672215, 3.144588 ], dtype=float32)}
episode index:1617
target Thresh 14.996302481463767
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([12.03098  ,  8.421921 ,  5.0250216], dtype=float32)}
done in step count: 15
reward sum = 0.8600583546412884
running average episode reward sum: 0.628943166495751
{'scaleFactor': 30, 'timeStep': 16, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([10.994668,  8.602416,  5.720145], dtype=float32)}
episode index:1618
target Thresh 14.996320922914402
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([6.940689 , 9.053422 , 5.1530313], dtype=float32)}
done in step count: 20
reward sum = 0.8179069375972308
running average episode reward sum: 0.6290598828460299
{'scaleFactor': 30, 'timeStep': 21, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([3.692697 , 9.401259 , 2.8261676], dtype=float32)}
episode index:1619
target Thresh 14.99633927238792
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([ 8.923447 , 10.11644  ,  0.5631245], dtype=float32)}
done in step count: 53
reward sum = 0.5870367819374844
running average episode reward sum: 0.6290339426602839
{'scaleFactor': 30, 'timeStep': 54, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([ 4.393587 , 10.786344 ,  2.6732905], dtype=float32)}
episode index:1620
target Thresh 14.996357530343053
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([ 4.804516, 10.07099 ,  4.092768], dtype=float32)}
done in step count: 41
reward sum = 0.6622820409839835
running average episode reward sum: 0.6290544535167452
{'scaleFactor': 30, 'timeStep': 42, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([13.120673 ,  5.8803086,  4.496766 ], dtype=float32)}
episode index:1621
target Thresh 14.996375697236259
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([11.739578 , 10.035239 ,  2.0742474], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6292831499079186
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([11.739578 , 10.035239 ,  2.0742474], dtype=float32)}
episode index:1622
target Thresh 14.996393773521703
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([6.2208166, 9.238125 , 3.659001 ], dtype=float32)}
done in step count: 135
reward sum = 0.25748460676394874
running average episode reward sum: 0.6290540688585384
{'scaleFactor': 30, 'timeStep': 136, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([13.177374 ,  3.6043773,  5.2209325], dtype=float32)}
episode index:1623
target Thresh 14.9964117596513
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([ 4.285551  , 11.169519  ,  0.59083813], dtype=float32)}
done in step count: 14
reward sum = 0.8687458127689782
running average episode reward sum: 0.6292016622969069
{'scaleFactor': 30, 'timeStep': 15, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([13.953765 ,  4.2995534,  4.833774 ], dtype=float32)}
episode index:1624
target Thresh 14.996429656074701
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([12.059058 ,  2.8907056,  6.015576 ], dtype=float32)}
done in step count: 31
reward sum = 0.7323033696543975
running average episode reward sum: 0.6292651095014345
{'scaleFactor': 30, 'timeStep': 32, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([5.6278296, 8.2610445, 3.6390545], dtype=float32)}
episode index:1625
target Thresh 14.996447463239319
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([9.861018, 8.891874, 4.420791], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6294931137391335
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([9.861018, 8.891874, 4.420791], dtype=float32)}
episode index:1626
target Thresh 14.99646518159033
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([ 5.903007 , 10.126667 ,  1.7773371], dtype=float32)}
done in step count: 69
reward sum = 0.4998370298991989
running average episode reward sum: 0.6294134234601907
{'scaleFactor': 30, 'timeStep': 70, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([0.34728253, 8.174435  , 3.7650697 ], dtype=float32)}
episode index:1627
target Thresh 14.996482811570699
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([11.83583 ,  3.872353,  1.405064], dtype=float32)}
done in step count: 107
reward sum = 0.34116606151404244
running average episode reward sum: 0.6292363673410591
{'scaleFactor': 30, 'timeStep': 108, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([0.16459434, 5.6740427 , 3.854715  ], dtype=float32)}
episode index:1628
target Thresh 14.996500353621173
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([ 3.1440105, 10.052348 ,  3.3501806], dtype=float32)}
done in step count: 191
reward sum = 0.14666354163210368
running average episode reward sum: 0.6289401286512439
{'scaleFactor': 30, 'timeStep': 192, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([ 5.120534 , 10.16283  ,  5.4822445], dtype=float32)}
episode index:1629
target Thresh 14.996517808180306
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([2.3912349, 6.915888 , 4.4385915], dtype=float32)}
done in step count: 26
reward sum = 0.7700431458051551
running average episode reward sum: 0.6290266949194365
{'scaleFactor': 30, 'timeStep': 27, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([3.522829 , 7.6064324, 2.0719976], dtype=float32)}
episode index:1630
target Thresh 14.996535175684462
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([11.352958 ,  3.741581 ,  1.5808916], dtype=float32)}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.629241945259768
{'scaleFactor': 30, 'timeStep': 3, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([11.617626 ,  7.377399 ,  1.4063518], dtype=float32)}
episode index:1631
target Thresh 14.996552456567828
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([1.6837636, 3.1241202, 2.9577584], dtype=float32)}
done in step count: 92
reward sum = 0.3966778064220251
running average episode reward sum: 0.6290994427237154
{'scaleFactor': 30, 'timeStep': 93, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([10.967926 ,  7.723559 ,  5.6862035], dtype=float32)}
episode index:1632
target Thresh 14.996569651262432
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([1.6441145, 3.7137065, 2.4512234], dtype=float32)}
done in step count: 15
reward sum = 0.8600583546412884
running average episode reward sum: 0.6292408750029056
{'scaleFactor': 30, 'timeStep': 16, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([4.6154695, 9.857761 , 0.5576991], dtype=float32)}
episode index:1633
target Thresh 14.996586760198136
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([ 8.2318325, 10.011727 ,  2.8499608], dtype=float32)}
done in step count: 48
reward sum = 0.617290140942288
running average episode reward sum: 0.6292335612121709
{'scaleFactor': 30, 'timeStep': 49, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([10.154157 ,  5.0615616,  5.6375837], dtype=float32)}
episode index:1634
target Thresh 14.99660378380267
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([6.9472036 , 9.595777  , 0.08432978], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6294603296762612
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([6.9472036 , 9.595777  , 0.08432978], dtype=float32)}
episode index:1635
target Thresh 14.99662072250162
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([9.989254 , 9.469935 , 3.4362965], dtype=float32)}
done in step count: 22
reward sum = 0.8016305895390459
running average episode reward sum: 0.6295655682214096
{'scaleFactor': 30, 'timeStep': 23, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([1.4326078, 3.709962 , 4.438826 ], dtype=float32)}
episode index:1636
target Thresh 14.996637576718456
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([7.2554164, 9.743802 , 1.1941483], dtype=float32)}
done in step count: 63
reward sum = 0.5309055429551132
running average episode reward sum: 0.6295052994216135
{'scaleFactor': 30, 'timeStep': 64, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([0.42132655, 3.0729055 , 5.6472383 ], dtype=float32)}
episode index:1637
target Thresh 14.996654346874536
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([3.1655993, 9.407892 , 3.7920587], dtype=float32)}
done in step count: 116
reward sum = 0.3116610814491425
running average episode reward sum: 0.6293112553324972
{'scaleFactor': 30, 'timeStep': 117, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([ 8.36159 , 10.224556,  4.431406], dtype=float32)}
episode index:1638
target Thresh 14.996671033389111
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([1.990979 , 7.987361 , 1.8051589], dtype=float32)}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.6295193015464493
{'scaleFactor': 30, 'timeStep': 4, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([2.3782423 , 9.6284    , 0.96777326], dtype=float32)}
episode index:1639
target Thresh 14.99668763667935
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([8.805681 , 9.08137  , 5.7568192], dtype=float32)}
done in step count: 88
reward sum = 0.41294967113388814
running average episode reward sum: 0.6293872468937588
{'scaleFactor': 30, 'timeStep': 89, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([1.9402161, 5.94915  , 3.6654556], dtype=float32)}
episode index:1640
target Thresh 14.996704157160334
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([9.918247 , 5.897113 , 3.7583144], dtype=float32)}
done in step count: 43
reward sum = 0.6491026283684022
running average episode reward sum: 0.6293992611420675
{'scaleFactor': 30, 'timeStep': 44, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([0.2641345, 4.8774   , 3.9614725], dtype=float32)}
episode index:1641
target Thresh 14.996720595245074
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([ 8.822072 , 10.100361 ,  0.6176065], dtype=float32)}
done in step count: 101
reward sum = 0.3623720178604969
running average episode reward sum: 0.6292366379731993
{'scaleFactor': 30, 'timeStep': 102, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([6.4035816, 8.839163 , 3.6731122], dtype=float32)}
episode index:1642
target Thresh 14.996736951344525
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([3.8161707, 8.629662 , 3.9235795], dtype=float32)}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6294266827153951
{'scaleFactor': 30, 'timeStep': 7, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([2.6852984, 5.5563912, 4.651098 ], dtype=float32)}
episode index:1643
target Thresh 14.99675322586759
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([3.006958, 9.779605, 2.772407], dtype=float32)}
done in step count: 21
reward sum = 0.8097278682212584
running average episode reward sum: 0.6295363549693525
{'scaleFactor': 30, 'timeStep': 22, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([6.206667 , 9.203934 , 5.4286203], dtype=float32)}
episode index:1644
target Thresh 14.996769419221131
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([12.139737,  7.871745,  4.06471 ], dtype=float32)}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6297259864553292
{'scaleFactor': 30, 'timeStep': 7, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([10.3198805,  7.345683 ,  5.168656 ], dtype=float32)}
episode index:1645
target Thresh 14.996785531809987
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([2.1325958, 8.854656 , 1.0924691], dtype=float32)}
done in step count: 68
reward sum = 0.5048858887870696
running average episode reward sum: 0.6296501419245466
{'scaleFactor': 30, 'timeStep': 69, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([10.561561 ,  3.5048223,  5.150032 ], dtype=float32)}
episode index:1646
target Thresh 14.99680156403697
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([10.0407   ,  7.2573814,  4.551643 ], dtype=float32)}
done in step count: 167
reward sum = 0.18667127671570335
running average episode reward sum: 0.6293811808649177
{'scaleFactor': 30, 'timeStep': 168, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([1.1005473, 4.1146345, 3.637324 ], dtype=float32)}
episode index:1647
target Thresh 14.996817516302885
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([ 8.170672 , 10.066018 ,  3.0481143], dtype=float32)}
done in step count: 15
reward sum = 0.8600583546412884
running average episode reward sum: 0.6295211548781315
{'scaleFactor': 30, 'timeStep': 16, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([10.847612 ,  3.1948767,  5.375288 ], dtype=float32)}
episode index:1648
target Thresh 14.996833389006543
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([11.837676,  8.977473,  5.679598], dtype=float32)}
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.6296769242637215
{'scaleFactor': 30, 'timeStep': 13, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([7.0505695, 7.514001 , 2.7348735], dtype=float32)}
episode index:1649
target Thresh 14.996849182544763
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([12.133642 ,  1.818733 ,  3.1223106], dtype=float32)}
done in step count: 90
reward sum = 0.4047319726783238
running average episode reward sum: 0.6295405939900334
{'scaleFactor': 30, 'timeStep': 91, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([10.578532 ,  9.939332 ,  2.3784475], dtype=float32)}
episode index:1650
target Thresh 14.99686489731238
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([11.656517 ,  3.9528637,  1.5925281], dtype=float32)}
done in step count: 76
reward sum = 0.46588077516979337
running average episode reward sum: 0.6294414662984402
{'scaleFactor': 30, 'timeStep': 77, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([ 3.655247, 10.209523,  4.647981], dtype=float32)}
episode index:1651
target Thresh 14.996880533702267
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([8.876388  , 9.626723  , 0.16730136], dtype=float32)}
done in step count: 27
reward sum = 0.7623427143471035
running average episode reward sum: 0.6295219149958063
{'scaleFactor': 30, 'timeStep': 28, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([ 4.464038 , 10.403986 ,  3.9139643], dtype=float32)}
episode index:1652
target Thresh 14.996896092105334
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([1.8570611, 6.18623  , 4.553602 ], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6297460396691301
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([1.8570611, 6.18623  , 4.553602 ], dtype=float32)}
episode index:1653
target Thresh 14.996911572910545
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([2.311982 , 2.2135606, 4.6815615], dtype=float32)}
done in step count: 165
reward sum = 0.1904614597650274
running average episode reward sum: 0.6294804504430696
{'scaleFactor': 30, 'timeStep': 166, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([ 9.054707 , 11.033242 ,  0.6331289], dtype=float32)}
episode index:1654
target Thresh 14.996926976504914
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([3.447452 , 7.2355847, 0.6859845], dtype=float32)}
done in step count: 14
reward sum = 0.8687458127689782
running average episode reward sum: 0.6296250216589764
{'scaleFactor': 30, 'timeStep': 15, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([10.742091 ,  7.835314 ,  0.4731049], dtype=float32)}
episode index:1655
target Thresh 14.996942303273537
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([11.596393 ,  3.7625308,  2.329088 ], dtype=float32)}
done in step count: 85
reward sum = 0.4255901233886546
running average episode reward sum: 0.6295018121793446
{'scaleFactor': 30, 'timeStep': 86, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([9.228122 , 7.7448273, 2.6261292], dtype=float32)}
episode index:1656
target Thresh 14.996957553599582
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([ 2.9078612, 10.164275 ,  2.7952738], dtype=float32)}
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.6296568411832895
{'scaleFactor': 30, 'timeStep': 13, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([3.0508876, 9.002365 , 4.2960606], dtype=float32)}
episode index:1657
target Thresh 14.99697272786431
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([1.9280959, 7.907734 , 4.120721 ], dtype=float32)}
done in step count: 125
reward sum = 0.28470777327319546
running average episode reward sum: 0.6294487898757442
{'scaleFactor': 30, 'timeStep': 126, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([11.303364 ,  5.441784 ,  4.8592377], dtype=float32)}
episode index:1658
target Thresh 14.996987826447077
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([11.032309 , 10.0340805,  1.1187062], dtype=float32)}
done in step count: 68
reward sum = 0.5048858887870696
running average episode reward sum: 0.6293737067527251
{'scaleFactor': 30, 'timeStep': 69, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([4.9735827, 8.225491 , 3.7905002], dtype=float32)}
episode index:1659
target Thresh 14.997002849725348
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([12.053137 ,  6.0351534,  5.9897847], dtype=float32)}
done in step count: 46
reward sum = 0.6298236312032323
running average episode reward sum: 0.6293739777915507
{'scaleFactor': 30, 'timeStep': 47, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([10.546318 ,  8.375041 ,  1.8132987], dtype=float32)}
episode index:1660
target Thresh 14.997017798074705
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([12.048718,  8.67225 ,  5.016551], dtype=float32)}
done in step count: 61
reward sum = 0.5416850759668536
running average episode reward sum: 0.6293211849548109
{'scaleFactor': 30, 'timeStep': 62, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([ 9.350601, 10.865364,  2.317487], dtype=float32)}
episode index:1661
target Thresh 14.997032671868858
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([2.3173661, 7.969611 , 5.1710215], dtype=float32)}
done in step count: 211
reward sum = 0.11995712819347787
running average episode reward sum: 0.6290147083863624
{'scaleFactor': 30, 'timeStep': 212, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([6.4059305 , 9.26326   , 0.45433158], dtype=float32)}
episode index:1662
target Thresh 14.997047471479654
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([ 8.78415 , 11.171394,  2.509383], dtype=float32)}
done in step count: 39
reward sum = 0.6757290490602831
running average episode reward sum: 0.629042798789654
{'scaleFactor': 30, 'timeStep': 40, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([ 4.8269687, 10.545363 ,  3.7236927], dtype=float32)}
episode index:1663
target Thresh 14.997062197277083
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([12.188106 ,  5.1024404,  5.8409686], dtype=float32)}
done in step count: 143
reward sum = 0.23759255478829303
running average episode reward sum: 0.6288075522487878
{'scaleFactor': 30, 'timeStep': 144, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([1.5301974, 6.531271 , 4.9639573], dtype=float32)}
episode index:1664
target Thresh 14.997076849629293
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([1.7460594, 6.860965 , 4.316008 ], dtype=float32)}
done in step count: 399
reward sum = 0.0
running average episode reward sum: 0.628429890055245
{'scaleFactor': 30, 'timeStep': 400, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([4.0792847 , 0.07034338, 4.0065775 ], dtype=float32)}
episode index:1665
target Thresh 14.99709142890259
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([11.888927 ,  8.984891 ,  6.1098013], dtype=float32)}
done in step count: 91
reward sum = 0.40068465295154054
running average episode reward sum: 0.6282931882322536
{'scaleFactor': 30, 'timeStep': 92, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([4.6881413, 9.521236 , 5.8711343], dtype=float32)}
episode index:1666
target Thresh 14.997105935461457
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([2.1006985, 9.087903 , 1.1006149], dtype=float32)}
done in step count: 49
reward sum = 0.611117239532865
running average episode reward sum: 0.6282828847237356
{'scaleFactor': 30, 'timeStep': 50, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([9.565172  , 7.470148  , 0.81343144], dtype=float32)}
episode index:1667
target Thresh 14.997120369668561
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([ 9.721248, 10.063807,  4.873473], dtype=float32)}
done in step count: 40
reward sum = 0.6689717585696803
running average episode reward sum: 0.6283072785329956
{'scaleFactor': 30, 'timeStep': 41, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([3.3080783, 8.826102 , 3.6881692], dtype=float32)}
episode index:1668
target Thresh 14.997134731884756
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([ 7.859495 , 10.021605 ,  0.8054939], dtype=float32)}
done in step count: 67
reward sum = 0.5099857462495653
running average episode reward sum: 0.6282363848647612
{'scaleFactor': 30, 'timeStep': 68, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([10.381039 ,  4.1483107,  4.174702 ], dtype=float32)}
episode index:1669
target Thresh 14.9971490224691
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([11.9072075,  5.191154 ,  4.6369696], dtype=float32)}
done in step count: 82
reward sum = 0.43861750180991077
running average episode reward sum: 0.628122840623411
{'scaleFactor': 30, 'timeStep': 83, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([8.939586 , 8.1134405, 2.6572983], dtype=float32)}
episode index:1670
target Thresh 14.997163241778857
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([2.6351032 , 8.871266  , 0.10328215], dtype=float32)}
done in step count: 15
reward sum = 0.8600583546412884
running average episode reward sum: 0.6282616410507107
{'scaleFactor': 30, 'timeStep': 16, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([3.5419445, 5.9563346, 3.8412201], dtype=float32)}
episode index:1671
target Thresh 14.997177390169508
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([2.1877859, 7.1053944, 4.558153 ], dtype=float32)}
done in step count: 48
reward sum = 0.617290140942288
running average episode reward sum: 0.6282550791487319
{'scaleFactor': 30, 'timeStep': 49, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([8.287842 , 9.80888  , 5.6775913], dtype=float32)}
episode index:1672
target Thresh 14.997191467994769
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([ 8.067178  , 10.239991  ,  0.20357652], dtype=float32)}
done in step count: 58
reward sum = 0.5582661385478637
running average episode reward sum: 0.6282132447550673
{'scaleFactor': 30, 'timeStep': 59, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([3.1377134, 8.100617 , 2.4418254], dtype=float32)}
episode index:1673
target Thresh 14.997205475606584
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([1.7792923, 4.9390945, 5.4740815], dtype=float32)}
done in step count: 79
reward sum = 0.45204365026647536
running average episode reward sum: 0.6281080060486823
{'scaleFactor': 30, 'timeStep': 80, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([9.0602255 , 9.745679  , 0.33313715], dtype=float32)}
episode index:1674
target Thresh 14.997219413355143
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([11.080757,  8.858376,  4.481203], dtype=float32)}
done in step count: 108
reward sum = 0.337754400898902
running average episode reward sum: 0.6279346606127719
{'scaleFactor': 30, 'timeStep': 109, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([ 4.387116 , 10.767505 ,  3.3152287], dtype=float32)}
episode index:1675
target Thresh 14.997233281588892
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([12.115479 ,  5.871318 ,  5.6503854], dtype=float32)}
done in step count: 399
reward sum = 0.0
running average episode reward sum: 0.6275599979274421
{'scaleFactor': 30, 'timeStep': 400, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([11.711778  , -0.45092446,  0.2674649 ], dtype=float32)}
episode index:1676
target Thresh 14.997247080654533
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([1.904026, 6.067964, 4.859029], dtype=float32)}
done in step count: 18
reward sum = 0.8345137614500875
running average episode reward sum: 0.6276834050613256
{'scaleFactor': 30, 'timeStep': 19, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([7.7588763, 8.028009 , 0.4273376], dtype=float32)}
episode index:1677
target Thresh 14.997260810897052
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([12.216044 ,  8.149265 ,  4.9185934], dtype=float32)}
done in step count: 75
reward sum = 0.4705866415856499
running average episode reward sum: 0.6275897836289802
{'scaleFactor': 30, 'timeStep': 76, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([11.482669,  7.103554,  4.517046], dtype=float32)}
episode index:1678
target Thresh 14.997274472659697
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([11.893486 ,  6.9667273,  0.1632175], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.627805632477325
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([11.872843 ,  7.1274357,  6.234486 ], dtype=float32)}
episode index:1679
target Thresh 14.997288066284018
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([12.103247 ,  2.9569552,  3.4254148], dtype=float32)}
done in step count: 26
reward sum = 0.7700431458051551
running average episode reward sum: 0.6278902976638298
{'scaleFactor': 30, 'timeStep': 27, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([ 9.161087  , 10.053758  ,  0.31960058], dtype=float32)}
episode index:1680
target Thresh 14.997301592109855
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([4.1000104, 9.26014  , 1.1908048], dtype=float32)}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.6280882189680155
{'scaleFactor': 30, 'timeStep': 5, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([3.7555082, 9.179521 , 1.8916894], dtype=float32)}
episode index:1681
target Thresh 14.997315050475354
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([11.776271 ,  4.2323174,  4.8469925], dtype=float32)}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.6282524840429504
{'scaleFactor': 30, 'timeStep': 11, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([9.911016, 7.019673, 3.351247], dtype=float32)}
episode index:1682
target Thresh 14.997328441716974
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([ 8.909523 , 10.245903 ,  4.0891066], dtype=float32)}
done in step count: 53
reward sum = 0.5870367819374844
running average episode reward sum: 0.6282279946180512
{'scaleFactor': 30, 'timeStep': 54, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([3.5843163, 8.808092 , 0.8778794], dtype=float32)}
episode index:1683
target Thresh 14.997341766169498
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([2.0903122, 2.7177994, 0.2462241], dtype=float32)}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.6284028857699572
{'scaleFactor': 30, 'timeStep': 9, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([6.5409813 , 8.133077  , 0.71741474], dtype=float32)}
episode index:1684
target Thresh 14.997355024166037
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([12.07715 ,  4.896724,  4.364206], dtype=float32)}
done in step count: 149
reward sum = 0.2236886739786474
running average episode reward sum: 0.6281626992941166
{'scaleFactor': 30, 'timeStep': 150, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([3.61549 , 9.176861, 4.067812], dtype=float32)}
episode index:1685
target Thresh 14.997368216038046
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([11.864081  ,  6.053567  ,  0.21402234], dtype=float32)}
done in step count: 92
reward sum = 0.3966778064220251
running average episode reward sum: 0.6280254010183919
{'scaleFactor': 30, 'timeStep': 93, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([4.344757 , 9.848999 , 3.2008805], dtype=float32)}
episode index:1686
target Thresh 14.997381342115316
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([12.211717 ,  7.9123983,  0.4003575], dtype=float32)}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6282112070340307
{'scaleFactor': 30, 'timeStep': 7, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([10.82845  ,  9.267921 ,  2.4992936], dtype=float32)}
episode index:1687
target Thresh 14.997394402726002
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([9.897641 , 7.459994 , 3.2188435], dtype=float32)}
done in step count: 70
reward sum = 0.49483865960020695
running average episode reward sum: 0.6281321948613803
{'scaleFactor': 30, 'timeStep': 71, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([3.7791963, 8.905597 , 0.4938895], dtype=float32)}
episode index:1688
target Thresh 14.997407398196621
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([12.038247,  9.859328,  1.026842], dtype=float32)}
done in step count: 47
reward sum = 0.6235253948912
running average episode reward sum: 0.6281294673303145
{'scaleFactor': 30, 'timeStep': 48, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([ 6.1444893, 10.227049 ,  2.4750166], dtype=float32)}
episode index:1689
target Thresh 14.997420328852062
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([7.07374 , 8.954388, 4.650951], dtype=float32)}
done in step count: 73
reward sum = 0.4801414565714212
running average episode reward sum: 0.6280419004600428
{'scaleFactor': 30, 'timeStep': 74, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([8.311756, 9.826546, 2.065106], dtype=float32)}
episode index:1690
target Thresh 14.997433195015587
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([12.124225 ,  8.09075  ,  4.4470696], dtype=float32)}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.6282500956697058
{'scaleFactor': 30, 'timeStep': 3, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([10.615651 ,  7.151044 ,  3.6119804], dtype=float32)}
episode index:1691
target Thresh 14.997445997008857
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([9.944374 , 9.030761 , 3.1212578], dtype=float32)}
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.628402657594083
{'scaleFactor': 30, 'timeStep': 13, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([11.736721 ,  3.6686285,  5.6720767], dtype=float32)}
episode index:1692
target Thresh 14.997458735151916
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([1.9231341, 5.7584023, 4.290401 ], dtype=float32)}
done in step count: 24
reward sum = 0.7856781408072188
running average episode reward sum: 0.6284955551033643
{'scaleFactor': 30, 'timeStep': 25, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([1.3569434, 9.723503 , 1.0701671], dtype=float32)}
episode index:1693
target Thresh 14.997471409763223
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([6.105696, 8.763063, 5.753311], dtype=float32)}
done in step count: 17
reward sum = 0.8429431933839268
running average episode reward sum: 0.6286221475698817
{'scaleFactor': 30, 'timeStep': 18, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([2.3508053, 6.493349 , 2.5186028], dtype=float32)}
episode index:1694
target Thresh 14.997484021159643
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([6.641107 , 7.78286  , 3.3711302], dtype=float32)}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.6288180023559762
{'scaleFactor': 30, 'timeStep': 5, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([1.0439062, 6.2617884, 2.9567308], dtype=float32)}
episode index:1695
target Thresh 14.997496569656459
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([9.054119, 9.96221 , 6.177257], dtype=float32)}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6290079622896696
{'scaleFactor': 30, 'timeStep': 6, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([ 8.836368  , 10.427705  ,  0.51592153], dtype=float32)}
episode index:1696
target Thresh 14.997509055567388
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([ 1.938242 , 10.269119 ,  1.6397122], dtype=float32)}
done in step count: 34
reward sum = 0.7105532272722921
running average episode reward sum: 0.6290560148913094
{'scaleFactor': 30, 'timeStep': 35, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([2.7053862, 3.97249  , 4.8675456], dtype=float32)}
episode index:1697
target Thresh 14.997521479204575
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([1.8026094, 4.861609 , 1.5054151], dtype=float32)}
done in step count: 53
reward sum = 0.5870367819374844
running average episode reward sum: 0.6290312685821493
{'scaleFactor': 30, 'timeStep': 54, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([ 3.1620302, 10.755955 ,  3.3384297], dtype=float32)}
episode index:1698
target Thresh 14.997533840878614
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([9.152829 , 9.157053 , 1.0026094], dtype=float32)}
done in step count: 63
reward sum = 0.5309055429551132
running average episode reward sum: 0.6289735135935519
{'scaleFactor': 30, 'timeStep': 64, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([2.4703798, 7.568864 , 3.6233094], dtype=float32)}
episode index:1699
target Thresh 14.997546140898546
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([ 9.956729 , 10.228343 ,  0.7224951], dtype=float32)}
done in step count: 30
reward sum = 0.7397003733882802
running average episode reward sum: 0.6290386470404901
{'scaleFactor': 30, 'timeStep': 31, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([11.752929 ,  4.6494193,  0.067537 ], dtype=float32)}
episode index:1700
target Thresh 14.997558379571872
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([11.516951 ,  7.7769175,  1.3871001], dtype=float32)}
done in step count: 48
reward sum = 0.617290140942288
running average episode reward sum: 0.6290317402173871
{'scaleFactor': 30, 'timeStep': 49, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([4.313109, 8.518088, 4.554063], dtype=float32)}
episode index:1701
target Thresh 14.997570557204561
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([5.2392216, 9.344513 , 2.8411467], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.6292438249763662
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([ 3.321649 , 10.04346  ,  2.7379518], dtype=float32)}
episode index:1702
target Thresh 14.997582674101054
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([1.941949 , 3.893729 , 5.9016533], dtype=float32)}
done in step count: 40
reward sum = 0.6689717585696803
running average episode reward sum: 0.629267153181647
{'scaleFactor': 30, 'timeStep': 41, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([6.155632 , 9.000491 , 0.5374393], dtype=float32)}
episode index:1703
target Thresh 14.997594730564273
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([ 3.1047573, 10.079355 ,  1.4992206], dtype=float32)}
done in step count: 75
reward sum = 0.4705866415856499
running average episode reward sum: 0.6291740308156869
{'scaleFactor': 30, 'timeStep': 76, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([8.508929, 8.845676, 5.37994 ], dtype=float32)}
episode index:1704
target Thresh 14.99760672689563
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([2.4735026, 6.146512 , 1.2362111], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.6293856589501059
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([3.0672073, 7.909338 , 1.1350454], dtype=float32)}
episode index:1705
target Thresh 14.997618663395036
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([11.890762 ,  2.8880606,  3.6410713], dtype=float32)}
done in step count: 35
reward sum = 0.7034476949995692
running average episode reward sum: 0.6294290716324327
{'scaleFactor': 30, 'timeStep': 36, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([11.897245 ,  7.086636 ,  0.8497587], dtype=float32)}
episode index:1706
target Thresh 14.997630540360904
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([11.358127,  8.896667,  5.248597], dtype=float32)}
done in step count: 92
reward sum = 0.3966778064220251
running average episode reward sum: 0.6292927205690405
{'scaleFactor': 30, 'timeStep': 93, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([3.8781595, 9.874424 , 3.4327648], dtype=float32)}
episode index:1707
target Thresh 14.997642358090154
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([1.9989824, 3.9531353, 3.8939896], dtype=float32)}
done in step count: 60
reward sum = 0.5471566423907612
running average episode reward sum: 0.6292446315302944
{'scaleFactor': 30, 'timeStep': 61, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([ 7.0404844 , 10.210561  ,  0.46069688], dtype=float32)}
episode index:1708
target Thresh 14.997654116878236
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([ 1.9431477, 10.234503 ,  4.6064696], dtype=float32)}
done in step count: 120
reward sum = 0.2993803913123313
running average episode reward sum: 0.6290516155910212
{'scaleFactor': 30, 'timeStep': 121, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([8.614419 , 9.039909 , 0.1581696], dtype=float32)}
episode index:1709
target Thresh 14.997665817019117
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([7.646728 , 7.855426 , 5.1539264], dtype=float32)}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6292288166040715
{'scaleFactor': 30, 'timeStep': 8, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([12.746969 ,  4.6993027,  6.093153 ], dtype=float32)}
episode index:1710
target Thresh 14.997677458805303
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([ 9.222547 , 10.239855 ,  2.6394944], dtype=float32)}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.6294281562787623
{'scaleFactor': 30, 'timeStep': 4, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([ 3.5189846, 10.263006 ,  3.426358 ], dtype=float32)}
episode index:1711
target Thresh 14.997689042527837
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([4.030529 , 8.386203 , 3.6262672], dtype=float32)}
done in step count: 42
reward sum = 0.6556592205741436
running average episode reward sum: 0.6294434781621123
{'scaleFactor': 30, 'timeStep': 43, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([11.711077 ,  5.493786 ,  5.0585623], dtype=float32)}
episode index:1712
target Thresh 14.997700568476315
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([3.6232285 , 7.0907564 , 0.48126143], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6296597983733428
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([3.6232285 , 7.0907564 , 0.48126143], dtype=float32)}
episode index:1713
target Thresh 14.997712036938884
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([1.9927694, 6.7530603, 2.2283137], dtype=float32)}
done in step count: 14
reward sum = 0.8687458127689782
running average episode reward sum: 0.629799288463422
{'scaleFactor': 30, 'timeStep': 15, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([ 7.6062374, 10.75441  ,  5.8378596], dtype=float32)}
episode index:1714
target Thresh 14.997723448202258
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([6.9985538, 9.976973 , 2.0666068], dtype=float32)}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.6299593950444979
{'scaleFactor': 30, 'timeStep': 11, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([ 4.67242  , 10.613658 ,  2.5573874], dtype=float32)}
episode index:1715
target Thresh 14.997734802551717
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([9.487696, 8.33007 , 4.062601], dtype=float32)}
done in step count: 399
reward sum = 0.0
running average episode reward sum: 0.6295922858399265
{'scaleFactor': 30, 'timeStep': 400, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([4.464883 , 7.913998 , 3.1729517], dtype=float32)}
episode index:1716
target Thresh 14.997746100271124
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([2.0223117 , 5.0932293 , 0.06572741], dtype=float32)}
done in step count: 97
reward sum = 0.37723664692350417
running average episode reward sum: 0.6294453110939064
{'scaleFactor': 30, 'timeStep': 98, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([3.1353483, 8.118566 , 2.516131 ], dtype=float32)}
episode index:1717
target Thresh 14.997757341642918
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([11.772104 ,  3.151066 ,  3.8392162], dtype=float32)}
done in step count: 51
reward sum = 0.598956006466161
running average episode reward sum: 0.6294275641179881
{'scaleFactor': 30, 'timeStep': 52, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([3.1395612, 8.099506 , 3.258127 ], dtype=float32)}
episode index:1718
target Thresh 14.997768526948139
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([12.07334 ,  6.88314 ,  5.631833], dtype=float32)}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.6296202159189666
{'scaleFactor': 30, 'timeStep': 5, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([11.957283 ,  7.0848393,  5.9276533], dtype=float32)}
episode index:1719
target Thresh 14.997779656466417
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([4.007464, 9.954638, 6.22159 ], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6298355530027346
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([4.007464, 9.954638, 6.22159 ], dtype=float32)}
episode index:1720
target Thresh 14.99779073047599
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([1.9661127, 7.693584 , 3.0771236], dtype=float32)}
done in step count: 114
reward sum = 0.3179890638191435
running average episode reward sum: 0.6296543522536447
{'scaleFactor': 30, 'timeStep': 115, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([ 5.682929, 10.425766,  5.442778], dtype=float32)}
episode index:1721
target Thresh 14.997801749253709
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([4.1143155, 8.982597 , 4.7438   ], dtype=float32)}
done in step count: 22
reward sum = 0.8016305895390459
running average episode reward sum: 0.6297542223101403
{'scaleFactor': 30, 'timeStep': 23, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([10.141985,  8.599532,  4.631943], dtype=float32)}
episode index:1722
target Thresh 14.997812713075046
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([10.977593 ,  9.072536 ,  0.9037556], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6299691066848878
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([10.977593 ,  9.072536 ,  0.9037556], dtype=float32)}
episode index:1723
target Thresh 14.997823622214096
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([12.000485 , 10.006397 ,  1.6394582], dtype=float32)}
done in step count: 101
reward sum = 0.3623720178604969
running average episode reward sum: 0.6298138879558713
{'scaleFactor': 30, 'timeStep': 102, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([0.81225723, 3.635655  , 4.6819024 ], dtype=float32)}
episode index:1724
target Thresh 14.997834476943588
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([2.0974255, 3.9982672, 3.8020678], dtype=float32)}
done in step count: 72
reward sum = 0.48499137027416284
running average episode reward sum: 0.6297299328731573
{'scaleFactor': 30, 'timeStep': 73, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([13.999091 ,  5.6341085,  5.67255  ], dtype=float32)}
episode index:1725
target Thresh 14.997845277534891
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([ 3.170476 , 10.298098 ,  3.1069036], dtype=float32)}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.6298943519430359
{'scaleFactor': 30, 'timeStep': 10, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([0.13210201, 9.462664  , 3.7206156 ], dtype=float32)}
episode index:1726
target Thresh 14.997856024258018
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([2.0602777, 9.881874 , 3.5914314], dtype=float32)}
done in step count: 14
reward sum = 0.8687458127689782
running average episode reward sum: 0.6300326562052397
{'scaleFactor': 30, 'timeStep': 15, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([0.2665087, 8.943575 , 3.7925406], dtype=float32)}
episode index:1727
target Thresh 14.997866717381642
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([11.924655 ,  2.878077 ,  1.8348486], dtype=float32)}
done in step count: 78
reward sum = 0.4566097477439145
running average episode reward sum: 0.6299322957258061
{'scaleFactor': 30, 'timeStep': 79, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([0.17343283, 4.530019  , 5.072113  ], dtype=float32)}
episode index:1728
target Thresh 14.99787735717309
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([11.525881 ,  5.8873796,  1.9029396], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.6301405477236512
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([10.443076 ,  7.4948745,  1.9124562], dtype=float32)}
episode index:1729
target Thresh 14.997887943898354
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([11.0219145,  5.759185 ,  2.364878 ], dtype=float32)}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.6303428364243889
{'scaleFactor': 30, 'timeStep': 3, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([7.754706 , 7.72943  , 2.7866004], dtype=float32)}
episode index:1730
target Thresh 14.997898477822108
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([10.715478, 10.007   ,  4.859955], dtype=float32)}
done in step count: 116
reward sum = 0.3116610814491425
running average episode reward sum: 0.6301587337352063
{'scaleFactor': 30, 'timeStep': 117, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([6.438987, 8.081209, 4.415387], dtype=float32)}
episode index:1731
target Thresh 14.997908959207697
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([3.2319486 , 6.81051   , 0.55829823], dtype=float32)}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.6303551195702322
{'scaleFactor': 30, 'timeStep': 4, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([8.677805, 9.165555, 6.131015], dtype=float32)}
episode index:1732
target Thresh 14.997919388317158
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([ 4.307818, 10.087226,  4.621926], dtype=float32)}
done in step count: 53
reward sum = 0.5870367819374844
running average episode reward sum: 0.6303301234146449
{'scaleFactor': 30, 'timeStep': 54, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([10.135156  , 10.287631  ,  0.94032675], dtype=float32)}
episode index:1733
target Thresh 14.997929765411218
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([10.817408  ,  9.253952  ,  0.78427976], dtype=float32)}
done in step count: 377
reward sum = 0.022618737647500813
running average episode reward sum: 0.6299796554874435
{'scaleFactor': 30, 'timeStep': 378, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([0.07595331, 5.4099083 , 2.452827  ], dtype=float32)}
episode index:1734
target Thresh 14.997940090749305
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([1.9462435, 9.9085865, 2.3197067], dtype=float32)}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6301591946770191
{'scaleFactor': 30, 'timeStep': 7, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([2.1985025, 9.830704 , 1.2978625], dtype=float32)}
episode index:1735
target Thresh 14.997950364589554
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([11.879381 ,  3.1830504,  4.74041  ], dtype=float32)}
done in step count: 19
reward sum = 0.8261686238355866
running average episode reward sum: 0.6302721033343686
{'scaleFactor': 30, 'timeStep': 20, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([9.931936 , 7.215252 , 1.8130155], dtype=float32)}
episode index:1736
target Thresh 14.997960587188812
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([3.8356557 , 5.7206535 , 0.06211716], dtype=float32)}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.6304404813373008
{'scaleFactor': 30, 'timeStep': 9, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([5.2254086, 7.5392737, 0.8144611], dtype=float32)}
episode index:1737
target Thresh 14.997970758802643
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([7.9526596 , 8.903757  , 0.03656739], dtype=float32)}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.6306360270902713
{'scaleFactor': 30, 'timeStep': 4, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([10.717684 ,  6.1880713,  5.568814 ], dtype=float32)}
episode index:1738
target Thresh 14.997980879685336
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([4.774242 , 9.852591 , 2.0603695], dtype=float32)}
done in step count: 94
reward sum = 0.3887839180742268
running average episode reward sum: 0.6304969516969327
{'scaleFactor': 30, 'timeStep': 95, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([7.174016, 7.060263, 4.252128], dtype=float32)}
episode index:1739
target Thresh 14.99799095008992
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([ 9.8143215, 10.161752 ,  4.274421 ], dtype=float32)}
done in step count: 100
reward sum = 0.3660323412732292
running average episode reward sum: 0.6303449605415168
{'scaleFactor': 30, 'timeStep': 101, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([0.15089995, 7.2149057 , 1.2773712 ], dtype=float32)}
episode index:1740
target Thresh 14.998000970268148
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([3.8657684 , 6.2362733 , 0.04244917], dtype=float32)}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6305291334819868
{'scaleFactor': 30, 'timeStep': 6, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([8.943586  , 9.3814945 , 0.93168026], dtype=float32)}
episode index:1741
target Thresh 14.998010940470529
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([5.256525 , 8.897603 , 1.9481308], dtype=float32)}
done in step count: 19
reward sum = 0.8261686238355866
running average episode reward sum: 0.6306414408817306
{'scaleFactor': 30, 'timeStep': 20, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([3.3936975, 5.824889 , 3.517928 ], dtype=float32)}
episode index:1742
target Thresh 14.99802086094632
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([1.9513632, 4.8105154, 2.826512 ], dtype=float32)}
done in step count: 36
reward sum = 0.6964132180495735
running average episode reward sum: 0.6306791756936456
{'scaleFactor': 30, 'timeStep': 37, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([5.3810062, 7.1038074, 3.5462465], dtype=float32)}
episode index:1743
target Thresh 14.998030731943532
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([2.0604866, 8.104885 , 6.0762024], dtype=float32)}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6308519888657863
{'scaleFactor': 30, 'timeStep': 8, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([4.0942297, 7.9540744, 5.876133 ], dtype=float32)}
episode index:1744
target Thresh 14.998040553708938
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([12.288276 ,  6.848804 ,  0.4605444], dtype=float32)}
done in step count: 39
reward sum = 0.6757290490602831
running average episode reward sum: 0.6308777063787917
{'scaleFactor': 30, 'timeStep': 40, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([3.8966017, 7.6025295, 3.0410047], dtype=float32)}
episode index:1745
target Thresh 14.998050326488086
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([ 8.0535755, 10.008538 ,  0.9770257], dtype=float32)}
done in step count: 67
reward sum = 0.5099857462495653
running average episode reward sum: 0.6308084669972744
{'scaleFactor': 30, 'timeStep': 68, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([5.132451 , 9.656873 , 3.3605797], dtype=float32)}
episode index:1746
target Thresh 14.998060050525295
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([10.105594  ,  9.957571  ,  0.40908134], dtype=float32)}
done in step count: 143
reward sum = 0.23759255478829303
running average episode reward sum: 0.6305833863377387
{'scaleFactor': 30, 'timeStep': 144, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([12.320747 ,  5.833675 ,  4.3694954], dtype=float32)}
episode index:1747
target Thresh 14.998069726063665
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([1.8770194 , 1.7399755 , 0.09581488], dtype=float32)}
done in step count: 18
reward sum = 0.8345137614500875
running average episode reward sum: 0.6307000513120593
{'scaleFactor': 30, 'timeStep': 19, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([3.5805001, 9.144314 , 1.0046434], dtype=float32)}
episode index:1748
target Thresh 14.998079353345085
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([2.051826  , 9.793063  , 0.25884467], dtype=float32)}
done in step count: 62
reward sum = 0.536268225207185
running average episode reward sum: 0.6306460594160588
{'scaleFactor': 30, 'timeStep': 63, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([10.04259  ,  8.024751 ,  0.9961493], dtype=float32)}
episode index:1749
target Thresh 14.998088932610239
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([1.8651743, 4.092456 , 4.969941 ], dtype=float32)}
done in step count: 34
reward sum = 0.7105532272722921
running average episode reward sum: 0.6306917206548338
{'scaleFactor': 30, 'timeStep': 35, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([10.377146 ,  8.805581 ,  1.0656745], dtype=float32)}
episode index:1750
target Thresh 14.99809846409861
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([10.007898 ,  8.723258 ,  0.3100121], dtype=float32)}
done in step count: 45
reward sum = 0.6361854860638709
running average episode reward sum: 0.6306948581564951
{'scaleFactor': 30, 'timeStep': 46, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([12.311561 ,  3.2805693,  5.966878 ], dtype=float32)}
episode index:1751
target Thresh 14.998107948048485
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([1.8894199, 8.873592 , 0.663739 ], dtype=float32)}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.630883157900698
{'scaleFactor': 30, 'timeStep': 5, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([8.175413 , 9.841967 , 6.0486274], dtype=float32)}
episode index:1752
target Thresh 14.998117384696961
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([11.069571 ,  9.102512 ,  0.7275059], dtype=float32)}
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.6310340164839028
{'scaleFactor': 30, 'timeStep': 12, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([11.0188465,  6.5188527,  4.865186 ], dtype=float32)}
episode index:1753
target Thresh 14.998126774279957
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([11.21493 , 10.033966,  4.138795], dtype=float32)}
done in step count: 51
reward sum = 0.598956006466161
running average episode reward sum: 0.631015727994725
{'scaleFactor': 30, 'timeStep': 52, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([10.114746 ,  7.518621 ,  4.1142554], dtype=float32)}
episode index:1754
target Thresh 14.998136117032212
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([ 6.199084  , 10.000402  ,  0.76134014], dtype=float32)}
done in step count: 16
reward sum = 0.8514577710948755
running average episode reward sum: 0.6311413359964915
{'scaleFactor': 30, 'timeStep': 17, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([10.566895,  6.549552,  4.714052], dtype=float32)}
episode index:1755
target Thresh 14.998145413187299
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([ 2.1696668, 10.735304 ,  3.0465674], dtype=float32)}
done in step count: 20
reward sum = 0.8179069375972308
running average episode reward sum: 0.6312476945395442
{'scaleFactor': 30, 'timeStep': 21, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([ 8.760075 , 11.990383 ,  6.2277017], dtype=float32)}
episode index:1756
target Thresh 14.998154662977615
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([6.8807664, 8.188196 , 5.9662857], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6314575706382696
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([6.8807664, 8.188196 , 5.9662857], dtype=float32)}
episode index:1757
target Thresh 14.99816386663441
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([6.1897435, 9.073474 , 3.2459288], dtype=float32)}
done in step count: 41
reward sum = 0.6622820409839835
running average episode reward sum: 0.6314751044666801
{'scaleFactor': 30, 'timeStep': 42, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([3.6822085, 3.1026905, 2.1127934], dtype=float32)}
episode index:1758
target Thresh 14.998173024387777
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([4.901102 , 8.980181 , 0.4202435], dtype=float32)}
done in step count: 29
reward sum = 0.7471720943315961
running average episode reward sum: 0.6315408787644997
{'scaleFactor': 30, 'timeStep': 30, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([3.9861424, 7.198988 , 1.0308354], dtype=float32)}
episode index:1759
target Thresh 14.998182136466657
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([12.177318 ,  6.9840937,  3.4927042], dtype=float32)}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.6317389237197472
{'scaleFactor': 30, 'timeStep': 3, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([10.300688 ,  8.385834 ,  2.4059515], dtype=float32)}
episode index:1760
target Thresh 14.998191203098854
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([12.021043 ,  6.3019786,  5.1468215], dtype=float32)}
done in step count: 16
reward sum = 0.8514577710948755
running average episode reward sum: 0.6318636930822543
{'scaleFactor': 30, 'timeStep': 17, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([12.010416 ,  7.0365543,  5.005423 ], dtype=float32)}
episode index:1761
target Thresh 14.998200224511034
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([3.021623 , 9.855821 , 4.0742474], dtype=float32)}
done in step count: 66
reward sum = 0.5151371174238033
running average episode reward sum: 0.6317974464445367
{'scaleFactor': 30, 'timeStep': 67, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([6.0873117, 7.67267  , 5.5995665], dtype=float32)}
episode index:1762
target Thresh 14.998209200928736
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([0.38396668, 2.4929764 , 3.0159855 ], dtype=float32)}
done in step count: 210
reward sum = 0.12116881635704835
running average episode reward sum: 0.6315078102391554
{'scaleFactor': 30, 'timeStep': 211, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([11.3634615,  4.7337737,  4.9821386], dtype=float32)}
episode index:1763
target Thresh 14.998218132576364
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([8.174803 , 9.67971  , 1.3830601], dtype=float32)}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.6316676795346454
{'scaleFactor': 30, 'timeStep': 10, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([ 9.116684 , 11.509563 ,  1.6089838], dtype=float32)}
episode index:1764
target Thresh 14.998227019677216
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([9.202784 , 8.814628 , 4.9981174], dtype=float32)}
done in step count: 125
reward sum = 0.28470777327319546
running average episode reward sum: 0.6314711016840723
{'scaleFactor': 30, 'timeStep': 126, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([8.955738 , 7.853274 , 5.7830763], dtype=float32)}
episode index:1765
target Thresh 14.998235862453466
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([ 9.82526 , 10.218646,  6.009637], dtype=float32)}
done in step count: 90
reward sum = 0.4047319726783238
running average episode reward sum: 0.6313427103312944
{'scaleFactor': 30, 'timeStep': 91, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([ 2.626133 , 10.636897 ,  2.9735472], dtype=float32)}
episode index:1766
target Thresh 14.998244661126186
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([6.6440077, 7.5601516, 3.9270005], dtype=float32)}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.6315400828777962
{'scaleFactor': 30, 'timeStep': 3, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([4.6201897, 7.3638372, 3.332221 ], dtype=float32)}
episode index:1767
target Thresh 14.998253415915345
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([6.9660892, 9.060395 , 5.613372 ], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6317484878082952
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([6.9660892, 9.060395 , 5.613372 ], dtype=float32)}
episode index:1768
target Thresh 14.998262127039808
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([11.993824 ,  7.945251 ,  4.3852773], dtype=float32)}
done in step count: 54
reward sum = 0.5811664141181095
running average episode reward sum: 0.6317198942109576
{'scaleFactor': 30, 'timeStep': 55, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([3.6497998, 9.924662 , 3.431337 ], dtype=float32)}
episode index:1769
target Thresh 14.998270794717357
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([1.8779776, 3.1191685, 2.5783236], dtype=float32)}
done in step count: 191
reward sum = 0.14666354163210368
running average episode reward sum: 0.6314458510739074
{'scaleFactor': 30, 'timeStep': 192, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([9.515804 , 9.600142 , 2.0788648], dtype=float32)}
episode index:1770
target Thresh 14.998279419164685
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([11.861018 ,  5.2514815,  4.5615387], dtype=float32)}
done in step count: 134
reward sum = 0.26008546137772603
running average episode reward sum: 0.6312361614128705
{'scaleFactor': 30, 'timeStep': 135, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([12.243965 ,  9.789953 ,  2.2016275], dtype=float32)}
episode index:1771
target Thresh 14.9982880005974
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([6.5491657, 7.001184 , 4.5867844], dtype=float32)}
done in step count: 150
reward sum = 0.22145178723886091
running average episode reward sum: 0.6310049061227047
{'scaleFactor': 30, 'timeStep': 151, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([2.5164886 , 0.15821266, 3.1464381 ], dtype=float32)}
episode index:1772
target Thresh 14.998296539230044
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([ 9.69967  , 10.045967 ,  2.8302438], dtype=float32)}
done in step count: 17
reward sum = 0.8429431933839268
running average episode reward sum: 0.6311244426637431
{'scaleFactor': 30, 'timeStep': 18, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([4.866412 , 8.008734 , 5.2939725], dtype=float32)}
episode index:1773
target Thresh 14.99830503527608
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([11.941746 ,  8.95863  ,  5.7646995], dtype=float32)}
done in step count: 72
reward sum = 0.48499137027416284
running average episode reward sum: 0.6310420677638618
{'scaleFactor': 30, 'timeStep': 73, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([3.1737528, 9.674216 , 4.2253532], dtype=float32)}
episode index:1774
target Thresh 14.998313488947908
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([11.866961 ,  8.831357 ,  6.0398197], dtype=float32)}
done in step count: 262
reward sum = 0.07184904244991483
running average episode reward sum: 0.6307270294397412
{'scaleFactor': 30, 'timeStep': 263, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([1.824597, 7.030747, 3.868331], dtype=float32)}
episode index:1775
target Thresh 14.99832190045687
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([12.090875  ,  4.0448785 ,  0.49912328], dtype=float32)}
done in step count: 17
reward sum = 0.8429431933839268
running average episode reward sum: 0.6308465205230431
{'scaleFactor': 30, 'timeStep': 18, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([13.762101 ,  6.4198427,  2.0602293], dtype=float32)}
episode index:1776
target Thresh 14.998330270013259
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([3.042205 , 5.086879 , 5.3135734], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.6310486327793611
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([3.4841702, 3.2416174, 4.9133124], dtype=float32)}
episode index:1777
target Thresh 14.998338597826312
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([9.890043 , 9.881445 , 3.0240579], dtype=float32)}
done in step count: 39
reward sum = 0.6757290490602831
running average episode reward sum: 0.6310737623723199
{'scaleFactor': 30, 'timeStep': 40, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([ 5.8564625, 10.191755 ,  3.1608775], dtype=float32)}
episode index:1778
target Thresh 14.99834688410422
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([6.9626083, 9.615795 , 6.0750604], dtype=float32)}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.6312589912917285
{'scaleFactor': 30, 'timeStep': 5, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([12.942324 ,  3.8727698,  4.828893 ], dtype=float32)}
episode index:1779
target Thresh 14.998355129054147
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([1.761178 , 4.1094728, 5.570905 ], dtype=float32)}
done in step count: 399
reward sum = 0.0
running average episode reward sum: 0.6309043514089803
{'scaleFactor': 30, 'timeStep': 400, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([ 9.864964 , 11.303297 ,  1.9824928], dtype=float32)}
episode index:1780
target Thresh 14.998363332882215
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([13.877552  ,  3.822544  ,  0.33973807], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6311115920875827
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([13.877552  ,  3.822544  ,  0.33973807], dtype=float32)}
episode index:1781
target Thresh 14.99837149579352
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([11.788597 ,  7.7842045,  1.9455569], dtype=float32)}
done in step count: 47
reward sum = 0.6235253948912
running average episode reward sum: 0.6311073349623323
{'scaleFactor': 30, 'timeStep': 48, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([ 8.653992, 10.000679,  3.675895], dtype=float32)}
episode index:1782
target Thresh 14.998379617992136
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([8.096295, 8.800945, 5.558909], dtype=float32)}
done in step count: 40
reward sum = 0.6689717585696803
running average episode reward sum: 0.6311285713188142
{'scaleFactor': 30, 'timeStep': 41, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([2.6388183, 9.904438 , 2.960868 ], dtype=float32)}
episode index:1783
target Thresh 14.998387699681114
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([10.2043705 ,  9.209474  ,  0.62718284], dtype=float32)}
done in step count: 39
reward sum = 0.6757290490602831
running average episode reward sum: 0.6311535715866065
{'scaleFactor': 30, 'timeStep': 40, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([2.9484682, 9.016614 , 2.5557435], dtype=float32)}
episode index:1784
target Thresh 14.998395741062504
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([ 5.914924, 10.19688 ,  4.532604], dtype=float32)}
done in step count: 31
reward sum = 0.7323033696543975
running average episode reward sum: 0.6312102381401458
{'scaleFactor': 30, 'timeStep': 32, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([4.603959 , 8.455064 , 3.2745795], dtype=float32)}
episode index:1785
target Thresh 14.998403742337334
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([9.871805 , 9.958857 , 5.4373584], dtype=float32)}
done in step count: 54
reward sum = 0.5811664141181095
running average episode reward sum: 0.6311822180819028
{'scaleFactor': 30, 'timeStep': 55, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([ 8.743131 , 11.838414 ,  2.5465188], dtype=float32)}
episode index:1786
target Thresh 14.99841170370564
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([2.0876522, 2.055696 , 6.1530113], dtype=float32)}
done in step count: 20
reward sum = 0.8179069375972308
running average episode reward sum: 0.6312867086915923
{'scaleFactor': 30, 'timeStep': 21, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([3.7972848, 8.758001 , 1.3862873], dtype=float32)}
episode index:1787
target Thresh 14.998419625366456
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([3.9962623, 8.788912 , 1.5445123], dtype=float32)}
done in step count: 74
reward sum = 0.47534004200570695
running average episode reward sum: 0.6311994901979201
{'scaleFactor': 30, 'timeStep': 75, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([13.990789 ,  3.2910028,  4.9965854], dtype=float32)}
episode index:1788
target Thresh 14.998427507517825
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([10.078567 ,  9.097462 ,  0.3212217], dtype=float32)}
done in step count: 91
reward sum = 0.40068465295154054
running average episode reward sum: 0.6310706389753117
{'scaleFactor': 30, 'timeStep': 92, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([1.6346385, 8.418472 , 4.298361 ], dtype=float32)}
episode index:1789
target Thresh 14.9984353503568
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([ 9.933208 , 10.051641 ,  0.5310154], dtype=float32)}
done in step count: 234
reward sum = 0.09519969035921708
running average episode reward sum: 0.6307712697302749
{'scaleFactor': 30, 'timeStep': 235, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([ 6.85688 , 11.395754,  2.795784], dtype=float32)}
episode index:1790
target Thresh 14.998443154079451
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([11.806106 ,  3.1073866,  0.7217014], dtype=float32)}
done in step count: 81
reward sum = 0.4430479816261725
running average episode reward sum: 0.6306664549407137
{'scaleFactor': 30, 'timeStep': 82, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([5.876621 , 7.304516 , 2.9866397], dtype=float32)}
episode index:1791
target Thresh 14.998450918880874
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([1.7594709, 3.157041 , 5.2910986], dtype=float32)}
done in step count: 68
reward sum = 0.5048858887870696
running average episode reward sum: 0.630596264892637
{'scaleFactor': 30, 'timeStep': 69, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([10.399742 ,  9.601209 ,  4.4293694], dtype=float32)}
episode index:1792
target Thresh 14.998458644955187
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([5.039558 , 9.835166 , 4.5903273], dtype=float32)}
done in step count: 118
reward sum = 0.3054590259283046
running average episode reward sum: 0.6304149278937723
{'scaleFactor': 30, 'timeStep': 119, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([12.948198,  8.529441,  1.191687], dtype=float32)}
episode index:1793
target Thresh 14.998466332495545
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([7.987556, 8.949949, 2.284171], dtype=float32)}
done in step count: 61
reward sum = 0.5416850759668536
running average episode reward sum: 0.6303654686675031
{'scaleFactor': 30, 'timeStep': 62, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([12.993453,  8.21986 ,  3.706236], dtype=float32)}
episode index:1794
target Thresh 14.998473981694135
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([11.878033 ,  8.897624 ,  4.2299843], dtype=float32)}
done in step count: 40
reward sum = 0.6689717585696803
running average episode reward sum: 0.6303869763498997
{'scaleFactor': 30, 'timeStep': 41, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([3.435774, 6.112889, 4.119866], dtype=float32)}
episode index:1795
target Thresh 14.998481592742188
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([10.095073,  8.875176,  5.426957], dtype=float32)}
done in step count: 102
reward sum = 0.3587482976818919
running average episode reward sum: 0.6302357298695723
{'scaleFactor': 30, 'timeStep': 103, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([8.604836 , 8.508167 , 2.0177176], dtype=float32)}
episode index:1796
target Thresh 14.99848916582998
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([11.686508 ,  5.8986826,  1.6101413], dtype=float32)}
done in step count: 53
reward sum = 0.5870367819374844
running average episode reward sum: 0.6302116903882523
{'scaleFactor': 30, 'timeStep': 54, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([7.859556  , 8.094364  , 0.09303716], dtype=float32)}
episode index:1797
target Thresh 14.99849670114684
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([3.6005764, 4.110054 , 5.7262897], dtype=float32)}
done in step count: 138
reward sum = 0.2498370564584527
running average episode reward sum: 0.6300001360868454
{'scaleFactor': 30, 'timeStep': 139, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([5.3278522 , 8.907891  , 0.76633006], dtype=float32)}
episode index:1798
target Thresh 14.99850419888115
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([3.9797177, 9.949953 , 1.9404438], dtype=float32)}
done in step count: 23
reward sum = 0.7936142836436554
running average episode reward sum: 0.6300910833617518
{'scaleFactor': 30, 'timeStep': 24, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([ 7.541233  , 11.864767  ,  0.19721927], dtype=float32)}
episode index:1799
target Thresh 14.998511659220352
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([12.101902 ,  2.1002455,  2.460987 ], dtype=float32)}
done in step count: 184
reward sum = 0.15735328210778962
running average episode reward sum: 0.629828451249944
{'scaleFactor': 30, 'timeStep': 185, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([3.9985242, 5.9080725, 3.95122  ], dtype=float32)}
episode index:1800
target Thresh 14.99851908235096
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([3.9790733, 9.917356 , 1.1557943], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.63003398792332
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([3.9790733, 9.917356 , 1.1557943], dtype=float32)}
episode index:1801
target Thresh 14.998526468458548
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([11.72599  ,  7.179261 ,  1.8725572], dtype=float32)}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.6302174296669808
{'scaleFactor': 30, 'timeStep': 5, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([6.6049767, 9.603716 , 2.2308538], dtype=float32)}
episode index:1802
target Thresh 14.998533817727772
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([11.892711 ,  3.8809912,  4.902581 ], dtype=float32)}
done in step count: 35
reward sum = 0.7034476949995692
running average episode reward sum: 0.6302580454547415
{'scaleFactor': 30, 'timeStep': 36, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([11.792087 ,  9.53878  ,  1.0013866], dtype=float32)}
episode index:1803
target Thresh 14.998541130342362
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([1.0111569, 9.395728 , 2.787642 ], dtype=float32)}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6304253444028857
{'scaleFactor': 30, 'timeStep': 8, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([3.6784139, 2.6664135, 5.758595 ], dtype=float32)}
episode index:1804
target Thresh 14.998548406485133
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([11.888347 ,  4.1053624,  6.162078 ], dtype=float32)}
done in step count: 34
reward sum = 0.7105532272722921
running average episode reward sum: 0.6304697365817608
{'scaleFactor': 30, 'timeStep': 35, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([8.54114  , 8.711939 , 1.8623785], dtype=float32)}
episode index:1805
target Thresh 14.998555646337993
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([12.141811 , 10.282744 ,  1.1472322], dtype=float32)}
done in step count: 37
reward sum = 0.6894490858690777
running average episode reward sum: 0.6305023940287637
{'scaleFactor': 30, 'timeStep': 38, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([ 6.286955, 10.189048,  3.021838], dtype=float32)}
episode index:1806
target Thresh 14.998562850081935
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([2.0013697, 2.8638473, 4.8659286], dtype=float32)}
done in step count: 55
reward sum = 0.5753547499769285
running average episode reward sum: 0.6304718751333283
{'scaleFactor': 30, 'timeStep': 56, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([8.775146 , 8.908989 , 5.6191416], dtype=float32)}
episode index:1807
target Thresh 14.998570017897055
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([10.871487 , 10.226514 ,  1.2596484], dtype=float32)}
done in step count: 72
reward sum = 0.48499137027416284
running average episode reward sum: 0.630391410252322
{'scaleFactor': 30, 'timeStep': 73, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([8.487082 , 8.2363825, 2.8080244], dtype=float32)}
episode index:1808
target Thresh 14.998577149962548
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([8.82612  , 8.833491 , 1.7457918], dtype=float32)}
done in step count: 172
reward sum = 0.17752252675876343
running average episode reward sum: 0.630141068138727
{'scaleFactor': 30, 'timeStep': 173, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([2.6520624, 7.4149823, 3.1722438], dtype=float32)}
episode index:1809
target Thresh 14.998584246456716
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([1.9724962, 7.1922154, 4.170518 ], dtype=float32)}
done in step count: 19
reward sum = 0.8261686238355866
running average episode reward sum: 0.6302493706556866
{'scaleFactor': 30, 'timeStep': 20, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([ 6.693421 , 10.876555 ,  0.0984582], dtype=float32)}
episode index:1810
target Thresh 14.998591307556971
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([11.896961 ,  1.9870887,  4.6297827], dtype=float32)}
done in step count: 38
reward sum = 0.682554595010387
running average episode reward sum: 0.6302782526128123
{'scaleFactor': 30, 'timeStep': 39, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([ 7.224196 , 11.83961  ,  2.9513745], dtype=float32)}
episode index:1811
target Thresh 14.99859833343984
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([1.8886803, 8.723639 , 4.134385 ], dtype=float32)}
done in step count: 117
reward sum = 0.30854447063465107
running average episode reward sum: 0.6301006953379898
{'scaleFactor': 30, 'timeStep': 118, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([8.75985   , 7.0990677 , 0.07232254], dtype=float32)}
episode index:1812
target Thresh 14.998605324280975
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([ 9.837612 , 10.194572 ,  2.8525841], dtype=float32)}
done in step count: 191
reward sum = 0.14666354163210368
running average episode reward sum: 0.6298340449498454
{'scaleFactor': 30, 'timeStep': 192, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([13.496939 ,  3.0185432,  4.3021016], dtype=float32)}
episode index:1813
target Thresh 14.998612280255143
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([9.766771  , 9.796236  , 0.66607964], dtype=float32)}
done in step count: 17
reward sum = 0.8429431933839268
running average episode reward sum: 0.6299515251860274
{'scaleFactor': 30, 'timeStep': 18, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([12.220303 ,  6.6635914,  4.8968143], dtype=float32)}
episode index:1814
target Thresh 14.998619201536245
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([11.988048 ,  7.0780053,  2.48275  ], dtype=float32)}
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.630092810776402
{'scaleFactor': 30, 'timeStep': 13, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([10.5115385,  4.04167  ,  3.9813893], dtype=float32)}
episode index:1815
target Thresh 14.998626088297314
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([12.087494 ,  9.891496 ,  1.6661937], dtype=float32)}
done in step count: 19
reward sum = 0.8261686238355866
running average episode reward sum: 0.6302007820390999
{'scaleFactor': 30, 'timeStep': 20, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([11.2447195,  7.582402 ,  3.3179486], dtype=float32)}
episode index:1816
target Thresh 14.998632940710518
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([10.455063  , 10.138371  ,  0.26903573], dtype=float32)}
done in step count: 29
reward sum = 0.7471720943315961
running average episode reward sum: 0.6302651581053037
{'scaleFactor': 30, 'timeStep': 30, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([6.2809153, 7.6414175, 3.3122485], dtype=float32)}
episode index:1817
target Thresh 14.99863975894717
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([10.185429 ,  7.216076 ,  3.8565276], dtype=float32)}
done in step count: 105
reward sum = 0.348093114492442
running average episode reward sum: 0.6301099479603022
{'scaleFactor': 30, 'timeStep': 106, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([1.8736378, 9.246765 , 4.531277 ], dtype=float32)}
episode index:1818
target Thresh 14.998646543177724
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([ 8.0699215, 10.368597 ,  0.5887982], dtype=float32)}
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.630250835768854
{'scaleFactor': 30, 'timeStep': 13, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([13.311082,  3.847641,  4.354787], dtype=float32)}
episode index:1819
target Thresh 14.998653293571786
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([9.774627, 9.138321, 6.05684 ], dtype=float32)}
done in step count: 40
reward sum = 0.6689717585696803
running average episode reward sum: 0.6302721110011621
{'scaleFactor': 30, 'timeStep': 41, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([6.792386 , 7.435807 , 3.6238427], dtype=float32)}
episode index:1820
target Thresh 14.998660010298119
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([11.293983 ,  8.921782 ,  2.1338694], dtype=float32)}
done in step count: 60
reward sum = 0.5471566423907612
running average episode reward sum: 0.6302264682397065
{'scaleFactor': 30, 'timeStep': 61, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([ 3.671732 , 10.080698 ,  2.5792255], dtype=float32)}
episode index:1821
target Thresh 14.998666693524639
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([1.9064023, 7.182062 , 1.9801521], dtype=float32)}
done in step count: 87
reward sum = 0.41712087993322033
running average episode reward sum: 0.6301095057872881
{'scaleFactor': 30, 'timeStep': 88, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([5.5535555, 9.626391 , 5.267613 ], dtype=float32)}
episode index:1822
target Thresh 14.998673343418426
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([11.882842 ,  3.0811117,  2.9058523], dtype=float32)}
done in step count: 161
reward sum = 0.19827425658891443
running average episode reward sum: 0.6298726241366034
{'scaleFactor': 30, 'timeStep': 162, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([ 7.620262, 11.79365 ,  2.334379], dtype=float32)}
episode index:1823
target Thresh 14.998679960145733
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([ 1.7700108, 10.146522 ,  2.82581  ], dtype=float32)}
done in step count: 36
reward sum = 0.6964132180495735
running average episode reward sum: 0.6299091047253714
{'scaleFactor': 30, 'timeStep': 37, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([0.53345245, 4.2928762 , 4.312389  ], dtype=float32)}
episode index:1824
target Thresh 14.99868654387197
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([10.101288 ,  6.952716 ,  4.7930994], dtype=float32)}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.6300903030296315
{'scaleFactor': 30, 'timeStep': 5, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([11.107652 ,  3.7106926,  5.535946 ], dtype=float32)}
episode index:1825
target Thresh 14.99869309476174
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([5.9364967, 8.4560175, 5.336955 ], dtype=float32)}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.6302766166643361
{'scaleFactor': 30, 'timeStep': 4, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([10.006297,  8.245635,  6.262403], dtype=float32)}
episode index:1826
target Thresh 14.998699612978807
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([12.333259 ,  6.0111933,  1.1522732], dtype=float32)}
done in step count: 48
reward sum = 0.617290140942288
running average episode reward sum: 0.6302695085769129
{'scaleFactor': 30, 'timeStep': 49, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([ 5.75796  , 11.209654 ,  2.6207705], dtype=float32)}
episode index:1827
target Thresh 14.998706098686135
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([1.725178 , 7.126558 , 6.0481234], dtype=float32)}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.630455520333709
{'scaleFactor': 30, 'timeStep': 4, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([1.8480523, 5.3219213, 4.557147 ], dtype=float32)}
episode index:1828
target Thresh 14.998712552045859
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([1.970099, 4.025375, 6.242511], dtype=float32)}
done in step count: 52
reward sum = 0.5929664464014994
running average episode reward sum: 0.6304350233003945
{'scaleFactor': 30, 'timeStep': 53, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([ 8.492425 , 10.993224 ,  1.5250893], dtype=float32)}
episode index:1829
target Thresh 14.998718973219319
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([10.0346775, 10.0148115,  0.6516935], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.6306315068942194
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([9.914605, 9.937206, 6.133005], dtype=float32)}
episode index:1830
target Thresh 14.998725362367043
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([1.8703498, 6.046893 , 3.7275202], dtype=float32)}
done in step count: 399
reward sum = 0.0
running average episode reward sum: 0.6302870877206016
{'scaleFactor': 30, 'timeStep': 400, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([2.5377629 , 0.37934577, 2.8282387 ], dtype=float32)}
episode index:1831
target Thresh 14.99873171964876
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([5.072676 , 8.840518 , 1.8809438], dtype=float32)}
done in step count: 204
reward sum = 0.12870034108965533
running average episode reward sum: 0.6300132958283358
{'scaleFactor': 30, 'timeStep': 205, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([10.243483 ,  3.2737591,  4.368458 ], dtype=float32)}
episode index:1832
target Thresh 14.9987380452234
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([3.450038 , 7.542759 , 0.6040638], dtype=float32)}
done in step count: 29
reward sum = 0.7471720943315961
running average episode reward sum: 0.6300772122486866
{'scaleFactor': 30, 'timeStep': 30, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([7.2437077 , 9.097709  , 0.25483483], dtype=float32)}
episode index:1833
target Thresh 14.998744339249106
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([1.8538425, 7.897576 , 4.7456484], dtype=float32)}
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.6302169656071749
{'scaleFactor': 30, 'timeStep': 13, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([8.068796  , 8.434281  , 0.56891286], dtype=float32)}
episode index:1834
target Thresh 14.998750601883229
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([11.719249 ,  6.8869357,  3.0711923], dtype=float32)}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.6303970086831382
{'scaleFactor': 30, 'timeStep': 5, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([6.4689765, 7.4371257, 2.5305898], dtype=float32)}
episode index:1835
target Thresh 14.998756833282332
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([1.8936148, 3.7630138, 5.349209 ], dtype=float32)}
done in step count: 66
reward sum = 0.5151371174238033
running average episode reward sum: 0.6303342309645874
{'scaleFactor': 30, 'timeStep': 67, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([0.06749031, 7.6796813 , 2.0494642 ], dtype=float32)}
episode index:1836
target Thresh 14.998763033602204
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([12.063921 ,  4.9324727,  4.258464 ], dtype=float32)}
done in step count: 191
reward sum = 0.14666354163210368
running average episode reward sum: 0.6300709371761647
{'scaleFactor': 30, 'timeStep': 192, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([6.7400055, 8.81732  , 3.3788357], dtype=float32)}
episode index:1837
target Thresh 14.99876920299785
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([ 2.856132 , 10.004814 ,  0.5236172], dtype=float32)}
done in step count: 17
reward sum = 0.8429431933839268
running average episode reward sum: 0.6301867545081602
{'scaleFactor': 30, 'timeStep': 18, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([2.0670664, 7.237037 , 3.1713603], dtype=float32)}
episode index:1838
target Thresh 14.998775341623508
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([11.910837 ,  7.9645157,  4.3101163], dtype=float32)}
done in step count: 46
reward sum = 0.6298236312032323
running average episode reward sum: 0.6301865570512244
{'scaleFactor': 30, 'timeStep': 47, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([10.22354  ,  8.011395 ,  3.1642697], dtype=float32)}
episode index:1839
target Thresh 14.998781449632643
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([9.98552  , 9.988352 , 0.5946991], dtype=float32)}
done in step count: 105
reward sum = 0.348093114492442
running average episode reward sum: 0.6300332453976598
{'scaleFactor': 30, 'timeStep': 106, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([4.351074 , 7.005746 , 3.4479847], dtype=float32)}
episode index:1840
target Thresh 14.998787527177955
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([11.97993 ,  7.980175,  5.301268], dtype=float32)}
done in step count: 18
reward sum = 0.8345137614500875
running average episode reward sum: 0.6301443157485846
{'scaleFactor': 30, 'timeStep': 19, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([4.151993 , 8.8688345, 2.8945181], dtype=float32)}
episode index:1841
target Thresh 14.998793574411383
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([10.085313 , 10.507067 ,  3.1271346], dtype=float32)}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.630328981700947
{'scaleFactor': 30, 'timeStep': 4, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([4.054738, 9.966869, 3.352636], dtype=float32)}
episode index:1842
target Thresh 14.99879959148411
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([11.6666765,  3.662264 ,  1.857619 ], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.6305241368926447
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([10.937892 ,  5.2361445,  2.1305418], dtype=float32)}
episode index:1843
target Thresh 14.998805578546559
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([5.8701906 , 9.804647  , 0.49622002], dtype=float32)}
done in step count: 51
reward sum = 0.598956006466161
running average episode reward sum: 0.6305070175160578
{'scaleFactor': 30, 'timeStep': 52, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([1.2308575e+01, 8.9520493e+00, 5.4385024e-03], dtype=float32)}
episode index:1844
target Thresh 14.99881153574841
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([2.4224715, 8.946808 , 1.6187841], dtype=float32)}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6306755666390306
{'scaleFactor': 30, 'timeStep': 7, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([ 3.4720635, 10.496931 ,  0.9091588], dtype=float32)}
episode index:1845
target Thresh 14.998817463238595
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([2.8388648, 9.015692 , 2.733518 ], dtype=float32)}
done in step count: 282
reward sum = 0.05876583027950327
running average episode reward sum: 0.630365756380981
{'scaleFactor': 30, 'timeStep': 283, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([12.443004,  4.376707,  4.132105], dtype=float32)}
episode index:1846
target Thresh 14.998823361165298
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([7.168542 , 8.952883 , 5.9038267], dtype=float32)}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.6305190598412423
{'scaleFactor': 30, 'timeStep': 10, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([5.9516926, 8.799603 , 3.013631 ], dtype=float32)}
episode index:1847
target Thresh 14.998829229675968
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([4.2132363, 9.957555 , 2.8248084], dtype=float32)}
done in step count: 32
reward sum = 0.7249803359578534
running average episode reward sum: 0.6305701752503964
{'scaleFactor': 30, 'timeStep': 33, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([9.985296 , 8.156224 , 0.3152091], dtype=float32)}
episode index:1848
target Thresh 14.998835068917321
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([10.000591 ,  5.499185 ,  2.5812068], dtype=float32)}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.630733233753726
{'scaleFactor': 30, 'timeStep': 8, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([2.7439113, 8.321898 , 3.6605377], dtype=float32)}
episode index:1849
target Thresh 14.998840879035335
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([10.994403  , 10.061286  ,  0.05971405], dtype=float32)}
done in step count: 76
reward sum = 0.46588077516979337
running average episode reward sum: 0.6306441243166536
{'scaleFactor': 30, 'timeStep': 77, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([2.587716, 9.69841 , 3.075942], dtype=float32)}
episode index:1850
target Thresh 14.998846660175264
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([0.47486973, 3.0216422 , 2.6671772 ], dtype=float32)}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.6307969461011848
{'scaleFactor': 30, 'timeStep': 10, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([2.5305862 , 6.926233  , 0.77241814], dtype=float32)}
episode index:1851
target Thresh 14.998852412481638
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([1.9572707, 2.157625 , 5.022261 ], dtype=float32)}
done in step count: 68
reward sum = 0.5048858887870696
running average episode reward sum: 0.6307289595691576
{'scaleFactor': 30, 'timeStep': 69, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([6.973539 , 7.3697143, 5.831512 ], dtype=float32)}
episode index:1852
target Thresh 14.998858136098262
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([12.18053  ,  2.0728564,  5.27592  ], dtype=float32)}
done in step count: 88
reward sum = 0.41294967113388814
running average episode reward sum: 0.6306114316207306
{'scaleFactor': 30, 'timeStep': 89, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([2.8256745, 7.8875027, 2.281652 ], dtype=float32)}
episode index:1853
target Thresh 14.998863831168231
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([5.676647, 8.684056, 5.727927], dtype=float32)}
done in step count: 29
reward sum = 0.7471720943315961
running average episode reward sum: 0.630674301449593
{'scaleFactor': 30, 'timeStep': 30, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([10.351302  ,  7.4073715 ,  0.28604162], dtype=float32)}
episode index:1854
target Thresh 14.99886949783392
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([4.037074  , 9.87456   , 0.27740163], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.630868008025631
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([3.8508968, 9.923    , 0.4252403], dtype=float32)}
episode index:1855
target Thresh 14.998875136236997
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([11.963041,  2.278082,  5.060066], dtype=float32)}
done in step count: 86
reward sum = 0.421334222154768
running average episode reward sum: 0.6307551126668642
{'scaleFactor': 30, 'timeStep': 87, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([ 7.4610662, 10.829983 ,  2.9517465], dtype=float32)}
episode index:1856
target Thresh 14.99888074651842
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([9.341127, 8.013139, 4.590947], dtype=float32)}
done in step count: 50
reward sum = 0.6050060671375364
running average episode reward sum: 0.6307412467295841
{'scaleFactor': 30, 'timeStep': 51, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([2.9204414, 7.5510297, 2.9837608], dtype=float32)}
episode index:1857
target Thresh 14.998886328818449
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([10.29837 ,  9.981893,  5.367625], dtype=float32)}
done in step count: 34
reward sum = 0.7105532272722921
running average episode reward sum: 0.6307842025856352
{'scaleFactor': 30, 'timeStep': 35, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([ 7.74078  , 11.816836 ,  2.4082954], dtype=float32)}
episode index:1858
target Thresh 14.99889188327664
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([ 5.970744 , 10.098781 ,  5.6301627], dtype=float32)}
done in step count: 61
reward sum = 0.5416850759668536
running average episode reward sum: 0.6307362740613647
{'scaleFactor': 30, 'timeStep': 62, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([3.9137359, 7.239746 , 3.2092748], dtype=float32)}
episode index:1859
target Thresh 14.998897410031855
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([2.9900777, 9.036052 , 1.1903863], dtype=float32)}
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.6308785331905029
{'scaleFactor': 30, 'timeStep': 12, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([10.220188 , 10.27562  ,  5.4220204], dtype=float32)}
episode index:1860
target Thresh 14.998902909222263
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([11.889483,  8.204718,  5.302965], dtype=float32)}
done in step count: 25
reward sum = 0.7778213593991467
running average episode reward sum: 0.630957492258858
{'scaleFactor': 30, 'timeStep': 26, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([ 2.378586 , 10.545615 ,  3.8239136], dtype=float32)}
episode index:1861
target Thresh 14.998908380985343
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([12.083059 ,  1.6224843,  1.9643253], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.6311503185250992
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([11.225236 ,  3.1737456,  2.2214599], dtype=float32)}
episode index:1862
target Thresh 14.998913825457892
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([2.0027382, 7.1520042, 4.552222 ], dtype=float32)}
done in step count: 45
reward sum = 0.6361854860638709
running average episode reward sum: 0.6311530212451951
{'scaleFactor': 30, 'timeStep': 46, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([ 3.939873 , 10.150325 ,  2.0409513], dtype=float32)}
episode index:1863
target Thresh 14.998919242776022
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([11.969772 ,  5.0546565,  1.0829545], dtype=float32)}
done in step count: 147
reward sum = 0.22823046013534068
running average episode reward sum: 0.6309368610729259
{'scaleFactor': 30, 'timeStep': 148, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([2.1578414, 7.7067633, 3.1143584], dtype=float32)}
episode index:1864
target Thresh 14.998924633075164
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([10.124509  ,  9.123457  ,  0.01061886], dtype=float32)}
done in step count: 94
reward sum = 0.3887839180742268
running average episode reward sum: 0.6308070203528194
{'scaleFactor': 30, 'timeStep': 95, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([ 1.4305208, 10.776061 ,  3.6396801], dtype=float32)}
episode index:1865
target Thresh 14.998929996490078
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([10.089038  ,  9.9213295 ,  0.38523418], dtype=float32)}
done in step count: 96
reward sum = 0.38104711810454966
running average episode reward sum: 0.6306731726024184
{'scaleFactor': 30, 'timeStep': 97, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([2.4839766, 8.743312 , 2.0730333], dtype=float32)}
episode index:1866
target Thresh 14.998935333154847
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([5.021052, 9.900442, 2.93982 ], dtype=float32)}
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.6308053889122184
{'scaleFactor': 30, 'timeStep': 14, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([2.4924805, 8.6775   , 4.111303 ], dtype=float32)}
episode index:1867
target Thresh 14.99894064320289
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([8.0174799e+00, 1.0255633e+01, 5.5564195e-03], dtype=float32)}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.6309871306740428
{'scaleFactor': 30, 'timeStep': 4, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([ 9.371169 , 11.899482 ,  1.6880424], dtype=float32)}
episode index:1868
target Thresh 14.998945926766957
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([0.844952 , 5.652895 , 2.2004662], dtype=float32)}
done in step count: 118
reward sum = 0.3054590259283046
running average episode reward sum: 0.6308129583333547
{'scaleFactor': 30, 'timeStep': 119, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([ 8.453054, 10.990517,  6.196256], dtype=float32)}
episode index:1869
target Thresh 14.99895118397914
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([10.853477 ,  5.370361 ,  2.0415595], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.6310050369652621
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([10.354845 ,  7.1934843,  2.00459  ], dtype=float32)}
episode index:1870
target Thresh 14.998956414970868
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([9.6965275, 9.095747 , 1.9231219], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6312022550107109
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([9.6965275, 9.095747 , 1.9231219], dtype=float32)}
episode index:1871
target Thresh 14.998961619872913
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([11.939295 ,  4.827338 ,  1.2791818], dtype=float32)}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.63137308182422
{'scaleFactor': 30, 'timeStep': 6, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([9.736642 , 8.337515 , 2.8113267], dtype=float32)}
episode index:1872
target Thresh 14.998966798815404
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([1.8813556, 5.9209304, 3.2630084], dtype=float32)}
done in step count: 88
reward sum = 0.41294967113388814
running average episode reward sum: 0.6312564649471831
{'scaleFactor': 30, 'timeStep': 89, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([10.071076 ,  8.52592  ,  1.1090795], dtype=float32)}
episode index:1873
target Thresh 14.99897195192781
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([9.09734 , 9.061073, 3.625696], dtype=float32)}
done in step count: 170
reward sum = 0.18112695312597024
running average episode reward sum: 0.6310162677690502
{'scaleFactor': 30, 'timeStep': 171, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([10.356444 ,  2.3928256,  4.5934434], dtype=float32)}
episode index:1874
target Thresh 14.99897707933896
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([4.8178563, 9.919377 , 5.8276296], dtype=float32)}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.631176827278457
{'scaleFactor': 30, 'timeStep': 8, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([3.756674 , 8.561356 , 3.8401618], dtype=float32)}
episode index:1875
target Thresh 14.998982181177043
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([ 2.939013 , 10.207224 ,  3.2196383], dtype=float32)}
done in step count: 46
reward sum = 0.6298236312032323
running average episode reward sum: 0.6311761059585874
{'scaleFactor': 30, 'timeStep': 47, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([13.257049 ,  3.9834213,  4.9248557], dtype=float32)}
episode index:1876
target Thresh 14.998987257569599
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([5.848175 , 8.996505 , 4.5805373], dtype=float32)}
done in step count: 39
reward sum = 0.6757290490602831
running average episode reward sum: 0.6311998422095739
{'scaleFactor': 30, 'timeStep': 40, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([0.2698781, 7.215092 , 2.945073 ], dtype=float32)}
episode index:1877
target Thresh 14.998992308643544
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([2.1331818, 1.885906 , 4.4132113], dtype=float32)}
done in step count: 106
reward sum = 0.3446121833475176
running average episode reward sum: 0.6310472396223205
{'scaleFactor': 30, 'timeStep': 107, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([7.0957274, 9.011695 , 6.023075 ], dtype=float32)}
episode index:1878
target Thresh 14.998997334525152
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([12.073356 ,  8.165765 ,  1.3562152], dtype=float32)}
done in step count: 32
reward sum = 0.7249803359578534
running average episode reward sum: 0.6310972306262244
{'scaleFactor': 30, 'timeStep': 33, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([ 9.588419 , 10.596678 ,  2.1130385], dtype=float32)}
episode index:1879
target Thresh 14.99900233534007
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([11.91858  ,  6.070312 ,  0.3751339], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6312934555035508
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([11.91858  ,  6.070312 ,  0.3751339], dtype=float32)}
episode index:1880
target Thresh 14.99900731121332
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([1.933807 , 4.0162334, 5.2296095], dtype=float32)}
done in step count: 51
reward sum = 0.598956006466161
running average episode reward sum: 0.6312762638772682
{'scaleFactor': 30, 'timeStep': 52, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([ 4.0563083, 10.524771 ,  0.7896482], dtype=float32)}
episode index:1881
target Thresh 14.999012262269298
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([11.726554 ,  4.95989  ,  2.5172334], dtype=float32)}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6314360880451905
{'scaleFactor': 30, 'timeStep': 8, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([5.3522844, 7.171691 , 1.3683277], dtype=float32)}
episode index:1882
target Thresh 14.999017188631782
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([ 2.964222, 10.118404,  3.314598], dtype=float32)}
done in step count: 69
reward sum = 0.4998370298991989
running average episode reward sum: 0.6313662000695421
{'scaleFactor': 30, 'timeStep': 70, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([11.73908  ,  4.476383 ,  5.3128924], dtype=float32)}
episode index:1883
target Thresh 14.999022090423932
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([1.8681151, 1.6739618, 4.95521  ], dtype=float32)}
done in step count: 181
reward sum = 0.16216989001100654
running average episode reward sum: 0.6311171574421225
{'scaleFactor': 30, 'timeStep': 182, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([9.294654 , 9.747102 , 1.0072387], dtype=float32)}
episode index:1884
target Thresh 14.999026967768291
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([5.951602 , 9.029565 , 3.9266024], dtype=float32)}
done in step count: 101
reward sum = 0.3623720178604969
running average episode reward sum: 0.6309745870762967
{'scaleFactor': 30, 'timeStep': 102, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([13.826511 ,  5.9528847,  6.163979 ], dtype=float32)}
episode index:1885
target Thresh 14.999031820786792
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([ 1.8459682, 10.179739 ,  1.3337135], dtype=float32)}
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.6311053115916321
{'scaleFactor': 30, 'timeStep': 14, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([3.7478666, 5.892749 , 4.047324 ], dtype=float32)}
episode index:1886
target Thresh 14.999036649600763
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([11.363696 ,  8.706154 ,  2.2673523], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.6312955048552296
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([10.924646 , 10.557854 ,  1.9912816], dtype=float32)}
episode index:1887
target Thresh 14.999041454330925
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([10.777278 , 10.5534935,  2.1593163], dtype=float32)}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.631464834593071
{'scaleFactor': 30, 'timeStep': 6, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([3.2033515, 9.315896 , 3.7273927], dtype=float32)}
episode index:1888
target Thresh 14.999046235097394
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([6.0098696, 9.083866 , 2.164749 ], dtype=float32)}
done in step count: 21
reward sum = 0.8097278682212584
running average episode reward sum: 0.6315592035891685
{'scaleFactor': 30, 'timeStep': 22, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([10.082991,  7.472037,  5.625775], dtype=float32)}
episode index:1889
target Thresh 14.99905099201969
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([ 8.24411 , 10.487287,  2.41726 ], dtype=float32)}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.6317083877393773
{'scaleFactor': 30, 'timeStep': 10, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([ 6.9361525, 10.944321 ,  2.6873236], dtype=float32)}
episode index:1890
target Thresh 14.999055725216738
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([ 7.1748333, 10.023444 ,  4.357874 ], dtype=float32)}
done in step count: 37
reward sum = 0.6894490858690777
running average episode reward sum: 0.6317389222174997
{'scaleFactor': 30, 'timeStep': 38, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([10.522804 , 10.320799 ,  6.0714116], dtype=float32)}
episode index:1891
target Thresh 14.999060434806868
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([3.7880776, 9.8847885, 3.0095513], dtype=float32)}
done in step count: 39
reward sum = 0.6757290490602831
running average episode reward sum: 0.6317621728130826
{'scaleFactor': 30, 'timeStep': 40, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([6.337942 , 9.10113  , 0.8299172], dtype=float32)}
episode index:1892
target Thresh 14.999065120907819
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([12.034341  ,  9.898605  ,  0.03368503], dtype=float32)}
done in step count: 29
reward sum = 0.7471720943315961
running average episode reward sum: 0.6318231394911167
{'scaleFactor': 30, 'timeStep': 30, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([ 5.935866 , 10.413277 ,  2.5846179], dtype=float32)}
episode index:1893
target Thresh 14.999069783636742
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([3.9272728, 8.772033 , 1.7736018], dtype=float32)}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.6319718692207854
{'scaleFactor': 30, 'timeStep': 10, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([10.641897  ,  9.252504  ,  0.69811547], dtype=float32)}
episode index:1894
target Thresh 14.99907442311021
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([9.822771 , 8.953906 , 2.9927254], dtype=float32)}
done in step count: 17
reward sum = 0.8429431933839268
running average episode reward sum: 0.6320831997348556
{'scaleFactor': 30, 'timeStep': 18, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([10.46835  ,  9.854468 ,  0.9872892], dtype=float32)}
episode index:1895
target Thresh 14.999079039444206
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([4.097752 , 9.216746 , 4.6677217], dtype=float32)}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.6322268172851055
{'scaleFactor': 30, 'timeStep': 11, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([10.23017 , 10.444123,  1.407665], dtype=float32)}
episode index:1896
target Thresh 14.999083632754143
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([2.8294406, 9.99174  , 1.247249 ], dtype=float32)}
done in step count: 34
reward sum = 0.7105532272722921
running average episode reward sum: 0.6322681069055521
{'scaleFactor': 30, 'timeStep': 35, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([7.268413 , 9.043336 , 0.7566355], dtype=float32)}
episode index:1897
target Thresh 14.999088203154846
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([1.6587907, 2.072174 , 2.7920995], dtype=float32)}
done in step count: 52
reward sum = 0.5929664464014994
running average episode reward sum: 0.6322474000243593
{'scaleFactor': 30, 'timeStep': 53, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([13.665273 ,  4.0114646,  5.503585 ], dtype=float32)}
episode index:1898
target Thresh 14.999092750760584
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([ 2.1954198, 10.229535 ,  3.4345586], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6324410559485172
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([ 2.1954198, 10.229535 ,  3.4345586], dtype=float32)}
episode index:1899
target Thresh 14.999097275685044
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([12.006822 ,  3.2160878,  3.5670347], dtype=float32)}
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.6325747105883948
{'scaleFactor': 30, 'timeStep': 13, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([9.451176 , 7.0753264, 3.3537803], dtype=float32)}
episode index:1900
target Thresh 14.999101778041348
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([7.177749 , 9.009554 , 6.2484827], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.6327627302040768
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([9.076094 , 8.162502 , 5.8872876], dtype=float32)}
episode index:1901
target Thresh 14.999106257942055
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([11.835271 ,  9.118289 ,  0.8428735], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.632955809736041
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([11.835271 ,  9.118289 ,  0.8428735], dtype=float32)}
episode index:1902
target Thresh 14.999110715499167
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([6.98471  , 8.951242 , 1.7501197], dtype=float32)}
done in step count: 133
reward sum = 0.2627125872502283
running average episode reward sum: 0.6327612520784027
{'scaleFactor': 30, 'timeStep': 134, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([12.665441 ,  2.7498138,  4.6584535], dtype=float32)}
episode index:1903
target Thresh 14.999115150824117
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([10.929587 , 10.018164 ,  2.3292153], dtype=float32)}
done in step count: 96
reward sum = 0.38104711810454966
running average episode reward sum: 0.6326290492769459
{'scaleFactor': 30, 'timeStep': 97, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([1.5943083, 5.5148087, 3.859931 ], dtype=float32)}
episode index:1904
target Thresh 14.999119564027794
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([7.195187 , 8.993087 , 1.4930642], dtype=float32)}
done in step count: 115
reward sum = 0.31480917318095203
running average episode reward sum: 0.632462214696318
{'scaleFactor': 30, 'timeStep': 116, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([13.060867 ,  8.354803 ,  4.8321323], dtype=float32)}
episode index:1905
target Thresh 14.999123955220524
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([12.005306 ,  4.0318356,  4.313084 ], dtype=float32)}
done in step count: 72
reward sum = 0.48499137027416284
running average episode reward sum: 0.6323848427947324
{'scaleFactor': 30, 'timeStep': 73, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([5.9044147, 7.7936473, 3.4923286], dtype=float32)}
episode index:1906
target Thresh 14.999128324512089
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([10.209981 ,  9.243795 ,  0.8506426], dtype=float32)}
done in step count: 14
reward sum = 0.8687458127689782
running average episode reward sum: 0.6325087866699156
{'scaleFactor': 30, 'timeStep': 15, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([7.851777  , 9.2608185 , 0.38100907], dtype=float32)}
episode index:1907
target Thresh 14.999132672011724
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([10.284777 ,  5.7129564,  2.8882134], dtype=float32)}
done in step count: 56
reward sum = 0.5696012024771592
running average episode reward sum: 0.6324758162379487
{'scaleFactor': 30, 'timeStep': 57, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([4.932651 , 9.372447 , 4.5150304], dtype=float32)}
episode index:1908
target Thresh 14.999136997828112
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([10.600481  ,  8.85307   ,  0.19914258], dtype=float32)}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.6326476969051892
{'scaleFactor': 30, 'timeStep': 5, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([13.933627 ,  6.8748903,  5.705102 ], dtype=float32)}
episode index:1909
target Thresh 14.9991413020694
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([7.087727, 8.930808, 3.112905], dtype=float32)}
done in step count: 20
reward sum = 0.8179069375972308
running average episode reward sum: 0.6327446912720436
{'scaleFactor': 30, 'timeStep': 21, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([1.4015858, 4.810693 , 4.169742 ], dtype=float32)}
episode index:1910
target Thresh 14.999145584843198
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([4.6853867, 8.0458355, 6.092468 ], dtype=float32)}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.6329264575246485
{'scaleFactor': 30, 'timeStep': 3, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([ 8.073427  , 10.001373  ,  0.99936354], dtype=float32)}
episode index:1911
target Thresh 14.99914984625657
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([8.73091   , 9.798165  , 0.10119511], dtype=float32)}
done in step count: 38
reward sum = 0.682554595010387
running average episode reward sum: 0.6329524136635009
{'scaleFactor': 30, 'timeStep': 39, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([3.7817543, 8.088098 , 4.3727307], dtype=float32)}
episode index:1912
target Thresh 14.999154086416056
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([7.777119, 9.181526, 1.212216], dtype=float32)}
done in step count: 64
reward sum = 0.525596487525562
running average episode reward sum: 0.6328962945175844
{'scaleFactor': 30, 'timeStep': 65, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([11.768711, 11.427765,  5.752483], dtype=float32)}
episode index:1913
target Thresh 14.999158305427654
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([12.038369 ,  2.0419629,  5.2918816], dtype=float32)}
done in step count: 156
reward sum = 0.20849246173476124
running average episode reward sum: 0.6326745579278338
{'scaleFactor': 30, 'timeStep': 157, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([2.5224144, 4.633047 , 5.710209 ], dtype=float32)}
episode index:1914
target Thresh 14.99916250339685
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([11.747139 ,  2.0893528,  4.7755203], dtype=float32)}
done in step count: 57
reward sum = 0.5639051904523875
running average episode reward sum: 0.6326386470309798
{'scaleFactor': 30, 'timeStep': 58, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([3.295765 , 8.894197 , 3.0647726], dtype=float32)}
episode index:1915
target Thresh 14.999166680428583
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([1.9403245, 1.8761821, 4.3808956], dtype=float32)}
done in step count: 52
reward sum = 0.5929664464014994
running average episode reward sum: 0.632617941289524
{'scaleFactor': 30, 'timeStep': 53, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([11.727485 ,  7.9595056,  0.5361368], dtype=float32)}
episode index:1916
target Thresh 14.999170836627284
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([4.9019847, 8.88422  , 3.245377 ], dtype=float32)}
done in step count: 56
reward sum = 0.5696012024771592
running average episode reward sum: 0.6325850687079838
{'scaleFactor': 30, 'timeStep': 57, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([10.45927   ,  9.966128  ,  0.36628047], dtype=float32)}
episode index:1917
target Thresh 14.999174972096858
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([1.880592 , 8.699706 , 1.7415581], dtype=float32)}
done in step count: 95
reward sum = 0.38489607889348454
running average episode reward sum: 0.6324559295057864
{'scaleFactor': 30, 'timeStep': 96, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([10.697185 ,  2.5466022,  4.4648323], dtype=float32)}
episode index:1918
target Thresh 14.999179086940693
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([9.906212, 9.103776, 0.445188], dtype=float32)}
done in step count: 57
reward sum = 0.5639051904523875
running average episode reward sum: 0.6324202073905946
{'scaleFactor': 30, 'timeStep': 58, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([2.8493178, 4.9981775, 3.023102 ], dtype=float32)}
episode index:1919
target Thresh 14.999183181261657
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([1.9227316, 4.1048036, 4.7922583], dtype=float32)}
done in step count: 28
reward sum = 0.7547192872036326
running average episode reward sum: 0.6324839048279972
{'scaleFactor': 30, 'timeStep': 29, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([5.0039077, 9.771457 , 1.5130793], dtype=float32)}
episode index:1920
target Thresh 14.99918725516211
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([11.551066 ,  3.5759492,  2.2457612], dtype=float32)}
done in step count: 59
reward sum = 0.5526834771623851
running average episode reward sum: 0.6324423637412374
{'scaleFactor': 30, 'timeStep': 60, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([8.878976 , 7.0889654, 4.071052 ], dtype=float32)}
episode index:1921
target Thresh 14.9991913087439
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([7.8593597, 9.8579445, 1.2234492], dtype=float32)}
done in step count: 68
reward sum = 0.5048858887870696
running average episode reward sum: 0.6323759972090032
{'scaleFactor': 30, 'timeStep': 69, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([4.4517956, 8.471794 , 2.9608006], dtype=float32)}
episode index:1922
target Thresh 14.999195342108365
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([5.5667696, 9.589171 , 6.045811 ], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.6325619691293313
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([7.2955213, 8.594107 , 5.646604 ], dtype=float32)}
episode index:1923
target Thresh 14.999199355356343
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([9.955948, 8.443779, 4.920077], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.632747747731655
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([10.231959 ,  6.830589 ,  4.6888556], dtype=float32)}
episode index:1924
target Thresh 14.999203348588162
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([ 9.066411 , 10.075556 ,  3.5056307], dtype=float32)}
done in step count: 65
reward sum = 0.5203405226503064
running average episode reward sum: 0.6326893543679764
{'scaleFactor': 30, 'timeStep': 66, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([12.889531 ,  3.0625024,  4.816731 ], dtype=float32)}
episode index:1925
target Thresh 14.999207321903656
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([3.6354618, 6.617431 , 5.3786516], dtype=float32)}
done in step count: 30
reward sum = 0.7397003733882802
running average episode reward sum: 0.6327449156447262
{'scaleFactor': 30, 'timeStep': 31, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([2.483916 , 8.91124  , 1.6026281], dtype=float32)}
episode index:1926
target Thresh 14.999211275402155
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([8.527315 , 8.619071 , 5.2438326], dtype=float32)}
done in step count: 47
reward sum = 0.6235253948912
running average episode reward sum: 0.6327401312540913
{'scaleFactor': 30, 'timeStep': 48, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([12.331739 ,  3.2886634,  3.6222057], dtype=float32)}
episode index:1927
target Thresh 14.999215209182498
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([10.9240675,  9.078325 ,  1.722708 ], dtype=float32)}
done in step count: 143
reward sum = 0.23759255478829303
running average episode reward sum: 0.6325351791916091
{'scaleFactor': 30, 'timeStep': 144, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([10.434545,  5.758134,  5.234386], dtype=float32)}
episode index:1928
target Thresh 14.999219123343028
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([6.232041, 8.840894, 5.346127], dtype=float32)}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.6326761055243292
{'scaleFactor': 30, 'timeStep': 11, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([12.923861,  4.331504,  4.750043], dtype=float32)}
episode index:1929
target Thresh 14.999223017981604
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([11.94759  ,  9.98628  ,  2.2128327], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6328664287857155
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([11.94759  ,  9.98628  ,  2.2128327], dtype=float32)}
episode index:1930
target Thresh 14.999226893195589
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([3.7044134, 9.004448 , 0.5697659], dtype=float32)}
done in step count: 60
reward sum = 0.5471566423907612
running average episode reward sum: 0.6328220425680071
{'scaleFactor': 30, 'timeStep': 61, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([3.128911, 6.663272, 5.328622], dtype=float32)}
episode index:1931
target Thresh 14.99923074908186
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([4.8500543, 9.233702 , 6.1316137], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6330120932706117
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([4.8500543, 9.233702 , 6.1316137], dtype=float32)}
episode index:1932
target Thresh 14.99923458573682
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([7.091646, 9.279769, 4.404096], dtype=float32)}
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.633138585215634
{'scaleFactor': 30, 'timeStep': 14, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([11.186465 ,  2.482723 ,  4.8633966], dtype=float32)}
episode index:1933
target Thresh 14.999238403256385
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([3.8989537, 8.914602 , 3.9840689], dtype=float32)}
done in step count: 60
reward sum = 0.5471566423907612
running average episode reward sum: 0.6330941271273068
{'scaleFactor': 30, 'timeStep': 61, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([11.788688 , 10.558521 ,  5.3998775], dtype=float32)}
episode index:1934
target Thresh 14.99924220173599
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([10.137033 , 10.0065   ,  2.2152762], dtype=float32)}
done in step count: 82
reward sum = 0.43861750180991077
running average episode reward sum: 0.6329936224113805
{'scaleFactor': 30, 'timeStep': 83, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([3.8153892, 2.843943 , 4.5291853], dtype=float32)}
episode index:1935
target Thresh 14.999245981270601
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([9.002008 , 9.070752 , 2.3849063], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.6331780265320358
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([8.978065 , 9.059892 , 3.0087943], dtype=float32)}
episode index:1936
target Thresh 14.999249741954701
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([2.1293623, 9.290513 , 2.475472 ], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6333674028735268
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([2.1293623, 9.290513 , 2.475472 ], dtype=float32)}
episode index:1937
target Thresh 14.999253483882315
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([5.810606  , 9.3051815 , 0.37204796], dtype=float32)}
done in step count: 26
reward sum = 0.7700431458051551
running average episode reward sum: 0.6334379269926865
{'scaleFactor': 30, 'timeStep': 27, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([13.885569,  8.574556,  5.513469], dtype=float32)}
episode index:1938
target Thresh 14.999257207146984
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([ 4.8828416, 10.174931 ,  1.2142576], dtype=float32)}
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.6335638079086258
{'scaleFactor': 30, 'timeStep': 14, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([ 8.644186  , 10.731312  ,  0.29929993], dtype=float32)}
episode index:1939
target Thresh 14.999260911841793
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([11.944318  ,  8.176544  ,  0.69494194], dtype=float32)}
done in step count: 75
reward sum = 0.4705866415856499
running average episode reward sum: 0.6334797990600057
{'scaleFactor': 30, 'timeStep': 76, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([6.5697823, 8.85672  , 2.8119102], dtype=float32)}
episode index:1940
target Thresh 14.999264598059362
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([3.9242454, 9.887024 , 4.030793 ], dtype=float32)}
done in step count: 95
reward sum = 0.38489607889348454
running average episode reward sum: 0.6333517291371996
{'scaleFactor': 30, 'timeStep': 96, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([9.989641 , 7.3199196, 6.1847982], dtype=float32)}
episode index:1941
target Thresh 14.999268265891843
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([9.019432 , 9.207555 , 4.2227263], dtype=float32)}
done in step count: 21
reward sum = 0.8097278682212584
running average episode reward sum: 0.6334425510419803
{'scaleFactor': 30, 'timeStep': 22, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([7.896553 , 9.838313 , 3.4597523], dtype=float32)}
episode index:1942
target Thresh 14.999271915430931
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([1.9325966, 5.0709677, 1.9487487], dtype=float32)}
done in step count: 36
reward sum = 0.6964132180495735
running average episode reward sum: 0.6334749600316909
{'scaleFactor': 30, 'timeStep': 37, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([6.869027  , 8.765174  , 0.07717124], dtype=float32)}
episode index:1943
target Thresh 14.99927554676787
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([3.8802586, 8.816017 , 1.0230435], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.6336583576859955
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([5.4068065 , 9.829802  , 0.49063754], dtype=float32)}
episode index:1944
target Thresh 14.999279159993439
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([1.9843658, 7.3698316, 2.1475117], dtype=float32)}
done in step count: 51
reward sum = 0.598956006466161
running average episode reward sum: 0.6336405158601756
{'scaleFactor': 30, 'timeStep': 52, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([ 8.970018 , 11.924262 ,  0.5198217], dtype=float32)}
episode index:1945
target Thresh 14.99928275519797
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([ 3.8940973, 10.374418 ,  5.7380295], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.6338236399527449
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([5.859042  , 9.924658  , 0.18196172], dtype=float32)}
episode index:1946
target Thresh 14.999286332471344
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([2.1022775, 5.1442833, 3.1735678], dtype=float32)}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.6339914737329438
{'scaleFactor': 30, 'timeStep': 5, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([0.54549193, 8.745102  , 1.4175196 ], dtype=float32)}
episode index:1947
target Thresh 14.999289891902993
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([2.0361931, 6.8099003, 3.747038 ], dtype=float32)}
done in step count: 16
reward sum = 0.8514577710948755
running average episode reward sum: 0.6341031094092076
{'scaleFactor': 30, 'timeStep': 17, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([1.6127697, 8.141244 , 3.5409114], dtype=float32)}
episode index:1948
target Thresh 14.999293433581903
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([ 2.8017592, 10.301506 ,  1.3413415], dtype=float32)}
done in step count: 73
reward sum = 0.4801414565714212
running average episode reward sum: 0.6340241142050835
{'scaleFactor': 30, 'timeStep': 74, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([ 7.511693, 10.088891,  5.03498 ], dtype=float32)}
episode index:1949
target Thresh 14.999296957596615
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([ 9.97124  , 10.021344 ,  2.9432976], dtype=float32)}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6341769558633922
{'scaleFactor': 30, 'timeStep': 8, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([1.4233744, 5.997404 , 4.1718254], dtype=float32)}
episode index:1950
target Thresh 14.99930046403523
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([2.8989487, 9.169219 , 4.843329 ], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.6343593356912428
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([3.262068 , 9.019575 , 5.2113476], dtype=float32)}
episode index:1951
target Thresh 14.999303952985409
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([ 4.190255 , 10.297982 ,  1.4278823], dtype=float32)}
done in step count: 116
reward sum = 0.3116610814491425
running average episode reward sum: 0.6341940189626352
{'scaleFactor': 30, 'timeStep': 117, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([10.42694  ,  7.452799 ,  1.9837067], dtype=float32)}
episode index:1952
target Thresh 14.999307424534377
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([ 9.352087 , 10.86663  ,  2.4853263], dtype=float32)}
done in step count: 18
reward sum = 0.8345137614500875
running average episode reward sum: 0.6342965892352862
{'scaleFactor': 30, 'timeStep': 19, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([ 6.159334 , 10.756707 ,  3.4066029], dtype=float32)}
episode index:1953
target Thresh 14.999310878768922
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([9.964862, 9.076624, 5.395768], dtype=float32)}
done in step count: 25
reward sum = 0.7778213593991467
running average episode reward sum: 0.6343700410112145
{'scaleFactor': 30, 'timeStep': 26, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([0.15411842, 6.0697093 , 3.590743  ], dtype=float32)}
episode index:1954
target Thresh 14.999314315775402
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([12.076086 ,  3.8579133,  6.0615754], dtype=float32)}
done in step count: 272
reward sum = 0.06497898609824965
running average episode reward sum: 0.6340787923897756
{'scaleFactor': 30, 'timeStep': 273, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([2.631781 , 8.41378  , 2.1100187], dtype=float32)}
episode index:1955
target Thresh 14.999317735639739
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([2.0246468, 7.001606 , 3.7982888], dtype=float32)}
done in step count: 59
reward sum = 0.5526834771623851
running average episode reward sum: 0.6340371792429313
{'scaleFactor': 30, 'timeStep': 60, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([6.205234  , 8.207533  , 0.74776125], dtype=float32)}
episode index:1956
target Thresh 14.999321138447431
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([2.587828 , 9.083859 , 1.7844609], dtype=float32)}
done in step count: 198
reward sum = 0.136700004956598
running average episode reward sum: 0.6337830468084467
{'scaleFactor': 30, 'timeStep': 199, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([3.5878134 , 0.05215801, 5.3213577 ], dtype=float32)}
episode index:1957
target Thresh 14.999324524283551
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([1.8014202, 8.087254 , 4.3469706], dtype=float32)}
done in step count: 147
reward sum = 0.22823046013534068
running average episode reward sum: 0.6335759208704115
{'scaleFactor': 30, 'timeStep': 148, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([4.0547104, 9.226591 , 1.4922366], dtype=float32)}
episode index:1958
target Thresh 14.99932789323274
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([3.4804873, 5.4235086, 0.9867679], dtype=float32)}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6337330950554705
{'scaleFactor': 30, 'timeStep': 7, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([ 7.3165536, 10.299964 ,  0.9023212], dtype=float32)}
episode index:1959
target Thresh 14.999331245379228
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([ 9.002739 , 10.325283 ,  1.7371253], dtype=float32)}
done in step count: 36
reward sum = 0.6964132180495735
running average episode reward sum: 0.6337650747100594
{'scaleFactor': 30, 'timeStep': 37, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([2.6050673, 7.157977 , 4.148495 ], dtype=float32)}
episode index:1960
target Thresh 14.999334580806813
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([ 5.02682  , 10.799942 ,  2.6757479], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.633946734539376
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([ 4.960042 , 10.9420595,  2.472182 ], dtype=float32)}
episode index:1961
target Thresh 14.999337899598887
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([2.07788  , 8.362818 , 0.9982705], dtype=float32)}
done in step count: 91
reward sum = 0.40068465295154054
running average episode reward sum: 0.633827844589535
{'scaleFactor': 30, 'timeStep': 92, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([11.834575 ,  9.559855 ,  3.8929615], dtype=float32)}
episode index:1962
target Thresh 14.999341201838414
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([12.169018 ,  6.1883993,  0.0515995], dtype=float32)}
done in step count: 43
reward sum = 0.6491026283684022
running average episode reward sum: 0.6338356259363404
{'scaleFactor': 30, 'timeStep': 44, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([ 8.833303 , 11.751416 ,  3.4792392], dtype=float32)}
episode index:1963
target Thresh 14.999344487607951
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([12.108866 ,  2.0341144,  6.2300987], dtype=float32)}
done in step count: 140
reward sum = 0.24486529903492948
running average episode reward sum: 0.6336375758717266
{'scaleFactor': 30, 'timeStep': 141, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([3.2679243, 7.026901 , 4.0431833], dtype=float32)}
episode index:1964
target Thresh 14.999347756989646
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([11.08121  , 10.096965 ,  5.8136125], dtype=float32)}
done in step count: 130
reward sum = 0.27075425951199406
running average episode reward sum: 0.6334529024282866
{'scaleFactor': 30, 'timeStep': 131, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([3.7841861, 4.308588 , 4.764831 ], dtype=float32)}
episode index:1965
target Thresh 14.999351010065233
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([4.0625052, 9.0950365, 5.2789674], dtype=float32)}
done in step count: 25
reward sum = 0.7778213593991467
running average episode reward sum: 0.6335263350106726
{'scaleFactor': 30, 'timeStep': 26, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([9.335241 , 7.057208 , 4.5786834], dtype=float32)}
episode index:1966
target Thresh 14.999354246916035
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([5.838024 , 8.628769 , 3.4889574], dtype=float32)}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.6336686791451276
{'scaleFactor': 30, 'timeStep': 10, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([6.001873 , 8.276735 , 2.8368042], dtype=float32)}
episode index:1967
target Thresh 14.999357467622977
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([7.037976 , 9.019747 , 1.9288791], dtype=float32)}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.6338108786209093
{'scaleFactor': 30, 'timeStep': 10, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([2.867371 , 9.88474  , 3.0718646], dtype=float32)}
episode index:1968
target Thresh 14.999360672266578
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([11.941817  ,  7.782049  ,  0.33850303], dtype=float32)}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6339623537195818
{'scaleFactor': 30, 'timeStep': 8, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([12.732364 ,  8.915534 ,  0.6811489], dtype=float32)}
episode index:1969
target Thresh 14.99936386092695
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([12.039358 ,  1.8158741,  4.8903823], dtype=float32)}
done in step count: 60
reward sum = 0.5471566423907612
running average episode reward sum: 0.6339182899067245
{'scaleFactor': 30, 'timeStep': 61, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([ 6.1134734, 10.194801 ,  3.173861 ], dtype=float32)}
episode index:1970
target Thresh 14.999367033683814
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([1.9165748, 4.2086353, 3.1364121], dtype=float32)}
done in step count: 55
reward sum = 0.5753547499769285
running average episode reward sum: 0.6338885773040204
{'scaleFactor': 30, 'timeStep': 56, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([4.9216695, 9.5541725, 1.0372473], dtype=float32)}
episode index:1971
target Thresh 14.999370190616487
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([6.9187493, 8.857864 , 0.6069175], dtype=float32)}
done in step count: 78
reward sum = 0.4566097477439145
running average episode reward sum: 0.6337986793174281
{'scaleFactor': 30, 'timeStep': 79, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([3.235099 , 8.1518135, 2.3008642], dtype=float32)}
episode index:1972
target Thresh 14.999373331803891
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([11.076042,  9.19244 ,  5.506077], dtype=float32)}
done in step count: 176
reward sum = 0.17052743088958636
running average episode reward sum: 0.633563873818985
{'scaleFactor': 30, 'timeStep': 177, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([1.7406815, 3.5437138, 4.879357 ], dtype=float32)}
episode index:1973
target Thresh 14.999376457324558
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([12.020696,  6.897859,  3.927484], dtype=float32)}
done in step count: 52
reward sum = 0.5929664464014994
running average episode reward sum: 0.6335433077463318
{'scaleFactor': 30, 'timeStep': 53, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([12.624028 ,  7.0433307,  1.2414174], dtype=float32)}
episode index:1974
target Thresh 14.999379567256627
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([11.783328,  5.173833,  5.620411], dtype=float32)}
done in step count: 42
reward sum = 0.6556592205741436
running average episode reward sum: 0.6335545056768775
{'scaleFactor': 30, 'timeStep': 43, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([8.056501 , 9.009852 , 2.7577147], dtype=float32)}
episode index:1975
target Thresh 14.999382661677844
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([8.784254, 9.122411, 4.764294], dtype=float32)}
done in step count: 92
reward sum = 0.3966778064220251
running average episode reward sum: 0.6334346288047851
{'scaleFactor': 30, 'timeStep': 93, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([3.430039 , 8.85781  , 2.0773482], dtype=float32)}
episode index:1976
target Thresh 14.999385740665572
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([1.8518608, 7.077835 , 2.80802  ], dtype=float32)}
done in step count: 28
reward sum = 0.7547192872036326
running average episode reward sum: 0.6334959766340207
{'scaleFactor': 30, 'timeStep': 29, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([10.933739 ,  5.527218 ,  5.5373178], dtype=float32)}
episode index:1977
target Thresh 14.999388804296782
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([11.92311 ,  6.706462,  4.707058], dtype=float32)}
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.6336238274404322
{'scaleFactor': 30, 'timeStep': 13, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([ 9.982702  , 10.691823  ,  0.31743848], dtype=float32)}
episode index:1978
target Thresh 14.99939185264807
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([2.0719206, 5.05854  , 2.6865137], dtype=float32)}
done in step count: 172
reward sum = 0.17752252675876343
running average episode reward sum: 0.6333933568488801
{'scaleFactor': 30, 'timeStep': 173, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([11.724982 , 10.9108515,  1.5589089], dtype=float32)}
episode index:1979
target Thresh 14.999394885795642
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([11.136164 ,  4.1752987,  1.7029634], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6335785117191585
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([11.136164 ,  4.1752987,  1.7029634], dtype=float32)}
episode index:1980
target Thresh 14.999397903815325
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([12.255982,  6.000692,  4.233846], dtype=float32)}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6337339390980994
{'scaleFactor': 30, 'timeStep': 7, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([8.3742075, 8.310659 , 2.381826 ], dtype=float32)}
episode index:1981
target Thresh 14.999400906782576
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([9.715992  , 9.638621  , 0.26716697], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.6339136898856381
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([11.675295  ,  9.740966  ,  0.14968032], dtype=float32)}
episode index:1982
target Thresh 14.999403894772461
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([6.8314815, 9.058333 , 4.8658843], dtype=float32)}
done in step count: 26
reward sum = 0.7700431458051551
running average episode reward sum: 0.6339823381236208
{'scaleFactor': 30, 'timeStep': 27, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([1.8483815, 2.9005375, 3.9321218], dtype=float32)}
episode index:1983
target Thresh 14.999406867859689
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([ 5.1138754, 10.03971  ,  4.5277452], dtype=float32)}
done in step count: 150
reward sum = 0.22145178723886091
running average episode reward sum: 0.6337744094185378
{'scaleFactor': 30, 'timeStep': 151, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([ 8.098939 , 10.148962 ,  3.2213883], dtype=float32)}
episode index:1984
target Thresh 14.99940982611858
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([7.154867 , 9.091014 , 3.4274347], dtype=float32)}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.6339488807488055
{'scaleFactor': 30, 'timeStep': 3, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([3.0581903, 9.847457 , 3.0912545], dtype=float32)}
episode index:1985
target Thresh 14.999412769623094
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([10.967285 ,  8.726636 ,  2.0222614], dtype=float32)}
done in step count: 73
reward sum = 0.4801414565714212
running average episode reward sum: 0.6338714349158864
{'scaleFactor': 30, 'timeStep': 74, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([3.711488, 5.34743 , 3.766274], dtype=float32)}
episode index:1986
target Thresh 14.999415698446818
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([5.7401056, 9.998905 , 4.473164 ], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6340556969013338
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([5.7401056, 9.998905 , 4.473164 ], dtype=float32)}
episode index:1987
target Thresh 14.99941861266297
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([0.66917753, 4.4733615 , 2.3020926 ], dtype=float32)}
done in step count: 225
reward sum = 0.10421225282987544
running average episode reward sum: 0.6337891760542154
{'scaleFactor': 30, 'timeStep': 226, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([10.657848 ,  7.4888716,  0.7222797], dtype=float32)}
episode index:1988
target Thresh 14.999421512344412
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([11.891979 ,  5.922542 ,  5.4949956], dtype=float32)}
done in step count: 38
reward sum = 0.682554595010387
running average episode reward sum: 0.6338136936102516
{'scaleFactor': 30, 'timeStep': 39, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([3.9921625, 9.06175  , 1.7537701], dtype=float32)}
episode index:1989
target Thresh 14.999424397563631
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([9.925559 , 4.0127816, 2.9101005], dtype=float32)}
done in step count: 15
reward sum = 0.8600583546412884
running average episode reward sum: 0.6339273843946893
{'scaleFactor': 30, 'timeStep': 16, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([9.681327 , 9.654559 , 1.4647124], dtype=float32)}
episode index:1990
target Thresh 14.999427268392758
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([ 8.300106 , 10.011555 ,  2.3522272], dtype=float32)}
done in step count: 38
reward sum = 0.682554595010387
running average episode reward sum: 0.6339518079057971
{'scaleFactor': 30, 'timeStep': 39, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([10.785159 ,  8.9735155,  0.2772047], dtype=float32)}
episode index:1991
target Thresh 14.999430124903567
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([7.871695, 9.02152 , 2.320218], dtype=float32)}
done in step count: 115
reward sum = 0.31480917318095203
running average episode reward sum: 0.6337915957397706
{'scaleFactor': 30, 'timeStep': 116, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([10.208276,  5.265953,  5.197408], dtype=float32)}
episode index:1992
target Thresh 14.999432967167467
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([5.8332224, 8.898927 , 5.323524 ], dtype=float32)}
done in step count: 15
reward sum = 0.8600583546412884
running average episode reward sum: 0.633905126476801
{'scaleFactor': 30, 'timeStep': 16, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([9.212409 , 8.164496 , 5.0189166], dtype=float32)}
episode index:1993
target Thresh 14.999435795255517
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([12.09223  ,  5.2255216,  5.1401324], dtype=float32)}
done in step count: 236
reward sum = 0.09330521652106866
running average episode reward sum: 0.6336340131819385
{'scaleFactor': 30, 'timeStep': 237, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([1.7198905, 6.203191 , 3.842665 ], dtype=float32)}
episode index:1994
target Thresh 14.999438609238421
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([1.6894735, 6.0049286, 5.8100133], dtype=float32)}
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.6337651932526536
{'scaleFactor': 30, 'timeStep': 12, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([7.2274146, 8.462716 , 0.59774  ], dtype=float32)}
episode index:1995
target Thresh 14.999441409186526
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([2.0054898, 7.0180926, 3.181265 ], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6339486776247715
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([2.0054898, 7.0180926, 3.181265 ], dtype=float32)}
episode index:1996
target Thresh 14.99944419516983
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([11.179048 ,  9.002131 ,  1.1553111], dtype=float32)}
done in step count: 142
reward sum = 0.2399924795841344
running average episode reward sum: 0.6337514036147361
{'scaleFactor': 30, 'timeStep': 143, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([0.41869074, 4.657972  , 4.7269745 ], dtype=float32)}
episode index:1997
target Thresh 14.999446967257985
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([11.98455  ,  3.1761794,  4.8707805], dtype=float32)}
done in step count: 399
reward sum = 0.0
running average episode reward sum: 0.633434210720034
{'scaleFactor': 30, 'timeStep': 400, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([10.5436   ,  5.4411216,  3.9493928], dtype=float32)}
episode index:1998
target Thresh 14.999449725520295
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([ 4.930867 , 10.140976 ,  1.9301493], dtype=float32)}
done in step count: 22
reward sum = 0.8016305895390459
running average episode reward sum: 0.6335183509795733
{'scaleFactor': 30, 'timeStep': 23, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([13.381875,  4.623452,  4.296302], dtype=float32)}
episode index:1999
target Thresh 14.99945247002571
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([12.19495  ,  3.874934 ,  2.9252408], dtype=float32)}
done in step count: 46
reward sum = 0.6298236312032323
running average episode reward sum: 0.633516503619685
{'scaleFactor': 30, 'timeStep': 47, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([2.508475, 4.792685, 4.915616], dtype=float32)}
episode index:2000
target Thresh 14.99945520084285
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([8.196038 , 9.79937  , 1.7055178], dtype=float32)}
done in step count: 20
reward sum = 0.8179069375972308
running average episode reward sum: 0.6336086527621027
{'scaleFactor': 30, 'timeStep': 21, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([1.16472  , 3.8785534, 3.9094946], dtype=float32)}
episode index:2001
target Thresh 14.999457918039981
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([1.8625991, 9.250677 , 2.7190547], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6337916654230606
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([1.8625991, 9.250677 , 2.7190547], dtype=float32)}
episode index:2002
target Thresh 14.999460621685039
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([7.1171713, 9.526082 , 3.5002968], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.6339695028342323
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([5.2849483, 8.430735 , 3.4768379], dtype=float32)}
episode index:2003
target Thresh 14.999463311845606
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([1.8212318, 9.982408 , 4.5089335], dtype=float32)}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6341182532559253
{'scaleFactor': 30, 'timeStep': 8, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([9.640524, 9.486684, 6.198915], dtype=float32)}
episode index:2004
target Thresh 14.999465988588943
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([ 6.840579 , 11.3418865,  2.313252 ], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.634300737917643
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([ 6.840579 , 11.3418865,  2.313252 ], dtype=float32)}
episode index:2005
target Thresh 14.999468651981967
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([6.1386228, 8.967508 , 5.9491158], dtype=float32)}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.634463397574713
{'scaleFactor': 30, 'timeStep': 5, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([12.700227 ,  5.3199925,  5.964835 ], dtype=float32)}
episode index:2006
target Thresh 14.999471302091262
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([8.166967, 9.060913, 4.340223], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6346455284179742
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([8.166967, 9.060913, 4.340223], dtype=float32)}
episode index:2007
target Thresh 14.999473938983083
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([7.0958524, 8.570785 , 3.560414 ], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6348274778560131
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([7.0958524, 8.570785 , 3.560414 ], dtype=float32)}
episode index:2008
target Thresh 14.99947656272335
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([11.098946,  9.057322,  5.604684], dtype=float32)}
done in step count: 21
reward sum = 0.8097278682212584
running average episode reward sum: 0.6349145362882506
{'scaleFactor': 30, 'timeStep': 22, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([7.7837815, 8.079802 , 3.951449 ], dtype=float32)}
episode index:2009
target Thresh 14.99947917337766
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([1.9496734, 3.0978465, 2.2758086], dtype=float32)}
done in step count: 252
reward sum = 0.07944545169055386
running average episode reward sum: 0.6346381835098438
{'scaleFactor': 30, 'timeStep': 253, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([11.973875 ,  7.0891075,  6.205819 ], dtype=float32)}
episode index:2010
target Thresh 14.999481771011277
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([6.5934386, 7.0696387, 4.967868 ], dtype=float32)}
done in step count: 82
reward sum = 0.43861750180991077
running average episode reward sum: 0.634540709277273
{'scaleFactor': 30, 'timeStep': 83, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([1.3491069, 5.0102153, 4.092462 ], dtype=float32)}
episode index:2011
target Thresh 14.99948435568914
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([ 2.9340339, 10.025805 ,  2.0959938], dtype=float32)}
done in step count: 44
reward sum = 0.6426116020847181
running average episode reward sum: 0.6345447206554079
{'scaleFactor': 30, 'timeStep': 45, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([12.098149  ,  9.9239    ,  0.09909933], dtype=float32)}
episode index:2012
target Thresh 14.99948692747587
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([10.963531,  9.482913,  6.055814], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6347262682358076
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([10.963531,  9.482913,  6.055814], dtype=float32)}
episode index:2013
target Thresh 14.99948948643576
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([12.133532 ,  8.871231 ,  5.5357804], dtype=float32)}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.6348692763918116
{'scaleFactor': 30, 'timeStep': 9, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([10.949699 ,  8.149078 ,  3.9380908], dtype=float32)}
episode index:2014
target Thresh 14.999492032632784
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([12.240392,  5.106007,  0.741947], dtype=float32)}
done in step count: 31
reward sum = 0.7323033696543975
running average episode reward sum: 0.6349176307805275
{'scaleFactor': 30, 'timeStep': 32, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([9.90458  , 7.5557265, 2.0610797], dtype=float32)}
episode index:2015
target Thresh 14.999494566130597
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([1.6037416, 5.917235 , 3.053428 ], dtype=float32)}
done in step count: 38
reward sum = 0.682554595010387
running average episode reward sum: 0.6349412602270701
{'scaleFactor': 30, 'timeStep': 39, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([4.7719827, 9.807839 , 1.1349272], dtype=float32)}
episode index:2016
target Thresh 14.999497086992537
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([11.868045 ,  2.7901564,  4.613677 ], dtype=float32)}
done in step count: 23
reward sum = 0.7936142836436554
running average episode reward sum: 0.6350199280621799
{'scaleFactor': 30, 'timeStep': 24, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([10.636016 ,  6.6920376,  1.5961366], dtype=float32)}
episode index:2017
target Thresh 14.999499595281627
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([11.73598  ,  2.9335582,  3.8294253], dtype=float32)}
done in step count: 90
reward sum = 0.4047319726783238
running average episode reward sum: 0.6349058111368162
{'scaleFactor': 30, 'timeStep': 91, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([6.296521 , 7.6733074, 3.3818355], dtype=float32)}
episode index:2018
target Thresh 14.999502091060572
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([12.73733  ,  7.499125 ,  5.4377975], dtype=float32)}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.6350719296057925
{'scaleFactor': 30, 'timeStep': 4, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([13.028981 ,  3.3859637,  5.313141 ], dtype=float32)}
episode index:2019
target Thresh 14.999504574391768
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([8.4229965, 9.644503 , 3.0678794], dtype=float32)}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.6352143418656054
{'scaleFactor': 30, 'timeStep': 9, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([2.7760496, 8.973994 , 3.440091 ], dtype=float32)}
episode index:2020
target Thresh 14.999507045337296
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([3.3831096, 6.4699035, 0.9119685], dtype=float32)}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.6353801432798234
{'scaleFactor': 30, 'timeStep': 4, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([8.726446, 8.813593, 6.138464], dtype=float32)}
episode index:2021
target Thresh 14.999509503958933
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([1.6923063, 9.929614 , 1.1072748], dtype=float32)}
done in step count: 110
reward sum = 0.33103308832101386
running average episode reward sum: 0.6352296254484886
{'scaleFactor': 30, 'timeStep': 111, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([5.5147295, 9.23074  , 4.596267 ], dtype=float32)}
episode index:2022
target Thresh 14.999511950318144
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([12.1127615,  7.070695 ,  0.8841622], dtype=float32)}
done in step count: 176
reward sum = 0.17052743088958636
running average episode reward sum: 0.6349999160097546
{'scaleFactor': 30, 'timeStep': 177, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([5.743699 , 9.884586 , 2.6773453], dtype=float32)}
episode index:2023
target Thresh 14.999514384476086
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([2.1330187, 4.9044747, 0.807065 ], dtype=float32)}
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.6351241180629691
{'scaleFactor': 30, 'timeStep': 13, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([0.5320727, 3.6370847, 3.959305 ], dtype=float32)}
episode index:2024
target Thresh 14.999516806493617
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([8.141579 , 9.261922 , 4.6181726], dtype=float32)}
done in step count: 66
reward sum = 0.5151371174238033
running average episode reward sum: 0.6350648652231473
{'scaleFactor': 30, 'timeStep': 67, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([0.9823594, 9.910717 , 1.3394694], dtype=float32)}
episode index:2025
target Thresh 14.999519216431285
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([ 7.207188 , 11.225354 ,  0.2642628], dtype=float32)}
done in step count: 45
reward sum = 0.6361854860638709
running average episode reward sum: 0.6350654183430094
{'scaleFactor': 30, 'timeStep': 46, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([13.502531 ,  2.3364644,  4.7210107], dtype=float32)}
episode index:2026
target Thresh 14.999521614349337
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([3.5674412 , 3.37565   , 0.93903387], dtype=float32)}
done in step count: 63
reward sum = 0.5309055429551132
running average episode reward sum: 0.6350140321193352
{'scaleFactor': 30, 'timeStep': 64, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([13.939465 ,  6.5876913,  4.922176 ], dtype=float32)}
episode index:2027
target Thresh 14.999524000307725
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([12.027394 ,  7.0957375,  1.4434203], dtype=float32)}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.63516050712712
{'scaleFactor': 30, 'timeStep': 8, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([2.3176916, 9.3485155, 2.9371657], dtype=float32)}
episode index:2028
target Thresh 14.999526374366093
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([10.367252 ,  3.8957584,  2.4396975], dtype=float32)}
done in step count: 65
reward sum = 0.5203405226503064
running average episode reward sum: 0.6351039176818382
{'scaleFactor': 30, 'timeStep': 66, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([ 2.6350794, 11.925018 ,  2.7048082], dtype=float32)}
episode index:2029
target Thresh 14.999528736583798
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([3.2235136, 6.4256697, 1.0439181], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6352836694465269
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([3.2235136, 6.4256697, 1.0439181], dtype=float32)}
episode index:2030
target Thresh 14.999531087019891
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([11.922707 ,  4.8875203,  4.308452 ], dtype=float32)}
done in step count: 79
reward sum = 0.45204365026647536
running average episode reward sum: 0.635193447871352
{'scaleFactor': 30, 'timeStep': 80, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([7.885254, 9.017743, 2.095189], dtype=float32)}
episode index:2031
target Thresh 14.999533425733137
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([ 7.0422225, 10.059069 ,  4.3955016], dtype=float32)}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6353441795158057
{'scaleFactor': 30, 'timeStep': 7, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([6.3710327, 8.077362 , 4.021271 ], dtype=float32)}
episode index:2032
target Thresh 14.999535752782
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([11.961454  ,  7.895343  ,  0.49513504], dtype=float32)}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.6355089384043862
{'scaleFactor': 30, 'timeStep': 4, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([12.047728,  8.145403,  5.103618], dtype=float32)}
episode index:2033
target Thresh 14.99953806822466
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([9.757531, 9.113215, 3.469511], dtype=float32)}
done in step count: 14
reward sum = 0.8687458127689782
running average episode reward sum: 0.6356236074674957
{'scaleFactor': 30, 'timeStep': 15, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([11.122038 ,  9.451316 ,  0.9002949], dtype=float32)}
episode index:2034
target Thresh 14.999540372119002
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([2.0885882, 5.1362476, 6.0613513], dtype=float32)}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6357785786922782
{'scaleFactor': 30, 'timeStep': 6, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([5.306161 , 9.473617 , 1.4233934], dtype=float32)}
episode index:2035
target Thresh 14.999542664522622
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([11.702138 ,  4.0963807,  5.8502913], dtype=float32)}
done in step count: 36
reward sum = 0.6964132180495735
running average episode reward sum: 0.6358083599493299
{'scaleFactor': 30, 'timeStep': 37, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([9.502902  , 9.895399  , 0.10071862], dtype=float32)}
episode index:2036
target Thresh 14.999544945492831
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([11.875889 ,  1.9764953,  4.358618 ], dtype=float32)}
done in step count: 51
reward sum = 0.598956006466161
running average episode reward sum: 0.6357902684650475
{'scaleFactor': 30, 'timeStep': 52, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([10.431499 ,  8.611731 ,  2.4425895], dtype=float32)}
episode index:2037
target Thresh 14.999547215086654
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([ 8.944987, 10.098147,  2.258951], dtype=float32)}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.6359496432155554
{'scaleFactor': 30, 'timeStep': 5, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([ 4.903299 , 11.163523 ,  2.5078018], dtype=float32)}
episode index:2038
target Thresh 14.99954947336083
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([ 5.179699 , 10.183276 ,  6.1115284], dtype=float32)}
done in step count: 379
reward sum = 0.022168624768315548
running average episode reward sum: 0.6356486226081757
{'scaleFactor': 30, 'timeStep': 380, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([2.2871394, 8.584097 , 3.4241734], dtype=float32)}
episode index:2039
target Thresh 14.999551720371818
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([ 4.314746, 10.082836,  4.046386], dtype=float32)}
done in step count: 134
reward sum = 0.26008546137772603
running average episode reward sum: 0.6354645230193372
{'scaleFactor': 30, 'timeStep': 135, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([13.304738 ,  3.5730462,  4.7987995], dtype=float32)}
episode index:2040
target Thresh 14.999553956175792
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([12.100961 ,  6.130352 ,  3.3776402], dtype=float32)}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6356144571821896
{'scaleFactor': 30, 'timeStep': 7, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([7.5949135, 8.801278 , 1.95591  ], dtype=float32)}
episode index:2041
target Thresh 14.999556180828645
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([8.082037, 8.451861, 4.496277], dtype=float32)}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6357689016448329
{'scaleFactor': 30, 'timeStep': 6, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([3.3458357, 6.7591453, 3.6017876], dtype=float32)}
episode index:2042
target Thresh 14.999558394385996
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([11.822994 ,  1.9997665,  4.074735 ], dtype=float32)}
done in step count: 160
reward sum = 0.2002770268574893
running average episode reward sum: 0.6355557387105268
{'scaleFactor': 30, 'timeStep': 161, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([6.521927 , 8.070873 , 2.8440754], dtype=float32)}
episode index:2043
target Thresh 14.999560596903185
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([1.9725378, 6.2424803, 1.0224009], dtype=float32)}
done in step count: 29
reward sum = 0.7471720943315961
running average episode reward sum: 0.63561034553813
{'scaleFactor': 30, 'timeStep': 30, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([7.7075996, 7.4471035, 6.1464376], dtype=float32)}
episode index:2044
target Thresh 14.999562788435274
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([3.00576  , 9.217635 , 2.9239554], dtype=float32)}
done in step count: 27
reward sum = 0.7623427143471035
running average episode reward sum: 0.6356723173566186
{'scaleFactor': 30, 'timeStep': 28, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([ 9.123945 , 10.430639 ,  5.9169593], dtype=float32)}
episode index:2045
target Thresh 14.99956496903705
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([10.116245 , 10.155614 ,  2.2002842], dtype=float32)}
done in step count: 40
reward sum = 0.6689717585696803
running average episode reward sum: 0.6356885927433307
{'scaleFactor': 30, 'timeStep': 41, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([10.01299  ,  6.5683527,  5.545295 ], dtype=float32)}
episode index:2046
target Thresh 14.999567138763028
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([12.102687,  8.858334,  5.780301], dtype=float32)}
done in step count: 25
reward sum = 0.7778213593991467
running average episode reward sum: 0.6357580274119461
{'scaleFactor': 30, 'timeStep': 26, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([6.64196  , 8.056925 , 2.6745696], dtype=float32)}
episode index:2047
target Thresh 14.999569297667454
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([12.291846 ,  2.8351827,  0.8771812], dtype=float32)}
done in step count: 76
reward sum = 0.46588077516979337
running average episode reward sum: 0.6356750795348748
{'scaleFactor': 30, 'timeStep': 77, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([11.862659,  8.231264,  3.493189], dtype=float32)}
episode index:2048
target Thresh 14.999571445804301
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([2.2976909, 5.0927505, 1.5170945], dtype=float32)}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.6358062200890348
{'scaleFactor': 30, 'timeStep': 11, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([2.547451  , 8.535015  , 0.15005553], dtype=float32)}
episode index:2049
target Thresh 14.999573583227267
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([ 8.405674 , 10.230641 ,  2.1580367], dtype=float32)}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.6359693872987475
{'scaleFactor': 30, 'timeStep': 4, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([ 6.714055 , 10.403939 ,  3.0270746], dtype=float32)}
episode index:2050
target Thresh 14.999575709989795
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([ 4.110872 , 10.108578 ,  1.9118958], dtype=float32)}
done in step count: 76
reward sum = 0.46588077516979337
running average episode reward sum: 0.6358864576975144
{'scaleFactor': 30, 'timeStep': 77, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([ 6.8879313, 10.273954 ,  0.8020797], dtype=float32)}
episode index:2051
target Thresh 14.999577826145048
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([8.988152, 8.843746, 3.068296], dtype=float32)}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.6360494267727106
{'scaleFactor': 30, 'timeStep': 4, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([5.05649  , 8.102584 , 3.1974869], dtype=float32)}
episode index:2052
target Thresh 14.999579931745936
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([7.8915677, 9.012705 , 3.7562587], dtype=float32)}
done in step count: 44
reward sum = 0.6426116020847181
running average episode reward sum: 0.6360526231562041
{'scaleFactor': 30, 'timeStep': 45, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([9.461256, 9.249083, 5.915231], dtype=float32)}
episode index:2053
target Thresh 14.999582026845093
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([11.949038 ,  5.8114767,  0.789865 ], dtype=float32)}
done in step count: 399
reward sum = 0.0
running average episode reward sum: 0.6357429578090005
{'scaleFactor': 30, 'timeStep': 400, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([9.908256, 6.339007, 3.267608], dtype=float32)}
episode index:2054
target Thresh 14.9995841114949
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([6.535748 , 7.856598 , 3.7515936], dtype=float32)}
done in step count: 14
reward sum = 0.8687458127689782
running average episode reward sum: 0.6358563411934093
{'scaleFactor': 30, 'timeStep': 15, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([1.4133517, 2.8624704, 4.2930136], dtype=float32)}
episode index:2055
target Thresh 14.999586185747471
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([12.214931 ,  6.166247 ,  0.5186194], dtype=float32)}
done in step count: 119
reward sum = 0.30240443566902153
running average episode reward sum: 0.6356941564144578
{'scaleFactor': 30, 'timeStep': 120, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([3.8135011, 3.007889 , 3.9528089], dtype=float32)}
episode index:2056
target Thresh 14.999588249654668
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([11.254556 , 10.015154 ,  1.1418175], dtype=float32)}
done in step count: 126
reward sum = 0.2818606955404635
running average episode reward sum: 0.6355221420922049
{'scaleFactor': 30, 'timeStep': 127, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([1.3029151, 7.4103384, 0.9717808], dtype=float32)}
episode index:2057
target Thresh 14.999590303268082
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([ 9.44713  , 10.466458 ,  2.4964437], dtype=float32)}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.6356800982962418
{'scaleFactor': 30, 'timeStep': 5, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([6.344816 , 9.2302065, 4.0262623], dtype=float32)}
episode index:2058
target Thresh 14.999592346639057
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([ 6.168176, 10.033664,  5.846692], dtype=float32)}
done in step count: 16
reward sum = 0.8514577710948755
running average episode reward sum: 0.6357848956118312
{'scaleFactor': 30, 'timeStep': 17, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([3.6869264, 6.3779135, 4.2288485], dtype=float32)}
episode index:2059
target Thresh 14.999594379818678
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([12.020658 ,  7.194739 ,  3.1522796], dtype=float32)}
done in step count: 154
reward sum = 0.2127257032290187
running average episode reward sum: 0.6355795270718396
{'scaleFactor': 30, 'timeStep': 155, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([0.03879353, 3.2431352 , 3.1054265 ], dtype=float32)}
episode index:2060
target Thresh 14.999596402857772
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([11.933327 ,  3.1254776,  1.207658 ], dtype=float32)}
done in step count: 346
reward sum = 0.03088711398143024
running average episode reward sum: 0.6352861294914949
{'scaleFactor': 30, 'timeStep': 347, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([3.5209417, 5.5981684, 4.26933  ], dtype=float32)}
episode index:2061
target Thresh 14.999598415806915
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([1.896646 , 3.0616958, 3.534996 ], dtype=float32)}
done in step count: 240
reward sum = 0.08962861870232462
running average episode reward sum: 0.635021504122538
{'scaleFactor': 30, 'timeStep': 241, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([12.066492 ,  4.6387205,  5.343652 ], dtype=float32)}
episode index:2062
target Thresh 14.999600418716435
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([5.817352  , 8.680898  , 0.23120736], dtype=float32)}
done in step count: 27
reward sum = 0.7623427143471035
running average episode reward sum: 0.6350832206568204
{'scaleFactor': 30, 'timeStep': 28, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([11.487832 ,  2.9348946,  4.0974646], dtype=float32)}
episode index:2063
target Thresh 14.9996024116364
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([11.96369  ,  4.120672 ,  2.1716728], dtype=float32)}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.6352456314026262
{'scaleFactor': 30, 'timeStep': 4, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([8.876883 , 8.234707 , 2.5867164], dtype=float32)}
episode index:2064
target Thresh 14.999604394616636
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([10.533088 ,  7.9539785,  5.921059 ], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6354222679007363
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([10.533088 ,  7.9539785,  5.921059 ], dtype=float32)}
episode index:2065
target Thresh 14.999606367706718
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([3.920765 , 7.664099 , 0.1481868], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.6355938931340854
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([5.97493  , 7.2773128, 6.053043 ], dtype=float32)}
episode index:2066
target Thresh 14.99960833095597
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([11.568079 ,  8.289723 ,  3.7532535], dtype=float32)}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6357418787442776
{'scaleFactor': 30, 'timeStep': 7, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([9.121189 , 7.9992285, 3.4878085], dtype=float32)}
episode index:2067
target Thresh 14.999610284413478
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([ 8.942709 , 10.1573715,  4.926455 ], dtype=float32)}
done in step count: 59
reward sum = 0.5526834771623851
running average episode reward sum: 0.6357017151071489
{'scaleFactor': 30, 'timeStep': 60, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([1.9446421, 8.2556715, 2.117211 ], dtype=float32)}
episode index:2068
target Thresh 14.999612228128074
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([5.3742275, 8.672133 , 2.876243 ], dtype=float32)}
done in step count: 20
reward sum = 0.8179069375972308
running average episode reward sum: 0.6357897794969459
{'scaleFactor': 30, 'timeStep': 21, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([9.140118, 9.377719, 5.638108], dtype=float32)}
episode index:2069
target Thresh 14.999614162148355
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([11.939432 ,  4.7912517,  4.179339 ], dtype=float32)}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.6359195342290772
{'scaleFactor': 30, 'timeStep': 11, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([8.922217 , 9.698548 , 1.0865993], dtype=float32)}
episode index:2070
target Thresh 14.999616086522668
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([12.251923,  9.031695,  4.751053], dtype=float32)}
done in step count: 53
reward sum = 0.5870367819374844
running average episode reward sum: 0.6358959307755323
{'scaleFactor': 30, 'timeStep': 54, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([ 6.2005453, 11.519263 ,  3.2100291], dtype=float32)}
episode index:2071
target Thresh 14.999618001299124
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([12.160247 ,  1.7184707,  5.532958 ], dtype=float32)}
done in step count: 89
reward sum = 0.40882017442254925
running average episode reward sum: 0.6357863382290299
{'scaleFactor': 30, 'timeStep': 90, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([6.614062 , 9.81868  , 2.5987442], dtype=float32)}
episode index:2072
target Thresh 14.999619906525593
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([9.022007 , 9.777403 , 2.6792676], dtype=float32)}
done in step count: 92
reward sum = 0.3966778064220251
running average episode reward sum: 0.6356709940265182
{'scaleFactor': 30, 'timeStep': 93, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([3.9377043, 3.4887016, 4.530781 ], dtype=float32)}
episode index:2073
target Thresh 14.999621802249704
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([ 2.694616, 10.003387,  2.455233], dtype=float32)}
done in step count: 72
reward sum = 0.48499137027416284
running average episode reward sum: 0.6355983423275055
{'scaleFactor': 30, 'timeStep': 73, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([6.9146495, 9.477441 , 5.390954 ], dtype=float32)}
episode index:2074
target Thresh 14.999623688518854
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([2.0605211, 5.3505373, 4.8060045], dtype=float32)}
done in step count: 51
reward sum = 0.598956006466161
running average episode reward sum: 0.6355806833704638
{'scaleFactor': 30, 'timeStep': 52, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([ 3.6626236, 10.584175 ,  3.3017209], dtype=float32)}
episode index:2075
target Thresh 14.999625565380196
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([9.037194 , 8.980198 , 3.3148737], dtype=float32)}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.6357190090019943
{'scaleFactor': 30, 'timeStep': 9, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([3.746354 , 8.20988  , 5.7917743], dtype=float32)}
episode index:2076
target Thresh 14.999627432880654
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([11.103582 ,  9.124733 ,  4.2549496], dtype=float32)}
done in step count: 127
reward sum = 0.27904208858505886
running average episode reward sum: 0.6355472820302
{'scaleFactor': 30, 'timeStep': 128, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([7.491858 , 7.5251913, 4.082369 ], dtype=float32)}
episode index:2077
target Thresh 14.999629291066915
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([4.865526 , 9.955518 , 1.5352936], dtype=float32)}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.635694506701697
{'scaleFactor': 30, 'timeStep': 7, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([ 7.4028444, 10.27263  ,  6.139486 ], dtype=float32)}
episode index:2078
target Thresh 14.99963113998543
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([6.365779 , 9.970846 , 1.0142019], dtype=float32)}
done in step count: 74
reward sum = 0.47534004200570695
running average episode reward sum: 0.6356173761270476
{'scaleFactor': 30, 'timeStep': 75, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([12.896313 ,  2.4672694,  4.4284487], dtype=float32)}
episode index:2079
target Thresh 14.99963297968243
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([11.881519 ,  5.1763043,  5.211022 ], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6357925600808327
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([11.881519 ,  5.1763043,  5.211022 ], dtype=float32)}
episode index:2080
target Thresh 14.999634810203899
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([10.137873 ,  3.045939 ,  2.6632457], dtype=float32)}
done in step count: 19
reward sum = 0.8261686238355866
running average episode reward sum: 0.6358840430523631
{'scaleFactor': 30, 'timeStep': 20, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([5.176503 , 8.146615 , 3.1273608], dtype=float32)}
episode index:2081
target Thresh 14.999636631595607
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([12.13549  ,  8.641783 ,  0.5497164], dtype=float32)}
done in step count: 239
reward sum = 0.0905339582851764
running average episode reward sum: 0.6356221073728401
{'scaleFactor': 30, 'timeStep': 240, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([3.4295902, 7.187652 , 4.2382946], dtype=float32)}
episode index:2082
target Thresh 14.999638443903084
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([12.164213, 10.084328,  2.114719], dtype=float32)}
done in step count: 176
reward sum = 0.17052743088958636
running average episode reward sum: 0.6353988262031409
{'scaleFactor': 30, 'timeStep': 177, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([4.9763074, 9.225826 , 6.0460835], dtype=float32)}
episode index:2083
target Thresh 14.999640247171639
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([6.5658503, 7.7820196, 5.7588906], dtype=float32)}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.6355367080976826
{'scaleFactor': 30, 'timeStep': 9, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([11.97871   ,  8.693135  ,  0.28423113], dtype=float32)}
episode index:2084
target Thresh 14.999642041446357
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([2.8382578, 4.9126735, 1.2493341], dtype=float32)}
done in step count: 63
reward sum = 0.5309055429551132
running average episode reward sum: 0.6354865252846646
{'scaleFactor': 30, 'timeStep': 64, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([6.927128 , 9.900735 , 6.2451324], dtype=float32)}
episode index:2085
target Thresh 14.99964382677209
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([1.7700931, 7.1061606, 2.77034  ], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6356612680817477
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([1.7700931, 7.1061606, 2.77034  ], dtype=float32)}
episode index:2086
target Thresh 14.999645603193477
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([2.9253876, 9.101629 , 3.4034333], dtype=float32)}
done in step count: 53
reward sum = 0.5870367819374844
running average episode reward sum: 0.6356379693341941
{'scaleFactor': 30, 'timeStep': 54, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([11.638989 ,  7.7360125,  5.766643 ], dtype=float32)}
episode index:2087
target Thresh 14.999647370754923
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([ 7.8495927, 10.908541 ,  1.5423634], dtype=float32)}
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.6357538137085547
{'scaleFactor': 30, 'timeStep': 14, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([ 9.554625 , 11.448872 ,  0.7348691], dtype=float32)}
episode index:2088
target Thresh 14.99964912950062
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([6.009505, 9.358392, 3.801845], dtype=float32)}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.6358824055042943
{'scaleFactor': 30, 'timeStep': 11, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([10.682265  ,  7.4126153 ,  0.25240016], dtype=float32)}
episode index:2089
target Thresh 14.999650879474537
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([1.6509311, 2.8535693, 5.202516 ], dtype=float32)}
done in step count: 209
reward sum = 0.12239274379499834
running average episode reward sum: 0.6356367166709406
{'scaleFactor': 30, 'timeStep': 210, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([10.8278675,  4.71819  ,  4.243932 ], dtype=float32)}
episode index:2090
target Thresh 14.999652620720422
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([5.903208 , 8.751436 , 1.2186458], dtype=float32)}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.6357967655869278
{'scaleFactor': 30, 'timeStep': 4, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([ 4.6069546, 10.383565 ,  2.153231 ], dtype=float32)}
episode index:2091
target Thresh 14.999654353281805
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([0.62915885, 6.149567  , 2.076368  ], dtype=float32)}
done in step count: 70
reward sum = 0.49483865960020695
running average episode reward sum: 0.6357293859951559
{'scaleFactor': 30, 'timeStep': 71, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([4.9740686, 8.646448 , 2.707938 ], dtype=float32)}
episode index:2092
target Thresh 14.999656077202006
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([3.92577 , 9.194906, 5.615197], dtype=float32)}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6358709703056727
{'scaleFactor': 30, 'timeStep': 8, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([3.638173 , 7.489511 , 5.4161816], dtype=float32)}
episode index:2093
target Thresh 14.999657792524117
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([3.9052474, 9.8058815, 1.3562701], dtype=float32)}
done in step count: 31
reward sum = 0.7323033696543975
running average episode reward sum: 0.6359170220723149
{'scaleFactor': 30, 'timeStep': 32, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([ 6.717844 , 10.8898735,  5.667484 ], dtype=float32)}
episode index:2094
target Thresh 14.999659499291024
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([2.1759672, 2.9159763, 3.230032 ], dtype=float32)}
done in step count: 18
reward sum = 0.8345137614500875
running average episode reward sum: 0.6360118176519701
{'scaleFactor': 30, 'timeStep': 19, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([ 9.590877  , 10.324389  ,  0.24606195], dtype=float32)}
episode index:2095
target Thresh 14.999661197545393
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([4.177899 , 9.148401 , 1.1987501], dtype=float32)}
done in step count: 112
reward sum = 0.3244455298634257
running average episode reward sum: 0.6358631696139031
{'scaleFactor': 30, 'timeStep': 113, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([13.466789 ,  6.1350994,  5.201541 ], dtype=float32)}
episode index:2096
target Thresh 14.999662887329686
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([9.0640545, 9.035016 , 1.9413495], dtype=float32)}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6360134447117982
{'scaleFactor': 30, 'timeStep': 6, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([ 6.3220057, 10.607676 ,  3.7169318], dtype=float32)}
episode index:2097
target Thresh 14.999664568686143
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([3.3250995, 7.9975924, 3.6530943], dtype=float32)}
done in step count: 19
reward sum = 0.8261686238355866
running average episode reward sum: 0.6361040811174816
{'scaleFactor': 30, 'timeStep': 20, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([0.84810805, 8.168987  , 2.583435  ], dtype=float32)}
episode index:2098
target Thresh 14.9996662416568
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([11.9314165,  1.8960463,  5.099962 ], dtype=float32)}
done in step count: 63
reward sum = 0.5309055429551132
running average episode reward sum: 0.6360539627095911
{'scaleFactor': 30, 'timeStep': 64, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([13.952331 ,  5.1533294,  2.017924 ], dtype=float32)}
episode index:2099
target Thresh 14.999667906283483
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([1.9680258, 2.9581497, 0.6191939], dtype=float32)}
done in step count: 27
reward sum = 0.7623427143471035
running average episode reward sum: 0.6361141002103708
{'scaleFactor': 30, 'timeStep': 28, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([ 4.3868637 , 11.90331   ,  0.21762022], dtype=float32)}
episode index:2100
target Thresh 14.999669562607803
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([8.952683, 9.93555 , 0.495071], dtype=float32)}
done in step count: 40
reward sum = 0.6689717585696803
running average episode reward sum: 0.6361297392671815
{'scaleFactor': 30, 'timeStep': 41, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([ 5.339782 , 10.053102 ,  4.4005685], dtype=float32)}
episode index:2101
target Thresh 14.999671210671172
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([1.9830872, 5.0216036, 4.4293756], dtype=float32)}
done in step count: 76
reward sum = 0.46588077516979337
running average episode reward sum: 0.6360487454688479
{'scaleFactor': 30, 'timeStep': 77, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([ 8.962735 , 11.979449 ,  6.2288127], dtype=float32)}
episode index:2102
target Thresh 14.999672850514791
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([12.028584 ,  2.8460784,  1.8181663], dtype=float32)}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.6362123456849826
{'scaleFactor': 30, 'timeStep': 3, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([12.910827 ,  6.5630035,  1.2844453], dtype=float32)}
episode index:2103
target Thresh 14.999674482179657
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([1.5241134, 7.765179 , 2.1888106], dtype=float32)}
done in step count: 226
reward sum = 0.10317013030157669
running average episode reward sum: 0.6359589986244392
{'scaleFactor': 30, 'timeStep': 227, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([11.098028 , 11.146164 ,  0.3601158], dtype=float32)}
episode index:2104
target Thresh 14.999676105706557
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([ 6.007285 , 10.114991 ,  0.8666966], dtype=float32)}
done in step count: 77
reward sum = 0.46122196741809546
running average episode reward sum: 0.6358759881583079
{'scaleFactor': 30, 'timeStep': 78, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([1.868977 , 7.424083 , 3.9731565], dtype=float32)}
episode index:2105
target Thresh 14.999677721136086
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([10.099774 ,  9.019956 ,  5.7100935], dtype=float32)}
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.635999189614196
{'scaleFactor': 30, 'timeStep': 12, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([9.518144 , 8.5587225, 3.4142761], dtype=float32)}
episode index:2106
target Thresh 14.999679328508625
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([2.8016522, 8.955668 , 4.8707285], dtype=float32)}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.6361532460073549
{'scaleFactor': 30, 'timeStep': 5, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([3.0060139, 8.963433 , 3.589518 ], dtype=float32)}
episode index:2107
target Thresh 14.999680927864361
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([2.223814 , 9.129915 , 2.7211552], dtype=float32)}
done in step count: 133
reward sum = 0.2627125872502283
running average episode reward sum: 0.6359760919946618
{'scaleFactor': 30, 'timeStep': 134, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([13.78048   ,  8.984883  ,  0.49071395], dtype=float32)}
episode index:2108
target Thresh 14.999682519243276
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([1.9286506, 6.9768186, 4.61442  ], dtype=float32)}
done in step count: 26
reward sum = 0.7700431458051551
running average episode reward sum: 0.6360396610102191
{'scaleFactor': 30, 'timeStep': 27, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([9.747905, 7.882709, 5.796065], dtype=float32)}
episode index:2109
target Thresh 14.999684102685157
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([ 6.790659 , 10.284312 ,  4.1522174], dtype=float32)}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6361799575442935
{'scaleFactor': 30, 'timeStep': 8, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([8.056083, 9.327236, 6.050506], dtype=float32)}
episode index:2110
target Thresh 14.999685678229588
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([5.073177 , 7.635457 , 3.2460237], dtype=float32)}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.6363428756127234
{'scaleFactor': 30, 'timeStep': 3, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([3.8088393, 9.432275 , 1.9120605], dtype=float32)}
episode index:2111
target Thresh 14.999687245915958
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([12.494064 ,  8.628977 ,  5.9079123], dtype=float32)}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.6364697881124375
{'scaleFactor': 30, 'timeStep': 11, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([9.872817, 9.382832, 3.148767], dtype=float32)}
episode index:2112
target Thresh 14.999688805783459
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([8.10183  , 8.966831 , 2.1368754], dtype=float32)}
done in step count: 99
reward sum = 0.36972963764972644
running average episode reward sum: 0.6363435504643244
{'scaleFactor': 30, 'timeStep': 100, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([12.436823 ,  2.1210022,  4.7784376], dtype=float32)}
episode index:2113
target Thresh 14.999690357871089
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([2.2140932, 8.821343 , 1.6676135], dtype=float32)}
done in step count: 36
reward sum = 0.6964132180495735
running average episode reward sum: 0.6363719656334755
{'scaleFactor': 30, 'timeStep': 37, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([5.921144  , 8.004587  , 0.65083516], dtype=float32)}
episode index:2114
target Thresh 14.99969190221765
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([12.15828  ,  5.229795 ,  1.4397178], dtype=float32)}
done in step count: 103
reward sum = 0.355160814705073
running average episode reward sum: 0.6362390052784267
{'scaleFactor': 30, 'timeStep': 104, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([6.8370786, 8.059649 , 4.406186 ], dtype=float32)}
episode index:2115
target Thresh 14.999693438861751
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([10.00984  ,  6.3873005,  2.6412706], dtype=float32)}
done in step count: 20
reward sum = 0.8179069375972308
running average episode reward sum: 0.6363248596887853
{'scaleFactor': 30, 'timeStep': 21, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([0.7965356, 6.8585815, 3.4826002], dtype=float32)}
episode index:2116
target Thresh 14.999694967841807
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([10.025461 ,  9.775553 ,  1.5753671], dtype=float32)}
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.6364387926898765
{'scaleFactor': 30, 'timeStep': 14, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([11.135897  ,  8.9695635 ,  0.31493676], dtype=float32)}
episode index:2117
target Thresh 14.999696489196042
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([1.9944842, 4.967419 , 2.1237543], dtype=float32)}
done in step count: 69
reward sum = 0.4998370298991989
running average episode reward sum: 0.6363742970511651
{'scaleFactor': 30, 'timeStep': 70, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([6.055857  , 8.055419  , 0.81991434], dtype=float32)}
episode index:2118
target Thresh 14.999698002962491
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([12.157792,  9.794972,  1.544848], dtype=float32)}
done in step count: 105
reward sum = 0.348093114492442
running average episode reward sum: 0.6362382511887024
{'scaleFactor': 30, 'timeStep': 106, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([1.4998164, 9.746442 , 4.198032 ], dtype=float32)}
episode index:2119
target Thresh 14.999699509178999
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([1.995642, 7.92229 , 5.682279], dtype=float32)}
done in step count: 152
reward sum = 0.21704489667280757
running average episode reward sum: 0.6360405184743081
{'scaleFactor': 30, 'timeStep': 153, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([9.311425  , 8.719272  , 0.40404433], dtype=float32)}
episode index:2120
target Thresh 14.999701007883221
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([8.978259 , 8.900105 , 1.5878115], dtype=float32)}
done in step count: 88
reward sum = 0.41294967113388814
running average episode reward sum: 0.6359353365566558
{'scaleFactor': 30, 'timeStep': 89, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([11.522714 ,  5.6457195,  6.0379868], dtype=float32)}
episode index:2121
target Thresh 14.999702499112624
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([6.838278 , 9.217285 , 6.0205173], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6361069033160542
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([6.838278 , 9.217285 , 6.0205173], dtype=float32)}
episode index:2122
target Thresh 14.99970398290449
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([12.305605 ,  9.072672 ,  2.5674202], dtype=float32)}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.6362689349207099
{'scaleFactor': 30, 'timeStep': 3, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([8.191264, 9.327187, 3.215745], dtype=float32)}
episode index:2123
target Thresh 14.999705459295916
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([2.8890257, 9.187637 , 1.6233029], dtype=float32)}
done in step count: 122
reward sum = 0.2934227215252159
running average episode reward sum: 0.6361075195660039
{'scaleFactor': 30, 'timeStep': 123, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([10.296144 ,  5.4018774,  5.548931 ], dtype=float32)}
episode index:2124
target Thresh 14.999706928323805
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([10.090806,  8.601633,  3.517461], dtype=float32)}
done in step count: 109
reward sum = 0.334376856889913
running average episode reward sum: 0.635965528665921
{'scaleFactor': 30, 'timeStep': 110, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([2.167178 , 8.044152 , 5.6544523], dtype=float32)}
episode index:2125
target Thresh 14.999708390024887
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([11.122499 ,  9.23751  ,  2.2236724], dtype=float32)}
done in step count: 147
reward sum = 0.22823046013534068
running average episode reward sum: 0.6357737435913535
{'scaleFactor': 30, 'timeStep': 148, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([ 4.415329 , 11.9422865,  3.3623686], dtype=float32)}
episode index:2126
target Thresh 14.999709844435706
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([2.1005511, 3.9885046, 4.4526463], dtype=float32)}
done in step count: 151
reward sum = 0.2192372693664723
running average episode reward sum: 0.635577910740284
{'scaleFactor': 30, 'timeStep': 152, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([8.099024 , 9.283075 , 0.2548972], dtype=float32)}
episode index:2127
target Thresh 14.99971129159262
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([2.1330733, 5.055417 , 6.2506986], dtype=float32)}
done in step count: 159
reward sum = 0.2023000271287771
running average episode reward sum: 0.6353743027122711
{'scaleFactor': 30, 'timeStep': 160, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([9.03636  , 7.4051476, 6.0016003], dtype=float32)}
episode index:2128
target Thresh 14.99971273153181
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([12.142491 ,  9.192452 ,  2.1415904], dtype=float32)}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.635500656762199
{'scaleFactor': 30, 'timeStep': 11, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([12.155956 ,  7.4387693,  4.4709663], dtype=float32)}
episode index:2129
target Thresh 14.999714164289273
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([12.125678,  6.182269,  4.390307], dtype=float32)}
done in step count: 18
reward sum = 0.8345137614500875
running average episode reward sum: 0.6355940901446816
{'scaleFactor': 30, 'timeStep': 19, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([8.614534 , 7.2207303, 1.989921 ], dtype=float32)}
episode index:2130
target Thresh 14.999715589900827
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([3.4463973, 9.544441 , 1.265234 ], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6357650924486963
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([3.4463973, 9.544441 , 1.265234 ], dtype=float32)}
episode index:2131
target Thresh 14.999717008402115
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([6.7944813, 9.80827  , 4.3475   ], dtype=float32)}
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.635878486412369
{'scaleFactor': 30, 'timeStep': 14, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([10.958326 ,  4.90304  ,  5.8096004], dtype=float32)}
episode index:2132
target Thresh 14.999718419828596
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([2.1973019, 4.022927 , 3.576006 ], dtype=float32)}
done in step count: 111
reward sum = 0.3277227574378037
running average episode reward sum: 0.6357340158408854
{'scaleFactor': 30, 'timeStep': 112, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([6.5632215, 8.127085 , 1.0950778], dtype=float32)}
episode index:2133
target Thresh 14.99971982421556
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([5.117327 , 9.908452 , 3.5930452], dtype=float32)}
done in step count: 58
reward sum = 0.5582661385478637
running average episode reward sum: 0.6356977141176928
{'scaleFactor': 30, 'timeStep': 59, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([7.88713  , 8.129995 , 5.6149387], dtype=float32)}
episode index:2134
target Thresh 14.999721221598115
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([1.909824 , 8.092795 , 1.6450421], dtype=float32)}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.6358321623520301
{'scaleFactor': 30, 'timeStep': 9, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([4.040388 , 8.728422 , 0.8185312], dtype=float32)}
episode index:2135
target Thresh 14.999722612011194
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([9.89541  , 9.312234 , 3.0324397], dtype=float32)}
done in step count: 18
reward sum = 0.8345137614500875
running average episode reward sum: 0.6359251780819449
{'scaleFactor': 30, 'timeStep': 19, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([10.026321 ,  7.104813 ,  4.0682793], dtype=float32)}
episode index:2136
target Thresh 14.999723995489562
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([ 6.970255 , 10.214104 ,  0.6399648], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6360955453360011
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([ 6.970255 , 10.214104 ,  0.6399648], dtype=float32)}
episode index:2137
target Thresh 14.9997253720678
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([4.735087 , 8.943535 , 2.0881157], dtype=float32)}
done in step count: 26
reward sum = 0.7700431458051551
running average episode reward sum: 0.6361581962249016
{'scaleFactor': 30, 'timeStep': 27, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([ 9.407913, 10.509463,  5.448644], dtype=float32)}
episode index:2138
target Thresh 14.999726741780327
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([1.9298154, 4.3126183, 2.2191932], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6363282952448993
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([1.9298154, 4.3126183, 2.2191932], dtype=float32)}
episode index:2139
target Thresh 14.999728104661383
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([7.128893, 8.79647 , 4.607147], dtype=float32)}
done in step count: 47
reward sum = 0.6235253948912
running average episode reward sum: 0.6363223125811825
{'scaleFactor': 30, 'timeStep': 48, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([4.450609 , 7.872023 , 3.1622329], dtype=float32)}
episode index:2140
target Thresh 14.99972946074504
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([3.044171 , 8.959602 , 0.9590616], dtype=float32)}
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.6364432915357259
{'scaleFactor': 30, 'timeStep': 12, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([ 8.71093  , 10.409688 ,  5.9269996], dtype=float32)}
episode index:2141
target Thresh 14.999730810065206
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([11.009172 ,  9.060565 ,  1.5784485], dtype=float32)}
done in step count: 31
reward sum = 0.7323033696543975
running average episode reward sum: 0.6364880441398896
{'scaleFactor': 30, 'timeStep': 32, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([10.015842 ,  6.7413054,  4.2551436], dtype=float32)}
episode index:2142
target Thresh 14.999732152655605
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([4.6215935, 8.917122 , 5.3621726], dtype=float32)}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6366303643010007
{'scaleFactor': 30, 'timeStep': 7, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([11.619385,  8.249017,  5.798674], dtype=float32)}
episode index:2143
target Thresh 14.99973348854981
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([9.6645  , 9.961757, 6.180755], dtype=float32)}
done in step count: 37
reward sum = 0.6894490858690777
running average episode reward sum: 0.636654999898747
{'scaleFactor': 30, 'timeStep': 38, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([13.568951,  7.16588 ,  4.491178], dtype=float32)}
episode index:2144
target Thresh 14.999734817781214
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([5.6434016, 8.175183 , 5.562148 ], dtype=float32)}
done in step count: 39
reward sum = 0.6757290490602831
running average episode reward sum: 0.6366732162386824
{'scaleFactor': 30, 'timeStep': 40, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([9.024701, 7.244022, 5.538232], dtype=float32)}
episode index:2145
target Thresh 14.999736140383046
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([2.1165814, 5.122118 , 3.3000932], dtype=float32)}
done in step count: 22
reward sum = 0.8016305895390459
running average episode reward sum: 0.636750083607415
{'scaleFactor': 30, 'timeStep': 23, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([0.7627609, 3.686068 , 4.376531 ], dtype=float32)}
episode index:2146
target Thresh 14.999737456388376
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([8.706144 , 7.9541264, 4.7968802], dtype=float32)}
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.6368622265694046
{'scaleFactor': 30, 'timeStep': 14, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([10.141963 ,  4.4483585,  5.0363145], dtype=float32)}
episode index:2147
target Thresh 14.999738765830102
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([ 9.733388 , 10.015543 ,  2.3133023], dtype=float32)}
done in step count: 39
reward sum = 0.6757290490602831
running average episode reward sum: 0.6368803209932831
{'scaleFactor': 30, 'timeStep': 40, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([2.8472238, 6.964112 , 4.23513  ], dtype=float32)}
episode index:2148
target Thresh 14.99974006874096
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([6.211357, 8.514776, 4.132104], dtype=float32)}
done in step count: 40
reward sum = 0.6689717585696803
running average episode reward sum: 0.636895254188991
{'scaleFactor': 30, 'timeStep': 41, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([3.377724, 8.161507, 2.839413], dtype=float32)}
episode index:2149
target Thresh 14.999741365153522
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([11.079174 ,  8.993942 ,  1.9163677], dtype=float32)}
done in step count: 23
reward sum = 0.7936142836436554
running average episode reward sum: 0.6369681467608302
{'scaleFactor': 30, 'timeStep': 24, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([ 8.058031 , 10.21966  ,  3.6362462], dtype=float32)}
episode index:2150
target Thresh 14.999742655100201
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([2.2102056 , 6.156112  , 0.96150947], dtype=float32)}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.6370967144506131
{'scaleFactor': 30, 'timeStep': 10, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([4.646011 , 8.697083 , 0.6702237], dtype=float32)}
episode index:2151
target Thresh 14.999743938613243
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([4.0301666, 8.716744 , 1.412816 ], dtype=float32)}
done in step count: 27
reward sum = 0.7623427143471035
running average episode reward sum: 0.6371549142646914
{'scaleFactor': 30, 'timeStep': 28, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([8.882808  , 8.886913  , 0.18170035], dtype=float32)}
episode index:2152
target Thresh 14.999745215724737
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([2.0411475, 7.995509 , 2.6895819], dtype=float32)}
done in step count: 34
reward sum = 0.7105532272722921
running average episode reward sum: 0.6371890054458376
{'scaleFactor': 30, 'timeStep': 35, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([9.05366  , 8.922176 , 1.7907721], dtype=float32)}
episode index:2153
target Thresh 14.999746486466613
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([2.0286856, 2.8857374, 4.728236 ], dtype=float32)}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6373259025407592
{'scaleFactor': 30, 'timeStep': 8, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([3.4769845, 4.59904  , 1.2872155], dtype=float32)}
episode index:2154
target Thresh 14.999747750870634
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([1.843476 , 4.8175864, 3.0404487], dtype=float32)}
done in step count: 27
reward sum = 0.7623427143471035
running average episode reward sum: 0.6373839149824326
{'scaleFactor': 30, 'timeStep': 28, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([7.0114746, 9.337862 , 5.8171754], dtype=float32)}
episode index:2155
target Thresh 14.999749008968417
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([7.9544864, 9.106506 , 2.2076507], dtype=float32)}
done in step count: 29
reward sum = 0.7471720943315961
running average episode reward sum: 0.6374348371435408
{'scaleFactor': 30, 'timeStep': 30, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([10.039686  ,  7.495133  ,  0.06749647], dtype=float32)}
episode index:2156
target Thresh 14.999750260791409
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([1.5254626, 3.9863265, 2.5077045], dtype=float32)}
done in step count: 321
reward sum = 0.03970977861200674
running average episode reward sum: 0.6371577277051859
{'scaleFactor': 30, 'timeStep': 322, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([13.72299  ,  3.8743186,  4.4264746], dtype=float32)}
episode index:2157
target Thresh 14.999751506370908
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([11.8594   ,  6.1977034,  5.043507 ], dtype=float32)}
done in step count: 83
reward sum = 0.43423132679181164
running average episode reward sum: 0.6370636932283956
{'scaleFactor': 30, 'timeStep': 84, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([12.342296 , 10.079061 ,  3.3963594], dtype=float32)}
episode index:2158
target Thresh 14.999752745738054
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([11.146699 ,  8.88535  ,  5.5091286], dtype=float32)}
done in step count: 56
reward sum = 0.5696012024771592
running average episode reward sum: 0.6370324461275381
{'scaleFactor': 30, 'timeStep': 57, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([3.9424024, 4.1646466, 1.1917472], dtype=float32)}
episode index:2159
target Thresh 14.99975397892383
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([10.176834  ,  9.796755  ,  0.33314535], dtype=float32)}
done in step count: 35
reward sum = 0.7034476949995692
running average episode reward sum: 0.6370631939279418
{'scaleFactor': 30, 'timeStep': 36, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([11.19232   ,  6.9323506 ,  0.04715174], dtype=float32)}
episode index:2160
target Thresh 14.999755205959065
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([6.9652834, 9.015087 , 0.5700571], dtype=float32)}
done in step count: 42
reward sum = 0.6556592205741436
running average episode reward sum: 0.6370717992156076
{'scaleFactor': 30, 'timeStep': 43, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([12.251549 ,  4.7191954,  3.7147968], dtype=float32)}
episode index:2161
target Thresh 14.99975642687444
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([3.0290098, 4.5743427, 0.8060386], dtype=float32)}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.637225928355656
{'scaleFactor': 30, 'timeStep': 4, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([5.647114 , 7.3544693, 1.1429002], dtype=float32)}
episode index:2162
target Thresh 14.999757641700471
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([5.0679684, 9.082377 , 2.3285959], dtype=float32)}
done in step count: 215
reward sum = 0.11523033871371334
running average episode reward sum: 0.6369845989106064
{'scaleFactor': 30, 'timeStep': 216, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([8.848857 , 9.526781 , 5.4382796], dtype=float32)}
episode index:2163
target Thresh 14.999758850467533
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([10.232786 ,  9.950085 ,  1.8903996], dtype=float32)}
done in step count: 102
reward sum = 0.3587482976818919
running average episode reward sum: 0.6368560239100386
{'scaleFactor': 30, 'timeStep': 103, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([3.9821544, 6.870093 , 4.440982 ], dtype=float32)}
episode index:2164
target Thresh 14.999760053205843
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([ 5.8161416, 10.063865 ,  1.9190596], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.6370191389105421
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([6.1249127, 9.909006 , 1.9618106], dtype=float32)}
episode index:2165
target Thresh 14.999761249945472
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([4.0646534, 6.753326 , 6.2386317], dtype=float32)}
done in step count: 14
reward sum = 0.8687458127689782
running average episode reward sum: 0.6371261226011508
{'scaleFactor': 30, 'timeStep': 15, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([5.6201863 , 7.551     , 0.42014202], dtype=float32)}
episode index:2166
target Thresh 14.999762440716335
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([11.759751 , 10.090267 ,  0.7209413], dtype=float32)}
done in step count: 81
reward sum = 0.4430479816261725
running average episode reward sum: 0.6370365618531236
{'scaleFactor': 30, 'timeStep': 82, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([6.974224 , 7.521581 , 2.5498226], dtype=float32)}
episode index:2167
target Thresh 14.999763625548207
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([1.6924101, 2.928975 , 3.633932 ], dtype=float32)}
done in step count: 38
reward sum = 0.682554595010387
running average episode reward sum: 0.6370575572558713
{'scaleFactor': 30, 'timeStep': 39, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([ 7.2836027, 10.712805 ,  5.7960224], dtype=float32)}
episode index:2168
target Thresh 14.999764804470702
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([11.982329  ,  4.927457  ,  0.03209322], dtype=float32)}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6371979088428447
{'scaleFactor': 30, 'timeStep': 7, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([13.083343 ,  8.014211 ,  1.4022058], dtype=float32)}
episode index:2169
target Thresh 14.999765977513299
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([2.8051894 , 8.772564  , 0.05186814], dtype=float32)}
done in step count: 69
reward sum = 0.4998370298991989
running average episode reward sum: 0.637134608898631
{'scaleFactor': 30, 'timeStep': 70, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([2.512    , 2.5931954, 4.5562983], dtype=float32)}
episode index:2170
target Thresh 14.99976714470532
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([2.1004634, 3.0931606, 6.2823787], dtype=float32)}
done in step count: 169
reward sum = 0.18295651830906084
running average episode reward sum: 0.6369254066459413
{'scaleFactor': 30, 'timeStep': 170, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([10.562079, 11.343852,  5.565279], dtype=float32)}
episode index:2171
target Thresh 14.999768306075948
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([1.5591594, 2.0263007, 1.943423 ], dtype=float32)}
done in step count: 58
reward sum = 0.5582661385478637
running average episode reward sum: 0.6368891915132995
{'scaleFactor': 30, 'timeStep': 59, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([11.36029  ,  5.0053577,  5.148106 ], dtype=float32)}
episode index:2172
target Thresh 14.999769461654214
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([5.008993, 7.270624, 5.666948], dtype=float32)}
done in step count: 108
reward sum = 0.337754400898902
running average episode reward sum: 0.636751531692492
{'scaleFactor': 30, 'timeStep': 109, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([10.017407,  8.868511,  4.076105], dtype=float32)}
episode index:2173
target Thresh 14.999770611469012
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([4.0405974, 8.684524 , 2.1779616], dtype=float32)}
done in step count: 53
reward sum = 0.5870367819374844
running average episode reward sum: 0.6367286638223195
{'scaleFactor': 30, 'timeStep': 54, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([ 6.098333  , 10.926656  ,  0.56292284], dtype=float32)}
episode index:2174
target Thresh 14.999771755549084
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([12.233299 ,  1.8891644,  5.9709616], dtype=float32)}
done in step count: 33
reward sum = 0.7177305325982749
running average episode reward sum: 0.6367659060608373
{'scaleFactor': 30, 'timeStep': 34, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([13.886622  ,  9.259567  ,  0.05466616], dtype=float32)}
episode index:2175
target Thresh 14.99977289392303
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([2.3461313, 8.008831 , 1.3921355], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6369328334937138
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([2.3461313, 8.008831 , 1.3921355], dtype=float32)}
episode index:2176
target Thresh 14.999774026619315
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([ 8.1328335, 10.040144 ,  1.203322 ], dtype=float32)}
done in step count: 137
reward sum = 0.2523606630893462
running average episode reward sum: 0.6367561811416677
{'scaleFactor': 30, 'timeStep': 138, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([2.6698184, 7.1307855, 3.0039756], dtype=float32)}
episode index:2177
target Thresh 14.999775153666253
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([12.378538 ,  3.1543343,  0.0597121], dtype=float32)}
done in step count: 17
reward sum = 0.8429431933839268
running average episode reward sum: 0.6368508491913656
{'scaleFactor': 30, 'timeStep': 18, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([ 9.820312 , 10.642786 ,  1.9987599], dtype=float32)}
episode index:2178
target Thresh 14.999776275092023
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([1.9873376, 7.912094 , 5.7264285], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.6370129185584187
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([2.0238419, 8.010551 , 5.325894 ], dtype=float32)}
episode index:2179
target Thresh 14.999777390924654
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([11.864641  ,  9.152837  ,  0.93557453], dtype=float32)}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.6371658020820158
{'scaleFactor': 30, 'timeStep': 4, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([11.635727,  8.852379,  2.634645], dtype=float32)}
episode index:2180
target Thresh 14.99977850119205
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([11.860518 ,  4.0805254,  4.1520286], dtype=float32)}
done in step count: 28
reward sum = 0.7547192872036326
running average episode reward sum: 0.6372197009747813
{'scaleFactor': 30, 'timeStep': 29, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([9.443821 , 8.355969 , 1.4795282], dtype=float32)}
episode index:2181
target Thresh 14.999779605921963
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([8.877929 , 9.699299 , 6.0214453], dtype=float32)}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.6373768413501366
{'scaleFactor': 30, 'timeStep': 3, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([9.030279, 9.449723, 5.308699], dtype=float32)}
episode index:2182
target Thresh 14.999780705142014
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([7.162094 , 8.990517 , 0.0314731], dtype=float32)}
done in step count: 44
reward sum = 0.6426116020847181
running average episode reward sum: 0.6373792393165748
{'scaleFactor': 30, 'timeStep': 45, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([3.8527074, 5.0242558, 3.172073 ], dtype=float32)}
episode index:2183
target Thresh 14.999781798879681
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([1.6919922, 6.9935675, 3.4099135], dtype=float32)}
done in step count: 26
reward sum = 0.7700431458051551
running average episode reward sum: 0.6374399828635019
{'scaleFactor': 30, 'timeStep': 27, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([ 5.2498736, 10.388417 ,  1.1609998], dtype=float32)}
episode index:2184
target Thresh 14.999782887162308
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([11.85224   ,  2.9533536 ,  0.17670792], dtype=float32)}
done in step count: 25
reward sum = 0.7778213593991467
running average episode reward sum: 0.6375042306330834
{'scaleFactor': 30, 'timeStep': 26, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([6.864119 , 8.54196  , 3.3362331], dtype=float32)}
episode index:2185
target Thresh 14.999783970017104
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([1.9378561, 2.0271332, 3.5336943], dtype=float32)}
done in step count: 399
reward sum = 0.0
running average episode reward sum: 0.6372126001524644
{'scaleFactor': 30, 'timeStep': 400, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([1.9523578, 7.3134193, 2.2941864], dtype=float32)}
episode index:2186
target Thresh 14.99978504747114
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([7.0414333, 9.940805 , 0.4727645], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.6373739112635057
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([ 6.8615494, 10.034475 ,  0.5235174], dtype=float32)}
episode index:2187
target Thresh 14.99978611955135
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([11.901668 ,  3.043048 ,  0.2334248], dtype=float32)}
done in step count: 74
reward sum = 0.47534004200570695
running average episode reward sum: 0.6372998555645762
{'scaleFactor': 30, 'timeStep': 75, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([ 8.908769 , 11.97723  ,  5.4941087], dtype=float32)}
episode index:2188
target Thresh 14.999787186284536
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([ 9.096784 , 10.043338 ,  5.5430326], dtype=float32)}
done in step count: 19
reward sum = 0.8261686238355866
running average episode reward sum: 0.6373861364089212
{'scaleFactor': 30, 'timeStep': 20, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([ 5.930647 , 11.299699 ,  1.4222796], dtype=float32)}
episode index:2189
target Thresh 14.99978824769737
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([2.0103974, 2.8175464, 3.1407986], dtype=float32)}
done in step count: 115
reward sum = 0.31480917318095203
running average episode reward sum: 0.6372388409919221
{'scaleFactor': 30, 'timeStep': 116, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([4.034041 , 9.150619 , 0.9400686], dtype=float32)}
episode index:2190
target Thresh 14.999789303816387
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([2.9840727, 8.980631 , 6.07583  ], dtype=float32)}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.6373649379369206
{'scaleFactor': 30, 'timeStep': 10, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([7.117782, 8.017163, 5.051344], dtype=float32)}
episode index:2191
target Thresh 14.999790354667986
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([11.936303 ,  6.980899 ,  5.9005146], dtype=float32)}
done in step count: 60
reward sum = 0.5471566423907612
running average episode reward sum: 0.6373237845174196
{'scaleFactor': 30, 'timeStep': 61, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([ 3.7983313, 10.26353  ,  2.8480268], dtype=float32)}
episode index:2192
target Thresh 14.999791400278442
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([10.033576,  9.051297,  5.912104], dtype=float32)}
done in step count: 101
reward sum = 0.3623720178604969
running average episode reward sum: 0.63719840751484
{'scaleFactor': 30, 'timeStep': 102, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([2.6916537, 5.885749 , 3.8403988], dtype=float32)}
episode index:2193
target Thresh 14.999792440673893
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([12.805073  , 10.425294  ,  0.21052685], dtype=float32)}
done in step count: 44
reward sum = 0.6426116020847181
running average episode reward sum: 0.6372008747867498
{'scaleFactor': 30, 'timeStep': 45, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([4.7980943, 8.180639 , 3.7941642], dtype=float32)}
episode index:2194
target Thresh 14.99979347588035
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([ 7.007445, 10.394311,  4.192775], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6373661591262547
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([ 7.007445, 10.394311,  4.192775], dtype=float32)}
episode index:2195
target Thresh 14.999794505923695
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([11.239026 , 10.121426 ,  5.5127616], dtype=float32)}
done in step count: 17
reward sum = 0.8429431933839268
running average episode reward sum: 0.6374597734405797
{'scaleFactor': 30, 'timeStep': 18, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([6.75041  , 9.133992 , 3.5522294], dtype=float32)}
episode index:2196
target Thresh 14.999795530829676
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([ 9.923594  , 10.044467  ,  0.25593513], dtype=float32)}
done in step count: 45
reward sum = 0.6361854860638709
running average episode reward sum: 0.6374591934281187
{'scaleFactor': 30, 'timeStep': 46, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([5.48368  , 9.8799305, 2.2223926], dtype=float32)}
episode index:2197
target Thresh 14.99979655062392
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([12.225092 ,  2.7960153,  4.586947 ], dtype=float32)}
done in step count: 18
reward sum = 0.8345137614500875
running average episode reward sum: 0.6375488451879103
{'scaleFactor': 30, 'timeStep': 19, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([11.35587  ,  4.0032587,  5.470805 ], dtype=float32)}
episode index:2198
target Thresh 14.999797565331916
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([ 7.130781, 10.046315,  4.634826], dtype=float32)}
done in step count: 115
reward sum = 0.31480917318095203
running average episode reward sum: 0.637402078624924
{'scaleFactor': 30, 'timeStep': 116, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([11.046892 ,  3.8141813,  4.0041056], dtype=float32)}
episode index:2199
target Thresh 14.999798574979033
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([1.9898785, 9.07295  , 4.1277995], dtype=float32)}
done in step count: 52
reward sum = 0.5929664464014994
running average episode reward sum: 0.637381880610277
{'scaleFactor': 30, 'timeStep': 53, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([0.30778372, 3.8458023 , 4.01288   ], dtype=float32)}
episode index:2200
target Thresh 14.999799579590517
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([ 5.153661, 10.401833,  3.055164], dtype=float32)}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.6375287293741978
{'scaleFactor': 30, 'timeStep': 5, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([3.5601614, 9.437645 , 3.4001896], dtype=float32)}
episode index:2201
target Thresh 14.99980057919148
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([2.432651, 7.659725, 4.115938], dtype=float32)}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.6376798512046364
{'scaleFactor': 30, 'timeStep': 4, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([1.7886271, 2.4254968, 4.9319816], dtype=float32)}
episode index:2202
target Thresh 14.999801573806911
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([11.996394 ,  3.9356546,  4.618927 ], dtype=float32)}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.6378009144020055
{'scaleFactor': 30, 'timeStep': 11, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([10.935776 ,  6.197515 ,  2.3698747], dtype=float32)}
episode index:2203
target Thresh 14.999802563461678
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([ 8.921926 , 10.04606  ,  3.3894246], dtype=float32)}
done in step count: 56
reward sum = 0.5696012024771592
running average episode reward sum: 0.6377699707940541
{'scaleFactor': 30, 'timeStep': 57, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([12.040125 ,  3.1231341,  2.9223537], dtype=float32)}
episode index:2204
target Thresh 14.999803548180521
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([1.9741063, 5.0626087, 1.5526407], dtype=float32)}
done in step count: 74
reward sum = 0.47534004200570695
running average episode reward sum: 0.6376963064272566
{'scaleFactor': 30, 'timeStep': 75, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([ 8.277119 , 10.9560585,  2.9230676], dtype=float32)}
episode index:2205
target Thresh 14.999804527988058
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([9.829071 , 8.913361 , 5.1281905], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6378605420091119
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([9.829071 , 8.913361 , 5.1281905], dtype=float32)}
episode index:2206
target Thresh 14.999805502908785
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([3.8495448, 9.98943  , 1.0138162], dtype=float32)}
done in step count: 69
reward sum = 0.4998370298991989
running average episode reward sum: 0.6377980030367015
{'scaleFactor': 30, 'timeStep': 70, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([3.177217 , 2.8206267, 0.974898 ], dtype=float32)}
episode index:2207
target Thresh 14.999806472967075
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([2.0564632, 4.0176086, 2.0949976], dtype=float32)}
done in step count: 31
reward sum = 0.7323033696543975
running average episode reward sum: 0.6378408043802785
{'scaleFactor': 30, 'timeStep': 32, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([ 7.3640633, 10.979156 ,  5.533605 ], dtype=float32)}
episode index:2208
target Thresh 14.999807438187178
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([1.9191382, 8.64869  , 1.9220775], dtype=float32)}
done in step count: 21
reward sum = 0.8097278682212584
running average episode reward sum: 0.6379186165413653
{'scaleFactor': 30, 'timeStep': 22, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([ 5.319516, 10.025435,  5.769209], dtype=float32)}
episode index:2209
target Thresh 14.999808398593226
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([11.666242 ,  6.092048 ,  1.7118255], dtype=float32)}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.6380690149049213
{'scaleFactor': 30, 'timeStep': 4, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([10.912417 ,  7.916526 ,  1.5068915], dtype=float32)}
episode index:2210
target Thresh 14.99980935420923
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([7.9686522, 8.741538 , 6.1573057], dtype=float32)}
done in step count: 25
reward sum = 0.7778213593991467
running average episode reward sum: 0.6381322226591023
{'scaleFactor': 30, 'timeStep': 26, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([10.0916815 ,  9.040738  ,  0.46805882], dtype=float32)}
episode index:2211
target Thresh 14.999810305059079
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([1.6853899, 9.960071 , 3.0106933], dtype=float32)}
done in step count: 39
reward sum = 0.6757290490602831
running average episode reward sum: 0.6381492194160648
{'scaleFactor': 30, 'timeStep': 40, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([12.207457 ,  6.694015 ,  1.3693541], dtype=float32)}
episode index:2212
target Thresh 14.999811251166543
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([11.825396 ,  8.94141  ,  1.3175288], dtype=float32)}
done in step count: 30
reward sum = 0.7397003733882802
running average episode reward sum: 0.6381951078724464
{'scaleFactor': 30, 'timeStep': 31, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([10.381249 ,  4.534285 ,  3.7968502], dtype=float32)}
episode index:2213
target Thresh 14.999812192555277
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([5.986574 , 9.067853 , 0.7184477], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.638354008004392
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([ 7.6795297, 10.238133 ,  0.5587103], dtype=float32)}
episode index:2214
target Thresh 14.999813129248816
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([8.8866825, 9.332658 , 3.2391462], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.6385127646599205
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([6.9941435, 9.299062 , 2.8307164], dtype=float32)}
episode index:2215
target Thresh 14.999814061270575
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([12.12767  ,  2.4078722,  3.4236526], dtype=float32)}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.6386368641557796
{'scaleFactor': 30, 'timeStep': 10, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([7.3816323, 8.926835 , 2.0342703], dtype=float32)}
episode index:2216
target Thresh 14.999814988643857
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([6.8871465, 8.943504 , 1.040199 ], dtype=float32)}
done in step count: 24
reward sum = 0.7856781408072188
running average episode reward sum: 0.6387031885926995
{'scaleFactor': 30, 'timeStep': 25, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([ 4.9859514, 10.40744  ,  2.623463 ], dtype=float32)}
episode index:2217
target Thresh 14.999815911391844
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([2.1641898, 6.1079764, 0.9977206], dtype=float32)}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6388354528665111
{'scaleFactor': 30, 'timeStep': 8, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([9.656072 , 7.113307 , 6.0007033], dtype=float32)}
episode index:2218
target Thresh 14.99981682953761
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([2.128644 , 9.433973 , 3.7586665], dtype=float32)}
done in step count: 33
reward sum = 0.7177305325982749
running average episode reward sum: 0.6388710072061831
{'scaleFactor': 30, 'timeStep': 34, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([ 4.9838686, 10.28653  ,  5.917805 ], dtype=float32)}
episode index:2219
target Thresh 14.999817743104101
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([11.954321 ,  8.906945 ,  6.1800294], dtype=float32)}
done in step count: 16
reward sum = 0.8514577710948755
running average episode reward sum: 0.6389667670097364
{'scaleFactor': 30, 'timeStep': 17, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([12.25597  ,  6.9365883,  5.2923064], dtype=float32)}
episode index:2220
target Thresh 14.999818652114161
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([11.929984 ,  3.1921675,  2.9185574], dtype=float32)}
done in step count: 87
reward sum = 0.41712087993322033
running average episode reward sum: 0.6388668814234796
{'scaleFactor': 30, 'timeStep': 88, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([11.021494 ,  8.36848  ,  1.8055052], dtype=float32)}
episode index:2221
target Thresh 14.999819556590516
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([6.1778345, 9.1589985, 4.784374 ], dtype=float32)}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6390030710130284
{'scaleFactor': 30, 'timeStep': 7, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([7.6233616e+00, 9.0245342e+00, 5.0894576e-03], dtype=float32)}
episode index:2222
target Thresh 14.999820456555774
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([2.2920687, 6.6644573, 1.8088241], dtype=float32)}
done in step count: 89
reward sum = 0.40882017442254925
running average episode reward sum: 0.6388995249506846
{'scaleFactor': 30, 'timeStep': 90, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([11.882086 ,  6.8702636,  5.6280847], dtype=float32)}
episode index:2223
target Thresh 14.99982135203244
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([1.9532354, 3.1854362, 5.8618555], dtype=float32)}
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.6390148301347259
{'scaleFactor': 30, 'timeStep': 12, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([4.069602 , 8.512559 , 1.9288046], dtype=float32)}
episode index:2224
target Thresh 14.999822243042894
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([ 6.094885, 10.088292,  3.338012], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.639177070660508
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([ 6.094885, 10.088292,  3.338012], dtype=float32)}
episode index:2225
target Thresh 14.999823129609416
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([3.1052718, 9.992906 , 3.085239 ], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6393391654176237
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([3.1052718, 9.992906 , 3.085239 ], dtype=float32)}
episode index:2226
target Thresh 14.999824011754171
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([5.508271, 8.579665, 5.647478], dtype=float32)}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6394706095947631
{'scaleFactor': 30, 'timeStep': 8, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([10.208021 ,  8.693912 ,  0.8273581], dtype=float32)}
episode index:2227
target Thresh 14.999824889499207
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([ 8.826265, 10.094956,  4.196355], dtype=float32)}
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.6395854514460484
{'scaleFactor': 30, 'timeStep': 12, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([2.4091778, 6.6407285, 2.830143 ], dtype=float32)}
episode index:2228
target Thresh 14.999825762866474
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([0.6187415, 5.063718 , 2.4163878], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6397471448280825
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([0.6187415, 5.063718 , 2.4163878], dtype=float32)}
episode index:2229
target Thresh 14.999826631877804
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([11.866006,  6.084871,  1.37724 ], dtype=float32)}
done in step count: 140
reward sum = 0.24486529903492948
running average episode reward sum: 0.6395700677671887
{'scaleFactor': 30, 'timeStep': 141, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([1.7074485, 7.317916 , 4.2528048], dtype=float32)}
episode index:2230
target Thresh 14.99982749655492
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([2.459372 , 7.0913506, 4.4732637], dtype=float32)}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.6397227033262353
{'scaleFactor': 30, 'timeStep': 3, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([1.3136668, 5.4182415, 4.159062 ], dtype=float32)}
episode index:2231
target Thresh 14.99982835691944
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([11.004644,  9.87856 ,  1.946999], dtype=float32)}
done in step count: 48
reward sum = 0.617290140942288
running average episode reward sum: 0.6397126528950596
{'scaleFactor': 30, 'timeStep': 49, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([11.947896 ,  6.8225937,  3.7164977], dtype=float32)}
episode index:2232
target Thresh 14.999829212992877
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([11.925696  ,  9.778578  ,  0.04904097], dtype=float32)}
done in step count: 58
reward sum = 0.5582661385478637
running average episode reward sum: 0.6396761788626605
{'scaleFactor': 30, 'timeStep': 59, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([3.4472365, 7.0588684, 3.288054 ], dtype=float32)}
episode index:2233
target Thresh 14.99983006479663
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([2.832572 , 9.011978 , 2.0202286], dtype=float32)}
done in step count: 20
reward sum = 0.8179069375972308
running average episode reward sum: 0.6397559598647798
{'scaleFactor': 30, 'timeStep': 21, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([8.529004 , 9.231556 , 1.5385162], dtype=float32)}
episode index:2234
target Thresh 14.999830912351992
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([11.912253 ,  2.3647468,  4.930816 ], dtype=float32)}
done in step count: 123
reward sum = 0.29048849430996376
running average episode reward sum: 0.6395996880681111
{'scaleFactor': 30, 'timeStep': 124, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([5.9780197, 9.482687 , 3.6430197], dtype=float32)}
episode index:2235
target Thresh 14.999831755680153
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([7.19065  , 9.022267 , 6.2622356], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.6397563966154867
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([9.206244 , 8.997272 , 6.1661744], dtype=float32)}
episode index:2236
target Thresh 14.9998325948022
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([8.915394 , 8.712375 , 2.1354604], dtype=float32)}
done in step count: 99
reward sum = 0.36972963764972644
running average episode reward sum: 0.6396356872909601
{'scaleFactor': 30, 'timeStep': 100, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([3.0982952, 1.9091606, 4.2933307], dtype=float32)}
episode index:2237
target Thresh 14.999833429739107
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([12.192657  ,  6.0985537 ,  0.50634736], dtype=float32)}
done in step count: 57
reward sum = 0.5639051904523875
running average episode reward sum: 0.6396018488205228
{'scaleFactor': 30, 'timeStep': 58, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([11.949259 ,  9.482108 ,  2.5980198], dtype=float32)}
episode index:2238
target Thresh 14.999834260511749
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([9.979948 , 6.8304687, 3.1660826], dtype=float32)}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.6397283083317364
{'scaleFactor': 30, 'timeStep': 9, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([5.471279 , 9.180368 , 2.9972887], dtype=float32)}
episode index:2239
target Thresh 14.999835087140896
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([12.384434 ,  5.058545 ,  1.2017442], dtype=float32)}
done in step count: 85
reward sum = 0.4255901233886546
running average episode reward sum: 0.639632710927744
{'scaleFactor': 30, 'timeStep': 86, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([3.7980182, 7.453175 , 4.209423 ], dtype=float32)}
episode index:2240
target Thresh 14.999835909647212
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([ 4.9393888, 10.343196 ,  6.2580323], dtype=float32)}
done in step count: 44
reward sum = 0.6426116020847181
running average episode reward sum: 0.6396340401964442
{'scaleFactor': 30, 'timeStep': 45, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([2.7215586, 8.799007 , 2.9660795], dtype=float32)}
episode index:2241
target Thresh 14.99983672805126
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([10.498566 ,  7.9613805,  3.8485308], dtype=float32)}
done in step count: 21
reward sum = 0.8097278682212584
running average episode reward sum: 0.6397099072026997
{'scaleFactor': 30, 'timeStep': 22, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([3.6200757, 7.562209 , 3.782191 ], dtype=float32)}
episode index:2242
target Thresh 14.999837542373502
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([12.061058 ,  6.8638153,  4.1192493], dtype=float32)}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6398486856880752
{'scaleFactor': 30, 'timeStep': 6, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([5.9043517, 7.7892075, 3.062675 ], dtype=float32)}
episode index:2243
target Thresh 14.999838352634296
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([ 8.266448 , 10.05093  ,  2.5913095], dtype=float32)}
done in step count: 45
reward sum = 0.6361854860638709
running average episode reward sum: 0.6398470532461749
{'scaleFactor': 30, 'timeStep': 46, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([10.284123 ,  8.4828415,  5.0820675], dtype=float32)}
episode index:2244
target Thresh 14.999839158853895
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([2.143207 , 2.1777973, 4.986558 ], dtype=float32)}
done in step count: 29
reward sum = 0.7471720943315961
running average episode reward sum: 0.6398948595005559
{'scaleFactor': 30, 'timeStep': 30, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([4.298519 , 9.181149 , 1.4234618], dtype=float32)}
episode index:2245
target Thresh 14.999839961052457
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([5.0494413, 9.026341 , 2.6682649], dtype=float32)}
done in step count: 48
reward sum = 0.617290140942288
running average episode reward sum: 0.6398847950666474
{'scaleFactor': 30, 'timeStep': 49, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([ 9.185581 , 10.674269 ,  0.6841796], dtype=float32)}
episode index:2246
target Thresh 14.99984075925004
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([12.270508 ,  8.804884 ,  3.8825588], dtype=float32)}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.6400362037025769
{'scaleFactor': 30, 'timeStep': 3, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([11.47163  ,  6.7897744,  4.423523 ], dtype=float32)}
episode index:2247
target Thresh 14.999841553466592
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([8.425141, 8.924344, 5.113708], dtype=float32)}
done in step count: 69
reward sum = 0.4998370298991989
running average episode reward sum: 0.6399738375220594
{'scaleFactor': 30, 'timeStep': 70, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([3.7657943, 8.132899 , 3.853693 ], dtype=float32)}
episode index:2248
target Thresh 14.999842343721975
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([3.3937833, 7.66486  , 1.0438664], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.6401294738770963
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([3.967003 , 9.467224 , 0.9618883], dtype=float32)}
episode index:2249
target Thresh 14.999843130035941
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([3.6841335 , 1.7089801 , 0.01952523], dtype=float32)}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6402634075106625
{'scaleFactor': 30, 'timeStep': 7, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([3.040398 , 5.625061 , 1.4248666], dtype=float32)}
episode index:2250
target Thresh 14.999843912428151
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([ 8.043316 , 10.147678 ,  5.9188013], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6404232194131455
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([ 8.043316 , 10.147678 ,  5.9188013], dtype=float32)}
episode index:2251
target Thresh 14.999844690918163
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([9.005049, 9.914185, 4.831036], dtype=float32)}
done in step count: 62
reward sum = 0.536268225207185
running average episode reward sum: 0.6403769694157183
{'scaleFactor': 30, 'timeStep': 63, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([ 3.6907198, 10.745498 ,  4.5627313], dtype=float32)}
episode index:2252
target Thresh 14.999845465525441
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([11.93279  ,  6.1886363,  3.4267654], dtype=float32)}
done in step count: 212
reward sum = 0.11875755691154309
running average episode reward sum: 0.6401454472619215
{'scaleFactor': 30, 'timeStep': 213, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([1.8347996, 5.2132297, 4.422365 ], dtype=float32)}
episode index:2253
target Thresh 14.999846236269349
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([5.132782  , 9.974422  , 0.05158168], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6403050987937485
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([5.132782  , 9.974422  , 0.05158168], dtype=float32)}
episode index:2254
target Thresh 14.999847003169155
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([11.959537  ,  5.005338  ,  0.45278996], dtype=float32)}
done in step count: 298
reward sum = 0.050036622866325604
running average episode reward sum: 0.6400433389374615
{'scaleFactor': 30, 'timeStep': 299, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([7.935273 , 7.4952483, 2.2749317], dtype=float32)}
episode index:2255
target Thresh 14.999847766244033
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([4.621583 , 8.66257  , 6.1586857], dtype=float32)}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.6401940732730388
{'scaleFactor': 30, 'timeStep': 3, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([8.262654 , 8.955442 , 6.2608056], dtype=float32)}
episode index:2256
target Thresh 14.999848525513057
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([9.069938  , 9.37163   , 0.12667742], dtype=float32)}
done in step count: 63
reward sum = 0.5309055429551132
running average episode reward sum: 0.640145651239225
{'scaleFactor': 30, 'timeStep': 64, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([4.661809 , 8.96795  , 2.9779332], dtype=float32)}
episode index:2257
target Thresh 14.999849280995212
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([ 9.692616  , 10.445735  ,  0.57222605], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.6403005911633883
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([11.291536  , 11.257412  ,  0.11760327], dtype=float32)}
episode index:2258
target Thresh 14.999850032709384
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([8.905341 , 8.989929 , 1.1804966], dtype=float32)}
done in step count: 39
reward sum = 0.6757290490602831
running average episode reward sum: 0.6403162744116826
{'scaleFactor': 30, 'timeStep': 40, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([2.987751 , 6.854761 , 2.5243013], dtype=float32)}
episode index:2259
target Thresh 14.999850780674368
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([2.4223957, 6.9348288, 1.141499 ], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.6404710017238898
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([3.9792266 , 8.13428   , 0.90341574], dtype=float32)}
episode index:2260
target Thresh 14.999851524908859
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([6.0152397, 9.933858 , 2.474423 ], dtype=float32)}
done in step count: 56
reward sum = 0.5696012024771592
running average episode reward sum: 0.6404396572748643
{'scaleFactor': 30, 'timeStep': 57, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([1.5440534, 5.612434 , 4.3397765], dtype=float32)}
episode index:2261
target Thresh 14.999852265431464
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([12.117244 ,  7.2321277,  3.8050761], dtype=float32)}
done in step count: 17
reward sum = 0.8429431933839268
running average episode reward sum: 0.64052918138455
{'scaleFactor': 30, 'timeStep': 18, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([5.9886036, 7.4624195, 2.8234694], dtype=float32)}
episode index:2262
target Thresh 14.9998530022607
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([10.123182,  8.984935,  2.74262 ], dtype=float32)}
done in step count: 56
reward sum = 0.5696012024771592
running average episode reward sum: 0.6404978389281172
{'scaleFactor': 30, 'timeStep': 57, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([0.05673738, 3.8623335 , 4.3158627 ], dtype=float32)}
episode index:2263
target Thresh 14.999853735414984
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([10.989312 ,  9.857561 ,  1.3971813], dtype=float32)}
done in step count: 14
reward sum = 0.8687458127689782
running average episode reward sum: 0.6405986551709797
{'scaleFactor': 30, 'timeStep': 15, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([3.6163065, 6.9128075, 3.2312784], dtype=float32)}
episode index:2264
target Thresh 14.999854464912644
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([ 2.8308282, 10.243701 ,  4.4090676], dtype=float32)}
done in step count: 45
reward sum = 0.6361854860638709
running average episode reward sum: 0.6405967067519479
{'scaleFactor': 30, 'timeStep': 46, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([5.948135, 8.548213, 1.212837], dtype=float32)}
episode index:2265
target Thresh 14.99985519077192
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([6.8595986, 9.962181 , 5.551396 ], dtype=float32)}
done in step count: 25
reward sum = 0.7778213593991467
running average episode reward sum: 0.6406572648510861
{'scaleFactor': 30, 'timeStep': 26, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([ 4.984986, 11.855126,  3.340149], dtype=float32)}
episode index:2266
target Thresh 14.999855913010958
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([8.08097 , 9.253824, 0.571141], dtype=float32)}
done in step count: 51
reward sum = 0.598956006466161
running average episode reward sum: 0.6406388699422264
{'scaleFactor': 30, 'timeStep': 52, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([3.5747614, 8.174913 , 2.4689398], dtype=float32)}
episode index:2267
target Thresh 14.999856631647814
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([8.91019  , 9.305309 , 4.6172647], dtype=float32)}
done in step count: 53
reward sum = 0.5870367819374844
running average episode reward sum: 0.6406152358646229
{'scaleFactor': 30, 'timeStep': 54, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([ 2.1658053, 10.641503 ,  3.0304565], dtype=float32)}
episode index:2268
target Thresh 14.999857346700454
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([1.8815573, 7.893802 , 5.959614 ], dtype=float32)}
done in step count: 36
reward sum = 0.6964132180495735
running average episode reward sum: 0.6406398273067494
{'scaleFactor': 30, 'timeStep': 37, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([9.2194605 , 9.030552  , 0.09179991], dtype=float32)}
episode index:2269
target Thresh 14.999858058186753
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([6.696213, 9.075592, 4.854894], dtype=float32)}
done in step count: 28
reward sum = 0.7547192872036326
running average episode reward sum: 0.6406900825754265
{'scaleFactor': 30, 'timeStep': 29, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([ 3.888438 , 10.552508 ,  2.4423766], dtype=float32)}
episode index:2270
target Thresh 14.9998587661245
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([12.130413 ,  9.897693 ,  2.1277761], dtype=float32)}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.6408102178307802
{'scaleFactor': 30, 'timeStep': 10, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([ 6.4680357, 11.588577 ,  3.1041563], dtype=float32)}
episode index:2271
target Thresh 14.999859470531392
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([6.100906 , 9.9004965, 0.8787033], dtype=float32)}
done in step count: 41
reward sum = 0.6622820409839835
running average episode reward sum: 0.640819668457168
{'scaleFactor': 30, 'timeStep': 42, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([7.6467  , 8.42806 , 5.916757], dtype=float32)}
episode index:2272
target Thresh 14.999860171425043
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([10.321522,  8.673688,  4.608805], dtype=float32)}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.6409356220016253
{'scaleFactor': 30, 'timeStep': 11, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([3.044368 , 9.934182 , 3.2287197], dtype=float32)}
episode index:2273
target Thresh 14.999860868822969
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([12.012129 ,  3.3146856,  5.644573 ], dtype=float32)}
done in step count: 89
reward sum = 0.40882017442254925
running average episode reward sum: 0.6408335483659265
{'scaleFactor': 30, 'timeStep': 90, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([11.915096 ,  8.955851 ,  2.2692904], dtype=float32)}
episode index:2274
target Thresh 14.999861562742609
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([8.662546 , 6.986159 , 4.9901915], dtype=float32)}
done in step count: 17
reward sum = 0.8429431933839268
running average episode reward sum: 0.6409223877703301
{'scaleFactor': 30, 'timeStep': 18, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([10.554092  ,  8.976404  ,  0.96108955], dtype=float32)}
episode index:2275
target Thresh 14.99986225320131
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([2.2153008, 1.6925359, 1.3139977], dtype=float32)}
done in step count: 83
reward sum = 0.43423132679181164
running average episode reward sum: 0.6408315744746453
{'scaleFactor': 30, 'timeStep': 84, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([10.983014 ,  4.6848135,  5.3231773], dtype=float32)}
episode index:2276
target Thresh 14.999862940216335
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([3.852861  , 7.6146746 , 0.23123142], dtype=float32)}
done in step count: 38
reward sum = 0.682554595010387
running average episode reward sum: 0.6408498981551616
{'scaleFactor': 30, 'timeStep': 39, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([12.652741  ,  7.0584583 ,  0.30307704], dtype=float32)}
episode index:2277
target Thresh 14.999863623804858
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([10.111803 ,  9.045917 ,  2.8155854], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.6410031686125123
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([ 8.650096 , 10.612852 ,  2.4938495], dtype=float32)}
episode index:2278
target Thresh 14.99986430398397
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([12.014879,  4.967474,  5.709339], dtype=float32)}
done in step count: 31
reward sum = 0.7323033696543975
running average episode reward sum: 0.6410432301311791
{'scaleFactor': 30, 'timeStep': 32, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([11.39903 ,  9.113708,  0.943727], dtype=float32)}
episode index:2279
target Thresh 14.999864980770672
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([1.8979189, 5.82716  , 4.229067 ], dtype=float32)}
done in step count: 143
reward sum = 0.23759255478829303
running average episode reward sum: 0.6408662780805902
{'scaleFactor': 30, 'timeStep': 144, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([ 7.1094975, 10.889156 ,  3.4560757], dtype=float32)}
episode index:2280
target Thresh 14.999865654181889
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([3.8284168, 8.417447 , 5.9349837], dtype=float32)}
done in step count: 198
reward sum = 0.136700004956598
running average episode reward sum: 0.6406452494645779
{'scaleFactor': 30, 'timeStep': 199, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([9.015074, 9.815047, 5.176471], dtype=float32)}
episode index:2281
target Thresh 14.999866324234452
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([ 6.887306 , 10.344307 ,  3.1029081], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6408027230625338
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([ 6.887306 , 10.344307 ,  3.1029081], dtype=float32)}
episode index:2282
target Thresh 14.999866990945115
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([ 5.2768617, 10.018412 ,  5.828711 ], dtype=float32)}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.6409427989657039
{'scaleFactor': 30, 'timeStep': 5, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([3.9235163, 6.1705256, 3.9379935], dtype=float32)}
episode index:2283
target Thresh 14.999867654330544
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([8.039823  , 9.949443  , 0.25773633], dtype=float32)}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.641082752210465
{'scaleFactor': 30, 'timeStep': 5, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([11.527696,  8.38137 ,  5.711007], dtype=float32)}
episode index:2284
target Thresh 14.999868314407323
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([11.914566 ,  8.020864 ,  5.3389506], dtype=float32)}
done in step count: 19
reward sum = 0.8261686238355866
running average episode reward sum: 0.6411637525919202
{'scaleFactor': 30, 'timeStep': 20, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([7.5395117, 7.2772646, 2.968523 ], dtype=float32)}
episode index:2285
target Thresh 14.999868971191956
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([1.3550851, 3.864891 , 4.557436 ], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6413207238287566
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([1.3550851, 3.864891 , 4.557436 ], dtype=float32)}
episode index:2286
target Thresh 14.999869624700864
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([3.2572958, 9.163081 , 3.573754 ], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6414775577929767
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([3.2572958, 9.163081 , 3.573754 ], dtype=float32)}
episode index:2287
target Thresh 14.99987027495038
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([11.893352 ,  2.9167674,  0.1548683], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.6416298840352
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([12.154433 ,  3.1653786,  6.1398273], dtype=float32)}
episode index:2288
target Thresh 14.999870921956765
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([11.750641  ,  3.1984174 ,  0.46170282], dtype=float32)}
done in step count: 29
reward sum = 0.7471720943315961
running average episode reward sum: 0.6416759924713278
{'scaleFactor': 30, 'timeStep': 30, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([ 3.6835444, 10.204684 ,  3.007495 ], dtype=float32)}
episode index:2289
target Thresh 14.999871565736191
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([11.888812  ,  1.8991789 ,  0.23875953], dtype=float32)}
done in step count: 45
reward sum = 0.6361854860638709
running average episode reward sum: 0.6416735948702764
{'scaleFactor': 30, 'timeStep': 46, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([ 3.7385507, 11.653669 ,  3.975366 ], dtype=float32)}
episode index:2290
target Thresh 14.999872206304754
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([3.6083994, 5.9911065, 5.573678 ], dtype=float32)}
done in step count: 151
reward sum = 0.2192372693664723
running average episode reward sum: 0.641489205378568
{'scaleFactor': 30, 'timeStep': 152, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([11.352064, 10.364797,  4.958253], dtype=float32)}
episode index:2291
target Thresh 14.999872843678467
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([ 3.4406052 , 11.151387  ,  0.53160137], dtype=float32)}
done in step count: 37
reward sum = 0.6894490858690777
running average episode reward sum: 0.6415101302827959
{'scaleFactor': 30, 'timeStep': 38, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([ 9.871139, 10.454477,  5.739647], dtype=float32)}
episode index:2292
target Thresh 14.999873477873267
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([ 9.317746 , 10.105901 ,  2.2844808], dtype=float32)}
done in step count: 116
reward sum = 0.3116610814491425
running average episode reward sum: 0.6413662798471946
{'scaleFactor': 30, 'timeStep': 117, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([1.8500631, 2.635443 , 3.9679508], dtype=float32)}
episode index:2293
target Thresh 14.999874108905008
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([11.176219 ,  8.883877 ,  3.1164079], dtype=float32)}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.6415096681297373
{'scaleFactor': 30, 'timeStep': 4, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([7.750558 , 7.711364 , 3.5795028], dtype=float32)}
episode index:2294
target Thresh 14.999874736789462
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([ 9.860346, 10.127124,  5.240706], dtype=float32)}
done in step count: 237
reward sum = 0.09237216435585796
running average episode reward sum: 0.6412703925289643
{'scaleFactor': 30, 'timeStep': 238, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([3.5123582, 4.821394 , 4.175232 ], dtype=float32)}
episode index:2295
target Thresh 14.999875361542331
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([9.248321 , 9.156069 , 2.2273204], dtype=float32)}
done in step count: 323
reward sum = 0.038919554017627804
running average episode reward sum: 0.6410080446027835
{'scaleFactor': 30, 'timeStep': 324, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([3.6022906, 6.5733914, 3.810885 ], dtype=float32)}
episode index:2296
target Thresh 14.999875983179232
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([8.03755  , 9.6583395, 5.618613 ], dtype=float32)}
done in step count: 137
reward sum = 0.2523606630893462
running average episode reward sum: 0.640838846787584
{'scaleFactor': 30, 'timeStep': 138, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([2.5263984, 8.855207 , 1.3063397], dtype=float32)}
episode index:2297
target Thresh 14.999876601715707
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([2.101786 , 7.133295 , 6.2409334], dtype=float32)}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6409696741603488
{'scaleFactor': 30, 'timeStep': 7, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([11.451666,  8.107279,  6.152977], dtype=float32)}
episode index:2298
target Thresh 14.999877217167217
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([11.832993  ,  2.2401083 ,  0.32130024], dtype=float32)}
done in step count: 113
reward sum = 0.3212010745647914
running average episode reward sum: 0.6408305838603943
{'scaleFactor': 30, 'timeStep': 114, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([8.0208645, 7.154292 , 2.0572555], dtype=float32)}
episode index:2299
target Thresh 14.99987782954915
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([12.057468 ,  9.7936325,  2.3733983], dtype=float32)}
done in step count: 62
reward sum = 0.536268225207185
running average episode reward sum: 0.6407851219653277
{'scaleFactor': 30, 'timeStep': 63, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([ 9.512838, 10.363592,  5.423899], dtype=float32)}
episode index:2300
target Thresh 14.999878438876816
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([10.923254,  9.113748,  5.360871], dtype=float32)}
done in step count: 42
reward sum = 0.6556592205741436
running average episode reward sum: 0.6407915861542058
{'scaleFactor': 30, 'timeStep': 43, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([7.5233507, 9.186172 , 1.7604669], dtype=float32)}
episode index:2301
target Thresh 14.999879045165448
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([ 7.929249 , 10.204587 ,  1.0740794], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6409476280368496
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([ 7.929249 , 10.204587 ,  1.0740794], dtype=float32)}
episode index:2302
target Thresh 14.999879648430202
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([3.2456992, 8.952263 , 2.694679 ], dtype=float32)}
done in step count: 44
reward sum = 0.6426116020847181
running average episode reward sum: 0.6409483505614036
{'scaleFactor': 30, 'timeStep': 45, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([1.0882082, 4.461772 , 4.7834415], dtype=float32)}
episode index:2303
target Thresh 14.99988024868616
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([8.0078535, 9.273117 , 0.4306442], dtype=float32)}
done in step count: 104
reward sum = 0.35160920655802225
running average episode reward sum: 0.6408227693357077
{'scaleFactor': 30, 'timeStep': 105, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([3.2504678, 8.497141 , 2.5191846], dtype=float32)}
episode index:2304
target Thresh 14.99988084594833
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([1.9477293, 2.2210197, 3.9939928], dtype=float32)}
done in step count: 55
reward sum = 0.5753547499769285
running average episode reward sum: 0.6407943667242723
{'scaleFactor': 30, 'timeStep': 56, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([3.922741 , 5.488575 , 1.0898027], dtype=float32)}
episode index:2305
target Thresh 14.999881440231642
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([9.08678 , 9.07602 , 5.795522], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.6409458002165861
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([10.427496 ,  7.682402 ,  5.4665337], dtype=float32)}
episode index:2306
target Thresh 14.999882031550953
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([1.7960503 , 2.642967  , 0.48752314], dtype=float32)}
done in step count: 246
reward sum = 0.08438356532646984
running average episode reward sum: 0.6407045508733308
{'scaleFactor': 30, 'timeStep': 247, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([13.085392 ,  3.0713294,  5.46837  ], dtype=float32)}
episode index:2307
target Thresh 14.999882619921049
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([11.980217 ,  2.9319255,  0.511423 ], dtype=float32)}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.6408267519753907
{'scaleFactor': 30, 'timeStep': 9, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([10.57016  , 10.741962 ,  2.4665565], dtype=float32)}
episode index:2308
target Thresh 14.999883205356634
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([ 3.1156123, 10.055765 ,  3.270641 ], dtype=float32)}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.6409448509340345
{'scaleFactor': 30, 'timeStep': 10, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([0.10245749, 3.5154588 , 3.6560707 ], dtype=float32)}
episode index:2309
target Thresh 14.999883787872347
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([12.184279 ,  3.0374064,  4.578577 ], dtype=float32)}
done in step count: 159
reward sum = 0.2023000271287771
running average episode reward sum: 0.6407549613999197
{'scaleFactor': 30, 'timeStep': 160, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([2.5900033, 4.872377 , 3.4930806], dtype=float32)}
episode index:2310
target Thresh 14.999884367482752
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([10.880444 , 10.25383  ,  1.4875656], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6409104114382581
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([10.880444 , 10.25383  ,  1.4875656], dtype=float32)}
episode index:2311
target Thresh 14.999884944202337
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([11.786245 ,  3.9130304,  5.168827 ], dtype=float32)}
done in step count: 127
reward sum = 0.27904208858505886
running average episode reward sum: 0.6407538939975777
{'scaleFactor': 30, 'timeStep': 128, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([11.593181 ,  5.293457 ,  2.0748131], dtype=float32)}
episode index:2312
target Thresh 14.999885518045524
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([1.9923309 , 9.233688  , 0.98122084], dtype=float32)}
done in step count: 173
reward sum = 0.1757473014911758
running average episode reward sum: 0.6405528535338914
{'scaleFactor': 30, 'timeStep': 174, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([0.6791426, 3.1159053, 4.543831 ], dtype=float32)}
episode index:2313
target Thresh 14.999886089026653
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([ 4.9110312, 10.111933 ,  5.119724 ], dtype=float32)}
done in step count: 39
reward sum = 0.6757290490602831
running average episode reward sum: 0.6405680550012752
{'scaleFactor': 30, 'timeStep': 40, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([11.499775  ,  8.110831  ,  0.01250938], dtype=float32)}
episode index:2314
target Thresh 14.999886657160003
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([3.1131923, 9.696794 , 4.7665787], dtype=float32)}
done in step count: 293
reward sum = 0.05261529589251448
running average episode reward sum: 0.6403140797273622
{'scaleFactor': 30, 'timeStep': 294, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([ 9.15141  , 10.989969 ,  3.1192203], dtype=float32)}
episode index:2315
target Thresh 14.999887222459774
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([1.677623 , 3.9325643, 1.6634479], dtype=float32)}
done in step count: 175
reward sum = 0.1722499301915014
running average episode reward sum: 0.6401119794900842
{'scaleFactor': 30, 'timeStep': 176, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([12.493999 ,  2.7334814,  5.5818505], dtype=float32)}
episode index:2316
target Thresh 14.999887784940103
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([5.370654 , 8.487534 , 5.4894786], dtype=float32)}
done in step count: 399
reward sum = 0.0
running average episode reward sum: 0.6398357119115387
{'scaleFactor': 30, 'timeStep': 400, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([ 0.38177687, 11.778111  ,  0.699432  ], dtype=float32)}
episode index:2317
target Thresh 14.99988834461505
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([10.378219,  9.041116,  3.261154], dtype=float32)}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.6399782758839668
{'scaleFactor': 30, 'timeStep': 4, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([ 4.613797, 11.333571,  2.373832], dtype=float32)}
episode index:2318
target Thresh 14.999888901498606
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([1.7476324, 5.9259634, 3.4967873], dtype=float32)}
done in step count: 40
reward sum = 0.6689717585696803
running average episode reward sum: 0.6399907784638226
{'scaleFactor': 30, 'timeStep': 41, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([0.9996687, 7.2084537, 5.548798 ], dtype=float32)}
episode index:2319
target Thresh 14.999889455604695
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([7.8893065, 9.988445 , 2.2222755], dtype=float32)}
done in step count: 219
reward sum = 0.11068980359934157
running average episode reward sum: 0.6397626314918982
{'scaleFactor': 30, 'timeStep': 220, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([10.859301 ,  4.494567 ,  5.1988063], dtype=float32)}
episode index:2320
target Thresh 14.999890006947165
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([10.023605 ,  8.864243 ,  1.0601209], dtype=float32)}
done in step count: 146
reward sum = 0.23053581831852593
running average episode reward sum: 0.6395863166219398
{'scaleFactor': 30, 'timeStep': 147, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([ 3.9756668, 10.142728 ,  1.7218533], dtype=float32)}
episode index:2321
target Thresh 14.999890555539805
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([3.1254478, 4.486439 , 0.4679588], dtype=float32)}
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.6396887863490617
{'scaleFactor': 30, 'timeStep': 14, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([3.1459346, 8.503712 , 2.6768503], dtype=float32)}
episode index:2322
target Thresh 14.999891101396328
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([8.10621 , 8.946354, 5.863591], dtype=float32)}
done in step count: 78
reward sum = 0.4566097477439145
running average episode reward sum: 0.6396099748817328
{'scaleFactor': 30, 'timeStep': 79, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([0.70016843, 1.9934897 , 4.1848226 ], dtype=float32)}
episode index:2323
target Thresh 14.999891644530377
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([3.8348572 , 7.79971   , 0.33638102], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.6397607451162932
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([5.684206  , 8.6480665 , 0.38122156], dtype=float32)}
episode index:2324
target Thresh 14.999892184955538
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([4.9267936, 8.839871 , 3.7854474], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.6399113856560281
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([3.1380174, 8.064882 , 3.2379377], dtype=float32)}
episode index:2325
target Thresh 14.999892722685315
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([4.072833  , 4.603635  , 0.29701376], dtype=float32)}
done in step count: 78
reward sum = 0.4566097477439145
running average episode reward sum: 0.6398325801367194
{'scaleFactor': 30, 'timeStep': 79, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([11.123495  ,  7.8552346 ,  0.48433027], dtype=float32)}
episode index:2326
target Thresh 14.999893257733154
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([6.271119 , 8.003535 , 5.0952063], dtype=float32)}
done in step count: 137
reward sum = 0.2523606630893462
running average episode reward sum: 0.639666068784314
{'scaleFactor': 30, 'timeStep': 138, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([11.924008,  3.903883,  4.211303], dtype=float32)}
episode index:2327
target Thresh 14.999893790112433
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([4.962425 , 9.057745 , 3.8341327], dtype=float32)}
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.6397720476515527
{'scaleFactor': 30, 'timeStep': 13, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([3.7380476, 4.888188 , 3.8342466], dtype=float32)}
episode index:2328
target Thresh 14.999894319836457
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([ 5.949426 , 10.2904825,  0.7766397], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6399267183052018
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([ 5.949426 , 10.2904825,  0.7766397], dtype=float32)}
episode index:2329
target Thresh 14.99989484691847
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([12.047509 ,  6.992261 ,  3.8752198], dtype=float32)}
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.6400363369901603
{'scaleFactor': 30, 'timeStep': 12, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([11.796632,  8.105384,  4.143838], dtype=float32)}
episode index:2330
target Thresh 14.999895371371652
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([11.836388 ,  7.0525045,  1.7896049], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.640186471551726
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([10.667014 ,  8.656756 ,  2.2553363], dtype=float32)}
episode index:2331
target Thresh 14.999895893209114
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([ 4.9330974, 10.173232 ,  0.3997531], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.640340765517613
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([ 4.9330974, 10.173232 ,  0.3997531], dtype=float32)}
episode index:2332
target Thresh 14.9998964124439
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([4.850383 , 9.927437 , 2.8978336], dtype=float32)}
done in step count: 80
reward sum = 0.4475232137638106
running average episode reward sum: 0.6402581176171612
{'scaleFactor': 30, 'timeStep': 81, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([1.1386726, 3.1983037, 5.0654483], dtype=float32)}
episode index:2333
target Thresh 14.99989692908899
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([2.0012786, 7.219987 , 1.8421786], dtype=float32)}
done in step count: 176
reward sum = 0.17052743088958636
running average episode reward sum: 0.6400568619673208
{'scaleFactor': 30, 'timeStep': 177, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([5.2802625, 8.635802 , 5.7806015], dtype=float32)}
episode index:2334
target Thresh 14.999897443157304
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([11.931236  ,  9.342059  ,  0.78595006], dtype=float32)}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.6401739756227882
{'scaleFactor': 30, 'timeStep': 10, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([7.7771   , 9.712175 , 3.0241044], dtype=float32)}
episode index:2335
target Thresh 14.99989795466169
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([11.020977 , 10.1767845,  2.242214 ], dtype=float32)}
done in step count: 52
reward sum = 0.5929664464014994
running average episode reward sum: 0.6401537669202106
{'scaleFactor': 30, 'timeStep': 53, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([1.862974 , 4.306883 , 3.5422592], dtype=float32)}
episode index:2336
target Thresh 14.999898463614938
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([5.8160152, 8.668745 , 5.4722376], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6403077447691964
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([5.8160152, 8.668745 , 5.4722376], dtype=float32)}
episode index:2337
target Thresh 14.999898970029772
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([3.989292 , 9.214295 , 1.9268317], dtype=float32)}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.6404246008439246
{'scaleFactor': 30, 'timeStep': 10, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([2.8618484, 7.679918 , 3.8737175], dtype=float32)}
episode index:2338
target Thresh 14.99989947391885
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([11.739594 ,  2.0344665,  6.1183643], dtype=float32)}
done in step count: 97
reward sum = 0.37723664692350417
running average episode reward sum: 0.6403120792732018
{'scaleFactor': 30, 'timeStep': 98, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([ 9.726079 , 11.184269 ,  2.8393173], dtype=float32)}
episode index:2339
target Thresh 14.999899975294774
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([1.8060334 , 2.9675763 , 0.52240765], dtype=float32)}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.6404327769719859
{'scaleFactor': 30, 'timeStep': 9, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([7.310506  , 9.165706  , 0.01512688], dtype=float32)}
episode index:2340
target Thresh 14.99990047417007
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([5.0517464, 9.10561  , 1.4627029], dtype=float32)}
done in step count: 82
reward sum = 0.43861750180991077
running average episode reward sum: 0.6403465679693535
{'scaleFactor': 30, 'timeStep': 83, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([10.596416 ,  5.049633 ,  5.2323327], dtype=float32)}
episode index:2341
target Thresh 14.999900970557219
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([2.1514292, 3.7906528, 3.272509 ], dtype=float32)}
done in step count: 121
reward sum = 0.296386587399208
running average episode reward sum: 0.6401997020510912
{'scaleFactor': 30, 'timeStep': 122, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([ 4.3508244 , 10.636266  ,  0.06723881], dtype=float32)}
episode index:2342
target Thresh 14.999901464468625
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([5.019693 , 9.081643 , 3.6975987], dtype=float32)}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6403323483796652
{'scaleFactor': 30, 'timeStep': 6, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([0.06576753, 3.5772817 , 4.515189  ], dtype=float32)}
episode index:2343
target Thresh 14.999901955916638
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([2.4936569, 6.6216865, 1.7115636], dtype=float32)}
done in step count: 55
reward sum = 0.5753547499769285
running average episode reward sum: 0.640304627561234
{'scaleFactor': 30, 'timeStep': 56, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([13.654028 ,  2.680746 ,  4.5898266], dtype=float32)}
episode index:2344
target Thresh 14.999902444913545
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([7.963053 , 9.094031 , 2.7727633], dtype=float32)}
done in step count: 43
reward sum = 0.6491026283684022
running average episode reward sum: 0.6403083793739449
{'scaleFactor': 30, 'timeStep': 44, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([12.283012 ,  6.523736 ,  4.8530397], dtype=float32)}
episode index:2345
target Thresh 14.999902931471567
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([11.975404 ,  2.0356681,  0.5663707], dtype=float32)}
done in step count: 176
reward sum = 0.17052743088958636
running average episode reward sum: 0.6401081317403199
{'scaleFactor': 30, 'timeStep': 177, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([3.7959719, 8.423729 , 3.244713 ], dtype=float32)}
episode index:2346
target Thresh 14.999903415602873
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([8.056212 , 9.9992485, 5.3537116], dtype=float32)}
done in step count: 50
reward sum = 0.6050060671375364
running average episode reward sum: 0.6400931755986058
{'scaleFactor': 30, 'timeStep': 51, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([ 3.2905965, 10.407296 ,  2.939741 ], dtype=float32)}
episode index:2347
target Thresh 14.999903897319562
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([11.893393 ,  5.8746896,  5.6513987], dtype=float32)}
done in step count: 14
reward sum = 0.8687458127689782
running average episode reward sum: 0.640190557471336
{'scaleFactor': 30, 'timeStep': 15, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([11.589499 ,  7.026066 ,  1.6063832], dtype=float32)}
episode index:2348
target Thresh 14.999904376633681
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([9.924126 , 9.061154 , 1.8758638], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6403437330535108
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([9.924126 , 9.061154 , 1.8758638], dtype=float32)}
episode index:2349
target Thresh 14.99990485355721
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([1.9545152, 2.2257907, 4.6874733], dtype=float32)}
done in step count: 125
reward sum = 0.28470777327319546
running average episode reward sum: 0.6401923986025404
{'scaleFactor': 30, 'timeStep': 126, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([4.012029 , 7.602606 , 2.6530542], dtype=float32)}
episode index:2350
target Thresh 14.999905328102074
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([10.654691 ,  9.649141 ,  2.0042212], dtype=float32)}
done in step count: 36
reward sum = 0.6964132180495735
running average episode reward sum: 0.6402163121795065
{'scaleFactor': 30, 'timeStep': 37, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([ 7.428057, 10.573965,  4.217723], dtype=float32)}
episode index:2351
target Thresh 14.999905800280134
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([1.865101 , 5.7555184, 1.9182842], dtype=float32)}
done in step count: 27
reward sum = 0.7623427143471035
running average episode reward sum: 0.640268236670224
{'scaleFactor': 30, 'timeStep': 28, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([9.999947 , 9.82605  , 5.6987014], dtype=float32)}
episode index:2352
target Thresh 14.999906270103198
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([2.2234411, 9.878067 , 1.1851995], dtype=float32)}
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.6403690665836659
{'scaleFactor': 30, 'timeStep': 14, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([11.475253  , 10.907311  ,  0.50775546], dtype=float32)}
episode index:2353
target Thresh 14.999906737583007
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([ 8.950415 , 10.2717905,  4.491275 ], dtype=float32)}
done in step count: 16
reward sum = 0.8514577710948755
running average episode reward sum: 0.6404587389305271
{'scaleFactor': 30, 'timeStep': 17, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([10.1787195,  9.400504 ,  6.1425548], dtype=float32)}
episode index:2354
target Thresh 14.999907202731253
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([7.223203 , 9.239409 , 3.2704158], dtype=float32)}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6405905993598134
{'scaleFactor': 30, 'timeStep': 6, 'currentTarget': array([2, 3], dtype=int32), 'previousTarget': array([2, 3], dtype=int32), 'currentState': array([3.2590988, 3.2996342, 4.6776776], dtype=float32)}
episode index:2355
target Thresh 14.999907665559562
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([ 9.757272 , 10.0731125,  1.1286073], dtype=float32)}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6407143152972273
{'scaleFactor': 30, 'timeStep': 8, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([ 4.7213297, 11.203593 ,  3.2874055], dtype=float32)}
episode index:2356
target Thresh 14.999908126079506
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([7.1547623, 8.947221 , 6.2806993], dtype=float32)}
done in step count: 23
reward sum = 0.7936142836436554
running average episode reward sum: 0.6407791858820158
{'scaleFactor': 30, 'timeStep': 24, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([1.050746 , 7.8437386, 3.2991517], dtype=float32)}
episode index:2357
target Thresh 14.999908584302595
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([4.9633183, 8.934333 , 1.6911881], dtype=float32)}
done in step count: 85
reward sum = 0.4255901233886546
running average episode reward sum: 0.6406879267376165
{'scaleFactor': 30, 'timeStep': 86, 'currentTarget': array([ 9, 10], dtype=int32), 'previousTarget': array([ 9, 10], dtype=int32), 'currentState': array([7.1493354, 8.945475 , 2.6557398], dtype=float32)}
episode index:2358
target Thresh 14.999909040240288
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([7.9866385 , 9.048534  , 0.18844926], dtype=float32)}
done in step count: 26
reward sum = 0.7700431458051551
running average episode reward sum: 0.6407427615061911
{'scaleFactor': 30, 'timeStep': 27, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([12.451884 ,  8.793143 ,  3.1168318], dtype=float32)}
episode index:2359
target Thresh 14.999909493903981
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([4.141388 , 7.9889436, 6.2631044], dtype=float32)}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.6408782925436886
{'scaleFactor': 30, 'timeStep': 5, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([11.812607  ,  8.020153  ,  0.67244357], dtype=float32)}
episode index:2360
target Thresh 14.999909945305019
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([1.878129, 8.017628, 2.260566], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6410303983071177
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([1.878129, 8.017628, 2.260566], dtype=float32)}
episode index:2361
target Thresh 14.999910394454684
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([4.712872  , 9.077719  , 0.71979123], dtype=float32)}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.6411698007633806
{'scaleFactor': 30, 'timeStep': 4, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([10.081584 ,  9.922214 ,  5.1449904], dtype=float32)}
episode index:2362
target Thresh 14.999910841364205
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([8.039702  , 9.145691  , 0.34069365], dtype=float32)}
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.6412735735399158
{'scaleFactor': 30, 'timeStep': 13, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([ 5.7322974, 11.450292 ,  2.3014958], dtype=float32)}
episode index:2363
target Thresh 14.999911286044757
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([12.237886 ,  3.7698383,  5.7920947], dtype=float32)}
done in step count: 24
reward sum = 0.7856781408072188
running average episode reward sum: 0.6413346583822455
{'scaleFactor': 30, 'timeStep': 25, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([7.610743 , 7.434306 , 2.9747503], dtype=float32)}
episode index:2364
target Thresh 14.999911728507454
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([10.873245 ,  8.862889 ,  0.0839096], dtype=float32)}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.6414458835055548
{'scaleFactor': 30, 'timeStep': 11, 'currentTarget': array([ 8, 10], dtype=int32), 'previousTarget': array([ 8, 10], dtype=int32), 'currentState': array([9.8365555, 9.333441 , 4.9985414], dtype=float32)}
episode index:2365
target Thresh 14.999912168763359
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([10.90798  ,  9.901937 ,  2.4755201], dtype=float32)}
done in step count: 137
reward sum = 0.2523606630893462
running average episode reward sum: 0.6412814349762157
{'scaleFactor': 30, 'timeStep': 138, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([ 7.215297 , 10.684982 ,  3.4696908], dtype=float32)}
episode index:2366
target Thresh 14.99991260682348
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([ 8.866686  , 10.133858  ,  0.21511823], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.6414287600987437
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([10.697761  , 10.35481   ,  0.40993723], dtype=float32)}
episode index:2367
target Thresh 14.999913042698767
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([11.91868  , 10.070392 ,  1.2308186], dtype=float32)}
done in step count: 65
reward sum = 0.5203405226503064
running average episode reward sum: 0.6413776248633347
{'scaleFactor': 30, 'timeStep': 66, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([ 3.8021555, 11.906465 ,  3.5943537], dtype=float32)}
episode index:2368
target Thresh 14.999913476400117
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([2.0493178, 2.9593928, 3.5797865], dtype=float32)}
done in step count: 360
reward sum = 0.026833050939885684
running average episode reward sum: 0.6411182138992471
{'scaleFactor': 30, 'timeStep': 361, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([10.138324 ,  2.2032168,  5.1094484], dtype=float32)}
episode index:2369
target Thresh 14.999913907938371
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([8.037633 , 9.00793  , 0.2679385], dtype=float32)}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.641261244188741
{'scaleFactor': 30, 'timeStep': 3, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([7.9644737, 8.697572 , 1.6036865], dtype=float32)}
episode index:2370
target Thresh 14.99991433732432
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([4.979712, 8.870637, 6.177283], dtype=float32)}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.641383894590984
{'scaleFactor': 30, 'timeStep': 8, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([13.35345  ,  4.9785485,  5.7794337], dtype=float32)}
episode index:2371
target Thresh 14.999914764568697
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([12.018069,  9.13356 ,  5.773544], dtype=float32)}
done in step count: 45
reward sum = 0.6361854860638709
running average episode reward sum: 0.6413817030190923
{'scaleFactor': 30, 'timeStep': 46, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([12.095735,  5.690312,  5.056104], dtype=float32)}
episode index:2372
target Thresh 14.999915189682184
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([7.0458083, 9.99355  , 0.8511733], dtype=float32)}
done in step count: 103
reward sum = 0.355160814705073
running average episode reward sum: 0.6412610873897986
{'scaleFactor': 30, 'timeStep': 104, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([3.243562 , 5.9656973, 5.0457435], dtype=float32)}
episode index:2373
target Thresh 14.999915612675409
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([2.4932065, 5.1559687, 1.2013555], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.6414079866790194
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([3.2513628, 7.0005813, 1.2963778], dtype=float32)}
episode index:2374
target Thresh 14.999916033558947
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([3.3206117 , 8.44725   , 0.52670103], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6415589727898914
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([3.3206117 , 8.44725   , 0.52670103], dtype=float32)}
episode index:2375
target Thresh 14.999916452343319
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([11.858897 ,  2.9433362,  3.096674 ], dtype=float32)}
done in step count: 45
reward sum = 0.6361854860638709
running average episode reward sum: 0.641556711221404
{'scaleFactor': 30, 'timeStep': 46, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([9.62678  , 9.466152 , 1.8409562], dtype=float32)}
episode index:2376
target Thresh 14.999916869038994
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([7.2286625, 9.0912   , 4.0487638], dtype=float32)}
done in step count: 56
reward sum = 0.5696012024771592
running average episode reward sum: 0.6415264396569343
{'scaleFactor': 30, 'timeStep': 57, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([10.771276 , 10.061386 ,  0.2054069], dtype=float32)}
episode index:2377
target Thresh 14.999917283656393
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([ 4.987852, 10.345553,  3.173579], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6416771854770955
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([ 4.987852, 10.345553,  3.173579], dtype=float32)}
episode index:2378
target Thresh 14.999917696205877
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([3.8807015, 8.79119  , 3.140493 ], dtype=float32)}
done in step count: 81
reward sum = 0.4430479816261725
running average episode reward sum: 0.6415936927474398
{'scaleFactor': 30, 'timeStep': 82, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([10.435694, 11.300564,  5.986202], dtype=float32)}
episode index:2379
target Thresh 14.999918106697763
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([11.865379 ,  4.95138  ,  3.4417765], dtype=float32)}
done in step count: 79
reward sum = 0.45204365026647536
running average episode reward sum: 0.6415140498724478
{'scaleFactor': 30, 'timeStep': 80, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([9.11214  , 8.606886 , 2.3156068], dtype=float32)}
episode index:2380
target Thresh 14.999918515142312
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([8.832138 , 9.851909 , 3.0668085], dtype=float32)}
done in step count: 118
reward sum = 0.3054590259283046
running average episode reward sum: 0.641372909585197
{'scaleFactor': 30, 'timeStep': 119, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([12.933329,  9.771939,  5.505629], dtype=float32)}
episode index:2381
target Thresh 14.999918921549735
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([11.581139 ,  7.118628 ,  5.3970885], dtype=float32)}
done in step count: 154
reward sum = 0.2127257032290187
running average episode reward sum: 0.6411929569376923
{'scaleFactor': 30, 'timeStep': 155, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([ 8.44264  , 11.848792 ,  3.3578875], dtype=float32)}
episode index:2382
target Thresh 14.999919325930192
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([10.657374 ,  6.2542233,  2.5860233], dtype=float32)}
done in step count: 79
reward sum = 0.45204365026647536
running average episode reward sum: 0.6411135824909147
{'scaleFactor': 30, 'timeStep': 80, 'currentTarget': array([2, 6], dtype=int32), 'previousTarget': array([2, 6], dtype=int32), 'currentState': array([0.30076376, 5.1155806 , 4.929635  ], dtype=float32)}
episode index:2383
target Thresh 14.999919728293795
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([2.43687  , 4.765806 , 1.5232012], dtype=float32)}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.6412557747801382
{'scaleFactor': 30, 'timeStep': 3, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([2.2787797, 8.881332 , 1.7332891], dtype=float32)}
episode index:2384
target Thresh 14.999920128650599
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([ 3.1522965, 10.647964 ,  4.308834 ], dtype=float32)}
done in step count: 25
reward sum = 0.7778213593991467
running average episode reward sum: 0.6413130349833328
{'scaleFactor': 30, 'timeStep': 26, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([2.3361475, 5.8452635, 5.667055 ], dtype=float32)}
episode index:2385
target Thresh 14.999920527010616
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([2.0983522, 7.1896515, 1.5893316], dtype=float32)}
done in step count: 252
reward sum = 0.07944545169055386
running average episode reward sum: 0.6410775498268816
{'scaleFactor': 30, 'timeStep': 253, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([13.645659 ,  3.4403672,  5.1872063], dtype=float32)}
episode index:2386
target Thresh 14.999920923383804
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([12.242     , 10.083928  ,  0.38329905], dtype=float32)}
done in step count: 64
reward sum = 0.525596487525562
running average episode reward sum: 0.6410291706637892
{'scaleFactor': 30, 'timeStep': 65, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([ 4.93901  , 10.788362 ,  3.6128204], dtype=float32)}
episode index:2387
target Thresh 14.999921317780073
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([11.899178 ,  8.985128 ,  1.0886571], dtype=float32)}
done in step count: 31
reward sum = 0.7323033696543975
running average episode reward sum: 0.6410673926901672
{'scaleFactor': 30, 'timeStep': 32, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([13.038788 ,  3.5188818,  3.9449043], dtype=float32)}
episode index:2388
target Thresh 14.999921710209282
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([9.928082 , 9.063469 , 4.5044713], dtype=float32)}
done in step count: 45
reward sum = 0.6361854860638709
running average episode reward sum: 0.641065349196393
{'scaleFactor': 30, 'timeStep': 46, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([5.106693, 8.462895, 3.275244], dtype=float32)}
episode index:2389
target Thresh 14.999922100681243
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([9.742918, 9.216247, 5.947015], dtype=float32)}
done in step count: 55
reward sum = 0.5753547499769285
running average episode reward sum: 0.6410378552218242
{'scaleFactor': 30, 'timeStep': 56, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([4.5416846, 9.313645 , 4.318541 ], dtype=float32)}
episode index:2390
target Thresh 14.999922489205716
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([9.920134, 7.354347, 3.315306], dtype=float32)}
done in step count: 21
reward sum = 0.8097278682212584
running average episode reward sum: 0.6411084072975245
{'scaleFactor': 30, 'timeStep': 22, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([7.09209 , 9.22618 , 1.678239], dtype=float32)}
episode index:2391
target Thresh 14.999922875792414
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([12.074608  ,  6.235378  ,  0.40188736], dtype=float32)}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.641246028782768
{'scaleFactor': 30, 'timeStep': 4, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([11.834288 ,  5.9523764,  0.6649719], dtype=float32)}
episode index:2392
target Thresh 14.999923260451006
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([9.517434 , 7.042845 , 4.5622487], dtype=float32)}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6413754663177105
{'scaleFactor': 30, 'timeStep': 6, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([10.512056 ,  4.6697435,  5.558957 ], dtype=float32)}
episode index:2393
target Thresh 14.999923643191103
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([1.7591398, 5.9311824, 2.337633 ], dtype=float32)}
done in step count: 29
reward sum = 0.7471720943315961
running average episode reward sum: 0.641419658727073
{'scaleFactor': 30, 'timeStep': 30, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([ 8.67547 , 10.151682,  5.076428], dtype=float32)}
episode index:2394
target Thresh 14.999924024022276
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([2.0293164, 9.976464 , 4.375154 ], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.6415652037547444
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([1.2277391, 8.010457 , 4.096062 ], dtype=float32)}
episode index:2395
target Thresh 14.999924402954045
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([6.0924416, 8.981287 , 3.555309 ], dtype=float32)}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6416864475544739
{'scaleFactor': 30, 'timeStep': 8, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([4.1848774, 7.7687364, 3.938217 ], dtype=float32)}
episode index:2396
target Thresh 14.999924779995885
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([ 9.9638195, 10.089681 ,  4.7870784], dtype=float32)}
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.6417922680829278
{'scaleFactor': 30, 'timeStep': 12, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([3.4936867, 6.5474315, 4.394228 ], dtype=float32)}
episode index:2397
target Thresh 14.99992515515722
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([1.9493994, 4.082771 , 4.059084 ], dtype=float32)}
done in step count: 49
reward sum = 0.611117239532865
running average episode reward sum: 0.6417794761610971
{'scaleFactor': 30, 'timeStep': 50, 'currentTarget': array([2, 9], dtype=int32), 'previousTarget': array([2, 9], dtype=int32), 'currentState': array([3.240867 , 7.1279087, 4.700979 ], dtype=float32)}
episode index:2398
target Thresh 14.99992552844743
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([11.917774,  5.834573,  4.870034], dtype=float32)}
done in step count: 27
reward sum = 0.7623427143471035
running average episode reward sum: 0.6418297317835173
{'scaleFactor': 30, 'timeStep': 28, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([10.574264 ,  8.141875 ,  2.8017747], dtype=float32)}
episode index:2399
target Thresh 14.999925899875848
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([2.22479  , 2.2365944, 0.5595891], dtype=float32)}
done in step count: 83
reward sum = 0.43423132679181164
running average episode reward sum: 0.641743232448104
{'scaleFactor': 30, 'timeStep': 84, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([8.552213 , 8.456106 , 6.0502887], dtype=float32)}
episode index:2400
target Thresh 14.999926269451759
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([8.24294  , 9.037888 , 2.8491504], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6418924439298
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([8.24294  , 9.037888 , 2.8491504], dtype=float32)}
episode index:2401
target Thresh 14.999926637184405
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([1.1558545, 4.827747 , 2.3401256], dtype=float32)}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6420171682035183
{'scaleFactor': 30, 'timeStep': 7, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([ 4.416849  , 10.166931  ,  0.33367068], dtype=float32)}
episode index:2402
target Thresh 14.999927003082972
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([8.3368635, 9.099482 , 3.4561179], dtype=float32)}
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.6421188609640311
{'scaleFactor': 30, 'timeStep': 13, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([ 9.801046 , 10.312177 ,  1.2006166], dtype=float32)}
episode index:2403
target Thresh 14.999927367156616
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([4.8969193, 8.391651 , 3.281037 ], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6422677299902525
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([4.8969193, 8.391651 , 3.281037 ], dtype=float32)}
episode index:2404
target Thresh 14.999927729414432
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([0.9756497, 7.2197695, 4.2064543], dtype=float32)}
done in step count: 167
reward sum = 0.18667127671570335
running average episode reward sum: 0.6420782927955437
{'scaleFactor': 30, 'timeStep': 168, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([12.82737  ,  6.9632244,  1.6470553], dtype=float32)}
episode index:2405
target Thresh 14.999928089865483
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([6.1573844, 9.444199 , 2.8590746], dtype=float32)}
done in step count: 36
reward sum = 0.6964132180495735
running average episode reward sum: 0.6421008758899968
{'scaleFactor': 30, 'timeStep': 37, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([10.325792 ,  3.0796247,  4.6027513], dtype=float32)}
episode index:2406
target Thresh 14.999928448518775
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([ 7.9867334, 10.160625 ,  1.9000611], dtype=float32)}
done in step count: 88
reward sum = 0.41294967113388814
running average episode reward sum: 0.6420056738938372
{'scaleFactor': 30, 'timeStep': 89, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([2.2532082, 6.128092 , 4.4690404], dtype=float32)}
episode index:2407
target Thresh 14.999928805383277
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([2.2343712, 9.207271 , 0.0408504], dtype=float32)}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.642142008331589
{'scaleFactor': 30, 'timeStep': 4, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([ 8.586654 , 10.75207  ,  0.4320555], dtype=float32)}
episode index:2408
target Thresh 14.999929160467907
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([10.954926  ,  9.911862  ,  0.41647068], dtype=float32)}
done in step count: 15
reward sum = 0.8600583546412884
running average episode reward sum: 0.6422324675870102
{'scaleFactor': 30, 'timeStep': 16, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([12.681544 ,  8.665294 ,  5.9317875], dtype=float32)}
episode index:2409
target Thresh 14.999929513781549
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([2.159625 , 9.113857 , 5.9368024], dtype=float32)}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6423566367495888
{'scaleFactor': 30, 'timeStep': 7, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([5.7914515 , 8.670231  , 0.19820184], dtype=float32)}
episode index:2410
target Thresh 14.99992986533303
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([2.1536124, 7.073037 , 3.651719 ], dtype=float32)}
done in step count: 52
reward sum = 0.5929664464014994
running average episode reward sum: 0.6423361513948197
{'scaleFactor': 30, 'timeStep': 53, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([ 1.9213896, 11.203683 ,  1.2574636], dtype=float32)}
episode index:2411
target Thresh 14.99993021513114
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([ 7.268816 , 10.297441 ,  5.8450184], dtype=float32)}
done in step count: 35
reward sum = 0.7034476949995692
running average episode reward sum: 0.642361487855684
{'scaleFactor': 30, 'timeStep': 36, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([3.7186663, 7.70691  , 2.9262881], dtype=float32)}
episode index:2412
target Thresh 14.999930563184625
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([12.0596895,  7.038228 ,  4.1254272], dtype=float32)}
done in step count: 45
reward sum = 0.6361854860638709
running average episode reward sum: 0.6423589283854014
{'scaleFactor': 30, 'timeStep': 46, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([3.0462155, 2.2251651, 5.067528 ], dtype=float32)}
episode index:2413
target Thresh 14.999930909502186
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([4.4066978, 9.359331 , 4.263593 ], dtype=float32)}
done in step count: 79
reward sum = 0.45204365026647536
running average episode reward sum: 0.6422800902420215
{'scaleFactor': 30, 'timeStep': 80, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([5.997553  , 8.11805   , 0.72732913], dtype=float32)}
episode index:2414
target Thresh 14.999931254092484
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([ 1.7964253, 10.1113205,  1.6391915], dtype=float32)}
done in step count: 87
reward sum = 0.41712087993322033
running average episode reward sum: 0.6421868566145644
{'scaleFactor': 30, 'timeStep': 88, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([9.260259 , 7.4214582, 6.1016774], dtype=float32)}
episode index:2415
target Thresh 14.999931596964126
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([12.799216 ,  6.641892 ,  1.1011318], dtype=float32)}
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.6422916378221986
{'scaleFactor': 30, 'timeStep': 12, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([10.998861 ,  9.369594 ,  2.8278973], dtype=float32)}
episode index:2416
target Thresh 14.999931938125691
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([2.0998356, 5.064056 , 5.158743 ], dtype=float32)}
done in step count: 31
reward sum = 0.7323033696543975
running average episode reward sum: 0.6423288789193571
{'scaleFactor': 30, 'timeStep': 32, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([8.224751 , 7.2903256, 0.3244111], dtype=float32)}
episode index:2417
target Thresh 14.999932277585705
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([12.204019 ,  3.9999475,  0.662943 ], dtype=float32)}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.642456530354833
{'scaleFactor': 30, 'timeStep': 6, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([12.704978 ,  6.155313 ,  1.8092787], dtype=float32)}
episode index:2418
target Thresh 14.999932615352657
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([ 5.870061 , 10.187117 ,  5.2170386], dtype=float32)}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.642588047295571
{'scaleFactor': 30, 'timeStep': 5, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([12.041343  ,  9.141573  ,  0.48997515], dtype=float32)}
episode index:2419
target Thresh 14.999932951434987
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([11.983956,  2.946867,  6.248538], dtype=float32)}
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.6426924895298531
{'scaleFactor': 30, 'timeStep': 12, 'currentTarget': array([12,  6], dtype=int32), 'previousTarget': array([12,  6], dtype=int32), 'currentState': array([12.998268  ,  4.311229  ,  0.11660123], dtype=float32)}
episode index:2420
target Thresh 14.999933285841099
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([10.221656 ,  9.943583 ,  2.8515897], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.6428359457506173
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([ 8.595687 , 11.062186 ,  2.2954156], dtype=float32)}
episode index:2421
target Thresh 14.999933618579357
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([ 3.1677217, 10.010231 ,  2.7253196], dtype=float32)}
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.6429365026977542
{'scaleFactor': 30, 'timeStep': 13, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([ 8.80563 , 10.677926,  5.447815], dtype=float32)}
episode index:2422
target Thresh 14.999933949658072
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([2.2207837, 9.0429   , 1.527569 ], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6430838669145524
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([2.2207837, 9.0429   , 1.527569 ], dtype=float32)}
episode index:2423
target Thresh 14.999934279085528
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([3.001669, 9.162968, 2.567683], dtype=float32)}
done in step count: 17
reward sum = 0.8429431933839268
running average episode reward sum: 0.6431663171317428
{'scaleFactor': 30, 'timeStep': 18, 'currentTarget': array([ 7, 10], dtype=int32), 'previousTarget': array([ 7, 10], dtype=int32), 'currentState': array([ 6.22984  , 10.973038 ,  0.8535694], dtype=float32)}
episode index:2424
target Thresh 14.999934606869957
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([ 5.405031 , 10.829884 ,  1.4041162], dtype=float32)}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.6432778020514756
{'scaleFactor': 30, 'timeStep': 10, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([8.921244, 9.510483, 4.973958], dtype=float32)}
episode index:2425
target Thresh 14.999934933019553
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([5.899    , 9.1142645, 1.5563996], dtype=float32)}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6433968406111851
{'scaleFactor': 30, 'timeStep': 8, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([ 8.697489, 10.518517,  6.215388], dtype=float32)}
episode index:2426
target Thresh 14.999935257542472
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([2.0764058, 9.111735 , 2.6442106], dtype=float32)}
done in step count: 31
reward sum = 0.7323033696543975
running average episode reward sum: 0.6434334728852037
{'scaleFactor': 30, 'timeStep': 32, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([1.3037186, 4.6401405, 4.374342 ], dtype=float32)}
episode index:2427
target Thresh 14.999935580446826
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([10.560425 ,  7.391377 ,  2.6244655], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.643580328950737
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([10.560425 ,  7.391377 ,  2.6244655], dtype=float32)}
episode index:2428
target Thresh 14.999935901740686
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([10.057239,  9.625942,  5.997344], dtype=float32)}
done in step count: 357
reward sum = 0.027654414711223742
running average episode reward sum: 0.6433267571457804
{'scaleFactor': 30, 'timeStep': 358, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([0.17350116, 1.9417211 , 5.2623367 ], dtype=float32)}
episode index:2429
target Thresh 14.99993622143209
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([11.892138 ,  8.832931 ,  5.2693443], dtype=float32)}
done in step count: 74
reward sum = 0.47534004200570695
running average episode reward sum: 0.6432576268103318
{'scaleFactor': 30, 'timeStep': 75, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([3.938815 , 8.776026 , 3.5199945], dtype=float32)}
episode index:2430
target Thresh 14.999936539529024
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([10.213198 , 10.611177 ,  1.7211304], dtype=float32)}
done in step count: 40
reward sum = 0.6689717585696803
running average episode reward sum: 0.6432682044046384
{'scaleFactor': 30, 'timeStep': 41, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([ 1.5192779, 10.679389 ,  3.6585774], dtype=float32)}
episode index:2431
target Thresh 14.999936856039444
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([7.0062146, 8.67553  , 5.7420793], dtype=float32)}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.6434067043205904
{'scaleFactor': 30, 'timeStep': 3, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([10.796683 ,  7.5732546,  5.79435  ], dtype=float32)}
episode index:2432
target Thresh 14.999937170971261
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([4.785843 , 8.498584 , 3.9136186], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.6435491594359539
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([3.307035 , 7.1510696, 3.9387183], dtype=float32)}
episode index:2433
target Thresh 14.99993748433235
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([10.371808 ,  4.0895467,  3.286877 ], dtype=float32)}
done in step count: 44
reward sum = 0.6426116020847181
running average episode reward sum: 0.6435487742439444
{'scaleFactor': 30, 'timeStep': 45, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([ 7.716898 , 10.980837 ,  3.2535176], dtype=float32)}
episode index:2434
target Thresh 14.999937796130542
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([6.9720087, 9.870299 , 1.7343466], dtype=float32)}
done in step count: 113
reward sum = 0.3212010745647914
running average episode reward sum: 0.6434163932584499
{'scaleFactor': 30, 'timeStep': 114, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([13.363323,  3.293652,  4.653865], dtype=float32)}
episode index:2435
target Thresh 14.999938106373634
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([5.8896136, 9.986009 , 2.9162395], dtype=float32)}
done in step count: 46
reward sum = 0.6298236312032323
running average episode reward sum: 0.6434108133068672
{'scaleFactor': 30, 'timeStep': 47, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([8.555316 , 8.88884  , 5.2091727], dtype=float32)}
episode index:2436
target Thresh 14.999938415069385
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([12.342887 ,  6.955077 ,  1.1934915], dtype=float32)}
done in step count: 89
reward sum = 0.40882017442254925
running average episode reward sum: 0.6433145512474153
{'scaleFactor': 30, 'timeStep': 90, 'currentTarget': array([ 5, 10], dtype=int32), 'previousTarget': array([ 5, 10], dtype=int32), 'currentState': array([ 4.7155952, 11.660335 ,  2.9294763], dtype=float32)}
episode index:2437
target Thresh 14.999938722225506
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([2.8135617, 9.456074 , 0.835948 ], dtype=float32)}
done in step count: 188
reward sum = 0.1511529349531471
running average episode reward sum: 0.6431126801988943
{'scaleFactor': 30, 'timeStep': 189, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([2.8003235, 4.623132 , 3.4786882], dtype=float32)}
episode index:2438
target Thresh 14.999939027849683
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([5.9316072, 8.943665 , 0.6284698], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6432590054632654
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([5.9316072, 8.943665 , 0.6284698], dtype=float32)}
episode index:2439
target Thresh 14.99993933194955
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([13.982333,  3.91355 ,  6.094755], dtype=float32)}
done in step count: 68
reward sum = 0.5048858887870696
running average episode reward sum: 0.6432022951695457
{'scaleFactor': 30, 'timeStep': 69, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([7.8429594, 8.759689 , 4.0660887], dtype=float32)}
episode index:2440
target Thresh 14.999939634532716
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([6.8485518, 9.018955 , 0.762231 ], dtype=float32)}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.6433168147923471
{'scaleFactor': 30, 'timeStep': 9, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([11.646737 , 10.775471 ,  1.4099957], dtype=float32)}
episode index:2441
target Thresh 14.99993993560674
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([0.09410381, 1.9653399 , 2.6430085 ], dtype=float32)}
done in step count: 155
reward sum = 0.21059844619672852
running average episode reward sum: 0.6431396164432088
{'scaleFactor': 30, 'timeStep': 156, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([13.383548 ,  2.4999053,  4.2796564], dtype=float32)}
episode index:2442
target Thresh 14.99994023517915
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([13.107139  ,  4.583143  ,  0.68627346], dtype=float32)}
done in step count: 117
reward sum = 0.30854447063465107
running average episode reward sum: 0.6430026556794722
{'scaleFactor': 30, 'timeStep': 118, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([4.782107 , 8.731649 , 4.0090346], dtype=float32)}
episode index:2443
target Thresh 14.999940533257439
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([3.7370105, 8.984805 , 4.203436 ], dtype=float32)}
done in step count: 85
reward sum = 0.4255901233886546
running average episode reward sum: 0.6429136980148688
{'scaleFactor': 30, 'timeStep': 86, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([10.659373 ,  4.5452056,  4.8780246], dtype=float32)}
episode index:2444
target Thresh 14.999940829849052
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([2.2639449, 5.941756 , 3.3506718], dtype=float32)}
done in step count: 130
reward sum = 0.27075425951199406
running average episode reward sum: 0.6427614855655833
{'scaleFactor': 30, 'timeStep': 131, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([11.478224, 10.868126,  3.990439], dtype=float32)}
episode index:2445
target Thresh 14.999941124961412
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([4.67986  , 9.136959 , 0.7217919], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6429075356532508
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 3, 10], dtype=int32), 'previousTarget': array([ 3, 10], dtype=int32), 'currentState': array([4.67986  , 9.136959 , 0.7217919], dtype=float32)}
episode index:2446
target Thresh 14.999941418601892
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([8.669714 , 9.879243 , 0.9511765], dtype=float32)}
done in step count: 129
reward sum = 0.2734891510222162
running average episode reward sum: 0.642756567780496
{'scaleFactor': 30, 'timeStep': 130, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([0.52454925, 5.9601083 , 2.386289  ], dtype=float32)}
episode index:2447
target Thresh 14.999941710777835
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([ 3.7747746, 11.165705 ,  0.1002754], dtype=float32)}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.6428903677936576
{'scaleFactor': 30, 'timeStep': 4, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([ 9.8272915 , 11.230766  ,  0.36340827], dtype=float32)}
episode index:2448
target Thresh 14.999942001496544
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([2.3257387, 3.0482295, 4.5149617], dtype=float32)}
done in step count: 14
reward sum = 0.8687458127689782
running average episode reward sum: 0.6429825913318263
{'scaleFactor': 30, 'timeStep': 15, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([4.6615543, 9.957188 , 1.066985 ], dtype=float32)}
episode index:2449
target Thresh 14.999942290765286
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([3.7378893, 7.180241 , 0.7168895], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.6431242310904665
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([4.8262634 , 8.3743305 , 0.98910475], dtype=float32)}
episode index:2450
target Thresh 14.999942578591293
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([10.564411 ,  6.7622776,  3.332249 ], dtype=float32)}
done in step count: 24
reward sum = 0.7856781408072188
running average episode reward sum: 0.6431823926203386
{'scaleFactor': 30, 'timeStep': 25, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([2.3370383, 6.026905 , 3.6148188], dtype=float32)}
episode index:2451
target Thresh 14.999942864981765
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([9.819688 , 8.725162 , 4.4558063], dtype=float32)}
done in step count: 97
reward sum = 0.37723664692350417
running average episode reward sum: 0.643073931875764
{'scaleFactor': 30, 'timeStep': 98, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([2.9829175, 9.655114 , 3.7509382], dtype=float32)}
episode index:2452
target Thresh 14.999943149943856
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([11.323264,  8.971407,  5.543802], dtype=float32)}
done in step count: 154
reward sum = 0.2127257032290187
running average episode reward sum: 0.64289849435899
{'scaleFactor': 30, 'timeStep': 155, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([2.7233846, 8.977817 , 2.8233073], dtype=float32)}
episode index:2453
target Thresh 14.999943433484695
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([3.489435  , 3.9925766 , 0.11671042], dtype=float32)}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6430163292626363
{'scaleFactor': 30, 'timeStep': 8, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([5.112196 , 7.469215 , 0.8723301], dtype=float32)}
episode index:2454
target Thresh 14.999943715611368
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([2.0542872, 8.191997 , 4.6017537], dtype=float32)}
done in step count: 19
reward sum = 0.8261686238355866
running average episode reward sum: 0.6430909330486131
{'scaleFactor': 30, 'timeStep': 20, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([10.843359  , 10.801542  ,  0.98325765], dtype=float32)}
episode index:2455
target Thresh 14.999943996330925
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([6.2151384, 8.87948  , 2.79567  ], dtype=float32)}
done in step count: 66
reward sum = 0.5151371174238033
running average episode reward sum: 0.6430388345894825
{'scaleFactor': 30, 'timeStep': 67, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([12.51714  ,  6.1211314,  4.55895  ], dtype=float32)}
episode index:2456
target Thresh 14.999944275650392
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([12.019949 ,  5.9389243,  1.3472223], dtype=float32)}
done in step count: 62
reward sum = 0.536268225207185
running average episode reward sum: 0.6429953789080083
{'scaleFactor': 30, 'timeStep': 63, 'currentTarget': array([2, 7], dtype=int32), 'previousTarget': array([2, 7], dtype=int32), 'currentState': array([3.4158604, 5.0581665, 6.2128587], dtype=float32)}
episode index:2457
target Thresh 14.999944553576746
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([2.1532578 , 3.3081615 , 0.28759173], dtype=float32)}
done in step count: 76
reward sum = 0.46588077516979337
running average episode reward sum: 0.6429233225191807
{'scaleFactor': 30, 'timeStep': 77, 'currentTarget': array([10, 10], dtype=int32), 'previousTarget': array([10, 10], dtype=int32), 'currentState': array([9.403497 , 8.271122 , 1.0797402], dtype=float32)}
episode index:2458
target Thresh 14.999944830116934
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([13.6744    ,  5.1586065 ,  0.15086865], dtype=float32)}
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.6430187262200672
{'scaleFactor': 30, 'timeStep': 14, 'currentTarget': array([12, 10], dtype=int32), 'previousTarget': array([12, 10], dtype=int32), 'currentState': array([11.5803385,  8.36078  ,  2.4281256], dtype=float32)}
episode index:2459
target Thresh 14.999945105277874
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([1.7405181, 9.910316 , 3.5594704], dtype=float32)}
done in step count: 33
reward sum = 0.7177305325982749
running average episode reward sum: 0.6430490968730666
{'scaleFactor': 30, 'timeStep': 34, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([ 5.533893  , 11.333043  ,  0.01354283], dtype=float32)}
episode index:2460
target Thresh 14.999945379066443
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([1.7958199, 5.823558 , 4.684025 ], dtype=float32)}
done in step count: 53
reward sum = 0.5870367819374844
running average episode reward sum: 0.643026336891378
{'scaleFactor': 30, 'timeStep': 54, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([ 5.4769382 , 10.79165   ,  0.03782672], dtype=float32)}
episode index:2461
target Thresh 14.999945651489487
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([2.845471  , 9.621719  , 0.53767926], dtype=float32)}
done in step count: 49
reward sum = 0.611117239532865
running average episode reward sum: 0.6430133762506963
{'scaleFactor': 30, 'timeStep': 50, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([12.292273 ,  4.91263  ,  6.1461864], dtype=float32)}
episode index:2462
target Thresh 14.999945922553813
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([11.705685 ,  3.8557482,  1.4434052], dtype=float32)}
done in step count: 24
reward sum = 0.7856781408072188
running average episode reward sum: 0.643071299419416
{'scaleFactor': 30, 'timeStep': 25, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([ 7.564423, 11.864526,  3.335245], dtype=float32)}
episode index:2463
target Thresh 14.9999461922662
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([4.594072 , 9.978538 , 3.4115663], dtype=float32)}
done in step count: 214
reward sum = 0.11639428152900338
running average episode reward sum: 0.6428575506296876
{'scaleFactor': 30, 'timeStep': 215, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([8.062049, 7.335053, 6.024471], dtype=float32)}
episode index:2464
target Thresh 14.999946460633392
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([12.106757  ,  6.404903  ,  0.30139005], dtype=float32)}
done in step count: 35
reward sum = 0.7034476949995692
running average episode reward sum: 0.6428821308099594
{'scaleFactor': 30, 'timeStep': 36, 'currentTarget': array([12,  2], dtype=int32), 'previousTarget': array([12,  2], dtype=int32), 'currentState': array([10.585894 ,  3.341448 ,  4.2546945], dtype=float32)}
episode index:2465
target Thresh 14.999946727662097
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([ 8.023903 , 10.006571 ,  1.6719825], dtype=float32)}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.6430188777155514
{'scaleFactor': 30, 'timeStep': 3, 'currentTarget': array([6, 9], dtype=int32), 'previousTarget': array([6, 9], dtype=int32), 'currentState': array([ 7.944758 , 10.323227 ,  1.4471388], dtype=float32)}
episode index:2466
target Thresh 14.999946993358991
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([5.943433 , 9.869116 , 2.9023447], dtype=float32)}
done in step count: 40
reward sum = 0.6689717585696803
running average episode reward sum: 0.6430293977321117
{'scaleFactor': 30, 'timeStep': 41, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([10.293022 , 10.299693 ,  4.7332973], dtype=float32)}
episode index:2467
target Thresh 14.999947257730716
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([12.013265 ,  4.0597625,  4.994725 ], dtype=float32)}
done in step count: 42
reward sum = 0.6556592205741436
running average episode reward sum: 0.6430345151643815
{'scaleFactor': 30, 'timeStep': 43, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([5.0426674, 8.40085  , 2.6729298], dtype=float32)}
episode index:2468
target Thresh 14.999947520783882
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([4.0033207, 9.948537 , 1.6933718], dtype=float32)}
done in step count: 117
reward sum = 0.30854447063465107
running average episode reward sum: 0.6428990392451713
{'scaleFactor': 30, 'timeStep': 118, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([9.842068  , 8.075077  , 0.22444129], dtype=float32)}
episode index:2469
target Thresh 14.999947782525064
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([0.1750412, 3.6252446, 3.7475982], dtype=float32)}
done in step count: 38
reward sum = 0.682554595010387
running average episode reward sum: 0.6429150941260479
{'scaleFactor': 30, 'timeStep': 39, 'currentTarget': array([2, 8], dtype=int32), 'previousTarget': array([2, 8], dtype=int32), 'currentState': array([0.01200052, 7.523779  , 0.5195029 ], dtype=float32)}
episode index:2470
target Thresh 14.999948042960808
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([12.450169  ,  9.104896  ,  0.40497312], dtype=float32)}
done in step count: 53
reward sum = 0.5870367819374844
running average episode reward sum: 0.642892480482912
{'scaleFactor': 30, 'timeStep': 54, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([12.052585,  6.788148,  3.682786], dtype=float32)}
episode index:2471
target Thresh 14.999948302097621
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([1.6493106, 7.9995894, 1.8849771], dtype=float32)}
done in step count: 32
reward sum = 0.7249803359578534
running average episode reward sum: 0.6429256875441882
{'scaleFactor': 30, 'timeStep': 33, 'currentTarget': array([9, 9], dtype=int32), 'previousTarget': array([9, 9], dtype=int32), 'currentState': array([7.5264153, 8.472869 , 6.209639 ], dtype=float32)}
episode index:2472
target Thresh 14.999948559941986
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([ 2.7964501, 10.10375  ,  0.5614722], dtype=float32)}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.6430351058862585
{'scaleFactor': 30, 'timeStep': 10, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([3.3243299, 6.69626  , 5.0880113], dtype=float32)}
episode index:2473
target Thresh 14.999948816500345
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([11.908431,  3.935785,  3.575214], dtype=float32)}
done in step count: 43
reward sum = 0.6491026283684022
running average episode reward sum: 0.6430375584014089
{'scaleFactor': 30, 'timeStep': 44, 'currentTarget': array([5, 9], dtype=int32), 'previousTarget': array([5, 9], dtype=int32), 'currentState': array([6.7094145, 9.267925 , 2.3168876], dtype=float32)}
episode index:2474
target Thresh 14.999949071779115
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([12.33931 ,  4.824093,  1.877198], dtype=float32)}
done in step count: 20
reward sum = 0.8179069375972308
running average episode reward sum: 0.6431082126960334
{'scaleFactor': 30, 'timeStep': 21, 'currentTarget': array([2, 5], dtype=int32), 'previousTarget': array([2, 5], dtype=int32), 'currentState': array([0.6283617, 6.230008 , 3.2013283], dtype=float32)}
episode index:2475
target Thresh 14.999949325784677
target distance 3.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([ 7.043096 , 10.011641 ,  1.3494807], dtype=float32)}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6432249159008843
{'scaleFactor': 30, 'timeStep': 8, 'currentTarget': array([ 4, 10], dtype=int32), 'previousTarget': array([ 4, 10], dtype=int32), 'currentState': array([ 5.2897444, 10.968498 ,  3.2426634], dtype=float32)}
episode index:2476
target Thresh 14.99994957852338
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([7.9998865, 9.033358 , 1.340454 ], dtype=float32)}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.6433303487467089
{'scaleFactor': 30, 'timeStep': 11, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([3.3412626, 9.738424 , 2.9437838], dtype=float32)}
episode index:2477
target Thresh 14.999949830001542
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([ 3.0178998, 10.282719 ,  5.0555525], dtype=float32)}
done in step count: 89
reward sum = 0.40882017442254925
running average episode reward sum: 0.6432357118724861
{'scaleFactor': 30, 'timeStep': 90, 'currentTarget': array([12,  9], dtype=int32), 'previousTarget': array([12,  9], dtype=int32), 'currentState': array([10.668762 ,  8.7736025,  0.8047616], dtype=float32)}
episode index:2478
target Thresh 14.999950080225455
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([1.8019762 , 5.7937284 , 0.74035424], dtype=float32)}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.6433715990399438
{'scaleFactor': 30, 'timeStep': 3, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([2.7983394, 9.210932 , 1.5080739], dtype=float32)}
episode index:2479
target Thresh 14.999950329201367
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([1.8225064, 6.0336013, 4.0740843], dtype=float32)}
done in step count: 102
reward sum = 0.3587482976818919
running average episode reward sum: 0.6432568315797187
{'scaleFactor': 30, 'timeStep': 103, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([7.3606687, 8.885182 , 6.218504 ], dtype=float32)}
episode index:2480
target Thresh 14.99995057693551
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([3.7656448 , 9.970614  , 0.19240311], dtype=float32)}
done in step count: 128
reward sum = 0.2762516676992083
running average episode reward sum: 0.6431089052742449
{'scaleFactor': 30, 'timeStep': 129, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([3.764508 , 2.1588244, 4.6363997], dtype=float32)}
episode index:2481
target Thresh 14.999950823434073
target distance 10.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([1.9620339 , 3.1733284 , 0.99019104], dtype=float32)}
done in step count: 147
reward sum = 0.22823046013534068
running average episode reward sum: 0.6429417503809577
{'scaleFactor': 30, 'timeStep': 148, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([13.921294 ,  5.8291235,  4.999742 ], dtype=float32)}
episode index:2482
target Thresh 14.999951068703217
target distance 2.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([3.725007 , 9.042908 , 5.7444987], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6430855515286094
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 2, 10], dtype=int32), 'previousTarget': array([ 2, 10], dtype=int32), 'currentState': array([3.725007 , 9.042908 , 5.7444987], dtype=float32)}
episode index:2483
target Thresh 14.99995131274908
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([7.0529304, 7.18859  , 4.1884336], dtype=float32)}
done in step count: 217
reward sum = 0.11293725497331045
running average episode reward sum: 0.6428721262884503
{'scaleFactor': 30, 'timeStep': 218, 'currentTarget': array([2, 2], dtype=int32), 'previousTarget': array([2, 2], dtype=int32), 'currentState': array([1.1672646, 3.1196046, 3.7627888], dtype=float32)}
episode index:2484
target Thresh 14.999951555577756
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([11.122082,  9.116021,  6.059947], dtype=float32)}
done in step count: 21
reward sum = 0.8097278682212584
running average episode reward sum: 0.6429392714562301
{'scaleFactor': 30, 'timeStep': 22, 'currentTarget': array([3, 9], dtype=int32), 'previousTarget': array([3, 9], dtype=int32), 'currentState': array([4.169201, 7.151593, 3.594739], dtype=float32)}
episode index:2485
target Thresh 14.999951797195319
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([12.033641,  8.87476 ,  3.163195], dtype=float32)}
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.6430371980854577
{'scaleFactor': 30, 'timeStep': 13, 'currentTarget': array([12,  5], dtype=int32), 'previousTarget': array([12,  5], dtype=int32), 'currentState': array([11.158755 ,  6.676777 ,  4.0061164], dtype=float32)}
episode index:2486
target Thresh 14.99995203760781
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([12.305274 ,  8.845295 ,  2.4921155], dtype=float32)}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.6431496659167172
{'scaleFactor': 30, 'timeStep': 9, 'currentTarget': array([8, 9], dtype=int32), 'previousTarget': array([8, 9], dtype=int32), 'currentState': array([ 8.587145 , 10.226919 ,  3.0111096], dtype=float32)}
episode index:2487
target Thresh 14.99995227682124
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([4.6209116, 7.5179067, 5.9437437], dtype=float32)}
done in step count: 277
reward sum = 0.06179436923202584
running average episode reward sum: 0.642916002212262
{'scaleFactor': 30, 'timeStep': 278, 'currentTarget': array([12,  4], dtype=int32), 'previousTarget': array([12,  4], dtype=int32), 'currentState': array([13.971626 ,  5.688533 ,  6.0062985], dtype=float32)}
episode index:2488
target Thresh 14.999952514841587
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([2.057342, 9.10099 , 4.964964], dtype=float32)}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.6430436358031771
{'scaleFactor': 30, 'timeStep': 5, 'currentTarget': array([2, 4], dtype=int32), 'previousTarget': array([2, 4], dtype=int32), 'currentState': array([3.355787 , 5.258205 , 4.6173515], dtype=float32)}
episode index:2489
target Thresh 14.999952751674803
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([11.136335,  9.218923,  4.231599], dtype=float32)}
done in step count: 28
reward sum = 0.7547192872036326
running average episode reward sum: 0.6430884854623741
{'scaleFactor': 30, 'timeStep': 29, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([4.237152 , 7.2898393, 3.2410598], dtype=float32)}
episode index:2490
target Thresh 14.999952987326807
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([7.961875  , 9.352198  , 0.35137898], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.6432277514256569
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([11, 10], dtype=int32), 'previousTarget': array([11, 10], dtype=int32), 'currentState': array([9.739416 , 9.784769 , 6.0365067], dtype=float32)}
episode index:2491
target Thresh 14.999953221803494
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([11.983098  ,  9.242209  ,  0.14508313], dtype=float32)}
done in step count: 86
reward sum = 0.421334222154768
running average episode reward sum: 0.6431387090784374
{'scaleFactor': 30, 'timeStep': 87, 'currentTarget': array([7, 9], dtype=int32), 'previousTarget': array([7, 9], dtype=int32), 'currentState': array([8.490022 , 9.849779 , 2.6962254], dtype=float32)}
episode index:2492
target Thresh 14.999953455110722
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([7.825414, 9.360155, 5.995149], dtype=float32)}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.6432778431702632
{'scaleFactor': 30, 'timeStep': 2, 'currentTarget': array([10,  9], dtype=int32), 'previousTarget': array([10,  9], dtype=int32), 'currentState': array([9.651834, 8.969015, 5.847328], dtype=float32)}
episode index:2493
target Thresh 14.999953687254324
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([9.752718 , 7.5873795, 3.114064 ], dtype=float32)}
done in step count: 65
reward sum = 0.5203405226503064
running average episode reward sum: 0.6432285499382984
{'scaleFactor': 30, 'timeStep': 66, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([4.7405   , 9.290026 , 2.0872285], dtype=float32)}
episode index:2494
target Thresh 14.99995391824011
target distance 4.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([9.784587 , 4.0477033, 3.163581 ], dtype=float32)}
done in step count: 18
reward sum = 0.8345137614500875
running average episode reward sum: 0.643305217357742
{'scaleFactor': 30, 'timeStep': 19, 'currentTarget': array([12,  8], dtype=int32), 'previousTarget': array([12,  8], dtype=int32), 'currentState': array([10.18366  ,  6.320368 ,  1.1388075], dtype=float32)}
episode index:2495
target Thresh 14.999954148073844
target distance 5.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([6.3596563, 9.587688 , 3.5540755], dtype=float32)}
done in step count: 15
reward sum = 0.8600583546412884
running average episode reward sum: 0.6433920575569742
{'scaleFactor': 30, 'timeStep': 16, 'currentTarget': array([11,  9], dtype=int32), 'previousTarget': array([11,  9], dtype=int32), 'currentState': array([10.417022  ,  9.57742   ,  0.44685018], dtype=float32)}
episode index:2496
target Thresh 14.99995437676128
target distance 8.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([11.736208 ,  5.092163 ,  1.5101111], dtype=float32)}
done in step count: 15
reward sum = 0.8600583546412884
running average episode reward sum: 0.6434788282005802
{'scaleFactor': 30, 'timeStep': 16, 'currentTarget': array([4, 9], dtype=int32), 'previousTarget': array([4, 9], dtype=int32), 'currentState': array([5.269226 , 8.622022 , 1.5659034], dtype=float32)}
episode index:2497
target Thresh 14.999954604308133
target distance 9.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([ 3.6739295, 11.893373 ,  1.440281 ], dtype=float32)}
done in step count: 41
reward sum = 0.6622820409839835
running average episode reward sum: 0.6434863555075392
{'scaleFactor': 30, 'timeStep': 42, 'currentTarget': array([12,  7], dtype=int32), 'previousTarget': array([12,  7], dtype=int32), 'currentState': array([11.827818 ,  6.0704193,  5.977025 ], dtype=float32)}
episode index:2498
target Thresh 14.99995483072009
target distance 7.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([5.8186374, 9.683662 , 5.1301985], dtype=float32)}
done in step count: 63
reward sum = 0.5309055429551132
running average episode reward sum: 0.6434413051623802
{'scaleFactor': 30, 'timeStep': 64, 'currentTarget': array([12,  3], dtype=int32), 'previousTarget': array([12,  3], dtype=int32), 'currentState': array([12.693561 ,  4.929685 ,  3.1810226], dtype=float32)}
episode index:2499
target Thresh 14.999955056002815
target distance 6.0
at step 0:
{'scaleFactor': 30, 'timeStep': 1, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([12.124853 ,  3.8801043,  2.5454178], dtype=float32)}
done in step count: 108
reward sum = 0.337754400898902
running average episode reward sum: 0.6433190304006747
{'scaleFactor': 30, 'timeStep': 109, 'currentTarget': array([ 6, 10], dtype=int32), 'previousTarget': array([ 6, 10], dtype=int32), 'currentState': array([6.026905 , 8.325857 , 2.5015643], dtype=float32)}

Process finished with exit code 0
