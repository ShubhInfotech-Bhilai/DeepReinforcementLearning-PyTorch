/home/yangyutu/anaconda3/bin/python /home/yangyutu/Dropbox/pythonScripts/DeepReinforcementLearning-PyTorch/Env/CustomEnv/ThreeDNavigation/NavigationExamples/FreeSpace/DDPG/DDPGHER_MLP.py
episode index:0
target thresh 9.999999999999998
model initialize at round 0
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14336543, 14.97488457,  0.98936482,  0.14327345,
       -0.02509932]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.941480149401
{'scaleFactor': 20, 'currentState': array([25.78090979, 20.33088204, 10.0781165 ,  0.2607735 ,  0.5976385 ,
       -0.75817241]), 'targetState': array([25., 25., 15.])}
episode index:1
target thresh 10.008999550014996
model initialize at round 1
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.4707400747005
{'scaleFactor': 20, 'currentState': array([ 2.68227684e+01,  6.28948273e+01,  4.93040756e+00, -3.56229249e-02,
        1.54643190e-01,  9.87327955e-01]), 'targetState': array([25., 25., 15.])}
episode index:2
target thresh 10.017998200119994
model initialize at round 2
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.50007786e+01,  1.49277420e+01,  9.97346673e-01,
        7.84353337e-04, -7.27942168e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.313826716467
{'scaleFactor': 20, 'currentState': array([ 4.29329984e+01,  6.05392391e+01, -2.75133787e+01,  4.54501483e-02,
        8.44844948e-01, -5.33077198e-01]), 'targetState': array([25., 25., 15.])}
episode index:3
target thresh 10.02699595040497
model initialize at round 3
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.87781463, 15.06441361,  0.99040695, -0.12223559,
        0.06444009]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.23537003735025
{'scaleFactor': 20, 'currentState': array([48.09245095,  0.71564181, 89.18570503, -0.2992407 ,  0.24659494,
        0.92176241]), 'targetState': array([25., 25., 15.])}
episode index:4
target thresh 10.035992800959903
model initialize at round 4
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.51537267e+01, 1.50164088e+01, 9.88025355e-01,
       1.53420086e-01, 1.63760505e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3784940398602
{'scaleFactor': 20, 'currentState': array([25.26663998, 20.07600952, 13.69933309,  0.54645541,  0.75159771,
       -0.36944196]), 'targetState': array([25., 25., 15.])}
episode index:5
target thresh 10.044988751874762
model initialize at round 5
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15117054, 15.04731928,  0.9874401 ,  0.15077965,
        0.04719693]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.470755924534665
{'scaleFactor': 20, 'currentState': array([28.87133187, 20.32707585, 19.87642659,  0.94215776,  0.25162563,
        0.22141206]), 'targetState': array([25., 25., 15.])}
episode index:6
target thresh 10.053983803239507
model initialize at round 6
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.84627329, 14.95319678,  0.98708135, -0.1532735 ,
       -0.04666524]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.40350507817257003
{'scaleFactor': 20, 'currentState': array([ 15.27347737, -13.2296778 ,   7.75888991,   0.09974378,
         0.12028853,   0.98771547]), 'targetState': array([25., 25., 15.])}
episode index:7
target thresh 10.062977955144103
model initialize at round 7
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11363819, 15.15372671,  0.98186192,  0.11270405,
        0.15246303]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.35306694340099876
{'scaleFactor': 20, 'currentState': array([ 3.44472596e+01,  5.03739817e+00,  1.02192561e+02,  6.07197217e-02,
       -6.72854315e-02,  9.95884424e-01]), 'targetState': array([25., 25., 15.])}
episode index:8
target thresh 10.071971207678466
model initialize at round 8
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.9011902 , 15.08992134,  0.9910167 , -0.09891127,
        0.09001369]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31383728302311
{'scaleFactor': 20, 'currentState': array([ 29.37913308, -10.73410232,  75.34987635,  -0.54531574,
        -0.46365951,   0.69831985]), 'targetState': array([25., 25., 15.])}
episode index:9
target thresh 10.080963560932531
model initialize at round 9
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.95167563, 15.13762515,  0.98931962, -0.04829116,
        0.13753057]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.282453554720799
{'scaleFactor': 20, 'currentState': array([ 4.62818426e+01,  8.32834586e+00,  9.66047078e+01, -1.71175133e-01,
       -7.84653621e-03,  9.85209372e-01]), 'targetState': array([25., 25., 15.])}
episode index:10
target thresh 10.089955014996244
model initialize at round 10
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.48462733e+01,  1.49907356e+01,  9.88115617e-01,
       -1.53434102e-01, -9.24680290e-03]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.25677595883709
{'scaleFactor': 20, 'currentState': array([ 18.19158742,  -0.38730008, -43.97199973,  -0.07208862,
        -0.69563309,   0.71477118]), 'targetState': array([25., 25., 15.])}
episode index:11
target thresh 10.098945569959517
model initialize at round 11
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.10135056,  0.98314007,  0.1526615 ,
        0.10064828]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.23537796226733246
{'scaleFactor': 20, 'currentState': array([ 2.23494719e+01,  1.96878958e+01,  1.05639652e+02, -2.61550303e-02,
       -3.05605845e-01,  9.51798814e-01]), 'targetState': array([25., 25., 15.])}
episode index:12
target thresh 10.107935225912223
model initialize at round 12
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.29042504593138385
{'scaleFactor': 20, 'currentState': array([25.08205694, 20.07665534, 17.63460527,  0.53999735,  0.76129903,
        0.3589243 ]), 'targetState': array([25., 25., 15.])}
episode index:13
target thresh 10.116923982944293
model initialize at round 13
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14885951, 15.07603571,  0.98604375,  0.14826463,
        0.07573186]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3369289818934993
{'scaleFactor': 20, 'currentState': array([25.73035777, 20.92133902, 19.96298369,  0.48184815,  0.61807694,
        0.62113063]), 'targetState': array([25., 25., 15.])}
episode index:14
target thresh 10.125911841145596
model initialize at round 14
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.50563991e+01,  1.49848265e+01,  9.98264351e-01,
        5.68699366e-02, -1.53001679e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.314467049767266
{'scaleFactor': 20, 'currentState': array([ 6.54513788e+01, -1.67139131e+01, -2.62345187e+01,  3.93915219e-01,
        8.62823739e-03,  9.19106280e-01]), 'targetState': array([25., 25., 15.])}
episode index:15
target thresh 10.134898800606019
model initialize at round 15
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.49999544e+01,  1.50152862e+01,  9.99880814e-01,
       -4.60307714e-05,  1.54387614e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.2948128591568119
{'scaleFactor': 20, 'currentState': array([ 2.83025723e+01,  1.76756687e+01,  1.04279520e+02,  8.02443283e-02,
       -4.67951442e-02,  9.95676183e-01]), 'targetState': array([25., 25., 15.])}
episode index:16
target thresh 10.143884861415431
model initialize at round 16
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.84627329, 15.09412475,  0.98382552, -0.15276794,
        0.09353771]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.27747092626523473
{'scaleFactor': 20, 'currentState': array([ 2.32933784e+01,  7.58320657e+00,  1.06475428e+02, -1.13766716e-02,
        1.51248644e-01,  9.88430280e-01]), 'targetState': array([25., 25., 15.])}
episode index:17
target thresh 10.152870023663684
model initialize at round 17
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.262055874806055
{'scaleFactor': 20, 'currentState': array([2.44423051e+01, 2.54049268e+01, 1.05076052e+02, 9.03566429e-02,
       6.95599535e-03, 9.95885180e-01]), 'targetState': array([25., 25., 15.])}
episode index:18
target thresh 10.161854287440642
model initialize at round 18
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.0524701 , 15.15372671,  0.98680545,  0.05230079,
        0.15323066]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.24826346034257843
{'scaleFactor': 20, 'currentState': array([ 2.87322751e+01,  3.14713672e+01,  1.02113984e+02, -2.68469988e-02,
        2.41587030e-01,  9.70007704e-01]), 'targetState': array([25., 25., 15.])}
episode index:19
target thresh 10.170837652836152
model initialize at round 19
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.2833997898204495
{'scaleFactor': 20, 'currentState': array([25.2880057 , 20.18638769, 13.68921756,  0.59726387,  0.80077908,
        0.04504154]), 'targetState': array([25., 25., 15.])}
episode index:20
target thresh 10.17982011994002
model initialize at round 20
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.0386192 ,  0.98742453,  0.15332679,
        0.03851874]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.31518980220519
{'scaleFactor': 20, 'currentState': array([25.40248404, 20.17702148, 15.13606556,  0.60175697,  0.79612855,
       -0.06377995]), 'targetState': array([25., 25., 15.])}
episode index:21
target thresh 10.188801688842098
model initialize at round 21
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.03733335,  0.9874725 ,  0.15333424,
        0.03723803]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.34408981346404494
{'scaleFactor': 20, 'currentState': array([25.34710638, 20.16716714, 16.11047517,  0.5891301 ,  0.78791245,
        0.1792197 ]), 'targetState': array([25., 25., 15.])}
episode index:22
target thresh 10.19778235963219
model initialize at round 22
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3291293867916951
{'scaleFactor': 20, 'currentState': array([ 3.75922704e+01,  2.56707307e+01,  1.00144453e+02, -1.25221905e-02,
        5.59485359e-03,  9.99905942e-01]), 'targetState': array([25., 25., 15.])}
episode index:23
target thresh 10.206762132400105
model initialize at round 23
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.93924533, 15.12851559,  0.98984788, -0.06074533,
        0.12849584]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31541566234204116
{'scaleFactor': 20, 'currentState': array([ 4.76862925e+01, -1.82883485e+00,  8.91823647e+01,  8.99870833e-02,
       -8.31121821e-02,  9.92468987e-01]), 'targetState': array([25., 25., 15.])}
episode index:24
target thresh 10.215741007235636
model initialize at round 24
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08924956, 15.10449703,  0.99050275,  0.08929488,
        0.10455009]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3027990358483595
{'scaleFactor': 20, 'currentState': array([ 3.34066111e+01,  3.06182945e+01,  9.85984950e+01,  3.72062998e-02,
       -1.47041737e-01,  9.88430280e-01]), 'targetState': array([25., 25., 15.])}
episode index:25
target thresh 10.224718984228588
model initialize at round 25
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.29115291908496105
{'scaleFactor': 20, 'currentState': array([ 2.34100907e+01,  2.19996024e+01,  1.07089700e+02,  2.66688009e-01,
       -1.42856086e-02,  9.63677035e-01]), 'targetState': array([25., 25., 15.])}
episode index:26
target thresh 10.233696063468722
model initialize at round 26
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.50785093e+01, 1.50137371e+01, 9.96774967e-01,
       7.90465982e-02, 1.38311371e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3152391128003699
{'scaleFactor': 20, 'currentState': array([27.07392874, 20.10609408, 12.09359629,  0.62205747,  0.68893025,
       -0.37204787]), 'targetState': array([25., 25., 15.])}
episode index:27
target thresh 10.242672245045814
model initialize at round 27
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10498876, 15.04756135,  0.9932909 ,  0.10533776,
        0.04771945]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.33760486410753526
{'scaleFactor': 20, 'currentState': array([26.17621842, 20.12963214, 19.79011919,  0.39570898,  0.69974874,
        0.5947824 ]), 'targetState': array([25., 25., 15.])}
episode index:28
target thresh 10.251647529049634
model initialize at round 28
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.08105969,  0.9849393 ,  0.15294088,
        0.08064533]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.35842814980730997
{'scaleFactor': 20, 'currentState': array([25.92132453, 21.46107956, 18.98341114,  0.41154628,  0.77111018,
        0.48581761]), 'targetState': array([25., 25., 15.])}
episode index:29
target thresh 10.260621915569923
model initialize at round 29
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.12906151,  0.98005931,  0.15218312,
        0.12776559]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.37786321646043297
{'scaleFactor': 20, 'currentState': array([25.69125133, 21.63226889, 19.15600509,  0.40480586,  0.87868918,
        0.25305641]), 'targetState': array([25., 25., 15.])}
episode index:30
target thresh 10.26959540469643
model initialize at round 30
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3656740804455803
{'scaleFactor': 20, 'currentState': array([ 5.89249286e+01,  1.43567905e+01,  5.90531523e+01,  1.15279525e-01,
       -3.85463351e-03,  9.93325613e-01]), 'targetState': array([25., 25., 15.])}
episode index:31
target thresh 10.278567996518895
model initialize at round 31
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.93742063, 15.15372671,  0.98623578, -0.06234143,
        0.1531422 ]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3542467654316559
{'scaleFactor': 20, 'currentState': array([ 2.60468698e+01,  1.63756271e+01,  1.07217823e+02, -8.30871644e-02,
       -2.33070192e-01,  9.68903921e-01]), 'targetState': array([25., 25., 15.])}
episode index:32
target thresh 10.287539691127034
model initialize at round 32
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14384454, 15.10550463,  0.98415063,  0.14299464,
        0.10488126]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.34351201496402994
{'scaleFactor': 20, 'currentState': array([ 2.81137355e+01,  2.75620406e+01,  1.03232071e+02, -8.70076202e-02,
        1.26996325e-01,  9.88079758e-01]), 'targetState': array([25., 25., 15.])}
episode index:33
target thresh 10.296510488610577
model initialize at round 33
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.33340872040626435
{'scaleFactor': 20, 'currentState': array([9.10336419e+00, 1.86177179e+01, 9.56212877e+01, 5.52431678e-02,
       1.53407844e-01, 9.86617568e-01]), 'targetState': array([25., 25., 15.])}
episode index:34
target thresh 10.305480389059207
model initialize at round 34
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.97109984, 15.04028858,  0.9987482 , -0.02915554,
        0.04064459]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32388275696608537
{'scaleFactor': 20, 'currentState': array([3.00474279e+01, 1.56678054e+01, 1.05561329e+02, 7.81421286e-02,
       1.37365339e-01, 9.87433325e-01]), 'targetState': array([25., 25., 15.])}
episode index:35
target thresh 10.314449392562663
model initialize at round 35
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.95308026, 15.141363  ,  0.98887088, -0.04686623,
        0.14120178]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31488601371702746
{'scaleFactor': 20, 'currentState': array([ 1.89252285, 29.35811934, 76.79563372,  0.17981437, -0.19873206,
        0.96341702]), 'targetState': array([25., 25., 15.])}
episode index:36
target thresh 10.323417499210596
model initialize at round 36
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3063755809138646
{'scaleFactor': 20, 'currentState': array([ 2.57162404e+01,  2.01429854e+01,  1.07292304e+02,  3.94177452e-02,
       -1.46464407e-01,  9.88430280e-01]), 'targetState': array([25., 25., 15.])}
episode index:37
target thresh 10.332384709092713
model initialize at round 37
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11104746, 15.15372671,  0.98214313,  0.11016616,
        0.1525067 ]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.2983130656266576
{'scaleFactor': 20, 'currentState': array([  6.62427763,  40.65136671, -20.6800005 ,  -0.78632464,
         0.59800124,  -0.15520331]), 'targetState': array([25., 25., 15.])}
episode index:38
target thresh 10.341351022298662
model initialize at round 38
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.07210202,  0.98560874,  0.15304484,
        0.0717822 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3148045293131792
{'scaleFactor': 20, 'currentState': array([26.25609771, 21.30169656, 18.6383236 ,  0.45224615,  0.79505095,
        0.40418734]), 'targetState': array([25., 25., 15.])}
episode index:39
target thresh 10.350316438918128
model initialize at round 39
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14786626, 15.07883864,  0.98597559,  0.14726517,
        0.07851816]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.33023604977802445
{'scaleFactor': 20, 'currentState': array([28.87412441, 20.5062034 , 19.15825599,  0.63097971,  0.39292735,
        0.66893401]), 'targetState': array([25., 25., 15.])}
episode index:40
target thresh 10.359280959040762
model initialize at round 40
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.94683461, 15.15372671,  0.98676944, -0.0529919 ,
        0.15322507]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3221815119785605
{'scaleFactor': 20, 'currentState': array([ 2.65896098e+01,  1.07317173e+01,  1.03731144e+02,  8.02581488e-02,
       -1.53550987e-02,  9.96655834e-01]), 'targetState': array([25., 25., 15.])}
episode index:41
target thresh 10.368244582756214
model initialize at round 41
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.85540926, 15.15372671,  0.97802484, -0.14284175,
        0.15186721]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31451052359811854
{'scaleFactor': 20, 'currentState': array([2.84448374e+01, 1.31918210e+01, 1.07628485e+02, 5.28713881e-02,
       1.44118786e-01, 9.88146949e-01]), 'targetState': array([25., 25., 15.])}
episode index:42
target thresh 10.377207310154091
model initialize at round 42
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3071963253749065
{'scaleFactor': 20, 'currentState': array([2.76574166e+01, 2.00508666e+01, 1.07097225e+02, 6.17188619e-02,
       7.29103561e-02, 9.95426975e-01]), 'targetState': array([25., 25., 15.])}
episode index:43
target thresh 10.386169141324043
model initialize at round 43
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.300214590707295
{'scaleFactor': 20, 'currentState': array([ 2.57355924e+01,  2.05405055e+01,  1.07485088e+02, -6.91790643e-02,
        1.34980070e-01,  9.88430391e-01]), 'targetState': array([25., 25., 15.])}
episode index:44
target thresh 10.395130076355697
model initialize at round 44
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.1478518 , 15.05828186,  0.98735893,  0.14745737,
        0.05812638]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.314464936456044
{'scaleFactor': 20, 'currentState': array([25.6948522 , 20.96559657, 19.67928627,  0.3458222 ,  0.60173417,
        0.71994652]), 'targetState': array([25., 25., 15.])}
episode index:45
target thresh 10.404090115338649
model initialize at round 45
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.94909495, 15.15372671,  0.98688477, -0.05074487,
        0.15324298]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3076287421852605
{'scaleFactor': 20, 'currentState': array([ 14.9173504 ,  25.0086536 , 102.15613761,  -0.29420385,
         0.17776165,   0.93906597]), 'targetState': array([25., 25., 15.])}
episode index:46
target thresh 10.413049258362495
model initialize at round 46
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.97412674,  0.98782851,  0.15338952,
       -0.02581651]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3211149423387869
{'scaleFactor': 20, 'currentState': array([26.56212837, 21.01099538, 18.04253551,  0.51115899,  0.63404706,
        0.58025927]), 'targetState': array([25., 25., 15.])}
episode index:47
target thresh 10.422007505516827
model initialize at round 47
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31442504770672886
{'scaleFactor': 20, 'currentState': array([2.29159162e+01, 4.61765926e+01, 8.33571789e+01, 4.92028915e-03,
       9.36494857e-01, 3.50646793e-01]), 'targetState': array([25., 25., 15.])}
episode index:48
target thresh 10.430964856891256
model initialize at round 48
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12287962, 15.15372671,  0.98080813,  0.12173871,
        0.1522994 ]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30800820999842826
{'scaleFactor': 20, 'currentState': array([ 4.06621042e+01,  3.53167661e+01,  1.00547071e+02,  5.41381241e-01,
       -7.06714325e-02,  8.37801827e-01]), 'targetState': array([25., 25., 15.])}
episode index:49
target thresh 10.439921312575319
model initialize at round 49
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.89225697, 15.06400326,  0.99208309, -0.10796974,
        0.06413794]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3018480457984597
{'scaleFactor': 20, 'currentState': array([ 4.92263075e+01,  7.02228950e+00,  8.04131129e+01, -1.87209916e-01,
        7.53684220e-02,  9.79424345e-01]), 'targetState': array([25., 25., 15.])}
episode index:50
target thresh 10.448876872658586
model initialize at round 50
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.97373961,  0.98781858,  0.15338798,
       -0.02620253]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.314576320388686
{'scaleFactor': 20, 'currentState': array([25.37424367, 20.17062307, 14.19971001,  0.59974257,  0.79829574,
       -0.05507051]), 'targetState': array([25., 25., 15.])}
episode index:51
target thresh 10.457831537230632
model initialize at round 51
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.51537267e+01, 1.50149617e+01, 9.88047692e-01,
       1.53423555e-01, 1.49322168e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3266321632543074
{'scaleFactor': 20, 'currentState': array([25.80836868, 21.33030581, 19.06281954,  0.3668031 ,  0.66334958,
        0.65224445]), 'targetState': array([25., 25., 15.])}
episode index:52
target thresh 10.466785306380988
model initialize at round 52
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10702256, 15.15372671,  0.98256761,  0.10621909,
        0.15257261]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32046929224950915
{'scaleFactor': 20, 'currentState': array([ 3.16534395e+01,  4.43128108e+01,  8.57912662e+01, -2.50317848e-02,
        4.74169838e-01,  8.80077482e-01]), 'targetState': array([25., 25., 15.])}
episode index:53
target thresh 10.475738180199201
model initialize at round 53
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.10867028,  0.98239566,  0.15254591,
        0.10783557]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3145346757263701
{'scaleFactor': 20, 'currentState': array([ 2.32935339e+01,  1.70617739e+01,  1.01987109e+02, -4.72542280e-01,
       -2.34423778e-02,  8.80996168e-01]), 'targetState': array([25., 25., 15.])}
episode index:54
target thresh 10.48469015877479
model initialize at round 54
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.90668784,  0.98389952,  0.15277943,
       -0.09273716]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3088158634404361
{'scaleFactor': 20, 'currentState': array([43.65640877, 26.8884525 , 27.94148936,  0.12905475,  0.08007876,
        0.98839884]), 'targetState': array([25., 25., 15.])}
episode index:55
target thresh 10.493641242197283
model initialize at round 55
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.51537267e+01, 1.50142562e+01, 9.88057836e-01,
       1.53425130e-01, 1.42281892e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3033012944504283
{'scaleFactor': 20, 'currentState': array([ 2.26177725e+01,  2.40643901e+01,  1.05335922e+02, -2.14823199e-02,
       -1.63827013e-01,  9.86255149e-01]), 'targetState': array([25., 25., 15.])}
episode index:56
target thresh 10.502591430556185
model initialize at round 56
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.14746634,  0.97762427,  0.15180501,
        0.14562291]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.31466425507235063
{'scaleFactor': 20, 'currentState': array([24.90243104, 20.06196825, 18.18963585,  0.53712673,  0.77591882,
        0.33082452]), 'targetState': array([25., 25., 15.])}
episode index:57
target thresh 10.511540723941016
model initialize at round 57
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10438823, 15.03549171,  0.99385541,  0.10479475,
        0.03562993]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3254714256642238
{'scaleFactor': 20, 'currentState': array([26.19313298, 20.81696122, 18.66674157,  0.34697326,  0.68023525,
        0.64566985]), 'targetState': array([25., 25., 15.])}
episode index:58
target thresh 10.520489122441223
model initialize at round 58
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31995496082245733
{'scaleFactor': 20, 'currentState': array([ 1.20617511e+01,  2.64304029e+01,  1.02875828e+02, -1.19833441e-02,
       -1.02616779e-01,  9.94648780e-01]), 'targetState': array([25., 25., 15.])}
episode index:59
target thresh 10.52943662614635
model initialize at round 59
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.04322559, 15.15372671,  0.98723942,  0.04310506,
        0.15329805]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31462237814208305
{'scaleFactor': 20, 'currentState': array([ 16.53804773,  17.33070154, 102.73137248,  -0.11831438,
        -0.10972495,   0.9868952 ]), 'targetState': array([25., 25., 15.])}
episode index:60
target thresh 10.53838323514582
model initialize at round 60
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.97401617,  0.98782569,  0.15338908,
       -0.02592676]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3250546350561473
{'scaleFactor': 20, 'currentState': array([25.35253763, 20.10074207, 13.86873534,  0.59182957,  0.78353504,
       -0.18923691]), 'targetState': array([25., 25., 15.])}
episode index:61
target thresh 10.547328949529145
model initialize at round 61
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.98064737,  0.98797356,  0.15341204,
       -0.01931302]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.33515036755362876
{'scaleFactor': 20, 'currentState': array([25.32827999, 20.1150358 , 15.62997027,  0.55334775,  0.75021201,
        0.36192294]), 'targetState': array([25., 25., 15.])}
episode index:62
target thresh 10.556273769385738
model initialize at round 62
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3298305204496029
{'scaleFactor': 20, 'currentState': array([ 2.31940498e+01,  2.23465521e+01,  1.07323438e+02, -2.63769881e-02,
        6.75368713e-02,  9.97368049e-01]), 'targetState': array([25., 25., 15.])}
episode index:63
target thresh 10.565217694805074
model initialize at round 63
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.49927580e+01,  1.51537267e+01,  9.88132048e-01,
       -7.22831253e-03,  1.53436653e-01]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32467691856757785
{'scaleFactor': 20, 'currentState': array([ 2.14945548e+01,  2.21920355e+01,  1.06541775e+02, -9.78471723e-02,
       -1.15894391e-01,  9.88430281e-01]), 'targetState': array([25., 25., 15.])}
episode index:64
target thresh 10.574160725876592
model initialize at round 64
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3196818890511536
{'scaleFactor': 20, 'currentState': array([2.33727631e+01, 2.22790523e+01, 1.06828731e+02, 3.72443874e-02,
       4.84620583e-02, 9.98130395e-01]), 'targetState': array([25., 25., 15.])}
episode index:65
target thresh 10.583102862689708
model initialize at round 65
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.06554674, 15.15372671,  0.98604977,  0.0652852 ,
        0.15311332]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31483822406553
{'scaleFactor': 20, 'currentState': array([2.47926770e+01, 2.05182580e+01, 1.07231790e+02, 1.01980222e-01,
       1.12265846e-01, 9.88431290e-01]), 'targetState': array([25., 25., 15.])}
episode index:66
target thresh 10.592044105333853
model initialize at round 66
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31013914609440274
{'scaleFactor': 20, 'currentState': array([2.46170727e+01, 2.22678591e+01, 1.07356149e+02, 1.22408304e-01,
       8.40106679e-02, 9.88917800e-01]), 'targetState': array([25., 25., 15.])}
episode index:67
target thresh 10.600984453898443
model initialize at round 67
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.94009178, 15.15372671,  0.98639593, -0.05969013,
        0.15316707]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3055782762988968
{'scaleFactor': 20, 'currentState': array([2.62851156e+01, 1.83534738e+01, 1.06809290e+02, 7.96962019e-02,
       1.29050752e-01, 9.88430280e-01]), 'targetState': array([25., 25., 15.])}
episode index:68
target thresh 10.609923908472874
model initialize at round 68
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14568158, 15.15372671,  0.97787375,  0.14389717,
        0.15184375]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3011496056278983
{'scaleFactor': 20, 'currentState': array([ 0.09472705, 17.18198939, 94.35945313, -0.10093626,  0.11321419,
        0.98843028]), 'targetState': array([25., 25., 15.])}
episode index:69
target thresh 10.618862469146539
model initialize at round 69
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.2968474684046426
{'scaleFactor': 20, 'currentState': array([ 17.18352046,  19.23754496, 105.53881118,  -0.47895078,
        -0.27828796,   0.83256349]), 'targetState': array([25., 25., 15.])}
episode index:70
target thresh 10.627800136008837
model initialize at round 70
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.0729444 , 14.93480523,  0.99515268,  0.07332406,
       -0.06553409]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.30592680193980254
{'scaleFactor': 20, 'currentState': array([27.24604277, 20.34493037, 13.26903596,  0.58814576,  0.80017373,
       -0.11750139]), 'targetState': array([25., 25., 15.])}
episode index:71
target thresh 10.636736909149125
model initialize at round 71
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.04091679,  0.98733479,  0.15331286,
        0.04080664]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3147539317656525
{'scaleFactor': 20, 'currentState': array([25.69285107, 21.34808615, 19.10814933,  0.2999019 ,  0.72514553,
        0.61985709]), 'targetState': array([25., 25., 15.])}
episode index:72
target thresh 10.64567278865679
model initialize at round 72
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.04450853,  0.98718417,  0.15328947,
        0.04438193]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.32346949502776684
{'scaleFactor': 20, 'currentState': array([25.35670523, 20.14775399, 14.11020456,  0.58913754,  0.78879167,
       -0.17528448]), 'targetState': array([25., 25., 15.])}
episode index:73
target thresh 10.654607774621184
model initialize at round 73
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.51537267e+01,  1.49843108e+01,  9.88036720e-01,
        1.53421851e-01, -1.56581000e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3319495025260403
{'scaleFactor': 20, 'currentState': array([25.3755565 , 20.13484271, 15.29659739,  0.59485818,  0.76779598,
        0.23797708]), 'targetState': array([25., 25., 15.])}
episode index:74
target thresh 10.663541867131654
model initialize at round 74
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3400765778177064
{'scaleFactor': 20, 'currentState': array([26.82086993, 21.33329696, 17.04673995,  0.61625621,  0.72495709,
        0.30767759]), 'targetState': array([25., 25., 15.])}
episode index:75
target thresh 10.672475066277542
model initialize at round 75
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.9710416 , 15.06711538,  0.99728532, -0.0291715 ,
        0.06760928]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.33560188600431556
{'scaleFactor': 20, 'currentState': array([ 24.45199474, -11.02257224,   2.21755099,  -0.19468314,
        -0.22663872,   0.95432351]), 'targetState': array([25., 25., 15.])}
episode index:76
target thresh 10.681407372148177
model initialize at round 76
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.95768718,  0.98727774,  0.153304  ,
       -0.04219647]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.34359394008088284
{'scaleFactor': 20, 'currentState': array([25.39133558, 20.17630296, 14.43891147,  0.60018619,  0.79703816,
       -0.06713195]), 'targetState': array([25., 25., 15.])}
episode index:77
target thresh 10.690338784832875
model initialize at round 77
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.92906749,  0.98569046,  0.15305752,
       -0.07062374]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3512591478926792
{'scaleFactor': 20, 'currentState': array([26.81396882, 21.14160985, 16.55829738,  0.56221034,  0.6662927 ,
        0.48987097]), 'targetState': array([25., 25., 15.])}
episode index:78
target thresh 10.699269304420977
model initialize at round 78
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.04224984, 15.10572745,  0.99345161,  0.04239714,
        0.10609606]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.35861112510805015
{'scaleFactor': 20, 'currentState': array([28.54227376, 21.1727765 , 18.8688933 ,  0.63587588,  0.55286433,
        0.53851917]), 'targetState': array([25., 25., 15.])}
episode index:79
target thresh 10.708198931001768
model initialize at round 79
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08891384, 15.15372671,  0.9842892 ,  0.08840094,
        0.15283994]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3541284860441995
{'scaleFactor': 20, 'currentState': array([ 27.18232306,  20.61429539, 105.92422359,  -0.1287095 ,
         0.26236081,   0.95634757]), 'targetState': array([25., 25., 15.])}
episode index:80
target thresh 10.717127664664538
model initialize at round 80
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14163122, 14.91801398,  0.98661133,  0.14114643,
       -0.08170539]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.36137974114736987
{'scaleFactor': 20, 'currentState': array([25.84937977, 21.42278385, 10.82361505,  0.4843104 ,  0.78673043,
       -0.38275144]), 'targetState': array([25., 25., 15.])}
episode index:81
target thresh 10.7260555054986
model initialize at round 81
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12144892, 14.97046738,  0.99212442,  0.12170954,
       -0.02959599]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3684541363699751
{'scaleFactor': 20, 'currentState': array([26.48697089, 21.43172383, 12.7795388 ,  0.46496663,  0.84168698,
       -0.27453425]), 'targetState': array([25., 25., 15.])}
episode index:82
target thresh 10.7349824535932
model initialize at round 82
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89447583,  0.98272177,  0.15259655,
       -0.10474838]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.37547264135226455
{'scaleFactor': 20, 'currentState': array([25.37343226, 20.18167212, 14.16240533,  0.60100401,  0.79765453,
        0.05041261]), 'targetState': array([25., 25., 15.])}
episode index:83
target thresh 10.743908509037626
model initialize at round 83
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.12508852,  0.98054458,  0.15225848,
        0.1238938 ]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3710027289552138
{'scaleFactor': 20, 'currentState': array([3.43372091e+01, 6.55115216e+00, 1.00241226e+02, 6.81566564e-02,
       7.88103347e-02, 9.94556987e-01]), 'targetState': array([25., 25., 15.])}
episode index:84
target thresh 10.752833671921147
model initialize at round 84
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.88391362, 15.15372671,  0.98159044, -0.11510028,
        0.15242088]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3666379909675054
{'scaleFactor': 20, 'currentState': array([52.82606256, 19.33389644, 89.45945264,  0.83788461,  0.10311784,
        0.53601874]), 'targetState': array([25., 25., 15.])}
episode index:85
target thresh 10.761757942332995
model initialize at round 85
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.50559261e+01,  1.49914173e+01,  9.98370794e-01,
        5.63989608e-02, -8.65528803e-03]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.3732127276761041
{'scaleFactor': 20, 'currentState': array([29.58317297, 20.48533967, 15.20015428,  0.80812877,  0.56465554,
        0.16760675]), 'targetState': array([25., 25., 15.])}
episode index:86
target thresh 10.77068132036243
model initialize at round 86
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.07701454, 15.07177878,  0.99439327,  0.0773563 ,
        0.07209731]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.37963632101209127
{'scaleFactor': 20, 'currentState': array([28.43781311, 20.61308623, 19.96852898,  0.51600421,  0.73548875,
        0.43908537]), 'targetState': array([25., 25., 15.])}
episode index:87
target thresh 10.77960380609867
model initialize at round 87
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.06888172,  0.98583058,  0.15307928,
        0.06859162]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.38602090997105615
{'scaleFactor': 20, 'currentState': array([25.51626732, 21.35339032, 19.62935963,  0.2916841 ,  0.72561025,
        0.6232256 ]), 'targetState': array([25., 25., 15.])}
episode index:88
target thresh 10.788525399630943
model initialize at round 88
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.12168022,  0.98094934,  0.15232133,
        0.12056781]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.39226202502083085
{'scaleFactor': 20, 'currentState': array([26.62132074, 21.21667872, 18.03481036,  0.54091327,  0.7871504 ,
        0.29632261]), 'targetState': array([25., 25., 15.])}
episode index:89
target thresh 10.79744610104848
model initialize at round 89
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09828181, 15.12721906,  0.98707077,  0.09799101,
        0.12684264]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.38790355807615495
{'scaleFactor': 20, 'currentState': array([37.51652387, 10.19397515, 99.65313841,  0.79926263,  0.24403138,
        0.54920664]), 'targetState': array([25., 25., 15.])}
episode index:90
target thresh 10.806365910440475
model initialize at round 90
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.50388279e+01, 1.50153574e+01, 9.99111758e-01,
       3.91852599e-02, 1.54987557e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3836408816137796
{'scaleFactor': 20, 'currentState': array([ 2.84897714, 37.80723981, 32.62714254,  0.15878509, -0.5487839 ,
        0.82074571]), 'targetState': array([25., 25., 15.])}
episode index:91
target thresh 10.815284827896122
model initialize at round 91
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.03123267, 15.08819553,  0.99556386,  0.0314082 ,
        0.0886912 ]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.37947087203102114
{'scaleFactor': 20, 'currentState': array([ 5.69836845e+01,  4.76290133e+01,  3.99908587e+01, -5.31762331e-02,
        1.57485503e-01,  9.86088538e-01]), 'targetState': array([25., 25., 15.])}
episode index:92
target thresh 10.824202853504616
model initialize at round 92
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.84627329, 15.11722097,  0.98146275, -0.15240105,
        0.11621011]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3753905400736983
{'scaleFactor': 20, 'currentState': array([ 33.40553776,  18.68196617, 104.06267116,   0.17643236,
         0.13453036,   0.975076  ]), 'targetState': array([25., 25., 15.])}
episode index:93
target thresh 10.833119987355143
model initialize at round 93
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.51537267e+01,  1.49962607e+01,  9.88150981e-01,
        1.53439593e-01, -3.73227380e-03]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3815139391144037
{'scaleFactor': 20, 'currentState': array([25.38413364, 20.08502578, 13.91419399,  0.61546282,  0.7683483 ,
       -0.17563144]), 'targetState': array([25., 25., 15.])}
episode index:94
target thresh 10.842036229536866
model initialize at round 94
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13475748, 14.98071012,  0.99067802,  0.13484977,
       -0.01930309]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3774980029131994
{'scaleFactor': 20, 'currentState': array([ 2.00519809e+01,  2.14924685e+01,  9.38014206e+01,  3.36054866e-02,
       -1.12122638e-01,  9.93125967e-01]), 'targetState': array([25., 25., 15.])}
episode index:95
target thresh 10.850951580138958
model initialize at round 95
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.97706515, 15.15372671,  0.98789904, -0.02288617,
        0.15340047]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.37356573204952026
{'scaleFactor': 20, 'currentState': array([ 2.80936185e+01,  1.58828522e+01,  1.07119404e+02, -1.24558442e-01,
        8.65492671e-02,  9.88430280e-01]), 'targetState': array([25., 25., 15.])}
episode index:96
target thresh 10.859866039250555
model initialize at round 96
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3697145389356077
{'scaleFactor': 20, 'currentState': array([ 2.09567956e+01,  2.56719146e+01,  1.04785882e+02, -4.29360370e-02,
        1.55607878e-01,  9.86885345e-01]), 'targetState': array([25., 25., 15.])}
episode index:97
target thresh 10.868779606960821
model initialize at round 97
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.03512508,  0.98755111,  0.15334645,
        0.03503819]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3755488818995403
{'scaleFactor': 20, 'currentState': array([27.6445826 , 20.49193562, 15.48997243,  0.81698951,  0.56723236,
        0.1038055 ]), 'targetState': array([25., 25., 15.])}
episode index:98
target thresh 10.877692283358876
model initialize at round 98
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11425522, 15.14850527,  0.9825568 ,  0.1133962 ,
        0.14738875]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.38126535934905
{'scaleFactor': 20, 'currentState': array([25.67111681, 21.0020786 , 19.8744347 ,  0.35328045,  0.77813879,
        0.5193197 ]), 'targetState': array([25., 25., 15.])}
episode index:99
target thresh 10.886604068533856
model initialize at round 99
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.51537267e+01,  1.49983126e+01,  9.88156462e-01,
        1.53440444e-01, -1.68427460e-03]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.38686750724956953
{'scaleFactor': 20, 'currentState': array([25.79074008, 21.44781061, 11.2425348 ,  0.35783117,  0.80581394,
       -0.47182703]), 'targetState': array([25., 25., 15.])}
episode index:100
target thresh 10.89551496257487
model initialize at round 100
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.06752096,  0.98592131,  0.15309337,
        0.06724278]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3830371358906629
{'scaleFactor': 20, 'currentState': array([3.26613915e+01, 2.22408596e+01, 1.04204659e+02, 8.80011315e-02,
       7.69808282e-02, 9.93141356e-01]), 'targetState': array([25., 25., 15.])}
episode index:101
target thresh 10.904424965571035
model initialize at round 101
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.05898828,  0.98644949,  0.15317539,
        0.05877673]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3886053017142838
{'scaleFactor': 20, 'currentState': array([25.39837749, 20.17761828, 15.08448095,  0.60189938,  0.79784616,
       -0.03403864]), 'targetState': array([25., 25., 15.])}
episode index:102
target thresh 10.91333407761146
model initialize at round 102
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.91708407,  0.98479096,  0.15291785,
       -0.08247966]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.384832434707349
{'scaleFactor': 20, 'currentState': array([ 4.24600933e+00,  2.49866179e+01,  5.60890630e+01,  1.48779037e-01,
       -2.95021912e-02,  9.88430280e-01]), 'targetState': array([25., 25., 15.])}
episode index:103
target thresh 10.922242298785223
model initialize at round 103
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.381132122835163
{'scaleFactor': 20, 'currentState': array([15.65514323, 15.27152431, 37.58777426,  0.09635868, -0.54322656,
        0.83403831]), 'targetState': array([25., 25., 15.])}
episode index:104
target thresh 10.931149629181402
model initialize at round 104
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12780249, 15.02391119,  0.99148575,  0.12799429,
        0.02394708]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3864687707072186
{'scaleFactor': 20, 'currentState': array([27.23648917, 20.421303  , 12.99344523,  0.59311024,  0.74738697,
       -0.29938764]), 'targetState': array([25., 25., 15.])}
episode index:105
target thresh 10.94005606888906
model initialize at round 105
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.03709317,  0.98748128,  0.1533356 ,
        0.0369988 ]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3917944431524335
{'scaleFactor': 20, 'currentState': array([25.33605912, 20.12724537, 16.06599535,  0.57702109,  0.77753183,
        0.24998182]), 'targetState': array([25., 25., 15.])}
episode index:106
target thresh 10.948961617997298
model initialize at round 106
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12254824, 14.89314392,  0.98678031,  0.12214969,
       -0.10650856]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3969316927435416
{'scaleFactor': 20, 'currentState': array([27.36618431, 20.36913767, 13.23933494,  0.64693291,  0.73383596,
       -0.2072742 ]), 'targetState': array([25., 25., 15.])}
episode index:107
target thresh 10.957866276595151
model initialize at round 107
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13480665, 14.84627329,  0.9793321 ,  0.13335402,
       -0.1520702 ]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.39325639929221257
{'scaleFactor': 20, 'currentState': array([ 6.69459318e+01, -2.69837645e+00,  3.83889402e+01,  5.08073268e-02,
       -1.32753670e-01,  9.89845987e-01]), 'targetState': array([25., 25., 15.])}
episode index:108
target thresh 10.966770044771657
model initialize at round 108
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08600399, 15.15372671,  0.9845369 ,  0.08552939,
        0.1528784 ]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3896485424179721
{'scaleFactor': 20, 'currentState': array([ 2.56890194e+01,  2.04464381e+01,  1.06667507e+02,  2.06430782e-01,
       -1.43359467e-03,  9.78460156e-01]), 'targetState': array([25., 25., 15.])}
episode index:109
target thresh 10.975672922615875
model initialize at round 109
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.12108771,  0.98101862,  0.15233208,
        0.11998919]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.39475164703144505
{'scaleFactor': 20, 'currentState': array([2.53026653e+01, 2.01761240e+01, 1.64018569e+01, 5.97626174e-01,
       8.01499006e-01, 2.10308969e-02]), 'targetState': array([25., 25., 15.])}
episode index:110
target thresh 10.984574910216816
model initialize at round 110
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.51537267e+01,  1.49841107e+01,  9.88033611e-01,
        1.53421368e-01, -1.58577236e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.39959231100329684
{'scaleFactor': 20, 'currentState': array([29.29136524, 20.78736367, 17.85046064,  0.80188955,  0.38438464,
        0.45740748]), 'targetState': array([25., 25., 15.])}
episode index:111
target thresh 10.993476007663505
model initialize at round 111
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.49982914e+01,  1.51537267e+01,  9.88156427e-01,
       -1.70541040e-03,  1.53440439e-01]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.39602452251219594
{'scaleFactor': 20, 'currentState': array([37.96355534, 11.505221  , -4.73722053,  0.14797606, -0.29907343,
        0.94268668]), 'targetState': array([25., 25., 15.])}
episode index:112
target thresh 11.00237621504495
model initialize at round 112
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.50948111e+01, 1.50158529e+01, 9.95319031e-01,
       9.53205465e-02, 1.59380259e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.40085156345811457
{'scaleFactor': 20, 'currentState': array([26.47141562, 20.73714652, 18.31047783,  0.51521584,  0.67422243,
        0.52912829]), 'targetState': array([25., 25., 15.])}
episode index:113
target thresh 11.01127553245016
model initialize at round 113
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.03095657, 15.02491101,  0.99919551,  0.03124411,
        0.02514239]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3973353216733943
{'scaleFactor': 20, 'currentState': array([3.32465933e+01, 3.44387442e+01, 9.23236411e+01, 2.79144683e-01,
       6.78063360e-02, 9.57852048e-01]), 'targetState': array([25., 25., 15.])}
episode index:114
target thresh 11.020173959968126
model initialize at round 114
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4021497106144952
{'scaleFactor': 20, 'currentState': array([24.92544233, 20.05257817, 18.11476082,  0.54983279,  0.78977867,
        0.27190725]), 'targetState': array([25., 25., 15.])}
episode index:115
target thresh 11.029071497687825
model initialize at round 115
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.93292613,  0.98595073,  0.15309794,
       -0.06679953]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4067991109488616
{'scaleFactor': 20, 'currentState': array([26.99909096, 21.17783004, 14.80226805,  0.56656932,  0.75296298,
        0.33473267]), 'targetState': array([25., 25., 15.])}
episode index:116
target thresh 11.037968145698251
model initialize at round 116
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15298139, 15.15372671,  0.97683539,  0.15094711,
        0.15168251]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.4033221954706662
{'scaleFactor': 20, 'currentState': array([ 3.25308364e+01,  1.69088143e+01,  9.87621908e+01, -7.05363486e-02,
       -1.34276597e-01,  9.88430280e-01]), 'targetState': array([25., 25., 15.])}
episode index:117
target thresh 11.046863904088344
model initialize at round 117
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.84627329, 15.15372671,  0.97672671, -0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3999042107632877
{'scaleFactor': 20, 'currentState': array([ 2.57754617e+01,  3.97738366e+00,  1.04141109e+02,  4.78215696e-02,
       -1.36129395e-01,  9.89536197e-01]), 'targetState': array([25., 25., 15.])}
episode index:118
target thresh 11.055758772947078
model initialize at round 118
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.12237066,  0.98086821,  0.15230873,
        0.12124191]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3965436711770416
{'scaleFactor': 20, 'currentState': array([ 2.52918071e+01,  2.15844097e+01,  1.06998577e+02, -1.79303966e-02,
        9.01598858e-02,  9.95765884e-01]), 'targetState': array([25., 25., 15.])}
episode index:119
target thresh 11.06465275236339
model initialize at round 119
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.96944152, 15.15372671,  0.98769852, -0.03048744,
        0.15336934]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3932391405838996
{'scaleFactor': 20, 'currentState': array([ 3.19557870e+01,  2.37462146e+01,  1.02137408e+02, -8.66375405e-02,
       -1.24497057e-01,  9.88430280e-01]), 'targetState': array([25., 25., 15.])}
episode index:120
target thresh 11.073545842426247
model initialize at round 120
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3899892303311401
{'scaleFactor': 20, 'currentState': array([ 8.06818381, 36.09338306, 81.81060235,  0.08968008, -0.12444829,
        0.98816502]), 'targetState': array([25., 25., 15.])}
episode index:121
target thresh 11.082438043224553
model initialize at round 121
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.03236973, 15.15372671,  0.9876425 ,  0.03229265,
        0.15336064]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3867925972956389
{'scaleFactor': 20, 'currentState': array([2.61503393e+01, 2.18758226e+01, 1.05676857e+02, 2.22768363e-01,
       1.22461121e-02, 9.74794486e-01]), 'targetState': array([25., 25., 15.])}
episode index:122
target thresh 11.091329354847247
model initialize at round 122
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.05693402, 15.12370927,  0.99067118,  0.05697262,
        0.12379314]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3836479420330728
{'scaleFactor': 20, 'currentState': array([ 3.64913237e+01,  2.17242814e+01,  9.88792866e+01,  1.44917530e-01,
       -6.78419984e-02,  9.87115177e-01]), 'targetState': array([25., 25., 15.])}
episode index:123
target thresh 11.100219777383224
model initialize at round 123
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.07092443,  0.98569102,  0.15305761,
        0.07061573]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.38822328161264474
{'scaleFactor': 20, 'currentState': array([25.4000462 , 20.17757545, 15.40303257,  0.60075777,  0.79640344,
        0.0695102 ]), 'targetState': array([25., 25., 15.])}
episode index:124
target thresh 11.109109310921406
model initialize at round 124
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3851174953597436
{'scaleFactor': 20, 'currentState': array([2.23073293e+01, 1.99842180e+01, 1.06830979e+02, 9.37904024e-02,
       1.02372979e-01, 9.90314664e-01]), 'targetState': array([25., 25., 15.])}
episode index:125
target thresh 11.117997955550674
model initialize at round 125
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3820610073013329
{'scaleFactor': 20, 'currentState': array([ 2.32627349e+01,  2.04919018e+01,  1.07155437e+02, -9.99429696e-02,
       -1.14078468e-01,  9.88431842e-01]), 'targetState': array([25., 25., 15.])}
episode index:126
target thresh 11.126885711359913
model initialize at round 126
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.37905265291313345
{'scaleFactor': 20, 'currentState': array([ 2.46829140e+01,  2.10160076e+01,  1.05824947e+02, -6.57381649e-03,
       -8.34197800e-02,  9.96492812e-01]), 'targetState': array([25., 25., 15.])}
episode index:127
target thresh 11.135772578438019
model initialize at round 127
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10607004, 15.05808055,  0.9926219 ,  0.10635096,
        0.05823437]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.38344661772944494
{'scaleFactor': 20, 'currentState': array([26.46331384, 20.03082924, 19.70953829,  0.51950473,  0.53202624,
        0.66862764]), 'targetState': array([25., 25., 15.])}
episode index:128
target thresh 11.144658556873853
model initialize at round 128
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.05957649, 15.15372671,  0.98641534,  0.05936077,
        0.15317008]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3804741633284415
{'scaleFactor': 20, 'currentState': array([ 4.35216655e+01,  1.40200663e+01,  9.35365112e+01,  7.11239722e-02,
       -1.33966271e-01,  9.88430280e-01]), 'targetState': array([25., 25., 15.])}
episode index:129
target thresh 11.153543646756269
model initialize at round 129
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.50075217e+01, 1.51537267e+01, 9.88130015e-01,
       7.50752863e-03, 1.53436338e-01]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3775474389951458
{'scaleFactor': 20, 'currentState': array([ 2.50467799e+01,  1.94134553e+01,  1.07342423e+02, -1.50601415e-02,
       -3.22553739e-02,  9.99366191e-01]), 'targetState': array([25., 25., 15.])}
episode index:130
target thresh 11.162427848174117
model initialize at round 130
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.94544292, 15.15372671,  0.98669597, -0.054375  ,
        0.15321366]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3746653974760989
{'scaleFactor': 20, 'currentState': array([2.58152143e+01, 1.17744539e+01, 1.06288953e+02, 1.84687697e-01,
       3.87071192e-03, 9.82789638e-01]), 'targetState': array([25., 25., 15.])}
episode index:131
target thresh 11.171311161216234
model initialize at round 131
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3718270232527951
{'scaleFactor': 20, 'currentState': array([ 2.23465209e+01,  1.96174485e+01,  1.06717987e+02, -8.18035465e-02,
       -5.65362818e-02,  9.95043632e-01]), 'targetState': array([25., 25., 15.])}
episode index:132
target thresh 11.180193585971477
model initialize at round 132
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13182502, 15.13890921,  0.98180008,  0.13073314,
        0.13775866]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.36903133134863875
{'scaleFactor': 20, 'currentState': array([ 2.42182558e+01,  2.08339753e+01,  1.05627091e+02, -1.65470003e-02,
       -3.63667794e-01,  9.31381733e-01]), 'targetState': array([25., 25., 15.])}
episode index:133
target thresh 11.189075122528646
model initialize at round 133
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.50159917e+01, 1.50366330e+01, 9.99185920e-01,
       1.61400419e-02, 3.69729028e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.36627736618932055
{'scaleFactor': 20, 'currentState': array([ 3.15217101e+01,  3.25227741e+01,  9.44793326e+01, -1.21126924e-01,
        9.12852530e-02,  9.88430711e-01]), 'targetState': array([25., 25., 15.])}
episode index:134
target thresh 11.197955770976575
model initialize at round 134
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.12619558,  0.98041082,  0.1522377 ,
        0.12497324]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3706085712538441
{'scaleFactor': 20, 'currentState': array([25.1655299 , 20.08892933, 17.36395361,  0.57767609,  0.76132949,
        0.29439387]), 'targetState': array([25., 25., 15.])}
episode index:135
target thresh 11.206835531404058
model initialize at round 135
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12210303, 14.97229089,  0.99209706,  0.12236167,
       -0.0277678 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3748061563872791
{'scaleFactor': 20, 'currentState': array([26.70871132, 20.49711149, 17.98366188,  0.44236281,  0.67700714,
        0.58819765]), 'targetState': array([25., 25., 15.])}
episode index:136
target thresh 11.215714403899902
model initialize at round 136
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.1322441 ,  0.97966017,  0.15212115,
        0.1308629 ]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.37207034502678804
{'scaleFactor': 20, 'currentState': array([ 2.33382768e+01,  2.41300351e+01,  1.06292053e+02,  1.48400645e-01,
       -3.13501095e-02,  9.88430280e-01]), 'targetState': array([25., 25., 15.])}
episode index:137
target thresh 11.224592388552878
model initialize at round 137
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.36937418310630404
{'scaleFactor': 20, 'currentState': array([ 2.43176076e+01,  2.26383499e+01,  1.07385348e+02, -2.79057882e-03,
       -1.51650235e-01,  9.88430280e-01]), 'targetState': array([25., 25., 15.])}
episode index:138
target thresh 11.233469485451774
model initialize at round 138
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3667168148825177
{'scaleFactor': 20, 'currentState': array([ 2.40955677e+01,  2.08529070e+01,  1.06443609e+02,  4.63696269e-02,
       -1.12030516e-01,  9.92622295e-01]), 'targetState': array([25., 25., 15.])}
episode index:139
target thresh 11.242345694685374
model initialize at round 139
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.06437531, 15.10060977,  0.99280042,  0.06455741,
        0.10089437]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.37082226727193546
{'scaleFactor': 20, 'currentState': array([26.47910696, 20.58040881, 18.90252734,  0.48199974,  0.79239107,
        0.37388854]), 'targetState': array([25., 25., 15.])}
episode index:140
target thresh 11.251221016342427
model initialize at round 140
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.51537267e+01,  1.49895603e+01,  9.88104220e-01,
        1.53432332e-01, -1.04197293e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.36819232211397845
{'scaleFactor': 20, 'currentState': array([ 1.47441652e+01,  3.90346284e+01,  8.65971023e+01, -3.60068439e-02,
        4.18755110e-02,  9.98473810e-01]), 'targetState': array([25., 25., 15.])}
episode index:141
target thresh 11.260095450511686
model initialize at round 141
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.36559941843711946
{'scaleFactor': 20, 'currentState': array([ 2.31727233e+01,  2.17685225e+01,  1.06993251e+02, -5.15161732e-02,
        1.42659262e-01,  9.88430280e-01]), 'targetState': array([25., 25., 15.])}
episode index:142
target thresh 11.268968997281902
model initialize at round 142
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3630427791473494
{'scaleFactor': 20, 'currentState': array([ 2.44033086e+01,  2.32538666e+01,  1.07219313e+02, -1.35962690e-01,
        6.72289222e-02,  9.88430280e-01]), 'targetState': array([25., 25., 15.])}
episode index:143
target thresh 11.277841656741817
model initialize at round 143
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15023528,  0.97723158,  0.15174403,
        0.14829763]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3605216487366039
{'scaleFactor': 20, 'currentState': array([41.71688332, 12.83643951, 97.76705855, -0.12218564,  0.10138348,
        0.98731558]), 'targetState': array([25., 25., 15.])}
episode index:144
target thresh 11.286713428980132
model initialize at round 144
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.03391351, 15.15372671,  0.98759221,  0.03383102,
        0.15335283]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3580352925384204
{'scaleFactor': 20, 'currentState': array([ 2.18571181e+01,  1.62484995e+01,  1.04349628e+02, -1.29342988e-03,
       -1.02636486e-01,  9.94718090e-01]), 'targetState': array([25., 25., 15.])}
episode index:145
target thresh 11.295584314085582
model initialize at round 145
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.94245481, 15.15372671,  0.98653185, -0.0573436 ,
        0.15318818]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3555829960141847
{'scaleFactor': 20, 'currentState': array([11.4096193 , 30.52804771, 84.72792743,  0.60499308,  0.09580802,
        0.79044557]), 'targetState': array([25., 25., 15.])}
episode index:146
target thresh 11.304454312146884
model initialize at round 146
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.92764546,  0.98559093,  0.15304207,
       -0.0720323 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.35956869093518345
{'scaleFactor': 20, 'currentState': array([27.32517609, 20.73692547, 13.24783172,  0.74561094,  0.6647681 ,
       -0.04634323]), 'targetState': array([25., 25., 15.])}
episode index:147
target thresh 11.313323423252719
model initialize at round 147
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.05368786, 15.15372671,  0.98674208,  0.05351119,
        0.15322082]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.35713917275318896
{'scaleFactor': 20, 'currentState': array([4.01009995e+01, 2.32206764e+01, 9.93117390e+01, 1.43101958e-01,
       7.22981784e-02, 9.87063728e-01]), 'targetState': array([25., 25., 15.])}
episode index:148
target thresh 11.322191647491797
model initialize at round 148
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.12959873,  0.97999258,  0.15217276,
        0.12828868]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.36112474910987896
{'scaleFactor': 20, 'currentState': array([25.05351922, 20.00393366, 17.70966644,  0.49122658,  0.71018951,
        0.50430875]), 'targetState': array([25., 25., 15.])}
episode index:149
target thresh 11.33105898495278
model initialize at round 149
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3587172507824798
{'scaleFactor': 20, 'currentState': array([2.26316516e+01, 2.34633252e+01, 1.05903432e+02, 1.00292042e-01,
       5.21812008e-02, 9.93588762e-01]), 'targetState': array([25., 25., 15.])}
episode index:150
target thresh 11.339925435724362
model initialize at round 150
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.06403362, 15.15372671,  0.98614568,  0.06378432,
        0.15312821]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3563416398501455
{'scaleFactor': 20, 'currentState': array([ 2.78907938e+01,  1.65493703e+01,  1.07418494e+02, -3.28746733e-02,
       -1.48070378e-01,  9.88430280e-01]), 'targetState': array([25., 25., 15.])}
episode index:151
target thresh 11.348790999895186
model initialize at round 151
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13751535, 15.15372671,  0.97897884,  0.13598446,
        0.15201535]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.35399728695639454
{'scaleFactor': 20, 'currentState': array([ 2.31124558e+01,  2.16565891e+01,  1.06657702e+02,  2.18624606e-01,
       -7.37169488e-02,  9.73020603e-01]), 'targetState': array([25., 25., 15.])}
episode index:152
target thresh 11.357655677553923
model initialize at round 152
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10839145, 14.97758893,  0.99380813,  0.10880839,
       -0.02249728]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.35783704422727436
{'scaleFactor': 20, 'currentState': array([26.93492132, 20.62308316, 12.9465506 ,  0.49717034,  0.76380664,
       -0.4116079 ]), 'targetState': array([25., 25., 15.])}
episode index:153
target thresh 11.366519468789226
model initialize at round 153
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.51537267e+01,  1.49842913e+01,  9.88036419e-01,
        1.53421804e-01, -1.56775550e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.36168868712125307
{'scaleFactor': 20, 'currentState': array([25.39038515, 20.16774472, 15.45045106,  0.59594096,  0.79262416,
        0.12884608]), 'targetState': array([25., 25., 15.])}
episode index:154
target thresh 11.375382373689714
model initialize at round 154
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.050662  ,  0.98689687,  0.15324486,
        0.0505032 ]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.36549063139724497
{'scaleFactor': 20, 'currentState': array([25.30544989, 20.13669994, 16.53240715,  0.60195246,  0.78955099,
        0.11942557]), 'targetState': array([25., 25., 15.])}
episode index:155
target thresh 11.384244392344034
model initialize at round 155
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13563091, 14.98008668,  0.99054878,  0.13570609,
       -0.01992436]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.36918287189726906
{'scaleFactor': 20, 'currentState': array([26.37942361, 21.51844733, 17.21870696,  0.42140361,  0.80466665,
        0.41824703]), 'targetState': array([25., 25., 15.])}
episode index:156
target thresh 11.393105524840784
model initialize at round 156
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3668313886367769
{'scaleFactor': 20, 'currentState': array([2.37614221e+01, 2.49263314e+01, 1.05224391e+02, 1.50380066e-01,
       1.97847903e-02, 9.88430270e-01]), 'targetState': array([25., 25., 15.])}
episode index:157
target thresh 11.401965771268596
model initialize at round 157
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12752486, 15.03476772,  0.99120436,  0.12767999,
        0.03481002]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.364509670987177
{'scaleFactor': 20, 'currentState': array([3.84443201e+01, 2.69445111e+01, 9.35342024e+01, 4.47630898e-02,
       1.64449499e-02, 9.98862267e-01]), 'targetState': array([25., 25., 15.])}
episode index:158
target thresh 11.410825131716063
model initialize at round 158
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09434137, 15.15372671,  0.98380569,  0.09375109,
        0.15276486]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3622171573331696
{'scaleFactor': 20, 'currentState': array([ 1.64358405e+01,  2.03657059e+01,  9.76167305e+01, -4.11295569e-01,
       -6.10395285e-02,  9.09455953e-01]), 'targetState': array([25., 25., 15.])}
episode index:159
target thresh 11.41968360627178
model initialize at round 159
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.88778157, 15.10455767,  0.98821035, -0.11201557,
        0.10436865]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3599533000998373
{'scaleFactor': 20, 'currentState': array([4.69185320e+01, 1.09745978e+01, 9.36054878e+01, 4.62129471e-03,
       3.13715397e-01, 9.49505815e-01]), 'targetState': array([25., 25., 15.])}
episode index:160
target thresh 11.428541195024334
model initialize at round 160
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12192449, 15.06894426,  0.99013918,  0.12194163,
        0.06895396]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.36356526810791906
{'scaleFactor': 20, 'currentState': array([25.97495495, 21.11280087, 18.99387069,  0.33773619,  0.72376359,
        0.6017479 ]), 'targetState': array([25., 25., 15.])}
episode index:161
target thresh 11.437397898062295
model initialize at round 161
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3613210380578702
{'scaleFactor': 20, 'currentState': array([34.63109226, 21.99582287, 32.30583599, -0.71704447,  0.38827185,
       -0.57887149]), 'targetState': array([25., 25., 15.])}
episode index:162
target thresh 11.446253715474253
model initialize at round 162
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.8662377 ,  0.97946652,  0.15209108,
       -0.13233909]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.36488029640966857
{'scaleFactor': 20, 'currentState': array([26.6256648 , 21.28318554, 16.0018329 ,  0.46008991,  0.79957148,
        0.38600871]), 'targetState': array([25., 25., 15.])}
episode index:163
target thresh 11.455108647348721
model initialize at round 163
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.05014846,  0.98692226,  0.1532488 ,
        0.04999255]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.36839614917181085
{'scaleFactor': 20, 'currentState': array([25.61797963, 21.26883387, 19.25425413,  0.27025929,  0.6875161 ,
        0.67400411]), 'targetState': array([25., 25., 15.])}
episode index:164
target thresh 11.463962693774288
model initialize at round 164
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.07924957,  0.98508077,  0.15296285,
        0.07885579]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.37192702129743627
{'scaleFactor': 20, 'currentState': array([25.36254567, 20.17102331, 15.33606985,  0.5935446 ,  0.79073383,
       -0.14981593]), 'targetState': array([25., 25., 15.])}
episode index:165
target thresh 11.47281585483949
model initialize at round 165
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.02012886,  0.98795848,  0.1534097 ,
        0.02008735]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3753580642378192
{'scaleFactor': 20, 'currentState': array([26.13081839, 21.33594023, 12.05713905,  0.36165732,  0.73835442,
       -0.56924225]), 'targetState': array([25., 25., 15.])}
episode index:166
target thresh 11.481668130632839
model initialize at round 166
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.98151626,  0.98798973,  0.15341455,
       -0.01844621]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3787480168435867
{'scaleFactor': 20, 'currentState': array([26.86924407, 20.21269524, 18.74952364,  0.69782748,  0.44432561,
        0.56179316]), 'targetState': array([25., 25., 15.])}
episode index:167
target thresh 11.49051952124286
model initialize at round 167
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09206714, 15.15372671,  0.98401169,  0.09151024,
        0.15279685]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3764935643623749
{'scaleFactor': 20, 'currentState': array([ 24.93763456,  20.34909424, 107.00660479,   0.30960378,
        -0.42483   ,   0.850685  ]), 'targetState': array([25., 25., 15.])}
episode index:168
target thresh 11.499370026758093
model initialize at round 168
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.90246001,  0.98350768,  0.15271858,
       -0.09690034]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.37426579179218333
{'scaleFactor': 20, 'currentState': array([ 2.62052136e+01,  3.45252919e+01,  7.96802245e+01, -2.00981855e-02,
       -1.51386045e-01,  9.88270372e-01]), 'targetState': array([25., 25., 15.])}
episode index:169
target thresh 11.508219647267016
model initialize at round 169
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09193804, 15.15372671,  0.98402323,  0.09138299,
        0.15279864]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.37206422831105285
{'scaleFactor': 20, 'currentState': array([ 20.45908158,  21.89060474, 105.47337086,  -0.23682588,
        -0.52091614,   0.82009748]), 'targetState': array([25., 25., 15.])}
episode index:170
target thresh 11.517068382858131
model initialize at round 170
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.51537267e+01,  1.49830532e+01,  9.88016525e-01,
        1.53418715e-01, -1.69128308e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3754497594314561
{'scaleFactor': 20, 'currentState': array([25.37364646, 20.14794898, 14.45115902,  0.57329695,  0.76785693,
       -0.28587818]), 'targetState': array([25., 25., 15.])}
episode index:171
target thresh 11.525916233619926
model initialize at round 171
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87797153,  0.98090848,  0.15231498,
       -0.12090784]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.37879592391092437
{'scaleFactor': 20, 'currentState': array([25.12095364, 20.04120102, 12.44067816,  0.59857248,  0.75191856,
       -0.27627788]), 'targetState': array([25., 25., 15.])}
episode index:172
target thresh 11.534763199640896
model initialize at round 172
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08900976, 14.94379638,  0.9943942 ,  0.08940484,
       -0.05645308]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.38199401306697095
{'scaleFactor': 20, 'currentState': array([28.82401452, 21.071358  , 12.66892111,  0.49205658,  0.76578387,
       -0.41407172]), 'targetState': array([25., 25., 15.])}
episode index:173
target thresh 11.543609281009493
model initialize at round 173
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15168452, 14.87560469,  0.98092796,  0.15029453,
       -0.12325539]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3797986451757815
{'scaleFactor': 20, 'currentState': array([25.40770743, 58.0928264 , 39.04960388, -0.09260499,  0.1201245 ,
        0.98843028]), 'targetState': array([25., 25., 15.])}
episode index:174
target thresh 11.552454477814189
model initialize at round 174
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3776283672033484
{'scaleFactor': 20, 'currentState': array([18.83394997, 34.69958485, 97.5069011 , -0.10331147, -0.11105099,
        0.98843028]), 'targetState': array([25., 25., 15.])}
episode index:175
target thresh 11.561298790143415
model initialize at round 175
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3754827514806021
{'scaleFactor': 20, 'currentState': array([2.21494194e+01, 2.17723501e+01, 1.06788326e+02, 3.80753485e-02,
       2.15326525e-02, 9.99042848e-01]), 'targetState': array([25., 25., 15.])}
episode index:176
target thresh 11.570142218085632
model initialize at round 176
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.06461843, 15.15372671,  0.98610888,  0.06436445,
        0.1531225 ]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3733613800033106
{'scaleFactor': 20, 'currentState': array([ 3.15831067e+01,  2.47652727e+01,  1.03198455e+02, -1.80203465e-03,
        9.21681664e-01,  3.87942861e-01]), 'targetState': array([25., 25., 15.])}
episode index:177
target thresh 11.578984761729272
model initialize at round 177
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.09410479,  0.98382735,  0.15276822,
        0.09351804]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3712638441605954
{'scaleFactor': 20, 'currentState': array([ 8.74878914, 29.88912396, 88.92510949, -0.39967959, -0.90506049,
        0.14533321]), 'targetState': array([25., 25., 15.])}
episode index:178
target thresh 11.587826421162761
model initialize at round 178
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.04213622,  0.98728507,  0.15330513,
        0.04202066]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3745025380474077
{'scaleFactor': 20, 'currentState': array([25.26162943, 20.08657277, 16.65608317,  0.53627892,  0.73930702,
        0.40722236]), 'targetState': array([25., 25., 15.])}
episode index:179
target thresh 11.596667196474508
model initialize at round 179
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.9802219 ,  0.98796537,  0.15341077,
       -0.01973745]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.37765241366603874
{'scaleFactor': 20, 'currentState': array([25.91137246, 21.39776431, 18.34646546,  0.30823759,  0.70754203,
        0.63590397]), 'targetState': array([25., 25., 15.])}
episode index:180
target thresh 11.605507087752931
model initialize at round 180
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.13138196,  0.97976921,  0.15213808,
        0.13002424]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3755659362424695
{'scaleFactor': 20, 'currentState': array([ 2.37929816e+01,  2.39202189e+01,  1.06438144e+02, -7.72336962e-02,
        8.82265078e-02,  9.93101727e-01]), 'targetState': array([25., 25., 15.])}
episode index:181
target thresh 11.614346095086425
model initialize at round 181
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.93526773, 15.15372671,  0.98610167, -0.06447737,
        0.15312138]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.37350238714223616
{'scaleFactor': 20, 'currentState': array([ 2.95799780e+01,  1.08576785e+01,  1.06872949e+02, -1.56406619e-01,
        7.09949615e-02,  9.85137901e-01]), 'targetState': array([25., 25., 15.])}
episode index:182
target thresh 11.623184218563388
model initialize at round 182
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.08349398,  0.9847441 ,  0.15291057,
        0.08305071]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3766060907611365
{'scaleFactor': 20, 'currentState': array([25.83248108, 21.36837615, 19.20940765,  0.35787674,  0.76620802,
        0.53371295]), 'targetState': array([25., 25., 15.])}
episode index:183
target thresh 11.632021458272169
model initialize at round 183
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.374559318528739
{'scaleFactor': 20, 'currentState': array([ 1.68555110e+01,  3.66052135e+01,  9.75279540e+01, -4.34451128e-02,
        1.18749289e-01,  9.91973351e-01]), 'targetState': array([25., 25., 15.])}
episode index:184
target thresh 11.640857814301187
model initialize at round 184
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11898972, 15.15372671,  0.98126131,  0.1179394 ,
        0.15236977]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.37253467356371883
{'scaleFactor': 20, 'currentState': array([2.51451702e+01, 2.22302253e+01, 1.07442303e+02, 1.42544825e-01,
       5.18319787e-02, 9.88430280e-01]), 'targetState': array([25., 25., 15.])}
episode index:185
target thresh 11.64969328673877
model initialize at round 185
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.37053179897466654
{'scaleFactor': 20, 'currentState': array([1.66495052e+01, 3.44184290e+01, 9.86785110e+01, 6.59767875e-03,
       6.36449267e-03, 9.99957981e-01]), 'targetState': array([25., 25., 15.])}
episode index:186
target thresh 11.658527875673286
model initialize at round 186
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.50037463e+01, 1.51537267e+01, 9.88150955e-01,
       3.73933419e-03, 1.53439589e-01]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3685503455042138
{'scaleFactor': 20, 'currentState': array([ 2.84733540e+01,  1.35919402e+01,  1.07284476e+02, -1.17567122e-01,
        9.62522218e-02,  9.88389337e-01]), 'targetState': array([25., 25., 15.])}
episode index:187
target thresh 11.66736158119307
model initialize at round 187
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3665899713259999
{'scaleFactor': 20, 'currentState': array([2.74560218e+01, 1.96285161e+01, 1.07219024e+02, 1.50663345e-01,
       1.74488012e-02, 9.88431129e-01]), 'targetState': array([25., 25., 15.])}
episode index:188
target thresh 11.676194403386486
model initialize at round 188
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.36465034184808454
{'scaleFactor': 20, 'currentState': array([ 2.46346739e+01,  2.54667428e+01,  1.05564643e+02, -2.70327357e-02,
       -4.38272270e-02,  9.98673323e-01]), 'targetState': array([25., 25., 15.])}
episode index:189
target thresh 11.685026342341843
model initialize at round 189
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.01937375, 15.15372671,  0.98797316,  0.01933409,
        0.15341198]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3627311295225683
{'scaleFactor': 20, 'currentState': array([ 2.61935930e+01,  2.08126960e+01,  1.07444019e+02, -1.31376153e-01,
       -7.92409712e-02,  9.88160501e-01]), 'targetState': array([25., 25., 15.])}
episode index:190
target thresh 11.693857398147456
model initialize at round 190
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3608320136611936
{'scaleFactor': 20, 'currentState': array([ 2.62609012e+01,  1.90276112e+01,  1.07274795e+02,  8.75817996e-02,
       -2.37546658e-02,  9.95874060e-01]), 'targetState': array([25., 25., 15.])}
episode index:191
target thresh 11.702687570891646
model initialize at round 191
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.04223256, 15.10312068,  0.99372477,  0.04239146,
        0.10350866]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.35895268025670823
{'scaleFactor': 20, 'currentState': array([30.88088622, -9.71696055, -0.81541012, -0.40296817, -0.73009493,
       -0.5518859 ]), 'targetState': array([25., 25., 15.])}
episode index:192
target thresh 11.71151686066272
model initialize at round 192
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.1292916 ,  0.98003076,  0.15217869,
        0.12798965]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.36197095729890666
{'scaleFactor': 20, 'currentState': array([25.8071831 , 21.09905692, 19.81822418,  0.4167754 ,  0.68967985,
        0.59214861]), 'targetState': array([25., 25., 15.])}
episode index:193
target thresh 11.720345267548948
model initialize at round 193
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.50001093e+01, 1.51537267e+01, 9.88157858e-01,
       1.09090817e-04, 1.53440661e-01]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.36010512762210817
{'scaleFactor': 20, 'currentState': array([3.59761588e+01, 3.68113594e+01, 8.15967374e+01, 3.24578366e-02,
       5.83549394e-02, 9.97768104e-01]), 'targetState': array([25., 25., 15.])}
episode index:194
target thresh 11.729172791638632
model initialize at round 194
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.49945470e+01,  1.49936361e+01,  9.99964172e-01,
       -5.50786418e-03, -6.42794552e-03]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3582584346599435
{'scaleFactor': 20, 'currentState': array([15.99142614, 27.89329054, 35.46022023,  0.06225177, -0.97299958,
       -0.22225331]), 'targetState': array([25., 25., 15.])}
episode index:195
target thresh 11.737999433020041
model initialize at round 195
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.84763897, 15.02353558,  0.98809097, -0.15206723,
        0.0234902 ]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3564305855035152
{'scaleFactor': 20, 'currentState': array([ 2.61978890e+01,  9.55225312e+00,  9.72315273e+01,  1.14869029e-02,
       -1.33008459e-01,  9.91048334e-01]), 'targetState': array([25., 25., 15.])}
episode index:196
target thresh 11.74682519178144
model initialize at round 196
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.50057565e+01, 1.51519177e+01, 9.88413814e-01,
       5.74723981e-03, 1.51674324e-01]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.35462129319131463
{'scaleFactor': 20, 'currentState': array([ 3.24432810e+01,  2.16647018e+01,  1.02073192e+02, -6.29190385e-02,
       -4.58714090e-02,  9.96963895e-01]), 'targetState': array([25., 25., 15.])}
episode index:197
target thresh 11.755650068011104
model initialize at round 197
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08804845, 15.15372671,  0.98436371,  0.08754717,
        0.15285151]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.35283027655903526
{'scaleFactor': 20, 'currentState': array([1.95638304e+01, 2.26194756e+01, 1.01957511e+02, 1.49237070e-01,
       2.70905037e-02, 9.88430271e-01]), 'targetState': array([25., 25., 15.])}
episode index:198
target thresh 11.764474061797259
model initialize at round 198
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.35105726009391447
{'scaleFactor': 20, 'currentState': array([ 2.50572390e+01,  2.17824998e+01,  1.06850753e+02,  6.10907460e-02,
       -7.27405097e-02,  9.95478146e-01]), 'targetState': array([25., 25., 15.])}
episode index:199
target thresh 11.773297173228158
model initialize at round 199
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.05021351, 15.15372671,  0.98691906,  0.05005725,
        0.1532483 ]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3493019737934449
{'scaleFactor': 20, 'currentState': array([ 2.64927323e+01,  2.20075181e+01,  1.06631852e+02, -4.23889335e-02,
       -1.45628172e-01,  9.88430885e-01]), 'targetState': array([25., 25., 15.])}
episode index:200
target thresh 11.782119402392022
model initialize at round 200
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3475641530283034
{'scaleFactor': 20, 'currentState': array([2.59099556e+01, 2.62747036e+01, 1.06129922e+02, 1.52214602e-01,
       1.97903806e-02, 9.88149308e-01]), 'targetState': array([25., 25., 15.])}
episode index:201
target thresh 11.790940749377087
model initialize at round 201
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12270438, 15.07655799,  0.98949673,  0.122642  ,
        0.07651907]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3458435384093514
{'scaleFactor': 20, 'currentState': array([ 2.84624726e+01,  2.86795609e+01,  9.95663912e+01, -1.53509174e-02,
       -1.50897086e-01,  9.88430280e-01]), 'targetState': array([25., 25., 15.])}
episode index:202
target thresh 11.799761214271554
model initialize at round 202
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3441398756585664
{'scaleFactor': 20, 'currentState': array([ 1.28248927e+01,  1.04863987e+01,  9.01467012e+01, -8.43042245e-03,
       -1.04974722e-01,  9.94439156e-01]), 'targetState': array([25., 25., 15.])}
episode index:203
target thresh 11.808580797163625
model initialize at round 203
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.8614339 , 15.10896903,  0.9845144 , -0.1377983 ,
        0.10836524]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.34245291548376955
{'scaleFactor': 20, 'currentState': array([ 31.7469683 ,   3.94310616, 102.16323496,   0.12576565,
         0.11277858,   0.98562873]), 'targetState': array([25., 25., 15.])}
episode index:204
target thresh 11.817399498141512
model initialize at round 204
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10686576, 15.14020206,  0.98451338,  0.10627351,
        0.13942505]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.34537499955165846
{'scaleFactor': 20, 'currentState': array([26.24669967, 20.91886162, 19.23056373,  0.54157222,  0.68425005,
        0.48836605]), 'targetState': array([25., 25., 15.])}
episode index:205
target thresh 11.826217317293386
model initialize at round 205
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.03698027, 15.0859292 ,  0.99556515,  0.03718815,
        0.08641224]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.34369842188393196
{'scaleFactor': 20, 'currentState': array([ 2.71244168e+01,  2.07384382e+01,  1.06639055e+02, -5.95640218e-02,
       -1.10358350e-01,  9.92105419e-01]), 'targetState': array([25., 25., 15.])}
episode index:206
target thresh 11.835034254707455
model initialize at round 206
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3420380430342511
{'scaleFactor': 20, 'currentState': array([ 2.46210082e+01,  2.27369806e+01,  1.07070830e+02, -8.82966226e-02,
       -1.23722566e-01,  9.88380713e-01]), 'targetState': array([25., 25., 15.])}
episode index:207
target thresh 11.843850310471836
model initialize at round 207
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.07505645, 15.15372671,  0.98539645,  0.07470744,
        0.15301187]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.34039362936581724
{'scaleFactor': 20, 'currentState': array([ 2.81478439e+01,  1.40646963e+01,  1.05362367e+02,  8.93248812e-03,
       -4.68980699e-02,  9.98859741e-01]), 'targetState': array([25., 25., 15.])}
episode index:208
target thresh 11.852665484674741
model initialize at round 208
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.91617923, 15.1025751 ,  0.99116651, -0.08391954,
        0.10269596]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3387649517133492
{'scaleFactor': 20, 'currentState': array([ 6.47256430e+01, -1.30929470e+01,  7.09181410e+01, -3.87519124e-02,
        2.60742598e-03,  9.99245461e-01]), 'targetState': array([25., 25., 15.])}
episode index:209
target thresh 11.861479777404282
model initialize at round 209
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.96830432, 15.15372671,  0.98766372, -0.03162088,
        0.15336393]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.337151785276619
{'scaleFactor': 20, 'currentState': array([2.74064449e+01, 1.85622832e+01, 1.04835376e+02, 1.18374739e-01,
       9.48315246e-02, 9.88430272e-01]), 'targetState': array([25., 25., 15.])}
episode index:210
target thresh 11.870293188748636
model initialize at round 210
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3400159007464028
{'scaleFactor': 20, 'currentState': array([25.52057667, 21.67201485, 19.46753947,  0.39651944,  0.88093241,
        0.25832232]), 'targetState': array([25., 25., 15.])}
episode index:211
target thresh 11.879105718795913
model initialize at round 211
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.90664853,  0.98389595,  0.15277887,
       -0.0927759 ]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3428978542801462
{'scaleFactor': 20, 'currentState': array([ 2.53758350e+01,  2.01809098e+01,  1.43597448e+01,  6.01855744e-01,
        7.98590567e-01, -4.77163852e-03]), 'targetState': array([25., 25., 15.])}
episode index:212
target thresh 11.887917367634248
model initialize at round 212
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.51537267e+01, 1.50070323e+01, 9.88133521e-01,
       1.53436882e-01, 7.01905481e-03]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3457080997971455
{'scaleFactor': 20, 'currentState': array([25.31485071, 21.02375275, 19.96921464,  0.25510339,  0.60021876,
        0.75806312]), 'targetState': array([25., 25., 15.])}
episode index:213
target thresh 11.896728135351765
model initialize at round 213
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.34409264138687845
{'scaleFactor': 20, 'currentState': array([ 2.43922709e+00,  4.05291897e+01,  8.82413251e+01,  8.21981170e-04,
       -7.04257624e-02,  9.97516685e-01]), 'targetState': array([25., 25., 15.])}
episode index:214
target thresh 11.905538022036556
model initialize at round 214
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.07943118, 15.15372671,  0.98506672,  0.07903537,
        0.15296067]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3424922104967069
{'scaleFactor': 20, 'currentState': array([2.64018324e+01, 1.75343221e+01, 1.06708693e+02, 1.23089443e-01,
       7.20947754e-02, 9.89773374e-01]), 'targetState': array([25., 25., 15.])}
episode index:215
target thresh 11.914347027776717
model initialize at round 215
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09903441, 15.15372671,  0.98336514,  0.09837069,
        0.15269645]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.340906598411074
{'scaleFactor': 20, 'currentState': array([2.71464126e+01, 2.33598656e+01, 1.05390840e+02, 1.26409543e-01,
       8.35834600e-03, 9.91942925e-01]), 'targetState': array([25., 25., 15.])}
episode index:216
target thresh 11.923155152660359
model initialize at round 216
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15359737,  0.97674561,  0.15166857,
        0.15154097]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3393356002617142
{'scaleFactor': 20, 'currentState': array([ 4.05612386e+01,  2.23979133e+01,  1.01860862e+02, -1.25312963e-01,
       -8.54531585e-02,  9.88430280e-01]), 'targetState': array([25., 25., 15.])}
episode index:217
target thresh 11.931962396775543
model initialize at round 217
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.1462648 ,  0.97779254,  0.15183114,
        0.14446124]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.34214135461785317
{'scaleFactor': 20, 'currentState': array([25.15281148, 20.14832943, 17.26634599,  0.58590962,  0.80327119,
        0.10707615]), 'targetState': array([25., 25., 15.])}
episode index:218
target thresh 11.940768760210362
model initialize at round 218
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.92778558,  0.98560082,  0.15304361,
       -0.07189353]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.34492148564653874
{'scaleFactor': 20, 'currentState': array([25.35622774, 20.15554673, 15.07090391,  0.5837984 ,  0.7807877 ,
        0.22259829]), 'targetState': array([25., 25., 15.])}
episode index:219
target thresh 11.94957424305285
model initialize at round 219
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.34335366071178175
{'scaleFactor': 20, 'currentState': array([ 2.33474462e+01,  2.24180071e+01,  1.07375355e+02,  6.88089208e-02,
       -1.36283504e-01,  9.88277359e-01]), 'targetState': array([25., 25., 15.])}
episode index:220
target thresh 11.958378845391094
model initialize at round 220
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3418000242379728
{'scaleFactor': 20, 'currentState': array([ 2.35420501e+01,  2.20086330e+01,  1.07369161e+02, -1.51366791e-01,
       -9.67861475e-03,  9.88430280e-01]), 'targetState': array([25., 25., 15.])}
episode index:221
target thresh 11.967182567313117
model initialize at round 221
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3402603844891531
{'scaleFactor': 20, 'currentState': array([ 2.24226615e+01,  2.11825908e+01,  1.07103946e+02,  1.48432257e-01,
       -3.12006528e-02,  9.88430263e-01]), 'targetState': array([25., 25., 15.])}
episode index:222
target thresh 11.975985408906975
model initialize at round 222
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.1010238 ,  0.98317213,  0.15266648,
        0.10032706]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.34295643724660535
{'scaleFactor': 20, 'currentState': array([25.52910121, 21.45267873, 19.6612951 ,  0.3449436 ,  0.8123063 ,
        0.47028968]), 'targetState': array([25., 25., 15.])}
episode index:223
target thresh 11.984787370260685
model initialize at round 223
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.90261847,  0.98352267,  0.15272091,
       -0.09674439]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.34562841810443745
{'scaleFactor': 20, 'currentState': array([27.25166024, 20.96836965, 13.80680599,  0.75567524,  0.64548233,
       -0.11093915]), 'targetState': array([25., 25., 15.])}
episode index:224
target thresh 11.993588451462267
model initialize at round 224
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.97260555, 15.04599589,  0.99854106, -0.02763079,
        0.04639271]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3440922918017511
{'scaleFactor': 20, 'currentState': array([ 4.15307913e+01,  9.11444250e+00,  9.37846832e+01, -5.48889632e-02,
       -1.41490458e-01,  9.88416740e-01]), 'targetState': array([25., 25., 15.])}
episode index:225
target thresh 12.002388652599727
model initialize at round 225
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3425697595371416
{'scaleFactor': 20, 'currentState': array([ 23.34807972,  21.32789011, 106.93717318,   0.17284301,
        -0.40220119,   0.89908815]), 'targetState': array([25., 25., 15.])}
episode index:226
target thresh 12.011187973761073
model initialize at round 226
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.93880607,  0.98631971,  0.15315523,
       -0.06096645]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3452500251334537
{'scaleFactor': 20, 'currentState': array([25.18949836, 20.13577618, 12.93884618,  0.58676717,  0.8014281 ,
       -0.11583302]), 'targetState': array([25., 25., 15.])}
episode index:227
target thresh 12.0199864150343
model initialize at round 227
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.08672591,  0.9844762 ,  0.15286898,
        0.08624201]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.34373577063725436
{'scaleFactor': 20, 'currentState': array([ 2.06505084e+01,  1.87983407e+01,  1.04028906e+02, -8.15670647e-02,
       -8.33155950e-02,  9.93179403e-01]), 'targetState': array([25., 25., 15.])}
episode index:228
target thresh 12.028783976507395
model initialize at round 228
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08405062, 15.0299521 ,  0.99596293,  0.08455687,
        0.03013251]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.34630489542882525
{'scaleFactor': 20, 'currentState': array([28.86666664, 20.93448308, 18.59834674,  0.70849386,  0.66707464,
        0.23032124]), 'targetState': array([25., 25., 15.])}
episode index:229
target thresh 12.037580658268322
model initialize at round 229
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.49913020e+01,  1.49836170e+01,  9.99824525e-01,
       -8.78434028e-03, -1.65455483e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.34479922197043905
{'scaleFactor': 20, 'currentState': array([ 4.71663628e+01,  5.12976046e+01,  7.06301469e+01, -1.13753167e-02,
        2.47788885e-01,  9.68747269e-01]), 'targetState': array([25., 25., 15.])}
episode index:230
target thresh 12.046376460405062
model initialize at round 230
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.05555944, 15.08719068,  0.99459115,  0.05581709,
        0.08759503]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3433065846458917
{'scaleFactor': 20, 'currentState': array([ 4.92281527e+01, -1.53718835e+00,  9.29839641e+01,  7.36863303e-02,
       -1.33032656e-01,  9.88368675e-01]), 'targetState': array([25., 25., 15.])}
episode index:231
target thresh 12.055171383005558
model initialize at round 231
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.08938525,  0.98424831,  0.15283359,
        0.08886594]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3458849189767327
{'scaleFactor': 20, 'currentState': array([25.69834876, 21.31491645, 19.46823155,  0.31385717,  0.69293417,
        0.64910393]), 'targetState': array([25., 25., 15.])}
episode index:232
target thresh 12.063965426157775
model initialize at round 232
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.11738401,  0.9814443 ,  0.15239818,
        0.11636956]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.34440043434593126
{'scaleFactor': 20, 'currentState': array([ 29.97479264,  22.27624566, 103.88087011,  -0.20583572,
        -0.11622098,   0.97166061]), 'targetState': array([25., 25., 15.])}
episode index:233
target thresh 12.07275858994964
model initialize at round 233
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.8574961 , 15.07494929,  0.98703115, -0.14207656,
        0.07472453]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.34292863761795717
{'scaleFactor': 20, 'currentState': array([ 3.61253126e+01,  1.57557100e+01,  9.91087660e+01,  4.53588999e-02,
       -1.44734761e-01,  9.88430280e-01]), 'targetState': array([25., 25., 15.])}
episode index:234
target thresh 12.081550874469094
model initialize at round 234
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3414693668195829
{'scaleFactor': 20, 'currentState': array([ 2.33371023e+01,  2.31236467e+01,  1.06897006e+02, -8.48027397e-02,
       -8.10419171e-02,  9.93096523e-01]), 'targetState': array([25., 25., 15.])}
episode index:235
target thresh 12.090342279804055
model initialize at round 235
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.92229379, 15.15372671,  0.98519893, -0.07732936,
        0.1529812 ]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3400224627228897
{'scaleFactor': 20, 'currentState': array([ 1.97017142e+01,  1.80555210e+01,  1.04300993e+02, -3.04518400e-02,
       -3.25889153e-02,  9.99004829e-01]), 'targetState': array([25., 25., 15.])}
episode index:236
target thresh 12.099132806042434
model initialize at round 236
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.50107480e+01, 1.50745727e+01, 9.97116589e-01,
       1.08252379e-02, 7.51087296e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.33858776878735014
{'scaleFactor': 20, 'currentState': array([ 2.78910892e+01,  1.82257783e+01,  1.06069405e+02, -3.28378175e-03,
        1.08277731e-01,  9.94115260e-01]), 'targetState': array([25., 25., 15.])}
episode index:237
target thresh 12.107922453272145
model initialize at round 237
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.33716513110336965
{'scaleFactor': 20, 'currentState': array([ 2.47237159e+01,  2.11435043e+01,  1.07452769e+02,  1.50565769e-01,
       -1.83174871e-02,  9.88430280e-01]), 'targetState': array([25., 25., 15.])}
episode index:238
target thresh 12.116711221581077
model initialize at round 238
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3357543983372468
{'scaleFactor': 20, 'currentState': array([ 2.46976167e+01,  2.24304847e+01,  1.07179097e+02, -3.24428447e-02,
       -2.28400400e-02,  9.99212587e-01]), 'targetState': array([25., 25., 15.])}
episode index:239
target thresh 12.125499111057126
model initialize at round 239
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.49975124e+01,  1.51537267e+01,  9.88154818e-01,
       -2.48294253e-03,  1.53440189e-01]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.33435542167750826
{'scaleFactor': 20, 'currentState': array([ 2.97052324e+01,  1.62105161e+01,  1.05452178e+02, -2.68673268e-02,
        1.34911063e-01,  9.90493388e-01]), 'targetState': array([25., 25., 15.])}
episode index:240
target thresh 12.134286121788163
model initialize at round 240
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10819232, 15.15372671,  0.9824458 ,  0.10736676,
        0.1525537 ]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.33296805478258085
{'scaleFactor': 20, 'currentState': array([ 2.29679788e+01,  2.18552602e+01,  1.07144538e+02, -1.41019614e-01,
       -1.42940811e-02,  9.89903605e-01]), 'targetState': array([25., 25., 15.])}
episode index:241
target thresh 12.143072253862053
model initialize at round 241
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.95236421, 15.15372671,  0.98704277, -0.0474935 ,
        0.15326751]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.33159215372976025
{'scaleFactor': 20, 'currentState': array([ 2.76078569e+01,  1.65665751e+01,  1.05734504e+02, -1.18309597e-01,
        1.03526021e-01,  9.87565290e-01]), 'targetState': array([25., 25., 15.])}
episode index:242
target thresh 12.151857507366671
model initialize at round 242
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08938261, 15.15372671,  0.98424854,  0.08886334,
        0.15283362]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.33022757696544025
{'scaleFactor': 20, 'currentState': array([6.21473927e+00, 2.11793509e+01, 8.74305039e+01, 6.53694794e-02,
       1.36855880e-01, 9.88431737e-01]), 'targetState': array([25., 25., 15.])}
episode index:243
target thresh 12.160641882389855
model initialize at round 243
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3288741852565655
{'scaleFactor': 20, 'currentState': array([18.140299  , 38.58682165, 88.93176221,  0.17390584,  0.13067652,
        0.97605349]), 'targetState': array([25., 25., 15.])}
episode index:244
target thresh 12.169425379019483
model initialize at round 244
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15266645, 15.10901984,  0.982516  ,  0.15151235,
        0.1081957 ]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32753184164327337
{'scaleFactor': 20, 'currentState': array([ 1.38291118e+01,  3.05296339e+01,  9.75789745e+01, -8.07140303e-03,
       -5.20542907e-02,  9.98611638e-01]), 'targetState': array([25., 25., 15.])}
episode index:245
target thresh 12.178207997343337
model initialize at round 245
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.97706189, 14.91137315,  0.99575171, -0.02307137,
       -0.08914175]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32620041139269096
{'scaleFactor': 20, 'currentState': array([50.83486286,  9.85819691, 47.16906829,  0.50033617,  0.82848435,
        0.25154999]), 'targetState': array([25., 25., 15.])}
episode index:246
target thresh 12.186989737449283
model initialize at round 246
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.10160858,  0.98311468,  0.15265756,
        0.10090191]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32487976195385415
{'scaleFactor': 20, 'currentState': array([2.39379992e+01, 2.38323324e+01, 1.05981014e+02, 2.09607643e-02,
       1.50220596e-01, 9.88430280e-01]), 'targetState': array([25., 25., 15.])}
episode index:247
target thresh 12.195770599425115
model initialize at round 247
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32356976291371764
{'scaleFactor': 20, 'currentState': array([ 3.46859604e+01,  4.16182056e+01,  8.84000309e+01, -2.90348382e-02,
       -8.63531553e-02,  9.95841408e-01]), 'targetState': array([25., 25., 15.])}
episode index:248
target thresh 12.204550583358664
model initialize at round 248
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.02041173, 15.15372671,  0.98795284,  0.02036953,
        0.15340883]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3222702859542248
{'scaleFactor': 20, 'currentState': array([ 2.72142676e+01,  1.80706860e+01,  1.07500019e+02,  5.58131300e-02,
       -6.02855312e-02,  9.96619561e-01]), 'targetState': array([25., 25., 15.])}
episode index:249
target thresh 12.213329689337705
model initialize at round 249
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.07520234, 15.15372671,  0.98538575,  0.07485183,
        0.15301021]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3209812048104079
{'scaleFactor': 20, 'currentState': array([3.05830672e+01, 9.58848803e+00, 1.03334608e+02, 4.94334072e-02,
       2.42811770e-02, 9.98482230e-01]), 'targetState': array([25., 25., 15.])}
episode index:250
target thresh 12.222107917450064
model initialize at round 250
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.97348183, 15.09664677,  0.99491518, -0.02664983,
        0.09712661]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31970239522948996
{'scaleFactor': 20, 'currentState': array([ 31.0898572 ,  16.57968583, 105.69200205,   0.18052377,
         0.42526704,   0.88688168]), 'targetState': array([25., 25., 15.])}
episode index:251
target thresh 12.230885267783476
model initialize at round 251
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.06900178,  0.98582248,  0.15307803,
        0.06871061]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3221697672698531
{'scaleFactor': 20, 'currentState': array([25.47348136, 21.28792082, 19.74562951,  0.26764887,  0.69391305,
        0.66846747]), 'targetState': array([25., 25., 15.])}
episode index:252
target thresh 12.239661740425756
model initialize at round 252
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3208963689802489
{'scaleFactor': 20, 'currentState': array([ 4.01835687e+01,  2.15572294e+01,  9.03969565e+01, -8.30292815e-02,
        7.95348418e-01,  6.00439034e-01]), 'targetState': array([25., 25., 15.])}
episode index:253
target thresh 12.248437335464645
model initialize at round 253
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.05122941,  0.98686853,  0.15324045,
        0.05106736]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.32337705276339757
{'scaleFactor': 20, 'currentState': array([25.2018823 , 20.03335893, 13.4473492 ,  0.51554481,  0.72325736,
       -0.45946963]), 'targetState': array([25., 25., 15.])}
episode index:254
target thresh 12.25721205298792
model initialize at round 254
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.3257640656855293
{'scaleFactor': 20, 'currentState': array([28.47826778, 21.03019723, 10.03618261,  0.59846307,  0.73365095,
       -0.3218668 ]), 'targetState': array([25., 25., 15.])}
episode index:255
target thresh 12.265985893083297
model initialize at round 255
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12034424, 15.11873444,  0.98573087,  0.11982529,
        0.11822243]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.32816920663754284
{'scaleFactor': 20, 'currentState': array([26.07205299, 20.83401076, 19.56918727,  0.47603204,  0.74060684,
        0.47423097]), 'targetState': array([25., 25., 15.])}
episode index:256
target thresh 12.274758855838542
model initialize at round 256
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.05660606, 14.87723965,  0.99080568,  0.05665213,
       -0.12286026]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.33051899707049787
{'scaleFactor': 20, 'currentState': array([29.10002405, 20.89090328, 13.1487223 ,  0.59640122,  0.79679337,
       -0.09708712]), 'targetState': array([25., 25., 15.])}
episode index:257
target thresh 12.28353094134138
model initialize at round 257
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.05934412, 14.96275883,  0.99750522,  0.05979401,
       -0.0375235 ]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3292379156865037
{'scaleFactor': 20, 'currentState': array([ 7.95997454e+00,  2.97377750e+01,  4.62110256e+01, -2.60753280e-02,
       -6.95154348e-02,  9.97240032e-01]), 'targetState': array([25., 25., 15.])}
episode index:258
target thresh 12.292302149679513
model initialize at round 258
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.89489185, 15.12557029,  0.98659442, -0.10474658,
        0.12513833]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3279667268228492
{'scaleFactor': 20, 'currentState': array([ 25.44094886,   8.96095861, 106.48577037,  -0.21186747,
        -0.11770938,   0.97018384]), 'targetState': array([25., 25., 15.])}
episode index:259
target thresh 12.301072480940679
model initialize at round 259
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.94961888,  0.98691079,  0.15324702,
       -0.05022391]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3303263938327652
{'scaleFactor': 20, 'currentState': array([26.77235   , 20.80669922, 17.31734162,  0.5202588 ,  0.63275779,
        0.5735402 ]), 'targetState': array([25., 25., 15.])}
episode index:260
target thresh 12.309841935212551
model initialize at round 260
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.49957728e+01,  1.50952749e+01,  9.95392120e-01,
       -4.25023861e-03,  9.57938578e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32906077546558987
{'scaleFactor': 20, 'currentState': array([56.95026526,  9.76113109, 82.87915576,  0.10550596, -0.10895555,
        0.98843168]), 'targetState': array([25., 25., 15.])}
episode index:261
target thresh 12.318610512582861
model initialize at round 261
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3278048183073243
{'scaleFactor': 20, 'currentState': array([ 2.48822073e+01,  2.56282562e+01,  1.04384997e+02,  2.14566940e-02,
       -1.50150674e-01,  9.88430263e-01]), 'targetState': array([25., 25., 15.])}
episode index:262
target thresh 12.327378213139273
model initialize at round 262
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.05532549, 15.15372671,  0.98665459,  0.05513853,
        0.15320723]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32655841215406445
{'scaleFactor': 20, 'currentState': array([8.34528064e+00, 3.18209600e+01, 8.69419827e+01, 1.81527892e-02,
       1.08036806e-01, 9.93981149e-01]), 'targetState': array([25., 25., 15.])}
episode index:263
target thresh 12.336145036969459
model initialize at round 263
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13386616, 15.14847546,  0.98021478,  0.13254302,
        0.14700792]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3253214484716627
{'scaleFactor': 20, 'currentState': array([ 26.82737519,  23.96357424, 104.57619649,   0.24607657,
         0.1727243 ,   0.95373615]), 'targetState': array([25., 25., 15.])}
episode index:264
target thresh 12.344910984161094
model initialize at round 264
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.92318992,  0.98526648,  0.15299169,
       -0.07644283]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.32768246206195834
{'scaleFactor': 20, 'currentState': array([25.51199137, 20.00233922, 15.08726728,  0.61216608,  0.77227596,
        0.1698309 ]), 'targetState': array([25., 25., 15.])}
episode index:265
target thresh 12.353676054801843
model initialize at round 265
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.50143977e+01, 1.51537267e+01, 9.88055840e-01,
       1.43694572e-02, 1.53424820e-01]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32645057310683817
{'scaleFactor': 20, 'currentState': array([2.85079832e+01, 1.86795310e+01, 1.07355864e+02, 7.50617972e-02,
       3.33387738e-02, 9.96621419e-01]), 'targetState': array([25., 25., 15.])}
episode index:266
target thresh 12.362440248979356
model initialize at round 266
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10807628, 15.15372671,  0.98245794,  0.10725293,
        0.15255558]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32522791178434063
{'scaleFactor': 20, 'currentState': array([ 3.14915717e+01,  2.56523098e+01,  1.01767855e+02, -3.06249205e-01,
        8.77326828e-02,  9.47899995e-01]), 'targetState': array([25., 25., 15.])}
episode index:267
target thresh 12.371203566781263
model initialize at round 267
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3240143748000707
{'scaleFactor': 20, 'currentState': array([ 2.27886928e+01,  2.59070360e+01,  1.05539694e+02, -6.51749841e-02,
        2.49197924e-02,  9.97562642e-01]), 'targetState': array([25., 25., 15.])}
episode index:268
target thresh 12.379966008295206
model initialize at round 268
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.05434186, 15.15372671,  0.98670745,  0.05416113,
        0.15321544]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3228098603956095
{'scaleFactor': 20, 'currentState': array([18.94905764, 18.77834947, 98.66300874, -0.43546288, -0.47566936,
        0.76427138]), 'targetState': array([25., 25., 15.])}
episode index:269
target thresh 12.388727573608804
model initialize at round 269
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3216142683200702
{'scaleFactor': 20, 'currentState': array([2.65108555e+01, 2.04586713e+01, 1.07154755e+02, 1.50810972e-01,
       1.61750392e-02, 9.88430280e-01]), 'targetState': array([25., 25., 15.])}
episode index:270
target thresh 12.397488262809686
model initialize at round 270
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3204274998022839
{'scaleFactor': 20, 'currentState': array([ 2.10219532e+01,  2.09298563e+01,  1.06627819e+02, -1.14557767e-01,
       -9.94087473e-02,  9.88430280e-01]), 'targetState': array([25., 25., 15.])}
episode index:271
target thresh 12.406248075985449
model initialize at round 271
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31924945752359907
{'scaleFactor': 20, 'currentState': array([12.79542334, 15.18636528, 69.57543396, -0.09401859, -0.23408668,
        0.967659  ]), 'targetState': array([25., 25., 15.])}
episode index:272
target thresh 12.41500701322369
model initialize at round 272
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3215286908271793
{'scaleFactor': 20, 'currentState': array([26.7450901 , 21.38960895, 17.29763326,  0.63054962,  0.75737316,
        0.1696852 ]), 'targetState': array([25., 25., 15.])}
episode index:273
target thresh 12.423765074612003
model initialize at round 273
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.49864493e+01,  1.49870610e+01,  9.99820964e-01,
       -1.36851638e-02, -1.30673760e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3203552284518976
{'scaleFactor': 20, 'currentState': array([ 3.25329260e+01,  2.12873462e+01,  9.99425023e+01, -7.15656422e-02,
       -6.60339517e-02,  9.95247646e-01]), 'targetState': array([25., 25., 15.])}
episode index:274
target thresh 12.432522260237954
model initialize at round 274
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31919030034843615
{'scaleFactor': 20, 'currentState': array([ 2.19709842e+01,  2.78605634e+01,  1.05597018e+02,  9.28620832e-02,
       -1.24876470e-01,  9.87817038e-01]), 'targetState': array([25., 25., 15.])}
episode index:275
target thresh 12.44127857018914
model initialize at round 275
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3180338137529708
{'scaleFactor': 20, 'currentState': array([2.63479783e+01, 2.73794858e+01, 1.02750149e+02, 6.94559604e-02,
       1.53271118e-01, 9.85740247e-01]), 'targetState': array([25., 25., 15.])}
episode index:276
target thresh 12.450034004553101
model initialize at round 276
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.07978586, 15.15372671,  0.98503918,  0.07938606,
        0.1529564 ]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31688567724122724
{'scaleFactor': 20, 'currentState': array([ 8.45903264, 35.3799659 , 91.75319366, -0.21903674, -0.47829961,
        0.85044246]), 'targetState': array([25., 25., 15.])}
episode index:277
target thresh 12.45878856341741
model initialize at round 277
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13343448, 14.93722645,  0.98908785,  0.13331153,
       -0.06271571]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.31913241994683794
{'scaleFactor': 20, 'currentState': array([27.49568222, 20.34078571, 15.78662514,  0.66946574,  0.63637898,
        0.3831937 ]), 'targetState': array([25., 25., 15.])}
episode index:278
target thresh 12.4675422468696
model initialize at round 278
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.50048411e+01, 1.51537267e+01, 9.88146327e-01,
       4.83202296e-03, 1.53438871e-01]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31798857614774534
{'scaleFactor': 20, 'currentState': array([2.52866692e+01, 2.23980800e+01, 1.03984109e+02, 9.81216150e-02,
       1.29911014e-04, 9.95174423e-01]), 'targetState': array([25., 25., 15.])}
episode index:279
target thresh 12.476295054997221
model initialize at round 279
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.09963904,  0.98330687,  0.1526874 ,
        0.09896541]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.32021533176650696
{'scaleFactor': 20, 'currentState': array([26.16066104, 20.93811152, 19.13555592,  0.36012223,  0.67230353,
        0.64677658]), 'targetState': array([25., 25., 15.])}
episode index:280
target thresh 12.485046987887783
model initialize at round 280
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31907577542570087
{'scaleFactor': 20, 'currentState': array([ 1.64340200e+01,  3.27551554e+01,  9.60746156e+01, -2.25704558e-02,
       -8.21033501e-03,  9.99711541e-01]), 'targetState': array([25., 25., 15.])}
episode index:281
target thresh 12.493798045628813
model initialize at round 281
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.50148348e+01, 1.51537267e+01, 9.88049553e-01,
       1.48055624e-02, 1.53423844e-01]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3179443010447587
{'scaleFactor': 20, 'currentState': array([ 1.90746475e+01,  1.95529493e+01,  1.05310784e+02,  2.87524786e-03,
       -4.70817577e-01,  8.82225902e-01]), 'targetState': array([25., 25., 15.])}
episode index:282
target thresh 12.50254822830782
model initialize at round 282
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.13453872,  0.97936668,  0.15207557,
        0.13309368]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3201476079294097
{'scaleFactor': 20, 'currentState': array([25.91052018, 21.43240186, 19.29135767,  0.42178455,  0.79177037,
        0.44181158]), 'targetState': array([25., 25., 15.])}
episode index:283
target thresh 12.51129753601231
model initialize at round 283
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.13089499,  0.9798305 ,  0.15214759,
        0.12955041]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3190203276197991
{'scaleFactor': 20, 'currentState': array([2.98185802e+01, 2.24516926e+01, 1.05570952e+02, 3.59578091e-02,
       1.47352076e-01, 9.88430272e-01]), 'targetState': array([25., 25., 15.])}
episode index:284
target thresh 12.520045968829784
model initialize at round 284
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.02186956, 15.15372671,  0.98792252,  0.02182367,
        0.15340412]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3179009580492033
{'scaleFactor': 20, 'currentState': array([42.03437915, 20.47471754, 52.13985668, -0.76572452,  0.55723019,
       -0.32118604]), 'targetState': array([25., 25., 15.])}
episode index:285
target thresh 12.528793526847704
model initialize at round 285
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31678941623784246
{'scaleFactor': 20, 'currentState': array([2.57320185e+01, 1.99055842e+01, 1.04254808e+02, 1.52606914e-01,
       1.01322463e-01, 9.83079289e-01]), 'targetState': array([25., 25., 15.])}
episode index:286
target thresh 12.537540210153574
model initialize at round 286
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3156856203624493
{'scaleFactor': 20, 'currentState': array([ 3.23254989e+01,  2.18228271e+01,  1.03406317e+02,  6.07134668e-02,
       -2.94042771e-02,  9.97722037e-01]), 'targetState': array([25., 25., 15.])}
episode index:287
target thresh 12.546286018834829
model initialize at round 287
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.95355011, 15.15372671,  0.98709752, -0.04631371,
        0.15327601]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3145894897361908
{'scaleFactor': 20, 'currentState': array([ 3.25227747e+01,  1.69641754e+01,  1.04998830e+02,  1.40373006e-01,
       -5.74528886e-02,  9.88430364e-01]), 'targetState': array([25., 25., 15.])}
episode index:288
target thresh 12.555030952978951
model initialize at round 288
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.06617115,  0.98600955,  0.15310707,
        0.06590443]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.316758661568941
{'scaleFactor': 20, 'currentState': array([26.15554757, 21.30460345, 18.81291072,  0.47950333,  0.75696369,
        0.44393978]), 'targetState': array([25., 25., 15.])}
episode index:289
target thresh 12.563775012673384
model initialize at round 289
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31566639032215155
{'scaleFactor': 20, 'currentState': array([ 26.30590214,  27.77763331, 104.09217117,   0.46134199,
         0.18373112,   0.86798989]), 'targetState': array([25., 25., 15.])}
episode index:290
target thresh 12.572518198005566
model initialize at round 290
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.90047938, 15.05368089,  0.99354033, -0.09987652,
        0.05387286]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3145816260942404
{'scaleFactor': 20, 'currentState': array([ 20.83698796,   3.97066646, 104.34838875,   0.20345099,
        -0.2421211 ,   0.94867543]), 'targetState': array([25., 25., 15.])}
episode index:291
target thresh 12.581260509062918
model initialize at round 291
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.02816011,  0.98776775,  0.15338009,
        0.02809662]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3167611069976848
{'scaleFactor': 20, 'currentState': array([25.34005983, 20.12805529, 13.78326159,  0.60318913,  0.77619561,
       -0.18352995]), 'targetState': array([25., 25., 15.])}
episode index:292
target thresh 12.590001945932894
model initialize at round 292
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.9550929 ,  0.98716668,  0.15328675,
       -0.04477858]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.31889325390008516
{'scaleFactor': 20, 'currentState': array([25.64202235, 20.95412605, 19.46003241,  0.28677492,  0.60551308,
        0.74237056]), 'targetState': array([25., 25., 15.])}
episode index:293
target thresh 12.598742508702877
model initialize at round 293
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3178085829684522
{'scaleFactor': 20, 'currentState': array([ 2.32129744e+01,  2.84110028e+01,  1.04381454e+02, -8.62400340e-02,
       -2.88024190e-02,  9.95857960e-01]), 'targetState': array([25., 25., 15.])}
episode index:294
target thresh 12.607482197460286
model initialize at round 294
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13065605, 15.15372671,  0.97986049,  0.12931788,
        0.15215225]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31673126573805066
{'scaleFactor': 20, 'currentState': array([3.01065092e+01, 1.46657706e+01, 1.03429791e+02, 6.58208211e-02,
       1.68122161e-01, 9.83566245e-01]), 'targetState': array([25., 25., 15.])}
episode index:295
target thresh 12.616221012292517
model initialize at round 295
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.103903  , 15.15130759,  0.98324383,  0.10319392,
        0.15027501]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31566122767812477
{'scaleFactor': 20, 'currentState': array([ 3.27381258e+01,  2.19430599e+01,  1.04166192e+02,  8.41653121e-03,
       -1.51442210e-01,  9.88430280e-01]), 'targetState': array([25., 25., 15.])}
episode index:296
target thresh 12.624958953286946
model initialize at round 296
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3145983952617001
{'scaleFactor': 20, 'currentState': array([-1.69717294e+01,  4.52954700e+01,  7.41697754e+01, -1.39563921e-01,
       -6.35750830e-02,  9.88170087e-01]), 'targetState': array([25., 25., 15.])}
episode index:297
target thresh 12.633696020530982
model initialize at round 297
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08906177, 15.15372671,  0.98427639,  0.08854687,
        0.15283795]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31354269594874135
{'scaleFactor': 20, 'currentState': array([ 2.51078122e+01,  2.42183979e+01,  1.05103237e+02,  6.80934587e-02,
       -1.52090844e-01,  9.86018081e-01]), 'targetState': array([25., 25., 15.])}
episode index:298
target thresh 12.642432214111976
model initialize at round 298
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3124940581696486
{'scaleFactor': 20, 'currentState': array([ 2.67711091e+01,  2.18747583e+01,  1.06545139e+02, -2.69033247e-02,
        6.30475124e-02,  9.97647845e-01]), 'targetState': array([25., 25., 15.])}
episode index:299
target thresh 12.651167534117281
model initialize at round 299
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.07628887, 15.15372671,  0.98530542,  0.07592711,
        0.15299774]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3114524113090831
{'scaleFactor': 20, 'currentState': array([ 2.58423907e+01,  2.02988111e+01,  1.07461597e+02,  8.62347728e-05,
       -5.54485857e-02,  9.98461540e-01]), 'targetState': array([25., 25., 15.])}
episode index:300
target thresh 12.65990198063427
model initialize at round 300
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.093968  , 15.15372671,  0.98383984,  0.0933833 ,
        0.15277016]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.310417685690116
{'scaleFactor': 20, 'currentState': array([ 3.10626427e+01,  2.12679158e+01,  1.05921185e+02, -1.40769940e-01,
        9.62144044e-02,  9.85356084e-01]), 'targetState': array([25., 25., 15.])}
episode index:301
target thresh 12.668635553750274
model initialize at round 301
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.09419026,  0.98381953,  0.15276701,
        0.09360224]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.31250729649710574
{'scaleFactor': 20, 'currentState': array([25.83240137, 20.92958878, 19.6457077 ,  0.33855709,  0.69794728,
        0.63106949]), 'targetState': array([25., 25., 15.])}
episode index:302
target thresh 12.677368253552624
model initialize at round 302
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09359502, 15.03502906,  0.99494369,  0.0940624 ,
        0.03520398]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3145831144934882
{'scaleFactor': 20, 'currentState': array([26.45134254, 20.01864239, 19.2553027 ,  0.4209922 ,  0.54978846,
        0.72145563]), 'targetState': array([25., 25., 15.])}
episode index:303
target thresh 12.686100080128659
model initialize at round 303
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.12929376,  0.9800305 ,  0.15217865,
        0.12799174]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3166452757925261
{'scaleFactor': 20, 'currentState': array([26.12182044, 21.29265126, 19.14507248,  0.58171912,  0.7404957 ,
        0.33655458]), 'targetState': array([25., 25., 15.])}
episode index:304
target thresh 12.694831033565702
model initialize at round 304
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.50867615e+01,  1.49959829e+01,  9.96173643e-01,
        8.73025416e-02, -4.04213418e-03]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.3186630465207702
{'scaleFactor': 20, 'currentState': array([29.29472362, 20.82323744, 15.30665523,  0.64944313,  0.65406452,
        0.38784434]), 'targetState': array([25., 25., 15.])}
episode index:305
target thresh 12.703561113951057
model initialize at round 305
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09328743, 15.15372671,  0.98390176,  0.09271279,
        0.15277978]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3176216640158004
{'scaleFactor': 20, 'currentState': array([23.47314211, -4.48495129, 80.1099334 ,  0.08653308,  0.13152155,
        0.98752929]), 'targetState': array([25., 25., 15.])}
episode index:306
target thresh 12.712290321372011
model initialize at round 306
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3165870657616772
{'scaleFactor': 20, 'currentState': array([17.517355  , 39.73391005, 89.30321581,  0.10151541, -0.11269517,
        0.98843028]), 'targetState': array([25., 25., 15.])}
episode index:307
target thresh 12.721018655915872
model initialize at round 307
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31555918567803537
{'scaleFactor': 20, 'currentState': array([ 2.59929080e+01,  2.57400015e+01,  1.04228783e+02, -1.17211501e-01,
       -9.82906859e-02,  9.88230947e-01]), 'targetState': array([25., 25., 15.])}
episode index:308
target thresh 12.729746117669915
model initialize at round 308
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.07604211,  0.98532376,  0.15300058,
        0.07568293]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3145379585399188
{'scaleFactor': 20, 'currentState': array([ 2.47973147e+01,  3.14609810e+01,  1.02115836e+02, -9.03081489e-02,
        1.21860665e-01,  9.88430279e-01]), 'targetState': array([25., 25., 15.])}
episode index:309
target thresh 12.738472706721426
model initialize at round 309
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13576319, 15.11976479,  0.98368764,  0.13489755,
        0.11900115]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3135233199639835
{'scaleFactor': 20, 'currentState': array([ 3.24086862e+01,  1.79142442e+01,  1.04981542e+02, -9.57475692e-02,
        8.17031401e-02,  9.92046874e-01]), 'targetState': array([25., 25., 15.])}
episode index:310
target thresh 12.747198423157668
model initialize at round 310
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3125152063949675
{'scaleFactor': 20, 'currentState': array([ 2.19830923e+01,  2.14991753e+01,  1.06931661e+02, -4.17875061e-03,
        1.61564227e-01,  9.86853352e-01]), 'targetState': array([25., 25., 15.])}
episode index:311
target thresh 12.755923267065883
model initialize at round 311
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.13760656,  0.97896682,  0.15201348,
        0.13607298]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3115135550924195
{'scaleFactor': 20, 'currentState': array([16.57780394, 41.20921978, 97.373927  , -0.58057909,  0.15084656,
        0.80010826]), 'targetState': array([25., 25., 15.])}
episode index:312
target thresh 12.764647238533334
model initialize at round 312
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.09284176,  0.98394207,  0.15278604,
        0.09227365]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31051830411768333
{'scaleFactor': 20, 'currentState': array([3.67869563e+01, 2.82599678e+01, 9.53032930e+01, 7.18296471e-02,
       6.64487721e-02, 9.95201016e-01]), 'targetState': array([25., 25., 15.])}
episode index:313
target thresh 12.773370337647261
model initialize at round 313
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10281041, 15.15372671,  0.98299561,  0.10208301,
        0.15263907]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3095293923211302
{'scaleFactor': 20, 'currentState': array([ 1.43316671e+01,  2.32149448e+01,  9.52093419e+01,  9.92151834e-02,
       -4.64535058e-02,  9.93981096e-01]), 'targetState': array([25., 25., 15.])}
episode index:314
target thresh 12.782092564494874
model initialize at round 314
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.1105794 , 15.15372671,  0.98219327,  0.10970742,
        0.15251448]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30854675932963455
{'scaleFactor': 20, 'currentState': array([ 2.36884940e+01,  2.35361385e+01,  1.07199258e+02, -2.06141728e-02,
        4.13523396e-02,  9.98931950e-01]), 'targetState': array([25., 25., 15.])}
episode index:315
target thresh 12.790813919163424
model initialize at round 315
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.03983488, 15.15372671,  0.98737769,  0.03972937,
        0.15331952]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30757034553428764
{'scaleFactor': 20, 'currentState': array([ 32.16992162, -12.02617201,  67.91679844,   0.80775006,
        -0.10616629,  -0.57988668]), 'targetState': array([25., 25., 15.])}
episode index:316
target thresh 12.79953440174011
model initialize at round 316
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.05679072,  0.98657411,  0.15319474,
        0.05659419]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3066000920783435
{'scaleFactor': 20, 'currentState': array([ 3.19348220e+01,  2.32668425e+01,  1.03492948e+02, -4.75142616e-02,
        2.82833576e-02,  9.98470053e-01]), 'targetState': array([25., 25., 15.])}
episode index:317
target thresh 12.808254012312148
model initialize at round 317
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.91962361, 15.15372671,  0.98499307, -0.07996989,
        0.15294923]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30563594084539275
{'scaleFactor': 20, 'currentState': array([ 25.75783458,  18.87196824, 106.94432626,   0.18203186,
         0.11380719,   0.97668435]), 'targetState': array([25., 25., 15.])}
episode index:318
target thresh 12.816972750966716
model initialize at round 318
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.94808347,  0.98683378,  0.15323506,
       -0.05175049]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.30762918287848245
{'scaleFactor': 20, 'currentState': array([25.8463823 , 21.35893762, 18.5290649 ,  0.34574178,  0.71210559,
        0.61103867]), 'targetState': array([25., 25., 15.])}
episode index:319
target thresh 12.825690617791018
model initialize at round 319
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3066678416819872
{'scaleFactor': 20, 'currentState': array([ 2.24233588e+01,  1.85215158e+01,  1.02870194e+02, -1.66429157e-02,
        1.50751884e-01,  9.88431527e-01]), 'targetState': array([25., 25., 15.])}
episode index:320
target thresh 12.834407612872212
model initialize at round 320
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.12918635,  0.98004383,  0.15218072,
        0.12788716]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.3086161205175791
{'scaleFactor': 20, 'currentState': array([29.82873119, 20.04297556, 17.69783606,  0.83531118,  0.54128163,
        0.09627793]), 'targetState': array([25., 25., 15.])}
episode index:321
target thresh 12.843123736297501
model initialize at round 321
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.12416855,  0.98065489,  0.1522756 ,
        0.12299646]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3076576853606922
{'scaleFactor': 20, 'currentState': array([ 2.18453042e+01,  2.94978762e+01,  1.04012949e+02, -8.07226023e-02,
       -1.28411223e-01,  9.88430280e-01]), 'targetState': array([25., 25., 15.])}
episode index:322
target thresh 12.851838988154007
model initialize at round 322
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3067051847868201
{'scaleFactor': 20, 'currentState': array([ 2.28037856e+01,  2.54295757e+01,  1.04654161e+02, -1.38683791e-01,
       -7.17573678e-02,  9.87733611e-01]), 'targetState': array([25., 25., 15.])}
episode index:323
target thresh 12.860553368528905
model initialize at round 323
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30575856384612005
{'scaleFactor': 20, 'currentState': array([ 1.74225943e+01,  2.73001660e+01,  1.03360649e+02,  2.40729933e-01,
       -2.92107266e-02,  9.70152479e-01]), 'targetState': array([25., 25., 15.])}
episode index:324
target thresh 12.869266877509355
model initialize at round 324
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.50094960e+01,  1.49813361e+01,  9.99776365e-01,
        9.58976014e-03, -1.88482518e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.3076856616432304
{'scaleFactor': 20, 'currentState': array([2.94079866e+01, 2.01625959e+01, 1.62231140e+01, 6.13538250e-01,
       7.89557747e-01, 1.30145910e-02]), 'targetState': array([25., 25., 15.])}
episode index:325
target thresh 12.877979515182458
model initialize at round 325
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.51537267e+01, 1.50136235e+01, 9.88066516e-01,
       1.53426478e-01, 1.35969116e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.309629816513653
{'scaleFactor': 20, 'currentState': array([25.86547889, 21.39231793, 18.52896108,  0.30117903,  0.70456838,
        0.64255319]), 'targetState': array([25., 25., 15.])}
episode index:326
target thresh 12.886691281635354
model initialize at round 326
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3086829363408284
{'scaleFactor': 20, 'currentState': array([ 4.39625247e+01,  2.59176224e+01,  8.97165057e+01, -1.40809661e-01,
       -6.26743475e-02,  9.88050892e-01]), 'targetState': array([25., 25., 15.])}
episode index:327
target thresh 12.895402176955173
model initialize at round 327
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.08888194,  0.98429196,  0.15284037,
        0.08836947]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3106411897358259
{'scaleFactor': 20, 'currentState': array([25.34556044, 20.12413496, 14.39655554,  0.57043387,  0.76627293,
       -0.29568734]), 'targetState': array([25., 25., 15.])}
episode index:328
target thresh 12.904112201229001
model initialize at round 328
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.90473744,  0.98372085,  0.15275169,
       -0.09465836]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3125586333822246
{'scaleFactor': 20, 'currentState': array([27.38735871, 20.26723168, 12.24743971,  0.7917379 ,  0.60322322,
       -0.09629562]), 'targetState': array([25., 25., 15.])}
episode index:329
target thresh 12.912821354543947
model initialize at round 329
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08711852, 15.06793883,  0.99383099,  0.08745564,
        0.06820173]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3144644561580391
{'scaleFactor': 20, 'currentState': array([27.00861512, 20.75589358, 17.19571634,  0.64216496,  0.76364433,
        0.06686936]), 'targetState': array([25., 25., 15.])}
episode index:330
target thresh 12.921529636987117
model initialize at round 330
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.94215109, 15.05782416,  0.99660439, -0.05823482,
        0.05820991]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3135144124838456
{'scaleFactor': 20, 'currentState': array([33.31384734, 22.49288471, 96.60032738, -0.2132141 , -0.36025013,
        0.90816275]), 'targetState': array([25., 25., 15.])}
episode index:331
target thresh 12.930237048645576
model initialize at round 331
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.51086516e+01, 1.50038274e+01, 9.94024091e-01,
       1.09093256e-01, 3.84294297e-03]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.31540587554684907
{'scaleFactor': 20, 'currentState': array([27.79818255, 20.04939113, 15.67942358,  0.76085748,  0.6462765 ,
        0.05850279]), 'targetState': array([25., 25., 15.])}
episode index:332
target thresh 12.93894358960641
model initialize at round 332
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13420628, 15.02696958,  0.99057535,  0.13428427,
        0.02698525]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.31728597847133605
{'scaleFactor': 20, 'currentState': array([26.59536763, 20.74111532, 18.07820465,  0.41285473,  0.69672745,
        0.58661898]), 'targetState': array([25., 25., 15.])}
episode index:333
target thresh 12.947649259956673
model initialize at round 333
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3163360204519608
{'scaleFactor': 20, 'currentState': array([25.61348183, 30.78465295, 86.23910818,  0.17489701,  0.08874347,
        0.98057923]), 'targetState': array([25., 25., 15.])}
episode index:334
target thresh 12.956354059783436
model initialize at round 334
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.12464223,  0.98059819,  0.1522668 ,
        0.12345853]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.315391733823746
{'scaleFactor': 20, 'currentState': array([2.60521489e+01, 2.18848572e+01, 1.06800626e+02, 2.20371889e-01,
       2.63789716e-02, 9.75059168e-01]), 'targetState': array([25., 25., 15.])}
episode index:335
target thresh 12.965057989173745
model initialize at round 335
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.09323363,  0.98390664,  0.15278053,
        0.09265979]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.31728339547873485
{'scaleFactor': 20, 'currentState': array([25.08547724, 20.04509798, 17.56004003,  0.52047048,  0.74002776,
        0.42599224]), 'targetState': array([25., 25., 15.])}
episode index:336
target thresh 12.973761048214616
model initialize at round 336
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.08375884,  0.98472252,  0.15290722,
        0.08331234]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3163419017236051
{'scaleFactor': 20, 'currentState': array([ 24.90081398,  25.30622441, 104.95506877,   0.2473632 ,
         0.15443791,   0.95653561]), 'targetState': array([25., 25., 15.])}
episode index:337
target thresh 12.982463236993102
model initialize at round 337
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12348983, 14.93419356,  0.99015833,  0.12350958,
       -0.06581697]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.31816356872414764
{'scaleFactor': 20, 'currentState': array([29.41567701, 20.61118201, 15.94963547,  0.64231891,  0.76019091,
        0.09765346]), 'targetState': array([25., 25., 15.])}
episode index:338
target thresh 12.991164555596214
model initialize at round 338
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.04237002,  0.98727537,  0.15330363,
        0.04225342]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3200303135063773
{'scaleFactor': 20, 'currentState': array([25.24733503, 20.00734066, 16.97292181,  0.55768065,  0.73447361,
        0.38670507]), 'targetState': array([25., 25., 15.])}
episode index:339
target thresh 12.999865004110989
model initialize at round 339
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.14823096,  0.97751651,  0.15178828,
        0.14636183]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.32188607743694675
{'scaleFactor': 20, 'currentState': array([24.92957861, 20.00849319, 18.14405935,  0.50007263,  0.73221611,
        0.46237098]), 'targetState': array([25., 25., 15.])}
episode index:340
target thresh 13.008564582624405
model initialize at round 340
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.09413319,  0.98382475,  0.15276782,
        0.09354602]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3209421299957827
{'scaleFactor': 20, 'currentState': array([ 2.32826752e+01,  2.30108988e+01,  1.06319394e+02, -9.25382566e-02,
        1.20391251e-01,  9.88404076e-01]), 'targetState': array([25., 25., 15.])}
episode index:341
target thresh 13.017263291223458
model initialize at round 341
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32000370271509326
{'scaleFactor': 20, 'currentState': array([ 30.18262273,  14.57926629, 101.34049992,   0.95500872,
        -0.23612506,   0.17945278]), 'targetState': array([25., 25., 15.])}
episode index:342
target thresh 13.025961129995157
model initialize at round 342
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.32184331305674024
{'scaleFactor': 20, 'currentState': array([24.95041088, 20.07667391, 11.9621636 ,  0.56321154,  0.80064886,
       -0.20433834]), 'targetState': array([25., 25., 15.])}
episode index:343
target thresh 13.034658099026453
model initialize at round 343
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.10062772,  0.98321085,  0.15267249,
        0.09993764]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3209077220304125
{'scaleFactor': 20, 'currentState': array([ 1.68883331e+01,  2.77687837e+01,  1.04103251e+02, -1.42001184e-01,
       -5.33033272e-02,  9.88430280e-01]), 'targetState': array([25., 25., 15.])}
episode index:344
target thresh 13.043354198404334
model initialize at round 344
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31997755472017947
{'scaleFactor': 20, 'currentState': array([ 2.62817833e+01,  2.10040603e+01,  1.05900571e+02,  1.28002624e-01,
       -8.27885723e-02,  9.88312390e-01]), 'targetState': array([25., 25., 15.])}
episode index:345
target thresh 13.052049428215762
model initialize at round 345
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12977899, 15.15372671,  0.97997014,  0.12846418,
        0.15216928]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3190527640996009
{'scaleFactor': 20, 'currentState': array([ 2.51085053e+01,  2.24247462e+01,  1.06944579e+02, -4.22440240e-02,
       -6.45825938e-02,  9.97017819e-01]), 'targetState': array([25., 25., 15.])}
episode index:346
target thresh 13.060743788547668
model initialize at round 346
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.51279172e+01,  1.49943025e+01,  9.91739416e-01,
        1.28141930e-01, -5.70755640e-03]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.320846502962141
{'scaleFactor': 20, 'currentState': array([27.05511873, 20.01140864, 18.12593253,  0.66470632,  0.42608946,
        0.61368826]), 'targetState': array([25., 25., 15.])}
episode index:347
target thresh 13.069437279487028
model initialize at round 347
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.92253649, 15.15372671,  0.9852173 , -0.07708928,
        0.15298405]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3199245302524797
{'scaleFactor': 20, 'currentState': array([ 3.58008760e+01,  2.47662438e+01,  1.00909419e+02, -9.87075722e-02,
        1.15162478e-01,  9.88430280e-01]), 'targetState': array([25., 25., 15.])}
episode index:348
target thresh 13.07812990112075
model initialize at round 348
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3190078410540485
{'scaleFactor': 20, 'currentState': array([ 2.08946578e+01,  2.36478564e+01,  1.06498874e+02,  1.21229886e-01,
       -9.26484105e-02,  9.88291246e-01]), 'targetState': array([25., 25., 15.])}
episode index:349
target thresh 13.086821653535774
model initialize at round 349
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3180963900796084
{'scaleFactor': 20, 'currentState': array([3.24066775e+01, 1.79856377e+01, 1.06150811e+02, 7.08905116e-02,
       5.86319536e-02, 9.95759423e-01]), 'targetState': array([25., 25., 15.])}
episode index:350
target thresh 13.09551253681902
model initialize at round 350
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.93943491, 15.15372671,  0.98635719, -0.06034223,
        0.15316105]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3171901325580141
{'scaleFactor': 20, 'currentState': array([ 24.36826429,   9.12029165, 103.48041443,  -0.10492368,
        -0.3669074 ,   0.92432136]), 'targetState': array([25., 25., 15.])}
episode index:351
target thresh 13.104202551057377
model initialize at round 351
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15065871,  0.97717093,  0.15173462,
        0.14870637]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.31896368374222717
{'scaleFactor': 20, 'currentState': array([25.40762077, 21.46361092, 19.99354638,  0.30801127,  0.7541256 ,
        0.58002038]), 'targetState': array([25., 25., 15.])}
episode index:352
target thresh 13.112891696337769
model initialize at round 352
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3180601039015976
{'scaleFactor': 20, 'currentState': array([ 4.49625961e+01,  2.42400266e+01,  6.43371716e+01, -5.46940138e-02,
        4.20187520e-02,  9.97618659e-01]), 'targetState': array([25., 25., 15.])}
episode index:353
target thresh 13.121579972747078
model initialize at round 353
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08064612, 15.15372671,  0.9849719 ,  0.08023652,
        0.15294595]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3171616290318191
{'scaleFactor': 20, 'currentState': array([ 28.46000022,  20.44050956, 101.7462289 ,  -0.43018126,
        -0.22545981,   0.87413498]), 'targetState': array([25., 25., 15.])}
episode index:354
target thresh 13.130267380372185
model initialize at round 354
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.02686374,  0.98780282,  0.15338553,
        0.02680412]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3162682159922928
{'scaleFactor': 20, 'currentState': array([ 2.42180946e+01,  2.42123115e+01,  1.05694481e+02,  9.59482385e-02,
       -2.62496765e-02,  9.95040145e-01]), 'targetState': array([25., 25., 15.])}
episode index:355
target thresh 13.138953919299956
model initialize at round 355
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.50096073e+01, 1.51537267e+01, 9.88112432e-01,
       9.58900602e-03, 1.53433608e-01]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31537982212714594
{'scaleFactor': 20, 'currentState': array([46.82957468,  8.52661146, 93.10950466,  0.88527374,  0.12745628,
        0.44726424]), 'targetState': array([25., 25., 15.])}
episode index:356
target thresh 13.147639589617267
model initialize at round 356
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.06457784, 14.96633371,  0.99730523,  0.06505436,
       -0.03391472]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.31710723256350404
{'scaleFactor': 20, 'currentState': array([29.51672819, 20.30088645, 15.91383431,  0.60967838,  0.69325324,
        0.38430745]), 'targetState': array([25., 25., 15.])}
episode index:357
target thresh 13.156324391410978
model initialize at round 357
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.14710734,  0.97767468,  0.15181284,
        0.14527588]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31622145817086855
{'scaleFactor': 20, 'currentState': array([2.43884690e+01, 2.28431951e+01, 1.06803130e+02, 1.50700299e-01,
       1.71755918e-02, 9.88430280e-01]), 'targetState': array([25., 25., 15.])}
episode index:358
target thresh 13.165008324767935
model initialize at round 358
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.12759059,  0.98024066,  0.15221128,
        0.12633281]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31534061845451516
{'scaleFactor': 20, 'currentState': array([23.99927185,  5.33942696, 93.37776484,  0.60779242, -0.77184731,
        0.18665502]), 'targetState': array([25., 25., 15.])}
episode index:359
target thresh 13.173691389774977
model initialize at round 359
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.51537267e+01, 1.50149610e+01, 9.88047703e-01,
       1.53423556e-01, 1.49314854e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3170798949293665
{'scaleFactor': 20, 'currentState': array([26.67645942, 21.13228643, 12.89415139,  0.49257836,  0.76124804,
       -0.42174397]), 'targetState': array([25., 25., 15.])}
episode index:360
target thresh 13.182373586518924
model initialize at round 360
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.11097366,  0.98215105,  0.15250793,
        0.11009383]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3162015572702824
{'scaleFactor': 20, 'currentState': array([2.74628563e+01, 2.54358801e+01, 1.04969830e+02, 1.50555781e-01,
       1.83994005e-02, 9.88430280e-01]), 'targetState': array([25., 25., 15.])}
episode index:361
target thresh 13.191054915086609
model initialize at round 361
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31532807230544735
{'scaleFactor': 20, 'currentState': array([ 2.54933170e+01,  2.18925750e+01,  1.06371146e+02,  3.90295397e-02,
       -1.21231799e-01,  9.91856616e-01]), 'targetState': array([25., 25., 15.])}
episode index:362
target thresh 13.199735375564847
model initialize at round 362
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.05713882, 15.15372671,  0.98655468,  0.05693997,
        0.15319172]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31445939992995026
{'scaleFactor': 20, 'currentState': array([ 15.4040738 ,   7.76315577, 100.31946373,  -0.28981919,
        -0.61744864,   0.73127424]), 'targetState': array([25., 25., 15.])}
episode index:363
target thresh 13.208414968040428
model initialize at round 363
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09332378, 14.84627329,  0.98389847,  0.09274861,
       -0.15277926]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3135955004795932
{'scaleFactor': 20, 'currentState': array([ 1.11778664e+01,  3.46847314e+01,  6.36693026e+01, -1.51528296e-01,
       -6.69203205e-03,  9.88430267e-01]), 'targetState': array([25., 25., 15.])}
episode index:364
target thresh 13.217093692600168
model initialize at round 364
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31273633472485457
{'scaleFactor': 20, 'currentState': array([ 2.09618769e+01,  2.66192201e+01,  1.04545655e+02, -5.64618023e-02,
        1.40775160e-01,  9.88430280e-01]), 'targetState': array([25., 25., 15.])}
episode index:365
target thresh 13.225771549330833
model initialize at round 365
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3118818638649506
{'scaleFactor': 20, 'currentState': array([ 2.48328607e+01,  1.98321613e+01,  1.06035761e+02, -1.16857425e-02,
       -4.14077447e-02,  9.99073992e-01]), 'targetState': array([25., 25., 15.])}
episode index:366
target thresh 13.234448538319231
model initialize at round 366
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11550894, 15.15372671,  0.98165498,  0.11453528,
        0.1524309 ]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3110320495219943
{'scaleFactor': 20, 'currentState': array([ 2.59736029e+01,  2.04335232e+01,  1.06916406e+02, -1.60525914e-01,
        1.05598600e-01,  9.81366581e-01]), 'targetState': array([25., 25., 15.])}
episode index:367
target thresh 13.243124659652105
model initialize at round 367
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.05568079, 15.15372671,  0.98663527,  0.05549154,
        0.15320423]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3101868537352498
{'scaleFactor': 20, 'currentState': array([ 2.73295337e+01,  1.90783128e+01,  1.07548533e+02, -9.34476850e-02,
       -1.19470127e-01,  9.88430280e-01]), 'targetState': array([25., 25., 15.])}
episode index:368
target thresh 13.251799913416217
model initialize at round 368
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30934623895547947
{'scaleFactor': 20, 'currentState': array([2.12662310e+01, 2.02381813e+01, 1.06042397e+02, 8.17151030e-03,
       1.42849346e-01, 9.89710711e-01]), 'targetState': array([25., 25., 15.])}
episode index:369
target thresh 13.260474299698332
model initialize at round 369
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.1294786 ,  0.98000753,  0.15217508,
        0.12817172]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3085101680393836
{'scaleFactor': 20, 'currentState': array([ 3.60209984e+01,  1.41907266e+01,  1.04460401e+02, -6.86318237e-02,
        9.78440890e-02,  9.92832416e-01]), 'targetState': array([25., 25., 15.])}
episode index:370
target thresh 13.26914781858518
model initialize at round 370
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11479341, 15.02181125,  0.9931067 ,  0.11515364,
        0.0218797 ]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3076786042441292
{'scaleFactor': 20, 'currentState': array([43.5290522 , 27.01893936, 90.78697163,  0.4584626 , -0.21823918,
        0.86150085]), 'targetState': array([25., 25., 15.])}
episode index:371
target thresh 13.277820470163526
model initialize at round 371
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.09226916,  0.98399359,  0.15279404,
        0.09170936]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3093823718386369
{'scaleFactor': 20, 'currentState': array([25.63641984, 21.26979461, 19.25425577,  0.2775293 ,  0.6995699 ,
        0.6584675 ]), 'targetState': array([25., 25., 15.])}
episode index:372
target thresh 13.286492254520056
model initialize at round 372
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.05872122,  0.98646488,  0.15317778,
        0.05851153]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.31107700395006416
{'scaleFactor': 20, 'currentState': array([25.51788569, 21.27422321, 19.61272838,  0.26476877,  0.68619852,
        0.67751686]), 'targetState': array([25., 25., 15.])}
episode index:373
target thresh 13.29516317174152
model initialize at round 373
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3102452472550105
{'scaleFactor': 20, 'currentState': array([ 3.78642067e+00,  4.18757587e+01,  9.58746261e+01,  3.76598536e-02,
       -3.18874174e-01,  9.47048571e-01]), 'targetState': array([25., 25., 15.])}
episode index:374
target thresh 13.30383322191462
model initialize at round 374
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.50678780e+01,  1.49837727e+01,  9.97524400e-01,
        6.83939217e-02, -1.63506067e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3094179265956638
{'scaleFactor': 20, 'currentState': array([ 3.29483934e+01,  1.69459804e+01,  1.03147630e+02,  3.92935700e-02,
       -9.64117749e-02,  9.94565626e-01]), 'targetState': array([25., 25., 15.])}
episode index:375
target thresh 13.312502405126036
model initialize at round 375
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.84627329, 15.08533305,  0.98459288, -0.15288709,
        0.08486698]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30859500657812217
{'scaleFactor': 20, 'currentState': array([ 32.31169803,   8.93896184, 101.13685008,   0.12240678,
        -0.10756111,   0.98663427]), 'targetState': array([25., 25., 15.])}
episode index:376
target thresh 13.321170721462494
model initialize at round 376
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10576038, 15.06488492,  0.99223738,  0.10599939,
        0.06503156]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3077764521840157
{'scaleFactor': 20, 'currentState': array([3.66616036e+01, 2.18638825e+01, 1.01701303e+02, 8.12813256e-02,
       1.66592005e-01, 9.82670062e-01]), 'targetState': array([25., 25., 15.])}
episode index:377
target thresh 13.329838171010644
model initialize at round 377
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13959689, 15.0264792 ,  0.98985725,  0.13957676,
        0.02647538]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3094529169914681
{'scaleFactor': 20, 'currentState': array([27.50775863, 20.21437908, 16.73153717,  0.79148644,  0.50686454,
        0.3415224 ]), 'targetState': array([25., 25., 15.])}
episode index:378
target thresh 13.338504753857173
model initialize at round 378
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08502844, 14.9465084 ,  0.99489138,  0.08544855,
       -0.05375589]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30863641852974916
{'scaleFactor': 20, 'currentState': array([ 4.48308034e+01,  6.04672563e-01,  8.20669411e+01,  2.29504002e-02,
       -5.69058512e-02,  9.98115726e-01]), 'targetState': array([25., 25., 15.])}
episode index:379
target thresh 13.347170470088754
model initialize at round 379
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.90401627, 15.15372671,  0.98365388, -0.09536846,
        0.15274129]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3078242174283551
{'scaleFactor': 20, 'currentState': array([2.81310839e+01, 1.58071757e+01, 1.07422376e+02, 1.38917466e-01,
       6.28007379e-02, 9.88310682e-01]), 'targetState': array([25., 25., 15.])}
episode index:380
target thresh 13.355835319792043
model initialize at round 380
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30701627984980295
{'scaleFactor': 20, 'currentState': array([2.91855734e+01, 2.54735870e+01, 1.04327863e+02, 2.25448696e-01,
       1.99450689e-02, 9.74050861e-01]), 'targetState': array([25., 25., 15.])}
episode index:381
target thresh 13.364499303053679
model initialize at round 381
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.51393634e+01, 1.50120299e+01, 9.90164941e-01,
       1.39386593e-01, 1.20319058e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.30867718003187417
{'scaleFactor': 20, 'currentState': array([26.92333884, 21.00882793, 17.19536244,  0.62153491,  0.63640517,
        0.45681815]), 'targetState': array([25., 25., 15.])}
episode index:382
target thresh 13.373162419960305
model initialize at round 382
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.04466496, 15.15372671,  0.98717732,  0.04453762,
        0.1532884 ]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3078712343921043
{'scaleFactor': 20, 'currentState': array([ 2.67002055e+01,  2.53195345e+01,  1.02244568e+02, -2.76846943e-01,
       -1.54501011e-03,  9.60912786e-01]), 'targetState': array([25., 25., 15.])}
episode index:383
target thresh 13.381824670598563
model initialize at round 383
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11856886, 15.14170463,  0.98302619,  0.11773363,
        0.14070643]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30706948638587483
{'scaleFactor': 20, 'currentState': array([3.26288093e+01, 3.05696483e+01, 8.59385411e+01, 3.66344046e-01,
       4.21615720e-02, 9.29523771e-01]), 'targetState': array([25., 25., 15.])}
episode index:384
target thresh 13.390486055055062
model initialize at round 384
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.04368024, 15.14692282,  0.98822561,  0.04360195,
        0.14665948]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30627190330435305
{'scaleFactor': 20, 'currentState': array([3.01771654e+01, 1.62537562e+01, 1.05539770e+02, 1.42670002e-01,
       5.59091377e-02, 9.88189981e-01]), 'targetState': array([25., 25., 15.])}
episode index:385
target thresh 13.39914657341642
model initialize at round 385
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12749388, 15.13067316,  0.98341829,  0.12664627,
        0.12980442]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30547845277765784
{'scaleFactor': 20, 'currentState': array([ 2.82015028e+01,  2.24858879e+01,  1.05685365e+02, -2.67016400e-02,
       -1.49307078e-01,  9.88430280e-01]), 'targetState': array([25., 25., 15.])}
episode index:386
target thresh 13.407806225769237
model initialize at round 386
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.12811134,  0.98017668,  0.15220135,
        0.12684015]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.30714644140071296
{'scaleFactor': 20, 'currentState': array([25.15341493, 20.08803761, 17.3206363 ,  0.5583554 ,  0.7760091 ,
        0.29334132]), 'targetState': array([25., 25., 15.])}
episode index:387
target thresh 13.41646501220013
model initialize at round 387
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.51537267e+01, 1.50108582e+01, 9.88099833e-01,
       1.53431651e-01, 1.08373826e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3088058321442678
{'scaleFactor': 20, 'currentState': array([2.53003321e+01, 2.01605624e+01, 1.63416711e+01, 5.97629078e-01,
       8.01675217e-01, 1.25032758e-02]), 'targetState': array([25., 25., 15.])}
episode index:388
target thresh 13.425122932795663
model initialize at round 388
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.9470241 ,  0.9867793 ,  0.1532266 ,
       -0.05280356]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.31043224427089183
{'scaleFactor': 20, 'currentState': array([26.61602389, 20.70473253, 11.75836936,  0.43395908,  0.69927728,
       -0.5680588 ]), 'targetState': array([25., 25., 15.])}
episode index:389
target thresh 13.433779987642435
model initialize at round 389
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.92514951,  0.98541152,  0.15301421,
       -0.07450357]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.31207470018276134
{'scaleFactor': 20, 'currentState': array([25.35118781, 20.17891839, 14.21983766,  0.59732071,  0.79574891,
        0.09995823]), 'targetState': array([25., 25., 15.])}
episode index:390
target thresh 13.442436176826988
model initialize at round 390
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3112765551695062
{'scaleFactor': 20, 'currentState': array([ 2.68710326e+01,  2.28616702e+01,  1.04397761e+02, -2.25282399e-02,
       -1.56046431e-01,  9.87492780e-01]), 'targetState': array([25., 25., 15.])}
episode index:391
target thresh 13.451091500435908
model initialize at round 391
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.84627329, 15.08774035,  0.98439006, -0.1528556 ,
        0.08724316]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.310482482324686
{'scaleFactor': 20, 'currentState': array([38.20446226, 12.92520867, 96.14669046,  0.49076659,  0.21165644,
        0.84519211]), 'targetState': array([25., 25., 15.])}
episode index:392
target thresh 13.459745958555757
model initialize at round 392
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.06806096,  0.98588552,  0.15308781,
        0.06777809]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.31208807435287
{'scaleFactor': 20, 'currentState': array([25.81327488, 21.45735778, 18.89108106,  0.32263829,  0.74029143,
        0.58980771]), 'targetState': array([25., 25., 15.])}
episode index:393
target thresh 13.468399551273059
model initialize at round 393
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.12606758,  0.98042634,  0.15224011,
        0.12484846]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3112959726413145
{'scaleFactor': 20, 'currentState': array([ 2.40272298e+01,  2.35051661e+01,  1.06570378e+02, -1.58672952e-01,
       -5.34420002e-02,  9.85883790e-01]), 'targetState': array([25., 25., 15.])}
episode index:394
target thresh 13.47705227867434
model initialize at round 394
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.96588549,  0.98758549,  0.15335178,
       -0.03403131]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.31289137562045294
{'scaleFactor': 20, 'currentState': array([26.86836064, 21.03469232, 12.4366088 ,  0.63765379,  0.68350756,
       -0.3552676 ]), 'targetState': array([25., 25., 15.])}
episode index:395
target thresh 13.485704140846156
model initialize at round 395
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.05574497, 15.0376545 ,  0.99769934,  0.05617851,
        0.03794734]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.31445494625754017
{'scaleFactor': 20, 'currentState': array([28.93488003, 20.19945237, 18.32125514,  0.51485633,  0.73683907,
        0.43816794]), 'targetState': array([25., 25., 15.])}
episode index:396
target thresh 13.494355137875013
model initialize at round 396
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.09981697,  0.98328966,  0.15268473,
        0.0991404 ]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3136628683072693
{'scaleFactor': 20, 'currentState': array([ 4.90014652, 19.80676315, 64.48307012,  0.07442313,  0.13215346,
        0.98843141]), 'targetState': array([25., 25., 15.])}
episode index:397
target thresh 13.503005269847424
model initialize at round 397
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3128747706482058
{'scaleFactor': 20, 'currentState': array([2.44298284e+01, 2.17284162e+01, 1.07154867e+02, 9.67837274e-02,
       1.24262320e-01, 9.87517993e-01]), 'targetState': array([25., 25., 15.])}
episode index:398
target thresh 13.511654536849882
model initialize at round 398
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.07130265, 15.15372671,  0.98566474,  0.07099041,
        0.15305353]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31209062335334814
{'scaleFactor': 20, 'currentState': array([ 32.55349308,  17.34467357, 106.01497871,   0.15393089,
         0.3757798 ,   0.91383523]), 'targetState': array([25., 25., 15.])}
episode index:399
target thresh 13.520302938968875
model initialize at round 399
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.05929797, 15.12556519,  0.99030562,  0.05931628,
        0.12560396]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.31366409716846727
{'scaleFactor': 20, 'currentState': array([27.22082464, 20.22391314, 17.16145162,  0.59923172,  0.7976646 ,
        0.06820941]), 'targetState': array([25., 25., 15.])}
episode index:400
target thresh 13.528950476290913
model initialize at round 400
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.02016715,  0.98795772,  0.15340958,
        0.02012555]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3152297232338851
{'scaleFactor': 20, 'currentState': array([27.45148153, 20.37096694, 16.88105588,  0.70456379,  0.66788705,
        0.23982652]), 'targetState': array([25., 25., 15.])}
episode index:401
target thresh 13.537597148902448
model initialize at round 401
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.02928832,  0.98773589,  0.15337514,
        0.02922134]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3168112165838008
{'scaleFactor': 20, 'currentState': array([25.36581113, 20.15460261, 14.16014781,  0.6024575 ,  0.79314002,
       -0.0892965 ]), 'targetState': array([25., 25., 15.])}
episode index:402
target thresh 13.546242956889953
model initialize at round 402
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.97920423,  0.98794506,  0.15340762,
       -0.0207526 ]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3183848613314837
{'scaleFactor': 20, 'currentState': array([25.31720655, 20.11489245, 16.07749428,  0.56995361,  0.77220944,
        0.28079435]), 'targetState': array([25., 25., 15.])}
episode index:403
target thresh 13.554887900339885
model initialize at round 403
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.05670376,  0.98657894,  0.15319549,
        0.05650782]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.31995071575863354
{'scaleFactor': 20, 'currentState': array([25.33140249, 20.14009466, 16.22887489,  0.58213079,  0.78387719,
        0.21600995]), 'targetState': array([25., 25., 15.])}
episode index:404
target thresh 13.563531979338695
model initialize at round 404
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.13207665,  0.9796814 ,  0.15212444,
        0.13070004]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3191607139913283
{'scaleFactor': 20, 'currentState': array([ 2.56836822e+01,  1.61447702e+01,  1.04843326e+02,  1.38418102e-01,
       -1.53697880e-02,  9.90254613e-01]), 'targetState': array([25., 25., 15.])}
episode index:405
target thresh 13.572175193972825
model initialize at round 405
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15163206, 15.06914398,  0.98612564,  0.15103865,
        0.06887339]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3183746038583447
{'scaleFactor': 20, 'currentState': array([ 26.00742239,  24.76153716, 105.00838504,   0.11087769,
         0.17551888,   0.97821228]), 'targetState': array([25., 25., 15.])}
episode index:406
target thresh 13.580817544328717
model initialize at round 406
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.8637879 , 15.08040094,  0.98747625, -0.13586487,
        0.08019598]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31759235667441754
{'scaleFactor': 20, 'currentState': array([ 4.62838657e+01,  1.86076525e+01,  9.18054088e+01, -3.96524435e-02,
        8.37944605e-01,  5.44312890e-01]), 'targetState': array([25., 25., 15.])}
episode index:407
target thresh 13.589459030492767
model initialize at round 407
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.02581986, 15.07044288,  0.99714073,  0.0260061 ,
        0.07095097]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31681394403550966
{'scaleFactor': 20, 'currentState': array([49.42882686, 54.71420411, 47.04861281,  0.17541083,  0.12883577,
        0.97602889]), 'targetState': array([25., 25., 15.])}
episode index:408
target thresh 13.59809965255142
model initialize at round 408
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.02933318, 15.06000666,  0.99773183,  0.02956227,
        0.06047531]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.31831822619656464
{'scaleFactor': 20, 'currentState': array([28.66532022, 21.53852169, 15.83267817,  0.5051479 ,  0.85503322,
       -0.11723392]), 'targetState': array([25., 25., 15.])}
episode index:409
target thresh 13.60673941059105
model initialize at round 409
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15237738, 15.11635786,  0.98175933,  0.15110901,
        0.11538931]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.31983813332633154
{'scaleFactor': 20, 'currentState': array([26.60496792, 20.92116243, 18.41899994,  0.58821286,  0.57553691,
        0.56812226]), 'targetState': array([25., 25., 15.])}
episode index:410
target thresh 13.615378304698101
model initialize at round 410
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.03926956, 15.14636033,  0.98848707,  0.03920955,
        0.14613666]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3190599383547346
{'scaleFactor': 20, 'currentState': array([ 2.95233401e+01,  1.71080197e+01,  1.06744120e+02, -1.53636237e-02,
        1.12476796e-02,  9.99818708e-01]), 'targetState': array([25., 25., 15.])}
episode index:411
target thresh 13.62401633495891
model initialize at round 411
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.89628193, 15.15372671,  0.98290479, -0.10297473,
        0.15262497]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3182855210286309
{'scaleFactor': 20, 'currentState': array([ 3.46264006e+01,  2.14113647e+01,  9.92469083e+01,  1.89010120e-02,
       -2.20931526e-01,  9.75106154e-01]), 'targetState': array([25., 25., 15.])}
episode index:412
target thresh 13.632653501459902
model initialize at round 412
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.0428703 ,  0.98725443,  0.15330038,
        0.0427514 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.319794466860041
{'scaleFactor': 20, 'currentState': array([26.56387149, 21.10986785, 12.29803729,  0.47251872,  0.75338198,
       -0.45732008]), 'targetState': array([25., 25., 15.])}
episode index:413
target thresh 13.641289804287403
model initialize at round 413
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.32129612309806266
{'scaleFactor': 20, 'currentState': array([25.78522347, 21.50318777, 10.64141147,  0.42950979,  0.84049894,
       -0.33027696]), 'targetState': array([25., 25., 15.])}
episode index:414
target thresh 13.649925243527827
model initialize at round 414
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.06873812,  0.98584023,  0.15308078,
        0.06844929]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.32281345786144083
{'scaleFactor': 20, 'currentState': array([25.23081747, 20.07440919, 16.83030897,  0.55041122,  0.75985738,
        0.34592522]), 'targetState': array([25., 25., 15.])}
episode index:415
target thresh 13.658559819267492
model initialize at round 415
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.02655438,  0.98781095,  0.15338679,
        0.02649567]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3243006374084109
{'scaleFactor': 20, 'currentState': array([25.36017861, 20.98598595, 19.94678256,  0.28863186,  0.57283069,
        0.76717446]), 'targetState': array([25., 25., 15.])}
episode index:416
target thresh 13.667193531592748
model initialize at round 416
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.06764026, 15.15372671,  0.98591343,  0.06736105,
        0.15309215]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.323522938038127
{'scaleFactor': 20, 'currentState': array([2.50190759e+01, 2.05529676e+01, 1.06832659e+02, 9.67087617e-02,
       1.85321885e-01, 9.77907569e-01]), 'targetState': array([25., 25., 15.])}
episode index:417
target thresh 13.67582638058995
model initialize at round 417
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.97262619, 15.15372671,  0.98778922, -0.02731269,
        0.15338342]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3227489597174616
{'scaleFactor': 20, 'currentState': array([ 2.74539717e+01,  1.39078231e+01,  1.06951902e+02, -8.68037595e-02,
        3.59431326e-02,  9.95576817e-01]), 'targetState': array([25., 25., 15.])}
episode index:418
target thresh 13.684458366345408
model initialize at round 418
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08544548, 15.15372671,  0.98458353,  0.08497799,
        0.15288564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32197867580405476
{'scaleFactor': 20, 'currentState': array([ 2.31378418e+01,  2.16165136e+01,  1.07373825e+02, -1.49099604e-02,
       -8.44299236e-02,  9.96317861e-01]), 'targetState': array([25., 25., 15.])}
episode index:419
target thresh 13.693089488945454
model initialize at round 419
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.49911487e+01,  1.51537267e+01,  9.88119301e-01,
       -8.83448413e-03,  1.53434674e-01]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3212120599092832
{'scaleFactor': 20, 'currentState': array([ 2.82142907e+01,  1.55389420e+01,  1.07648257e+02,  5.54653974e-02,
       -5.63775854e-02,  9.96867673e-01]), 'targetState': array([25., 25., 15.])}
episode index:420
target thresh 13.701719748476393
model initialize at round 420
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.07946789, 15.15372671,  0.98506388,  0.07907166,
        0.15296023]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3204490858952469
{'scaleFactor': 20, 'currentState': array([ 2.79997667e+01,  2.07857791e+01,  1.06328978e+02,  4.35667016e-02,
       -2.71868528e-02,  9.98680538e-01]), 'targetState': array([25., 25., 15.])}
episode index:421
target thresh 13.710349145024525
model initialize at round 421
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.1248267 , 15.13312961,  0.9834304 ,  0.12399835,
        0.13224617]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31968972787179845
{'scaleFactor': 20, 'currentState': array([60.88832742, 15.61148909, 84.93881083,  0.59981587, -0.43693429,
        0.67030542]), 'targetState': array([25., 25., 15.])}
episode index:422
target thresh 13.718977678676147
model initialize at round 422
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.84627329, 14.95340556,  0.98709092, -0.15327499,
       -0.04645752]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31893396019361453
{'scaleFactor': 20, 'currentState': array([63.23164515, 27.9333569 , 55.40263403, -0.07801889, -0.13007178,
        0.98843026]), 'targetState': array([25., 25., 15.])}
episode index:423
target thresh 13.727605349517546
model initialize at round 423
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31818175745730887
{'scaleFactor': 20, 'currentState': array([20.25337984, 28.18938203, 83.11599267, -0.43967913, -0.30239374,
        0.8457188 ]), 'targetState': array([25., 25., 15.])}
episode index:424
target thresh 13.736232157634998
model initialize at round 424
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08061418, 15.15372671,  0.98497441,  0.08020496,
        0.15294634]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31743309449858575
{'scaleFactor': 20, 'currentState': array([ 1.51268335e+01,  2.73626747e+01,  1.00127640e+02,  1.63091330e-02,
       -1.50796528e-01,  9.88430280e-01]), 'targetState': array([25., 25., 15.])}
episode index:425
target thresh 13.744858103114765
model initialize at round 425
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3188979936884975
{'scaleFactor': 20, 'currentState': array([27.31406096, 20.10276858, 18.48156283,  0.71587984,  0.52263062,
        0.46300463]), 'targetState': array([25., 25., 15.])}
episode index:426
target thresh 13.753483186043136
model initialize at round 426
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13497581, 15.05562594,  0.98930145,  0.13488057,
        0.05558669]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3203560315238898
{'scaleFactor': 20, 'currentState': array([25.59535858, 21.2283282 , 19.62917634,  0.35221643,  0.80168104,
        0.48296077]), 'targetState': array([25., 25., 15.])}
episode index:427
target thresh 13.762107406506308
model initialize at round 427
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.97876704,  0.98793602,  0.15340621,
       -0.02118869]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3218294754920583
{'scaleFactor': 20, 'currentState': array([25.11916015, 20.03042228, 12.72247584,  0.52661904,  0.74554421,
       -0.40845589]), 'targetState': array([25., 25., 15.])}
episode index:428
target thresh 13.770730764590578
model initialize at round 428
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.09950165,  0.98332014,  0.15268946,
        0.09883028]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3210792902345011
{'scaleFactor': 20, 'currentState': array([ 3.00507387e+01,  1.61154017e+01,  1.03765198e+02, -6.03417075e-02,
       -5.15745263e-02,  9.96844495e-01]), 'targetState': array([25., 25., 15.])}
episode index:429
target thresh 13.779353260382143
model initialize at round 429
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08713151, 15.14787437,  0.98530208,  0.08671804,
        0.14717266]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32033259421069993
{'scaleFactor': 20, 'currentState': array([ 2.49191391e+01,  2.71793015e+01,  1.04535800e+02, -3.81861224e-02,
       -7.01828115e-02,  9.96802986e-01]), 'targetState': array([25., 25., 15.])}
episode index:430
target thresh 13.787974893967236
model initialize at round 430
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12419245, 15.05971918,  0.99045069,  0.12424898,
        0.05974636]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3217737718329512
{'scaleFactor': 20, 'currentState': array([25.89607322, 20.89836873, 19.31840398,  0.30683647,  0.67538138,
        0.67060523]), 'targetState': array([25., 25., 15.])}
episode index:431
target thresh 13.796595665432088
model initialize at round 431
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.323208277336581
{'scaleFactor': 20, 'currentState': array([26.2334631 , 21.23692402, 19.12908853,  0.53163656,  0.75925271,
        0.37536368]), 'targetState': array([25., 25., 15.])}
episode index:432
target thresh 13.805215574862883
model initialize at round 432
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.51498292e+01, 1.50020522e+01, 9.88738682e-01,
       1.49638290e-01, 2.04957433e-03]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32246183789700456
{'scaleFactor': 20, 'currentState': array([39.554445  , 24.79935541, 96.12204068,  0.10291819, -0.11141487,
        0.98843036]), 'targetState': array([25., 25., 15.])}
episode index:433
target thresh 13.813834622345844
model initialize at round 433
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3217188382705138
{'scaleFactor': 20, 'currentState': array([19.64662979,  4.01690575, 97.45047806, -0.10267146, -0.13457051,
        0.98557057]), 'targetState': array([25., 25., 15.])}
episode index:434
target thresh 13.822452807967146
model initialize at round 434
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08165639, 15.13953695,  0.9869264 ,  0.08140288,
        0.13910374]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3209792547342597
{'scaleFactor': 20, 'currentState': array([ 2.52429032e+01,  1.95362181e+01,  1.06840756e+02,  2.20826791e-02,
       -1.50059871e-01,  9.88430266e-01]), 'targetState': array([25., 25., 15.])}
episode index:435
target thresh 13.831070131812972
model initialize at round 435
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12987508, 15.15372671,  0.97995816,  0.12855773,
        0.15216742]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32024306378303435
{'scaleFactor': 20, 'currentState': array([ 2.35516538e+01,  2.12462023e+01,  1.07166833e+02,  5.16420089e-03,
       -7.30936700e-02,  9.97311710e-01]), 'targetState': array([25., 25., 15.])}
episode index:436
target thresh 13.839686593969503
model initialize at round 436
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31951024212678025
{'scaleFactor': 20, 'currentState': array([ 2.09349910e+01,  2.34690665e+01,  1.00414072e+02, -1.85451282e-01,
        6.95369007e-02,  9.80190003e-01]), 'targetState': array([25., 25., 15.])}
episode index:437
target thresh 13.8483021945229
model initialize at round 437
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.05550674, 14.94737705,  0.99702882,  0.05590083,
       -0.05299656]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31878076668813465
{'scaleFactor': 20, 'currentState': array([2.91670312e+01, 2.31853573e+01, 1.01055730e+02, 4.05069948e-02,
       9.36989092e-02, 9.94776205e-01]), 'targetState': array([25., 25., 15.])}
episode index:438
target thresh 13.856916933559315
model initialize at round 438
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.98272036, 15.15372671,  0.98801092, -0.01724492,
        0.15341784]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3180546146000068
{'scaleFactor': 20, 'currentState': array([ 2.77612727e+01,  1.76831131e+01,  1.07595674e+02, -1.53409190e-01,
       -1.60373315e-02,  9.88032603e-01]), 'targetState': array([25., 25., 15.])}
episode index:439
target thresh 13.865530811164906
model initialize at round 439
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14796821, 15.14088942,  0.979361  ,  0.14637808,
        0.13937536]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31733176320318857
{'scaleFactor': 20, 'currentState': array([ 2.55476191e+01,  1.98642750e+01,  1.04972522e+02, -1.47349140e-01,
        3.59325963e-02,  9.88431626e-01]), 'targetState': array([25., 25., 15.])}
episode index:440
target thresh 13.8741438274258
model initialize at round 440
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31661219004399765
{'scaleFactor': 20, 'currentState': array([2.05501693e+01, 2.38879529e+01, 1.05674661e+02, 3.59785857e-02,
       3.78804259e-02, 9.98634375e-01]), 'targetState': array([25., 25., 15.])}
episode index:441
target thresh 13.88275598242813
model initialize at round 441
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.12687315,  0.98032839,  0.15222491,
        0.12563369]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.31802591845883255
{'scaleFactor': 20, 'currentState': array([26.83958783, 21.32412969, 15.10644824,  0.52207306,  0.78943183,
       -0.32285773]), 'targetState': array([25., 25., 15.])}
episode index:442
target thresh 13.891367276258016
model initialize at round 442
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10983727, 14.84627329,  0.98227235,  0.10897991,
       -0.15252676]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.31943326435260716
{'scaleFactor': 20, 'currentState': array([26.45286679, 20.11307301, 10.18849485,  0.45707222,  0.68468796,
       -0.56770361]), 'targetState': array([25., 25., 15.])}
episode index:443
target thresh 13.899977709001575
model initialize at round 443
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85997018,  0.97864497,  0.1519635 ,
       -0.13842372]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3208556895452815
{'scaleFactor': 20, 'currentState': array([25.16764519, 20.18358848, 13.14548472,  0.58950708,  0.80120003,
        0.10276143]), 'targetState': array([25., 25., 15.])}
episode index:444
target thresh 13.90858728074491
model initialize at round 444
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32013466552383146
{'scaleFactor': 20, 'currentState': array([ 20.31444533,  28.27552868, 104.64975494,  -0.14692606,
        -0.108366  ,   0.98319354]), 'targetState': array([25., 25., 15.])}
episode index:445
target thresh 13.917195991574127
model initialize at round 445
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.07363695, 15.08022474,  0.99400476,  0.07393483,
        0.08054926]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3215278168329731
{'scaleFactor': 20, 'currentState': array([26.24505683, 20.33085855, 19.45767292,  0.38709975,  0.66820243,
        0.63534187]), 'targetState': array([25., 25., 15.])}
episode index:446
target thresh 13.925803841575291
model initialize at round 446
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.08302993,  0.98478174,  0.15291642,
        0.08259228]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3229360097481119
{'scaleFactor': 20, 'currentState': array([25.20421885, 20.07474183, 17.01408722,  0.54358164,  0.75474036,
        0.36726829]), 'targetState': array([25., 25., 15.])}
episode index:447
target thresh 13.934410830834498
model initialize at round 447
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3222151704406384
{'scaleFactor': 20, 'currentState': array([ 23.69061044,  22.87213768, 107.20432488,  -0.13485554,
         0.12135472,   0.98340582]), 'targetState': array([25., 25., 15.])}
episode index:448
target thresh 13.943016959437815
model initialize at round 448
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.06232634,  0.98625125,  0.1531446 ,
        0.06209033]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3235943797478998
{'scaleFactor': 20, 'currentState': array([25.29483539, 21.06739709, 19.99039954,  0.20740563,  0.62498111,
        0.75258323]), 'targetState': array([25., 25., 15.])}
episode index:449
target thresh 13.951622227471304
model initialize at round 449
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.32496745923601783
{'scaleFactor': 20, 'currentState': array([25.51680953, 21.5465424 , 19.71079899,  0.35327772,  0.81830395,
        0.45340214]), 'targetState': array([25., 25., 15.])}
episode index:450
target thresh 13.960226635021
model initialize at round 450
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.09924183,  0.98334519,  0.15269335,
        0.09857473]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3263344496798426
{'scaleFactor': 20, 'currentState': array([25.56585866, 21.37935285, 19.70700185,  0.34332405,  0.71192251,
        0.61261321]), 'targetState': array([25., 25., 15.])}
episode index:451
target thresh 13.968830182172976
model initialize at round 451
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13455601, 15.12122409,  0.98367533,  0.13369639,
        0.12044965]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3256124708088695
{'scaleFactor': 20, 'currentState': array([2.51462827e+01, 2.41374351e+01, 1.05604045e+02, 1.02145768e-01,
       1.83603003e-01, 9.77678976e-01]), 'targetState': array([25., 25., 15.])}
episode index:452
target thresh 13.977432869013251
model initialize at round 452
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.51537267e+01,  1.49966640e+01,  9.88152386e-01,
        1.53439811e-01, -3.32972999e-03]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3269929952660243
{'scaleFactor': 20, 'currentState': array([25.26239525, 20.07391783, 16.45505522,  0.53187456,  0.73482315,
        0.42088525]), 'targetState': array([25., 25., 15.])}
episode index:453
target thresh 13.986034695627858
model initialize at round 453
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3262727463777732
{'scaleFactor': 20, 'currentState': array([2.40466781e+01, 2.27933593e+01, 1.06534702e+02, 1.58713829e-02,
       1.50843231e-01, 9.88430280e-01]), 'targetState': array([25., 25., 15.])}
episode index:454
target thresh 13.994635662102795
model initialize at round 454
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.07959573, 15.15372671,  0.98505396,  0.07919807,
        0.15295869]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3255556634187012
{'scaleFactor': 20, 'currentState': array([ 1.69889606e+01,  2.30489855e+01,  1.04365724e+02,  5.43672529e-02,
       -6.57111795e-02,  9.96356484e-01]), 'targetState': array([25., 25., 15.])}
episode index:455
target thresh 14.003235768524103
model initialize at round 455
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.50130502e+01, 1.51537267e+01, 9.88074041e-01,
       1.30248308e-02, 1.53427646e-01]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3248417255603268
{'scaleFactor': 20, 'currentState': array([2.54068096e+01, 1.65189916e+01, 1.02477378e+02, 2.62922270e-02,
       1.77452172e-02, 9.99496786e-01]), 'targetState': array([25., 25., 15.])}
episode index:456
target thresh 14.011835014977759
model initialize at round 456
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.50058675e+01, 1.51537267e+01, 9.88140917e-01,
       5.85649793e-03, 1.53438031e-01]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3241309121564749
{'scaleFactor': 20, 'currentState': array([2.73212419e+01, 1.75434547e+01, 1.07536670e+02, 1.51831167e-01,
       2.17113880e-02, 9.88167958e-01]), 'targetState': array([25., 25., 15.])}
episode index:457
target thresh 14.02043340154976
model initialize at round 457
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3234232027412861
{'scaleFactor': 20, 'currentState': array([ 1.07374495e+01,  2.97566734e+01,  9.75379014e+01, -7.47289253e-03,
        1.76083923e-01,  9.84346793e-01]), 'targetState': array([25., 25., 15.])}
episode index:458
target thresh 14.029030928326103
model initialize at round 458
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32271857702725276
{'scaleFactor': 20, 'currentState': array([ 2.51068106e+01,  2.42901103e+01,  1.06243467e+02, -7.65335346e-02,
        5.86893138e-02,  9.95338225e-01]), 'targetState': array([25., 25., 15.])}
episode index:459
target thresh 14.037627595392754
model initialize at round 459
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.50084447e+01, 1.51029807e+01, 9.94597547e-01,
       8.48396161e-03, 1.03458892e-01]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3220170149032805
{'scaleFactor': 20, 'currentState': array([ 3.74271275e+01,  1.39732633e+01,  9.90158866e+01, -2.66020670e-01,
        7.01196092e-02,  9.61413669e-01]), 'targetState': array([25., 25., 15.])}
episode index:460
target thresh 14.046223402835679
model initialize at round 460
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.84627329, 15.07330811,  0.98552309, -0.15303154,
        0.0729766 ]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32131849643277444
{'scaleFactor': 20, 'currentState': array([31.31200575, 18.37345907, 98.11399663, -0.15449994, -0.14935213,
        0.97663899]), 'targetState': array([25., 25., 15.])}
episode index:461
target thresh 14.054818350740838
model initialize at round 461
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32062300185175113
{'scaleFactor': 20, 'currentState': array([ 18.73864205,  26.78765731, 102.55049459,  -0.69389647,
        -0.16719732,   0.70039471]), 'targetState': array([25., 25., 15.])}
episode index:462
target thresh 14.06341243919419
model initialize at round 462
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.05595397,  0.98662033,  0.15320191,
        0.05576295]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31993051156697416
{'scaleFactor': 20, 'currentState': array([ 2.37072480e+01,  2.38512192e+01,  1.05419947e+02,  4.94465880e-02,
       -1.23803394e-01,  9.91074041e-01]), 'targetState': array([25., 25., 15.])}
episode index:463
target thresh 14.072005668281651
model initialize at round 463
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.50637226e+01, 1.50115816e+01, 9.97866907e-01,
       6.42289884e-02, 1.16736328e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31924100615411427
{'scaleFactor': 20, 'currentState': array([3.69705274e+01, 2.09701110e+01, 9.75015079e+01, 3.19882084e-02,
       3.65262215e-02, 9.98820599e-01]), 'targetState': array([25., 25., 15.])}
episode index:464
target thresh 14.080598038089164
model initialize at round 464
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.04634549, 15.15372671,  0.98710227,  0.04620984,
        0.15327675]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3185544663559334
{'scaleFactor': 20, 'currentState': array([2.78351141e+01, 1.46038454e+01, 1.07652565e+02, 1.49467474e-01,
       3.45774537e-02, 9.88161866e-01]), 'targetState': array([25., 25., 15.])}
episode index:465
target thresh 14.089189548702674
model initialize at round 465
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12502802, 15.15372671,  0.98055186,  0.12383481,
        0.15225961]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3178708730804915
{'scaleFactor': 20, 'currentState': array([ 2.20779316e+01,  2.61419527e+01,  9.88716218e+01, -6.43312258e-02,
       -7.55529797e-02,  9.95064440e-01]), 'targetState': array([25., 25., 15.])}
episode index:466
target thresh 14.097780200208065
model initialize at round 466
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.50014091e+01, 1.51537267e+01, 9.88156886e-01,
       1.40649094e-03, 1.53440510e-01]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3171902073993769
{'scaleFactor': 20, 'currentState': array([ 2.75710729e+01,  1.79673503e+01,  1.07557814e+02, -1.23293040e-01,
        3.20285569e-02,  9.91853315e-01]), 'targetState': array([25., 25., 15.])}
episode index:467
target thresh 14.10636999269126
model initialize at round 467
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.0932036 , 15.15372671,  0.98390936,  0.0926302 ,
        0.15278096]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31651245054595945
{'scaleFactor': 20, 'currentState': array([ 2.76322191e+01,  2.02378216e+01,  1.06202685e+02,  1.32147288e-01,
       -2.56290031e-02,  9.90898708e-01]), 'targetState': array([25., 25., 15.])}
episode index:468
target thresh 14.114958926238153
model initialize at round 468
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.04776978, 15.15372671,  0.9870365 ,  0.04762678,
        0.15326654]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3158375839136653
{'scaleFactor': 20, 'currentState': array([2.77947024e+01, 1.78766496e+01, 1.06785108e+02, 9.94902879e-02,
       7.07636976e-03, 9.95013371e-01]), 'targetState': array([25., 25., 15.])}
episode index:469
target thresh 14.123547000934632
model initialize at round 469
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.92070827, 15.14826062,  0.98588346, -0.07896203,
        0.14764414]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31516558905427455
{'scaleFactor': 20, 'currentState': array([ 3.19533705e+01,  1.60740560e+01,  1.04235056e+02,  1.57292146e-01,
       -2.52158092e-02,  9.87230137e-01]), 'targetState': array([25., 25., 15.])}
episode index:470
target thresh 14.132134216866598
model initialize at round 470
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.0954749 ,  0.98370119,  0.15274863,
        0.09486744]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31449644767623997
{'scaleFactor': 20, 'currentState': array([ 3.6110804 , 26.99059674, 87.3826907 ,  0.15566801, -0.17135048,
        0.97283425]), 'targetState': array([25., 25., 15.])}
episode index:471
target thresh 14.140720574119891
model initialize at round 471
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15309352,  0.97681907,  0.15167998,
        0.15105522]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3138301416430276
{'scaleFactor': 20, 'currentState': array([25.01106355, 31.99307664, 99.48199093, -0.10116992, -0.12732005,
        0.98668853]), 'targetState': array([25., 25., 15.])}
episode index:472
target thresh 14.149306072780387
model initialize at round 472
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.06593813,  0.9860246 ,  0.15310941,
        0.06567335]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31316665297147783
{'scaleFactor': 20, 'currentState': array([2.41823693e+01, 2.33901468e+01, 1.05947158e+02, 7.13299778e-02,
       6.59576531e-02, 9.95269623e-01]), 'targetState': array([25., 25., 15.])}
episode index:473
target thresh 14.157890712933952
model initialize at round 473
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.06787148, 15.15372671,  0.98589811,  0.06759027,
        0.15308977]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3125059638301878
{'scaleFactor': 20, 'currentState': array([ 2.44038896e+01,  2.11948722e+01,  1.07391703e+02,  1.32005487e-01,
       -7.56186775e-02,  9.88360444e-01]), 'targetState': array([25., 25., 15.])}
episode index:474
target thresh 14.166474494666426
model initialize at round 474
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12845507, 15.15372671,  0.98013432,  0.12717497,
        0.15219477]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31184805653791375
{'scaleFactor': 20, 'currentState': array([2.42197052e+01, 1.75658958e+01, 1.06229188e+02, 2.04807559e-02,
       1.29467189e-01, 9.91372173e-01]), 'targetState': array([25., 25., 15.])}
episode index:475
target thresh 14.17505741806363
model initialize at round 475
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14237231, 15.15372671,  0.9783288 ,  0.14069387,
        0.15191441]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3131708130355253
{'scaleFactor': 20, 'currentState': array([25.62939286, 21.2232183 , 19.61755706,  0.30569429,  0.7326816 ,
        0.60805318]), 'targetState': array([25., 25., 15.])}
episode index:476
target thresh 14.183639483211419
model initialize at round 476
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.07164182,  0.98564106,  0.15304985,
        0.07132638]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3144880233842999
{'scaleFactor': 20, 'currentState': array([25.72812823, 21.37854374, 19.10951438,  0.29592985,  0.71025624,
        0.63871872]), 'targetState': array([25., 25., 15.])}
episode index:477
target thresh 14.19222069019559
model initialize at round 477
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.97487337, 15.15372671,  0.98784723, -0.02507199,
        0.15339243]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31383009864918626
{'scaleFactor': 20, 'currentState': array([ 29.12781115,  15.82797456, 107.43145116,   0.13182934,
         0.16362745,   0.97767432]), 'targetState': array([25., 25., 15.])}
episode index:478
target thresh 14.200801039101973
model initialize at round 478
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.05587427,  0.98662469,  0.15320259,
        0.05568377]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3151404327843675
{'scaleFactor': 20, 'currentState': array([25.90012388, 21.2320725 , 18.79115514,  0.32290769,  0.66496479,
        0.67346303]), 'targetState': array([25., 25., 15.])}
episode index:479
target thresh 14.209380530016368
model initialize at round 479
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31448389021606676
{'scaleFactor': 20, 'currentState': array([ 2.70944218e+01,  2.33481514e+01,  1.06350949e+02, -6.20940152e-02,
       -1.40866421e-01,  9.88079442e-01]), 'targetState': array([25., 25., 15.])}
episode index:480
target thresh 14.217959163024574
model initialize at round 480
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3138300775544949
{'scaleFactor': 20, 'currentState': array([ 2.40446960e+01,  2.26617933e+01,  1.07484904e+02,  1.06398678e-01,
       -1.08096673e-01,  9.88430286e-01]), 'targetState': array([25., 25., 15.])}
episode index:481
target thresh 14.226536938212353
model initialize at round 481
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.13114034,  0.97979964,  0.1521428 ,
        0.12978915]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3131789778085312
{'scaleFactor': 20, 'currentState': array([16.74299611, 29.29709058, 96.58446925, -0.09922053,  0.11555271,
        0.98833337]), 'targetState': array([25., 25., 15.])}
episode index:482
target thresh 14.235113855665515
model initialize at round 482
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3144798083915384
{'scaleFactor': 20, 'currentState': array([25.71185067, 21.4990384 , 19.34821471,  0.33252441,  0.76464243,
        0.55204119]), 'targetState': array([25., 25., 15.])}
episode index:483
target thresh 14.243689915469826
model initialize at round 483
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15305439, 15.09647181,  0.98370842,  0.15208171,
        0.09585872]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3138300567213079
{'scaleFactor': 20, 'currentState': array([ 2.79480807e+01,  2.67597453e+01,  1.03668888e+02, -8.15833892e-02,
       -4.16135078e-02,  9.95797402e-01]), 'targetState': array([25., 25., 15.])}
episode index:484
target thresh 14.252265117711016
model initialize at round 484
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10592972, 15.151965  ,  0.98294106,  0.10517441,
        0.15088145]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31318298443940834
{'scaleFactor': 20, 'currentState': array([ 2.03558792e+01,  2.14045721e+01,  1.05955566e+02, -1.45688644e-01,
       -4.21787664e-02,  9.88430964e-01]), 'targetState': array([25., 25., 15.])}
episode index:485
target thresh 14.260839462474861
model initialize at round 485
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3125385750064054
{'scaleFactor': 20, 'currentState': array([ 2.73904667e+01,  2.25886218e+01,  1.06647233e+02, -1.75245406e-02,
        7.46793354e-02,  9.97053603e-01]), 'targetState': array([25., 25., 15.])}
episode index:486
target thresh 14.269412949847094
model initialize at round 486
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09246376, 15.15372671,  0.98397611,  0.09190114,
        0.15279132]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3118968120187126
{'scaleFactor': 20, 'currentState': array([ 2.64957832e+01,  2.19831568e+01,  1.07254942e+02, -2.75521441e-02,
       -4.62439707e-02,  9.98550136e-01]), 'targetState': array([25., 25., 15.])}
episode index:487
target thresh 14.277985579913466
model initialize at round 487
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.49853624e+01,  1.51537267e+01,  9.88052414e-01,
       -1.46087543e-02,  1.53424288e-01]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3112576792071988
{'scaleFactor': 20, 'currentState': array([ 28.61494465,  22.52712837, 103.80894624,   0.18843328,
        -0.11654744,   0.97514593]), 'targetState': array([25., 25., 15.])}
episode index:488
target thresh 14.286557352759688
model initialize at round 488
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.310621160435814
{'scaleFactor': 20, 'currentState': array([2.29924227e+01, 2.34773191e+01, 1.06085486e+02, 4.43291007e-02,
       1.26861855e-01, 9.90929362e-01]), 'targetState': array([25., 25., 15.])}
episode index:489
target thresh 14.29512826847148
model initialize at round 489
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12656351, 15.15372671,  0.98036611,  0.1253319 ,
        0.15223076]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3099872397002307
{'scaleFactor': 20, 'currentState': array([ 2.34563201e+01,  2.37459866e+01,  1.06330533e+02,  1.33113294e-01,
       -7.27080200e-02,  9.88430268e-01]), 'targetState': array([25., 25., 15.])}
episode index:490
target thresh 14.303698327134562
model initialize at round 490
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30935590112650313
{'scaleFactor': 20, 'currentState': array([ 27.39288127,  21.26966941, 106.82191823,  -0.1802624 ,
         0.15274102,   0.97168701]), 'targetState': array([25., 25., 15.])}
episode index:491
target thresh 14.31226752883462
model initialize at round 491
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.07386978,  0.98548273,  0.15302527,
        0.07353272]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.31064070650917486
{'scaleFactor': 20, 'currentState': array([26.76418528, 21.41516067, 16.6429933 ,  0.5227275 ,  0.83083292,
        0.19097808]), 'targetState': array([25., 25., 15.])}
episode index:492
target thresh 14.320835873657368
model initialize at round 492
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.51537267e+01, 1.50124216e+01, 9.88081921e-01,
       1.53428870e-01, 1.23975460e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3119395895586492
{'scaleFactor': 20, 'currentState': array([25.36247701, 20.15593156, 15.90501751,  0.58928461,  0.78805899,
        0.17806366]), 'targetState': array([25., 25., 15.])}
episode index:493
target thresh 14.329403361688453
model initialize at round 493
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.12413129,  0.98065934,  0.15227629,
        0.12296011]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3132139631615689
{'scaleFactor': 20, 'currentState': array([25.65625718, 21.31787515, 19.67533141,  0.39302733,  0.72617175,
        0.56409583]), 'targetState': array([25., 25., 15.])}
episode index:494
target thresh 14.337969993013576
model initialize at round 494
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.04670092,  0.98708604,  0.15327423,
        0.04656346]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3145023997004345
{'scaleFactor': 20, 'currentState': array([25.51091626, 20.00552829, 15.9440875 ,  0.69059487,  0.72145835,
        0.05076   ]), 'targetState': array([25., 25., 15.])}
episode index:495
target thresh 14.346535767718404
model initialize at round 495
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.88833655,  0.98207683,  0.1524964 ,
       -0.11076978]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.31576646774418565
{'scaleFactor': 20, 'currentState': array([26.77250335, 21.33175099, 13.05149006,  0.657834  ,  0.74445751,
        0.11418161]), 'targetState': array([25., 25., 15.])}
episode index:496
target thresh 14.355100685888589
model initialize at round 496
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.49919838e+01,  1.50980875e+01,  9.95095286e-01,
       -8.05741032e-03,  9.85923421e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3151311227386641
{'scaleFactor': 20, 'currentState': array([ 3.04103430e+01,  2.65049871e+01,  1.01032264e+02, -9.18898975e-02,
        1.20672399e-01,  9.88430280e-01]), 'targetState': array([25., 25., 15.])}
episode index:497
target thresh 14.363664747609771
model initialize at round 497
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31449832931951016
{'scaleFactor': 20, 'currentState': array([ 3.33196055, 29.64500161, 87.09656952, -0.51873107, -0.71034039,
        0.47574636]), 'targetState': array([25., 25., 15.])}
episode index:498
target thresh 14.37222795296761
model initialize at round 498
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12986568, 15.15372671,  0.97995933,  0.12854857,
        0.1521676 ]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3138680721465252
{'scaleFactor': 20, 'currentState': array([2.38798128e+01, 2.21154542e+01, 1.07342993e+02, 1.90645573e-03,
       2.24114465e-02, 9.99747014e-01]), 'targetState': array([25., 25., 15.])}
episode index:499
target thresh 14.38079030204772
model initialize at round 499
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.01973793, 15.0815917 ,  0.99642433,  0.01986601,
        0.08212117]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31324033600223217
{'scaleFactor': 20, 'currentState': array([ 4.15076564e+01,  7.23474444e+00,  1.00343318e+02,  6.26108101e-03,
       -2.69044525e-01,  9.63107389e-01]), 'targetState': array([25., 25., 15.])}
episode index:500
target thresh 14.389351794935735
model initialize at round 500
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.94048896, 15.05069295,  0.99689679, -0.05992562,
        0.0510461 ]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3126151057906508
{'scaleFactor': 20, 'currentState': array([ 3.09107843e+01,  1.32475244e+01,  1.03140028e+02, -1.00665520e-01,
        7.65050738e-02,  9.91974509e-01]), 'targetState': array([25., 25., 15.])}
episode index:501
target thresh 14.397912431717263
model initialize at round 501
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3119923665360878
{'scaleFactor': 20, 'currentState': array([ 24.43397982,  21.55924669, 106.99278723,   0.11612397,
         0.17598272,   0.97751998]), 'targetState': array([25., 25., 15.])}
episode index:502
target thresh 14.406472212477928
model initialize at round 502
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.03597964,  0.98752126,  0.15334181,
        0.03588956]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3132438333012268
{'scaleFactor': 20, 'currentState': array([25.82870401, 21.41120883, 18.72518668,  0.35227935,  0.75974732,
        0.54651923]), 'targetState': array([25., 25., 15.])}
episode index:503
target thresh 14.415031137303313
model initialize at round 503
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13002481, 15.08578206,  0.98784637,  0.12974195,
        0.08559545]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.31449033392840886
{'scaleFactor': 20, 'currentState': array([27.13136011, 20.41918688, 17.41812435,  0.55394892,  0.70412808,
        0.44423445]), 'targetState': array([25., 25., 15.])}
episode index:504
target thresh 14.423589206278997
model initialize at round 504
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31386758079191696
{'scaleFactor': 20, 'currentState': array([ 3.41669890e+01,  2.93602988e+01,  1.00720541e+02, -2.91633066e-01,
        7.09895610e-02,  9.53892361e-01]), 'targetState': array([25., 25., 15.])}
episode index:505
target thresh 14.432146419490577
model initialize at round 505
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.06008945,  0.98638529,  0.15316542,
        0.05987005]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.31510792183659897
{'scaleFactor': 20, 'currentState': array([27.07704242, 20.62436257, 17.85182244,  0.72226155,  0.59189364,
        0.35777113]), 'targetState': array([25., 25., 15.])}
episode index:506
target thresh 14.440702777023628
model initialize at round 506
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.50979696e+01,  1.49923512e+01,  9.95109804e-01,
        9.84752186e-02, -7.68831262e-03]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.31634337001719937
{'scaleFactor': 20, 'currentState': array([26.69624158, 21.14515964, 16.50949447,  0.45183018,  0.77901251,
        0.43472866]), 'targetState': array([25., 25., 15.])}
episode index:507
target thresh 14.449258278963695
model initialize at round 507
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31572064684787415
{'scaleFactor': 20, 'currentState': array([ 2.37594323e+01,  2.31398174e+01,  1.07267563e+02, -9.66007036e-02,
       -9.96893538e-02,  9.90318301e-01]), 'targetState': array([25., 25., 15.])}
episode index:508
target thresh 14.457812925396352
model initialize at round 508
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.0994151 , 15.15372671,  0.98332849,  0.09874515,
        0.15269076]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31510037052793727
{'scaleFactor': 20, 'currentState': array([2.68650937e+01, 1.96993378e+01, 1.07543083e+02, 8.38140054e-02,
       1.27451341e-01, 9.88297206e-01]), 'targetState': array([25., 25., 15.])}
episode index:509
target thresh 14.46636671640713
model initialize at round 509
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.314482526664157
{'scaleFactor': 20, 'currentState': array([25.33095547,  1.25918027, 55.81417962,  0.64605279, -0.28636881,
       -0.70753706]), 'targetState': array([25., 25., 15.])}
episode index:510
target thresh 14.474919652081574
model initialize at round 510
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10983593, 14.95947173,  0.99308011,  0.11017765,
       -0.04065436]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.31570952788282014
{'scaleFactor': 20, 'currentState': array([26.66589521, 21.38565014, 13.45093535,  0.50130921,  0.85758285,
       -0.11506832]), 'targetState': array([25., 25., 15.])}
episode index:511
target thresh 14.483471732505215
model initialize at round 511
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.02723169,  0.98779304,  0.15338401,
        0.02717098]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.31695031015238495
{'scaleFactor': 20, 'currentState': array([25.31723879, 20.12925308, 16.23200398,  0.58318045,  0.78681595,
        0.20204263]), 'targetState': array([25., 25., 15.])}
episode index:512
target thresh 14.492022957763584
model initialize at round 512
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.05727947,  0.9865468 ,  0.1531905 ,
        0.05707968]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.31816771724643683
{'scaleFactor': 20, 'currentState': array([25.46170773, 21.18239828, 19.59542891,  0.2545834 ,  0.68489577,
        0.68271889]), 'targetState': array([25., 25., 15.])}
episode index:513
target thresh 14.500573327942167
model initialize at round 513
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.05087683,  0.98688618,  0.1532432 ,
        0.05071681]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3193988890998485
{'scaleFactor': 20, 'currentState': array([25.32685885, 20.16514354, 16.25333752,  0.5964385 ,  0.79904701,
        0.07605907]), 'targetState': array([25., 25., 15.])}
episode index:514
target thresh 14.509122843126487
model initialize at round 514
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.97874605,  0.98793558,  0.15340615,
       -0.02120963]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.32060681387713225
{'scaleFactor': 20, 'currentState': array([25.92315061, 21.43495464, 18.22685699,  0.32308546,  0.73208691,
        0.59972039]), 'targetState': array([25., 25., 15.])}
episode index:515
target thresh 14.517671503402042
model initialize at round 515
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.1526265 ,  0.97688697,  0.15169052,
        0.15060489]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3199854828424867
{'scaleFactor': 20, 'currentState': array([2.47873096e+01, 1.55670957e+01, 1.05575125e+02, 1.89861228e-01,
       2.55330308e-02, 9.81478873e-01]), 'targetState': array([25., 25., 15.])}
episode index:516
target thresh 14.526219308854305
model initialize at round 516
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.49998482e+01,  1.49837717e+01,  9.99865663e-01,
       -1.53359547e-04, -1.63899915e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31936655540952247
{'scaleFactor': 20, 'currentState': array([ 4.70633048e+01,  2.84244716e+01,  8.99404031e+01, -6.12293478e-02,
        1.38767963e-01,  9.88430280e-01]), 'targetState': array([25., 25., 15.])}
episode index:517
target thresh 14.534766259568766
model initialize at round 517
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.12483843,  0.98057465,  0.15226314,
        0.12364989]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3187500176577666
{'scaleFactor': 20, 'currentState': array([ 2.90553986e+01,  2.23417845e+01,  1.05514973e+02, -1.50497789e-01,
       -1.88678743e-02,  9.88430280e-01]), 'targetState': array([25., 25., 15.])}
episode index:518
target thresh 14.543312355630878
model initialize at round 518
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31813585577403297
{'scaleFactor': 20, 'currentState': array([ 2.39060767e+01,  2.40328429e+01,  1.06154543e+02, -1.48089536e-01,
       -3.27882673e-02,  9.88430280e-01]), 'targetState': array([25., 25., 15.])}
episode index:519
target thresh 14.551857597126116
model initialize at round 519
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3175240560513906
{'scaleFactor': 20, 'currentState': array([ 32.63189728,  24.33280189, 102.2668944 ,  -0.13753014,
         0.48723024,   0.86237588]), 'targetState': array([25., 25., 15.])}
episode index:520
target thresh 14.560401984139936
model initialize at round 520
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.05681825,  0.98657258,  0.1531945 ,
        0.05662154]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31691460488814416
{'scaleFactor': 20, 'currentState': array([4.17323481e+01, 2.32971095e+01, 9.35731941e+01, 1.29804135e-02,
       1.54291443e-01, 9.87940109e-01]), 'targetState': array([25., 25., 15.])}
episode index:521
target thresh 14.56894551675777
model initialize at round 521
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.06729543,  0.98593617,  0.15309568,
        0.06701919]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.31812930880579143
{'scaleFactor': 20, 'currentState': array([25.03255457, 20.06726761, 17.66696465,  0.55660011,  0.78643883,
        0.26778776]), 'targetState': array([25., 25., 15.])}
episode index:522
target thresh 14.577488195065058
model initialize at round 522
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.94976824,  0.98691816,  0.15324816,
       -0.05007539]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.31933936758417425
{'scaleFactor': 20, 'currentState': array([25.11044398, 20.07180933, 12.58650529,  0.54299792,  0.76263716,
       -0.35147947]), 'targetState': array([25., 25., 15.])}
episode index:523
target thresh 14.586030019147234
model initialize at round 523
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.90675977,  0.98390604,  0.15278044,
       -0.09266629]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3205448078176014
{'scaleFactor': 20, 'currentState': array([25.30776346, 20.14039364, 14.87859136,  0.56353286,  0.76071393,
        0.32209475]), 'targetState': array([25., 25., 15.])}
episode index:524
target thresh 14.594570989089695
model initialize at round 524
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.12685676,  0.98033039,  0.15222522,
        0.12561771]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31993424627890127
{'scaleFactor': 20, 'currentState': array([ 2.40076767e+01,  2.37754972e+01,  1.05981414e+02, -4.08510990e-02,
        1.04373742e-01,  9.93698802e-01]), 'targetState': array([25., 25., 15.])}
episode index:525
target thresh 14.603111104977884
model initialize at round 525
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13893045, 15.15372671,  0.97879164,  0.13735754,
        0.15198628]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31932600626696417
{'scaleFactor': 20, 'currentState': array([ 2.61904962e+01,  2.11913290e+01,  1.07353467e+02, -1.46996611e-03,
       -1.37285609e-01,  9.90530414e-01]), 'targetState': array([25., 25., 15.])}
episode index:526
target thresh 14.611650366897177
model initialize at round 526
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.03938389, 15.15372671,  0.98739524,  0.03928027,
        0.15332224]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31872007456626783
{'scaleFactor': 20, 'currentState': array([2.59775507e+01, 2.05786772e+01, 1.07234980e+02, 6.60152972e-02,
       1.36556075e-01, 9.88430280e-01]), 'targetState': array([25., 25., 15.])}
episode index:527
target thresh 14.620188774932963
model initialize at round 527
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3181164380614075
{'scaleFactor': 20, 'currentState': array([ 22.10865637,  20.40609936, 106.94225388,  -0.13220865,
        -0.4145766 ,   0.90035944]), 'targetState': array([25., 25., 15.])}
episode index:528
target thresh 14.62872632917065
model initialize at round 528
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86024306,  0.97868147,  0.15196917,
       -0.13815911]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3175150837361496
{'scaleFactor': 20, 'currentState': array([ 5.98261595e+00,  3.08009987e+01,  5.91910904e+01,  4.34076184e-03,
       -1.37437037e-02,  9.99896129e-01]), 'targetState': array([25., 25., 15.])}
episode index:529
target thresh 14.63726302969558
model initialize at round 529
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.95700317, 15.15372671,  0.9872491 , -0.04287735,
        0.15329955]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31691599867249653
{'scaleFactor': 20, 'currentState': array([ 2.83014229e+01,  1.31600832e+01,  1.06872023e+02, -2.36233493e-02,
        9.54417750e-02,  9.95154664e-01]), 'targetState': array([25., 25., 15.])}
episode index:530
target thresh 14.645798876593163
model initialize at round 530
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10415049, 15.15372671,  0.98286125,  0.10339947,
        0.15261821]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3163191700497611
{'scaleFactor': 20, 'currentState': array([ 2.34944377e+01,  2.42741398e+01,  1.05906263e+02,  2.19019135e-02,
       -7.45942362e-02,  9.96973423e-01]), 'targetState': array([25., 25., 15.])}
episode index:531
target thresh 14.654333869948722
model initialize at round 531
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.50114473e+01, 1.51537267e+01, 9.88093367e-01,
       1.14252096e-02, 1.53430647e-01]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31572458514365254
{'scaleFactor': 20, 'currentState': array([-7.89488762e+00,  2.83493075e+01,  8.29489838e+01, -2.90782484e-01,
        5.08349669e-02,  9.55437781e-01]), 'targetState': array([25., 25., 15.])}
episode index:532
target thresh 14.662868009847617
model initialize at round 532
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14149084, 14.97807781,  0.98970302,  0.14144839,
       -0.02191561]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31513223132537177
{'scaleFactor': 20, 'currentState': array([31.63793982, 44.89829502, 18.87007072, -0.14419851, -0.04703589,
        0.98843028]), 'targetState': array([25., 25., 15.])}
episode index:533
target thresh 14.671401296375208
model initialize at round 533
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31454209606071754
{'scaleFactor': 20, 'currentState': array([ 2.22966790e+01,  2.27008519e+01,  1.07128078e+02,  1.06654638e-01,
       -1.07844190e-01,  9.88430280e-01]), 'targetState': array([25., 25., 15.])}
episode index:534
target thresh 14.67993372961679
model initialize at round 534
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31395416690920214
{'scaleFactor': 20, 'currentState': array([-0.83716084, 14.25214329, 97.74047641, -0.40298066, -0.40388701,
        0.82126845]), 'targetState': array([25., 25., 15.])}
episode index:535
target thresh 14.688465309657717
model initialize at round 535
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.50892233e+01, 1.50033758e+01, 9.95957617e-01,
       8.97601912e-02, 3.39610141e-03]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3133684315231775
{'scaleFactor': 20, 'currentState': array([3.24435499e+01, 1.87201920e+01, 1.04331479e+02, 1.43630897e-02,
       1.53186202e-01, 9.88092956e-01]), 'targetState': array([25., 25., 15.])}
episode index:536
target thresh 14.696996036583299
model initialize at round 536
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.12203572,  0.98090763,  0.15231485,
        0.12091492]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3127848776469705
{'scaleFactor': 20, 'currentState': array([ 1.60908733e+01,  3.34078714e+01,  9.69507961e+01,  2.04878811e-01,
       -6.46480346e-02,  9.76650042e-01]), 'targetState': array([25., 25., 15.])}
episode index:537
target thresh 14.705525910478833
model initialize at round 537
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3122034931160282
{'scaleFactor': 20, 'currentState': array([ 23.75729673,  21.56832828, 107.26327134,  -0.18231811,
        -0.16709544,   0.96893716]), 'targetState': array([25., 25., 15.])}
episode index:538
target thresh 14.714054931429633
model initialize at round 538
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.03394677,  0.9875911 ,  0.15335266,
        0.03386417]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.31338862587444
{'scaleFactor': 20, 'currentState': array([25.40395467, 20.17549244, 15.23337783,  0.59988629,  0.79504477,
        0.08966744]), 'targetState': array([25., 25., 15.])}
episode index:539
target thresh 14.72258309952098
model initialize at round 539
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.05741824,  0.986539  ,  0.15318929,
        0.05721751]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.31455175832541515
{'scaleFactor': 20, 'currentState': array([25.90436878, 20.89928287, 19.51882955,  0.39272564,  0.58295756,
        0.7112855 ]), 'targetState': array([25., 25., 15.])}
episode index:540
target thresh 14.731110414838145
model initialize at round 540
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.1114018 , 15.02224363,  0.99348073,  0.11179348,
        0.02232184]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3157105908412665
{'scaleFactor': 20, 'currentState': array([26.63027249, 21.33852884, 13.35763444,  0.491711  ,  0.85047764,
       -0.18683703]), 'targetState': array([25., 25., 15.])}
episode index:541
target thresh 14.739636877466433
model initialize at round 541
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87271136,  0.98027764,  0.15221702,
       -0.12603859]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.316865147222373
{'scaleFactor': 20, 'currentState': array([27.00022801, 21.07933813, 13.00832312,  0.69889496,  0.69824767,
       -0.15490653]), 'targetState': array([25., 25., 15.])}
episode index:542
target thresh 14.74816248749108
model initialize at round 542
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.97390446,  0.98782283,  0.15338864,
       -0.02603816]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.31801545109378854
{'scaleFactor': 20, 'currentState': array([26.43810121, 21.46382229, 12.70299497,  0.43262746,  0.80317729,
       -0.40956039]), 'targetState': array([25., 25., 15.])}
episode index:543
target thresh 14.756687244997346
model initialize at round 543
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15330131, 14.93503795,  0.98615099,  0.15270529,
       -0.06470949]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.31916152590685326
{'scaleFactor': 20, 'currentState': array([27.40332026, 20.57594242, 14.4317514 ,  0.66064618,  0.74940957,
        0.0439537 ]), 'targetState': array([25., 25., 15.])}
episode index:544
target thresh 14.76521115007049
model initialize at round 544
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.94408618,  0.98662253,  0.15320226,
       -0.05572306]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.32032084429950125
{'scaleFactor': 20, 'currentState': array([25.37699688, 20.15924923, 14.12182313,  0.60121568,  0.79710821,
       -0.05619792]), 'targetState': array([25., 25., 15.])}
episode index:545
target thresh 14.77373420279574
model initialize at round 545
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.04610977, 15.08058426,  0.99563132,  0.04637205,
        0.08104264]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3197341760864985
{'scaleFactor': 20, 'currentState': array([ 2.65750241e+01,  2.47852915e+01,  1.01850675e+02,  1.03378407e-01,
       -6.89679724e-02,  9.92248116e-01]), 'targetState': array([25., 25., 15.])}
episode index:546
target thresh 14.782256403258343
model initialize at round 546
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.07903809, 15.12905972,  0.98851664,  0.07891966,
        0.12886635]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3191496529126658
{'scaleFactor': 20, 'currentState': array([ 2.48761848e+01,  1.89640000e+01,  1.04596541e+02,  5.15716868e-02,
       -2.33531149e-01,  9.70980723e-01]), 'targetState': array([25., 25., 15.])}
episode index:547
target thresh 14.790777751543505
model initialize at round 547
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.48945754e+01,  1.50012753e+01,  9.94376954e-01,
       -1.05890660e-01,  1.28097555e-03]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3185672630350879
{'scaleFactor': 20, 'currentState': array([1.50280478e+01, 3.88771342e+01, 5.35014959e+01, 1.49916452e-01,
       2.30355901e-02, 9.88430280e-01]), 'targetState': array([25., 25., 15.])}
episode index:548
target thresh 14.799298247736436
model initialize at round 548
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.08503612,  0.98461751,  0.15289092,
        0.08457379]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.319701894886392
{'scaleFactor': 20, 'currentState': array([25.85098131, 21.42867518, 18.79928714,  0.35707673,  0.77495336,
        0.52148203]), 'targetState': array([25., 25., 15.])}
episode index:549
target thresh 14.807817891922358
model initialize at round 549
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.32083240080369124
{'scaleFactor': 20, 'currentState': array([25.46415856, 21.36411725, 19.92064575,  0.28821766,  0.72552519,
        0.62493502]), 'targetState': array([25., 25., 15.])}
episode index:550
target thresh 14.81633668418646
model initialize at round 550
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.06813778,  0.9858804 ,  0.15308702,
        0.06785424]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32025012784397494
{'scaleFactor': 20, 'currentState': array([ 24.26734309,  25.06232575, 104.53631374,  -0.22966345,
        -0.20312274,   0.95183815]), 'targetState': array([25., 25., 15.])}
episode index:551
target thresh 14.824854624613915
model initialize at round 551
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.04224654,  0.98728049,  0.15330442,
        0.04213049]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3213755445496942
{'scaleFactor': 20, 'currentState': array([26.7888237 , 21.55691029, 14.98626605,  0.52833912,  0.8313168 ,
       -0.17254026]), 'targetState': array([25., 25., 15.])}
episode index:552
target thresh 14.83337171328991
model initialize at round 552
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.03218316,  0.98764842,  0.15336156,
        0.03210672]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.32249689103224627
{'scaleFactor': 20, 'currentState': array([26.88987973, 21.00554232, 17.24634589,  0.5779542 ,  0.67584769,
        0.45738259]), 'targetState': array([25., 25., 15.])}
episode index:553
target thresh 14.841887950299649
model initialize at round 553
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10262312, 15.13495073,  0.98565143,  0.10217235,
        0.13435796]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3236141893325509
{'scaleFactor': 20, 'currentState': array([25.963761  , 20.87803505, 19.40144029,  0.34109455,  0.71625632,
        0.60879503]), 'targetState': array([25., 25., 15.])}
episode index:554
target thresh 14.850403335728245
model initialize at round 554
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.09114537,  0.98409378,  0.15280959,
        0.09060161]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32303110070312285
{'scaleFactor': 20, 'currentState': array([ 2.39199806e+01,  2.51618553e+01,  1.04662324e+02, -1.78012418e-02,
       -1.41358883e-01,  9.89798354e-01]), 'targetState': array([25., 25., 15.])}
episode index:555
target thresh 14.858917869660882
model initialize at round 555
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10956986, 15.15372671,  0.98230072,  0.10871773,
        0.15253117]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32245010951480785
{'scaleFactor': 20, 'currentState': array([ 2.70568435e+01,  1.93763643e+01,  1.07668069e+02, -1.78758094e-02,
        1.43017086e-01,  9.89558775e-01]), 'targetState': array([25., 25., 15.])}
episode index:556
target thresh 14.867431552182698
model initialize at round 556
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11588246, 15.15372671,  0.98161327,  0.11490077,
        0.15242442]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32187120447079565
{'scaleFactor': 20, 'currentState': array([ 25.34152449,  28.73729549, 102.11935495,  -0.17394511,
        -0.11817253,   0.97763917]), 'targetState': array([25., 25., 15.])}
episode index:557
target thresh 14.875944383378814
model initialize at round 557
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.02208335, 15.06697721,  0.99747231,  0.02225003,
        0.06748274]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3212943743552566
{'scaleFactor': 20, 'currentState': array([ 2.77977704e+01,  1.88038711e+01,  1.06242068e+02, -6.64932357e-02,
        1.73220503e-02,  9.97636505e-01]), 'targetState': array([25., 25., 15.])}
episode index:558
target thresh 14.884456363334397
model initialize at round 558
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09546726, 15.15372671,  0.98370189,  0.09485993,
        0.15274874]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3207196080326175
{'scaleFactor': 20, 'currentState': array([ 2.17376150e+01,  2.17341862e+01,  1.07083138e+02, -2.13732813e-02,
       -1.12881413e-01,  9.93378563e-01]), 'targetState': array([25., 25., 15.])}
episode index:559
target thresh 14.892967492134535
model initialize at round 559
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14640993, 15.14481038,  0.97904416,  0.14478968,
        0.14320784]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32014689444684497
{'scaleFactor': 20, 'currentState': array([ 15.67944628,  16.49051251, 101.62560401,  -0.10187679,
        -0.32277739,   0.94097602]), 'targetState': array([25., 25., 15.])}
episode index:560
target thresh 14.901477769864336
model initialize at round 560
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09665255, 15.15372671,  0.98359133,  0.09602688,
        0.15273157]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3195762226207365
{'scaleFactor': 20, 'currentState': array([57.04016688, 36.47532514, 86.15391685,  0.49392132,  0.62791689,
        0.60146663]), 'targetState': array([25., 25., 15.])}
episode index:561
target thresh 14.90998719660892
model initialize at round 561
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.13282459,  0.97958638,  0.15210969,
        0.13142743]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3190075816552192
{'scaleFactor': 20, 'currentState': array([ 2.36470157e+01,  2.31267730e+01,  1.06560885e+02,  1.24995668e-01,
       -8.59166110e-02,  9.88430280e-01]), 'targetState': array([25., 25., 15.])}
episode index:562
target thresh 14.918495772453378
model initialize at round 562
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31844096072865574
{'scaleFactor': 20, 'currentState': array([2.42873987e+01, 2.21730579e+01, 1.07250330e+02, 1.30584804e-01,
       8.91718672e-03, 9.91397041e-01]), 'targetState': array([25., 25., 15.])}
episode index:563
target thresh 14.927003497482783
model initialize at round 563
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.10874583,  0.98238772,  0.15254468,
        0.10790966]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31787634909615814
{'scaleFactor': 20, 'currentState': array([ 3.90628986e+01,  3.29274478e+01,  7.85674612e+01, -4.78231903e-02,
        2.55695402e-01,  9.65573821e-01]), 'targetState': array([25., 25., 15.])}
episode index:564
target thresh 14.935510371782247
model initialize at round 564
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.03542708, 15.14450419,  0.98889477,  0.03538753,
        0.14434286]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31731373608890834
{'scaleFactor': 20, 'currentState': array([ 2.80480529e+01,  1.59643497e+01,  1.05371496e+02,  3.07899215e-01,
       -5.73253063e-02,  9.49690414e-01]), 'targetState': array([25., 25., 15.])}
episode index:565
target thresh 14.944016395436787
model initialize at round 565
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.04638437, 15.08224684,  0.99548226,  0.04664123,
        0.0827023 ]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31675311111348625
{'scaleFactor': 20, 'currentState': array([ 1.92459244e+01,  2.94928812e+01,  8.50544420e+01, -1.88351875e-02,
       -1.27338233e-01,  9.91680498e-01]), 'targetState': array([25., 25., 15.])}
episode index:566
target thresh 14.952521568531496
model initialize at round 566
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.316194463651205
{'scaleFactor': 20, 'currentState': array([ 2.25936882e+01,  2.29720235e+01,  1.07130307e+02, -5.80509373e-02,
       -5.64099733e-02,  9.96718618e-01]), 'targetState': array([25., 25., 15.])}
episode index:567
target thresh 14.961025891151426
model initialize at round 567
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.97591833, 15.15372671,  0.98787252, -0.02402992,
        0.15339635]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3156377832574529
{'scaleFactor': 20, 'currentState': array([2.76474852e+01, 1.57863796e+01, 1.07504600e+02, 1.41869569e-01,
       5.70274575e-02, 9.88241314e-01]), 'targetState': array([25., 25., 15.])}
episode index:568
target thresh 14.969529363381618
model initialize at round 568
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13098479, 15.15372671,  0.97981921,  0.1296378 ,
        0.15214584]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3150830595610426
{'scaleFactor': 20, 'currentState': array([ 2.64138663e+01,  1.77785976e+01,  1.07263576e+02, -1.42230476e-01,
       -5.26589727e-02,  9.88431851e-01]), 'targetState': array([25., 25., 15.])}
episode index:569
target thresh 14.978031985307094
model initialize at round 569
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31453028226356705
{'scaleFactor': 20, 'currentState': array([ 2.50702184e+01,  2.15286961e+01,  1.05063117e+02,  1.66564247e-01,
       -4.81188209e-02,  9.84855792e-01]), 'targetState': array([25., 25., 15.])}
episode index:570
target thresh 14.986533757012898
model initialize at round 570
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31397944113876225
{'scaleFactor': 20, 'currentState': array([ 2.06022368e+01,  3.20904560e+01,  1.03163779e+02, -9.00917704e-02,
       -6.77840148e-02,  9.93624074e-01]), 'targetState': array([25., 25., 15.])}
episode index:571
target thresh 14.99503467858403
model initialize at round 571
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.96980682, 15.15372671,  0.98770943, -0.03012332,
        0.15337103]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31343052603187627
{'scaleFactor': 20, 'currentState': array([2.93359992e+01, 1.31833725e+01, 1.07025265e+02, 5.86126352e-03,
       1.83003644e-01, 9.83094762e-01]), 'targetState': array([25., 25., 15.])}
episode index:572
target thresh 15.00353475010552
model initialize at round 572
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15244236, 15.07800306,  0.98536825,  0.15172916,
        0.07763812]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3145431953579987
{'scaleFactor': 20, 'currentState': array([25.33321828, 20.09998749, 16.46452365,  0.57762892,  0.77203024,
        0.26516813]), 'targetState': array([25., 25., 15.])}
episode index:573
target thresh 15.012033971662342
model initialize at round 573
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.12925402,  0.98003543,  0.15217941,
        0.12795305]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31399521069709624
{'scaleFactor': 20, 'currentState': array([2.74432369e+01, 2.11443993e+01, 1.06634055e+02, 2.69577013e-02,
       1.49261058e-01, 9.88430280e-01]), 'targetState': array([25., 25., 15.])}
episode index:574
target thresh 15.02053234333951
model initialize at round 574
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31344913206979697
{'scaleFactor': 20, 'currentState': array([12.60480766, 22.32757582, 99.49514075, -0.29728652, -0.66957659,
        0.68065257]), 'targetState': array([25., 25., 15.])}
episode index:575
target thresh 15.029029865222011
model initialize at round 575
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31290494954884246
{'scaleFactor': 20, 'currentState': array([ 2.59333668e+01,  2.35360694e+01,  1.06298601e+02, -1.59703371e-01,
        7.29678614e-02,  9.84464588e-01]), 'targetState': array([25., 25., 15.])}
episode index:576
target thresh 15.037526537394786
model initialize at round 576
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.11295345,  0.98193685,  0.15247467,
        0.11203349]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3123626532757942
{'scaleFactor': 20, 'currentState': array([ 22.49719245,  31.20636305, 101.51923147,  -0.18280001,
         0.18066622,   0.96640772]), 'targetState': array([25., 25., 15.])}
episode index:577
target thresh 15.046022359942846
model initialize at round 577
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.50095825e+01, 1.51496837e+01, 9.88716965e-01,
       9.57008270e-03, 1.49489723e-01]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31182223346043814
{'scaleFactor': 20, 'currentState': array([ 3.23703986e+01,  2.10852787e+01,  1.04478871e+02,  9.68133263e-02,
       -4.25696210e-02,  9.94391778e-01]), 'targetState': array([25., 25., 15.])}
episode index:578
target thresh 15.054517332951123
model initialize at round 578
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.01912668,  0.98797784,  0.15341271,
        0.01908762]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.31290972554323704
{'scaleFactor': 20, 'currentState': array([25.88236043, 21.4491594 , 18.71616348,  0.36473963,  0.78978662,
        0.49315525]), 'targetState': array([25., 25., 15.])}
episode index:579
target thresh 15.063011456504572
model initialize at round 579
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.14932704,  0.97736114,  0.15176415,
        0.14742065]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3123702260164384
{'scaleFactor': 20, 'currentState': array([ 6.84226124e+00,  1.52675056e+01,  8.79011506e+01, -2.37999855e-02,
        1.14810644e-01,  9.93102249e-01]), 'targetState': array([25., 25., 15.])}
episode index:580
target thresh 15.071504730688135
model initialize at round 580
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.50098983e+01, 1.51537267e+01, 9.88109639e-01,
       9.87943458e-03, 1.53433174e-01]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3118325836308679
{'scaleFactor': 20, 'currentState': array([ 25.47390439,  20.96563916, 105.62070066,   0.10693931,
        -0.11668797,   0.9873945 ]), 'targetState': array([25., 25., 15.])}
episode index:581
target thresh 15.079997155586744
model initialize at round 581
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.14484996,  0.97798903,  0.15186165,
        0.1430926 ]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3112967888136327
{'scaleFactor': 20, 'currentState': array([1.68857028e+01, 2.19285736e+01, 1.00445237e+02, 1.30376941e-01,
       4.71817388e-02, 9.90341222e-01]), 'targetState': array([25., 25., 15.])}
episode index:582
target thresh 15.08848873128532
model initialize at round 582
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.12947502,  0.98000797,  0.15217515,
        0.12816823]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31076283205752014
{'scaleFactor': 20, 'currentState': array([ 8.15833447e+00,  1.75535973e+01,  9.39703877e+01,  2.67149070e-02,
       -2.06468160e-01,  9.78088551e-01]), 'targetState': array([25., 25., 15.])}
episode index:583
target thresh 15.096979457868787
model initialize at round 583
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.50158130e+01, 1.51537267e+01, 9.88034801e-01,
       1.57816319e-02, 1.53421553e-01]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31023070392043534
{'scaleFactor': 20, 'currentState': array([2.68860383e+01, 1.75506335e+01, 1.06299139e+02, 9.30980868e-02,
       1.29824897e-01, 9.87156645e-01]), 'targetState': array([25., 25., 15.])}
episode index:584
target thresh 15.10546933542205
model initialize at round 584
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30970039502484487
{'scaleFactor': 20, 'currentState': array([1.87232921e+01, 1.96824474e+01, 1.05243612e+02, 9.86779106e-02,
       1.15187658e-01, 9.88430308e-01]), 'targetState': array([25., 25., 15.])}
episode index:585
target thresh 15.113958364030012
model initialize at round 585
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.03952768,  0.98738966,  0.15332138,
        0.03942346]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.31079474597173085
{'scaleFactor': 20, 'currentState': array([25.15279579, 20.00961529, 17.03667522,  0.50231406,  0.71417116,
        0.48748347]), 'targetState': array([25., 25., 15.])}
episode index:586
target thresh 15.122446543777535
model initialize at round 586
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.51537267e+01, 1.50084022e+01, 9.88123114e-01,
       1.53435266e-01, 8.38629950e-03]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3102652830314042
{'scaleFactor': 20, 'currentState': array([ 8.14258249, 17.93582246, 96.51529134, -0.63055524, -0.6766978 ,
        0.38010548]), 'targetState': array([25., 25., 15.])}
episode index:587
target thresh 15.13093387474953
model initialize at round 587
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13094424, 14.89495684,  0.98592645,  0.13040544,
       -0.10461094]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3113387777021008
{'scaleFactor': 20, 'currentState': array([27.30466235, 20.32561838, 15.77300391,  0.55449533,  0.7182459 ,
        0.42030673]), 'targetState': array([25., 25., 15.])}
episode index:588
target thresh 15.139420357030875
model initialize at round 588
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.12589538,  0.9804472 ,  0.15224335,
        0.12468057]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3108101889453909
{'scaleFactor': 20, 'currentState': array([ 24.97936823,  25.16713883, 104.50055372,   0.30502727,
         0.29174124,   0.9065569 ]), 'targetState': array([25., 25., 15.])}
episode index:589
target thresh 15.147905990706423
model initialize at round 589
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.133063  ,  0.97955598,  0.15210497,
        0.13165925]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.31189523955717846
{'scaleFactor': 20, 'currentState': array([25.39325929, 20.09857465, 14.83479446,  0.63097073,  0.73555241,
       -0.2466548 ]), 'targetState': array([25., 25., 15.])}
episode index:590
target thresh 15.156390775861029
model initialize at round 590
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12704989, 14.86792871,  0.98329491,  0.12618941,
       -0.1311768 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.31296052705268407
{'scaleFactor': 20, 'currentState': array([26.50959404, 21.52775908, 13.20324112,  0.49299474,  0.86853831,
        0.05096467]), 'targetState': array([25., 25., 15.])}
episode index:591
target thresh 15.164874712579524
model initialize at round 591
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.12261839,  0.980839  ,  0.15230419,
        0.12148374]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31243187751374374
{'scaleFactor': 20, 'currentState': array([ 3.23753732e+01,  2.23469046e+01,  1.01682656e+02,  1.31408998e-01,
       -7.57446788e-02,  9.88430280e-01]), 'targetState': array([25., 25., 15.])}
episode index:592
target thresh 15.173357800946786
model initialize at round 592
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31190501094120787
{'scaleFactor': 20, 'currentState': array([ 21.52855287,  20.92557956, 106.29778014,  -0.44757979,
        -0.36074598,   0.81825099]), 'targetState': array([25., 25., 15.])}
episode index:593
target thresh 15.18184004104761
model initialize at round 593
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.04833226, 14.88224645,  0.99183565,  0.04842187,
       -0.11797188]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31137991833019574
{'scaleFactor': 20, 'currentState': array([30.50366081, 27.62313818, 96.7482074 , -0.10219991,  0.1120748 ,
        0.98843028]), 'targetState': array([25., 25., 15.])}
episode index:594
target thresh 15.190321432966847
model initialize at round 594
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3124389103151887
{'scaleFactor': 20, 'currentState': array([25.56960241, 21.42159274, 19.76759463,  0.35605148,  0.81006957,
        0.46584829]), 'targetState': array([25., 25., 15.])}
episode index:595
target thresh 15.198801976789289
model initialize at round 595
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.97248579,  0.98778543,  0.15338283,
       -0.02745266]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.31351030484469344
{'scaleFactor': 20, 'currentState': array([25.30459158, 20.10253786, 16.11385358,  0.55988988,  0.76222883,
        0.32485462]), 'targetState': array([25., 25., 15.])}
episode index:596
target thresh 15.207281672599748
model initialize at round 596
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.11277224,  0.98195661,  0.15247773,
        0.11185601]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31298516195550635
{'scaleFactor': 20, 'currentState': array([ 2.35747549e+01,  2.37683729e+01,  1.05810864e+02, -4.20150939e-02,
        2.35596989e-01,  9.70942218e-01]), 'targetState': array([25., 25., 15.])}
episode index:597
target thresh 15.215760520483034
model initialize at round 597
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.12464937,  0.98059734,  0.15226667,
        0.12346549]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31246177539705233
{'scaleFactor': 20, 'currentState': array([ 2.34144569e+01,  2.35557785e+01,  1.06052709e+02,  2.40658524e-02,
       -1.50566106e-01,  9.88306978e-01]), 'targetState': array([25., 25., 15.])}
episode index:598
target thresh 15.224238520523926
model initialize at round 598
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08113942, 15.15372671,  0.98493299,  0.08072414,
        0.15293991]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3119401363730172
{'scaleFactor': 20, 'currentState': array([ 2.85854016e+01,  1.91402577e+01,  1.06363627e+02, -1.35710398e-01,
       -5.36043252e-02,  9.89297359e-01]), 'targetState': array([25., 25., 15.])}
episode index:599
target thresh 15.232715672807185
model initialize at round 599
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.10652822,  0.9826187 ,  0.15258054,
        0.10573396]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31142023614572883
{'scaleFactor': 20, 'currentState': array([ 2.39027370e+01,  2.47573499e+01,  1.04873497e+02, -9.91128099e-02,
        1.14813902e-01,  9.88430280e-01]), 'targetState': array([25., 25., 15.])}
episode index:600
target thresh 15.241191977417612
model initialize at round 600
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3109020660356694
{'scaleFactor': 20, 'currentState': array([ 2.35182949e+01,  2.19331142e+01,  1.07222458e+02,  1.86975728e-01,
       -5.93388442e-02,  9.80570741e-01]), 'targetState': array([25., 25., 15.])}
episode index:601
target thresh 15.249667434439962
model initialize at round 601
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.10673842,  0.982597  ,  0.15257717,
        0.10594025]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.31194953793494734
{'scaleFactor': 20, 'currentState': array([25.42112281, 21.17526526, 19.86936246,  0.23325671,  0.64946046,
        0.72373504]), 'targetState': array([25., 25., 15.])}
episode index:602
target thresh 15.258142043958978
model initialize at round 602
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12364312, 15.15372671,  0.98071754,  0.12248381,
        0.15228533]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3114322086846406
{'scaleFactor': 20, 'currentState': array([ 25.15340494,  25.97677684, 105.39795195,  -0.47236517,
         0.36503894,   0.80225789]), 'targetState': array([25., 25., 15.])}
episode index:603
target thresh 15.266615806059413
model initialize at round 603
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.08741471,  0.98441782,  0.15285991,
        0.08692181]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3124753344143035
{'scaleFactor': 20, 'currentState': array([26.45173416, 20.52357874, 19.36993028,  0.73348786,  0.39763539,
        0.55125462]), 'targetState': array([25., 25., 15.])}
episode index:604
target thresh 15.275088720826012
model initialize at round 604
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.49196129e+01,  1.49944360e+01,  9.96703931e-01,
       -8.09314182e-02, -5.60168436e-03]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31195884625824677
{'scaleFactor': 20, 'currentState': array([41.69910519, 17.89235578, 14.34467982, -0.48385382, -0.36089024,
        0.79727268]), 'targetState': array([25., 25., 15.])}
episode index:605
target thresh 15.283560788343486
model initialize at round 605
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.03195318, 15.12197943,  0.99198597,  0.03201728,
        0.12222413]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3114440626835632
{'scaleFactor': 20, 'currentState': array([ 3.42154509e+01,  1.78230046e+01,  1.04608146e+02, -2.71513460e-02,
       -5.84052379e-02,  9.97923661e-01]), 'targetState': array([25., 25., 15.])}
episode index:606
target thresh 15.292032008696577
model initialize at round 606
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.1353891 , 15.15372671,  0.9792567 ,  0.13391988,
        0.15205849]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3109309752656332
{'scaleFactor': 20, 'currentState': array([ 20.65170768,  20.42344001, 105.75316586,   0.24989011,
        -0.39215031,   0.88530959]), 'targetState': array([25., 25., 15.])}
episode index:607
target thresh 15.300502381969993
model initialize at round 607
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.05082437,  0.98688879,  0.1532436 ,
        0.05066465]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.31196806272309263
{'scaleFactor': 20, 'currentState': array([25.92271469, 21.50014935, 18.59081925,  0.36905922,  0.78453618,
        0.49829536]), 'targetState': array([25., 25., 15.])}
episode index:608
target thresh 15.308971908248425
model initialize at round 608
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.13809241,  0.97890272,  0.15200353,
        0.13654448]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3114557998943191
{'scaleFactor': 20, 'currentState': array([ 31.61026718,  22.08436369, 105.29281901,   0.11629032,
        -0.12161267,   0.98574181]), 'targetState': array([25., 25., 15.])}
episode index:609
target thresh 15.31744058761657
model initialize at round 609
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.04701417,  0.98707164,  0.15327199,
        0.0468751 ]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.3124731925959792
{'scaleFactor': 20, 'currentState': array([29.10240041, 20.35362337, 18.92185916,  0.62126122,  0.54402363,
        0.56397942]), 'targetState': array([25., 25., 15.])}
episode index:610
target thresh 15.325908420159129
model initialize at round 610
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13695794, 15.15372671,  0.97905207,  0.13544339,
        0.15202672]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31196177984213963
{'scaleFactor': 20, 'currentState': array([2.82975446e+01, 1.95500905e+01, 1.06851249e+02, 1.30658701e-02,
       1.66568712e-02, 9.99775891e-01]), 'targetState': array([25., 25., 15.])}
episode index:611
target thresh 15.334375405960754
model initialize at round 611
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.49964061e+01,  1.51537267e+01,  9.88151506e-01,
       -3.58720641e-03,  1.53439675e-01]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31145203837180935
{'scaleFactor': 20, 'currentState': array([ 2.75970639e+01,  1.66465539e+01,  1.06588554e+02, -1.17136986e-01,
       -9.63552954e-02,  9.88430364e-01]), 'targetState': array([25., 25., 15.])}
episode index:612
target thresh 15.342841545106156
model initialize at round 612
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31094396000578683
{'scaleFactor': 20, 'currentState': array([ 2.61092619e+01,  1.77564711e+01,  1.06096284e+02,  1.40917343e-01,
       -7.56999050e-02,  9.87123005e-01]), 'targetState': array([25., 25., 15.])}
episode index:613
target thresh 15.351306837679957
model initialize at round 613
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.13710224,  0.97903314,  0.15202378,
        0.13558348]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31043753661815526
{'scaleFactor': 20, 'currentState': array([ 2.50719868e+01,  2.30206920e+01,  1.05988537e+02, -1.00898228e-02,
       -2.13060200e-01,  9.76986974e-01]), 'targetState': array([25., 25., 15.])}
episode index:614
target thresh 15.359771283766833
model initialize at round 614
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.51537267e+01, 1.50101441e+01, 9.88107214e-01,
       1.53432797e-01, 1.01247149e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3114790854202396
{'scaleFactor': 20, 'currentState': array([25.39603455, 20.17084486, 15.10107329,  0.58827209,  0.78160847,
        0.20742266]), 'targetState': array([25., 25., 15.])}
episode index:615
target thresh 15.368234883451425
model initialize at round 615
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3109734375542977
{'scaleFactor': 20, 'currentState': array([ 2.36468577e+01,  1.89111589e+01,  1.05413870e+02, -1.01559036e-01,
       -1.12744071e-01,  9.88420223e-01]), 'targetState': array([25., 25., 15.])}
episode index:616
target thresh 15.37669763681835
model initialize at round 616
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3104694287414058
{'scaleFactor': 20, 'currentState': array([2.19096256e+01, 2.83899975e+01, 1.05106656e+02, 1.26510286e-01,
       8.36640206e-02, 9.88430817e-01]), 'targetState': array([25., 25., 15.])}
episode index:617
target thresh 15.385159543952264
model initialize at round 617
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3115058698759667
{'scaleFactor': 20, 'currentState': array([25.12004429, 20.0920095 , 17.51329992,  0.53283445,  0.7473793 ,
        0.39687735]), 'targetState': array([25., 25., 15.])}
episode index:618
target thresh 15.393620604937762
model initialize at round 618
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.13101907,  0.9798149 ,  0.15214517,
        0.12967115]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3110026293753593
{'scaleFactor': 20, 'currentState': array([ 25.43774675,  19.37111273, 105.88251705,   0.23680337,
        -0.15751847,   0.95870334]), 'targetState': array([25., 25., 15.])}
episode index:619
target thresh 15.402080819859476
model initialize at round 619
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13420443, 15.04669612,  0.98985581,  0.13418488,
        0.04668931]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31050101223120546
{'scaleFactor': 20, 'currentState': array([ 29.96626068,  19.12469228, 103.03166678,   0.17177426,
         0.11311464,   0.97862081]), 'targetState': array([25., 25., 15.])}
episode index:620
target thresh 15.410540188802003
model initialize at round 620
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.51537267e+01, 1.50009219e+01, 9.88157445e-01,
       1.53440597e-01, 9.20156149e-04]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.311517081695247
{'scaleFactor': 20, 'currentState': array([25.80147039, 21.33324245, 18.61520421,  0.28517458,  0.68886284,
        0.66644088]), 'targetState': array([25., 25., 15.])}
episode index:621
target thresh 15.418998711849907
model initialize at round 621
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.04210785, 15.15372671,  0.98728624,  0.04199242,
        0.15330532]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3110162503741935
{'scaleFactor': 20, 'currentState': array([ 2.21496558e+01,  1.57222686e+01,  1.05485372e+02,  1.66344460e-01,
       -4.94321420e-02,  9.84827896e-01]), 'targetState': array([25., 25., 15.])}
episode index:622
target thresh 15.427456389087823
model initialize at round 622
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31051702685834404
{'scaleFactor': 20, 'currentState': array([ 2.16975279e+01,  2.12361567e+01,  1.06763115e+02, -1.90350722e-03,
        6.01394064e-02,  9.98188173e-01]), 'targetState': array([25., 25., 15.])}
episode index:623
target thresh 15.435913220600284
model initialize at round 623
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.91918095, 15.15366552,  0.98496745, -0.08040821,
        0.15288438]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31001940341786594
{'scaleFactor': 20, 'currentState': array([2.75172276e+01, 1.11004965e+01, 1.07528803e+02, 3.29167359e-02,
       2.23988263e-02, 9.99207076e-01]), 'targetState': array([25., 25., 15.])}
episode index:624
target thresh 15.444369206471887
model initialize at round 624
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.02518704, 15.15372671,  0.98784574,  0.02513223,
        0.1533922 ]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30952337237239735
{'scaleFactor': 20, 'currentState': array([ 26.39347397,  26.31042807, 105.16350135,  -0.2627844 ,
         0.30819214,   0.91430956]), 'targetState': array([25., 25., 15.])}
episode index:625
target thresh 15.452824346787175
model initialize at round 625
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.04201048, 15.05156484,  0.99775079,  0.04233939,
        0.05196854]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3090289260906523
{'scaleFactor': 20, 'currentState': array([ 2.31972095e+01,  1.94818014e+01,  1.03664466e+02, -5.17524050e-02,
        6.83139829e-02,  9.96320675e-01]), 'targetState': array([25., 25., 15.])}
episode index:626
target thresh 15.461278641630717
model initialize at round 626
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09806842, 14.94258828,  0.99347653,  0.09841281,
       -0.05761333]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3085360569900293
{'scaleFactor': 20, 'currentState': array([ 3.21506749e+01,  2.27120452e+01,  9.89587948e+01, -7.02845249e-02,
       -1.35028339e-01,  9.88345806e-01]), 'targetState': array([25., 25., 15.])}
episode index:627
target thresh 15.46973209108703
model initialize at round 627
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.1042073 ,  0.98285551,  0.15261732,
        0.10345527]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.30955907290230633
{'scaleFactor': 20, 'currentState': array([25.38325541, 20.17981587, 15.37300616,  0.60177513,  0.79819186,
       -0.0275035 ]), 'targetState': array([25., 25., 15.])}
episode index:628
target thresh 15.478184695240671
model initialize at round 628
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.98180998,  0.98799503,  0.15341538,
       -0.01815318]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3105637169030992
{'scaleFactor': 20, 'currentState': array([26.97617865, 21.25874856, 15.99043939,  0.5653636 ,  0.78271081,
        0.26024561]), 'targetState': array([25., 25., 15.])}
episode index:629
target thresh 15.48663645417616
model initialize at round 629
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.12746317,  0.98025627,  0.15221371,
        0.12620866]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3100707586223006
{'scaleFactor': 20, 'currentState': array([ 2.81735465e+01,  1.69293718e+01,  1.06690841e+02, -7.38423055e-02,
        1.28597112e-01,  9.88943930e-01]), 'targetState': array([25., 25., 15.])}
episode index:630
target thresh 15.49508736797801
model initialize at round 630
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14131847, 15.1461972 ,  0.97955269,  0.13982716,
        0.14465441]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30957936280831916
{'scaleFactor': 20, 'currentState': array([ 2.86686985e+01,  2.58959977e+01,  1.04887169e+02, -1.50693863e-01,
        1.72323095e-02,  9.88430274e-01]), 'targetState': array([25., 25., 15.])}
episode index:631
target thresh 15.50353743673073
model initialize at round 631
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30908952204438195
{'scaleFactor': 20, 'currentState': array([ 2.33755451e+01,  2.55482359e+01,  1.04291429e+02, -1.79718436e-02,
        2.55618136e-02,  9.99511684e-01]), 'targetState': array([25., 25., 15.])}
episode index:632
target thresh 15.51198666051883
model initialize at round 632
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09163212, 15.15372671,  0.98405053,  0.09108146,
        0.15280288]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30860122896058356
{'scaleFactor': 20, 'currentState': array([ 2.40893936e+01,  2.17199317e+01,  1.07399090e+02, -7.94069544e-03,
       -1.32076445e-01,  9.91207727e-01]), 'targetState': array([25., 25., 15.])}
episode index:633
target thresh 15.520435039426793
model initialize at round 633
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.02835077, 15.06327795,  0.99755624,  0.02856716,
        0.06376093]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3081144762335164
{'scaleFactor': 20, 'currentState': array([ 3.27794290e+01,  2.15694165e+01,  1.03943063e+02, -1.52718954e-01,
        1.80748391e-03,  9.88268007e-01]), 'targetState': array([25., 25., 15.])}
episode index:634
target thresh 15.528882573539104
model initialize at round 634
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.91683935, 15.15372671,  0.98477116, -0.08272143,
        0.15291478]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30762925658590456
{'scaleFactor': 20, 'currentState': array([ 2.90165526e+01,  1.19297096e+01,  1.06395844e+02, -1.33002775e-01,
        3.21578336e-02,  9.90593830e-01]), 'targetState': array([25., 25., 15.])}
episode index:635
target thresh 15.537329262940236
model initialize at round 635
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.05876091, 15.15372671,  0.9864626 ,  0.05855095,
        0.15317742]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30714556278624117
{'scaleFactor': 20, 'currentState': array([3.40981860e+00, 3.51306078e+01, 4.57544450e+01, 1.41578821e-02,
       1.61898867e-01, 9.86705788e-01]), 'targetState': array([25., 25., 15.])}
episode index:636
target thresh 15.545775107714665
model initialize at round 636
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12397262, 15.15372671,  0.98067828,  0.12280531,
        0.15227924]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3066633876484292
{'scaleFactor': 20, 'currentState': array([ 2.48264833e+01,  3.81649692e+01,  9.74949426e+01,  2.78345646e-02,
       -1.12847591e-01,  9.93222361e-01]), 'targetState': array([25., 25., 15.])}
episode index:637
target thresh 15.554220107946836
model initialize at round 637
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.02309325, 15.15372671,  0.98789546,  0.02304416,
        0.15339992]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30618272403142544
{'scaleFactor': 20, 'currentState': array([ 2.47093957e+01,  2.30902536e+01,  1.04799669e+02,  2.66326044e-02,
       -1.50612180e-01,  9.88234120e-01]), 'targetState': array([25., 25., 15.])}
episode index:638
target thresh 15.562664263721226
model initialize at round 638
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3071769297049302
{'scaleFactor': 20, 'currentState': array([26.01655017, 21.02823143, 19.5674248 ,  0.42170091,  0.78805009,
        0.44849236]), 'targetState': array([25., 25., 15.])}
episode index:639
target thresh 15.571107575122245
model initialize at round 639
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14786375, 15.02212598,  0.98878787,  0.14768271,
        0.02209889]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3081680284857053
{'scaleFactor': 20, 'currentState': array([25.65212224, 20.94405289, 19.5523482 ,  0.27457839,  0.62282405,
        0.73259601]), 'targetState': array([25., 25., 15.])}
episode index:640
target thresh 15.579550042234347
model initialize at round 640
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.05787343, 15.15372671,  0.9865133 ,  0.05766961,
        0.15318529]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3076872671308134
{'scaleFactor': 20, 'currentState': array([2.44946960e+01, 2.23745822e+01, 1.07147514e+02, 1.48887837e-01,
       2.89481126e-02, 9.88430280e-01]), 'targetState': array([25., 25., 15.])}
episode index:641
target thresh 15.587991665141942
model initialize at round 641
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3072080034748464
{'scaleFactor': 20, 'currentState': array([2.39202959e+01, 2.60889253e+01, 1.06176700e+02, 1.34743648e-01,
       6.96400058e-02, 9.88430280e-01]), 'targetState': array([25., 25., 15.])}
episode index:642
target thresh 15.596432443929453
model initialize at round 642
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30673023053009546
{'scaleFactor': 20, 'currentState': array([20.78564755,  5.79080415, 86.91577523,  0.15376024, -0.77634061,
        0.61127167]), 'targetState': array([25., 25., 15.])}
episode index:643
target thresh 15.60487237868129
model initialize at round 643
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.51418875e+01,  1.49849051e+01,  9.89772413e-01,
        1.41854922e-01, -1.50914516e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.30771586705008136
{'scaleFactor': 20, 'currentState': array([26.34416298, 21.50200569, 17.07911295,  0.39550742,  0.77159579,
        0.49821062]), 'targetState': array([25., 25., 15.])}
episode index:644
target thresh 15.61331146948185
model initialize at round 644
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.1248506 ,  0.98057318,  0.15226292,
        0.12366177]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30723878818643785
{'scaleFactor': 20, 'currentState': array([2.47045181e+01, 2.30554084e+01, 1.06474389e+02, 1.72538631e-01,
       5.75783304e-02, 9.83318441e-01]), 'targetState': array([25., 25., 15.])}
episode index:645
target thresh 15.621749716415522
model initialize at round 645
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30676318634713995
{'scaleFactor': 20, 'currentState': array([2.39812555e+01, 2.54827609e+01, 1.05563261e+02, 1.02492672e-02,
       2.64760410e-02, 9.99596905e-01]), 'targetState': array([25., 25., 15.])}
episode index:646
target thresh 15.630187119566695
model initialize at round 646
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.96314725, 15.15372671,  0.98749002, -0.03675931,
        0.15333696]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3062890546835431
{'scaleFactor': 20, 'currentState': array([2.79728946e+01, 1.39263946e+01, 1.04608425e+02, 4.80212104e-01,
       4.86505119e-02, 8.75802182e-01]), 'targetState': array([25., 25., 15.])}
episode index:647
target thresh 15.638623679019737
model initialize at round 647
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.06861436,  0.98584854,  0.15308207,
        0.06832664]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3072692878544034
{'scaleFactor': 20, 'currentState': array([25.49579203, 21.2042673 , 19.8233409 ,  0.30844004,  0.65861362,
        0.68636203]), 'targetState': array([25., 25., 15.])}
episode index:648
target thresh 15.647059394859008
model initialize at round 648
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.06481274, 15.15372671,  0.98609658,  0.06455719,
        0.15312059]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30679583748790973
{'scaleFactor': 20, 'currentState': array([1.51534019e+01, 3.33384549e+01, 1.01170797e+02, 1.71001535e-02,
       3.26084424e-02, 9.99321907e-01]), 'targetState': array([25., 25., 15.])}
episode index:649
target thresh 15.65549426716888
model initialize at round 649
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.02708657, 15.10326092,  0.99423627,  0.02720247,
        0.10370278]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3063238438917745
{'scaleFactor': 20, 'currentState': array([ 28.3116213 ,  16.88885396, 106.80322314,   0.26547187,
        -0.33347048,   0.90461159]), 'targetState': array([25., 25., 15.])}
episode index:650
target thresh 15.663928296033692
model initialize at round 650
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.90600903,  0.98383775,  0.15276984,
       -0.09340592]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3072995064194385
{'scaleFactor': 20, 'currentState': array([27.47604773, 20.11410942, 12.16296143,  0.74679705,  0.65493235,
       -0.1155759 ]), 'targetState': array([25., 25., 15.])}
episode index:651
target thresh 15.672361481537777
model initialize at round 651
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30682818815805896
{'scaleFactor': 20, 'currentState': array([ 6.1663473 , 14.83915373, 87.95574684,  0.18507294, -0.7952463 ,
        0.57734853]), 'targetState': array([25., 25., 15.])}
episode index:652
target thresh 15.680793823765493
model initialize at round 652
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.51537267e+01,  1.49897631e+01,  9.88106283e-01,
        1.53432653e-01, -1.02173198e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.30780009008951825
{'scaleFactor': 20, 'currentState': array([26.68635654, 21.03779724, 17.84704295,  0.56152377,  0.76095961,
        0.32501005]), 'targetState': array([25., 25., 15.])}
episode index:653
target thresh 15.689225322801137
model initialize at round 653
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.94365072,  0.98659858,  0.15319854,
       -0.05615568]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3087835609760787
{'scaleFactor': 20, 'currentState': array([25.31939663, 20.14905333, 13.64228431,  0.58636282,  0.78942514,
       -0.18162213]), 'targetState': array([25., 25., 15.])}
episode index:654
target thresh 15.697655978729042
model initialize at round 654
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.51537267e+01, 1.50106513e+01, 9.88102023e-01,
       1.53431991e-01, 1.06308793e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.30976402889809995
{'scaleFactor': 20, 'currentState': array([25.40810009, 20.15231134, 15.50396034,  0.60023807,  0.78528664,
        0.15178652]), 'targetState': array([25., 25., 15.])}
episode index:655
target thresh 15.706085791633484
model initialize at round 655
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.07486845,  0.98541021,  0.15301401,
        0.07452135]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3092918276345358
{'scaleFactor': 20, 'currentState': array([ 17.87591831,  16.25934163, 103.54056361,  -0.22654725,
        -0.67026246,   0.70669977]), 'targetState': array([25., 25., 15.])}
episode index:656
target thresh 15.714514761598808
model initialize at round 656
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.50014639e+01,  1.48474753e+01,  9.88338066e-01,
        1.46142309e-03, -1.52268618e-01]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30882106381774044
{'scaleFactor': 20, 'currentState': array([3.73453335e+00, 1.94147629e+01, 4.44784608e+01, 1.18664136e-02,
       1.44623767e-01, 9.89415562e-01]), 'targetState': array([25., 25., 15.])}
episode index:657
target thresh 15.722942888709268
model initialize at round 657
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30835173089400525
{'scaleFactor': 20, 'currentState': array([ 2.38877236e+01,  2.19478534e+01,  1.06874178e+02, -1.58127973e-02,
        8.15484930e-02,  9.96543927e-01]), 'targetState': array([25., 25., 15.])}
episode index:658
target thresh 15.731370173049154
model initialize at round 658
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.04359317, 15.15372671,  0.98722375,  0.04347092,
        0.15329561]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3078838223494013
{'scaleFactor': 20, 'currentState': array([ 2.63330581e+01,  2.15848755e+01,  1.07336891e+02, -1.55152702e-01,
       -7.84995540e-02,  9.84766703e-01]), 'targetState': array([25., 25., 15.])}
episode index:659
target thresh 15.739796614702751
model initialize at round 659
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09523836, 15.04203542,  0.99451675,  0.09567287,
        0.0422272 ]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.307417331709478
{'scaleFactor': 20, 'currentState': array([ 3.34276095e+01,  1.24586791e+01,  1.01933331e+02, -1.50955323e-01,
        5.59704640e-02,  9.86954810e-01]), 'targetState': array([25., 25., 15.])}
episode index:660
target thresh 15.748222213754303
model initialize at round 660
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.05254689,  0.98680149,  0.15323005,
        0.05237712]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3069522525389644
{'scaleFactor': 20, 'currentState': array([35.16678198, 35.45270278, 88.65175091,  0.19204123,  0.19896948,
        0.96100536]), 'targetState': array([25., 25., 15.])}
episode index:661
target thresh 15.75664697028808
model initialize at round 661
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.8945463 ,  0.98272896,  0.15259767,
       -0.1046792 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3079107538937409
{'scaleFactor': 20, 'currentState': array([26.36049303, 20.42434889, 10.26945491,  0.64193303,  0.37677424,
       -0.66780473]), 'targetState': array([25., 25., 15.])}
episode index:662
target thresh 15.765070884388322
model initialize at round 662
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.89284019, 14.96932522,  0.99372142, -0.10756262,
       -0.03079009]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30744633345046224
{'scaleFactor': 20, 'currentState': array([ 1.28153733e+01,  3.24637667e+01,  4.49767173e+01, -1.50835335e-01,
        1.76661152e-02,  9.88401037e-01]), 'targetState': array([25., 25., 15.])}
episode index:663
target thresh 15.773493956139284
model initialize at round 663
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.03961966,  0.98738609,  0.15332082,
        0.03951505]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.308401203655207
{'scaleFactor': 20, 'currentState': array([26.6196396 , 21.44236591, 13.11326659,  0.52838002,  0.78936716,
       -0.31259245]), 'targetState': array([25., 25., 15.])}
episode index:664
target thresh 15.781916185625178
model initialize at round 664
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.11058363,  0.98219282,  0.15251441,
        0.10971157]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3093675026721165
{'scaleFactor': 20, 'currentState': array([25.16982777, 20.09659275, 17.20929239,  0.56500033,  0.7818805 ,
        0.26350997]), 'targetState': array([25., 25., 15.])}
episode index:665
target thresh 15.790337572930223
model initialize at round 665
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.50976583e+01,  1.49937138e+01,  9.95149961e-01,
        9.81663214e-02, -6.31890318e-03]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.31031662076029803
{'scaleFactor': 20, 'currentState': array([27.34159662, 20.1959547 , 13.05555947,  0.66465975,  0.56346123,
       -0.49065146]), 'targetState': array([25., 25., 15.])}
episode index:666
target thresh 15.798758118138656
model initialize at round 666
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.04822803, 14.86805137,  0.990081  ,  0.04823198,
       -0.13195943]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.3112487777725119
{'scaleFactor': 20, 'currentState': array([28.66996744, 20.26484079, 10.84901025,  0.47174204,  0.72261637,
       -0.50525739]), 'targetState': array([25., 25., 15.])}
episode index:667
target thresh 15.807177821334673
model initialize at round 667
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.51537267e+01,  1.49842269e+01,  9.88035422e-01,
        1.53421649e-01, -1.57417529e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3121922379096803
{'scaleFactor': 20, 'currentState': array([25.74509338, 21.30441648, 11.17338484,  0.27615104,  0.68158511,
       -0.67762994]), 'targetState': array([25., 25., 15.])}
episode index:668
target thresh 15.81559668260245
model initialize at round 668
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31172558284554025
{'scaleFactor': 20, 'currentState': array([31.82071445, 56.51232341, 41.02765876, -0.32802353,  0.18795389,
        0.92578286]), 'targetState': array([25., 25., 15.])}
episode index:669
target thresh 15.824014702026211
model initialize at round 669
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3112603207815917
{'scaleFactor': 20, 'currentState': array([19.36667344, -3.95088817, 26.67962212,  0.55724115,  0.63018104,
       -0.54069784]), 'targetState': array([25., 25., 15.])}
episode index:670
target thresh 15.832431879690102
model initialize at round 670
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.0566267 , 14.84627329,  0.98658322,  0.05643127,
       -0.15319615]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31079644548981583
{'scaleFactor': 20, 'currentState': array([44.19524645, 41.35448746, 40.65573281, -0.55986744,  0.76748682,
        0.3122698 ]), 'targetState': array([25., 25., 15.])}
episode index:671
target thresh 15.840848215678328
model initialize at round 671
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.9657229 ,  0.98758003,  0.15335094,
       -0.03419331]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.31172095278507944
{'scaleFactor': 20, 'currentState': array([28.74491967, 20.44872139, 10.70561779,  0.46931796,  0.56923373,
       -0.67506564]), 'targetState': array([25., 25., 15.])}
episode index:672
target thresh 15.849263710075023
model initialize at round 672
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12144328, 14.84627329,  0.98097709,  0.12033644,
       -0.15232563]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31125777157737505
{'scaleFactor': 20, 'currentState': array([14.01220488, 49.12921832, 18.82477734, -0.75553408,  0.56045398,
        0.33920435]), 'targetState': array([25., 25., 15.])}
episode index:673
target thresh 15.857678362964355
model initialize at round 673
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.92817046,  0.9856279 ,  0.15304781,
       -0.07151232]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.31219281961568907
{'scaleFactor': 20, 'currentState': array([26.44183542, 21.06615753, 11.85931794,  0.43425267,  0.7788458 ,
       -0.45257468]), 'targetState': array([25., 25., 15.])}
episode index:674
target thresh 15.866092174430479
model initialize at round 674
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.97280055,  0.9877939 ,  0.15338415,
       -0.02713883]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.31313918588277695
{'scaleFactor': 20, 'currentState': array([25.3580502 , 20.0551112 , 13.51908038,  0.59484974,  0.76221744,
       -0.25530054]), 'targetState': array([25., 25., 15.])}
episode index:675
target thresh 15.874505144557528
model initialize at round 675
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09859342, 14.93571829,  0.99300701,  0.09889288,
       -0.06447696]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31267596223502137
{'scaleFactor': 20, 'currentState': array([ 39.81849878, -14.83350673, -47.30069557,  -0.42751122,
         0.06371667,  -0.9017618 ]), 'targetState': array([25., 25., 15.])}
episode index:676
target thresh 15.882917273429609
model initialize at round 676
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.91484233,  0.98460744,  0.15288935,
       -0.08469382]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3122141070470819
{'scaleFactor': 20, 'currentState': array([12.12870158, 26.27411794, -1.57476551,  0.53268828,  0.48636247,
        0.69259999]), 'targetState': array([25., 25., 15.])}
episode index:677
target thresh 15.89132856113088
model initialize at round 677
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.03395067, 14.84909305,  0.98801335,  0.03388254,
       -0.15060412]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31175361426382664
{'scaleFactor': 20, 'currentState': array([ 72.3306329 ,  40.95898124, -50.3284867 ,   0.24537492,
         0.81955623,  -0.51780183]), 'targetState': array([25., 25., 15.])}
episode index:678
target thresh 15.899739007745428
model initialize at round 678
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.92898695,  0.98568487,  0.15305666,
       -0.07070352]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3126810465688888
{'scaleFactor': 20, 'currentState': array([26.32591874, 20.31858818, 10.36713238,  0.40205897,  0.63509545,
       -0.65954708]), 'targetState': array([25., 25., 15.])}
episode index:679
target thresh 15.908148613357353
model initialize at round 679
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86066302,  0.97873753,  0.15197788,
       -0.13775185]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31222122150040515
{'scaleFactor': 20, 'currentState': array([ 7.09812921, 22.84317055, 53.90076943, -0.40165194,  0.45580983,
        0.79430039]), 'targetState': array([25., 25., 15.])}
episode index:680
target thresh 15.916557378050777
model initialize at round 680
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.51537267e+01,  1.49829697e+01,  9.88015129e-01,
        1.53418498e-01, -1.69961769e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.313145243420964
{'scaleFactor': 20, 'currentState': array([25.32660424, 21.10105372, 10.08958521,  0.2176335 ,  0.63667563,
       -0.73978362]), 'targetState': array([25., 25., 15.])}
episode index:681
target thresh 15.924965301909777
model initialize at round 681
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86075736,  0.9787501 ,  0.15197983,
       -0.13766036]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3126860861725462
{'scaleFactor': 20, 'currentState': array([-20.63034111,  36.10637594,  37.77994261,  -0.43541835,
         0.18395082,   0.88123377]), 'targetState': array([25., 25., 15.])}
episode index:682
target thresh 15.93337238501842
model initialize at round 682
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13528459, 14.84627329,  0.97927025,  0.13381836,
       -0.1520606 ]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3122282734548704
{'scaleFactor': 20, 'currentState': array([ 28.21140795,  12.45467438, -72.59340126,  -0.35018139,
        -0.35331057,  -0.86749331]), 'targetState': array([25., 25., 15.])}
episode index:683
target thresh 15.9417786274608
model initialize at round 683
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.91346745, 14.94884274,  0.99488446, -0.08695949,
       -0.05140966]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31177179937087207
{'scaleFactor': 20, 'currentState': array([ -2.62911117,  36.3017744 , -37.03409993,  -0.59133858,
         0.7247185 ,   0.35369731]), 'targetState': array([25., 25., 15.])}
episode index:684
target thresh 15.950184029320946
model initialize at round 684
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.93654686, 14.84627329,  0.98618189, -0.06320842,
       -0.15313383]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3113166580579219
{'scaleFactor': 20, 'currentState': array([ 32.91166713,   4.09822181, -68.21824369,   0.38273638,
         0.24483492,  -0.89082474]), 'targetState': array([25., 25., 15.])}
episode index:685
target thresh 15.958588590682943
model initialize at round 685
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3122352637304337
{'scaleFactor': 20, 'currentState': array([25.87556767, 21.03054016, 10.02451415,  0.46888296,  0.65304364,
       -0.59471234]), 'targetState': array([25., 25., 15.])}
episode index:686
target thresh 15.966992311630834
model initialize at round 686
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3117807728079731
{'scaleFactor': 20, 'currentState': array([ 10.6937487 ,  11.91647434, -61.53131575,  -0.37908501,
        -0.8014743 ,   0.46252946]), 'targetState': array([25., 25., 15.])}
episode index:687
target thresh 15.975395192248632
model initialize at round 687
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.9720511 ,  0.98777358,  0.15338099,
       -0.02788605]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.31270985605956036
{'scaleFactor': 20, 'currentState': array([25.35730423, 20.03339439, 13.53301379,  0.57444028,  0.73935146,
       -0.35125175]), 'targetState': array([25., 25., 15.])}
episode index:688
target thresh 15.98379723262039
model initialize at round 688
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86421721,  0.97920556,  0.15205055,
       -0.13430228]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3122559956008382
{'scaleFactor': 20, 'currentState': array([ 30.51180969,  24.60877958, -30.67372959,  -0.53772662,
         0.80660771,  -0.24542632]), 'targetState': array([25., 25., 15.])}
episode index:689
target thresh 15.992198432830108
model initialize at round 689
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.065822  , 14.84627329,  0.98603209,  0.06555819,
       -0.15311057]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.3131542700244703
{'scaleFactor': 20, 'currentState': array([28.95681796, 20.22269907, 10.3845893 ,  0.63864952,  0.49156236,
       -0.59202469]), 'targetState': array([25., 25., 15.])}
episode index:690
target thresh 16.000598792961817
model initialize at round 690
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08859303, 14.86183396,  0.98653419,  0.08828288,
       -0.13768235]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3127010800533785
{'scaleFactor': 20, 'currentState': array([22.47484205, 38.96752606, -6.96913074,  0.3662904 ,  0.88232172,
        0.29553296]), 'targetState': array([25., 25., 15.])}
episode index:691
target thresh 16.00899831309952
model initialize at round 691
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14552243, 14.88244705,  0.98261129,  0.14443635,
       -0.11667561]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.3135961151225311
{'scaleFactor': 20, 'currentState': array([29.25007051, 20.9188731 , 12.13343457,  0.64821481,  0.73269252,
       -0.20731433]), 'targetState': array([25., 25., 15.])}
episode index:692
target thresh 16.017396993327203
model initialize at round 692
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.97237474,  0.98778242,  0.15338236,
       -0.02756338]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3145021526900325
{'scaleFactor': 20, 'currentState': array([26.70033915, 21.5842713 , 14.42213036,  0.49526485,  0.84509982,
       -0.20129338]), 'targetState': array([25., 25., 15.])}
episode index:693
target thresh 16.025794833728845
model initialize at round 693
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31404897955935523
{'scaleFactor': 20, 'currentState': array([24.48747569, 26.61669101, -8.613296  , -0.11723184, -0.14866278,
       -0.98191449]), 'targetState': array([25., 25., 15.])}
episode index:694
target thresh 16.034191834388444
model initialize at round 694
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31359711052401806
{'scaleFactor': 20, 'currentState': array([ 3.78027130e+01,  2.71473462e+00, -1.28251394e+01, -2.73500445e-02,
       -1.51246196e-01, -9.88117687e-01]), 'targetState': array([25., 25., 15.])}
episode index:695
target thresh 16.042587995389958
model initialize at round 695
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09911137, 14.86590241,  0.98610996,  0.09872193,
       -0.13357068]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.31449924132700224
{'scaleFactor': 20, 'currentState': array([26.65829864, 20.00203407, 10.42210566,  0.55192882,  0.74237471,
       -0.37980833]), 'targetState': array([25., 25., 15.])}
episode index:696
target thresh 16.05098331681736
model initialize at round 696
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.04199853,  0.98729075,  0.15330602,
        0.04188359]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.31539878351936096
{'scaleFactor': 20, 'currentState': array([26.49494278, 21.36351461, 17.86064221,  0.52497334,  0.82512646,
        0.20873262]), 'targetState': array([25., 25., 15.])}
episode index:697
target thresh 16.05937779875457
model initialize at round 697
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12263125, 14.89464288,  0.98692629,  0.12225051,
       -0.10503001]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3149469227979865
{'scaleFactor': 20, 'currentState': array([ 47.19496896,  -0.95598303, -40.33429878,   0.81549583,
         0.12109205,  -0.56595341]), 'targetState': array([25., 25., 15.])}
episode index:698
target thresh 16.067771441285583
model initialize at round 698
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14567345, 15.04777104,  0.9882214 ,  0.14541174,
        0.04768522]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.31584325073304087
{'scaleFactor': 20, 'currentState': array([25.92730117, 21.45649098, 18.63575069,  0.38055058,  0.81253529,
        0.44155143]), 'targetState': array([25., 25., 15.])}
episode index:699
target thresh 16.076164244494294
model initialize at round 699
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.96239103,  0.98746235,  0.15333266,
       -0.03751256]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.316737017731138
{'scaleFactor': 20, 'currentState': array([27.34789614, 20.46680333, 12.90766867,  0.69199645,  0.65168815,
       -0.3105535 ]), 'targetState': array([25., 25., 15.])}
episode index:700
target thresh 16.08455620846465
model initialize at round 700
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.50015528e+01,  1.49789162e+01,  9.99772072e-01,
        1.56812392e-03, -2.12918855e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.3176148042221164
{'scaleFactor': 20, 'currentState': array([28.83510097, 20.26501407, 11.93666172,  0.46848505,  0.72233582,
       -0.50867743]), 'targetState': array([25., 25., 15.])}
episode index:701
target thresh 16.092947333280584
model initialize at round 701
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.94599116,  0.98672514,  0.15321819,
       -0.05383018]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31716236148105925
{'scaleFactor': 20, 'currentState': array([-5.71445657e+00,  3.47893378e+01, -2.41844119e+01,  1.55374725e-01,
        2.45690197e-02,  9.87550028e-01]), 'targetState': array([25., 25., 15.])}
episode index:702
target thresh 16.10133761902598
model initialize at round 702
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.50246362e+01,  1.49910304e+01,  9.99649508e-01,
        2.48763375e-02, -9.05701739e-03]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3167112059170748
{'scaleFactor': 20, 'currentState': array([ 3.10651999e+01,  4.15851298e+01,  2.55808813e+01,  1.57180190e-01,
       -1.22746035e-02,  9.87493657e-01]), 'targetState': array([25., 25., 15.])}
episode index:703
target thresh 16.10972706578474
model initialize at round 703
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.96291821,  0.9874817 ,  0.15333567,
       -0.03698746]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3175986618027054
{'scaleFactor': 20, 'currentState': array([26.30058726, 21.25376379, 11.84640395,  0.39863161,  0.74548192,
       -0.53418119]), 'targetState': array([25., 25., 15.])}
episode index:704
target thresh 16.118115673640776
model initialize at round 704
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85767966,  0.97833587,  0.15191551,
       -0.14064353]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3171481672469569
{'scaleFactor': 20, 'currentState': array([ 12.76421029,   9.57218606, -43.96482077,  -0.41184971,
        -0.67375686,   0.61354014]), 'targetState': array([25., 25., 15.])}
episode index:705
target thresh 16.126503442677965
model initialize at round 705
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.51251520e+01,  1.49832537e+01,  9.91964324e-01,
        1.25400272e-01, -1.67795103e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.31803249016785495
{'scaleFactor': 20, 'currentState': array([27.54306189, 20.17572512, 16.25204148,  0.64356325,  0.72789063,
        0.23664654]), 'targetState': array([25., 25., 15.])}
episode index:706
target thresh 16.134890372980205
model initialize at round 706
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.51537267e+01, 1.50005575e+01, 9.88157711e-01,
       1.53440638e-01, 5.56428935e-04]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3189143114680433
{'scaleFactor': 20, 'currentState': array([25.94408827, 21.44045322, 18.26542977,  0.31639625,  0.71792548,
        0.62006163]), 'targetState': array([25., 25., 15.])}
episode index:707
target thresh 16.143276464631327
model initialize at round 707
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.15372671,  0.97672671,  0.15166564,
        0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3197936417476096
{'scaleFactor': 20, 'currentState': array([25.54920193, 21.69071747, 19.37489376,  0.40468134,  0.88964482,
        0.21157768]), 'targetState': array([25., 25., 15.])}
episode index:708
target thresh 16.15166171771523
model initialize at round 708
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.51537267e+01, 1.50161274e+01, 9.88029859e-01,
       1.53420786e-01, 1.60953314e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.32067049154683863
{'scaleFactor': 20, 'currentState': array([26.42501241, 21.00970323, 11.93351478,  0.50501582,  0.61320112,
       -0.60740712]), 'targetState': array([25., 25., 15.])}
episode index:709
target thresh 16.16004613231573
model initialize at round 709
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12510862, 14.84627329,  0.98054217,  0.12391341,
       -0.1522581 ]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3202188429671952
{'scaleFactor': 20, 'currentState': array([ 5.35202699, 10.37818912, 16.74125116, -0.60658427, -0.52564623,
        0.59644913]), 'targetState': array([25., 25., 15.])}
episode index:710
target thresh 16.168429708516708
model initialize at round 710
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31976846484769145
{'scaleFactor': 20, 'currentState': array([ 35.5752204 ,  -2.66916661, -31.94860429,   0.88641014,
         0.40701228,  -0.22049505]), 'targetState': array([25., 25., 15.])}
episode index:711
target thresh 16.17681244640198
model initialize at round 711
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.88693515,  0.98192469,  0.15247278,
       -0.1121426 ]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31931935183526494
{'scaleFactor': 20, 'currentState': array([ 41.26921647,  14.50147359, -31.64303541,  -0.72538038,
        -0.47040023,  -0.50254048]), 'targetState': array([25., 25., 15.])}
episode index:712
target thresh 16.185194346055365
model initialize at round 712
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.05432724,  0.98670823,  0.15321556,
        0.0541466 ]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31887149860688446
{'scaleFactor': 20, 'currentState': array([ 26.69313885,  -1.09071142, -41.50625115,   0.82759047,
        -0.55919414,  -0.04894815]), 'targetState': array([25., 25., 15.])}
episode index:713
target thresh 16.1935754075607
model initialize at round 713
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85124105,  0.9774418 ,  0.15177668,
       -0.14687194]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3184248998693398
{'scaleFactor': 20, 'currentState': array([ 2.22853653e+01, -3.23974988e+01, -4.01697484e+01, -1.86416044e-02,
       -6.25321759e-01, -7.80144338e-01]), 'targetState': array([25., 25., 15.])}
episode index:714
target thresh 16.201955631001795
model initialize at round 714
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08502419, 14.92052724,  0.99316078,  0.08529565,
       -0.0797265 ]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.317979550359033
{'scaleFactor': 20, 'currentState': array([ 17.17692624,   2.26022863, -57.70957339,   0.10152474,
        -0.97839705,   0.1800887 ]), 'targetState': array([25., 25., 15.])}
episode index:715
target thresh 16.21033501646244
model initialize at round 715
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85565302,  0.97805845,  0.15187243,
       -0.14260584]), 'targetState': array([25., 25., 15.])}
done in step count: 39
reward sum = 0.6757290490602831
running average episode reward sum: 0.31847920049688394
{'scaleFactor': 20, 'currentState': array([20.20614011, 21.75793626, 18.81156821,  0.89932326,  0.42731297,
       -0.09285101]), 'targetState': array([25., 25., 15.])}
episode index:716
target thresh 16.218713564026434
model initialize at round 716
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3180350175115326
{'scaleFactor': 20, 'currentState': array([10.63545809, 30.63256059,  4.30949953, -0.73711865, -0.03729365,
       -0.67473349]), 'targetState': array([25., 25., 15.])}
episode index:717
target thresh 16.22709127377756
model initialize at round 717
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11473406, 14.84627329,  0.98174109,  0.11377691,
       -0.15244427]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31759207180469207
{'scaleFactor': 20, 'currentState': array([ 1.39969137e+01,  4.21061824e+01,  6.30945318e+00, -2.51635859e-02,
        3.22825283e-02,  9.99161965e-01]), 'targetState': array([25., 25., 15.])}
episode index:718
target thresh 16.235468145799604
model initialize at round 718
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.49979604e+01,  1.49678296e+01,  9.99470324e-01,
       -2.05912849e-03, -3.24781667e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.3184466938855019
{'scaleFactor': 20, 'currentState': array([28.48196004, 21.04677461, 12.09911352,  0.4264666 ,  0.77133345,
       -0.47240972]), 'targetState': array([25., 25., 15.])}
episode index:719
target thresh 16.243844180176325
model initialize at round 719
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09528509, 14.84627329,  0.98371877,  0.09468053,
       -0.15275136]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3180044068106609
{'scaleFactor': 20, 'currentState': array([ 33.48512565,  31.0740032 , -16.88777935,  -0.14073132,
        -0.23589606,   0.96153406]), 'targetState': array([25., 25., 15.])}
episode index:720
target thresh 16.252219376991484
model initialize at round 720
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.95449614, 14.89577634,  0.9934667 , -0.0456632 ,
       -0.10458862]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31756334660704
{'scaleFactor': 20, 'currentState': array([ 32.72456004,  -4.93216586, -49.44183582,   0.76009398,
        -0.25223834,  -0.59885972]), 'targetState': array([25., 25., 15.])}
episode index:721
target thresh 16.260593736328833
model initialize at round 721
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.49905211e+01,  1.49082073e+01,  9.95683776e-01,
       -9.53332685e-03, -9.23197395e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3171235081768363
{'scaleFactor': 20, 'currentState': array([  8.15655583,  -4.89955448, -15.14481763,  -0.41580496,
         0.15902976,   0.89544166]), 'targetState': array([25., 25., 15.])}
episode index:722
target thresh 16.268967258272127
model initialize at round 722
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.97625731, 14.89545259,  0.99418745, -0.02384311,
       -0.10498962]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3166848864504507
{'scaleFactor': 20, 'currentState': array([27.1476197 , 39.20752742, 20.02514858,  0.080001  ,  0.94883075,
       -0.3054833 ]), 'targetState': array([25., 25., 15.])}
episode index:723
target thresh 16.2773399429051
model initialize at round 723
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3162474763862926
{'scaleFactor': 20, 'currentState': array([16.5170582 , 31.01799022, 27.68912165,  0.14551919,  0.82664937,
        0.5435761 ]), 'targetState': array([25., 25., 15.])}
episode index:724
target thresh 16.285711790311453
model initialize at round 724
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.51537267e+01, 1.50147259e+01, 9.88051137e-01,
       1.53424090e-01, 1.46969094e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.31712298338424255
{'scaleFactor': 20, 'currentState': array([25.38805322, 20.17537239, 15.50230176,  0.60081933,  0.79671098,
       -0.06532797]), 'targetState': array([25., 25., 15.])}
episode index:725
target thresh 16.294082800574927
model initialize at round 725
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89843138,  0.98311862,  0.15265817,
       -0.10086263]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.31799607851718437
{'scaleFactor': 20, 'currentState': array([25.13487947, 20.09454144, 12.65796558,  0.56362752,  0.78372893,
       -0.26094632]), 'targetState': array([25., 25., 15.])}
episode index:726
target thresh 16.302452973779246
model initialize at round 726
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.97274264,  0.98779235,  0.15338391,
       -0.02719658]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3188667717377935
{'scaleFactor': 20, 'currentState': array([25.39311167, 20.16946408, 15.01618116,  0.58949448,  0.78338465,
        0.1969892 ]), 'targetState': array([25., 25., 15.])}
episode index:727
target thresh 16.310822310008078
model initialize at round 727
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.03775309,  0.98745702,  0.15333184,
        0.03765611]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3197220098939243
{'scaleFactor': 20, 'currentState': array([27.19478729, 20.88959856, 14.24989802,  0.57519852,  0.73321174,
       -0.36269438]), 'targetState': array([25., 25., 15.])}
episode index:728
target thresh 16.31919080934514
model initialize at round 728
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.1462446 , 14.89067136,  0.9834134 ,  0.14527162,
       -0.10860126]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31928343374866514
{'scaleFactor': 20, 'currentState': array([ 1.72752544e+01,  4.71162975e+01,  2.37312480e+01, -4.54308787e-02,
        7.33592044e-01, -6.78069870e-01]), 'targetState': array([25., 25., 15.])}
episode index:729
target thresh 16.327558471874106
model initialize at round 729
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.49950224e+01,  1.48462733e+01,  9.88145668e-01,
       -4.96829012e-03, -1.53438768e-01]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31884605918188613
{'scaleFactor': 20, 'currentState': array([43.1422644 , 34.74748912, 19.1458603 , -0.14272981,  0.13589844,
       -0.98038758]), 'targetState': array([25., 25., 15.])}
episode index:730
target thresh 16.335925297678656
model initialize at round 730
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.01765678, 14.84718917,  0.9881426 ,  0.01762366,
       -0.15252413]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31840988126234865
{'scaleFactor': 20, 'currentState': array([ 4.10771662e+01, -6.28680919e+00, -4.72949163e+01,  3.79244761e-02,
        1.69926770e-01, -9.84726676e-01]), 'targetState': array([25., 25., 15.])}
episode index:731
target thresh 16.34429128684246
model initialize at round 731
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14426365, 14.84627329,  0.97806993,  0.14252519,
       -0.15187421]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31797489508576077
{'scaleFactor': 20, 'currentState': array([12.25440713, 22.39407211, -6.19702293, -0.97465493,  0.05462552,
        0.21694199]), 'targetState': array([25., 25., 15.])}
episode index:732
target thresh 16.352656439449177
model initialize at round 732
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.50139169e+01,  1.48462733e+01,  9.88062539e-01,
        1.38896947e-02, -1.53425860e-01]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3175410957745933
{'scaleFactor': 20, 'currentState': array([39.15503462, -4.83870544, -9.83046409,  0.04896157,  0.61729181,
       -0.78520927]), 'targetState': array([25., 25., 15.])}
episode index:733
target thresh 16.361020755582445
model initialize at round 733
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13998256, 14.84627329,  0.97865129,  0.13837789,
       -0.15196449]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31710847847789764
{'scaleFactor': 20, 'currentState': array([ 15.81444477,  -1.60416756, -25.11770871,   0.13165507,
         0.0753104 ,  -0.98843072]), 'targetState': array([25., 25., 15.])}
episode index:734
target thresh 16.369384235325935
model initialize at round 734
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.04790677, 14.84627329,  0.98703007,  0.04776306,
       -0.15326554]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.316677038371125
{'scaleFactor': 20, 'currentState': array([ 42.99372077,  12.74044125, -18.25623148,  -0.4344756 ,
         0.6703064 ,  -0.60159811]), 'targetState': array([25., 25., 15.])}
episode index:735
target thresh 16.377746878763265
model initialize at round 735
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13501623, 14.96105306,  0.99007612,  0.13502661,
       -0.03894993]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3162467706559468
{'scaleFactor': 20, 'currentState': array([ 31.16604794,   4.52196357, -44.89959587,   0.65420605,
        -0.36571348,   0.6620182 ]), 'targetState': array([25., 25., 15.])}
episode index:736
target thresh 16.38610868597805
model initialize at round 736
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87124481,  0.98009724,  0.15218901,
       -0.12746728]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.31710802340933086
{'scaleFactor': 20, 'currentState': array([25.35109029, 20.18427844, 14.09821614,  0.60031246,  0.79924338,
       -0.02889568]), 'targetState': array([25., 25., 15.])}
episode index:737
target thresh 16.394469657053932
model initialize at round 737
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.1419947 , 14.90869136,  0.98577038,  0.14138805,
       -0.09091854]), 'targetState': array([25., 25., 15.])}
done in step count: 45
reward sum = 0.6361854860638709
running average episode reward sum: 0.31754037769477067
{'scaleFactor': 20, 'currentState': array([26.63590711, 21.70392074, 19.3384873 , -0.41896522,  0.90565903,
       -0.06519095]), 'targetState': array([25., 25., 15.])}
episode index:738
target thresh 16.402829792074513
model initialize at round 738
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.93039222,  0.98578143,  0.15307165,
       -0.06931117]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.31838468049816204
{'scaleFactor': 20, 'currentState': array([25.55255123, 21.00015717, 10.12584301,  0.28887664,  0.69777184,
       -0.65548817]), 'targetState': array([25., 25., 15.])}
episode index:739
target thresh 16.41118909112339
model initialize at round 739
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86921851,  0.97984475,  0.15214981,
       -0.12943996]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31795443092992126
{'scaleFactor': 20, 'currentState': array([13.00197838, 30.96454797,  2.59401168, -0.8988643 ,  0.22693556,
       -0.37489094]), 'targetState': array([25., 25., 15.])}
episode index:740
target thresh 16.419547554284154
model initialize at round 740
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31752534262907117
{'scaleFactor': 20, 'currentState': array([ 2.24340933e+01,  2.09130521e+01, -7.60227601e+01, -1.72410139e-02,
       -5.79628484e-02, -9.98169853e-01]), 'targetState': array([25., 25., 15.])}
episode index:741
target thresh 16.42790518164039
model initialize at round 741
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.50087583e+01,  1.48462733e+01,  9.88120107e-01,
        8.74164697e-03, -1.53434799e-01]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31709741090046056
{'scaleFactor': 20, 'currentState': array([ 30.48534206,  10.70665381, -73.2698483 ,  -0.45758354,
        -0.46250304,  -0.75941309]), 'targetState': array([25., 25., 15.])}
episode index:742
target thresh 16.436261973275677
model initialize at round 742
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.05645045, 14.85757917,  0.9882374 ,  0.05634994,
       -0.14216726]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.316670631074215
{'scaleFactor': 20, 'currentState': array([ 25.88838989,   9.94644575, -68.40721889,  -0.44321301,
        -0.86383698,  -0.23947423]), 'targetState': array([25., 25., 15.])}
episode index:743
target thresh 16.444617929273587
model initialize at round 743
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.90657849,  0.9838896 ,  0.15277789,
       -0.09284491]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.31752321093822816
{'scaleFactor': 20, 'currentState': array([25.25538957, 20.12677662, 13.20164423,  0.56772853,  0.77509332,
       -0.27733492]), 'targetState': array([25., 25., 15.])}
episode index:744
target thresh 16.452973049717677
model initialize at round 744
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.92127692,  0.98512134,  0.15296915,
       -0.07833513]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3183735019972373
{'scaleFactor': 20, 'currentState': array([25.27750347, 20.09764447, 13.43268051,  0.56204011,  0.76774243,
       -0.30770519]), 'targetState': array([25., 25., 15.])}
episode index:745
target thresh 16.46132733469149
model initialize at round 745
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10495469, 14.89709538,  0.98915718,  0.10486534,
       -0.10281701]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3179467278658737
{'scaleFactor': 20, 'currentState': array([ 42.09895544,  42.71344528, -68.02256807,  -0.08101965,
         0.52861925,  -0.84498373]), 'targetState': array([25., 25., 15.])}
episode index:746
target thresh 16.469680784278584
model initialize at round 746
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.1415    , 14.84627329,  0.97844711,  0.13984875,
       -0.15193278]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31752109636939996
{'scaleFactor': 20, 'currentState': array([ 26.67968991,   8.68901156, -24.96975199,  -0.10888232,
        -0.31306975,  -0.94346806]), 'targetState': array([25., 25., 15.])}
episode index:747
target thresh 16.478033398562488
model initialize at round 747
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.91964204,  0.98499451,  0.15294946,
       -0.07995167]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3170966029250558
{'scaleFactor': 20, 'currentState': array([15.37717889, 20.10497836, 14.42263767,  0.34798365,  0.59066918,
       -0.72802287]), 'targetState': array([25., 25., 15.])}
episode index:748
target thresh 16.486385177626715
model initialize at round 748
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31667324297455507
{'scaleFactor': 20, 'currentState': array([ 26.64300488,  15.24125621, -16.96435353,  -0.13058672,
         0.03274799,  -0.9908959 ]), 'targetState': array([25., 25., 15.])}
episode index:749
target thresh 16.494736121554798
model initialize at round 749
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10304393, 14.84627329,  0.98297232,  0.10231246,
       -0.15263545]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3162510119839223
{'scaleFactor': 20, 'currentState': array([ 34.26722031,  27.05794435, -65.17813004,   0.7427415 ,
         0.33427234,  -0.58016986]), 'targetState': array([25., 25., 15.])}
episode index:750
target thresh 16.50308623043024
model initialize at round 750
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89303379,  0.98257344,  0.15257352,
       -0.10616379]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.31708354079539647
{'scaleFactor': 20, 'currentState': array([26.23390453, 20.97123782, 11.05323514,  0.42522096,  0.6227202 ,
       -0.65681557]), 'targetState': array([25., 25., 15.])}
episode index:751
target thresh 16.511435504336536
model initialize at round 751
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.06959033, 14.84627329,  0.98578262,  0.06929388,
       -0.15307184]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31666188715072174
{'scaleFactor': 20, 'currentState': array([28.53038148, 14.74123901,  3.36653878, -0.14548558,  0.96745761,
        0.20702588]), 'targetState': array([25., 25., 15.])}
episode index:752
target thresh 16.519783943357204
model initialize at round 752
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.9542452 ,  0.98712896,  0.15328089,
       -0.04562211]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.31750428842927325
{'scaleFactor': 20, 'currentState': array([25.25811065, 20.06481407, 16.28900277,  0.52911126,  0.73212154,
        0.42899804]), 'targetState': array([25., 25., 15.])}
episode index:753
target thresh 16.528131547575697
model initialize at round 753
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.0192941 ,  0.98797467,  0.15341222,
        0.01925463]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.31834445522167476
{'scaleFactor': 20, 'currentState': array([25.19845279, 20.03587464, 13.31024028,  0.51881343,  0.72770279,
       -0.44864381]), 'targetState': array([25., 25., 15.])}
episode index:754
target thresh 16.53647831707551
model initialize at round 754
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84824967,  0.97701383,  0.15171022,
       -0.14975977]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31792280693661296
{'scaleFactor': 20, 'currentState': array([ 3.26884410e+01,  1.49517075e+01, -1.27799808e+01,  3.06237459e-02,
       -4.40302235e-02, -9.98560727e-01]), 'targetState': array([25., 25., 15.])}
episode index:755
target thresh 16.544824251940106
model initialize at round 755
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.84627329, 14.84627329,  0.97672671, -0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31750227412320475
{'scaleFactor': 20, 'currentState': array([ 23.51451277, -22.48497741, -37.66274585,   0.65824827,
        -0.48817081,   0.57306062]), 'targetState': array([25., 25., 15.])}
episode index:756
target thresh 16.55316935225294
model initialize at round 756
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.50076554e+01, 1.51185322e+01, 9.92879305e-01,
       7.67770519e-03, 1.18876986e-01]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31708285236082273
{'scaleFactor': 20, 'currentState': array([-41.87308418,  21.02727384,  39.68042208,  -0.68475601,
        -0.6494175 ,   0.33070548]), 'targetState': array([25., 25., 15.])}
episode index:757
target thresh 16.561513618097468
model initialize at round 757
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.05841909, 14.93791005,  0.99631273,  0.0587916 ,
       -0.06248586]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31666453725216726
{'scaleFactor': 20, 'currentState': array([  1.16658268,   6.15739386, -17.69003701,  -0.41004898,
        -0.29653349,   0.86251245]), 'targetState': array([25., 25., 15.])}
episode index:758
target thresh 16.569857049557136
model initialize at round 758
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10433354, 14.87817798,  0.98712862,  0.10403094,
       -0.12146869]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.316247324423113
{'scaleFactor': 20, 'currentState': array([38.51569002, 26.79827445,  1.54655448, -0.4831931 ,  0.13999453,
        0.86424878]), 'targetState': array([25., 25., 15.])}
episode index:759
target thresh 16.578199646715362
model initialize at round 759
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09084517, 15.08945121,  0.99180954,  0.09101121,
        0.08961471]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.3170576112961181
{'scaleFactor': 20, 'currentState': array([29.60167833, 20.08981792, 15.46704114,  0.66196906,  0.69289924,
       -0.28581044]), 'targetState': array([25., 25., 15.])}
episode index:760
target thresh 16.5865414096556
model initialize at round 760
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10548485, 14.85074219,  0.98338201,  0.1047797 ,
       -0.14826005]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31664097842976313
{'scaleFactor': 20, 'currentState': array([28.95514444,  1.64084693, -4.03243621,  0.34939082,  0.9352018 ,
       -0.05765104]), 'targetState': array([25., 25., 15.])}
episode index:761
target thresh 16.594882338461236
model initialize at round 761
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.92717374,  0.98555748,  0.15303688,
       -0.07249946]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3174609773417989
{'scaleFactor': 20, 'currentState': array([26.29656683, 20.35909978, 10.35742301,  0.38129782,  0.64152003,
       -0.66563055]), 'targetState': array([25., 25., 15.])}
episode index:762
target thresh 16.603222433215702
model initialize at round 762
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31704490790884765
{'scaleFactor': 20, 'currentState': array([ 16.55935225,  -3.8709405 , -38.35068873,   0.10989959,
        -0.87260758,   0.47589714]), 'targetState': array([25., 25., 15.])}
episode index:763
target thresh 16.611561694002397
model initialize at round 763
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14686192, 15.13711415,  0.98002092,  0.14538157,
        0.13573205]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31662992766289366
{'scaleFactor': 20, 'currentState': array([23.62449792, 25.35803455, 90.58334335, -0.66173527, -0.65267162,
        0.36895284]), 'targetState': array([25., 25., 15.])}
episode index:764
target thresh 16.619900120904695
model initialize at round 764
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.49916824e+01,  1.48462733e+01,  9.88123810e-01,
       -8.30187451e-03, -1.53435374e-01]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31621603233261536
{'scaleFactor': 20, 'currentState': array([ 16.63802191,   4.59589386, -49.17483773,  -0.3692088 ,
        -0.86381552,   0.34279382]), 'targetState': array([25., 25., 15.])}
episode index:765
target thresh 16.628237714006
model initialize at round 765
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3158032176689958
{'scaleFactor': 20, 'currentState': array([ 18.21338527,   9.58285221, -71.55153597,  -0.16295301,
         0.12782731,  -0.9783182 ]), 'targetState': array([25., 25., 15.])}
episode index:766
target thresh 16.636574473389697
model initialize at round 766
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.315391479445177
{'scaleFactor': 20, 'currentState': array([ 41.3979056 ,  13.82561777, -51.40783888,  -0.18787173,
         0.60820283,  -0.77122859]), 'targetState': array([25., 25., 15.])}
episode index:767
target thresh 16.644910399139114
model initialize at round 767
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.02080117, 14.84627329,  0.98794494,  0.02075799,
       -0.1534076 ]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31498081345631607
{'scaleFactor': 20, 'currentState': array([ 17.55688454, -30.13524984,  -8.86697102,  -0.06443138,
        -0.41345149,  -0.90824361]), 'targetState': array([25., 25., 15.])}
episode index:768
target thresh 16.653245491337643
model initialize at round 768
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.49890506e+01,  1.48764092e+01,  9.92237749e-01,
       -1.09741982e-02, -1.23870156e-01]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3145712155194418
{'scaleFactor': 20, 'currentState': array([ 45.84304311,   0.83189854, -50.53437462,  -0.34894655,
        -0.22739436,  -0.90913592]), 'targetState': array([25., 25., 15.])}
episode index:769
target thresh 16.661579750068633
model initialize at round 769
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85085971,  0.97738769,  0.15176827,
       -0.14724029]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3141626814733126
{'scaleFactor': 20, 'currentState': array([  8.79433405,  -1.19985863, -39.57098136,  -0.98123537,
        -0.10909803,  -0.15898038]), 'targetState': array([25., 25., 15.])}
episode index:770
target thresh 16.669913175415417
model initialize at round 770
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.02364199, 14.84627329,  0.98788284,  0.02359143,
       -0.15339796]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3137552071782759
{'scaleFactor': 20, 'currentState': array([23.91449517, 37.22666554, 28.72739221,  0.93390618,  0.19737601,
       -0.29809722]), 'targetState': array([25., 25., 15.])}
episode index:771
target thresh 16.67824576746132
model initialize at round 771
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89295472,  0.98256525,  0.15257224,
       -0.10624139]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3145683223884089
{'scaleFactor': 20, 'currentState': array([26.55535109, 21.20698369, 11.75778588,  0.57416161,  0.71968823,
       -0.39036817]), 'targetState': array([25., 25., 15.])}
episode index:772
target thresh 16.686577526289692
model initialize at round 772
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10748056, 14.88890022,  0.98802827,  0.1072665 ,
       -0.1108785 ]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3141613775987732
{'scaleFactor': 20, 'currentState': array([ 33.45829097,  -6.46781443, -54.7694063 ,  -0.33883769,
        -0.72524304,  -0.5993426 ]), 'targetState': array([25., 25., 15.])}
episode index:773
target thresh 16.694908451983835
model initialize at round 773
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84750634,  0.97690625,  0.15169352,
       -0.15047677]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.31498415366117793
{'scaleFactor': 20, 'currentState': array([25.21958767, 20.1419702 , 12.97835752,  0.57930542,  0.79040917,
       -0.19914464]), 'targetState': array([25., 25., 15.])}
episode index:774
target thresh 16.703238544627062
model initialize at round 774
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.51537267e+01, 1.50076349e+01, 9.88129171e-01,
       1.53436207e-01, 7.62048756e-03]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.31580480643051834
{'scaleFactor': 20, 'currentState': array([25.33594273, 20.14957031, 16.10294295,  0.59378203,  0.7960497 ,
        0.11716556]), 'targetState': array([25., 25., 15.])}
episode index:775
target thresh 16.711567804302685
model initialize at round 775
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.96299742,  0.98748458,  0.15333611,
       -0.03690856]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.3165989566128333
{'scaleFactor': 20, 'currentState': array([28.70782556, 20.01541811, 10.11007719,  0.66207014,  0.26453021,
       -0.70120389]), 'targetState': array([25., 25., 15.])}
episode index:776
target thresh 16.719896231093966
model initialize at round 776
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.94500376, 14.84627329,  0.98667239, -0.05481139,
       -0.15321   ]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31619149334820934
{'scaleFactor': 20, 'currentState': array([ 12.43657177,  15.782217  , -40.75218349,   0.09200288,
        -0.51671783,   0.85119807]), 'targetState': array([25., 25., 15.])}
episode index:777
target thresh 16.72822382508422
model initialize at round 777
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13844923, 14.85279437,  0.97979581,  0.13702219,
       -0.14568835]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31578507754699053
{'scaleFactor': 20, 'currentState': array([ 13.94369684,   8.31074026, -23.69094105,   0.04511483,
        -0.6599893 ,  -0.74991918]), 'targetState': array([25., 25., 15.])}
episode index:778
target thresh 16.736550586356714
model initialize at round 778
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.96364139, 14.84627329,  0.98750779, -0.03626708,
       -0.15333972]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3153797051752999
{'scaleFactor': 20, 'currentState': array([ 2.87749671e+01, -4.46051869e+00, -5.99789287e+01,  9.96978260e-01,
       -7.23503757e-02, -2.82802317e-02]), 'targetState': array([25., 25., 15.])}
episode index:779
target thresh 16.7448765149947
model initialize at round 779
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.04330171,  0.98723618,  0.15329754,
        0.04318082]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.31618239805251236
{'scaleFactor': 20, 'currentState': array([27.40786473, 20.4225923 , 13.48960842,  0.63846708,  0.71854105,
       -0.27578716]), 'targetState': array([25., 25., 15.])}
episode index:780
target thresh 16.753201611081458
model initialize at round 780
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.94607899,  0.98672978,  0.15321891,
       -0.0537429 ]), 'targetState': array([25., 25., 15.])}
done in step count: 38
reward sum = 0.682554595010387
running average episode reward sum: 0.3166515045787068
{'scaleFactor': 20, 'currentState': array([22.11971899, 28.72946389, 12.52958024,  0.33851207, -0.83522296,
        0.43337303]), 'targetState': array([25., 25., 15.])}
episode index:781
target thresh 16.761525874700244
model initialize at round 781
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3162465793810358
{'scaleFactor': 20, 'currentState': array([ 14.2766411 ,   1.43520647, -20.81171906,   0.80396533,
        -0.31154469,   0.50653692]), 'targetState': array([25., 25., 15.])}
episode index:782
target thresh 16.76984930593427
model initialize at round 782
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3158426884750574
{'scaleFactor': 20, 'currentState': array([ 13.05174932,  14.94725251, -21.06254478,  -0.99720678,
        -0.05538938,  -0.05010646]), 'targetState': array([25., 25., 15.])}
episode index:783
target thresh 16.778171904866788
model initialize at round 783
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.90380337,  0.98363402,  0.1527382 ,
       -0.09557806]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3166406954405242
{'scaleFactor': 20, 'currentState': array([26.85582402, 21.084712  , 12.30359245,  0.64478321,  0.71226468,
       -0.27736915]), 'targetState': array([25., 25., 15.])}
episode index:784
target thresh 16.786493671581038
model initialize at round 784
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.50125069e+01,  1.49516654e+01,  9.98730786e-01,
        1.26171517e-02, -4.87608920e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3162373314972879
{'scaleFactor': 20, 'currentState': array([ 29.6352996 ,  -1.47889279, -33.43934358,  -0.16193351,
        -0.13788518,  -0.97712088]), 'targetState': array([25., 25., 15.])}
episode index:785
target thresh 16.794814606160223
model initialize at round 785
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13888535, 14.94309526,  0.98870205,  0.13870326,
       -0.05683013]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3158349939254084
{'scaleFactor': 20, 'currentState': array([ 41.90870273,  13.04253217, -16.75634829,  -0.09572476,
         0.68799491,  -0.71937458]), 'targetState': array([25., 25., 15.])}
episode index:786
target thresh 16.80313470868754
model initialize at round 786
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15262878, 14.89960567,  0.98339675,  0.15161075,
       -0.09972471]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3154336788124155
{'scaleFactor': 20, 'currentState': array([ 27.18178844,  -6.86335057, -47.29027987,  -0.14017019,
        -0.49529791,  -0.85734024]), 'targetState': array([25., 25., 15.])}
episode index:787
target thresh 16.811453979246206
model initialize at round 787
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31503338226569927
{'scaleFactor': 20, 'currentState': array([ 12.87696722,  10.90891625, -13.64627295,  -0.80618979,
        -0.58461664,  -0.09100229]), 'targetState': array([25., 25., 15.])}
episode index:788
target thresh 16.81977241791942
model initialize at round 788
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.05408122, 14.84627329,  0.9867213 ,  0.05390211,
       -0.15321759]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31463410041238404
{'scaleFactor': 20, 'currentState': array([40.47496415,  6.88186658,  7.4732764 ,  0.77116493,  0.42038334,
        0.47810303]), 'targetState': array([25., 25., 15.])}
episode index:789
target thresh 16.82809002479034
model initialize at round 789
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.51537267e+01, 1.50105232e+01, 9.88103358e-01,
       1.53432199e-01, 1.05030245e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.31543961427249495
{'scaleFactor': 20, 'currentState': array([25.41211691, 20.08996098, 14.2712844 ,  0.59541063,  0.76575561,
       -0.24311422]), 'targetState': array([25., 25., 15.])}
episode index:790
target thresh 16.836406799942193
model initialize at round 790
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31504082841374337
{'scaleFactor': 20, 'currentState': array([ 33.88629433,  -7.61160146, -25.34453275,   0.65130912,
        -0.09348361,  -0.75303204]), 'targetState': array([25., 25., 15.])}
episode index:791
target thresh 16.844722743458085
model initialize at round 791
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.50693869e+01, 1.50128634e+01, 9.97469080e-01,
       6.99103825e-02, 1.29604000e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.3158198997767399
{'scaleFactor': 20, 'currentState': array([28.91750401, 20.12065171, 11.39021306,  0.4827405 ,  0.67703377,
       -0.55550597]), 'targetState': array([25., 25., 15.])}
episode index:792
target thresh 16.853037855421217
model initialize at round 792
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3166208709622674
{'scaleFactor': 20, 'currentState': array([24.94812359, 20.03713211, 11.92851381,  0.53115886,  0.76668323,
       -0.36064814]), 'targetState': array([25., 25., 15.])}
episode index:793
target thresh 16.86135213591472
model initialize at round 793
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.94432047,  0.98663534,  0.15320424,
       -0.0554903 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.31740784738347483
{'scaleFactor': 20, 'currentState': array([25.75951505, 20.68909872, 10.07303595,  0.29463093,  0.59000719,
       -0.75172078]), 'targetState': array([25., 25., 15.])}
episode index:794
target thresh 16.869665585021743
model initialize at round 794
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86623958,  0.97946677,  0.15209111,
       -0.13233725]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3181928439897862
{'scaleFactor': 20, 'currentState': array([25.75433115, 21.20289499, 10.47219078,  0.3154498 ,  0.66345901,
       -0.67846412]), 'targetState': array([25., 25., 15.])}
episode index:795
target thresh 16.877978202825417
model initialize at round 795
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3177931042360302
{'scaleFactor': 20, 'currentState': array([ 31.73191653,   5.080492  , -20.82125474,   0.08909109,
         0.12775276,  -0.98779654]), 'targetState': array([25., 25., 15.])}
episode index:796
target thresh 16.886289989408887
model initialize at round 796
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.03126867, 14.89680439,  0.99412069,  0.03139882,
       -0.10362514]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.317394367593325
{'scaleFactor': 20, 'currentState': array([ 42.16439488,  -3.04548256, -65.18590169,   0.25934048,
         0.11719511,  -0.95864896]), 'targetState': array([25., 25., 15.])}
episode index:797
target thresh 16.89460094485524
model initialize at round 797
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.86135877, 14.84627329,  0.97883005, -0.13707697,
       -0.15199224]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31699663029057645
{'scaleFactor': 20, 'currentState': array([ 3.58109015e+01, -1.82909386e+01, -5.85594131e+01, -4.04578778e-02,
        1.36149367e-01, -9.89861864e-01]), 'targetState': array([25., 25., 15.])}
episode index:798
target thresh 16.902911069247615
model initialize at round 798
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3165998885755695
{'scaleFactor': 20, 'currentState': array([40.18861364,  8.67889445, 31.33518555, -0.0647073 ,  0.10186331,
        0.99269171]), 'targetState': array([25., 25., 15.])}
episode index:799
target thresh 16.911220362669088
model initialize at round 799
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13255092, 14.91387526,  0.98749139,  0.13221505,
       -0.0859065 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.31738098890160127
{'scaleFactor': 20, 'currentState': array([25.7409874 , 20.65418049, 10.10041842,  0.27041513,  0.63304154,
       -0.725351  ]), 'targetState': array([25., 25., 15.])}
episode index:800
target thresh 16.91952882520278
model initialize at round 800
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3169847579541586
{'scaleFactor': 20, 'currentState': array([ 0.41923468, 45.57079297, 13.65903657, -0.70402524, -0.14360832,
        0.6955035 ]), 'targetState': array([25., 25., 15.])}
episode index:801
target thresh 16.927836456931743
model initialize at round 801
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14961076, 15.05465377,  0.9873032 ,  0.14920321,
        0.05450489]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.31776343051207234
{'scaleFactor': 20, 'currentState': array([26.30376826, 21.32040412, 12.17581975,  0.40903256,  0.76422558,
       -0.49864981]), 'targetState': array([25., 25., 15.])}
episode index:802
target thresh 16.936143257939086
model initialize at round 802
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.1383548 , 14.90746354,  0.98615897,  0.13781801,
       -0.09217743]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31736771017519555
{'scaleFactor': 20, 'currentState': array([  0.94889252, -18.34029073, -19.00443715,  -0.04358847,
        -0.14598753,  -0.9883257 ]), 'targetState': array([25., 25., 15.])}
episode index:803
target thresh 16.944449228307846
model initialize at round 803
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14455411, 14.86045232,  0.98002057,  0.14309697,
       -0.13814101]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.31814396942796397
{'scaleFactor': 20, 'currentState': array([26.4784643 , 20.69950418, 10.89937834,  0.51576718,  0.57305863,
       -0.63685792]), 'targetState': array([25., 25., 15.])}
episode index:804
target thresh 16.952754368121102
model initialize at round 804
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.50076253e+01,  1.48462733e+01,  9.88129243e-01,
        7.61089447e-03, -1.53436218e-01]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3177487595280534
{'scaleFactor': 20, 'currentState': array([ 46.18866076,  -1.73293902, -53.05123563,  -0.65580597,
        -0.41920027,  -0.62784525]), 'targetState': array([25., 25., 15.])}
episode index:805
target thresh 16.961058677461903
model initialize at round 805
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.04648809, 14.90424908,  0.99426992,  0.0466886 ,
       -0.09616389]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3173545302978697
{'scaleFactor': 20, 'currentState': array([ 2.17977884e+01, -1.78880583e+01, -3.64995680e+01,  3.75585199e-02,
       -3.67467079e-03, -9.99287673e-01]), 'targetState': array([25., 25., 15.])}
episode index:806
target thresh 16.969362156413304
model initialize at round 806
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09370119, 14.84627329,  0.98386417,  0.09312045,
       -0.15277394]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31696127809180047
{'scaleFactor': 20, 'currentState': array([23.85535387, 18.18714699, -6.42982309,  0.32412296,  0.9380184 ,
       -0.1227428 ]), 'targetState': array([25., 25., 15.])}
episode index:807
target thresh 16.9776648050583
model initialize at round 807
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.93042   ,  0.98578332,  0.15307194,
       -0.06928364]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.31773419748698506
{'scaleFactor': 20, 'currentState': array([26.51901604, 20.08583876, 10.2877009 ,  0.54214069,  0.41915911,
       -0.72827818]), 'targetState': array([25., 25., 15.])}
episode index:808
target thresh 16.985966623479953
model initialize at round 808
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08049788, 14.84627329,  0.98498354,  0.08008999,
       -0.15294775]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3173414481699431
{'scaleFactor': 20, 'currentState': array([12.91242132, 48.08396318, 19.49569363, -0.190493  , -0.18570726,
        0.96396329]), 'targetState': array([25., 25., 15.])}
episode index:809
target thresh 16.99426761176127
model initialize at round 809
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.84962014, 14.97271927,  0.98829255, -0.1501205 ,
       -0.02723368]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3169496686043012
{'scaleFactor': 20, 'currentState': array([ 37.33383258, -24.94936746,  -7.99376245,   0.58741355,
        -0.40513225,  -0.7005806 ]), 'targetState': array([25., 25., 15.])}
episode index:810
target thresh 17.002567769985276
model initialize at round 810
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12239884, 14.84627329,  0.98086489,  0.12126942,
       -0.15230821]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3165588552028162
{'scaleFactor': 20, 'currentState': array([ 2.01618525e+01, -1.14307596e+01, -5.06216274e+01,  8.65924607e-02,
        7.00112845e-03, -9.96219218e-01]), 'targetState': array([25., 25., 15.])}
episode index:811
target thresh 17.01086709823494
model initialize at round 811
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.05682973, 14.90154219,  0.99347151,  0.05702901,
       -0.09880306]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31616900439591616
{'scaleFactor': 20, 'currentState': array([31.96660975,  4.86919342, -8.62085429, -0.128799  ,  0.60333233,
       -0.78702028]), 'targetState': array([25., 25., 15.])}
episode index:812
target thresh 17.01916559659329
model initialize at round 812
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.93342389,  0.98598326,  0.15310299,
       -0.06630599]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31578011263159156
{'scaleFactor': 20, 'currentState': array([22.75469664, 16.4795872 , -9.03543042, -0.36915266,  0.09752938,
       -0.92423716]), 'targetState': array([25., 25., 15.])}
episode index:813
target thresh 17.027463265143282
model initialize at round 813
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12659461, 14.92520562,  0.9891495 ,  0.12648585,
       -0.07473012]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.31654878589543606
{'scaleFactor': 20, 'currentState': array([26.91283794, 21.05219731, 13.50060683,  0.54072064,  0.84018557,
       -0.04134491]), 'targetState': array([25., 25., 15.])}
episode index:814
target thresh 17.035760103967924
model initialize at round 814
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.06118868,  0.98632002,  0.15315528,
        0.06096123]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3173155728445226
{'scaleFactor': 20, 'currentState': array([26.78839337, 21.51204797, 15.84470938,  0.54402168,  0.83083858,
       -0.11725043]), 'targetState': array([25., 25., 15.])}
episode index:815
target thresh 17.044056113150152
model initialize at round 815
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.94329858,  0.98657907,  0.15319551,
       -0.05650549]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.318080480413832
{'scaleFactor': 20, 'currentState': array([25.42400789, 21.21411806, 10.22044037,  0.25084905,  0.67632127,
       -0.69257801]), 'targetState': array([25., 25., 15.])}
episode index:816
target thresh 17.05235129277294
model initialize at round 816
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.88384613,  0.98158288,  0.1524197 ,
       -0.11516632]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31769115302042467
{'scaleFactor': 20, 'currentState': array([27.4571746 , 31.31716603,  0.54052118,  0.08079204,  0.94200919,
       -0.32571665]), 'targetState': array([25., 25., 15.])}
episode index:817
target thresh 17.060645642919248
model initialize at round 817
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.02553982,  0.98783694,  0.15339083,
        0.02548402]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3184653570508398
{'scaleFactor': 20, 'currentState': array([25.41288762, 20.1245554 , 15.7121104 ,  0.60209254,  0.77606562,
        0.18763457]), 'targetState': array([25., 25., 15.])}
episode index:818
target thresh 17.068939163672002
model initialize at round 818
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.13250206,  0.97962742,  0.15211606,
        0.13111379]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.31922605887300115
{'scaleFactor': 20, 'currentState': array([27.16672403, 20.39825183, 18.00032776,  0.67355632,  0.7243741 ,
        0.14698313]), 'targetState': array([25., 25., 15.])}
episode index:819
target thresh 17.07723185511416
model initialize at round 819
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.51537267e+01,  1.49919249e+01,  9.88125768e-01,
        1.53435678e-01, -8.05977354e-03]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.31998490532486457
{'scaleFactor': 20, 'currentState': array([25.78107687, 21.36033353, 11.18968275,  0.29270336,  0.70126652,
       -0.65003847]), 'targetState': array([25., 25., 15.])}
episode index:820
target thresh 17.08552371732861
model initialize at round 820
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.32074190318610224
{'scaleFactor': 20, 'currentState': array([26.01931858, 20.67547613, 10.14512955,  0.40943938,  0.5516331 ,
       -0.72667758]), 'targetState': array([25., 25., 15.])}
episode index:821
target thresh 17.093814750398316
model initialize at round 821
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.07240748, 14.84627329,  0.98558718,  0.07208473,
       -0.15304149]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3203517062235887
{'scaleFactor': 20, 'currentState': array([ 23.78094547,  19.43886719, -11.27001078,  -0.44261778,
         0.04811408,  -0.89541864]), 'targetState': array([25., 25., 15.])}
episode index:822
target thresh 17.102104954406183
model initialize at round 822
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3199624574918468
{'scaleFactor': 20, 'currentState': array([ 2.63521588e+01, -5.23300687e+00, -3.33425262e+01, -1.74894933e-01,
        2.29506776e-02, -9.84319577e-01]), 'targetState': array([25., 25., 15.])}
episode index:823
target thresh 17.110394329435074
model initialize at round 823
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31957415353858004
{'scaleFactor': 20, 'currentState': array([ 21.1310431 ,   1.05411142, -67.16717368,   0.58591351,
        -0.21797171,  -0.78050861]), 'targetState': array([25., 25., 15.])}
episode index:824
target thresh 17.118682875567913
model initialize at round 824
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.02701773, 14.92400717,  0.99669796,  0.02720052,
       -0.07650697]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3191867909282302
{'scaleFactor': 20, 'currentState': array([24.48006036, -0.090304  ,  3.62083919,  0.8229056 ,  0.54213176,
       -0.17005745]), 'targetState': array([25., 25., 15.])}
episode index:825
target thresh 17.12697059288759
model initialize at round 825
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13588894, 14.84627329,  0.97919175,  0.13440538,
       -0.15204841]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31880036624187646
{'scaleFactor': 20, 'currentState': array([ 27.35251132,  11.39018527, -61.1168717 ,  -0.73330705,
         0.10029574,  -0.67245932]), 'targetState': array([25., 25., 15.])}
episode index:826
target thresh 17.135257481476973
model initialize at round 826
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.07524842, 14.84627329,  0.98538237,  0.07489744,
       -0.15300968]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31841487607713415
{'scaleFactor': 20, 'currentState': array([ 25.01025823,  -6.85689658, -39.91424629,   0.04702555,
        -0.5708616 ,  -0.8196985 ]), 'targetState': array([25., 25., 15.])}
episode index:827
target thresh 17.143543541418914
model initialize at round 827
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.8477724 ,  0.97694481,  0.1516995 ,
       -0.15022016]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3180303170480555
{'scaleFactor': 20, 'currentState': array([ 13.19365208,   1.21246956, -21.63353367,   0.10868411,
         0.13443197,  -0.98494457]), 'targetState': array([25., 25., 15.])}
episode index:828
target thresh 17.151828772796307
model initialize at round 828
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12851047, 14.84627329,  0.98012748,  0.12722894,
       -0.15219371]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3176466857850301
{'scaleFactor': 20, 'currentState': array([ 35.82438298,   5.55997027, -63.49001666,  -0.2150985 ,
         0.1660104 ,  -0.96237892]), 'targetState': array([25., 25., 15.])}
episode index:829
target thresh 17.160113175691972
model initialize at round 829
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13628484, 14.84627329,  0.97914014,  0.13478985,
       -0.15204039]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31726397893468666
{'scaleFactor': 20, 'currentState': array([ 2.06769759e+01, -2.00985262e+00, -4.09956573e+01,  8.97418669e-02,
       -3.01193574e-02, -9.95509529e-01]), 'targetState': array([25., 25., 15.])}
episode index:830
target thresh 17.168396750188776
model initialize at round 830
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.97589879, 14.84627329,  0.98787206, -0.02404941,
       -0.15339628]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3168821931597954
{'scaleFactor': 20, 'currentState': array([ 13.24791322, -30.87747259,  -4.84470048,   0.58082846,
        -0.62415735,  -0.52255709]), 'targetState': array([25., 25., 15.])}
episode index:831
target thresh 17.17667949636955
model initialize at round 831
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08508999, 14.84627329,  0.98461305,  0.08462698,
       -0.15289022]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3165013251391706
{'scaleFactor': 20, 'currentState': array([ 1.61463555e+01, -4.54690666e-02, -3.81750738e+01, -1.21231504e-01,
       -2.69524096e-02, -9.92258278e-01]), 'targetState': array([25., 25., 15.])}
episode index:832
target thresh 17.18496141431711
model initialize at round 832
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09126385, 14.84627329,  0.98408328,  0.09071842,
       -0.15280796]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31612137156757497
{'scaleFactor': 20, 'currentState': array([32.22238907, 13.73586621, -2.11650511, -0.25942992, -0.07627237,
       -0.96274537]), 'targetState': array([25., 25., 15.])}
episode index:833
target thresh 17.19324250411429
model initialize at round 833
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11213309, 14.84872971,  0.98238821,  0.11127093,
       -0.15010722]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31574232915562345
{'scaleFactor': 20, 'currentState': array([ 9.54009799, 48.44675021, -0.14071677,  0.76275261, -0.46684854,
        0.44750519]), 'targetState': array([25., 25., 15.])}
episode index:834
target thresh 17.20152276584388
model initialize at round 834
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31536419462968857
{'scaleFactor': 20, 'currentState': array([ 6.88441312e+00, -5.31884948e+00, -3.31092774e+01,  2.57819420e-02,
       -8.47106953e-01,  5.30796666e-01]), 'targetState': array([25., 25., 15.])}
episode index:835
target thresh 17.20980219958872
model initialize at round 835
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11206952, 14.85998057,  0.9839841 ,  0.11138851,
       -0.13916858]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31498696473180615
{'scaleFactor': 20, 'currentState': array([-12.46867774,  20.14050657,  -8.66084874,   0.32508032,
         0.06868741,  -0.94318865]), 'targetState': array([25., 25., 15.])}
episode index:836
target thresh 17.21808080543157
model initialize at round 836
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86198741,  0.97891327,  0.15200517,
       -0.13646703]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3146106362195818
{'scaleFactor': 20, 'currentState': array([ 33.43138255,   8.76945517, -62.04877263,  -0.84594459,
         0.42132479,  -0.32689934]), 'targetState': array([25., 25., 15.])}
episode index:837
target thresh 17.226358583455227
model initialize at round 837
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.1270376 , 14.98016095,  0.99167131,  0.12725206,
       -0.01987254]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3153586905312541
{'scaleFactor': 20, 'currentState': array([26.43007123, 21.110421  , 12.01135267,  0.45293223,  0.7113739 ,
       -0.53740076]), 'targetState': array([25., 25., 15.])}
episode index:838
target thresh 17.23463553374247
model initialize at round 838
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11290157, 14.85580481,  0.98331697,  0.11213943,
       -0.14322179]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3149828160490953
{'scaleFactor': 20, 'currentState': array([ 41.26996601,  11.62175315, -33.21943538,  -0.25369876,
         0.83846824,  -0.48229447]), 'targetState': array([25., 25., 15.])}
episode index:839
target thresh 17.24291165637606
model initialize at round 839
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.05258944,  0.9867993 ,  0.15322971,
        0.05241942]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3157399675179654
{'scaleFactor': 20, 'currentState': array([25.36583779, 20.16122212, 15.92848417,  0.59231752,  0.79118754,
        0.15225713]), 'targetState': array([25., 25., 15.])}
episode index:840
target thresh 17.25118695143878
model initialize at round 840
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.88964769,  0.98221752,  0.15251825,
       -0.10948482]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31536453354945415
{'scaleFactor': 20, 'currentState': array([24.37553944,  9.38359314, -0.94710197, -0.09228406,  0.22495837,
       -0.96998834]), 'targetState': array([25., 25., 15.])}
episode index:841
target thresh 17.259461419013356
model initialize at round 841
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31498999134808897
{'scaleFactor': 20, 'currentState': array([ 29.67830397, -27.15158553, -18.77997664,   0.58519192,
         0.39837491,  -0.70629162]), 'targetState': array([25., 25., 15.])}
episode index:842
target thresh 17.267735059182556
model initialize at round 842
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.876854  ,  0.98077658,  0.1522945 ,
       -0.1219987 ]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3146163377403214
{'scaleFactor': 20, 'currentState': array([ 35.57995991,  -2.23344156, -40.05410717,   0.28151535,
         0.14721024,  -0.94819737]), 'targetState': array([25., 25., 15.])}
episode index:843
target thresh 17.276007872029098
model initialize at round 843
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13346221, 14.84627329,  0.97950497,  0.13204737,
       -0.15209704]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31424356956764327
{'scaleFactor': 20, 'currentState': array([ 33.67744641,   0.92767749, -61.05785455,  -0.0912056 ,
         0.27791499,  -0.95626607]), 'targetState': array([25., 25., 15.])}
episode index:844
target thresh 17.28427985763572
model initialize at round 844
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.0634038 , 14.84627329,  0.98618495,  0.06315947,
       -0.15313431]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31387168368649815
{'scaleFactor': 20, 'currentState': array([ -2.89582281,  34.06334526, -26.16412405,  -0.97135365,
         0.15080238,   0.18365929]), 'targetState': array([25., 25., 15.])}
episode index:845
target thresh 17.292551016085145
model initialize at round 845
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09627634, 14.84627329,  0.98362657,  0.09565653,
       -0.15273704]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31350067696819256
{'scaleFactor': 20, 'currentState': array([ 32.92752525,  -2.30484279, -34.51992978,   0.08079202,
         0.2154797 ,  -0.97316039]), 'targetState': array([25., 25., 15.])}
episode index:846
target thresh 17.300821347460072
model initialize at round 846
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09675508, 14.90983555,  0.99119453,  0.09687182,
       -0.09027324]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31313054629880865
{'scaleFactor': 20, 'currentState': array([ -0.34281293,  38.65465269, -12.13250762,   0.22452277,
        -0.53833251,   0.81227313]), 'targetState': array([25., 25., 15.])}
episode index:847
target thresh 17.309090851843223
model initialize at round 847
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.02095725,  0.98794174,  0.1534071 ,
        0.02091368]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3138715246043537
{'scaleFactor': 20, 'currentState': array([27.55304349, 20.43838491, 15.99815813,  0.6884613 ,  0.72364855,
        0.04851615]), 'targetState': array([25., 25., 15.])}
episode index:848
target thresh 17.317359529317265
model initialize at round 848
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.97783258,  0.98791607,  0.15340312,
       -0.02212076]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3146219586741954
{'scaleFactor': 20, 'currentState': array([25.47727886, 20.0780898 , 15.07740023,  0.61595763,  0.77814624,
        0.12281948]), 'targetState': array([25., 25., 15.])}
episode index:849
target thresh 17.325627379964914
model initialize at round 849
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.94681962,  0.98676866,  0.15322495,
       -0.0530068 ]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31425181519340223
{'scaleFactor': 20, 'currentState': array([ 48.86957214,  32.0559233 , -40.4079868 ,  -0.7896528 ,
         0.53406958,   0.3020234 ]), 'targetState': array([25., 25., 15.])}
episode index:850
target thresh 17.333894403868833
model initialize at round 850
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13951825, 15.07775888,  0.9872338 ,  0.13912842,
        0.07754161]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.3149778005432419
{'scaleFactor': 20, 'currentState': array([29.16631167, 20.84562198, 14.0438984 ,  0.62544525,  0.67515446,
       -0.39113258]), 'targetState': array([25., 25., 15.])}
episode index:851
target thresh 17.3421606011117
model initialize at round 851
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13368503, 14.84627329,  0.97947643,  0.13226398,
       -0.15209261]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3146081082890832
{'scaleFactor': 20, 'currentState': array([ 42.93532688, -18.45953944, -47.7800901 ,   0.2427721 ,
        -0.0913588 ,  -0.96577185]), 'targetState': array([25., 25., 15.])}
episode index:852
target thresh 17.350425971776172
model initialize at round 852
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3153430110336458
{'scaleFactor': 20, 'currentState': array([25.65400826, 21.57275172, 10.60057725,  0.35893603,  0.80924765,
       -0.46506254]), 'targetState': array([25., 25., 15.])}
episode index:853
target thresh 17.358690515944897
model initialize at round 853
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.93855429,  0.98630459,  0.15315289,
       -0.06121635]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31497375692236523
{'scaleFactor': 20, 'currentState': array([ 12.95406573,  14.43707062, -14.67075271,   0.02840403,
         0.19254901,  -0.98087619]), 'targetState': array([25., 25., 15.])}
episode index:854
target thresh 17.366954233700525
model initialize at round 854
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.07670909, 14.92135539,  0.99389913,  0.07701121,
       -0.07895435]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3157065129369601
{'scaleFactor': 20, 'currentState': array([26.32910385, 20.3559677 , 10.63332192,  0.45327024,  0.58915785,
       -0.6689089 ]), 'targetState': array([25., 25., 15.])}
episode index:855
target thresh 17.375217125125697
model initialize at round 855
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.03073931, 14.90868455,  0.99529743,  0.03090379,
       -0.09180407]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31533769691717395
{'scaleFactor': 20, 'currentState': array([ 15.84934387,   5.31406062, -22.92617894,   0.0816661 ,
        -0.89826928,   0.43179039]), 'targetState': array([25., 25., 15.])}
episode index:856
target thresh 17.383479190303042
model initialize at round 856
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10025822, 14.84627329,  0.98324684,  0.09957432,
       -0.15267808]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.314969741611553
{'scaleFactor': 20, 'currentState': array([ 36.94359546,   3.36141989, -54.79652529,  -0.12828469,
        -0.15215204,  -0.97999632]), 'targetState': array([25., 25., 15.])}
episode index:857
target thresh 17.39174042931517
model initialize at round 857
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3146026440106071
{'scaleFactor': 20, 'currentState': array([  8.12967974,  -9.29466707, -35.61362211,   0.18085825,
        -0.04581371,  -0.98244155]), 'targetState': array([25., 25., 15.])}
episode index:858
target thresh 17.40000084224471
model initialize at round 858
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14561709, 14.89598008,  0.98405241,  0.14474228,
       -0.103395  ]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3153434908160662
{'scaleFactor': 20, 'currentState': array([25.49777305, 20.01719395, 14.24002289,  0.65134969,  0.7570544 ,
       -0.0511098 ]), 'targetState': array([25., 25., 15.])}
episode index:859
target thresh 17.40826042917426
model initialize at round 859
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.8609332 ,  0.97877351,  0.15198346,
       -0.1374898 ]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3149768123383731
{'scaleFactor': 20, 'currentState': array([ 23.47643513,  13.0044071 , -23.66069533,   0.06078614,
        -0.79445363,   0.60427517]), 'targetState': array([25., 25., 15.])}
episode index:860
target thresh 17.41651919018642
model initialize at round 860
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.07786698, 14.88928831,  0.99078286,  0.07792855,
       -0.11079924]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31461098561091855
{'scaleFactor': 20, 'currentState': array([ 31.56784189,   3.16021457, -53.87238521,   0.27602883,
        -0.22085321,  -0.93543142]), 'targetState': array([25., 25., 15.])}
episode index:861
target thresh 17.424777125363754
model initialize at round 861
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3142460076693746
{'scaleFactor': 20, 'currentState': array([ 19.24916612,  10.41432213, -36.41665153,  -0.63187052,
        -0.52228697,  -0.5726744 ]), 'targetState': array([25., 25., 15.])}
episode index:862
target thresh 17.43303423478887
model initialize at round 862
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10237743, 14.90643193,  0.99032878,  0.10241143,
       -0.09359915]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31388187556315283
{'scaleFactor': 20, 'currentState': array([ 1.93926265e+01,  1.05176127e+01,  1.16769678e+01,  9.99532581e-01,
       -2.63793836e-02,  1.54514848e-02]), 'targetState': array([25., 25., 15.])}
episode index:863
target thresh 17.441290518544317
model initialize at round 863
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14942701, 14.87571384,  0.98126852,  0.14810911,
       -0.12319   ]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3135185863553251
{'scaleFactor': 20, 'currentState': array([ 26.58649079,   9.847646  , -55.61144801,   0.61240955,
        -0.72041557,   0.32550876]), 'targetState': array([25., 25., 15.])}
episode index:864
target thresh 17.449545976712677
model initialize at round 864
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.02186165, 14.84627329,  0.98792269,  0.02181578,
       -0.15340414]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31315613712254436
{'scaleFactor': 20, 'currentState': array([ 48.2237416 ,  -0.60533163, -36.03134122,   0.76359835,
        -0.42004362,  -0.49038853]), 'targetState': array([25., 25., 15.])}
episode index:865
target thresh 17.457800609376484
model initialize at round 865
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89938656,  0.98321224,  0.15267271,
       -0.0999236 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3138816844808336
{'scaleFactor': 20, 'currentState': array([25.38282169, 21.24693232, 10.00076682,  0.25107759,  0.67726996,
       -0.69156739]), 'targetState': array([25., 25., 15.])}
episode index:866
target thresh 17.466054416618316
model initialize at round 866
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31351965254948316
{'scaleFactor': 20, 'currentState': array([ 31.80444876, -16.58813951, -35.30751734,  -0.21661544,
        -0.0881578 ,  -0.97226846]), 'targetState': array([25., 25., 15.])}
episode index:867
target thresh 17.474307398520683
model initialize at round 867
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14876241, 14.86204301,  0.97964004,  0.14720567,
       -0.13651332]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31315845479308974
{'scaleFactor': 20, 'currentState': array([  9.71835539,  39.02887956, -12.61244978,  -0.05569344,
        -0.47466539,   0.87840253]), 'targetState': array([25., 25., 15.])}
episode index:868
target thresh 17.482559555166112
model initialize at round 868
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.50150281e+01,  1.48462733e+01,  9.88046713e-01,
        1.49984374e-02, -1.53423403e-01]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3127980883318779
{'scaleFactor': 20, 'currentState': array([ 40.02975492,  11.01369047, -10.83256517,  -0.72697136,
         0.37324185,  -0.57637069]), 'targetState': array([25., 25., 15.])}
episode index:869
target thresh 17.490810886637153
model initialize at round 869
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09435103, 14.92677121,  0.99280138,  0.09461801,
       -0.073436  ]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.3135098897796654
{'scaleFactor': 20, 'currentState': array([28.59359573, 20.43474693, 10.70969258,  0.54685743,  0.44667493,
       -0.70811613]), 'targetState': array([25., 25., 15.])}
episode index:870
target thresh 17.49906139301629
model initialize at round 870
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.05020253, 14.84627329,  0.9869196 ,  0.05004632,
       -0.15324839]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31314994731149126
{'scaleFactor': 20, 'currentState': array([ 18.46528063,  -8.40416962, -13.80075859,   0.92984336,
        -0.16861104,   0.3270499 ]), 'targetState': array([25., 25., 15.])}
episode index:871
target thresh 17.507311074386045
model initialize at round 871
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09330828, 14.84627329,  0.98389987,  0.09273334,
       -0.15277948]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3127908303994368
{'scaleFactor': 20, 'currentState': array([  8.627658  ,  25.3839693 , -53.12723871,  -0.95225493,
        -0.15740943,   0.26159668]), 'targetState': array([25., 25., 15.])}
episode index:872
target thresh 17.515559930828918
model initialize at round 872
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12038975, 14.84627329,  0.98109981,  0.11930743,
       -0.15234469]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3124325362065394
{'scaleFactor': 20, 'currentState': array([ 33.97802948, -28.91201791, -34.12889831,  -0.16908068,
        -0.80739383,  -0.56526713]), 'targetState': array([25., 25., 15.])}
episode index:873
target thresh 17.523807962427373
model initialize at round 873
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.92062759, 14.96587261,  0.9962135 , -0.07987057,
       -0.03434159]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31207506190882023
{'scaleFactor': 20, 'currentState': array([ 49.63038791,  18.97409127, -52.34967257,  -0.30039109,
         0.35312692,  -0.88603983]), 'targetState': array([25., 25., 15.])}
episode index:874
target thresh 17.532055169263916
model initialize at round 874
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10932908, 14.84627329,  0.9823262 ,  0.10848164,
       -0.15253512]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31171840469521017
{'scaleFactor': 20, 'currentState': array([ 30.40010011,  10.80384951, -36.83675687,  -0.93002909,
        -0.33141519,   0.15877615]), 'targetState': array([25., 25., 15.])}
episode index:875
target thresh 17.54030155142101
model initialize at round 875
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12770848, 14.93598357,  0.98974885,  0.12767608,
       -0.06400019]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.31243731079647247
{'scaleFactor': 20, 'currentState': array([26.21721042, 20.37910636, 10.60698546,  0.34293492,  0.6280191 ,
       -0.69856113]), 'targetState': array([25., 25., 15.])}
episode index:876
target thresh 17.548547108981126
model initialize at round 876
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14382048, 14.86705075,  0.98098698,  0.14251113,
       -0.13173887]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3120810538856441
{'scaleFactor': 20, 'currentState': array([46.11176418, 31.52203767,  5.87714935,  0.98180563,  0.06363171,
       -0.17890979]), 'targetState': array([25., 25., 15.])}
episode index:877
target thresh 17.556791842026698
model initialize at round 877
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3117256084939748
{'scaleFactor': 20, 'currentState': array([ 16.39559464,   5.53918509, -32.61639949,  -0.66271356,
        -0.47888742,   0.5757409 ]), 'targetState': array([25., 25., 15.])}
episode index:878
target thresh 17.565035750640202
model initialize at round 878
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.51537267e+01, 1.50019594e+01, 9.88155974e-01,
       1.53440369e-01, 1.95577476e-03]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.312442052795348
{'scaleFactor': 20, 'currentState': array([26.17412953, 21.51243796, 12.22328166,  0.40126694,  0.78642128,
       -0.4696024 ]), 'targetState': array([25., 25., 15.])}
episode index:879
target thresh 17.57327883490405
model initialize at round 879
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87270725,  0.98027714,  0.15221695,
       -0.1260426 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.31315686881421806
{'scaleFactor': 20, 'currentState': array([25.84565822, 21.40462405, 10.94087251,  0.35836457,  0.75404423,
       -0.55044721]), 'targetState': array([25., 25., 15.])}
episode index:880
target thresh 17.581521094900687
model initialize at round 880
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86160139,  0.97886221,  0.15199724,
       -0.13684159]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3128014126634641
{'scaleFactor': 20, 'currentState': array([ 29.83167052,  17.05233286, -19.22745513,  -0.35697308,
         0.42848044,  -0.83004502]), 'targetState': array([25., 25., 15.])}
episode index:881
target thresh 17.589762530712548
model initialize at round 881
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.03756034, 14.84627329,  0.98746415,  0.03746413,
       -0.15333294]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3124467625357278
{'scaleFactor': 20, 'currentState': array([ 17.94610759,  -8.37207589, -40.95515303,   0.099138  ,
        -0.58204262,  -0.80709234]), 'targetState': array([25., 25., 15.])}
episode index:882
target thresh 17.598003142422016
model initialize at round 882
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31209291569253894
{'scaleFactor': 20, 'currentState': array([  8.00963779,   5.85141489, -37.53526998,  -0.55249049,
        -0.42334858,  -0.71800434]), 'targetState': array([25., 25., 15.])}
episode index:883
target thresh 17.606242930111527
model initialize at round 883
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3117398694078189
{'scaleFactor': 20, 'currentState': array([ 42.33073516,  -1.1077529 , -48.2530192 ,   0.81271915,
        -0.55584065,  -0.17472482]), 'targetState': array([25., 25., 15.])}
episode index:884
target thresh 17.614481893863466
model initialize at round 884
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13477515, 14.87742075,  0.9834863 ,  0.1338884 ,
       -0.12177274]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31138762096781003
{'scaleFactor': 20, 'currentState': array([ 22.66498012,  10.64986099, -70.85938874,  -0.41054195,
         0.25833765,  -0.87448097]), 'targetState': array([25., 25., 15.])}
episode index:885
target thresh 17.62272003376022
model initialize at round 885
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3110361676710066
{'scaleFactor': 20, 'currentState': array([19.7997486 ,  7.68462372, -9.19002377, -0.39395238, -0.80971372,
       -0.43493127]), 'targetState': array([25., 25., 15.])}
episode index:886
target thresh 17.63095734988417
model initialize at round 886
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.97295509, 14.84627329,  0.98779802, -0.02698476,
       -0.15338479]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31068550682808554
{'scaleFactor': 20, 'currentState': array([ 20.79494029,  -9.06421543, -32.53596471,  -0.20772354,
        -0.30736182,  -0.92864398]), 'targetState': array([25., 25., 15.])}
episode index:887
target thresh 17.63919384231769
model initialize at round 887
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3103356357618377
{'scaleFactor': 20, 'currentState': array([ 1.14566251e+01, -2.01680569e+01, -2.82144988e+01,  1.33862820e-01,
       -1.76614670e-02, -9.90842479e-01]), 'targetState': array([25., 25., 15.])}
episode index:888
target thresh 17.64742951114315
model initialize at round 888
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.50010943e+01,  1.48462733e+01,  9.88157274e-01,
        1.09224281e-03, -1.53440571e-01]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3099865518071
{'scaleFactor': 20, 'currentState': array([ 34.32261468, -15.83310007, -36.48207668,  -0.47312868,
        -0.51096342,  -0.71768074]), 'targetState': array([25., 25., 15.])}
episode index:889
target thresh 17.655664356442912
model initialize at round 889
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.07229436, 14.90283083,  0.99259989,  0.07248421,
       -0.09742435]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30963825231068753
{'scaleFactor': 20, 'currentState': array([49.55647953, 50.67200613, -5.06767098,  0.7039778 ,  0.16405876,
       -0.69101373]), 'targetState': array([25., 25., 15.])}
episode index:890
target thresh 17.663898378299326
model initialize at round 890
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30929073463132645
{'scaleFactor': 20, 'currentState': array([-43.40346923,  20.90530351, -26.62192555,  -0.43825245,
        -0.88540503,  -0.15489586]), 'targetState': array([25., 25., 15.])}
episode index:891
target thresh 17.672131576794705
model initialize at round 891
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30894399613958734
{'scaleFactor': 20, 'currentState': array([ 1.08932493e+01, -6.40603049e+00, -3.42277878e+01, -1.80391289e-02,
       -1.50999782e-01, -9.88369190e-01]), 'targetState': array([25., 25., 15.])}
episode index:892
target thresh 17.6803639520114
model initialize at round 892
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30859803421781845
{'scaleFactor': 20, 'currentState': array([ 32.01850236, -11.50098629, -19.9556364 ,   0.69953997,
         0.47543617,  -0.53348316]), 'targetState': array([25., 25., 15.])}
episode index:893
target thresh 17.688595504031746
model initialize at round 893
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.9700908 ,  0.98771782,  0.15337233,
       -0.02984026]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3093165935194764
{'scaleFactor': 20, 'currentState': array([25.39612359, 20.17343628, 15.06060611,  0.59204726,  0.78544344,
       -0.18044014]), 'targetState': array([25., 25., 15.])}
episode index:894
target thresh 17.696826232938033
model initialize at round 894
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.95238654,  0.98704382,  0.15326767,
       -0.04747128]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3100229215148747
{'scaleFactor': 20, 'currentState': array([26.03718255, 20.50223502, 10.4824839 ,  0.31388724,  0.61344644,
       -0.72467805]), 'targetState': array([25., 25., 15.])}
episode index:895
target thresh 17.70505613881258
model initialize at round 895
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3096769137899697
{'scaleFactor': 20, 'currentState': array([ 23.78940098,  -3.67362352, -15.52164794,   0.13474467,
        -0.29785736,  -0.94505284]), 'targetState': array([25., 25., 15.])}
episode index:896
target thresh 17.713285221737706
model initialize at round 896
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14563485, 14.86717947,  0.98075061,  0.14427421,
       -0.13157961]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30933167754271224
{'scaleFactor': 20, 'currentState': array([  6.09161127,   7.51084259, -42.61730995,   0.25766219,
        -0.55243727,   0.79273152]), 'targetState': array([25., 25., 15.])}
episode index:897
target thresh 17.721513481795657
model initialize at round 897
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.51537267e+01,  1.49902785e+01,  9.88111347e-01,
        1.53433439e-01, -9.70291905e-03]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.31003562907039406
{'scaleFactor': 20, 'currentState': array([25.30166919, 21.11652908, 10.08336868,  0.23783822,  0.6770689 ,
       -0.69642709]), 'targetState': array([25., 25., 15.])}
episode index:898
target thresh 17.72974091906877
model initialize at round 898
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89677397,  0.98295412,  0.15263263,
       -0.10249137]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30969076185229577
{'scaleFactor': 20, 'currentState': array([ 29.54792843,  33.65375438, -50.98528226,  -0.94795048,
         0.10195328,   0.30165446]), 'targetState': array([25., 25., 15.])}
episode index:899
target thresh 17.73796753363929
model initialize at round 899
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.95092926,  0.9869747 ,  0.15325694,
       -0.04892079]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3103927500606832
{'scaleFactor': 20, 'currentState': array([25.87939329, 21.27726871, 11.35457487,  0.30001743,  0.68565762,
       -0.66322181]), 'targetState': array([25., 25., 15.])}
episode index:900
target thresh 17.746193325589466
model initialize at round 900
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86358696,  0.9791234 ,  0.15203779,
       -0.13491434]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3100482520029022
{'scaleFactor': 20, 'currentState': array([ 33.49534158, -15.24689007, -44.7310389 ,   0.69026605,
        -0.07077634,  -0.72008575]), 'targetState': array([25., 25., 15.])}
episode index:901
target thresh 17.75441829500157
model initialize at round 901
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30970451779890784
{'scaleFactor': 20, 'currentState': array([ 23.2070627 ,  26.79259763, -15.45967966,   0.24592136,
        -0.23697843,   0.93987441]), 'targetState': array([25., 25., 15.])}
episode index:902
target thresh 17.762642441957876
model initialize at round 902
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.03976337,  0.98738049,  0.15331995,
        0.03965815]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3104146900382224
{'scaleFactor': 20, 'currentState': array([25.38552372, 20.16584641, 14.76205904,  0.59291335,  0.78929883,
       -0.15956539]), 'targetState': array([25., 25., 15.])}
episode index:903
target thresh 17.7708657665406
model initialize at round 903
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86263994,  0.97899927,  0.15201852,
       -0.13583373]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31007131095632173
{'scaleFactor': 20, 'currentState': array([ 36.35872048,  10.84693414, -62.45086252,   0.45332555,
        -0.17713148,  -0.87356762]), 'targetState': array([25., 25., 15.])}
episode index:904
target thresh 17.779088268831977
model initialize at round 904
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.92324851, 14.84627329,  0.98527087, -0.07638485,
       -0.15299237]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30972869072322085
{'scaleFactor': 20, 'currentState': array([ 6.91998634, 36.15280088, -7.45629808,  0.03977817, -0.73563334,
        0.67621098]), 'targetState': array([25., 25., 15.])}
episode index:905
target thresh 17.787309948914242
model initialize at round 905
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30938682682617535
{'scaleFactor': 20, 'currentState': array([ 2.48120232, 30.77097974, 26.23386041, -0.97475153, -0.09616656,
        0.20152282]), 'targetState': array([25., 25., 15.])}
episode index:906
target thresh 17.795530806869596
model initialize at round 906
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08495018, 14.855158  ,  0.98591898,  0.0846    ,
       -0.14424493]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30904571676352244
{'scaleFactor': 20, 'currentState': array([-18.98029206,  31.61501199, -41.86410867,  -0.15200423,
        -0.27098587,  -0.95050585]), 'targetState': array([25., 25., 15.])}
episode index:907
target thresh 17.803750842780264
model initialize at round 907
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15068717, 14.84627329,  0.97716684,  0.14873384,
       -0.15173398]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3087053580446199
{'scaleFactor': 20, 'currentState': array([-3.39012398, 30.35408056, 13.61503041, -0.79862686,  0.27548013,
       -0.53507554]), 'targetState': array([25., 25., 15.])}
episode index:908
target thresh 17.811970056728445
model initialize at round 908
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30836574818978535
{'scaleFactor': 20, 'currentState': array([  0.2561356 ,   4.57214853, -27.94210435,  -0.18291538,
         0.79149071,  -0.58316757]), 'targetState': array([25., 25., 15.])}
episode index:909
target thresh 17.820188448796316
model initialize at round 909
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.50251554e+01,  1.49953275e+01,  9.99666209e-01,
        2.54010064e-02, -4.71809439e-03]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3080268847302361
{'scaleFactor': 20, 'currentState': array([-14.22511117,  13.44234545,  -5.38510911,  -0.01753892,
        -0.15736296,  -0.98738507]), 'targetState': array([25., 25., 15.])}
episode index:910
target thresh 17.82840601906608
model initialize at round 910
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.02155006, 14.89898521,  0.99460153,  0.02165022,
       -0.1014843 ]), 'targetState': array([25., 25., 15.])}
done in step count: 45
reward sum = 0.6361854860638709
running average episode reward sum: 0.3083871027338954
{'scaleFactor': 20, 'currentState': array([21.5409087 , 28.59539696, 14.74896764,  0.89617354,  0.08876647,
        0.43473384]), 'targetState': array([25., 25., 15.])}
episode index:911
target thresh 17.836622767619904
model initialize at round 911
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.92289127,  0.98524405,  0.15298821,
       -0.07673831]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.30908128370611815
{'scaleFactor': 20, 'currentState': array([26.22469389, 21.47149499, 11.80699883,  0.45963643,  0.84178115,
       -0.28308805]), 'targetState': array([25., 25., 15.])}
episode index:912
target thresh 17.844838694539945
model initialize at round 912
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13859684, 15.07392515,  0.98764529,  0.13826719,
        0.07374932]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.3097636320787368
{'scaleFactor': 20, 'currentState': array([29.65276167, 20.37785643, 17.29975464,  0.76793409,  0.6262083 ,
        0.13468628]), 'targetState': array([25., 25., 15.])}
episode index:913
target thresh 17.85305379990837
model initialize at round 913
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.51415428e+01, 1.50077003e+01, 9.89904158e-01,
       1.41529058e-01, 7.69953759e-03]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.31045478800578524
{'scaleFactor': 20, 'currentState': array([27.35515231, 20.41174508, 13.20349627,  0.60387872,  0.73338765,
       -0.31220673]), 'targetState': array([25., 25., 15.])}
episode index:914
target thresh 17.861268083807346
model initialize at round 914
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86502683,  0.97931057,  0.15206686,
       -0.13351581]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.31114443320949586
{'scaleFactor': 20, 'currentState': array([26.56396698, 21.01478656, 11.35950081,  0.52012498,  0.76744045,
       -0.37484019]), 'targetState': array([25., 25., 15.])}
episode index:915
target thresh 17.869481546318987
model initialize at round 915
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.92158223,  0.98514473,  0.15297278,
       -0.07803319]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31080475588066453
{'scaleFactor': 20, 'currentState': array([-3.53265608,  4.81441522, 16.17829962, -0.431532  , -0.18294697,
        0.88335188]), 'targetState': array([25., 25., 15.])}
episode index:916
target thresh 17.87769418752546
model initialize at round 916
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.93804103, 14.87136582,  0.98975968, -0.06194393,
       -0.12860296]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3104658193966071
{'scaleFactor': 20, 'currentState': array([ 20.04434671,  -2.89066237, -25.1464296 ,   0.06161069,
         0.34552127,  -0.93638623]), 'targetState': array([25., 25., 15.])}
episode index:917
target thresh 17.88590600750887
model initialize at round 917
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31012762133626226
{'scaleFactor': 20, 'currentState': array([  4.59082725,   6.57598252, -38.64913614,   0.38277723,
        -0.73530391,   0.55929398]), 'targetState': array([25., 25., 15.])}
episode index:918
target thresh 17.89411700635132
model initialize at round 918
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30979015928910636
{'scaleFactor': 20, 'currentState': array([ 17.54148513,   5.01014132, -13.90073215,   0.57653045,
         0.19654133,  -0.79308521]), 'targetState': array([25., 25., 15.])}
episode index:919
target thresh 17.902327184134947
model initialize at round 919
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08731074, 14.85947996,  0.9863234 ,  0.0869865 ,
       -0.13999819]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30945343085509647
{'scaleFactor': 20, 'currentState': array([ 19.86664807,  -8.70953681, -33.33244196,   0.58614456,
        -0.77832003,  -0.22506109]), 'targetState': array([25., 25., 15.])}
episode index:920
target thresh 17.91053654094187
model initialize at round 920
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3091174336446132
{'scaleFactor': 20, 'currentState': array([ 13.10343591,  39.04275376, -21.32802098,   0.20553807,
        -0.3926797 ,   0.89641327]), 'targetState': array([25., 25., 15.])}
episode index:921
target thresh 17.918745076854137
model initialize at round 921
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30878216527840424
{'scaleFactor': 20, 'currentState': array([ 9.66983180e+00,  4.18741605e+01, -4.09844883e+01, -8.63600689e-01,
        9.80457429e-03,  5.04081065e-01]), 'targetState': array([25., 25., 15.])}
episode index:922
target thresh 17.926952791953855
model initialize at round 922
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10904659, 14.84627329,  0.98235604,  0.10820462,
       -0.15253976]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3084476233875284
{'scaleFactor': 20, 'currentState': array([ 16.59273497,  13.08025721, -17.42698879,   0.39715959,
         0.02732678,   0.91734263]), 'targetState': array([25., 25., 15.])}
episode index:923
target thresh 17.9351596863231
model initialize at round 923
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.51537267e+01, 1.50010129e+01, 9.88157359e-01,
       1.53440584e-01, 1.01099187e-03]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.30914301562401375
{'scaleFactor': 20, 'currentState': array([25.36194934, 20.15126902, 14.17913803,  0.59113278,  0.7904687 ,
       -0.16037853]), 'targetState': array([25., 25., 15.])}
episode index:924
target thresh 17.94336576004394
model initialize at round 924
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.94390058,  0.98661234,  0.15320067,
       -0.05590745]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3098266233362051
{'scaleFactor': 20, 'currentState': array([25.82046627, 21.42024185, 11.15888284,  0.31457359,  0.71657738,
       -0.62254342]), 'targetState': array([25., 25., 15.])}
episode index:925
target thresh 17.951571013198443
model initialize at round 925
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3094920373498809
{'scaleFactor': 20, 'currentState': array([  8.68918548,  -8.11420275, -36.98473031,  -0.31602875,
        -0.8620949 ,  -0.39612903]), 'targetState': array([25., 25., 15.])}
episode index:926
target thresh 17.959775445868654
model initialize at round 926
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.07341741, 14.84627329,  0.98551526,  0.07308482,
       -0.15303032]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30915817323191985
{'scaleFactor': 20, 'currentState': array([ 27.08271967,  -4.56850952, -37.20450282,   0.83042369,
        -0.41171152,  -0.37535333]), 'targetState': array([25., 25., 15.])}
episode index:927
target thresh 17.967979058136617
model initialize at round 927
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.02497539, 14.84627329,  0.98785096,  0.02492117,
       -0.15339301]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3088250286486958
{'scaleFactor': 20, 'currentState': array([-2.45030960e+01,  1.81229675e+01, -2.96400046e+01, -1.57251632e-01,
       -1.18845718e-03, -9.87557852e-01]), 'targetState': array([25., 25., 15.])}
episode index:928
target thresh 17.97618185008436
model initialize at round 928
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08626551, 14.84627329,  0.98451497,  0.08578756,
       -0.152875  ]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3084926012766305
{'scaleFactor': 20, 'currentState': array([27.61274072, 23.08140658, -4.1872518 , -0.76228097,  0.46223187,
       -0.45306668]), 'targetState': array([25., 25., 15.])}
episode index:929
target thresh 17.984383821793948
model initialize at round 929
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86866321,  0.9797749 ,  0.15213896,
       -0.1299803 ]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3081608888021395
{'scaleFactor': 20, 'currentState': array([ 18.38434366,   2.13568782, -15.78694637,   0.53813087,
         0.25419096,  -0.80361814]), 'targetState': array([25., 25., 15.])}
episode index:930
target thresh 17.99258497334735
model initialize at round 930
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.90558825, 14.95282766,  0.9943655 , -0.09482807,
       -0.04738035]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30782988892157864
{'scaleFactor': 20, 'currentState': array([ 6.46823264e+01,  2.38321743e+00, -3.95683835e+01, -2.45690732e-01,
       -5.36346424e-02, -9.67863311e-01]), 'targetState': array([25., 25., 15.])}
episode index:931
target thresh 18.000785304826607
model initialize at round 931
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10233821, 14.84627329,  0.98304256,  0.101619  ,
       -0.15264636]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3074995993411907
{'scaleFactor': 20, 'currentState': array([31.21432365, 13.37450444, -7.71996036, -0.17559694,  0.28611757,
       -0.94196733]), 'targetState': array([25., 25., 15.])}
episode index:932
target thresh 18.00898481631372
model initialize at round 932
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.07379152, 14.84627329,  0.98548837,  0.07345523,
       -0.15302614]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3071700177770522
{'scaleFactor': 20, 'currentState': array([ 37.58146518,   0.78059617, -55.61632111,  -0.14312272,
        -0.16445052,  -0.97594668]), 'targetState': array([25., 25., 15.])}
episode index:933
target thresh 18.017183507890678
model initialize at round 933
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3068411419550211
{'scaleFactor': 20, 'currentState': array([ 35.02702415,  12.18640458, -27.37705585,  -0.07402827,
         0.51694029,  -0.85281449]), 'targetState': array([25., 25., 15.])}
episode index:934
target thresh 18.02538137963946
model initialize at round 934
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3065129696106842
{'scaleFactor': 20, 'currentState': array([ 10.2497952 ,   2.82928035, -40.5089956 ,   0.12994437,
        -0.68969396,   0.71234592]), 'targetState': array([25., 25., 15.])}
episode index:935
target thresh 18.033578431642074
model initialize at round 935
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.51537267e+01, 1.50073723e+01, 9.88131111e-01,
       1.53436508e-01, 7.35837338e-03]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3072015134998822
{'scaleFactor': 20, 'currentState': array([25.28313166, 20.11024879, 13.58838581,  0.56873119,  0.77447675,
       -0.2770029 ]), 'targetState': array([25., 25., 15.])}
episode index:936
target thresh 18.04177466398046
model initialize at round 936
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.95113794,  0.98698473,  0.1532585 ,
       -0.04871324]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.30788858771162186
{'scaleFactor': 20, 'currentState': array([25.0694412 , 20.00465472, 12.50058462,  0.50403916,  0.72472534,
       -0.46980604]), 'targetState': array([25., 25., 15.])}
episode index:937
target thresh 18.04997007673659
model initialize at round 937
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3075603482790935
{'scaleFactor': 20, 'currentState': array([ 37.47870939,  10.39843626, -48.30156517,  -0.11506347,
         0.64980786,  -0.7513389 ]), 'targetState': array([25., 25., 15.])}
episode index:938
target thresh 18.058164669992426
model initialize at round 938
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.1016991 , 14.9271777 ,  0.99211257,  0.10191612,
       -0.0729777 ]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.30822542282608806
{'scaleFactor': 20, 'currentState': array([2.93849759e+01, 2.05993457e+01, 1.24916765e+01, 7.46319675e-01,
       6.65278219e-01, 2.02937120e-02]), 'targetState': array([25., 25., 15.])}
episode index:939
target thresh 18.066358443829913
model initialize at round 939
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.06913063, 15.06035451,  0.99573114,  0.06953083,
        0.0607039 ]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.30888908232085494
{'scaleFactor': 20, 'currentState': array([28.58092067, 20.49990262, 11.43461939,  0.40897346,  0.64851124,
       -0.6420077 ]), 'targetState': array([25., 25., 15.])}
episode index:940
target thresh 18.074551398330975
model initialize at round 940
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3085608261228519
{'scaleFactor': 20, 'currentState': array([ 30.93503625,   1.25609547, -26.44655794,  -0.44568273,
         0.20682886,  -0.87096999]), 'targetState': array([25., 25., 15.])}
episode index:941
target thresh 18.08274353357755
model initialize at round 941
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13484411, 14.84627329,  0.97932726,  0.13339042,
       -0.15206945]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30823326685945185
{'scaleFactor': 20, 'currentState': array([30.49468029, 23.13710707, -2.37287815, -0.74519035,  0.51034182,
       -0.42923486]), 'targetState': array([25., 25., 15.])}
episode index:942
target thresh 18.090934849651564
model initialize at round 942
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09642656, 14.84627329,  0.98361251,  0.09580441,
       -0.15273486]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30790640231347155
{'scaleFactor': 20, 'currentState': array([ 39.32823535,  12.63496069, -13.71643816,   0.08144646,
         0.43327321,  -0.89757495]), 'targetState': array([25., 25., 15.])}
episode index:943
target thresh 18.099125346634924
model initialize at round 943
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.05475547, 14.84627329,  0.98668534,  0.05457214,
       -0.15321201]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3075802302771225
{'scaleFactor': 20, 'currentState': array([ 36.32592836, -10.17390313, -63.70145942,   0.78634216,
        -0.53896196,  -0.30197022]), 'targetState': array([25., 25., 15.])}
episode index:944
target thresh 18.107315024609537
model initialize at round 944
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30725474855196155
{'scaleFactor': 20, 'currentState': array([-23.06263447,   5.30741185, -13.63065328,  -0.22493633,
        -0.76198766,  -0.60727131]), 'targetState': array([25., 25., 15.])}
episode index:945
target thresh 18.115503883657304
model initialize at round 945
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08229062, 14.84627329,  0.9848413 ,  0.08186182,
       -0.15292567]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30692995494884107
{'scaleFactor': 20, 'currentState': array([ 21.67402744,  11.75082534, -12.40780723,   0.24169654,
         0.24806392,  -0.93810824]), 'targetState': array([25., 25., 15.])}
episode index:946
target thresh 18.123691923860108
model initialize at round 946
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09217473, 14.84627329,  0.98400205,  0.09161629,
       -0.15279535]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3066058472878603
{'scaleFactor': 20, 'currentState': array([ 3.96782095e+01, -8.64386438e+00, -3.76961374e+01,  9.55444570e-01,
       -2.62073747e-02, -2.94004844e-01]), 'targetState': array([25., 25., 15.])}
episode index:947
target thresh 18.131879145299823
model initialize at round 947
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3062824233983161
{'scaleFactor': 20, 'currentState': array([  1.99042663, -18.47796277,  22.78500578,   0.10071448,
        -0.92169345,   0.37461684]), 'targetState': array([25., 25., 15.])}
episode index:948
target thresh 18.140065548058327
model initialize at round 948
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.94203307, 14.93568916,  0.99619767, -0.05832982,
       -0.06471345]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30595968111865507
{'scaleFactor': 20, 'currentState': array([ 32.83737266,  40.03791555, -31.45158206,  -0.37006738,
        -0.27341972,   0.88785798]), 'targetState': array([25., 25., 15.])}
episode index:949
target thresh 18.148251132217496
model initialize at round 949
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3056376182964249
{'scaleFactor': 20, 'currentState': array([ 26.80045609,   8.83030292, -40.1574843 ,  -0.17372413,
        -0.10018108,  -0.9796855 ]), 'targetState': array([25., 25., 15.])}
episode index:950
target thresh 18.15643589785917
model initialize at round 950
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3053162327882268
{'scaleFactor': 20, 'currentState': array([ 27.08017141, -11.67509252, -33.52759077,  -0.82198664,
        -0.03422282,  -0.56847758]), 'targetState': array([25., 25., 15.])}
episode index:951
target thresh 18.1646198450652
model initialize at round 951
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.92516264,  0.98541248,  0.15301436,
       -0.07449058]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.30599446158771393
{'scaleFactor': 20, 'currentState': array([24.97541589, 20.03415915, 12.16284981,  0.55476418,  0.7910524 ,
       -0.25782323]), 'targetState': array([25., 25., 15.])}
episode index:952
target thresh 18.172802973917435
model initialize at round 952
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.03818096,  0.98744106,  0.15332936,
        0.03808227]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.30666128812267013
{'scaleFactor': 20, 'currentState': array([26.3975577 , 21.55075864, 17.62505279,  0.4682543 ,  0.83249244,
        0.29613215]), 'targetState': array([25., 25., 15.])}
episode index:953
target thresh 18.180985284497698
model initialize at round 953
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.01994011,  0.9879622 ,  0.15341028,
        0.01989907]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.30733668514759394
{'scaleFactor': 20, 'currentState': array([25.43298717, 20.10835347, 14.32266582,  0.64989652,  0.75312932,
       -0.10213094]), 'targetState': array([25., 25., 15.])}
episode index:954
target thresh 18.18916677688781
model initialize at round 954
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.91846719,  0.9849018 ,  0.15293506,
       -0.08111294]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3070148666291148
{'scaleFactor': 20, 'currentState': array([ 4.35970687e+01, -4.81782107e+00, -1.27461571e+01,  2.49827391e-01,
        1.13534624e-02, -9.68223824e-01]), 'targetState': array([25., 25., 15.])}
episode index:955
target thresh 18.197347451169588
model initialize at round 955
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.49916323e+01,  1.48462733e+01,  9.88123399e-01,
       -8.35188756e-03, -1.53435310e-01]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30669372137113454
{'scaleFactor': 20, 'currentState': array([ 31.68736051,  -0.7659926 , -24.2370681 ,   0.23349797,
         0.48565583,  -0.84238775]), 'targetState': array([25., 25., 15.])}
episode index:956
target thresh 18.20552730742484
model initialize at round 956
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.9552623 ,  0.98717413,  0.15328791,
       -0.04461   ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3073570300733601
{'scaleFactor': 20, 'currentState': array([25.81593613, 21.22446444, 10.87245243,  0.33284473,  0.65954253,
       -0.673957  ]), 'targetState': array([25., 25., 15.])}
episode index:957
target thresh 18.21370634573537
model initialize at round 957
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30703619810042343
{'scaleFactor': 20, 'currentState': array([ 32.42936075, -10.06614451, -38.3762317 ,   0.75604834,
        -0.61966653,  -0.21072328]), 'targetState': array([25., 25., 15.])}
episode index:958
target thresh 18.221884566182954
model initialize at round 958
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.94689346,  0.98677251,  0.15322555,
       -0.05293341]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.30769776634995477
{'scaleFactor': 20, 'currentState': array([25.28457018, 21.07499014, 10.03382638,  0.2255305 ,  0.6617668 ,
       -0.714983  ]), 'targetState': array([25., 25., 15.])}
episode index:959
target thresh 18.230061968849387
model initialize at round 959
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30737724784334025
{'scaleFactor': 20, 'currentState': array([ 25.40149805,   1.98655291, -44.65575833,  -0.63868341,
         0.17642302,  -0.74897157]), 'targetState': array([25., 25., 15.])}
episode index:960
target thresh 18.238238553816444
model initialize at round 960
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3070573963887686
{'scaleFactor': 20, 'currentState': array([34.44119868, 27.15093403,  3.4218825 , -0.17142369,  0.93317567,
       -0.31590678]), 'targetState': array([25., 25., 15.])}
episode index:961
target thresh 18.246414321165883
model initialize at round 961
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.04638332, 14.90063912,  0.9939218 ,  0.04656707,
       -0.09975449]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.306738209906036
{'scaleFactor': 20, 'currentState': array([ 23.46669152,  76.30373195, -42.47942623,   0.46389298,
         0.52060187,  -0.71678239]), 'targetState': array([25., 25., 15.])}
episode index:962
target thresh 18.254589270979473
model initialize at round 962
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11475454, 14.93531194,  0.9912631 ,  0.11490095,
       -0.06477059]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3064196863235791
{'scaleFactor': 20, 'currentState': array([  9.28585973,   3.50416315, -24.49033876,  -0.33773102,
        -0.25203996,  -0.90687023]), 'targetState': array([25., 25., 15.])}
episode index:963
target thresh 18.262763403338933
model initialize at round 963
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.079059  , 14.84627329,  0.98509549,  0.07866733,
       -0.15296514]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30610182357843013
{'scaleFactor': 20, 'currentState': array([ 28.48889451,  13.2347543 , -19.04270164,  -0.41727093,
         0.3843409 ,  -0.82350898]), 'targetState': array([25., 25., 15.])}
episode index:964
target thresh 18.27093671832605
model initialize at round 964
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89235443,  0.98250289,  0.15256256,
       -0.10683038]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.30676024671399754
{'scaleFactor': 20, 'currentState': array([26.11268233, 21.01119881, 10.80120103,  0.36753644,  0.6626368 ,
       -0.65255608]), 'targetState': array([25., 25., 15.])}
episode index:965
target thresh 18.279109216022515
model initialize at round 965
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85111685,  0.97742419,  0.15177394,
       -0.14699191]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30644268952278225
{'scaleFactor': 20, 'currentState': array([-35.72212879,   8.10378949, -20.37843517,   0.10386074,
        -0.33697918,  -0.93576599]), 'targetState': array([25., 25., 15.])}
episode index:966
target thresh 18.287280896510072
model initialize at round 966
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.07389361, 14.84627329,  0.98548101,  0.07355631,
       -0.153025  ]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3061257891199665
{'scaleFactor': 20, 'currentState': array([ 21.23197054,  17.16723679, -21.71016922,   0.75353546,
        -0.17885326,   0.63261032]), 'targetState': array([25., 25., 15.])}
episode index:967
target thresh 18.295451759870453
model initialize at round 967
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30580954347004924
{'scaleFactor': 20, 'currentState': array([25.51983314, 35.43034675,  3.73812468,  0.35728595,  0.80359243,
       -0.47601046]), 'targetState': array([25., 25., 15.])}
episode index:968
target thresh 18.303621806185333
model initialize at round 968
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.91137378,  0.98431404,  0.1528438 ,
       -0.08811721]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3064655502873154
{'scaleFactor': 20, 'currentState': array([25.74672362, 20.83294148, 10.24868317,  0.27721925,  0.63999758,
       -0.71662583]), 'targetState': array([25., 25., 15.])}
episode index:969
target thresh 18.31179103553644
model initialize at round 969
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30614960642103983
{'scaleFactor': 20, 'currentState': array([21.30997752,  9.32011934,  4.00784971,  0.77760894, -0.59814643,
       -0.19376582]), 'targetState': array([25., 25., 15.])}
episode index:970
target thresh 18.319959448005452
model initialize at round 970
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30583431331453004
{'scaleFactor': 20, 'currentState': array([ 10.85246556,  -2.87937553, -36.17570155,  -0.91255516,
        -0.39408833,   0.10925871]), 'targetState': array([25., 25., 15.])}
episode index:971
target thresh 18.32812704367407
model initialize at round 971
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.06739984, 14.86062064,  0.9879918 ,  0.06726312,
       -0.13909663]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30551966895926813
{'scaleFactor': 20, 'currentState': array([  7.86570335,   2.61770486, -24.26044239,   0.10253272,
        -0.08009855,  -0.9914995 ]), 'targetState': array([25., 25., 15.])}
episode index:972
target thresh 18.33629382262394
model initialize at round 972
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12700646, 14.84627329,  0.98031212,  0.12576361,
       -0.15222238]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3052056713549935
{'scaleFactor': 20, 'currentState': array([ 29.81465392, -10.44793693, -19.481408  ,  -0.11252939,
         0.25947181,  -0.95917231]), 'targetState': array([25., 25., 15.])}
episode index:973
target thresh 18.344459784936774
model initialize at round 973
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3048923185096598
{'scaleFactor': 20, 'currentState': array([ 16.97586434,  21.66466276, -13.81893598,  -0.95170195,
         0.30407681,  -0.0424346 ]), 'targetState': array([25., 25., 15.])}
episode index:974
target thresh 18.352624930694184
model initialize at round 974
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30457960843939347
{'scaleFactor': 20, 'currentState': array([ 10.89515853,  14.59562279, -14.83117048,  -0.89908928,
        -0.43486565,  -0.05030243]), 'targetState': array([25., 25., 15.])}
episode index:975
target thresh 18.36078925997784
model initialize at round 975
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.51537267e+01,  1.49987892e+01,  9.88157142e-01,
        1.53440550e-01, -1.20857685e-03]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.30523217046906725
{'scaleFactor': 20, 'currentState': array([26.7253074 , 21.54154206, 14.84536075,  0.5009155 ,  0.84966537,
       -0.16477992]), 'targetState': array([25., 25., 15.])}
episode index:976
target thresh 18.368952772869395
model initialize at round 976
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89674012,  0.98295073,  0.1526321 ,
       -0.10252462]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.30588339665016445
{'scaleFactor': 20, 'currentState': array([26.62685932, 20.79869423, 11.38809448,  0.5254348 ,  0.6488978 ,
       -0.55031801]), 'targetState': array([25., 25., 15.])}
episode index:977
target thresh 18.377115469450477
model initialize at round 977
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.0685832 , 14.84627329,  0.98585063,  0.06829575,
       -0.1530824 ]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3055706324409107
{'scaleFactor': 20, 'currentState': array([16.73093009, 12.64310141, -3.16964862,  0.82409505, -0.44223951,
       -0.35396547]), 'targetState': array([25., 25., 15.])}
episode index:978
target thresh 18.38527734980272
model initialize at round 978
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.49628796e+01,  1.49883678e+01,  9.99228915e-01,
       -3.74664355e-02, -1.17406074e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 40
reward sum = 0.6689717585696803
running average episode reward sum: 0.3059418286882332
{'scaleFactor': 20, 'currentState': array([27.64811504, 27.72463071, 11.13045459,  0.85337124, -0.07928184,
        0.51523966]), 'targetState': array([25., 25., 15.])}
episode index:979
target thresh 18.393438414007722
model initialize at round 979
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87343492,  0.98036592,  0.15223073,
       -0.12533342]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3066000411588575
{'scaleFactor': 20, 'currentState': array([24.96192907, 20.02821008, 12.01162267,  0.54062123,  0.77718925,
       -0.32203347]), 'targetState': array([25., 25., 15.])}
episode index:980
target thresh 18.401598662147112
model initialize at round 980
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.03837127,  0.98743391,  0.15332825,
        0.03827181]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.30725691170803293
{'scaleFactor': 20, 'currentState': array([25.38875723, 20.17368238, 15.12267692,  0.59491075,  0.79062894,
       -0.14486917]), 'targetState': array([25., 25., 15.])}
episode index:981
target thresh 18.409758094302497
model initialize at round 981
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84783519,  0.9769539 ,  0.15170092,
       -0.1501596 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3079027602189219
{'scaleFactor': 20, 'currentState': array([25.42735259, 21.39094776, 10.03968431,  0.29947714,  0.7466145 ,
       -0.59403722]), 'targetState': array([25., 25., 15.])}
episode index:982
target thresh 18.41791671055545
model initialize at round 982
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87062548,  0.98002046,  0.15217709,
       -0.12807038]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3075895325889942
{'scaleFactor': 20, 'currentState': array([ 18.86406353,  -0.71056165, -23.43714031,  -0.56174571,
         0.41044085,  -0.71831753]), 'targetState': array([25., 25., 15.])}
episode index:983
target thresh 18.42607451098758
model initialize at round 983
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.93500317,  0.98608489,  0.15311877,
       -0.06473979]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3082337303703072
{'scaleFactor': 20, 'currentState': array([26.4282766 , 20.8966359 , 11.36355653,  0.47322557,  0.6229924 ,
       -0.62284671]), 'targetState': array([25., 25., 15.])}
episode index:984
target thresh 18.434231495680454
model initialize at round 984
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10714739, 14.84627329,  0.98255467,  0.10634159,
       -0.1525706 ]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30792080272526123
{'scaleFactor': 20, 'currentState': array([  1.85462807,  -0.87745686, -27.27124119,   0.04164139,
        -0.84889886,  -0.52691245]), 'targetState': array([25., 25., 15.])}
episode index:985
target thresh 18.442387664715632
model initialize at round 985
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12791367, 14.95534238,  0.99076506,  0.12801252,
       -0.04469214]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30760850982188875
{'scaleFactor': 20, 'currentState': array([22.26648871, 28.26605288, 30.07609271, -0.37044506,  0.52170593,
        0.76850074]), 'targetState': array([25., 25., 15.])}
episode index:986
target thresh 18.45054301817468
model initialize at round 986
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08625009, 15.04092517,  0.99538268,  0.08671904,
        0.04114768]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.3082411915220763
{'scaleFactor': 20, 'currentState': array([28.94808623, 20.47381586, 11.79649404,  0.56882211,  0.51206972,
       -0.64360392]), 'targetState': array([25., 25., 15.])}
episode index:987
target thresh 18.45869755613917
model initialize at round 987
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3079292065104143
{'scaleFactor': 20, 'currentState': array([ 18.9318488 ,  -6.54523433, -24.61378521,  -0.47894591,
         0.18238541,  -0.85868875]), 'targetState': array([25., 25., 15.])}
episode index:988
target thresh 18.466851278690644
model initialize at round 988
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.96480557, 14.97317257,  0.99900243, -0.03551447,
       -0.02707139]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3076178524087859
{'scaleFactor': 20, 'currentState': array([ 54.08618038,  -6.97679046, -25.52910678,  -0.17750304,
         0.89683859,  -0.40518294]), 'targetState': array([25., 25., 15.])}
episode index:989
target thresh 18.475004185910613
model initialize at round 989
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.97062612,  0.98773342,  0.15337475,
       -0.02930663]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3082581173552427
{'scaleFactor': 20, 'currentState': array([26.07543966, 20.89703904, 10.98923509,  0.32899302,  0.65958225,
       -0.67580682]), 'targetState': array([25., 25., 15.])}
episode index:990
target thresh 18.48315627788063
model initialize at round 990
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30794705971916275
{'scaleFactor': 20, 'currentState': array([  7.28132802,  -1.8132903 , -26.85442103,  -0.44925387,
        -0.1342782 ,  -0.88325552]), 'targetState': array([25., 25., 15.])}
episode index:991
target thresh 18.491307554682212
model initialize at round 991
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86143632,  0.97884033,  0.15199384,
       -0.13700174]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3076366292154136
{'scaleFactor': 20, 'currentState': array([ 8.26745685, -4.17003122, -6.58014837,  0.08877019,  0.19549131,
       -0.97667958]), 'targetState': array([25., 25., 15.])}
episode index:992
target thresh 18.499458016396876
model initialize at round 992
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30732682394933564
{'scaleFactor': 20, 'currentState': array([  7.15866196,   8.95838839, -17.62384301,  -0.77252556,
         0.10237369,  -0.62667686]), 'targetState': array([25., 25., 15.])}
episode index:993
target thresh 18.507607663106096
model initialize at round 993
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10875718, 14.84627329,  0.98238652,  0.1079208 ,
       -0.15254449]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30701764203389365
{'scaleFactor': 20, 'currentState': array([  5.80197579,  -3.60721636, -29.92652927,   0.07219877,
        -0.45667949,  -0.88669678]), 'targetState': array([25., 25., 15.])}
episode index:994
target thresh 18.515756494891413
model initialize at round 994
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.8833661 ,  0.98152897,  0.15241133,
       -0.11563591]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3067090815896385
{'scaleFactor': 20, 'currentState': array([ 9.71754833, 24.83224314, -5.81668509,  0.68436678, -0.54839834,
        0.48052197]), 'targetState': array([25., 25., 15.])}
episode index:995
target thresh 18.523904511834278
model initialize at round 995
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30640114074466895
{'scaleFactor': 20, 'currentState': array([ 25.59684066,  -4.65263796, -25.67048537,   0.57035893,
         0.28516836,  -0.77030493]), 'targetState': array([25., 25., 15.])}
episode index:996
target thresh 18.532051714016195
model initialize at round 996
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3060938176345941
{'scaleFactor': 20, 'currentState': array([ 12.27115765,  11.91407812, -24.52627367,  -0.81499994,
         0.11295578,  -0.56834505]), 'targetState': array([25., 25., 15.])}
episode index:997
target thresh 18.540198101518634
model initialize at round 997
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3057871104024953
{'scaleFactor': 20, 'currentState': array([ 28.01083203,   3.02129961, -50.41815322,   0.07900573,
        -0.44226106,  -0.89339983]), 'targetState': array([25., 25., 15.])}
episode index:998
target thresh 18.54834367442305
model initialize at round 998
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3054810171988892
{'scaleFactor': 20, 'currentState': array([ 21.07022144,  14.43787687, -23.479032  ,   0.47146289,
         0.63686986,  -0.610016  ]), 'targetState': array([25., 25., 15.])}
episode index:999
target thresh 18.5564884328109
model initialize at round 999
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.06746403, 15.05757353,  0.99601108,  0.06787365,
        0.0579231 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3061170163310913
{'scaleFactor': 20, 'currentState': array([27.03547367, 20.76390214, 16.33441927,  0.55817729,  0.82879092,
       -0.03929022]), 'targetState': array([25., 25., 15.])}
episode index:1000
target thresh 18.564632376763647
model initialize at round 1000
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.93054867,  0.98579206,  0.1530733 ,
       -0.06915613]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3067612451358554
{'scaleFactor': 20, 'currentState': array([2.54232287e+01, 2.01398267e+01, 1.47420538e+01, 6.44109368e-01,
       7.64705276e-01, 1.86805466e-02]), 'targetState': array([25., 25., 15.])}
episode index:1001
target thresh 18.572775506362692
model initialize at round 1001
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.50639403e+01, 1.50010351e+01, 9.97920270e-01,
       6.44518829e-02, 1.04339648e-03]), 'targetState': array([25., 25., 15.])}
done in step count: 43
reward sum = 0.6491026283684022
running average episode reward sum: 0.30710290320295375
{'scaleFactor': 20, 'currentState': array([26.1040471 , 28.93028891, 10.22620452,  0.65119884,  0.69924933,
        0.29494143]), 'targetState': array([25., 25., 15.])}
episode index:1002
target thresh 18.580917821689503
model initialize at round 1002
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12918216, 14.94112903,  0.98987438,  0.12916577,
       -0.0588635 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.30773538300973147
{'scaleFactor': 20, 'currentState': array([26.10162481, 21.0337644 , 10.958133  ,  0.38680166,  0.75132113,
       -0.53469714]), 'targetState': array([25., 25., 15.])}
episode index:1003
target thresh 18.589059322825495
model initialize at round 1003
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.91473652,  0.98459866,  0.15288799,
       -0.08479829]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.30836660289657536
{'scaleFactor': 20, 'currentState': array([25.75730986, 21.42056091, 10.76795951,  0.33781956,  0.74036534,
       -0.58115154]), 'targetState': array([25., 25., 15.])}
episode index:1004
target thresh 18.597200009852077
model initialize at round 1004
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.07184487, 14.85050993,  0.98625492,  0.07157308,
       -0.14892457]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30805977045588223
{'scaleFactor': 20, 'currentState': array([ 2.83564689e+01, -1.07108400e+01, -1.46894492e+01,  9.99952412e-01,
       -8.51126872e-03,  4.76775713e-03]), 'targetState': array([25., 25., 15.])}
episode index:1005
target thresh 18.605339882850657
model initialize at round 1005
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.05874998, 14.91476994,  0.99457777,  0.05902164,
       -0.08562416]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3077535480200414
{'scaleFactor': 20, 'currentState': array([ 24.20598266,  20.21171998, -19.64724143,  -0.10452652,
         0.88139259,  -0.46067485]), 'targetState': array([25., 25., 15.])}
episode index:1006
target thresh 18.61347894190264
model initialize at round 1006
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.07885919, 14.95939358,  0.9960103 ,  0.07933795,
       -0.04085294]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30744793377175933
{'scaleFactor': 20, 'currentState': array([ 48.43628602,  34.29536226, -23.15778112,  -0.9319301 ,
         0.31859897,   0.17320794]), 'targetState': array([25., 25., 15.])}
episode index:1007
target thresh 18.621617187089413
model initialize at round 1007
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.05595317, 14.85763532,  0.98827279,  0.05585555,
       -0.14211631]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30714292590095404
{'scaleFactor': 20, 'currentState': array([ 61.93159444, -18.37173369, -22.4963759 ,   0.7248486 ,
         0.60447189,  -0.3304667 ]), 'targetState': array([25., 25., 15.])}
episode index:1008
target thresh 18.629754618492345
model initialize at round 1008
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87937625,  0.98107264,  0.15234047,
       -0.11953602]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3077716050124506
{'scaleFactor': 20, 'currentState': array([25.86891102, 21.56352527, 11.19416311,  0.37686076,  0.81858232,
       -0.43347312]), 'targetState': array([25., 25., 15.])}
episode index:1009
target thresh 18.63789123619283
model initialize at round 1009
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.93316255,  0.98596621,  0.15310034,
       -0.06656512]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.30839903921481554
{'scaleFactor': 20, 'currentState': array([25.32362961, 21.11572912, 10.02914928,  0.22936805,  0.65977516,
       -0.71560257]), 'targetState': array([25., 25., 15.])}
episode index:1010
target thresh 18.64602704027223
model initialize at round 1010
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.88061403,  0.98121578,  0.1523627 ,
       -0.11832666]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3090252322021411
{'scaleFactor': 20, 'currentState': array([25.48234533, 21.42280512, 10.19555069,  0.32014272,  0.77560878,
       -0.54400336]), 'targetState': array([25., 25., 15.])}
episode index:1011
target thresh 18.654162030811893
model initialize at round 1011
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.88885982,  0.98213317,  0.15250515,
       -0.11025703]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3087198713007556
{'scaleFactor': 20, 'currentState': array([ 4.57356264e+01,  1.65682765e+01, -3.60919383e+01,  4.55795528e-02,
        7.99374643e-01, -5.99101564e-01]), 'targetState': array([25., 25., 15.])}
episode index:1012
target thresh 18.66229620789318
model initialize at round 1012
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13383918, 15.03007606,  0.99053628,  0.13391168,
        0.03009235]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.30934451125939355
{'scaleFactor': 20, 'currentState': array([26.66308633, 21.49977474, 16.19140915,  0.50715821,  0.8564594 ,
       -0.09626967]), 'targetState': array([25., 25., 15.])}
episode index:1013
target thresh 18.670429571597424
model initialize at round 1013
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85550136,  0.97803754,  0.15186918,
       -0.14275262]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30903943777688925
{'scaleFactor': 20, 'currentState': array([ 30.13874873,  12.15403541, -19.81081327,   0.2645158 ,
         0.29410639,  -0.91844043]), 'targetState': array([25., 25., 15.])}
episode index:1014
target thresh 18.67856212200598
model initialize at round 1014
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.50072138e+01,  1.48462733e+01,  9.88132249e-01,
        7.20017317e-03, -1.53436685e-01]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30873496542439965
{'scaleFactor': 20, 'currentState': array([-15.33924478,   4.2943144 ,   1.50641545,   0.66824561,
        -0.4146041 ,  -0.61769835]), 'targetState': array([25., 25., 15.])}
episode index:1015
target thresh 18.686693859200133
model initialize at round 1015
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.04384321, 14.84627329,  0.98721302,  0.04371979,
       -0.15329395]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3084310924269347
{'scaleFactor': 20, 'currentState': array([ 17.27720096,  -3.36369214, -52.21417761,  -0.22010516,
         0.17385082,  -0.95985916]), 'targetState': array([25., 25., 15.])}
episode index:1016
target thresh 18.694824783261243
model initialize at round 1016
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08132505, 14.84627329,  0.98491829,  0.08090761,
       -0.15293762]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3081278170164854
{'scaleFactor': 20, 'currentState': array([ 2.15933679e+01,  5.50304715e+01,  1.71221016e+01,  9.67802275e-01,
       -4.37770313e-02,  2.47875631e-01]), 'targetState': array([25., 25., 15.])}
episode index:1017
target thresh 18.702954894270583
model initialize at round 1017
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.95634082,  0.98722092,  0.15329517,
       -0.04353662]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3087593123336598
{'scaleFactor': 20, 'currentState': array([25.49599614, 20.06703514, 14.55569324,  0.65021121,  0.75270953,
       -0.10321696]), 'targetState': array([25., 25., 15.])}
episode index:1018
target thresh 18.711084192309492
model initialize at round 1018
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12968887, 14.97132094,  0.99111976,  0.12983556,
       -0.0287115 ]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3084563100644413
{'scaleFactor': 20, 'currentState': array([  4.30791885,  -3.48728243, -20.255782  ,   0.59358549,
        -0.80042527,   0.08352037]), 'targetState': array([25., 25., 15.])}
episode index:1019
target thresh 18.71921267745922
model initialize at round 1019
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.49865674e+01,  1.49066145e+01,  9.95489690e-01,
       -1.35070599e-02, -9.39033317e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.3090676914740908
{'scaleFactor': 20, 'currentState': array([28.50191658, 20.03237786, 10.50884372,  0.39802562,  0.66136356,
       -0.63574668]), 'targetState': array([25., 25., 15.])}
episode index:1020
target thresh 18.727340349801093
model initialize at round 1020
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87989604,  0.98113292,  0.15234983,
       -0.11902823]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30876498070869013
{'scaleFactor': 20, 'currentState': array([ 21.19995269,  17.00566186, -20.70684601,  -0.94598607,
         0.12173284,  -0.30048538]), 'targetState': array([25., 25., 15.])}
episode index:1021
target thresh 18.735467209416356
model initialize at round 1021
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.90349464,  0.98360513,  0.15273372,
       -0.09588198]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30846286233226283
{'scaleFactor': 20, 'currentState': array([ 23.27758217,  12.92229105, -24.92648374,  -0.2543399 ,
         0.70439549,  -0.66267504]), 'targetState': array([25., 25., 15.])}
episode index:1022
target thresh 18.743593256386294
model initialize at round 1022
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87561775,  0.98062933,  0.15227164,
       -0.12320494]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30816133460759787
{'scaleFactor': 20, 'currentState': array([ 13.76373241,   8.34260943, -38.50621456,  -0.92183201,
        -0.32862638,   0.20550049]), 'targetState': array([25., 25., 15.])}
episode index:1023
target thresh 18.751718490792157
model initialize at round 1023
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.91896954,  0.98494161,  0.15294124,
       -0.08061644]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30786039580427016
{'scaleFactor': 20, 'currentState': array([ 23.06025584,  -2.38549921, -20.32828268,  -0.18917484,
        -0.62083745,  -0.76077181]), 'targetState': array([25., 25., 15.])}
episode index:1024
target thresh 18.759842912715207
model initialize at round 1024
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30756004419860744
{'scaleFactor': 20, 'currentState': array([ 41.39602473, -20.31591686, -47.59354365,   0.47461254,
        -0.85045454,  -0.22687005]), 'targetState': array([25., 25., 15.])}
episode index:1025
target thresh 18.76796652223669
model initialize at round 1025
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12950668, 14.84627329,  0.98000404,  0.12819906,
       -0.15217454]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3072602780736575
{'scaleFactor': 20, 'currentState': array([15.96110004,  3.07811636, -7.44499468, -0.24684462,  0.16959182,
       -0.95409976]), 'targetState': array([25., 25., 15.])}
episode index:1026
target thresh 18.776089319437837
model initialize at round 1026
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3069610957191554
{'scaleFactor': 20, 'currentState': array([ -7.47926058,  -3.60329111, -12.96271094,   0.13395126,
         0.07782818,  -0.98792704]), 'targetState': array([25., 25., 15.])}
episode index:1027
target thresh 18.78421130439989
model initialize at round 1027
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3066624954314909
{'scaleFactor': 20, 'currentState': array([ 18.37352434,   9.40550486, -24.16541066,  -0.78477217,
         0.49882948,  -0.36783392]), 'targetState': array([25., 25., 15.])}
episode index:1028
target thresh 18.79233247720404
model initialize at round 1028
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.07558654, 14.84627329,  0.98535747,  0.07523208,
       -0.15300582]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.306364475513676
{'scaleFactor': 20, 'currentState': array([  2.22849502,  -3.907803  , -21.51397886,  -0.73219964,
        -0.65532224,  -0.18557062]), 'targetState': array([25., 25., 15.])}
episode index:1029
target thresh 18.800452837931502
model initialize at round 1029
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30606703427531323
{'scaleFactor': 20, 'currentState': array([22.53491497, 25.03300162, -4.08209535, -0.07826794,  0.68376551,
       -0.72549215]), 'targetState': array([25., 25., 15.])}
episode index:1030
target thresh 18.808572386663513
model initialize at round 1030
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.51487080e+01,  1.49848240e+01,  9.88792240e-01,
        1.48526618e-01, -1.51575169e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.30669256581326154
{'scaleFactor': 20, 'currentState': array([25.4108432 , 20.11870242, 14.42112537,  0.60037182,  0.7907254 ,
       -0.11961196]), 'targetState': array([25., 25., 15.])}
episode index:1031
target thresh 18.816691123481245
model initialize at round 1031
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.07763463,  0.98520435,  0.15298204,
        0.07725856]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3073168850807874
{'scaleFactor': 20, 'currentState': array([25.33375515, 20.14717968, 16.25852554,  0.58128817,  0.7821896 ,
        0.2242398 ]), 'targetState': array([25., 25., 15.])}
episode index:1032
target thresh 18.824809048465884
model initialize at round 1032
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.51537267e+01, 1.50125239e+01, 9.88080666e-01,
       1.53428675e-01, 1.24996075e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3079307894992968
{'scaleFactor': 20, 'currentState': array([26.42743916, 21.23022662, 12.38823696,  0.40203649,  0.74324594,
       -0.53474492]), 'targetState': array([25., 25., 15.])}
episode index:1033
target thresh 18.832926161698605
model initialize at round 1033
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3076329840935915
{'scaleFactor': 20, 'currentState': array([ 26.47357652,   2.43772142, -22.80394271,  -0.35669828,
        -0.08159797,  -0.93064929]), 'targetState': array([25., 25., 15.])}
episode index:1034
target thresh 18.841042463260603
model initialize at round 1034
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13845988, 14.84627329,  0.97885409,  0.13690103,
       -0.15199598]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3073357541572692
{'scaleFactor': 20, 'currentState': array([ 30.54493106,  32.28230107, -58.59281988,   0.19384782,
         0.75693238,  -0.62408044]), 'targetState': array([25., 25., 15.])}
episode index:1035
target thresh 18.84915795323301
model initialize at round 1035
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87229089,  0.98022612,  0.15220902,
       -0.12644829]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30703909802391277
{'scaleFactor': 20, 'currentState': array([16.17800062,  8.5644301 , -4.68492018, -0.59254086,  0.14429888,
       -0.79251067]), 'targetState': array([25., 25., 15.])}
episode index:1036
target thresh 18.857272631696997
model initialize at round 1036
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87128159,  0.98010179,  0.15218972,
       -0.12743145]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3067430140335329
{'scaleFactor': 20, 'currentState': array([  3.3083575 ,   9.83371268, -22.21077899,  -0.90228739,
        -0.42906508,  -0.04219748]), 'targetState': array([25., 25., 15.])}
episode index:1037
target thresh 18.865386498733717
model initialize at round 1037
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89487816,  0.9827628 ,  0.15260292,
       -0.10435337]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3073545141639447
{'scaleFactor': 20, 'currentState': array([25.83428157, 21.02098393, 10.46253079,  0.30696509,  0.6729175 ,
       -0.67301893]), 'targetState': array([25., 25., 15.])}
episode index:1038
target thresh 18.8734995544243
model initialize at round 1038
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12697943, 14.84627329,  0.98031542,  0.12573727,
       -0.15222289]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3070586965372229
{'scaleFactor': 20, 'currentState': array([ 34.01502394,   7.85328888, -16.946881  ,   0.64002384,
         0.75526617,   0.14121788]), 'targetState': array([25., 25., 15.])}
episode index:1039
target thresh 18.881611798849875
model initialize at round 1039
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86179483,  0.97888781,  0.15200121,
       -0.1366539 ]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30676344779055253
{'scaleFactor': 20, 'currentState': array([ 25.01537532,  39.40470575, -37.84239784,  -0.83634692,
        -0.52198671,  -0.16749237]), 'targetState': array([25., 25., 15.])}
episode index:1040
target thresh 18.88972323209156
model initialize at round 1040
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3064687662845097
{'scaleFactor': 20, 'currentState': array([ 15.04541227,   3.50149829, -29.82563721,  -0.5624364 ,
        -0.69230175,   0.45208803]), 'targetState': array([25., 25., 15.])}
episode index:1041
target thresh 18.897833854230495
model initialize at round 1041
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.06976367, 14.84627329,  0.98577081,  0.06946564,
       -0.15307   ]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30617465038596414
{'scaleFactor': 20, 'currentState': array([ 12.90340599,  11.08380958, -17.52236496,  -0.55057104,
        -0.59745981,  -0.58302085]), 'targetState': array([25., 25., 15.])}
episode index:1042
target thresh 18.905943665347756
model initialize at round 1042
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.97729192,  0.98790413,  0.15340126,
       -0.02266   ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3067837639995931
{'scaleFactor': 20, 'currentState': array([26.2791012 , 21.46864473, 12.58856213,  0.38198096,  0.73872662,
       -0.5553139 ]), 'targetState': array([25., 25., 15.])}
episode index:1043
target thresh 18.91405266552445
model initialize at round 1043
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.92368186,  0.98530324,  0.1529974 ,
       -0.07595607]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3064899098195169
{'scaleFactor': 20, 'currentState': array([ 24.41461062, -33.84475904,  -9.63498929,   0.40237125,
        -0.38526093,  -0.83046456]), 'targetState': array([25., 25., 15.])}
episode index:1044
target thresh 18.922160854841685
model initialize at round 1044
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.49891773e+01,  1.48462733e+01,  9.88100212e-01,
       -1.08019581e-02, -1.53431710e-01]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30619661803978526
{'scaleFactor': 20, 'currentState': array([28.73032928, 23.27727498, 26.15531261,  0.13512527,  0.9852377 ,
        0.10510867]), 'targetState': array([25., 25., 15.])}
episode index:1045
target thresh 18.93026823338051
model initialize at round 1045
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.88691323,  0.98192229,  0.15247241,
       -0.11216406]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3059038870473954
{'scaleFactor': 20, 'currentState': array([ 27.19925996,  19.40800932, -10.53668932,  -0.1768667 ,
        -0.05215478,  -0.982852  ]), 'targetState': array([25., 25., 15.])}
episode index:1046
target thresh 18.938374801222025
model initialize at round 1046
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14255844, 14.84627329,  0.97830347,  0.14087416,
       -0.15191048]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3056117152355068
{'scaleFactor': 20, 'currentState': array([  8.46600848,  13.35049585, -19.20720752,  -0.97522156,
         0.02688002,   0.21959139]), 'targetState': array([25., 25., 15.])}
episode index:1047
target thresh 18.946480558447288
model initialize at round 1047
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.0391912 , 14.84627329,  0.98740267,  0.03908838,
       -0.1533234 ]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30532010100341184
{'scaleFactor': 20, 'currentState': array([ 28.72253994,   4.21038057, -16.20758418,  -0.61522797,
         0.21648214,  -0.75804355]), 'targetState': array([25., 25., 15.])}
episode index:1048
target thresh 18.954585505137356
model initialize at round 1048
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3050290427565068
{'scaleFactor': 20, 'currentState': array([29.96925378, 22.53321176,  3.38033395, -0.451869  ,  0.60098828,
       -0.65926284]), 'targetState': array([25., 25., 15.])}
episode index:1049
target thresh 18.962689641373277
model initialize at round 1049
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08621847, 14.89109684,  0.99030034,  0.08624463,
       -0.1089362 ]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3047385389062625
{'scaleFactor': 20, 'currentState': array([ 33.22100602,  19.78827132, -16.70573798,  -0.86026211,
         0.45139834,  -0.23704142]), 'targetState': array([25., 25., 15.])}
episode index:1050
target thresh 18.970792967236093
model initialize at round 1050
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.51537267e+01,  1.49855702e+01,  9.88055386e-01,
        1.53424749e-01, -1.44014210e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3053443824937932
{'scaleFactor': 20, 'currentState': array([26.39889781, 21.47964073, 12.45150224,  0.47900174,  0.79398769,
       -0.37435395]), 'targetState': array([25., 25., 15.])}
episode index:1051
target thresh 18.978895482806834
model initialize at round 1051
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.92772353,  0.98559644,  0.15304293,
       -0.07195498]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30505413117963565
{'scaleFactor': 20, 'currentState': array([ 23.09442757,  14.15701178, -14.5197743 ,   0.40131847,
        -0.54387333,  -0.73698391]), 'targetState': array([25., 25., 15.])}
episode index:1052
target thresh 18.986997188166534
model initialize at round 1052
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30476443115002533
{'scaleFactor': 20, 'currentState': array([16.14545628, 11.67874595, -6.74002149, -0.91599859,  0.07342646,
       -0.3944048 ]), 'targetState': array([25., 25., 15.])}
episode index:1053
target thresh 18.99509808339621
model initialize at round 1053
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.97868191, 14.84627329,  0.98793423, -0.02127361,
       -0.15340594]), 'targetState': array([25., 25., 15.])}
done in step count: 41
reward sum = 0.6622820409839835
running average episode reward sum: 0.30510363191836876
{'scaleFactor': 20, 'currentState': array([25.22249467, 21.04020647, 12.79198388,  0.31361636,  0.61362997,
       -0.72463994]), 'targetState': array([25., 25., 15.])}
episode index:1054
target thresh 19.003198168576862
model initialize at round 1054
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13339771, 14.84627329,  0.97951322,  0.13198466,
       -0.15209833]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3048144341629959
{'scaleFactor': 20, 'currentState': array([ -6.06033009,   8.61683094, -16.9150101 ,  -0.16373409,
        -0.39856023,  -0.90240839]), 'targetState': array([25., 25., 15.])}
episode index:1055
target thresh 19.0112974437895
model initialize at round 1055
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.95678611,  0.98723991,  0.15329812,
       -0.04309341]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3054263428900196
{'scaleFactor': 20, 'currentState': array([25.27840229, 20.12445592, 13.37506606,  0.56262431,  0.76655058,
       -0.30960312]), 'targetState': array([25., 25., 15.])}
episode index:1056
target thresh 19.0193959091151
model initialize at round 1056
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.90412096,  0.98366363,  0.1527428 ,
       -0.09526538]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3060280967277783
{'scaleFactor': 20, 'currentState': array([26.24685457, 21.14468122, 11.2325716 ,  0.4269156 ,  0.77809456,
       -0.46077318]), 'targetState': array([25., 25., 15.])}
episode index:1057
target thresh 19.027493564634668
model initialize at round 1057
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.02807846,  0.98777001,  0.15338044,
        0.02801522]), 'targetState': array([25., 25., 15.])}
done in step count: 38
reward sum = 0.682554595010387
running average episode reward sum: 0.3063839818868356
{'scaleFactor': 20, 'currentState': array([20.94574734, 21.61578156, 10.54280759,  0.73616668, -0.64880914,
       -0.19262742]), 'targetState': array([25., 25., 15.])}
episode index:1058
target thresh 19.03559041042916
model initialize at round 1058
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30609466745634756
{'scaleFactor': 20, 'currentState': array([  6.02157543,  14.84448265, -16.18346641,   0.02905068,
        -0.36846544,  -0.92918743]), 'targetState': array([25., 25., 15.])}
episode index:1059
target thresh 19.043686446579567
model initialize at round 1059
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30580589890214344
{'scaleFactor': 20, 'currentState': array([ 28.95511738,  -5.91422259, -32.0428653 ,  -0.04823417,
         0.29589413,  -0.95400216]), 'targetState': array([25., 25., 15.])}
episode index:1060
target thresh 19.051781673166836
model initialize at round 1060
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30551767468074653
{'scaleFactor': 20, 'currentState': array([16.64449151,  2.18641908, -3.55996074,  0.75307088,  0.52319322,
       -0.39893996]), 'targetState': array([25., 25., 15.])}
episode index:1061
target thresh 19.05987609027191
model initialize at round 1061
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.49869527e+01,  1.49502843e+01,  9.98654958e-01,
       -1.31613973e-02, -5.01502937e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30522999325449346
{'scaleFactor': 20, 'currentState': array([17.25871214, 54.04949299, 13.5606192 ,  0.37244619, -0.76283051,
        0.5285579 ]), 'targetState': array([25., 25., 15.])}
episode index:1062
target thresh 19.067969697975762
model initialize at round 1062
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.06536272, 14.84627329,  0.98606155,  0.0651027 ,
       -0.15311515]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3049428530915071
{'scaleFactor': 20, 'currentState': array([ 40.90827606,  35.81275157, -33.10248136,   0.12614881,
         0.97016122,  -0.20705963]), 'targetState': array([25., 25., 15.])}
episode index:1063
target thresh 19.076062496359302
model initialize at round 1063
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.49939954e+01,  1.48462733e+01,  9.88140116e-01,
       -5.99329324e-03, -1.53437906e-01]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.3055322539324991
{'scaleFactor': 20, 'currentState': array([28.4043445 , 20.82821118, 10.89874508,  0.43852192,  0.76112513,
       -0.47789859]), 'targetState': array([25., 25., 15.])}
episode index:1064
target thresh 19.084154485503458
model initialize at round 1064
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.30613831759068455
{'scaleFactor': 20, 'currentState': array([24.90724728, 20.01008825, 11.7965446 ,  0.51163159,  0.74866576,
       -0.42158356]), 'targetState': array([25., 25., 15.])}
episode index:1065
target thresh 19.092245665489173
model initialize at round 1065
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11416481, 14.93095358,  0.99104064,  0.11428482,
       -0.069119  ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.30673432306142595
{'scaleFactor': 20, 'currentState': array([27.0804721 , 21.07473327, 14.04683024,  0.64272383,  0.73894899,
       -0.2021397 ]), 'targetState': array([25., 25., 15.])}
episode index:1066
target thresh 19.100336036397326
model initialize at round 1066
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11443669, 14.9262051 ,  0.99067317,  0.11451451,
       -0.07384508]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30644684946905343
{'scaleFactor': 20, 'currentState': array([ 18.31493783, -12.19063999,  -5.36071123,   0.56589078,
         0.14479182,  -0.81166678]), 'targetState': array([25., 25., 15.])}
episode index:1067
target thresh 19.108425598308866
model initialize at round 1067
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.93769157, 14.84627329,  0.98625234, -0.06207256,
       -0.15314477]), 'targetState': array([25., 25., 15.])}
done in step count: 35
reward sum = 0.7034476949995692
running average episode reward sum: 0.3068185731071906
{'scaleFactor': 20, 'currentState': array([21.20447087, 24.80216923, 15.73367321,  0.85513115, -0.38250606,
        0.34991403]), 'targetState': array([25., 25., 15.])}
episode index:1068
target thresh 19.116514351304637
model initialize at round 1068
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.51537267e+01,  1.49904425e+01,  9.88112902e-01,
        1.53433680e-01, -9.53930555e-03]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3074122696238359
{'scaleFactor': 20, 'currentState': array([26.31908011, 20.86095616, 11.48568573,  0.38095996,  0.67396299,
       -0.63296398]), 'targetState': array([25., 25., 15.])}
episode index:1069
target thresh 19.124602295465564
model initialize at round 1069
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3080048564273659
{'scaleFactor': 20, 'currentState': array([25.73825879, 21.46757452, 10.48523097,  0.41872911,  0.81184397,
       -0.40690944]), 'targetState': array([25., 25., 15.])}
episode index:1070
target thresh 19.132689430872507
model initialize at round 1070
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.50650420e+01, 1.50110173e+01, 9.97787264e-01,
       6.55536231e-02, 1.11039513e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3085963366262209
{'scaleFactor': 20, 'currentState': array([27.3258957 , 20.36225114, 14.18227338,  0.59462606,  0.71220648,
       -0.37307075]), 'targetState': array([25., 25., 15.])}
episode index:1071
target thresh 19.14077575760633
model initialize at round 1071
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10615016, 14.8754956 ,  0.98661716,  0.10578744,
       -0.12407897]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3091867133172421
{'scaleFactor': 20, 'currentState': array([26.14339945, 21.14456698, 11.08078075,  0.40991415,  0.78863017,
       -0.4582934 ]), 'targetState': array([25., 25., 15.])}
episode index:1072
target thresh 19.14886127574793
model initialize at round 1072
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.9554969 ,  0.98718441,  0.1532895 ,
       -0.04437653]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3097759895857265
{'scaleFactor': 20, 'currentState': array([26.82690463, 21.3694988 , 13.12393375,  0.61556837,  0.73264644,
       -0.29035286]), 'targetState': array([25., 25., 15.])}
episode index:1073
target thresh 19.156945985378137
model initialize at round 1073
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.07971019, 14.84627329,  0.98504507,  0.07931124,
       -0.15295731]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30948755756562807
{'scaleFactor': 20, 'currentState': array([25.66589736, 26.7744733 ,  2.75866238, -0.75458461,  0.43698777,
       -0.48953422]), 'targetState': array([25., 25., 15.])}
episode index:1074
target thresh 19.1650298865778
model initialize at round 1074
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10988249, 14.87084526,  0.98564562,  0.10939919,
       -0.12858667]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30919966216324146
{'scaleFactor': 20, 'currentState': array([-33.10756844,   0.48045231,  -2.96720434,  -0.60114151,
        -0.76085207,  -0.24440337]), 'targetState': array([25., 25., 15.])}
episode index:1075
target thresh 19.173112979427763
model initialize at round 1075
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09883841, 14.85652656,  0.98486566,  0.09832582,
       -0.14272936]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3089123018824206
{'scaleFactor': 20, 'currentState': array([ 37.32243051, -12.00433428, -15.2174475 ,   0.49717318,
         0.45686787,  -0.73762496]), 'targetState': array([25., 25., 15.])}
episode index:1076
target thresh 19.181195264008867
model initialize at round 1076
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10796246, 14.91690486,  0.99066362,  0.10803483,
       -0.08315084]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3094996443592252
{'scaleFactor': 20, 'currentState': array([26.63279934, 20.68690176, 11.33269021,  0.59275724,  0.65713132,
       -0.46563644]), 'targetState': array([25., 25., 15.])}
episode index:1077
target thresh 19.189276740401905
model initialize at round 1077
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.0631661 , 14.96593449,  0.99738282,  0.06363716,
       -0.03431955]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3092125389377417
{'scaleFactor': 20, 'currentState': array([ 69.15146472, -16.20447409,  -9.24355675,  -0.83666282,
         0.26195835,  -0.48101263]), 'targetState': array([25., 25., 15.])}
episode index:1078
target thresh 19.197357408687708
model initialize at round 1078
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10454519, 14.84627329,  0.98282135,  0.10378711,
       -0.15261201]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3089259656857141
{'scaleFactor': 20, 'currentState': array([34.13544426, 24.49547093,  2.10825516,  0.79518942,  0.60396143,
       -0.05389228]), 'targetState': array([25., 25., 15.])}
episode index:1079
target thresh 19.2054372689471
model initialize at round 1079
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.308639923124894
{'scaleFactor': 20, 'currentState': array([ 15.63250332,   5.91357659, -22.34080543,   0.06315716,
        -0.38363504,  -0.9213226 ]), 'targetState': array([25., 25., 15.])}
episode index:1080
target thresh 19.213516321260858
model initialize at round 1080
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.06862504, 14.84627329,  0.98584783,  0.06833722,
       -0.15308196]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30835440978250284
{'scaleFactor': 20, 'currentState': array([24.53895222, 30.66139522, -3.80590761, -0.51347204,  0.79750903,
       -0.31674251]), 'targetState': array([25., 25., 15.])}
episode index:1081
target thresh 19.221594565709776
model initialize at round 1081
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15017859, 14.91083539,  0.98479243,  0.14938862,
       -0.08869559]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3089483429064561
{'scaleFactor': 20, 'currentState': array([25.25362065, 20.0910927 , 13.09477564,  0.56449517,  0.76783976,
       -0.30293119]), 'targetState': array([25., 25., 15.])}
episode index:1082
target thresh 19.22967200237464
model initialize at round 1082
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84920235,  0.97715099,  0.15173152,
       -0.14884047]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.3095237048685988
{'scaleFactor': 20, 'currentState': array([29.5555093 , 20.69436179, 12.34710317,  0.85158189,  0.51050206,
       -0.11914668]), 'targetState': array([25., 25., 15.])}
episode index:1083
target thresh 19.237748631336228
model initialize at round 1083
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.10704519,  0.98256526,  0.15257225,
        0.1062413 ]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3101154634894765
{'scaleFactor': 20, 'currentState': array([24.92955152, 20.01206821, 18.04418667,  0.53452365,  0.77413246,
        0.33912153]), 'targetState': array([25., 25., 15.])}
episode index:1084
target thresh 19.245824452675297
model initialize at round 1084
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.07659462,  0.98528261,  0.15299419,
        0.07622964]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.310706131311053
{'scaleFactor': 20, 'currentState': array([25.36710249, 20.17991431, 15.73782563,  0.598194  ,  0.79541798,
       -0.09733537]), 'targetState': array([25., 25., 15.])}
episode index:1085
target thresh 19.253899466472614
model initialize at round 1085
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.92599063,  0.98547265,  0.1530237 ,
       -0.07367092]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3112869545321303
{'scaleFactor': 20, 'currentState': array([25.8736887 , 21.50160636, 11.28647972,  0.33740942,  0.75480548,
       -0.56251539]), 'targetState': array([25., 25., 15.])}
episode index:1086
target thresh 19.261973672808917
model initialize at round 1086
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11017184, 14.86442326,  0.98478515,  0.10959151,
       -0.13486259]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3110005819888625
{'scaleFactor': 20, 'currentState': array([24.3276783 , 23.25737609, -5.30234132, -0.66283287,  0.69322277,
       -0.2830102 ]), 'targetState': array([25., 25., 15.])}
episode index:1087
target thresh 19.270047071764964
model initialize at round 1087
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.07557672, 14.84627329,  0.9853582 ,  0.07522236,
       -0.15300593]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31071473586571097
{'scaleFactor': 20, 'currentState': array([11.24431669, 20.52246292, -2.71469005,  0.26207086,  0.34604632,
       -0.90087225]), 'targetState': array([25., 25., 15.])}
episode index:1088
target thresh 19.278119663421467
model initialize at round 1088
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.8816144 ,  0.98133044,  0.1523805 ,
       -0.11734888]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.31129395112148256
{'scaleFactor': 20, 'currentState': array([25.52658552, 21.38162801, 10.26564059,  0.31759254,  0.72818739,
       -0.60735335]), 'targetState': array([25., 25., 15.])}
episode index:1089
target thresh 19.286191447859192
model initialize at round 1089
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.50001314e+01,  1.48462733e+01,  9.88157855e-01,
        1.31122992e-04, -1.53440661e-01]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31100836034063717
{'scaleFactor': 20, 'currentState': array([28.15012835, 24.62515154, -6.008255  , -0.6468286 ,  0.13469632,
       -0.75064617]), 'targetState': array([25., 25., 15.])}
episode index:1090
target thresh 19.294262425158802
model initialize at round 1090
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31072329309926167
{'scaleFactor': 20, 'currentState': array([ 18.30346624,  17.63925532, -15.41468355,  -0.82767989,
         0.55942589,  -0.04459466]), 'targetState': array([25., 25., 15.])}
episode index:1091
target thresh 19.30233259540106
model initialize at round 1091
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14925563, 14.87597433,  0.98132438,  0.14794767,
       -0.12293881]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3104387479590609
{'scaleFactor': 20, 'currentState': array([ 30.20658739,  14.28153869, -12.23391449,  -0.15056917,
         0.72496637,  -0.6721255 ]), 'targetState': array([25., 25., 15.])}
episode index:1092
target thresh 19.310401958666635
model initialize at round 1092
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3101547234870032
{'scaleFactor': 20, 'currentState': array([12.28838959, 20.3334039 , -9.18023246,  0.11150429,  0.97474694,
       -0.19348178]), 'targetState': array([25., 25., 15.])}
episode index:1093
target thresh 19.31847051503621
model initialize at round 1093
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08365477, 15.05159954,  0.99510775,  0.08408637,
        0.05186576]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.31072319754954425
{'scaleFactor': 20, 'currentState': array([28.93198467, 21.14089424, 13.62796732,  0.53784409,  0.71154845,
       -0.45213111]), 'targetState': array([25., 25., 15.])}
episode index:1094
target thresh 19.32653826459051
model initialize at round 1094
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.90361131,  0.98361606,  0.15273541,
       -0.09576714]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.31129923129552733
{'scaleFactor': 20, 'currentState': array([26.88234392, 21.07520967, 12.56954687,  0.58632117,  0.74216177,
       -0.32468968]), 'targetState': array([25., 25., 15.])}
episode index:1095
target thresh 19.334605207410192
model initialize at round 1095
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13530988, 14.91647301,  0.98734489,  0.13494699,
       -0.08330298]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3110151991501847
{'scaleFactor': 20, 'currentState': array([-30.80693851,  48.71591662,  -7.34902564,  -0.41936132,
        -0.62135427,   0.6618572 ]), 'targetState': array([25., 25., 15.])}
episode index:1096
target thresh 19.342671343575923
model initialize at round 1096
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84841886,  0.97703825,  0.15171401,
       -0.14959654]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31073168483920005
{'scaleFactor': 20, 'currentState': array([  9.85976636,  15.1580196 , -14.64432299,  -0.90966259,
        -0.35157955,  -0.22114655]), 'targetState': array([25., 25., 15.])}
episode index:1097
target thresh 19.350736673168356
model initialize at round 1097
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86598642,  0.97943427,  0.15208607,
       -0.13258333]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31044868694772537
{'scaleFactor': 20, 'currentState': array([25.61568622, -3.70395034, -7.29448346,  0.20340062,  0.38058489,
       -0.9020994 ]), 'targetState': array([25., 25., 15.])}
episode index:1098
target thresh 19.35880119626817
model initialize at round 1098
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.0894948 , 14.84627329,  0.98423878,  0.08897399,
       -0.15283211]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31016620406606227
{'scaleFactor': 20, 'currentState': array([28.73620089,  5.73214291,  0.48361083,  0.44474539,  0.49461592,
       -0.74669715]), 'targetState': array([25., 25., 15.])}
episode index:1099
target thresh 19.366864912955993
model initialize at round 1099
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.06709299, 14.84627329,  0.98594948,  0.06681848,
       -0.15309774]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.30988423478963856
{'scaleFactor': 20, 'currentState': array([15.98820729, 46.69601575,  7.25642155, -0.64328659,  0.50146341,
       -0.57854715]), 'targetState': array([25., 25., 15.])}
episode index:1100
target thresh 19.37492782331246
model initialize at round 1100
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.92849842,  0.98565086,  0.15305138,
       -0.07118747]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.31045789138783236
{'scaleFactor': 20, 'currentState': array([26.18541984, 21.29201697, 11.46053456,  0.4059646 ,  0.77658793,
       -0.48177165]), 'targetState': array([25., 25., 15.])}
episode index:1101
target thresh 19.382989927418205
model initialize at round 1101
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.51537267e+01, 1.50044690e+01, 9.88148033e-01,
       1.53439135e-01, 4.46066161e-03]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3110391365407472
{'scaleFactor': 20, 'currentState': array([25.26885105, 20.08278338, 13.65615811,  0.55534995,  0.76103349,
       -0.33528266]), 'targetState': array([25., 25., 15.])}
episode index:1102
target thresh 19.39105122535385
model initialize at round 1102
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.51537267e+01, 1.50115805e+01, 9.88091856e-01,
       1.53430412e-01, 1.15581902e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3116193277586613
{'scaleFactor': 20, 'currentState': array([25.39964032, 20.1744195 , 14.74450808,  0.596649  ,  0.79202632,
       -0.129245  ]), 'targetState': array([25., 25., 15.])}
episode index:1103
target thresh 19.3991117172
model initialize at round 1103
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.93861905,  0.98630849,  0.15315349,
       -0.06115208]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3121898538652214
{'scaleFactor': 20, 'currentState': array([25.56721169, 21.17673424, 10.28893002,  0.32012141,  0.70080404,
       -0.63749195]), 'targetState': array([25., 25., 15.])}
episode index:1104
target thresh 19.40717140303727
model initialize at round 1104
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.93269511,  0.98593555,  0.15309558,
       -0.06702857]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3119073291105922
{'scaleFactor': 20, 'currentState': array([11.31274446, 28.48167797, -1.37515478, -0.94099989, -0.12806287,
        0.3132397 ]), 'targetState': array([25., 25., 15.])}
episode index:1105
target thresh 19.41523028294626
model initialize at round 1105
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89076036,  0.98233566,  0.15253659,
       -0.10839393]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.31247656312532135
{'scaleFactor': 20, 'currentState': array([25.63231754, 21.45518104, 10.60823307,  0.34824504,  0.8066899 ,
       -0.47746916]), 'targetState': array([25., 25., 15.])}
episode index:1106
target thresh 19.42328835700754
model initialize at round 1106
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.96712942,  0.98762644,  0.15335814,
       -0.03279178]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.31305335940967066
{'scaleFactor': 20, 'currentState': array([25.31474685, 20.10447493, 13.84695975,  0.5474335 ,  0.74608161,
       -0.37904987]), 'targetState': array([25., 25., 15.])}
episode index:1107
target thresh 19.43134562530171
model initialize at round 1107
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31277082027662945
{'scaleFactor': 20, 'currentState': array([  2.02763832,   8.2089679 , -19.02607144,  -0.78549417,
        -0.57674334,   0.22442379]), 'targetState': array([25., 25., 15.])}
episode index:1108
target thresh 19.43940208790934
model initialize at round 1108
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12280265, 14.85634195,  0.98226171,  0.12184277,
       -0.14253515]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31248879068215096
{'scaleFactor': 20, 'currentState': array([  3.55952593,  -0.32116034, -23.27471599,  -0.24220805,
        -0.41889385,  -0.8751361 ]), 'targetState': array([25., 25., 15.])}
episode index:1109
target thresh 19.447457744910977
model initialize at round 1109
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.31306401704180664
{'scaleFactor': 20, 'currentState': array([24.99151817, 20.10935508, 12.11418237,  0.56210159,  0.79368717,
       -0.23259938]), 'targetState': array([25., 25., 15.])}
episode index:1110
target thresh 19.4555125963872
model initialize at round 1110
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.02058183,  0.98794941,  0.15340829,
        0.0205392 ]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3127822312478896
{'scaleFactor': 20, 'currentState': array([ 51.69781245,   8.39312373, -21.97798713,   0.10743138,
         0.79582672,  -0.59591806]), 'targetState': array([25., 25., 15.])}
episode index:1111
target thresh 19.463566642418563
model initialize at round 1111
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09600245, 14.84627329,  0.98365214,  0.09538689,
       -0.15274101]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3125009522629545
{'scaleFactor': 20, 'currentState': array([ -1.90459754, -12.86587776,  -6.28745403,   0.27838393,
         0.08970413,  -0.9562717 ]), 'targetState': array([25., 25., 15.])}
episode index:1112
target thresh 19.471619883085566
model initialize at round 1112
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.0643043 , 14.84627329,  0.98612869,  0.06405284,
       -0.15312557]), 'targetState': array([25., 25., 15.])}
done in step count: 40
reward sum = 0.6689717585696803
running average episode reward sum: 0.3128212315139039
{'scaleFactor': 20, 'currentState': array([24.89867006, 20.13830469, 14.0640491 ,  0.46318491,  0.63806404,
       -0.61508862]), 'targetState': array([25., 25., 15.])}
episode index:1113
target thresh 19.479672318468786
model initialize at round 1113
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31254042250895425
{'scaleFactor': 20, 'currentState': array([ 27.05190983,  15.50772293, -18.99978988,  -0.18774512,
         0.54033338,  -0.82023875]), 'targetState': array([25., 25., 15.])}
episode index:1114
target thresh 19.487723948648718
model initialize at round 1114
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.312260117197287
{'scaleFactor': 20, 'currentState': array([ 24.77937608,  -2.90374849, -19.9032068 ,   0.11910302,
        -0.56908529,  -0.81360704]), 'targetState': array([25., 25., 15.])}
episode index:1115
target thresh 19.495774773705897
model initialize at round 1115
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.9179111 , 14.84627329,  0.98485746, -0.08166249,
       -0.15292818]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.311980314224888
{'scaleFactor': 20, 'currentState': array([ 78.94011488, -22.1423467 ,  17.67811059,   0.32066705,
         0.86012037,  -0.39669333]), 'targetState': array([25., 25., 15.])}
episode index:1116
target thresh 19.503824793720803
model initialize at round 1116
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09376998, 14.84627329,  0.9838579 ,  0.09318822,
       -0.15277297]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3117010122425918
{'scaleFactor': 20, 'currentState': array([20.51568854, 15.15512483, -7.73949325,  0.38683535,  0.46726228,
       -0.79499961]), 'targetState': array([25., 25., 15.])}
episode index:1117
target thresh 19.511874008773976
model initialize at round 1117
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.07241527, 14.84627329,  0.98558663,  0.07209245,
       -0.1530414 ]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31142220990605995
{'scaleFactor': 20, 'currentState': array([ 22.67544857,   7.21121881, -14.67975255,   0.77837169,
        -0.50277971,   0.37596552]), 'targetState': array([25., 25., 15.])}
episode index:1118
target thresh 19.51992241894589
model initialize at round 1118
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31114390587575963
{'scaleFactor': 20, 'currentState': array([ 38.1880027 ,  41.05657357, -21.44449581,  -0.88963157,
         0.42625104,   0.16390765]), 'targetState': array([25., 25., 15.])}
episode index:1119
target thresh 19.52797002431701
model initialize at round 1119
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.02656752, 14.84627329,  0.98781061,  0.02650877,
       -0.15338674]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.310866098816942
{'scaleFactor': 20, 'currentState': array([ 3.78414320e+01,  6.52172850e+00, -5.09108527e+00, -2.78150518e-02,
        6.64392176e-01, -7.46866360e-01]), 'targetState': array([25., 25., 15.])}
episode index:1120
target thresh 19.53601682496785
model initialize at round 1120
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 35
reward sum = 0.7034476949995692
running average episode reward sum: 0.3112163054147855
{'scaleFactor': 20, 'currentState': array([20.5858831 , 23.04108276, 18.10455827,  0.96543169,  0.22194801,
        0.13667751]), 'targetState': array([25., 25., 15.])}
episode index:1121
target thresh 19.544062820978848
model initialize at round 1121
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89853111,  0.98312843,  0.15265969,
       -0.1007646 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3117780378960567
{'scaleFactor': 20, 'currentState': array([25.59693403, 21.35858449, 10.50891292,  0.29426827,  0.72272686,
       -0.62535756]), 'targetState': array([25., 25., 15.])}
episode index:1122
target thresh 19.55210801243047
model initialize at round 1122
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85370113,  0.97778779,  0.1518304 ,
       -0.14449419]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31150040829864256
{'scaleFactor': 20, 'currentState': array([17.97713776, 35.47928217, -9.31722572,  0.31626361,  0.70549874,
        0.63423092]), 'targetState': array([25., 25., 15.])}
episode index:1123
target thresh 19.560152399403176
model initialize at round 1123
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.96183009,  0.98744148,  0.15332942,
       -0.03807127]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.31206088849535285
{'scaleFactor': 20, 'currentState': array([25.39424101, 21.18435063, 10.23882641,  0.25980479,  0.70168665,
       -0.66342846]), 'targetState': array([25., 25., 15.])}
episode index:1124
target thresh 19.5681959819774
model initialize at round 1124
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.93034949,  0.98577852,  0.1530712 ,
       -0.06935352]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3126203722828245
{'scaleFactor': 20, 'currentState': array([25.71901887, 21.45143285, 10.84759131,  0.31891401,  0.74309629,
       -0.58830414]), 'targetState': array([25., 25., 15.])}
episode index:1125
target thresh 19.57623876023359
model initialize at round 1125
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14582236, 14.84627329,  0.97785418,  0.14403334,
       -0.15184071]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31234273429678294
{'scaleFactor': 20, 'currentState': array([ 10.11537496,   5.09917744, -11.24902001,   0.28748368,
        -0.30953685,  -0.90638848]), 'targetState': array([25., 25., 15.])}
episode index:1126
target thresh 19.584280734252157
model initialize at round 1126
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11419872, 14.9351708 ,  0.99131726,  0.11435067,
       -0.06491546]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31206558901346726
{'scaleFactor': 20, 'currentState': array([49.75334174, -1.64944526, -9.47837828, -0.17772275,  0.78294912,
       -0.59615878]), 'targetState': array([25., 25., 15.])}
episode index:1127
target thresh 19.59232190411354
model initialize at round 1127
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.88112874,  0.98127489,  0.15237188,
       -0.11782362]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31178893512249783
{'scaleFactor': 20, 'currentState': array([-0.27734376, -4.82052513,  5.22739796,  0.61440517, -0.20376452,
       -0.76222458]), 'targetState': array([25., 25., 15.])}
episode index:1128
target thresh 19.60036226989814
model initialize at round 1128
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.90129885,  0.98339711,  0.15270141,
       -0.09804286]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.31234667756207135
{'scaleFactor': 20, 'currentState': array([25.6960158 , 21.29646972, 10.69101531,  0.31547575,  0.6692869 ,
       -0.67270357]), 'targetState': array([25., 25., 15.])}
episode index:1129
target thresh 19.608401831686372
model initialize at round 1129
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.03990428, 14.84627329,  0.98737497,  0.03979847,
       -0.1533191 ]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31207026457307835
{'scaleFactor': 20, 'currentState': array([20.21930778, 24.15029198, 33.35409426,  0.83290001, -0.45763033,
        0.31121063]), 'targetState': array([25., 25., 15.])}
episode index:1130
target thresh 19.616440589558604
model initialize at round 1130
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.50075390e+01,  1.48462733e+01,  9.88129887e-01,
        7.52477610e-03, -1.53436318e-01]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31179434037805354
{'scaleFactor': 20, 'currentState': array([30.95959758, 25.1360301 , -0.86172431,  0.31818116,  0.74984283,
       -0.58008316]), 'targetState': array([25., 25., 15.])}
episode index:1131
target thresh 19.62447854359525
model initialize at round 1131
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.51537267e+01, 1.50036781e+01, 9.88151204e-01,
       1.53439628e-01, 3.67123614e-03]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3123590008988326
{'scaleFactor': 20, 'currentState': array([25.23925065, 20.05185281, 13.53335893,  0.52113121,  0.7255358 ,
       -0.44946642]), 'targetState': array([25., 25., 15.])}
episode index:1132
target thresh 19.632515693876673
model initialize at round 1132
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31208330892981334
{'scaleFactor': 20, 'currentState': array([-2.16784665, -8.16193936,  2.90056628,  0.3600601 , -0.12090077,
       -0.92506201]), 'targetState': array([25., 25., 15.])}
episode index:1133
target thresh 19.64055204048326
model initialize at round 1133
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.1083217 , 14.84627329,  0.98243225,  0.10749367,
       -0.15255159]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31180810319001634
{'scaleFactor': 20, 'currentState': array([ 3.22269215e+01,  6.96692283e+01, -3.14592840e+01, -6.98727753e-01,
        7.15308745e-01, -1.06266712e-02]), 'targetState': array([25., 25., 15.])}
episode index:1134
target thresh 19.64858758349537
model initialize at round 1134
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 39
reward sum = 0.6757290490602831
running average episode reward sum: 0.3121287383846157
{'scaleFactor': 20, 'currentState': array([25.90566679, 24.06210714, 19.30482561,  0.70678156,  0.44751863,
       -0.54789315]), 'targetState': array([25., 25., 15.])}
episode index:1135
target thresh 19.656622322993343
model initialize at round 1135
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.01780133, 14.84627329,  0.98800192,  0.0177654 ,
       -0.15341645]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31185397717124896
{'scaleFactor': 20, 'currentState': array([28.46161854, 60.19168563, 22.59157596, -0.9031461 ,  0.41528711,
        0.10892076]), 'targetState': array([25., 25., 15.])}
episode index:1136
target thresh 19.664656259057544
model initialize at round 1136
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.0278494 ,  0.98777631,  0.15338141,
        0.02778685]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.312416102125276
{'scaleFactor': 20, 'currentState': array([25.3220614 , 20.13953244, 16.24191215,  0.58610844,  0.78932539,
        0.18287244]), 'targetState': array([25., 25., 15.])}
episode index:1137
target thresh 19.672689391768316
model initialize at round 1137
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.97615432,  0.98787809,  0.15339722,
       -0.02379457]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3129688824831633
{'scaleFactor': 20, 'currentState': array([26.15757472, 20.90995098, 10.78613079,  0.45523371,  0.65294375,
       -0.60533191]), 'targetState': array([25., 25., 15.])}
episode index:1138
target thresh 19.680721721205973
model initialize at round 1138
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3126941073448989
{'scaleFactor': 20, 'currentState': array([ 1.39372306e+01,  2.36957009e+01, -6.64585022e+00, -7.44440852e-01,
       -1.63511806e-02, -6.67488170e-01]), 'targetState': array([25., 25., 15.])}
episode index:1139
target thresh 19.68875324745084
model initialize at round 1139
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3124198142682806
{'scaleFactor': 20, 'currentState': array([-1.19342057, 43.59261851, 23.71615319, -0.97701794, -0.11730414,
       -0.17797666]), 'targetState': array([25., 25., 15.])}
episode index:1140
target thresh 19.696783970583255
model initialize at round 1140
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.94577095,  0.98671346,  0.15321638,
       -0.05404902]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.31297113796252485
{'scaleFactor': 20, 'currentState': array([25.83558023, 21.47926045, 11.18229292,  0.34977081,  0.78389251,
       -0.51300381]), 'targetState': array([25., 25., 15.])}
episode index:1141
target thresh 19.704813890683493
model initialize at round 1141
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.9246484 ,  0.98537478,  0.15300851,
       -0.07499956]), 'targetState': array([25., 25., 15.])}
done in step count: 43
reward sum = 0.6491026283684022
running average episode reward sum: 0.31326547376848446
{'scaleFactor': 20, 'currentState': array([29.64562602, 21.24925026, 18.71362333,  0.18805307,  0.53896658,
       -0.82106703]), 'targetState': array([25., 25., 15.])}
episode index:1142
target thresh 19.71284300783187
model initialize at round 1142
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15158941, 14.84627329,  0.97703705,  0.14960451,
       -0.15171383]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3129914007380658
{'scaleFactor': 20, 'currentState': array([ 2.14079028e+01,  7.03994202e+01,  2.35339776e+01, -7.05733429e-01,
        7.06763748e-01, -4.92476591e-02]), 'targetState': array([25., 25., 15.])}
episode index:1143
target thresh 19.720871322108692
model initialize at round 1143
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08781225, 14.84627329,  0.98438392,  0.08731411,
       -0.15285465]), 'targetState': array([25., 25., 15.])}
done in step count: 46
reward sum = 0.6298236312032323
running average episode reward sum: 0.3132683519884724
{'scaleFactor': 20, 'currentState': array([20.65108061, 28.82877525, 17.93274891,  0.76019146, -0.57212589,
        0.30786507]), 'targetState': array([25., 25., 15.])}
episode index:1144
target thresh 19.72889883359421
model initialize at round 1144
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.91839193,  0.98489582,  0.15293413,
       -0.08118732]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31299475517450864
{'scaleFactor': 20, 'currentState': array([20.27666433, 42.51537138, 14.71131203, -0.43727967,  0.62002153,
       -0.65142904]), 'targetState': array([25., 25., 15.])}
episode index:1145
target thresh 19.736925542368734
model initialize at round 1145
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.95790261,  0.98728667,  0.15330538,
       -0.04198202]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3135431717488773
{'scaleFactor': 20, 'currentState': array([25.73504593, 21.22558021, 10.81510603,  0.3131307 ,  0.65821565,
       -0.68461765]), 'targetState': array([25., 25., 15.])}
episode index:1146
target thresh 19.744951448512506
model initialize at round 1146
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31326981240123225
{'scaleFactor': 20, 'currentState': array([ 2.41282092, 40.66753597, 25.4965003 , -0.70255852, -0.14113911,
       -0.69748927]), 'targetState': array([25., 25., 15.])}
episode index:1147
target thresh 19.75297655210577
model initialize at round 1147
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12563121, 14.84627329,  0.98047915,  0.12442301,
       -0.15224832]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31299692928938444
{'scaleFactor': 20, 'currentState': array([27.98577964, 22.86062953,  5.55241466, -0.47268927,  0.70803477,
       -0.52464427]), 'targetState': array([25., 25., 15.])}
episode index:1148
target thresh 19.76100085322883
model initialize at round 1148
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.94297991,  0.98656132,  0.15319275,
       -0.05682204]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3135521887503162
{'scaleFactor': 20, 'currentState': array([25.31154072, 20.08171048, 16.25261756,  0.57836167,  0.76752202,
        0.27641948]), 'targetState': array([25., 25., 15.])}
episode index:1149
target thresh 19.76902435196187
model initialize at round 1149
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.51537267e+01, 1.50157244e+01, 9.88036176e-01,
       1.53421766e-01, 1.56932068e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3141064825426203
{'scaleFactor': 20, 'currentState': array([25.38544991, 20.1703572 , 15.64794035,  0.59612656,  0.79316965,
        0.12455937]), 'targetState': array([25., 25., 15.])}
episode index:1150
target thresh 19.777047048385178
model initialize at round 1150
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.0308452 ,  0.98768986,  0.15336799,
        0.03077322]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.31465981318324354
{'scaleFactor': 20, 'currentState': array([25.38481402, 20.16388184, 14.66809924,  0.59310837,  0.78993824,
       -0.1556279 ]), 'targetState': array([25., 25., 15.])}
episode index:1151
target thresh 19.785068942578942
model initialize at round 1151
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14506657, 14.97176062,  0.98904022,  0.14492593,
       -0.028212  ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.31520392805843256
{'scaleFactor': 20, 'currentState': array([26.59821244, 21.28397312, 12.78706574,  0.47795818,  0.79484176,
       -0.37387505]), 'targetState': array([25., 25., 15.])}
episode index:1152
target thresh 19.793090034623408
model initialize at round 1152
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08440722, 14.84627329,  0.98466941,  0.08395273,
       -0.15289898]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3149305508441581
{'scaleFactor': 20, 'currentState': array([4.60641941e+01, 4.33007019e+01, 2.29728194e+01, 9.78509502e-01,
       3.64942416e-02, 2.02946606e-01]), 'targetState': array([25., 25., 15.])}
episode index:1153
target thresh 19.80111032459876
model initialize at round 1153
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3146576474205497
{'scaleFactor': 20, 'currentState': array([22.06649306, 22.74844484,  2.06172239, -0.48584178,  0.64631469,
       -0.58841744]), 'targetState': array([25., 25., 15.])}
episode index:1154
target thresh 19.809129812585212
model initialize at round 1154
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.06200753, 14.93864138,  0.9961403 ,  0.06239212,
       -0.06173919]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3143852165569821
{'scaleFactor': 20, 'currentState': array([-1.05666531e+01,  1.29384148e+01,  4.05218107e+01,  2.39819380e-01,
       -9.70441573e-01,  2.70151535e-02]), 'targetState': array([25., 25., 15.])}
episode index:1155
target thresh 19.817148498662974
model initialize at round 1155
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11701453, 14.95437656,  0.99204876,  0.11725668,
       -0.04571786]), 'targetState': array([25., 25., 15.])}
done in step count: 47
reward sum = 0.6235253948912
running average episode reward sum: 0.3146526388565792
{'scaleFactor': 20, 'currentState': array([25.11946351, 20.67683233, 12.65788878,  0.71404645,  0.66924389,
       -0.20554874]), 'targetState': array([25., 25., 15.])}
episode index:1156
target thresh 19.825166382912208
model initialize at round 1156
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12146209, 14.89054242,  0.98663441,  0.12104917,
       -0.10908547]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31438068324823293
{'scaleFactor': 20, 'currentState': array([26.10569822, 68.37077817, 13.56895456, -0.38588488,  0.68380369,
       -0.6192781 ]), 'targetState': array([25., 25., 15.])}
episode index:1157
target thresh 19.833183465413107
model initialize at round 1157
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.91763674, 14.84627329,  0.98483547, -0.08193359,
       -0.15292476]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31410919733869214
{'scaleFactor': 20, 'currentState': array([46.20540492, 51.74621039,  9.58740888,  0.61515206,  0.17359815,
        0.76905892]), 'targetState': array([25., 25., 15.])}
episode index:1158
target thresh 19.84119974624584
model initialize at round 1158
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86800136,  0.97969129,  0.15212598,
       -0.13062416]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3138381799121704
{'scaleFactor': 20, 'currentState': array([25.93611035, 18.42087675, -4.76975944, -0.75278552,  0.63088398,
       -0.18788124]), 'targetState': array([25., 25., 15.])}
episode index:1159
target thresh 19.84921522549058
model initialize at round 1159
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3135676297570737
{'scaleFactor': 20, 'currentState': array([ 11.18447157,  20.24409813, -11.39320531,  -0.99474937,
         0.08970157,   0.04926791]), 'targetState': array([25., 25., 15.])}
episode index:1160
target thresh 19.85722990322746
model initialize at round 1160
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.97025839,  0.98772273,  0.1533731 ,
       -0.02967319]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.31410846741395904
{'scaleFactor': 20, 'currentState': array([26.84461006, 21.18915576, 15.82850342,  0.52588535,  0.80720514,
        0.26807547]), 'targetState': array([25., 25., 15.])}
episode index:1161
target thresh 19.865243779536645
model initialize at round 1161
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.98192513,  0.98799709,  0.1534157 ,
       -0.01803831]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3146483741970804
{'scaleFactor': 20, 'currentState': array([26.35342345, 21.09279159, 11.93293381,  0.37854189,  0.71182554,
       -0.5916168 ]), 'targetState': array([25., 25., 15.])}
episode index:1162
target thresh 19.873256854498266
model initialize at round 1162
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.91696438,  0.98478128,  0.15291635,
       -0.0825979 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.31518735250765983
{'scaleFactor': 20, 'currentState': array([25.61468723, 21.35742342, 10.56055154,  0.28807708,  0.70982345,
       -0.64277699]), 'targetState': array([25., 25., 15.])}
episode index:1163
target thresh 19.881269128192457
model initialize at round 1163
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3149165729951962
{'scaleFactor': 20, 'currentState': array([ 12.72334649,   7.35444127, -26.3038484 ,  -0.65265808,
        -0.54658782,  -0.52467055]), 'targetState': array([25., 25., 15.])}
episode index:1164
target thresh 19.889280600699344
model initialize at round 1164
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.91704615,  0.9847879 ,  0.15291738,
       -0.08251712]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.31546255881228186
{'scaleFactor': 20, 'currentState': array([25.38881787, 20.16623374, 14.35432629,  0.59307759,  0.78877567,
       -0.16152991]), 'targetState': array([25., 25., 15.])}
episode index:1165
target thresh 19.897291272099014
model initialize at round 1165
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.95683328,  0.98724191,  0.15329843,
       -0.04304646]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.31599945211467356
{'scaleFactor': 20, 'currentState': array([27.3978991 , 20.82859674, 14.38303227,  0.7506231 ,  0.65027071,
        0.11710238]), 'targetState': array([25., 25., 15.])}
episode index:1166
target thresh 19.90530114247162
model initialize at round 1166
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11061113, 15.13915863,  0.98425886,  0.10996968,
        0.13835163]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3165354252914399
{'scaleFactor': 20, 'currentState': array([ 2.68673076e+01,  2.11875013e+01,  1.67610829e+01,  6.08285374e-01,
        7.93710277e-01, -3.59157287e-03]), 'targetState': array([25., 25., 15.])}
episode index:1167
target thresh 19.91331021189722
model initialize at round 1167
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87526148,  0.98058664,  0.15226501,
       -0.12355245]), 'targetState': array([25., 25., 15.])}
done in step count: 44
reward sum = 0.6426116020847181
running average episode reward sum: 0.31681460010033824
{'scaleFactor': 20, 'currentState': array([28.68807367, 20.37244984, 15.41849017,  0.39794701,  0.70734389,
       -0.58421126]), 'targetState': array([25., 25., 15.])}
episode index:1168
target thresh 19.92131848045593
model initialize at round 1168
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12387635, 14.85431362,  0.98185017,  0.12285658,
       -0.14448707]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3165435867555133
{'scaleFactor': 20, 'currentState': array([ 34.7479234 ,  18.74107029, -10.63646766,   0.59923967,
         0.71658839,  -0.35694944]), 'targetState': array([25., 25., 15.])}
episode index:1169
target thresh 19.929325948227827
model initialize at round 1169
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.96407751,  0.98752327,  0.15334212,
       -0.03583262]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3170858486898248
{'scaleFactor': 20, 'currentState': array([25.34992736, 20.16402828, 13.91595547,  0.58919735,  0.78816169,
       -0.17789779]), 'targetState': array([25., 25., 15.])}
episode index:1170
target thresh 19.93733261529298
model initialize at round 1170
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86015101,  0.97866917,  0.15196726,
       -0.13824837]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3168150665816354
{'scaleFactor': 20, 'currentState': array([ 23.66258863,  21.97774438, -17.56747887,  -0.38426317,
         0.91472556,   0.12497588]), 'targetState': array([25., 25., 15.])}
episode index:1171
target thresh 19.945338481731454
model initialize at round 1171
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12677443, 14.92982447,  0.98945775,  0.12670499,
       -0.07013709]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.31734805726663484
{'scaleFactor': 20, 'currentState': array([27.23889418, 20.60075137, 13.46446224,  0.57017041,  0.76022344,
       -0.31139369]), 'targetState': array([25., 25., 15.])}
episode index:1172
target thresh 19.953343547623316
model initialize at round 1172
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31707751331329587
{'scaleFactor': 20, 'currentState': array([ 7.14784965,  5.37292497, -4.64265738,  0.05381581,  0.3500225 ,
       -0.93519415]), 'targetState': array([25., 25., 15.])}
episode index:1173
target thresh 19.96134781304861
model initialize at round 1173
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.0725049 , 14.96749185,  0.99679451,  0.07300251,
       -0.03273126]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31680743025255204
{'scaleFactor': 20, 'currentState': array([24.15576392, 16.40569776,  7.55326705,  0.79751051,  0.43252239,
       -0.42059645]), 'targetState': array([25., 25., 15.])}
episode index:1174
target thresh 19.969351278087387
model initialize at round 1174
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.88314115,  0.98150363,  0.1524074 ,
       -0.11585595]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31653780690765626
{'scaleFactor': 20, 'currentState': array([16.9421553 , 19.18821479, -9.64248741, -0.80150827, -0.11587153,
       -0.58665006]), 'targetState': array([25., 25., 15.])}
episode index:1175
target thresh 19.977353942819676
model initialize at round 1175
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31626864210586403
{'scaleFactor': 20, 'currentState': array([-3.06997327e+00,  2.26135606e+01,  2.14646356e+01, -9.37627934e-01,
       -3.47630816e-01, -2.58321120e-03]), 'targetState': array([25., 25., 15.])}
episode index:1176
target thresh 19.9853558073255
model initialize at round 1176
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85762353,  0.97832824,  0.15191432,
       -0.1406979 ]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31599993467841636
{'scaleFactor': 20, 'currentState': array([16.54758061,  8.9453502 , 18.1022422 ,  0.76915074,  0.48806695,
       -0.41255036]), 'targetState': array([25., 25., 15.])}
episode index:1177
target thresh 19.993356871684874
model initialize at round 1177
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.94940667,  0.98690028,  0.15324539,
       -0.05043492]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.31653897552325644
{'scaleFactor': 20, 'currentState': array([25.11090181, 20.01381635, 12.66869049,  0.50526151,  0.72178297,
       -0.47301179]), 'targetState': array([25., 25., 15.])}
episode index:1178
target thresh 20.001357135977827
model initialize at round 1178
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.51537267e+01, 1.50144300e+01, 9.88055382e-01,
       1.53424749e-01, 1.44016861e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3170771019646277
{'scaleFactor': 20, 'currentState': array([25.27263999, 20.08105604, 13.59528549,  0.53522516,  0.73740529,
       -0.41202847]), 'targetState': array([25., 25., 15.])}
episode index:1179
target thresh 20.009356600284356
model initialize at round 1179
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3168083925561831
{'scaleFactor': 20, 'currentState': array([-4.79265288, 11.42757027, 14.15106362,  0.19896761,  0.11072326,
       -0.9737311 ]), 'targetState': array([25., 25., 15.])}
episode index:1180
target thresh 20.017355264684433
model initialize at round 1180
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13625442, 14.84627329,  0.97914411,  0.13476031,
       -0.15204101]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3165401382017748
{'scaleFactor': 20, 'currentState': array([22.06841613, 25.25505087, -4.2491769 , -0.49045767,  0.58933184,
       -0.64198073]), 'targetState': array([25., 25., 15.])}
episode index:1181
target thresh 20.02535312925807
model initialize at round 1181
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13314157, 14.84627329,  0.97954595,  0.13173564,
       -0.15210341]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31627233774644337
{'scaleFactor': 20, 'currentState': array([-3.94368233, 17.92484892, -2.3132746 , -0.41617735, -0.35802406,
       -0.83583203]), 'targetState': array([25., 25., 15.])}
episode index:1182
target thresh 20.03335019408524
model initialize at round 1182
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.04786693, 15.03925294,  0.99805079,  0.04825619,
        0.03957215]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.31679287283533647
{'scaleFactor': 20, 'currentState': array([28.83176498, 21.33348075, 14.09629661,  0.57308883,  0.78937248,
       -0.22013696]), 'targetState': array([25., 25., 15.])}
episode index:1183
target thresh 20.04134645924591
model initialize at round 1183
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.50685424e+01, 1.50031435e+01, 9.97606850e-01,
       6.90690947e-02, 3.16760732e-03]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3173204803324358
{'scaleFactor': 20, 'currentState': array([27.40273689, 20.34066717, 15.46697119,  0.67527687,  0.73486716,
        0.06301911]), 'targetState': array([25., 25., 15.])}
episode index:1184
target thresh 20.04934192482004
model initialize at round 1184
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.06919748, 14.95483134,  0.99653453,  0.06965422,
       -0.0454668 ]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.3178392523725831
{'scaleFactor': 20, 'currentState': array([28.10087645, 20.53894049, 10.43039454,  0.32520704,  0.645457  ,
       -0.69110465]), 'targetState': array([25., 25., 15.])}
episode index:1185
target thresh 20.057336590887598
model initialize at round 1185
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3175712597483229
{'scaleFactor': 20, 'currentState': array([13.84712984, 20.37383988,  2.09473793, -0.96210459,  0.27149642,
       -0.02538614]), 'targetState': array([25., 25., 15.])}
episode index:1186
target thresh 20.065330457528518
model initialize at round 1186
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.9099133 ,  0.98418708,  0.15282408,
       -0.08955775]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.31809687802098735
{'scaleFactor': 20, 'currentState': array([26.47102072, 20.02950075, 10.12212038,  0.51607319,  0.46813789,
       -0.71729727]), 'targetState': array([25., 25., 15.])}
episode index:1187
target thresh 20.07332352482273
model initialize at round 1187
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09061151, 14.94653714,  0.99440065,  0.09101429,
       -0.05370051]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31782911970615485
{'scaleFactor': 20, 'currentState': array([ 43.37762014,   4.57130111, -18.44364607,   0.60111065,
         0.47039726,  -0.64605913]), 'targetState': array([25., 25., 15.])}
episode index:1188
target thresh 20.081315792850198
model initialize at round 1188
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31756181178377796
{'scaleFactor': 20, 'currentState': array([  9.64837108,  -6.06703116, -11.2646518 ,   0.36324794,
         0.51266308,  -0.77796369]), 'targetState': array([25., 25., 15.])}
episode index:1189
target thresh 20.089307261690802
model initialize at round 1189
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10451256, 14.97581057,  0.99418037,  0.10495387,
       -0.02429157]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31729495311841344
{'scaleFactor': 20, 'currentState': array([42.81942332, 20.12713236,  9.81951617,  0.46847301,  0.44567837,
       -0.76282621]), 'targetState': array([25., 25., 15.])}
episode index:1190
target thresh 20.097297931424485
model initialize at round 1190
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.91343734,  0.98448997,  0.15287111,
       -0.08608088]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3178190380859051
{'scaleFactor': 20, 'currentState': array([26.75487719, 20.25877161, 11.15038541,  0.45731642,  0.66791887,
       -0.58715081]), 'targetState': array([25., 25., 15.])}
episode index:1191
target thresh 20.105287802131155
model initialize at round 1191
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.1178452 , 14.87637681,  0.98544292,  0.11730275,
       -0.12305414]), 'targetState': array([25., 25., 15.])}
done in step count: 36
reward sum = 0.6964132180495735
running average episode reward sum: 0.31813665065298874
{'scaleFactor': 20, 'currentState': array([20.75109237, 24.63506314, 14.78786828,  0.98186165,  0.02718278,
       -0.18764007]), 'targetState': array([25., 25., 15.])}
episode index:1192
target thresh 20.113276873890694
model initialize at round 1192
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31786998120566856
{'scaleFactor': 20, 'currentState': array([ 59.730559  ,  13.4440491 , -15.8340732 ,   0.36888785,
         0.90032045,  -0.23096503]), 'targetState': array([25., 25., 15.])}
episode index:1193
target thresh 20.121265146783006
model initialize at round 1193
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13744438, 14.84627329,  0.97898818,  0.13591557,
       -0.1520168 ]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31760375844083966
{'scaleFactor': 20, 'currentState': array([14.61657088, 26.09528575, -0.88244375, -0.85631718,  0.23466322,
       -0.46005875]), 'targetState': array([25., 25., 15.])}
episode index:1194
target thresh 20.12925262088797
model initialize at round 1194
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.1305961 , 14.84627329,  0.97986801,  0.12925953,
       -0.15215342]), 'targetState': array([25., 25., 15.])}
done in step count: 32
reward sum = 0.7249803359578534
running average episode reward sum: 0.3179446593425276
{'scaleFactor': 20, 'currentState': array([20.17916082, 25.53681054, 18.38765666,  0.60246825, -0.76347323,
        0.2326814 ]), 'targetState': array([25., 25., 15.])}
episode index:1195
target thresh 20.137239296285447
model initialize at round 1195
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.49955619e+01,  1.48462733e+01,  9.88148168e-01,
       -4.42978638e-03, -1.53439157e-01]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3176788193263549
{'scaleFactor': 20, 'currentState': array([-9.93821471e+00,  8.04276684e+01, -1.84295632e+01, -8.63166513e-01,
        5.04327758e-01, -2.44352761e-02]), 'targetState': array([25., 25., 15.])}
episode index:1196
target thresh 20.145225173055337
model initialize at round 1196
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31741342348731866
{'scaleFactor': 20, 'currentState': array([ 0.31288835,  8.32353246,  5.16909088,  0.50788214,  0.05171815,
       -0.85987264]), 'targetState': array([25., 25., 15.])}
episode index:1197
target thresh 20.153210251277464
model initialize at round 1197
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.97277298, 14.85217488,  0.98866937, -0.02719042,
       -0.14762644]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31714847071312224
{'scaleFactor': 20, 'currentState': array([40.76572443, 32.19066125,  5.52670812, -0.37601535,  0.85953286,
       -0.34614408]), 'targetState': array([25., 25., 15.])}
episode index:1198
target thresh 20.16119453103169
model initialize at round 1198
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14306734, 14.84627329,  0.97823405,  0.14136701,
       -0.1518997 ]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3168839598951797
{'scaleFactor': 20, 'currentState': array([ 7.22548767, 25.18398709, -2.88111812, -0.8127819 , -0.14933575,
        0.56310249]), 'targetState': array([25., 25., 15.])}
episode index:1199
target thresh 20.169178012397857
model initialize at round 1199
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.92793945,  0.98561166,  0.15304529,
       -0.07174113]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.31741238163685037
{'scaleFactor': 20, 'currentState': array([25.15426676, 20.08579502, 12.78502643,  0.56762288,  0.78688941,
       -0.24209363]), 'targetState': array([25., 25., 15.])}
episode index:1200
target thresh 20.17716069545582
model initialize at round 1200
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.06504194,  0.98608202,  0.15311833,
        0.06478454]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.31793992340892624
{'scaleFactor': 20, 'currentState': array([25.28366374, 20.12547927, 16.58417192,  0.57126726,  0.77686591,
        0.2648265 ]), 'targetState': array([25., 25., 15.])}
episode index:1201
target thresh 20.185142580285387
model initialize at round 1201
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.97666714,  0.98788998,  0.15339907,
       -0.02328313]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.31845867567680647
{'scaleFactor': 20, 'currentState': array([25.95605989, 21.48742801, 11.49699714,  0.37398528,  0.79185929,
       -0.48279797]), 'targetState': array([25., 25., 15.])}
episode index:1202
target thresh 20.19312366696636
model initialize at round 1202
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87964684,  0.98110405,  0.15234535,
       -0.11927169]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3181939552481474
{'scaleFactor': 20, 'currentState': array([ 9.18653396, 13.65689164, -9.42627769, -0.90941963, -0.34854807,
        0.22687042]), 'targetState': array([25., 25., 15.])}
episode index:1203
target thresh 20.201103955578592
model initialize at round 1203
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.10506424,  0.98276866,  0.15260383,
        0.10429681]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3187195333998516
{'scaleFactor': 20, 'currentState': array([25.13345634, 20.07958011, 17.36996086,  0.55665065,  0.77664391,
        0.29489707]), 'targetState': array([25., 25., 15.])}
episode index:1204
target thresh 20.20908344620185
model initialize at round 1204
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.51537267e+01,  1.49844252e+01,  9.88038480e-01,
        1.53422124e-01, -1.55439018e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3192442392226733
{'scaleFactor': 20, 'currentState': array([25.22015713, 20.04186148, 13.18667378,  0.5290039 ,  0.73068491,
       -0.43157205]), 'targetState': array([25., 25., 15.])}
episode index:1205
target thresh 20.217062138915953
model initialize at round 1205
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.318979525923152
{'scaleFactor': 20, 'currentState': array([20.4828574 , 51.83420398, 18.7218763 , -0.30626001,  0.13057953,
       -0.94294952]), 'targetState': array([25., 25., 15.])}
episode index:1206
target thresh 20.225040033800667
model initialize at round 1206
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.93242687, 14.89497111,  0.99213679, -0.06771898,
       -0.10525558]), 'targetState': array([25., 25., 15.])}
done in step count: 29
reward sum = 0.7471720943315961
running average episode reward sum: 0.31933428364345723
{'scaleFactor': 20, 'currentState': array([20.14328514, 29.68480576, 15.68647003,  0.51237704, -0.15843791,
        0.84401848]), 'targetState': array([25., 25., 15.])}
episode index:1207
target thresh 20.23301713093578
model initialize at round 1207
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.9199987 ,  0.9850224 ,  0.15295379,
       -0.07959906]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3198493050555082
{'scaleFactor': 20, 'currentState': array([26.42155729, 21.22770139, 11.7743749 ,  0.47945276,  0.82627527,
       -0.29562515]), 'targetState': array([25., 25., 15.])}
episode index:1208
target thresh 20.240993430401065
model initialize at round 1208
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.51537267e+01, 1.50110116e+01, 9.88098182e-01,
       1.53431395e-01, 1.09904739e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.32036347448838287
{'scaleFactor': 20, 'currentState': array([26.47542064, 21.24840931, 12.47059675,  0.49973867,  0.64555903,
       -0.57750741]), 'targetState': array([25., 25., 15.])}
episode index:1209
target thresh 20.248968932276277
model initialize at round 1209
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11288981, 14.84627329,  0.98194379,  0.11197116,
       -0.15247574]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3200987112863264
{'scaleFactor': 20, 'currentState': array([-8.67950632, 15.4461066 , 30.12630652,  0.78494729, -0.6013814 ,
        0.14899047]), 'targetState': array([25., 25., 15.])}
episode index:1210
target thresh 20.2569436366412
model initialize at round 1210
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.03003852, 14.88352583,  0.99269957,  0.03012043,
       -0.11679177]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3198343853480222
{'scaleFactor': 20, 'currentState': array([25.57180959, 45.95208435, 17.74644178, -0.79889652, -0.29017287,
       -0.52684348]), 'targetState': array([25., 25., 15.])}
episode index:1211
target thresh 20.264917543575546
model initialize at round 1211
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.95574548,  0.98719523,  0.15329119,
       -0.04412914]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3203551408468275
{'scaleFactor': 20, 'currentState': array([25.27102726, 20.09429903, 13.41838003,  0.5424037 ,  0.7454875 ,
       -0.38735851]), 'targetState': array([25., 25., 15.])}
episode index:1212
target thresh 20.27289065315906
model initialize at round 1212
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10504997, 14.84686607,  0.98285821,  0.10429215,
       -0.15202923]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3200910393292291
{'scaleFactor': 20, 'currentState': array([ 9.82231729, 47.5984581 , 25.13969472, -0.69482897, -0.5902462 ,
        0.4108797 ]), 'targetState': array([25., 25., 15.])}
episode index:1213
target thresh 20.28086296547148
model initialize at round 1213
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 34
reward sum = 0.7105532272722921
running average episode reward sum: 0.320412672103482
{'scaleFactor': 20, 'currentState': array([20.47403995, 21.98679909, 17.39505554,  0.83280387,  0.46478671,
       -0.30068428]), 'targetState': array([25., 25., 15.])}
episode index:1214
target thresh 20.288834480592534
model initialize at round 1214
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.88667105,  0.98189581,  0.15246829,
       -0.11240123]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3201489579700635
{'scaleFactor': 20, 'currentState': array([30.77516368, 42.58878362, 13.53288659, -0.478633  ,  0.77493701,
       -0.41277486]), 'targetState': array([25., 25., 15.])}
episode index:1215
target thresh 20.29680519860194
model initialize at round 1215
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10089459, 14.84627329,  0.98318478,  0.10020002,
       -0.15266844]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31988567757699604
{'scaleFactor': 20, 'currentState': array([35.40063001,  8.62175179, 15.91522226, -0.23284175,  0.97099541,
        0.05433812]), 'targetState': array([25., 25., 15.])}
episode index:1216
target thresh 20.30477511957939
model initialize at round 1216
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.02086907,  0.98794355,  0.15340738,
        0.02082572]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3204042514244266
{'scaleFactor': 20, 'currentState': array([25.3888259 , 20.17236676, 15.59238993,  0.59813647,  0.79522414,
        0.09925387]), 'targetState': array([25., 25., 15.])}
episode index:1217
target thresh 20.312744243604584
model initialize at round 1217
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.95264328,  0.98705578,  0.15326953,
       -0.04721588]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.320914165954785
{'scaleFactor': 20, 'currentState': array([25.4859588 , 21.09648586, 10.20185983,  0.28443649,  0.67611243,
       -0.67968218]), 'targetState': array([25., 25., 15.])}
episode index:1218
target thresh 20.320712570757227
model initialize at round 1218
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87895208,  0.98102326,  0.1523328 ,
       -0.11995033]), 'targetState': array([25., 25., 15.])}
done in step count: 43
reward sum = 0.6491026283684022
running average episode reward sum: 0.3211833935695624
{'scaleFactor': 20, 'currentState': array([29.04075704, 21.40027558, 19.45987665,  0.32169504,  0.47934144,
       -0.81654399]), 'targetState': array([25., 25., 15.])}
episode index:1219
target thresh 20.32868010111699
model initialize at round 1219
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12539469, 14.87955979,  0.98492609,  0.12475202,
       -0.11982293]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3216918335333586
{'scaleFactor': 20, 'currentState': array([26.49511065, 20.64175221, 10.76604863,  0.55099344,  0.73048129,
       -0.40348893]), 'targetState': array([25., 25., 15.])}
episode index:1220
target thresh 20.33664683476356
model initialize at round 1220
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.51407983e+01,  1.49832120e+01,  9.89898050e-01,
        1.40783782e-01, -1.67862266e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3221994406716614
{'scaleFactor': 20, 'currentState': array([26.40638803, 21.49557568, 12.95068985,  0.41854268,  0.79511078,
       -0.43888595]), 'targetState': array([25., 25., 15.])}
episode index:1221
target thresh 20.344612771776593
model initialize at round 1221
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.321935775008264
{'scaleFactor': 20, 'currentState': array([-5.6906587 , 44.03494579,  8.41750579, -0.93002981, -0.2390362 ,
        0.2791169 ]), 'targetState': array([25., 25., 15.])}
episode index:1222
target thresh 20.35257791223576
model initialize at round 1222
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.03126946, 14.97183396,  0.99909769,  0.03155682,
       -0.02842488]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32167254052338395
{'scaleFactor': 20, 'currentState': array([ 4.80088453e+01,  4.75652147e+01,  3.43961420e+01,  9.99920569e-01,
       -1.25183686e-02, -1.46489479e-03]), 'targetState': array([25., 25., 15.])}
episode index:1223
target thresh 20.360542256220704
model initialize at round 1223
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11240257, 14.84627329,  0.98199682,  0.1114939 ,
       -0.15248398]), 'targetState': array([25., 25., 15.])}
done in step count: 43
reward sum = 0.6491026283684022
running average episode reward sum: 0.3219400487650874
{'scaleFactor': 20, 'currentState': array([29.91035463, 21.27156109, 19.2213909 ,  0.52092183,  0.82731188,
       -0.21022725]), 'targetState': array([25., 25., 15.])}
episode index:1224
target thresh 20.368505803811065
model initialize at round 1224
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.93567672,  0.98612749,  0.15312539,
       -0.06407168]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32167724056201386
{'scaleFactor': 20, 'currentState': array([37.1828759 , 55.09514063, 50.19191277,  0.84390676, -0.21646945,
        0.49087918]), 'targetState': array([25., 25., 15.])}
episode index:1225
target thresh 20.37646855508648
model initialize at round 1225
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.51537267e+01, 1.50084788e+01, 9.88122478e-01,
       1.53435167e-01, 8.46275920e-03]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3214148610835783
{'scaleFactor': 20, 'currentState': array([44.23504948, 69.12319619, 39.93669373,  0.29941721,  0.90714314,
        0.29570365]), 'targetState': array([25., 25., 15.])}
episode index:1226
target thresh 20.384430510126585
model initialize at round 1226
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13465628, 14.84627329,  0.97935151,  0.13320791,
       -0.15207322]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3211529092815542
{'scaleFactor': 20, 'currentState': array([ 7.34689736e+00,  9.68503820e+00,  3.60112842e+01,  8.60569728e-01,
       -2.73458033e-02,  5.08598024e-01]), 'targetState': array([25., 25., 15.])}
episode index:1227
target thresh 20.39239166901099
model initialize at round 1227
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.1446471 , 14.94572323,  0.9880413 ,  0.14436092,
       -0.05416938]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.3216503949807606
{'scaleFactor': 20, 'currentState': array([28.51231005, 21.14223738, 11.1863696 ,  0.47703293,  0.77116276,
       -0.4216012 ]), 'targetState': array([25., 25., 15.])}
episode index:1228
target thresh 20.400352031819324
model initialize at round 1228
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.51537267e+01, 1.50011592e+01, 9.88157202e-01,
       1.53440559e-01, 1.15699478e-03]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.32216246955758665
{'scaleFactor': 20, 'currentState': array([25.32305793, 20.12439619, 13.81295743,  0.5601197 ,  0.75944055,
       -0.33093198]), 'targetState': array([25., 25., 15.])}
episode index:1229
target thresh 20.40831159863116
model initialize at round 1229
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.91375638,  0.98451681,  0.15287528,
       -0.08576596]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.32266597986640244
{'scaleFactor': 20, 'currentState': array([26.33850149, 20.88366194, 10.94654766,  0.55730435,  0.59117932,
       -0.58302561]), 'targetState': array([25., 25., 15.])}
episode index:1230
target thresh 20.416270369526114
model initialize at round 1230
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.02202067, 14.86027981,  0.98994722,  0.0220195 ,
       -0.13971274]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3224038629046913
{'scaleFactor': 20, 'currentState': array([12.2091317 , 21.80205281, 13.54267447, -0.33518675,  0.78525208,
        0.52060446]), 'targetState': array([25., 25., 15.])}
episode index:1231
target thresh 20.424228344583785
model initialize at round 1231
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32214217145752844
{'scaleFactor': 20, 'currentState': array([-13.8829726 ,  34.44679983,  27.89291608,  -0.38926672,
        -0.79320242,   0.46829622]), 'targetState': array([25., 25., 15.])}
episode index:1232
target thresh 20.432185523883728
model initialize at round 1232
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14428096, 14.91223787,  0.98576089,  0.14366316,
       -0.08738634]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.3226368374562709
{'scaleFactor': 20, 'currentState': array([29.08718531, 21.29287854, 12.89564455,  0.63178472,  0.7729259 ,
       -0.05859709]), 'targetState': array([25., 25., 15.])}
episode index:1233
target thresh 20.440141907505538
model initialize at round 1233
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.0237512 ,  0.9878803 ,  0.15339756,
        0.02370035]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.32314603779050405
{'scaleFactor': 20, 'currentState': array([25.25699204, 20.06698405, 13.64103877,  0.53209896,  0.73607661,
       -0.41840403]), 'targetState': array([25., 25., 15.])}
episode index:1234
target thresh 20.44809749552875
model initialize at round 1234
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85632781,  0.97815123,  0.15188684,
       -0.14195266]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3228843810797425
{'scaleFactor': 20, 'currentState': array([25.8333373 , 34.76681026, 34.70660393, -0.13336405,  0.38165512,
       -0.91463293]), 'targetState': array([25., 25., 15.])}
episode index:1235
target thresh 20.456052288032932
model initialize at round 1235
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3226231477617168
{'scaleFactor': 20, 'currentState': array([1.78259733e+01, 4.94309492e+01, 4.83315137e+01, 9.63929399e-01,
       3.50494216e-02, 2.63840202e-01]), 'targetState': array([25., 25., 15.])}
episode index:1236
target thresh 20.464006285097657
model initialize at round 1236
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12994267, 14.84627329,  0.97994973,  0.12862352,
       -0.15216611]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32236233680960547
{'scaleFactor': 20, 'currentState': array([-1.91335219e+00,  2.28926171e+01,  3.62616608e+01, -8.33161062e-01,
        8.13647031e-03,  5.52970562e-01]), 'targetState': array([25., 25., 15.])}
episode index:1237
target thresh 20.471959486802426
model initialize at round 1237
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.49897832e+01,  1.48462733e+01,  9.88106486e-01,
       -1.01972663e-02, -1.53432684e-01]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32210194719990465
{'scaleFactor': 20, 'currentState': array([37.57959964, 62.955816  , 28.72947014, -0.50431794,  0.64508148,
       -0.57404991]), 'targetState': array([25., 25., 15.])}
episode index:1238
target thresh 20.4799118932268
model initialize at round 1238
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.51293199e+01, 1.50059945e+01, 9.91558186e-01,
       1.29523421e-01, 6.00396634e-03]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3218419779124148
{'scaleFactor': 20, 'currentState': array([-0.52054825, 46.63117411, 31.12402086, -0.83151523, -0.46470858,
        0.30434907]), 'targetState': array([25., 25., 15.])}
episode index:1239
target thresh 20.48786350445029
model initialize at round 1239
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.1526209 , 14.84627329,  0.97688778,  0.15059949,
       -0.15169065]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3215824279302274
{'scaleFactor': 20, 'currentState': array([ 4.80995504, 46.14520999, 21.29008889, -0.54947222,  0.5219932 ,
       -0.65238285]), 'targetState': array([25., 25., 15.])}
episode index:1240
target thresh 20.49581432055242
model initialize at round 1240
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.97243329,  0.98778401,  0.15338261,
       -0.02750501]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.32208194261312084
{'scaleFactor': 20, 'currentState': array([26.13521079, 20.624846  , 10.44863166,  0.40623679,  0.67587648,
       -0.61494931]), 'targetState': array([25., 25., 15.])}
episode index:1241
target thresh 20.503764341612683
model initialize at round 1241
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12055086, 14.94629429,  0.99123147,  0.12070081,
       -0.05377252]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.322573072569074
{'scaleFactor': 20, 'currentState': array([28.57620708, 20.73465374, 10.68994334,  0.58842496,  0.59919095,
       -0.54288698]), 'targetState': array([25., 25., 15.])}
episode index:1242
target thresh 20.511713567710586
model initialize at round 1242
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89917178,  0.98319127,  0.15266945,
       -0.10013477]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3230709865488262
{'scaleFactor': 20, 'currentState': array([26.8621319 , 20.93793214, 11.88092016,  0.67469718,  0.69019695,
       -0.26155666]), 'targetState': array([25., 25., 15.])}
episode index:1243
target thresh 20.519661998925642
model initialize at round 1243
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.51181291e+01, 1.50037253e+01, 9.92949287e-01,
       1.18481027e-01, 3.73637300e-03]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3228112831834333
{'scaleFactor': 20, 'currentState': array([48.36407642, 50.02683237, 57.83998209, -0.55422346, -0.11767249,
        0.82400822]), 'targetState': array([25., 25., 15.])}
episode index:1244
target thresh 20.527609635337296
model initialize at round 1244
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.06800942, 14.84627329,  0.98588894,  0.067727  ,
       -0.15308835]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3225519970122016
{'scaleFactor': 20, 'currentState': array([14.39043034, 52.7274457 , 49.31884968, -0.49869459,  0.79784571,
       -0.33874169]), 'targetState': array([25., 25., 15.])}
episode index:1245
target thresh 20.535556477025064
model initialize at round 1245
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3222931270306509
{'scaleFactor': 20, 'currentState': array([-9.51386824e+00,  4.08893419e+01,  5.11087414e+01, -3.34343464e-01,
        3.15523008e-04,  9.42451245e-01]), 'targetState': array([25., 25., 15.])}
episode index:1246
target thresh 20.54350252406839
model initialize at round 1246
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09621277, 15.13099643,  0.98678979,  0.09590078,
        0.13057166]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3227896683477081
{'scaleFactor': 20, 'currentState': array([26.03867011, 20.53011163, 19.91990691,  0.4355846 ,  0.72914001,
        0.52784552]), 'targetState': array([25., 25., 15.])}
episode index:1247
target thresh 20.551447776546738
model initialize at round 1247
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.97723883,  0.98790295,  0.15340108,
       -0.02271296]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3225310227801218
{'scaleFactor': 20, 'currentState': array([ 4.48919758e+01,  3.88806458e+01,  6.83108246e+01,  1.65656743e-01,
       -5.95118948e-02,  9.84386193e-01]), 'targetState': array([25., 25., 15.])}
episode index:1248
target thresh 20.55939223453955
model initialize at round 1248
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.51537267e+01, 1.50020981e+01, 9.88155697e-01,
       1.53440326e-01, 2.09416779e-03]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.32302657852601524
{'scaleFactor': 20, 'currentState': array([26.26532563, 20.381827  , 10.60652517,  0.43012208,  0.59370324,
       -0.68008195]), 'targetState': array([25., 25., 15.])}
episode index:1249
target thresh 20.567335898126306
model initialize at round 1249
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12054273, 14.84627329,  0.98108205,  0.11945688,
       -0.15234193]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3227681572631944
{'scaleFactor': 20, 'currentState': array([17.34276153, 60.24443787, 59.87098166, -0.70866503, -0.07013825,
        0.70205021]), 'targetState': array([25., 25., 15.])}
episode index:1250
target thresh 20.575278767386408
model initialize at round 1250
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87509822,  0.98056704,  0.15226196,
       -0.12371168]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.323262731197757
{'scaleFactor': 20, 'currentState': array([25.69772784, 21.54498748, 10.69607835,  0.35052767,  0.79310174,
       -0.49811644]), 'targetState': array([25., 25., 15.])}
episode index:1251
target thresh 20.583220842399307
model initialize at round 1251
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15124257, 14.90482514,  0.9840971 ,  0.15034079,
       -0.09460738]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32300453412811025
{'scaleFactor': 20, 'currentState': array([-5.14188285, 50.29117771, 41.07624656, -0.43948522, -0.46103617,
        0.77090751]), 'targetState': array([25., 25., 15.])}
episode index:1252
target thresh 20.59116212324441
model initialize at round 1252
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.95470749,  0.98714962,  0.1532841 ,
       -0.0451621 ]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.322746749184672
{'scaleFactor': 20, 'currentState': array([21.74492369, 51.51044334, 38.7029854 , -0.69714117,  0.70461992,
       -0.13230631]), 'targetState': array([25., 25., 15.])}
episode index:1253
target thresh 20.59910261000113
model initialize at round 1253
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3224893753814944
{'scaleFactor': 20, 'currentState': array([31.43738766, 53.84814169, 57.66767474, -0.58888749,  0.19547511,
        0.78422   ]), 'targetState': array([25., 25., 15.])}
episode index:1254
target thresh 20.60704230274888
model initialize at round 1254
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3222324117357721
{'scaleFactor': 20, 'currentState': array([13.32727159, 51.7799518 , 58.27730745, -0.52889496,  0.76144461,
       -0.37479624]), 'targetState': array([25., 25., 15.])}
episode index:1255
target thresh 20.61498120156704
model initialize at round 1255
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.1024698 , 14.85354355,  0.98408884,  0.10185796,
       -0.14558198]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32197585726782957
{'scaleFactor': 20, 'currentState': array([44.66063556, 38.66567858, 65.95658125, -0.62722878,  0.31055225,
        0.71424181]), 'targetState': array([25., 25., 15.])}
episode index:1256
target thresh 20.622919306535014
model initialize at round 1256
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.04087329, 14.84627329,  0.98733654,  0.04076332,
       -0.15331313]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32171971100110897
{'scaleFactor': 20, 'currentState': array([ 4.48071006e+01,  4.59600152e+00,  6.90292726e+01, -5.18789976e-02,
       -1.21478490e-01,  9.91237381e-01]), 'targetState': array([25., 25., 15.])}
episode index:1257
target thresh 20.630856617732196
model initialize at round 1257
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.50922577e+01, 1.50103179e+01, 9.95632326e-01,
       9.27825267e-02, 1.03765924e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32146397196215737
{'scaleFactor': 20, 'currentState': array([46.95150942, 27.10695216, 22.54437016, -0.14435328, -0.98777286,
       -0.0588804 ]), 'targetState': array([25., 25., 15.])}
episode index:1258
target thresh 20.638793135237933
model initialize at round 1258
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12943797, 14.84627329,  0.98001258,  0.12813216,
       -0.15217587]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32120863918061476
{'scaleFactor': 20, 'currentState': array([42.1976799 , 37.65827153, 69.84158759,  0.44239145,  0.09335813,
        0.89194958]), 'targetState': array([25., 25., 15.])}
episode index:1259
target thresh 20.646728859131603
model initialize at round 1259
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11205639, 14.8602333 ,  0.9840199 ,  0.11137952,
       -0.13892244]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32095371168920156
{'scaleFactor': 20, 'currentState': array([32.54487586, 41.00617272, 72.60768333, -0.45972138,  0.57944745,
        0.67297616]), 'targetState': array([25., 25., 15.])}
episode index:1260
target thresh 20.654663789492556
model initialize at round 1260
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86333796,  0.97909084,  0.15203274,
       -0.13515612]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3214458024407573
{'scaleFactor': 20, 'currentState': array([25.83661917, 21.19471377, 10.47938795,  0.40793943,  0.67765571,
       -0.61185632]), 'targetState': array([25., 25., 15.])}
episode index:1261
target thresh 20.66259792640015
model initialize at round 1261
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10488689, 14.89303253,  0.98874346,  0.10475376,
       -0.1068317 ]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3211910910283637
{'scaleFactor': 20, 'currentState': array([ 7.31360634, 40.39726202, 33.12244469, -0.0649571 , -0.13929679,
        0.9881179 ]), 'targetState': array([25., 25., 15.])}
episode index:1262
target thresh 20.670531269933722
model initialize at round 1262
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3209367829594576
{'scaleFactor': 20, 'currentState': array([49.87976153, 21.17679863, 69.64373236, -0.10349755, -0.11264282,
        0.98823067]), 'targetState': array([25., 25., 15.])}
episode index:1263
target thresh 20.67846382017261
model initialize at round 1263
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86955092,  0.97988643,  0.15215628,
       -0.12911645]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3214352428225435
{'scaleFactor': 20, 'currentState': array([24.9929537 , 20.02269656, 12.08484742,  0.52223461,  0.75279867,
       -0.40070585]), 'targetState': array([25., 25., 15.])}
episode index:1264
target thresh 20.686395577196127
model initialize at round 1264
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.51368312e+01,  1.49998685e+01,  9.90583229e-01,
        1.36911828e-01, -1.31545676e-04]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3219329146067944
{'scaleFactor': 20, 'currentState': array([25.48587346, 20.02065388, 14.88189772,  0.61519491,  0.78754984,
        0.036062  ]), 'targetState': array([25., 25., 15.])}
episode index:1265
target thresh 20.69432654108361
model initialize at round 1265
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.51046293e+01, 1.50161100e+01, 9.94331382e-01,
       1.05087077e-01, 1.61805089e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3224222884099494
{'scaleFactor': 20, 'currentState': array([27.37919655, 20.09871153, 13.60968866,  0.57864664,  0.70213852,
       -0.4149332 ]), 'targetState': array([25., 25., 15.])}
episode index:1266
target thresh 20.702256711914345
model initialize at round 1266
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.94007869,  0.98639517,  0.15316695,
       -0.05970312]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.32291839556187524
{'scaleFactor': 20, 'currentState': array([25.25107805, 20.13295133, 13.24727765,  0.58117059,  0.79077837,
       -0.1921206 ]), 'targetState': array([25., 25., 15.])}
episode index:1267
target thresh 20.710186089767657
model initialize at round 1267
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.03019057,  0.9877095 ,  0.15337104,
        0.03012072]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3234137202104069
{'scaleFactor': 20, 'currentState': array([25.23570692, 20.04864669, 13.62528924,  0.52070327,  0.72512201,
       -0.45062865]), 'targetState': array([25., 25., 15.])}
episode index:1268
target thresh 20.71811467472282
model initialize at round 1268
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32315886306288094
{'scaleFactor': 20, 'currentState': array([10.96387707, 52.2754496 , 59.17080228, -0.61759931, -0.36239828,
        0.69802477]), 'targetState': array([25., 25., 15.])}
episode index:1269
target thresh 20.72604246685913
model initialize at round 1269
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32290440726519365
{'scaleFactor': 20, 'currentState': array([-5.18846411, 40.69292761, 25.81223477, -0.93363793,  0.34605506,
        0.09255331]), 'targetState': array([25., 25., 15.])}
episode index:1270
target thresh 20.733969466255875
model initialize at round 1270
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.88990207,  0.98224463,  0.15252246,
       -0.10923546]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3226503518700204
{'scaleFactor': 20, 'currentState': array([ 1.03403488e+01,  4.13932841e+01,  7.49407587e+01, -4.12953730e-02,
       -3.09066878e-01,  9.50143335e-01]), 'targetState': array([25., 25., 15.])}
episode index:1271
target thresh 20.741895672992307
model initialize at round 1271
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87470435,  0.98051964,  0.1522546 ,
       -0.1240958 ]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3223966959330157
{'scaleFactor': 20, 'currentState': array([11.31561274, 50.84017063, 57.55867949, -0.2484649 ,  0.07869561,
        0.96543886]), 'targetState': array([25., 25., 15.])}
episode index:1272
target thresh 20.7498210871477
model initialize at round 1272
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.50140092e+01, 1.50294297e+01, 9.99458473e-01,
       1.41430443e-02, 2.97108671e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.3228756186761217
{'scaleFactor': 20, 'currentState': array([28.77226472, 21.32700723, 14.73795188,  0.49890158,  0.83375362,
       -0.23654197]), 'targetState': array([25., 25., 15.])}
episode index:1273
target thresh 20.757745708801288
model initialize at round 1273
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.06860687, 14.86477197,  0.98847225,  0.068501  ,
       -0.13501934]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32262218412457055
{'scaleFactor': 20, 'currentState': array([ 3.71133148e+01,  4.73227401e+01,  5.98374965e+01,  5.60570975e-01,
       -1.45963879e-02,  8.27977734e-01]), 'targetState': array([25., 25., 15.])}
episode index:1274
target thresh 20.76566953803235
model initialize at round 1274
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32236914711741405
{'scaleFactor': 20, 'currentState': array([ 1.25992665e+01,  5.54035984e+01,  5.91316128e+01, -8.67031432e-01,
        4.97805615e-01, -2.11202712e-02]), 'targetState': array([25., 25., 15.])}
episode index:1275
target thresh 20.773592574920098
model initialize at round 1275
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11412406, 14.84627329,  0.98180848,  0.11317977,
       -0.15245473]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3221165067199866
{'scaleFactor': 20, 'currentState': array([ 4.69044113, 44.12479665, 47.33439519,  0.36140159,  0.72722281,
        0.58355452]), 'targetState': array([25., 25., 15.])}
episode index:1276
target thresh 20.781514819543766
model initialize at round 1276
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11108222, 14.84627329,  0.9821394 ,  0.11020023,
       -0.15250612]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3218642620005504
{'scaleFactor': 20, 'currentState': array([-1.36778229e+00,  5.11867987e+01,  4.27035745e+01, -9.64894176e-01,
       -2.62296673e-01, -1.34046648e-02]), 'targetState': array([25., 25., 15.])}
episode index:1277
target thresh 20.7894362719826
model initialize at round 1277
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3216124120302839
{'scaleFactor': 20, 'currentState': array([ 1.98368689e+01,  5.32647314e+01,  5.26116913e+01, -1.18910235e-01,
       -3.97566745e-02,  9.92108745e-01]), 'targetState': array([25., 25., 15.])}
episode index:1278
target thresh 20.79735693231578
model initialize at round 1278
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.03742715, 14.95246074,  0.99813766,  0.03773479,
       -0.04793003]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3213609558832704
{'scaleFactor': 20, 'currentState': array([38.11056367, 37.34884028, 65.66233972, -0.57310531, -0.11970976,
        0.81069099]), 'targetState': array([25., 25., 15.])}
episode index:1279
target thresh 20.80527680062253
model initialize at round 1279
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3211098926364866
{'scaleFactor': 20, 'currentState': array([-11.07410641,  27.46882558,  43.51139523,  -0.49772832,
        -0.23774656,   0.83411216]), 'targetState': array([25., 25., 15.])}
episode index:1280
target thresh 20.81319587698206
model initialize at round 1280
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32085922136979145
{'scaleFactor': 20, 'currentState': array([23.52080014, 42.76996427, 66.31789109,  0.71357879, -0.10784429,
        0.69222462]), 'targetState': array([25., 25., 15.])}
episode index:1281
target thresh 20.82111416147353
model initialize at round 1281
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3206089411659149
{'scaleFactor': 20, 'currentState': array([27.96182218, 54.191948  , 30.10570002, -0.73997682,  0.46879443,
       -0.48235473]), 'targetState': array([25., 25., 15.])}
episode index:1282
target thresh 20.829031654176145
model initialize at round 1282
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.1191069 , 14.84627329,  0.98124786,  0.11805393,
       -0.15236768]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3203590511104465
{'scaleFactor': 20, 'currentState': array([-2.51648942, 54.70476793, 40.96426812, -0.75606608, -0.1245541 ,
        0.64253432]), 'targetState': array([25., 25., 15.])}
episode index:1283
target thresh 20.836948355169092
model initialize at round 1283
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08531401, 14.84627329,  0.98459446,  0.08484818,
       -0.15288734]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32010955029182464
{'scaleFactor': 20, 'currentState': array([37.56032684, 25.76837972, 11.3452416 ,  0.47073549,  0.70546397,
       -0.52983835]), 'targetState': array([25., 25., 15.])}
episode index:1284
target thresh 20.844864264531505
model initialize at round 1284
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.040487  , 14.84627329,  0.98735197,  0.04037871,
       -0.15331552]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31986043780132517
{'scaleFactor': 20, 'currentState': array([ 4.06832193, 14.90571023, 36.17751379,  0.41341462, -0.36755197,
       -0.83306297]), 'targetState': array([25., 25., 15.])}
episode index:1285
target thresh 20.85277938234257
model initialize at round 1285
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08160975, 14.84627329,  0.98489568,  0.08118898,
       -0.15293411]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31961171273305045
{'scaleFactor': 20, 'currentState': array([20.97192606, 35.47713356, 64.20790949,  0.16959781, -0.44553597,
        0.87905306]), 'targetState': array([25., 25., 15.])}
episode index:1286
target thresh 20.86069370868142
model initialize at round 1286
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.95355551,  0.98709776,  0.15327605,
       -0.04630834]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3200949049915337
{'scaleFactor': 20, 'currentState': array([25.79965615, 21.39294702, 11.01479132,  0.35065101,  0.73247367,
       -0.58354623]), 'targetState': array([25., 25., 15.])}
episode index:1287
target thresh 20.868607243627203
model initialize at round 1287
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.9041045 ,  0.9836621 ,  0.15274256,
       -0.09528158]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31984638410256516
{'scaleFactor': 20, 'currentState': array([27.51942969,  6.78270602, 30.28328436, -0.14703668, -0.09442723,
        0.98461348]), 'targetState': array([25., 25., 15.])}
episode index:1288
target thresh 20.87651998725907
model initialize at round 1288
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.51476308e+01,  1.49956456e+01,  9.89054024e-01,
        1.47489706e-01, -4.35028890e-03]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3203286445876687
{'scaleFactor': 20, 'currentState': array([27.05909273, 20.75588466, 13.14713301,  0.54903629,  0.74385616,
       -0.38109996]), 'targetState': array([25., 25., 15.])}
episode index:1289
target thresh 20.884431939656135
model initialize at round 1289
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09721436, 14.91080165,  0.99123636,  0.09733576,
       -0.08930975]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3200803278089186
{'scaleFactor': 20, 'currentState': array([46.35070904, 31.08104932, 62.81130948, -0.75013888,  0.30056261,
        0.58902782]), 'targetState': array([25., 25., 15.])}
episode index:1290
target thresh 20.892343100897513
model initialize at round 1290
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08393345, 14.91762587,  0.99301824,  0.08418934,
       -0.08262527]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.32056165997126723
{'scaleFactor': 20, 'currentState': array([26.43634717, 20.8687888 , 11.68695633,  0.43283929,  0.77550897,
       -0.45960416]), 'targetState': array([25., 25., 15.])}
episode index:1291
target thresh 20.900253471062324
model initialize at round 1291
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.95167615,  0.98701038,  0.15326248,
       -0.04817793]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3210496076414907
{'scaleFactor': 20, 'currentState': array([25.10644021, 20.01672385, 12.64684812,  0.51313213,  0.73162719,
       -0.44879512]), 'targetState': array([25., 25., 15.])}
episode index:1292
target thresh 20.908163050229668
model initialize at round 1292
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85641846,  0.97816366,  0.15188877,
       -0.1418649 ]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3208013094143898
{'scaleFactor': 20, 'currentState': array([ 3.51335051, 50.54153513, 18.17855616, -0.6158819 , -0.73245876,
        0.29016141]), 'targetState': array([25., 25., 15.])}
episode index:1293
target thresh 20.916071838478643
model initialize at round 1293
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3205533949558006
{'scaleFactor': 20, 'currentState': array([ 1.20569473e+01,  7.32187740e+01,  2.30424591e+01, -9.98522710e-01,
        2.44850293e-02,  4.85065089e-02]), 'targetState': array([25., 25., 15.])}
episode index:1294
target thresh 20.92397983588833
model initialize at round 1294
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.96813978,  0.98765858,  0.15336313,
       -0.03178487]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.32104021862757215
{'scaleFactor': 20, 'currentState': array([ 2.53743858e+01,  2.01756142e+01,  1.42307983e+01,  6.00732585e-01,
        7.99074889e-01, -2.44884305e-02]), 'targetState': array([25., 25., 15.])}
episode index:1295
target thresh 20.931887042537824
model initialize at round 1295
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.97802183,  0.98792018,  0.15340375,
       -0.021932  ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3215189531420578
{'scaleFactor': 20, 'currentState': array([27.51191425, 20.00038147, 12.71218406,  0.69297139,  0.53967686,
       -0.47805808]), 'targetState': array([25., 25., 15.])}
episode index:1296
target thresh 20.939793458506173
model initialize at round 1296
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.07423131, 14.87413939,  0.98928245,  0.07417751,
       -0.12576939]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32127105880655893
{'scaleFactor': 20, 'currentState': array([38.03294048, 38.54494012, 62.85460051,  0.6901171 ,  0.09026292,
        0.71804665]), 'targetState': array([25., 25., 15.])}
episode index:1297
target thresh 20.94769908387247
model initialize at round 1297
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.06148597, 14.84627329,  0.98630217,  0.06125631,
       -0.15315251]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.321023546434597
{'scaleFactor': 20, 'currentState': array([ 2.79034877e+01,  4.25412450e+01,  4.60617233e+01, -3.88864147e-02,
        9.39828435e-01, -3.39426514e-01]), 'targetState': array([25., 25., 15.])}
episode index:1298
target thresh 20.95560391871576
model initialize at round 1298
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.93766262,  0.98625057,  0.1531445 ,
       -0.06210129]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.32150850910085216
{'scaleFactor': 20, 'currentState': array([25.21267092, 20.05348114, 13.12028423,  0.52038663,  0.72742602,
       -0.44726853]), 'targetState': array([25., 25., 15.])}
episode index:1299
target thresh 20.96350796311508
model initialize at round 1299
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3212611948630823
{'scaleFactor': 20, 'currentState': array([30.04810981, 25.07859305, 21.41174808,  0.06378464,  0.88365153,
       -0.46377957]), 'targetState': array([25., 25., 15.])}
episode index:1300
target thresh 20.971411217149484
model initialize at round 1300
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.02490559,  0.98785267,  0.15339327,
        0.02485157]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.32173791965519444
{'scaleFactor': 20, 'currentState': array([27.00936756, 21.19395787, 15.63134479,  0.5572752 ,  0.81192202,
       -0.1738591 ]), 'targetState': array([25., 25., 15.])}
episode index:1301
target thresh 20.97931368089799
model initialize at round 1301
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 42
reward sum = 0.6556592205741436
running average episode reward sum: 0.32199438762825044
{'scaleFactor': 20, 'currentState': array([21.04199626, 26.19960271, 18.32682451,  0.86173128,  0.48770781,
       -0.13985813]), 'targetState': array([25., 25., 15.])}
episode index:1302
target thresh 20.98721535443965
model initialize at round 1302
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.51537267e+01,  1.49874458e+01,  9.88080292e-01,
        1.53428617e-01, -1.25298271e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.32247711645578053
{'scaleFactor': 20, 'currentState': array([25.38892185, 20.16727281, 14.4504383 ,  0.59408131,  0.79066382,
       -0.1480477 ]), 'targetState': array([25., 25., 15.])}
episode index:1303
target thresh 20.995116237853438
model initialize at round 1303
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89377569,  0.98265   ,  0.1525854 ,
       -0.10543567]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3222298180535905
{'scaleFactor': 20, 'currentState': array([28.48863786, 25.71830669, 52.69992958,  0.85082328, -0.39027505,
       -0.35183112]), 'targetState': array([25., 25., 15.])}
episode index:1304
target thresh 21.003016331218404
model initialize at round 1304
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3219828986527832
{'scaleFactor': 20, 'currentState': array([ 2.82734151, 16.45002928, 52.86971011,  0.16649124, -0.81098757,
        0.56087416]), 'targetState': array([25., 25., 15.])}
episode index:1305
target thresh 21.010915634613536
model initialize at round 1305
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.51052165e+01,  1.49902056e+01,  9.94351637e-01,
        1.05678980e-01, -9.83748089e-03]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.32245724570542345
{'scaleFactor': 20, 'currentState': array([26.42740322, 20.94203592, 11.90708422,  0.39494118,  0.72545163,
       -0.56368555]), 'targetState': array([25., 25., 15.])}
episode index:1306
target thresh 21.018814148117816
model initialize at round 1306
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15209494, 14.88620835,  0.98208612,  0.15087912,
       -0.11288202]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.32293086690182404
{'scaleFactor': 20, 'currentState': array([25.74127472, 21.52599392, 10.80334452,  0.35614571,  0.797015  ,
       -0.48777794]), 'targetState': array([25., 25., 15.])}
episode index:1307
target thresh 21.02671187181023
model initialize at round 1307
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12523404, 14.91582561,  0.98858295,  0.12505478,
       -0.08405391]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3234037639067929
{'scaleFactor': 20, 'currentState': array([26.49259518, 20.081292  , 10.46222538,  0.46686266,  0.70833143,
       -0.52943917]), 'targetState': array([25., 25., 15.])}
episode index:1308
target thresh 21.03460880576977
model initialize at round 1308
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11305998, 14.98172014,  0.99337491,  0.1134454 ,
       -0.01834217]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32315670220785725
{'scaleFactor': 20, 'currentState': array([14.65602928, 20.9496942 , -2.68983357, -0.86466873,  0.46078254,
       -0.20006858]), 'targetState': array([25., 25., 15.])}
episode index:1309
target thresh 21.042504950075404
model initialize at round 1309
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14890624, 14.90484702,  0.98444025,  0.14806999,
       -0.09461861]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3236287048393024
{'scaleFactor': 20, 'currentState': array([26.6393637 , 20.50859593, 11.02278648,  0.49930416,  0.70787453,
       -0.49960884]), 'targetState': array([25., 25., 15.])}
episode index:1310
target thresh 21.050400304806082
model initialize at round 1310
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08862705, 14.93053037,  0.99359298,  0.0889487 ,
       -0.06972176]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.3240928060163182
{'scaleFactor': 20, 'currentState': array([28.54622612, 21.05733983, 11.72097619,  0.42594806,  0.73915305,
       -0.52174804]), 'targetState': array([25., 25., 15.])}
episode index:1311
target thresh 21.05829487004075
model initialize at round 1311
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.90756441,  0.98397865,  0.15279172,
       -0.09187338]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.324570624037571
{'scaleFactor': 20, 'currentState': array([25.08672276, 20.07598869, 12.47221881,  0.55437077,  0.77867404,
       -0.29383631]), 'targetState': array([25., 25., 15.])}
episode index:1312
target thresh 21.066188645858386
model initialize at round 1312
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.51537267e+01, 1.50168861e+01, 9.88017535e-01,
       1.53418872e-01, 1.68523025e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.32504771423243956
{'scaleFactor': 20, 'currentState': array([25.44986324, 20.07828647, 14.3334793 ,  0.65457796,  0.70472872,
       -0.27365147]), 'targetState': array([25., 25., 15.])}
episode index:1313
target thresh 21.074081632337894
model initialize at round 1313
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09212809, 14.84627329,  0.98400623,  0.09157032,
       -0.152796  ]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32480034154276494
{'scaleFactor': 20, 'currentState': array([30.72572938, 54.41034626, 12.74246689, -0.50745045,  0.85833722,
       -0.07583704]), 'targetState': array([25., 25., 15.])}
episode index:1314
target thresh 21.08197382955822
model initialize at round 1314
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.93241819, 15.07893986,  0.99453608, -0.06789147,
        0.07930156]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32455334508531797
{'scaleFactor': 20, 'currentState': array([ 6.37419375e+01,  4.11912987e+01,  4.02747085e+01,  6.96396863e-01,
        4.36597191e-02, -7.16327605e-01]), 'targetState': array([25., 25., 15.])}
episode index:1315
target thresh 21.089865237598293
model initialize at round 1315
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.05209104, 14.84627329,  0.98682488,  0.05192397,
       -0.15323368]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3243067240024264
{'scaleFactor': 20, 'currentState': array([13.84336285, 37.89509018, 41.56656859,  0.37258125, -0.92681701,
        0.04683414]), 'targetState': array([25., 25., 15.])}
episode index:1316
target thresh 21.097755856537002
model initialize at round 1316
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 35
reward sum = 0.7034476949995692
running average episode reward sum: 0.32459460628868086
{'scaleFactor': 20, 'currentState': array([25.53419215, 29.39922607, 19.69430356,  0.57107816,  0.67645609,
       -0.46505579]), 'targetState': array([25., 25., 15.])}
episode index:1317
target thresh 21.10564568645328
model initialize at round 1317
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08262499, 14.84627329,  0.98481443,  0.08219221,
       -0.1529215 ]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3243483281351993
{'scaleFactor': 20, 'currentState': array([-20.08071973,  23.14375103,  21.19811925,  -0.11316141,
        -0.99289764,  -0.03672551]), 'targetState': array([25., 25., 15.])}
episode index:1318
target thresh 21.11353472742602
model initialize at round 1318
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3241024234133379
{'scaleFactor': 20, 'currentState': array([-3.11193002, 49.5127935 , 27.64482089, -0.56968997, -0.64949058,
        0.50360234]), 'targetState': array([25., 25., 15.])}
episode index:1319
target thresh 21.12142297953409
model initialize at round 1319
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 37
reward sum = 0.6894490858690777
running average episode reward sum: 0.32437920118792557
{'scaleFactor': 20, 'currentState': array([20.18556584, 22.74307578, 15.28606077,  0.73500049,  0.46430526,
       -0.49416081]), 'targetState': array([25., 25., 15.])}
episode index:1320
target thresh 21.129310442856408
model initialize at round 1320
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3241336453959589
{'scaleFactor': 20, 'currentState': array([-9.17326147,  0.98770158,  6.03523353,  0.52302194, -0.12498933,
       -0.84310481]), 'targetState': array([25., 25., 15.])}
episode index:1321
target thresh 21.137197117471818
model initialize at round 1321
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10486042, 14.84627329,  0.98278938,  0.10409668,
       -0.15260705]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3238884610953568
{'scaleFactor': 20, 'currentState': array([ 15.29435518,  20.49940697, -12.80196002,  -0.67683145,
         0.51909548,  -0.52195697]), 'targetState': array([25., 25., 15.])}
episode index:1322
target thresh 21.1450830034592
model initialize at round 1322
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.32436246078455155
{'scaleFactor': 20, 'currentState': array([24.8184014 , 20.00470996, 11.53243396,  0.49991119,  0.74260288,
       -0.445679  ]), 'targetState': array([25., 25., 15.])}
episode index:1323
target thresh 21.152968100897407
model initialize at round 1323
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86261493,  0.97899598,  0.15201801,
       -0.13585801]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32411747403169316
{'scaleFactor': 20, 'currentState': array([25.08829697, 46.4697136 , 18.90523501, -0.54775488, -0.41354383,
       -0.7272868 ]), 'targetState': array([25., 25., 15.])}
episode index:1324
target thresh 21.160852409865306
model initialize at round 1324
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.8823437 ,  0.98141344,  0.15239339,
       -0.11663583]), 'targetState': array([25., 25., 15.])}
done in step count: 39
reward sum = 0.6757290490602831
running average episode reward sum: 0.32438284125812983
{'scaleFactor': 20, 'currentState': array([22.23265588, 20.23468584, 13.60273087,  0.47064599,  0.11413091,
       -0.87490941]), 'targetState': array([25., 25., 15.])}
episode index:1325
target thresh 21.168735930441716
model initialize at round 1325
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.05892485, 14.84627329,  0.98645315,  0.05871374,
       -0.15317596]), 'targetState': array([25., 25., 15.])}
done in step count: 35
reward sum = 0.7034476949995692
running average episode reward sum: 0.32466871218855325
{'scaleFactor': 20, 'currentState': array([21.13367758, 24.55906778, 17.02402101,  0.98109232,  0.07073781,
       -0.18014998]), 'targetState': array([25., 25., 15.])}
episode index:1326
target thresh 21.176618662705494
model initialize at round 1326
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13013729, 14.84627329,  0.97992543,  0.12881297,
       -0.15216233]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3244240485019002
{'scaleFactor': 20, 'currentState': array([ 6.85977813, 52.37190101, 19.71495974, -0.61360084, -0.69270125,
       -0.37902374]), 'targetState': array([25., 25., 15.])}
episode index:1327
target thresh 21.184500606735448
model initialize at round 1327
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84643278,  0.97675001,  0.15166926,
       -0.1515119 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3248886991802881
{'scaleFactor': 20, 'currentState': array([25.62834476, 21.47270148, 10.47738001,  0.33610328,  0.783289  ,
       -0.52296551]), 'targetState': array([25., 25., 15.])}
episode index:1328
target thresh 21.192381762610413
model initialize at round 1328
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.92423495,  0.98534429,  0.15300377,
       -0.07540875]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.32535265061010055
{'scaleFactor': 20, 'currentState': array([25.39823466, 21.117104  , 10.22469777,  0.22164136,  0.63632289,
       -0.73889666]), 'targetState': array([25., 25., 15.])}
episode index:1329
target thresh 21.200262130409186
model initialize at round 1329
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13387418, 14.84627329,  0.97945217,  0.13244784,
       -0.15208885]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32510802455701027
{'scaleFactor': 20, 'currentState': array([23.60237237, 12.28454303,  9.23661342,  0.1700111 ,  0.2835327 ,
       -0.94377192]), 'targetState': array([25., 25., 15.])}
episode index:1330
target thresh 21.208141710210604
model initialize at round 1330
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.50099679e+01,  1.48462733e+01,  9.88108959e-01,
        9.94883165e-03, -1.53433068e-01]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3248637660862687
{'scaleFactor': 20, 'currentState': array([29.6308054 , 55.73471459, 11.44770627, -0.54486608,  0.36488382,
       -0.7549707 ]), 'targetState': array([25., 25., 15.])}
episode index:1331
target thresh 21.216020502093414
model initialize at round 1331
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12430308, 14.84627329,  0.98063881,  0.1231277 ,
       -0.15227311]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32461987436998774
{'scaleFactor': 20, 'currentState': array([11.23719374, 24.71507696, -4.61204875, -0.95640263,  0.25606465,
        0.1404454 ]), 'targetState': array([25., 25., 15.])}
episode index:1332
target thresh 21.22389850613644
model initialize at round 1332
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32437634858276343
{'scaleFactor': 20, 'currentState': array([-0.93531605,  7.45524209, -7.47962713, -0.47673332, -0.47759499,
       -0.73798941]), 'targetState': array([25., 25., 15.])}
episode index:1333
target thresh 21.231775722418444
model initialize at round 1333
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3241331879016669
{'scaleFactor': 20, 'currentState': array([36.12393221, 10.71240242, 18.5445625 ,  0.29373002,  0.27591687,
        0.91520083]), 'targetState': array([25., 25., 15.])}
episode index:1334
target thresh 21.23965215101822
model initialize at round 1334
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32389039150623494
{'scaleFactor': 20, 'currentState': array([ 8.76019477,  4.67334979, -0.62309369, -0.14302214, -0.46188619,
       -0.87533183]), 'targetState': array([25., 25., 15.])}
episode index:1335
target thresh 21.2475277920145
model initialize at round 1335
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3236479585784608
{'scaleFactor': 20, 'currentState': array([10.34619738, 13.80427623, 21.00284753,  0.97881227, -0.13126283,
       -0.15715156]), 'targetState': array([25., 25., 15.])}
episode index:1336
target thresh 21.255402645486054
model initialize at round 1336
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.98176155, 14.92661021,  0.9970953 , -0.01836916,
       -0.07391577]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32340588830278505
{'scaleFactor': 20, 'currentState': array([36.62669281, 48.03273428, 33.40397057, -0.95696426,  0.22219482,
        0.18667851]), 'targetState': array([25., 25., 15.])}
episode index:1337
target thresh 21.263276711511647
model initialize at round 1337
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10382231, 14.88240489,  0.98767789,  0.10357879,
       -0.11731928]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3231641798660864
{'scaleFactor': 20, 'currentState': array([64.60568256, 44.93205904, 27.85872485, -0.23147781,  0.75508531,
       -0.61340379]), 'targetState': array([25., 25., 15.])}
episode index:1338
target thresh 21.271149990170002
model initialize at round 1338
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85665483,  0.97819605,  0.1518938 ,
       -0.14163604]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3229228324576726
{'scaleFactor': 20, 'currentState': array([ 9.85116586, 29.23500798,  0.87291367, -0.84920448, -0.12737118,
        0.51247277]), 'targetState': array([25., 25., 15.])}
episode index:1339
target thresh 21.279022481539855
model initialize at round 1339
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08977663, 14.95359622,  0.99483011,  0.09021465,
       -0.04663018]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3226818452692714
{'scaleFactor': 20, 'currentState': array([ 33.00074245,   1.50829254, -21.85377476,   0.70445474,
         0.68494184,  -0.18600587]), 'targetState': array([25., 25., 15.])}
episode index:1340
target thresh 21.286894185699936
model initialize at round 1340
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85737161,  0.97829394,  0.151909  ,
       -0.14094191]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3224412174950214
{'scaleFactor': 20, 'currentState': array([28.6778358 ,  4.79777256, -6.39593831,  0.82411121,  0.1687445 ,
       -0.5407088 ]), 'targetState': array([25., 25., 15.])}
episode index:1341
target thresh 21.294765102728952
model initialize at round 1341
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.0488862 , 14.84627329,  0.98698357,  0.04873725,
       -0.15325832]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3222009483314633
{'scaleFactor': 20, 'currentState': array([ 30.87077937,  17.02189365, -11.65861249,   0.52572794,
         0.82356837,  -0.21294432]), 'targetState': array([25., 25., 15.])}
episode index:1342
target thresh 21.302635232705626
model initialize at round 1342
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13670491, 14.84627329,  0.97908523,  0.13519773,
       -0.15203187]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3219610369775307
{'scaleFactor': 20, 'currentState': array([ 9.2771449 , 58.34786547, 29.67404522, -0.38446537, -0.19472932,
       -0.90236737]), 'targetState': array([25., 25., 15.])}
episode index:1343
target thresh 21.310504575708645
model initialize at round 1343
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3217214826345415
{'scaleFactor': 20, 'currentState': array([  7.19907492,  22.37712119, -10.77237174,  -0.99725842,
        -0.0331256 ,  -0.06616908]), 'targetState': array([25., 25., 15.])}
episode index:1344
target thresh 21.318373131816703
model initialize at round 1344
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15360248, 14.87002758,  0.97996434,  0.15204541,
       -0.12865489]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32148228450618865
{'scaleFactor': 20, 'currentState': array([-4.71908898, 30.31309722,  2.73657987,  0.4343466 , -0.17452594,
       -0.88367625]), 'targetState': array([25., 25., 15.])}
episode index:1345
target thresh 21.326240901108505
model initialize at round 1345
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32124344179853176
{'scaleFactor': 20, 'currentState': array([ 32.17200086,  23.49207127, -10.83753001,  -0.10066876,
         0.99128126,  -0.08501327]), 'targetState': array([25., 25., 15.])}
episode index:1346
target thresh 21.33410788366271
model initialize at round 1346
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11621987, 14.84627329,  0.98157548,  0.11523089,
       -0.15241855]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32100495371998794
{'scaleFactor': 20, 'currentState': array([59.78108687, 32.28732401, 37.32270771,  0.84043535,  0.09369358,
        0.53375081]), 'targetState': array([25., 25., 15.])}
episode index:1347
target thresh 21.341974079558
model initialize at round 1347
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12907359, 14.84627329,  0.98005781,  0.12777736,
       -0.15218289]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3207668194813233
{'scaleFactor': 20, 'currentState': array([12.24833171,  7.07225671, -5.96508716,  0.03389456,  0.41550274,
       -0.90896019]), 'targetState': array([25., 25., 15.])}
episode index:1348
target thresh 21.349839488873023
model initialize at round 1348
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32052903829564405
{'scaleFactor': 20, 'currentState': array([ 8.21354063, 21.80424074, -1.63540404, -0.97264984,  0.15309479,
        0.17468334]), 'targetState': array([25., 25., 15.])}
episode index:1349
target thresh 21.357704111686438
model initialize at round 1349
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.06301123, 14.92050093,  0.99479125,  0.06331618,
       -0.07988382]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.320291609378388
{'scaleFactor': 20, 'currentState': array([33.33731151, 21.45324954, -9.57415993, -0.43227124,  0.68392929,
        0.58769236]), 'targetState': array([25., 25., 15.])}
episode index:1350
target thresh 21.3655679480769
model initialize at round 1350
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3200545319473159
{'scaleFactor': 20, 'currentState': array([35.77873577,  5.5111218 , -8.11543851, -0.36992749,  0.91442839,
        0.16423878]), 'targetState': array([25., 25., 15.])}
episode index:1351
target thresh 21.373430998123034
model initialize at round 1351
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.90765148,  0.98398646,  0.15279293,
       -0.09178757]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3205141662797521
{'scaleFactor': 20, 'currentState': array([27.01460001, 20.71359866, 12.1255938 ,  0.60387722,  0.76368843,
       -0.22828115]), 'targetState': array([25., 25., 15.])}
episode index:1352
target thresh 21.38129326190348
model initialize at round 1352
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.03788259, 14.96901498,  0.99878034,  0.03821857,
       -0.03125983]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3202772748043051
{'scaleFactor': 20, 'currentState': array([14.11263904, 32.07979749, 27.5963786 , -0.8287279 , -0.22692039,
       -0.51158304]), 'targetState': array([25., 25., 15.])}
episode index:1353
target thresh 21.389154739496863
model initialize at round 1353
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.94336167, 14.84627329,  0.98658258, -0.05644282,
       -0.15319605]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3200407332424112
{'scaleFactor': 20, 'currentState': array([30.91129994, 24.8379375 , -2.07275253,  0.11369678,  0.96324289,
       -0.24338485]), 'targetState': array([25., 25., 15.])}
episode index:1354
target thresh 21.39701543098178
model initialize at round 1354
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.93274148,  0.9859386 ,  0.15309606,
       -0.0669826 ]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.32050637849455704
{'scaleFactor': 20, 'currentState': array([25.29423371, 20.13152206, 13.47599751,  0.57560588,  0.78047212,
       -0.24401053]), 'targetState': array([25., 25., 15.])}
episode index:1355
target thresh 21.404875336436866
model initialize at round 1355
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.90825284,  0.98404028,  0.15280129,
       -0.09119484]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32027001685849915
{'scaleFactor': 20, 'currentState': array([ 13.11854514,  29.11983754, -13.06363308,   0.1527055 ,
         0.96485771,  -0.21384721]), 'targetState': array([25., 25., 15.])}
episode index:1356
target thresh 21.412734455940697
model initialize at round 1356
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.93191858, 14.90100668,  0.99271643, -0.06826822,
       -0.09926494]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3200340035815216
{'scaleFactor': 20, 'currentState': array([ 26.28033027,  10.69854869, -15.592484  ,  -0.19981478,
        -0.11284264,  -0.97331423]), 'targetState': array([25., 25., 15.])}
episode index:1357
target thresh 21.42059278957187
model initialize at round 1357
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3197983378940536
{'scaleFactor': 20, 'currentState': array([ 36.35587168,   9.31720704, -11.4744806 ,   0.60405535,
         0.79022893,  -0.10322485]), 'targetState': array([25., 25., 15.])}
episode index:1358
target thresh 21.42845033740898
model initialize at round 1358
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.50881423e+01,  1.49962281e+01,  9.96052828e-01,
        8.86812339e-02, -3.79497526e-03]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.32024886549524045
{'scaleFactor': 20, 'currentState': array([29.14002572, 20.88638904, 17.27118989,  0.59838826,  0.72564921,
        0.33965383]), 'targetState': array([25., 25., 15.])}
episode index:1359
target thresh 21.436307099530584
model initialize at round 1359
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.04727339,  0.98705965,  0.15327013,
        0.04713299]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3207056532039947
{'scaleFactor': 20, 'currentState': array([26.90988607, 21.3881826 , 15.34857281,  0.58092114,  0.80989771,
       -0.08121779]), 'targetState': array([25., 25., 15.])}
episode index:1360
target thresh 21.444163076015265
model initialize at round 1360
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10356496, 14.933334  ,  0.99234966,  0.10381077,
       -0.06682422]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.3211548520979719
{'scaleFactor': 20, 'currentState': array([29.58290465, 20.28447092, 12.23818678,  0.70897308,  0.57531964,
       -0.40787802]), 'targetState': array([25., 25., 15.])}
episode index:1361
target thresh 21.452018266941565
model initialize at round 1361
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14961583, 14.89747476,  0.98362885,  0.14865298,
       -0.10186544]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.32161030385810624
{'scaleFactor': 20, 'currentState': array([25.4975683 , 21.19883708, 10.25702036,  0.2562612 ,  0.67322148,
       -0.69361591]), 'targetState': array([25., 25., 15.])}
episode index:1362
target thresh 21.459872672388048
model initialize at round 1362
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.88124019,  0.98128765,  0.15237386,
       -0.11771468]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3213743461883644
{'scaleFactor': 20, 'currentState': array([14.27290763, 28.8794359 , -1.7625472 , -0.97392534,  0.19307613,
        0.11912616]), 'targetState': array([25., 25., 15.])}
episode index:1363
target thresh 21.467726292433266
model initialize at round 1363
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89025057,  0.98228167,  0.15252821,
       -0.10889379]), 'targetState': array([25., 25., 15.])}
done in step count: 41
reward sum = 0.6622820409839835
running average episode reward sum: 0.3216242785159272
{'scaleFactor': 20, 'currentState': array([2.04728691e+01, 2.39453188e+01, 1.03431924e+01, 9.37021195e-01,
       3.48989305e-01, 1.40621917e-02]), 'targetState': array([25., 25., 15.])}
episode index:1364
target thresh 21.47557912715574
model initialize at round 1364
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.94458511,  0.98664974,  0.15320648,
       -0.05522736]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.32207838538104444
{'scaleFactor': 20, 'currentState': array([26.64981953, 21.47093116, 13.02908627,  0.51340648,  0.80673042,
       -0.29257444]), 'targetState': array([25., 25., 15.])}
episode index:1365
target thresh 21.483431176634017
model initialize at round 1365
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14739889, 14.92599767,  0.9864048 ,  0.14686361,
       -0.07373359]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.32253182737520253
{'scaleFactor': 20, 'currentState': array([26.05023477, 21.07291267, 10.94949171,  0.40078717,  0.63683889,
       -0.65863942]), 'targetState': array([25., 25., 15.])}
episode index:1366
target thresh 21.49128244094659
model initialize at round 1366
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08704481, 14.84627329,  0.98444923,  0.08655676,
       -0.15286479]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3222958860237942
{'scaleFactor': 20, 'currentState': array([30.42725693, 25.70978254, -7.00390463,  0.13790233,  0.90941474,
       -0.3923618 ]), 'targetState': array([25., 25., 15.])}
episode index:1367
target thresh 21.49913292017199
model initialize at round 1367
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11450413, 14.84627329,  0.98176653,  0.11355184,
       -0.15244822]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32206028961588207
{'scaleFactor': 20, 'currentState': array([ 2.10721552e+01,  1.50317520e+01,  1.20700653e+01, -4.83497147e-01,
       -1.52923893e-02, -8.75212347e-01]), 'targetState': array([25., 25., 15.])}
episode index:1368
target thresh 21.506982614388725
model initialize at round 1368
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3218250373955637
{'scaleFactor': 20, 'currentState': array([10.19099903, 26.08833857, -3.63473316, -0.84148142,  0.21601503,
        0.49522371]), 'targetState': array([25., 25., 15.])}
episode index:1369
target thresh 21.51483152367527
model initialize at round 1369
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.94314084,  0.9865703 ,  0.15319415,
       -0.05666218]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.32228428193023845
{'scaleFactor': 20, 'currentState': array([25.31412009, 20.15253813, 13.61058183,  0.5819835 ,  0.78429776,
       -0.21487725]), 'targetState': array([25., 25., 15.])}
episode index:1370
target thresh 21.522679648110156
model initialize at round 1370
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.88921993,  0.9821718 ,  0.15251115,
       -0.1099041 ]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3227428565239436
{'scaleFactor': 20, 'currentState': array([25.04119287, 20.03776534, 12.30393228,  0.53771904,  0.76550664,
       -0.35335226]), 'targetState': array([25., 25., 15.])}
episode index:1371
target thresh 21.530526987771815
model initialize at round 1371
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.91103179,  0.98428449,  0.15283921,
       -0.08845457]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.32319383122720674
{'scaleFactor': 20, 'currentState': array([25.4284418 , 21.20667377, 10.18202002,  0.24514009,  0.66664609,
       -0.70391003]), 'targetState': array([25., 25., 15.])}
episode index:1372
target thresh 21.538373542738743
model initialize at round 1372
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11221887, 14.84627329,  0.98201675,  0.11131395,
       -0.15248707]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.322958438779117
{'scaleFactor': 20, 'currentState': array([  6.50654753, -12.19658838,  -5.24828501,  -0.6088859 ,
        -0.09178801,  -0.78792951]), 'targetState': array([25., 25., 15.])}
episode index:1373
target thresh 21.54621931308942
model initialize at round 1373
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3227233889692341
{'scaleFactor': 20, 'currentState': array([ 22.21565456,  20.0563185 , -16.99328744,  -0.06199774,
         0.77387317,  -0.63029881]), 'targetState': array([25., 25., 15.])}
episode index:1374
target thresh 21.554064298902286
model initialize at round 1374
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13468118, 14.91670162,  0.98744698,  0.13433386,
       -0.08308357]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.32317339388591176
{'scaleFactor': 20, 'currentState': array([25.51544085, 20.94695508, 10.17974217,  0.23818551,  0.63665284,
       -0.73344449]), 'targetState': array([25., 25., 15.])}
episode index:1375
target thresh 21.56190850025579
model initialize at round 1375
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32293852950082025
{'scaleFactor': 20, 'currentState': array([ 32.05090109,  24.0689431 , -10.70232866,   0.18150197,
         0.98043014,   0.07624806]), 'targetState': array([25., 25., 15.])}
episode index:1376
target thresh 21.569751917228388
model initialize at round 1376
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.9566745 ,  0.98723517,  0.15329739,
       -0.0432045 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3233877245770005
{'scaleFactor': 20, 'currentState': array([25.7128031 , 21.15991242, 10.83194331,  0.27254345,  0.659361  ,
       -0.70068762]), 'targetState': array([25., 25., 15.])}
episode index:1377
target thresh 21.577594549898482
model initialize at round 1377
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.323153045531589
{'scaleFactor': 20, 'currentState': array([ 11.26410372,  18.8099872 , -11.40173054,  -0.73344582,
         0.47681122,  -0.48446701]), 'targetState': array([25., 25., 15.])}
episode index:1378
target thresh 21.585436398344548
model initialize at round 1378
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32291870684737467
{'scaleFactor': 20, 'currentState': array([17.77050099, 13.23376714, 49.70566001, -0.27072201, -0.23832198,
        0.93269085]), 'targetState': array([25., 25., 15.])}
episode index:1379
target thresh 21.593277462644956
model initialize at round 1379
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.95817366,  0.98729784,  0.15330712,
       -0.04171218]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.32337383100900696
{'scaleFactor': 20, 'currentState': array([25.25217507, 20.08112811, 13.19877285,  0.57408457,  0.77920517,
       -0.25152777]), 'targetState': array([25., 25., 15.])}
episode index:1380
target thresh 21.601117742878152
model initialize at round 1380
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.97026725,  0.98772299,  0.15337314,
       -0.02966436]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3238214098058151
{'scaleFactor': 20, 'currentState': array([26.97760092, 21.04970662, 13.2211617 ,  0.57420966,  0.79652244,
       -0.18930206]), 'targetState': array([25., 25., 15.])}
episode index:1381
target thresh 21.608957239122518
model initialize at round 1381
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.93336968,  0.98597973,  0.15310244,
       -0.06635974]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3242683408764339
{'scaleFactor': 20, 'currentState': array([25.311352  , 21.06772784, 10.06031222,  0.20837605,  0.62510926,
       -0.75220864]), 'targetState': array([25., 25., 15.])}
episode index:1382
target thresh 21.616795951456456
model initialize at round 1382
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.07646501, 14.84627329,  0.98529229,  0.0761014 ,
       -0.1529957 ]), 'targetState': array([25., 25., 15.])}
done in step count: 36
reward sum = 0.6964132180495735
running average episode reward sum: 0.32453742610938635
{'scaleFactor': 20, 'currentState': array([25.46837367, 28.50073239, 17.83021982,  0.24594557, -0.87711741,
        0.41252372]), 'targetState': array([25., 25., 15.])}
episode index:1383
target thresh 21.624633879958356
model initialize at round 1383
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87019824,  0.9799673 ,  0.15216884,
       -0.12848635]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3243029337494807
{'scaleFactor': 20, 'currentState': array([  3.22969785,  16.94035719, -12.68515336,  -0.73178748,
        -0.17941866,   0.65749223]), 'targetState': array([25., 25., 15.])}
episode index:1384
target thresh 21.63247102470658
model initialize at round 1384
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.51537267e+01, 1.50070143e+01, 9.88133646e-01,
       1.53436902e-01, 7.00107554e-03]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.32474854906764067
{'scaleFactor': 20, 'currentState': array([26.68834078, 20.39010095, 11.38266806,  0.55753419,  0.48302406,
       -0.67516175]), 'targetState': array([25., 25., 15.])}
episode index:1385
target thresh 21.640307385779533
model initialize at round 1385
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11822116, 14.84627329,  0.98134919,  0.11718812,
       -0.15238342]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32451424275518204
{'scaleFactor': 20, 'currentState': array([ 22.72276776, -13.96428303, -10.4218444 ,   0.79140087,
        -0.42459675,  -0.43977525]), 'targetState': array([25., 25., 15.])}
episode index:1386
target thresh 21.648142963255555
model initialize at round 1386
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.0669754 , 14.85169899,  0.98675943,  0.06675617,
       -0.14781558]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32428027430330375
{'scaleFactor': 20, 'currentState': array([51.43490669, 50.25099421, 22.494285  , -0.30174147,  0.51741021,
       -0.80077385]), 'targetState': array([25., 25., 15.])}
episode index:1387
target thresh 21.655977757212995
model initialize at round 1387
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32404664298175956
{'scaleFactor': 20, 'currentState': array([  8.76452852,   2.55932315, -27.79489591,   0.66486278,
        -0.17810276,  -0.72542187]), 'targetState': array([25., 25., 15.])}
episode index:1388
target thresh 21.663811767730223
model initialize at round 1388
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32381334806240625
{'scaleFactor': 20, 'currentState': array([ 1.16340328e+01,  2.35445408e+01, -2.83736959e+00, -9.97920430e-01,
       -6.26142374e-02,  1.53059711e-02]), 'targetState': array([25., 25., 15.])}
episode index:1389
target thresh 21.671644994885565
model initialize at round 1389
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3235803888191959
{'scaleFactor': 20, 'currentState': array([ 27.27133104,   4.88208045, -21.52768574,   0.1878911 ,
         0.81865472,  -0.54267981]), 'targetState': array([25., 25., 15.])}
episode index:1390
target thresh 21.679477438757356
model initialize at round 1390
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3233477645281684
{'scaleFactor': 20, 'currentState': array([ 8.83643167, 57.48485601,  3.4049135 ,  0.14714038, -0.95799452,
        0.24616298]), 'targetState': array([25., 25., 15.])}
episode index:1391
target thresh 21.687309099423924
model initialize at round 1391
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85173871,  0.97751223,  0.15178761,
       -0.14639114]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32311547446744415
{'scaleFactor': 20, 'currentState': array([21.45192778, 23.33069456,  0.68315465, -0.85753769,  0.4700095 ,
       -0.20909374]), 'targetState': array([25., 25., 15.])}
episode index:1392
target thresh 21.695139976963574
model initialize at round 1392
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.95160413,  0.98700697,  0.15326195,
       -0.04824955]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.32355938306395066
{'scaleFactor': 20, 'currentState': array([26.00793179, 21.53656838, 11.62004674,  0.39046069,  0.7981423 ,
       -0.45881295]), 'targetState': array([25., 25., 15.])}
episode index:1393
target thresh 21.70297007145463
model initialize at round 1393
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.95964651,  0.98735727,  0.15331635,
       -0.04024577]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.32400265477581364
{'scaleFactor': 20, 'currentState': array([25.72540004, 21.35005578, 10.99615824,  0.29039423,  0.70356386,
       -0.64859008]), 'targetState': array([25., 25., 15.])}
episode index:1394
target thresh 21.710799382975377
model initialize at round 1394
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3237703948082324
{'scaleFactor': 20, 'currentState': array([21.0870978 , 22.71746606, -9.38496687, -0.70029898,  0.70485678,
        0.11295246]), 'targetState': array([25., 25., 15.])}
episode index:1395
target thresh 21.718627911604127
model initialize at round 1395
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.03896002, 14.84627329,  0.98741154,  0.03885816,
       -0.15332477]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32353846759132104
{'scaleFactor': 20, 'currentState': array([  1.97442072,  12.62870059, -18.85835767,  -0.32286323,
        -0.87855529,  -0.35199423]), 'targetState': array([25., 25., 15.])}
episode index:1396
target thresh 21.72645565741915
model initialize at round 1396
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.07848325, 14.84627329,  0.98513972,  0.07809795,
       -0.15297201]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3233068724105112
{'scaleFactor': 20, 'currentState': array([ 2.31422091e+01,  2.26294202e+01,  3.40647517e+01,  4.07274506e-03,
        9.65893024e-01, -2.58909403e-01]), 'targetState': array([25., 25., 15.])}
episode index:1397
target thresh 21.734282620498735
model initialize at round 1397
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12914655, 14.88705647,  0.98531363,  0.12853521,
       -0.11240889]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32307560855327905
{'scaleFactor': 20, 'currentState': array([  0.86694026,  27.32163249, -20.95241303,  -0.89198676,
         0.44072027,   0.10062439]), 'targetState': array([25., 25., 15.])}
episode index:1398
target thresh 21.742108800921145
model initialize at round 1398
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.49866900e+01,  1.50078114e+01,  9.99878516e-01,
       -1.34428607e-02,  7.88934514e-03]), 'targetState': array([25., 25., 15.])}
done in step count: 32
reward sum = 0.7249803359578534
running average episode reward sum: 0.3233628885585718
{'scaleFactor': 20, 'currentState': array([20.2852639 , 29.87004395, 17.36952825,  0.21248004, -0.85348405,
        0.47583318]), 'targetState': array([25., 25., 15.])}
episode index:1399
target thresh 21.74993419876463
model initialize at round 1399
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32313191506674427
{'scaleFactor': 20, 'currentState': array([-8.61991383e+00,  1.67511437e+01, -1.68439600e+01,  8.84655921e-02,
       -6.48639849e-03, -9.96058114e-01]), 'targetState': array([25., 25., 15.])}
episode index:1400
target thresh 21.757758814107476
model initialize at round 1400
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.50079921e+01,  1.48462733e+01,  9.88126423e-01,
        7.97701225e-03, -1.53435780e-01]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3229012713015289
{'scaleFactor': 20, 'currentState': array([ -1.14001626,  -0.95359593, -17.72999595,  -0.15707145,
        -0.98633665,   0.04968468]), 'targetState': array([25., 25., 15.])}
episode index:1401
target thresh 21.765582647027905
model initialize at round 1401
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10439605, 14.84627329,  0.98283644,  0.10364065,
       -0.15261435]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3226709565573766
{'scaleFactor': 20, 'currentState': array([  7.34795736,  30.32156139, -17.99221158,  -0.66419163,
         0.69566834,  -0.27366959]), 'targetState': array([25., 25., 15.])}
episode index:1402
target thresh 21.773405697604154
model initialize at round 1402
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10200478, 14.88915999,  0.98862159,  0.10186276,
       -0.11068568]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3224409701307498
{'scaleFactor': 20, 'currentState': array([ 0.38991139, 27.45639995, -4.78550138,  0.58183954, -0.31890636,
       -0.74817209]), 'targetState': array([25., 25., 15.])}
episode index:1403
target thresh 21.78122796591445
model initialize at round 1403
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.97037972,  0.98772627,  0.15337364,
       -0.02955225]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3228818812270961
{'scaleFactor': 20, 'currentState': array([26.0714211 , 21.28357947, 11.63849151,  0.36181188,  0.69773926,
       -0.61826539]), 'targetState': array([25., 25., 15.])}
episode index:1404
target thresh 21.789049452037034
model initialize at round 1404
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08805785, 14.84627329,  0.9843629 ,  0.08755645,
       -0.15285138]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32265207205896296
{'scaleFactor': 20, 'currentState': array([13.87568564, 21.38527473, 27.10017925, -0.92562718,  0.36577264,
        0.09708093]), 'targetState': array([25., 25., 15.])}
episode index:1405
target thresh 21.796870156050108
model initialize at round 1405
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.06487725, 14.84627329,  0.98609248,  0.06462118,
       -0.15311995]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32242258978865074
{'scaleFactor': 20, 'currentState': array([ 16.72964508,  20.97406139, -17.98019024,  -0.56381172,
         0.82560079,  -0.02235331]), 'targetState': array([25., 25., 15.])}
episode index:1406
target thresh 21.804690078031896
model initialize at round 1406
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14458944, 14.87027301,  0.98128794,  0.14331704,
       -0.12858539]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3221934337191492
{'scaleFactor': 20, 'currentState': array([53.02350724, 31.70761141, 10.59722927,  0.42648998,  0.71640245,
       -0.5521538 ]), 'targetState': array([25., 25., 15.])}
episode index:1407
target thresh 21.812509218060573
model initialize at round 1407
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.1129048 , 14.88205251,  0.98667111,  0.11252515,
       -0.11755089]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32196460315542824
{'scaleFactor': 20, 'currentState': array([ -3.26706503,  27.58220813, -24.14049206,  -0.93251243,
         0.10229155,  -0.3463481 ]), 'targetState': array([25., 25., 15.])}
episode index:1408
target thresh 21.82032757621435
model initialize at round 1408
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32173609740443077
{'scaleFactor': 20, 'currentState': array([ 59.11565857,  13.04781155, -19.77170918,  -0.14658266,
         0.90439775,   0.40072214]), 'targetState': array([25., 25., 15.])}
episode index:1409
target thresh 21.828145152571388
model initialize at round 1409
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14191121, 14.90202703,  0.98516608,  0.14121829,
       -0.09749459]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3221756321930808
{'scaleFactor': 20, 'currentState': array([25.60364742, 20.81742759, 10.04516969,  0.25233404,  0.6339263 ,
       -0.73107111]), 'targetState': array([25., 25., 15.])}
episode index:1410
target thresh 21.835961947209892
model initialize at round 1410
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3219473007740921
{'scaleFactor': 20, 'currentState': array([ 17.56333653,  19.41097058, -28.45081081,   0.39789008,
         0.76630225,  -0.50444459]), 'targetState': array([25., 25., 15.])}
episode index:1411
target thresh 21.843777960208
model initialize at round 1411
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.03416641, 14.8925079 ,  0.99357241,  0.0342897 ,
       -0.10787998]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32171929277071104
{'scaleFactor': 20, 'currentState': array([ -4.43648836,  24.41254004, -16.72771814,  -0.15784982,
        -0.062334  ,  -0.98549374]), 'targetState': array([25., 25., 15.])}
episode index:1412
target thresh 21.851593191643893
model initialize at round 1412
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86262745,  0.97899763,  0.15201826,
       -0.13584586]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3221579062573567
{'scaleFactor': 20, 'currentState': array([25.48526429, 21.3461279 , 10.07057692,  0.32147347,  0.70153656,
       -0.63600414]), 'targetState': array([25., 25., 15.])}
episode index:1413
target thresh 21.85940764159573
model initialize at round 1413
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.90095876,  0.98336448,  0.15269635,
       -0.09837741]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3225958993571754
{'scaleFactor': 20, 'currentState': array([25.64929881, 21.36097718, 10.64978931,  0.30081042,  0.73017981,
       -0.61347415]), 'targetState': array([25., 25., 15.])}
episode index:1414
target thresh 21.867221310141627
model initialize at round 1414
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12895778, 14.90200935,  0.98688033,  0.12855142,
       -0.09768186]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.3230266198155145
{'scaleFactor': 20, 'currentState': array([28.16845642, 20.99279428, 10.24304506,  0.41189172,  0.65835706,
       -0.63000888]), 'targetState': array([25., 25., 15.])}
episode index:1415
target thresh 21.875034197359746
model initialize at round 1415
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.06412468, 14.92295242,  0.99491292,  0.0644429 ,
       -0.07742993]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.32345673191162433
{'scaleFactor': 20, 'currentState': array([28.75312642, 20.28398075, 10.93334864,  0.47827046,  0.60573318,
       -0.63588104]), 'targetState': array([25., 25., 15.])}
episode index:1416
target thresh 21.882846303328197
model initialize at round 1416
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14264489, 14.85665855,  0.97976862,  0.1411707 ,
       -0.14186006]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32322846322290755
{'scaleFactor': 20, 'currentState': array([ -5.95224279,  13.89149078, -16.02034008,  -0.10455666,
        -0.12282326,  -0.98690544]), 'targetState': array([25., 25., 15.])}
episode index:1417
target thresh 21.89065762812511
model initialize at round 1417
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13041976, 14.84627329,  0.9798901 ,  0.12908791,
       -0.15215685]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32300051649284905
{'scaleFactor': 20, 'currentState': array([ -7.08320743,   5.92849411, -16.90719547,  -0.09132214,
        -0.08818571,  -0.99190904]), 'targetState': array([25., 25., 15.])}
episode index:1418
target thresh 21.89846817182861
model initialize at round 1418
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11749235, 14.84627329,  0.98143203,  0.11647551,
       -0.15239628]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32277289104077517
{'scaleFactor': 20, 'currentState': array([ -4.21937978,  -4.90549156, -30.19071747,  -0.13840533,
        -0.98962103,  -0.03865472]), 'targetState': array([25., 25., 15.])}
episode index:1419
target thresh 21.906277934516783
model initialize at round 1419
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32254558618792956
{'scaleFactor': 20, 'currentState': array([-4.99394423e+00,  1.64465896e+01, -4.51372732e+01,  3.53395645e-02,
        3.59486909e-01, -9.32480712e-01]), 'targetState': array([25., 25., 15.])}
episode index:1420
target thresh 21.91408691626774
model initialize at round 1420
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32231860125746653
{'scaleFactor': 20, 'currentState': array([ 66.94802016,  36.56187476, -19.39733204,   0.39814173,
        -0.19526516,   0.89630055]), 'targetState': array([25., 25., 15.])}
episode index:1421
target thresh 21.92189511715956
model initialize at round 1421
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.9281396 , 14.84627329,  0.98562573, -0.07154288,
       -0.15304747]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3220919355744444
{'scaleFactor': 20, 'currentState': array([ 19.91469647,  16.32508033, -19.38450811,  -0.34879322,
         0.74418674,  -0.5696748 ]), 'targetState': array([25., 25., 15.])}
episode index:1422
target thresh 21.929702537270323
model initialize at round 1422
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32186558846581864
{'scaleFactor': 20, 'currentState': array([ -5.15456942,  -2.28313648, -18.24773258,  -0.10163889,
         0.11523575,  -0.98812462]), 'targetState': array([25., 25., 15.])}
episode index:1423
target thresh 21.937509176678127
model initialize at round 1423
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.91039246,  0.98422896,  0.15283058,
       -0.08908519]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32163955926043536
{'scaleFactor': 20, 'currentState': array([-20.06905865,  17.05271547, -25.33733817,  -0.44269355,
        -0.86639894,   0.23103093]), 'targetState': array([25., 25., 15.])}
episode index:1424
target thresh 21.94531503546101
model initialize at round 1424
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84876548,  0.97708819,  0.15172177,
       -0.14926208]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3220745351131656
{'scaleFactor': 20, 'currentState': array([26.07691864, 20.93785507, 10.47814113,  0.43901778,  0.59794729,
       -0.67061347]), 'targetState': array([25., 25., 15.])}
episode index:1425
target thresh 21.953120113697054
model initialize at round 1425
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12932802, 14.84627329,  0.98002624,  0.1280251 ,
       -0.15217799]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3218486763928899
{'scaleFactor': 20, 'currentState': array([  0.8285047 ,  15.06732542, -30.17891604,   0.36738423,
         0.16711949,  -0.91493164]), 'targetState': array([25., 25., 15.])}
episode index:1426
target thresh 21.96092441146429
model initialize at round 1426
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.04695223, 14.85418948,  0.98823992,  0.04686876,
       -0.14555129]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.321623134223028
{'scaleFactor': 20, 'currentState': array([ -8.7783407 ,  24.87131175, -32.15673266,  -0.74952767,
        -0.47583991,  -0.46020067]), 'targetState': array([25., 25., 15.])}
episode index:1427
target thresh 21.96872792884077
model initialize at round 1427
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13608572, 14.9184494 ,  0.9874017 ,  0.13572856,
       -0.08133656]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3220572077630686
{'scaleFactor': 20, 'currentState': array([26.51560864, 21.66574309, 13.54798035,  0.47921403,  0.86958097,
       -0.11909177]), 'targetState': array([25., 25., 15.])}
episode index:1428
target thresh 21.976530665904537
model initialize at round 1428
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.91871806,  0.98492171,  0.15293815,
       -0.080865  ]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3224973287162785
{'scaleFactor': 20, 'currentState': array([25.19064126, 20.11678938, 12.89859804,  0.56823497,  0.78241353,
       -0.25482952]), 'targetState': array([25., 25., 15.])}
episode index:1429
target thresh 21.984332622733593
model initialize at round 1429
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.97816895,  0.98792335,  0.15340425,
       -0.02178525]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.32293018383563843
{'scaleFactor': 20, 'currentState': array([26.23319597, 20.66080473, 10.91043063,  0.42059404,  0.56300314,
       -0.71142682]), 'targetState': array([25., 25., 15.])}
episode index:1430
target thresh 21.992133799405988
model initialize at round 1430
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10749907, 14.84627329,  0.98251814,  0.10668665,
       -0.15256493]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3227045163416932
{'scaleFactor': 20, 'currentState': array([  6.80921729,   5.1714491 , -29.69333378,  -0.7945342 ,
         0.08506372,  -0.60123171]), 'targetState': array([25., 25., 15.])}
episode index:1431
target thresh 21.999934195999714
model initialize at round 1431
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32247916402581217
{'scaleFactor': 20, 'currentState': array([ 8.66281446e+00,  9.18225820e+00, -7.01726725e+00, -3.31929155e-01,
        3.45685285e-03, -9.43297984e-01]), 'targetState': array([25., 25., 15.])}
episode index:1432
target thresh 22.00773381259279
model initialize at round 1432
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85171449,  0.97750881,  0.15178708,
       -0.14641454]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3222541262281668
{'scaleFactor': 20, 'currentState': array([ 11.01198637,  19.10405963, -39.68211521,   0.63289297,
         0.38009016,  -0.67452054]), 'targetState': array([25., 25., 15.])}
episode index:1433
target thresh 22.015532649263204
model initialize at round 1433
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10882815, 14.88253461,  0.98717005,  0.10851706,
       -0.11712961]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3220294022907692
{'scaleFactor': 20, 'currentState': array([ -4.36052036,  65.52689675, -19.83733652,  -0.61844334,
        -0.69810525,   0.36080035]), 'targetState': array([25., 25., 15.])}
episode index:1434
target thresh 22.023330706088927
model initialize at round 1434
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.51537267e+01,  1.49997508e+01,  9.88157833e-01,
        1.53440657e-01, -2.48691938e-04]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3224610752852711
{'scaleFactor': 20, 'currentState': array([26.6036797 , 20.82644299, 11.97650431,  0.45552192,  0.65170182,
       -0.6064524 ]), 'targetState': array([25., 25., 15.])}
episode index:1435
target thresh 22.03112798314798
model initialize at round 1435
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14190943, 14.84627329,  0.97839167,  0.14024546,
       -0.15192417]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32223652021891647
{'scaleFactor': 20, 'currentState': array([  3.15433807,   5.71039804, -39.30302681,  -0.57498737,
        -0.41675086,  -0.70406552]), 'targetState': array([25., 25., 15.])}
episode index:1436
target thresh 22.038924480518297
model initialize at round 1436
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3220122776857091
{'scaleFactor': 20, 'currentState': array([ -0.24574028,   6.56177135, -41.46131104,   0.10771702,
        -0.49917112,  -0.85978209]), 'targetState': array([25., 25., 15.])}
episode index:1437
target thresh 22.046720198277857
model initialize at round 1437
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3217883470336328
{'scaleFactor': 20, 'currentState': array([  8.09800243,  -0.1326749 , -33.5478066 ,  -0.68672022,
         0.26012394,  -0.67878633]), 'targetState': array([25., 25., 15.])}
episode index:1438
target thresh 22.054515136504627
model initialize at round 1438
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32156472761248367
{'scaleFactor': 20, 'currentState': array([ -8.3694406 ,  16.03170705, -45.6766539 ,   0.33302526,
         0.23851524,  -0.91225252]), 'targetState': array([25., 25., 15.])}
episode index:1439
target thresh 22.06230929527654
model initialize at round 1439
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84851172,  0.97705164,  0.15171609,
       -0.14950694]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3213414187738639
{'scaleFactor': 20, 'currentState': array([ -2.7244396 ,  24.23226936, -39.25725683,  -0.88438471,
         0.17576322,  -0.4324014 ]), 'targetState': array([25., 25., 15.])}
episode index:1440
target thresh 22.070102674671553
model initialize at round 1440
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32111841987117556
{'scaleFactor': 20, 'currentState': array([  4.05125026,   9.79415577, -34.58120024,  -0.07158031,
         0.32155562,  -0.94418125]), 'targetState': array([25., 25., 15.])}
episode index:1441
target thresh 22.077895274767577
model initialize at round 1441
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12956892, 14.84627329,  0.97999629,  0.12825966,
       -0.15217334]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3208957302596144
{'scaleFactor': 20, 'currentState': array([ 18.08326081,  37.22377476, -14.82364718,   0.05654598,
        -0.50011164,   0.86411278]), 'targetState': array([25., 25., 15.])}
episode index:1442
target thresh 22.08568709564257
model initialize at round 1442
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.0721882 , 14.92788063,  0.99473008,  0.0725331 ,
       -0.07246394]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3206733492961635
{'scaleFactor': 20, 'currentState': array([ 12.15840106,  25.28459771, -20.54371738,  -0.29217765,
         0.45337936,  -0.84206851]), 'targetState': array([25., 25., 15.])}
episode index:1443
target thresh 22.093478137374433
model initialize at round 1443
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3204512763395872
{'scaleFactor': 20, 'currentState': array([-16.44801906,   3.1281668 , -30.2237289 ,  -0.430092  ,
        -0.89249076,   0.13594528]), 'targetState': array([25., 25., 15.])}
episode index:1444
target thresh 22.101268400041064
model initialize at round 1444
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15322125, 14.9096118 ,  0.98423608,  0.15232917,
       -0.08986194]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3208810541064117
{'scaleFactor': 20, 'currentState': array([26.27667038, 20.96234648, 10.73152632,  0.58516192,  0.64019241,
       -0.49773407]), 'targetState': array([25., 25., 15.])}
episode index:1445
target thresh 22.109057883720375
model initialize at round 1445
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.49935520e+01,  1.48948032e+01,  9.94380980e-01,
       -6.47652434e-03, -1.05662302e-01]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32065914466373785
{'scaleFactor': 20, 'currentState': array([  1.2485991 ,  34.04424891, -29.14889873,  -0.28593153,
        -0.68408829,  -0.67101891]), 'targetState': array([25., 25., 15.])}
episode index:1446
target thresh 22.11684658849028
model initialize at round 1446
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09366639, 14.84627329,  0.98386734,  0.09308616,
       -0.15277443]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3204375419376399
{'scaleFactor': 20, 'currentState': array([-15.02982824,  17.41729474, -37.86380941,  -0.80475004,
        -0.5858428 ,  -0.09573709]), 'targetState': array([25., 25., 15.])}
episode index:1447
target thresh 22.124634514428642
model initialize at round 1447
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.8926377 ,  0.98253236,  0.15256714,
       -0.10655246]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3208664387659986
{'scaleFactor': 20, 'currentState': array([25.40763745, 21.37656347, 10.08829855,  0.31906065,  0.78053555,
       -0.53755424]), 'targetState': array([25., 25., 15.])}
episode index:1448
target thresh 22.132421661613357
model initialize at round 1448
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14558711, 15.03976618,  0.98857897,  0.14537814,
        0.0397091 ]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3206449988496659
{'scaleFactor': 20, 'currentState': array([ 1.53014554e+01,  3.44355340e+01,  6.56581446e+00,  6.65401100e-03,
       -8.52005250e-01, -5.23490954e-01]), 'targetState': array([25., 25., 15.])}
episode index:1449
target thresh 22.140208030122277
model initialize at round 1449
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08073652, 14.9055756 ,  0.99221793,  0.08091739,
       -0.09463595]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32042386436770065
{'scaleFactor': 20, 'currentState': array([ 25.0260796 ,   2.279671  , -27.83575445,   0.64973848,
         0.66174073,  -0.37408437]), 'targetState': array([25., 25., 15.])}
episode index:1450
target thresh 22.14799362003328
model initialize at round 1450
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.95596597,  0.98720479,  0.15329267,
       -0.0439097 ]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.32085843789322255
{'scaleFactor': 20, 'currentState': array([25.17756565, 20.04101382, 13.01206224,  0.53845638,  0.75317499,
       -0.37787851]), 'targetState': array([25., 25., 15.])}
episode index:1451
target thresh 22.155778431424224
model initialize at round 1451
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.96584806,  0.98758423,  0.15335159,
       -0.0340686 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.32128586331437115
{'scaleFactor': 20, 'currentState': array([25.90579276, 21.55071037, 11.40859169,  0.3656096 ,  0.79619502,
       -0.48208206]), 'targetState': array([25., 25., 15.])}
episode index:1452
target thresh 22.163562464372944
model initialize at round 1452
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.92465984,  0.98537562,  0.15300864,
       -0.07498824]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32106474434443694
{'scaleFactor': 20, 'currentState': array([ -9.93329795,  15.6052094 , -38.1523689 ,  -0.65146125,
        -0.61711359,  -0.44132647]), 'targetState': array([25., 25., 15.])}
episode index:1453
target thresh 22.1713457189573
model initialize at round 1453
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12626749, 14.84627329,  0.98040209,  0.12504334,
       -0.15223635]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32084392952714363
{'scaleFactor': 20, 'currentState': array([15.03474559, 33.21768825, 25.99272688,  0.29964651, -0.94971785,
        0.09081836]), 'targetState': array([25., 25., 15.])}
episode index:1454
target thresh 22.179128195255103
model initialize at round 1454
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.02339363,  0.98788859,  0.15339885,
        0.02334374]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3212704836301497
{'scaleFactor': 20, 'currentState': array([26.8520887 , 21.07819154, 16.55489057,  0.5065926 ,  0.76599074,
        0.39575513]), 'targetState': array([25., 25., 15.])}
episode index:1455
target thresh 22.186909893344186
model initialize at round 1455
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.02129703,  0.98793468,  0.15340601,
        0.0212526 ]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3217029833322581
{'scaleFactor': 20, 'currentState': array([25.37657419, 20.14033564, 14.53736004,  0.57766227,  0.75965595,
       -0.29871245]), 'targetState': array([25., 25., 15.])}
episode index:1456
target thresh 22.194690813302365
model initialize at round 1456
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32148218512818655
{'scaleFactor': 20, 'currentState': array([ -6.70847173,  22.31353587, -47.17722428,  -0.45342682,
        -0.50894721,  -0.7316945 ]), 'targetState': array([25., 25., 15.])}
episode index:1457
target thresh 22.202470955207453
model initialize at round 1457
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32126168980230985
{'scaleFactor': 20, 'currentState': array([ 5.10736511e+01,  1.99036353e+01,  7.27054731e+00,  3.78770811e-02,
       -1.59237274e-01,  9.86513465e-01]), 'targetState': array([25., 25., 15.])}
episode index:1458
target thresh 22.21025031913726
model initialize at round 1458
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32104149673184906
{'scaleFactor': 20, 'currentState': array([-10.97764007, -17.95526043, -25.93298478,   0.26844929,
        -0.53638426,  -0.8001418 ]), 'targetState': array([25., 25., 15.])}
episode index:1459
target thresh 22.21802890516956
model initialize at round 1459
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32082160529573134
{'scaleFactor': 20, 'currentState': array([  8.58850095,  39.43112718, -45.8822706 ,   0.18589964,
         0.94161672,  -0.28071208]), 'targetState': array([25., 25., 15.])}
episode index:1460
target thresh 22.225806713382145
model initialize at round 1460
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.04504634, 15.01891758,  0.99878446,  0.04544604,
        0.01908544]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3206020148745844
{'scaleFactor': 20, 'currentState': array([ 2.36545952e+01,  2.22119318e+01, -2.41831601e+01,  6.74777052e-01,
       -7.37948472e-01,  1.03914547e-02]), 'targetState': array([25., 25., 15.])}
episode index:1461
target thresh 22.233583743852815
model initialize at round 1461
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.0955111 , 14.84627329,  0.98369783,  0.09490309,
       -0.15274811]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3203827248507303
{'scaleFactor': 20, 'currentState': array([ 21.57402919,  28.82267453, -39.39510531,   0.77842768,
         0.54521273,  -0.31111641]), 'targetState': array([25., 25., 15.])}
episode index:1462
target thresh 22.241359996659295
model initialize at round 1462
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09376585, 14.84627329,  0.98385828,  0.09318415,
       -0.15277302]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32016373460818026
{'scaleFactor': 20, 'currentState': array([ 20.56280585,  37.10251396, -35.39149411,  -0.26194171,
         0.95751695,   0.12061438]), 'targetState': array([25., 25., 15.])}
episode index:1463
target thresh 22.249135471879388
model initialize at round 1463
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15013366, 15.04064754,  0.98788211,  0.14981248,
        0.04056058]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.32059462690004625
{'scaleFactor': 20, 'currentState': array([ 2.54393597e+01,  2.00869187e+01,  1.56771002e+01,  6.12237165e-01,
        7.90391198e-01, -2.11520304e-02]), 'targetState': array([25., 25., 15.])}
episode index:1464
target thresh 22.25691016959084
model initialize at round 1464
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.90142919,  0.98340959,  0.15270335,
       -0.09791463]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3210184395433916
{'scaleFactor': 20, 'currentState': array([25.76413639, 20.91383299, 10.10212143,  0.35419574,  0.6762542 ,
       -0.64593005]), 'targetState': array([25., 25., 15.])}
episode index:1465
target thresh 22.264684089871388
model initialize at round 1465
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13713842, 14.97741672,  0.99028874,  0.13717842,
       -0.02258986]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3207994638001833
{'scaleFactor': 20, 'currentState': array([ -4.15462321,  17.94225366, -28.37074049,  -0.22567449,
        -0.97132014,  -0.07488798]), 'targetState': array([25., 25., 15.])}
episode index:1466
target thresh 22.272457232798782
model initialize at round 1466
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.8773453 ,  0.98083471,  0.15230353,
       -0.12151918]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32058078659241224
{'scaleFactor': 20, 'currentState': array([ 34.91683939,  29.29414967, -17.7235538 ,  -0.06381171,
         0.96357203,   0.25972488]), 'targetState': array([25., 25., 15.])}
episode index:1467
target thresh 22.28022959845074
model initialize at round 1467
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3203624073099923
{'scaleFactor': 20, 'currentState': array([ 25.17870504,  39.28748933, -38.17010064,   0.61141929,
         0.7023257 ,  -0.36456146]), 'targetState': array([25., 25., 15.])}
episode index:1468
target thresh 22.288001186904992
model initialize at round 1468
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12942957, 14.86996723,  0.98325804,  0.12854815,
       -0.12914724]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32014432534449877
{'scaleFactor': 20, 'currentState': array([ 6.34965733e+00,  4.54655299e+01, -3.86368237e+01, -9.78339799e-01,
        1.15067177e-02, -2.06685349e-01]), 'targetState': array([25., 25., 15.])}
episode index:1469
target thresh 22.295771998239267
model initialize at round 1469
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.8783629 ,  0.9809544 ,  0.15232211,
       -0.1205257 ]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3199265400891624
{'scaleFactor': 20, 'currentState': array([ 29.80897903,  53.3856895 , -31.47165336,  -0.11423831,
         0.99139243,  -0.06395819]), 'targetState': array([25., 25., 15.])}
episode index:1470
target thresh 22.303542032531254
model initialize at round 1470
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3197090509388638
{'scaleFactor': 20, 'currentState': array([ -8.30762894,  41.60306904, -44.85426914,  -0.71817546,
        -0.3535458 ,  -0.59935747]), 'targetState': array([25., 25., 15.])}
episode index:1471
target thresh 22.311311289858658
model initialize at round 1471
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.04591187, 15.07194429,  0.9963047 ,  0.04620425,
        0.07240246]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31949185729012813
{'scaleFactor': 20, 'currentState': array([ 34.48093313,  37.31702048, -11.09977595,   0.37590834,
         0.86700276,   0.32710722]), 'targetState': array([25., 25., 15.])}
episode index:1472
target thresh 22.319079770299176
model initialize at round 1472
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10308458, 14.89305734,  0.98893097,  0.10297326,
       -0.10682718]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3192749585411192
{'scaleFactor': 20, 'currentState': array([23.06721066, 46.91553839, -9.69361951,  0.15762108,  0.82909601,
       -0.53642837]), 'targetState': array([25., 25., 15.])}
episode index:1473
target thresh 22.32684747393049
model initialize at round 1473
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87035389,  0.97998669,  0.15217185,
       -0.12833481]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3190583540916341
{'scaleFactor': 20, 'currentState': array([  8.18510436,  57.6977453 , -33.85218464,  -0.28327649,
        -0.50184072,  -0.81725781]), 'targetState': array([25., 25., 15.])}
episode index:1474
target thresh 22.334614400830276
model initialize at round 1474
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3188420433430974
{'scaleFactor': 20, 'currentState': array([ 35.84711903,  52.20577293, -15.57569542,   0.89214441,
         0.43410096,  -0.12503883]), 'targetState': array([25., 25., 15.])}
episode index:1475
target thresh 22.342380551076214
model initialize at round 1475
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14779579, 14.84627329,  0.9775779 ,  0.14594132,
       -0.15179781]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31862602569855597
{'scaleFactor': 20, 'currentState': array([ 24.75264605,  58.36601935, -48.93986585,  -0.36934841,
         0.91111646,  -0.18288944]), 'targetState': array([25., 25., 15.])}
episode index:1476
target thresh 22.350145924745945
model initialize at round 1476
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3184103005626734
{'scaleFactor': 20, 'currentState': array([ 3.44057596e+01,  4.31219772e+01, -3.70558122e+01,  8.34450731e-01,
        5.51010227e-01, -8.92792748e-03]), 'targetState': array([25., 25., 15.])}
episode index:1477
target thresh 22.357910521917145
model initialize at round 1477
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.05048868, 14.84627329,  0.98690547,  0.05033087,
       -0.15324619]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31819486734172436
{'scaleFactor': 20, 'currentState': array([-1.20771893e+00,  4.46260679e+01, -2.77423284e+01,  1.49388037e-01,
        3.15374686e-02, -9.88275570e-01]), 'targetState': array([25., 25., 15.])}
episode index:1478
target thresh 22.36567434266744
model initialize at round 1478
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3179797254435893
{'scaleFactor': 20, 'currentState': array([ 33.48002088,  31.80469495, -34.5798046 ,   0.51493773,
         0.82925195,   0.21721033]), 'targetState': array([25., 25., 15.])}
episode index:1479
target thresh 22.37343738707449
model initialize at round 1479
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87374224,  0.98040327,  0.15223653,
       -0.12503386]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3184010095138308
{'scaleFactor': 20, 'currentState': array([25.48352555, 21.5397022 , 10.38480205,  0.38303611,  0.87574965,
       -0.29384671]), 'targetState': array([25., 25., 15.])}
episode index:1480
target thresh 22.3811996552159
model initialize at round 1480
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.9668312 ,  0.98761676,  0.15335664,
       -0.03308895]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.318821724665679
{'scaleFactor': 20, 'currentState': array([27.10875374, 20.97675052, 13.72217271,  0.61166595,  0.78051013,
        0.12910734]), 'targetState': array([25., 25., 15.])}
episode index:1481
target thresh 22.38896114716933
model initialize at round 1481
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08868659, 15.08866289,  0.99207241,  0.08887224,
        0.08884849]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3186065952968088
{'scaleFactor': 20, 'currentState': array([  6.76837356,  28.21664082, -12.71840758,  -0.08423204,
         0.0564673 ,  -0.99484492]), 'targetState': array([25., 25., 15.])}
episode index:1482
target thresh 22.39672186301235
model initialize at round 1482
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.04264016, 14.84627329,  0.98726409,  0.04252232,
       -0.15330188]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3183917560552061
{'scaleFactor': 20, 'currentState': array([ 4.54739981e+01,  7.41875907e+01,  1.26295456e+01, -8.96921775e-01,
       -2.63234643e-02, -4.41405035e-01]), 'targetState': array([25., 25., 15.])}
episode index:1483
target thresh 22.404481802822584
model initialize at round 1483
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89990682,  0.98326288,  0.15268057,
       -0.09941203]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.31881162694021
{'scaleFactor': 20, 'currentState': array([25.50794321, 21.514817  , 10.41031346,  0.39325704,  0.88076279,
       -0.26382915]), 'targetState': array([25., 25., 15.])}
episode index:1484
target thresh 22.412240966677643
model initialize at round 1484
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.95506131,  0.98716529,  0.15328654,
       -0.04481001]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3192373363159405
{'scaleFactor': 20, 'currentState': array([25.22636586, 20.04950117, 13.1048941 ,  0.58042993,  0.75063287,
       -0.31567609]), 'targetState': array([25., 25., 15.])}
episode index:1485
target thresh 22.419999354655108
model initialize at round 1485
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13402754, 14.90934621,  0.98690523,  0.13360857,
       -0.09037041]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.31965607306768007
{'scaleFactor': 20, 'currentState': array([26.64168923, 20.68401242, 11.11090293,  0.58438305,  0.7477007 ,
       -0.31534125]), 'targetState': array([25., 25., 15.])}
episode index:1486
target thresh 22.42775696683257
model initialize at round 1486
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.32007424662271255
{'scaleFactor': 20, 'currentState': array([25.711481  , 21.2339259 , 10.17769395,  0.44186887,  0.84803757,
       -0.29254774]), 'targetState': array([25., 25., 15.])}
episode index:1487
target thresh 22.4355138032876
model initialize at round 1487
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.90987164,  0.98418343,  0.15282351,
       -0.08959883]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.31985914296234785
{'scaleFactor': 20, 'currentState': array([ 19.96831942,  52.18888845, -41.13143978,   0.36908883,
         0.62579738,  -0.6871325 ]), 'targetState': array([25., 25., 15.])}
episode index:1488
target thresh 22.443269864097772
model initialize at round 1488
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.05752974, 14.84627329,  0.98653272,  0.05732825,
       -0.15318831]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.32027029555129655
{'scaleFactor': 20, 'currentState': array([28.93149703, 20.6893138 , 11.15874739,  0.72485503,  0.68074474,
       -0.1056967 ]), 'targetState': array([25., 25., 15.])}
episode index:1489
target thresh 22.45102514934063
model initialize at round 1489
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.50589816e+01, 1.50066791e+01, 9.98207340e-01,
       5.94706042e-02, 6.73448508e-03]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.32068721491629637
{'scaleFactor': 20, 'currentState': array([27.01224926, 20.79641793, 13.74901006,  0.54313179,  0.82542282,
       -0.15389939]), 'targetState': array([25., 25., 15.])}
episode index:1490
target thresh 22.458779659093754
model initialize at round 1490
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.97252757,  0.98778656,  0.15338301,
       -0.02741101]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.32110995323620495
{'scaleFactor': 20, 'currentState': array([25.35078228, 20.15674206, 13.9235842 ,  0.58857347,  0.78840907,
       -0.17886419]), 'targetState': array([25., 25., 15.])}
episode index:1491
target thresh 22.466533393434663
model initialize at round 1491
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.151189  , 14.8541109 ,  0.97821419,  0.14938912,
       -0.14415231]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.32152575095481406
{'scaleFactor': 20, 'currentState': array([25.88457678, 21.22068865, 10.50766154,  0.46997921,  0.843925  ,
       -0.25866994]), 'targetState': array([25., 25., 15.])}
episode index:1492
target thresh 22.47428635244091
model initialize at round 1492
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86363178,  0.97912925,  0.1520387 ,
       -0.13487082]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.32194099167714907
{'scaleFactor': 20, 'currentState': array([25.79573926, 21.51689851, 10.76524789,  0.42952431,  0.87059867,
       -0.23993085]), 'targetState': array([25., 25., 15.])}
episode index:1493
target thresh 22.482038536190018
model initialize at round 1493
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15221319, 14.88858748,  0.98232772,  0.15103357,
       -0.1105491 ]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.3223493747803819
{'scaleFactor': 20, 'currentState': array([28.89478742, 20.60412322, 10.40961486,  0.78395814,  0.59283578,
       -0.18426982]), 'targetState': array([25., 25., 15.])}
episode index:1494
target thresh 22.48978994475952
model initialize at round 1494
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.02235709, 14.87589972,  0.9919856 ,  0.02240193,
       -0.12434918]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.322133756469492
{'scaleFactor': 20, 'currentState': array([  8.54538682,  36.37494927, -10.07186423,   0.08547834,
        -0.03899063,  -0.99557681]), 'targetState': array([25., 25., 15.])}
episode index:1495
target thresh 22.497540578226904
model initialize at round 1495
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.05738677, 14.84627329,  0.98654077,  0.05718625,
       -0.15318956]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32191842641837604
{'scaleFactor': 20, 'currentState': array([ 24.22780543,  38.71581548, -38.59200594,   0.93232249,
         0.07192552,  -0.35440302]), 'targetState': array([25., 25., 15.])}
episode index:1496
target thresh 22.5052904366697
model initialize at round 1496
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10453582, 14.9069111 ,  0.99015186,  0.10455186,
       -0.09310317]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.32233229530480395
{'scaleFactor': 20, 'currentState': array([26.8263333 , 20.84944801, 12.278208  ,  0.64511102,  0.74576288,
       -0.16634151]), 'targetState': array([25., 25., 15.])}
episode index:1497
target thresh 22.5130395201654
model initialize at round 1497
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.04887526, 14.84627329,  0.98698409,  0.04872637,
       -0.1532584 ]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32211712020780475
{'scaleFactor': 20, 'currentState': array([ 49.24734492,  32.76197102, -10.87931573,   0.5674571 ,
         0.08046982,   0.81946144]), 'targetState': array([25., 25., 15.])}
episode index:1498
target thresh 22.520787828791498
model initialize at round 1498
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.03216045, 14.95385746,  0.99839007,  0.032433  ,
       -0.04653359]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3219022322023292
{'scaleFactor': 20, 'currentState': array([40.2477191 , 17.51186748,  5.16466987,  0.93180408,  0.11829092,
        0.34314489]), 'targetState': array([25., 25., 15.])}
episode index:1499
target thresh 22.52853536262547
model initialize at round 1499
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87385832,  0.98041736,  0.15223872,
       -0.1249207 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.32231528414712834
{'scaleFactor': 20, 'currentState': array([25.72173357, 21.67567435, 10.98133519,  0.4080965 ,  0.87596612,
       -0.25717813]), 'targetState': array([25., 25., 15.])}
episode index:1500
target thresh 22.5362821217448
model initialize at round 1500
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32210055044683045
{'scaleFactor': 20, 'currentState': array([  5.959194  ,  46.28843876, -55.42468305,  -0.48901396,
        -0.2448822 ,  -0.83719655]), 'targetState': array([25., 25., 15.])}
episode index:1501
target thresh 22.544028106226943
model initialize at round 1501
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3225129203529251
{'scaleFactor': 20, 'currentState': array([25.31189981, 21.58633464, 10.10497904,  0.38277785,  0.88984099,
       -0.24832262]), 'targetState': array([25., 25., 15.])}
episode index:1502
target thresh 22.551773316149358
model initialize at round 1502
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85439985,  0.97788507,  0.15184551,
       -0.1438184 ]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3222983408982658
{'scaleFactor': 20, 'currentState': array([ 23.98130811,  53.69922961, -50.3960526 ,  -0.31421713,
         0.68289586,  -0.65948528]), 'targetState': array([25., 25., 15.])}
episode index:1503
target thresh 22.55951775158953
model initialize at round 1503
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.322084046788626
{'scaleFactor': 20, 'currentState': array([  3.64751236,  19.4768535 , -41.3548006 ,  -0.10294632,
        -0.06604231,  -0.99249205]), 'targetState': array([25., 25., 15.])}
episode index:1504
target thresh 22.567261412624873
model initialize at round 1504
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.0511745 , 14.84627329,  0.98687128,  0.05101277,
       -0.15324088]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32187003745521164
{'scaleFactor': 20, 'currentState': array([ 24.9257844 ,  36.31752342, -34.46880281,   0.85205766,
         0.20493146,  -0.48166466]), 'targetState': array([25., 25., 15.])}
episode index:1505
target thresh 22.57500429933281
model initialize at round 1505
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.03839995, 14.89277067,  0.99344694,  0.03853365,
       -0.10760267]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3216563123307394
{'scaleFactor': 20, 'currentState': array([ 11.38012434,  38.20263992, -30.00515169,   0.07585272,
        -0.09993733,  -0.99209823]), 'targetState': array([25., 25., 15.])}
episode index:1506
target thresh 22.58274641179081
model initialize at round 1506
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.07611591, 14.86561797,  0.98804946,  0.07596594,
       -0.13411727]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.32206760883841706
{'scaleFactor': 20, 'currentState': array([2.70732984e+01, 2.00431997e+01, 1.16452096e+01, 6.39927206e-01,
       7.68318743e-01, 1.33970067e-02]), 'targetState': array([25., 25., 15.])}
episode index:1507
target thresh 22.59048775007626
model initialize at round 1507
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.97637266,  0.98788318,  0.15339801,
       -0.02357682]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.32248466616007593
{'scaleFactor': 20, 'currentState': array([25.14865844, 20.07288031, 12.83366902,  0.56213596,  0.78161856,
       -0.27032497]), 'targetState': array([25., 25., 15.])}
episode index:1508
target thresh 22.59822831426659
model initialize at round 1508
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.32289486860092476
{'scaleFactor': 20, 'currentState': array([25.35659133, 21.51174013, 10.01620756,  0.42630117,  0.86428028,
       -0.26699608]), 'targetState': array([25., 25., 15.])}
episode index:1509
target thresh 22.60596810443921
model initialize at round 1509
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11836253, 14.84627329,  0.98133307,  0.11732632,
       -0.15238091]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3233045277272824
{'scaleFactor': 20, 'currentState': array([26.88398956, 20.19416854, 10.74845267,  0.66618084,  0.70335858,
       -0.24797134]), 'targetState': array([25., 25., 15.])}
episode index:1510
target thresh 22.6137071206715
model initialize at round 1510
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3237136446178673
{'scaleFactor': 20, 'currentState': array([25.51854133, 21.63923676, 10.46509358,  0.39236795,  0.87754156,
       -0.2756233 ]), 'targetState': array([25., 25., 15.])}
episode index:1511
target thresh 22.62144536304087
model initialize at round 1511
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.32412222034854393
{'scaleFactor': 20, 'currentState': array([26.06121751, 21.4352322 , 11.18342657,  0.51889062,  0.84281546,
       -0.14287974]), 'targetState': array([25., 25., 15.])}
episode index:1512
target thresh 22.629182831624696
model initialize at round 1512
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.32453025599233276
{'scaleFactor': 20, 'currentState': array([2.61124569e+01, 2.16537007e+01, 1.17483952e+01, 5.16434777e-01,
       8.56303153e-01, 6.32702402e-03]), 'targetState': array([25., 25., 15.])}
episode index:1513
target thresh 22.636919526500343
model initialize at round 1513
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12148771, 14.89659582,  0.9872633 ,  0.12115188,
       -0.10311834]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.32493775261941904
{'scaleFactor': 20, 'currentState': array([26.96193361, 20.96457405, 13.58476298,  0.55898765,  0.81359741,
        0.15997521]), 'targetState': array([25., 25., 15.])}
episode index:1514
target thresh 22.644655447745176
model initialize at round 1514
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.121076  , 15.01862594,  0.9924313 ,  0.12137335,
        0.01867168]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3253447112971627
{'scaleFactor': 20, 'currentState': array([27.4670888 , 20.49152772, 15.2093932 ,  0.6921387 ,  0.72048146,
        0.04301732]), 'targetState': array([25., 25., 15.])}
episode index:1515
target thresh 22.65239059543658
model initialize at round 1515
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.07893516, 14.96347773,  0.99616308,  0.07942656,
       -0.03674964]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.32574492279888423
{'scaleFactor': 20, 'currentState': array([2.89501548e+01, 2.11645283e+01, 1.20655304e+01, 7.59116358e-01,
       6.50804876e-01, 1.39774525e-02]), 'targetState': array([25., 25., 15.])}
episode index:1516
target thresh 22.660124969651875
model initialize at round 1516
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.97399244, 14.92569353,  0.99685307, -0.0261876 ,
       -0.07482084]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32553019312004516
{'scaleFactor': 20, 'currentState': array([ 1.83819089e+01,  2.35572707e+01,  6.83121584e-02, -2.28079533e-02,
        3.57651545e-02, -9.99099920e-01]), 'targetState': array([25., 25., 15.])}
episode index:1517
target thresh 22.667858570468425
model initialize at round 1517
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.02224122, 14.84627329,  0.98791446,  0.02219437,
       -0.15340287]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.32531574635250887
{'scaleFactor': 20, 'currentState': array([ 27.28453546,  51.92745915, -10.75018808,   0.11265541,
         0.22579446,  -0.9676392 ]), 'targetState': array([25., 25., 15.])}
episode index:1518
target thresh 22.675591397963558
model initialize at round 1518
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89701741,  0.98297844,  0.1526364 ,
       -0.10225219]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.32572764516985414
{'scaleFactor': 20, 'currentState': array([25.12085778, 20.13633204, 12.70411412,  0.58544246,  0.8060231 ,
       -0.08708551]), 'targetState': array([25., 25., 15.])}
episode index:1519
target thresh 22.68332345221461
model initialize at round 1519
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.92976342,  0.98573846,  0.15306498,
       -0.06993424]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.32613900201507134
{'scaleFactor': 20, 'currentState': array([25.14525987, 20.12160218, 12.77796035,  0.58276214,  0.8021824 ,
       -0.12996806]), 'targetState': array([25., 25., 15.])}
episode index:1520
target thresh 22.691054733298888
model initialize at round 1520
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.326549817957139
{'scaleFactor': 20, 'currentState': array([24.92166039, 20.12388006, 12.0288347 ,  0.57268513,  0.81051709,
       -0.12285677]), 'targetState': array([25., 25., 15.])}
episode index:1521
target thresh 22.698785241293706
model initialize at round 1521
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12910216, 14.8995465 ,  0.98662252,  0.12866172,
       -0.10011079]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3263352648572986
{'scaleFactor': 20, 'currentState': array([ 26.19709614,  57.49264408, -12.92454078,  -0.41562422,
        -0.11379662,  -0.90238952]), 'targetState': array([25., 25., 15.])}
episode index:1522
target thresh 22.70651497627639
model initialize at round 1522
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86760292,  0.97964076,  0.15211813,
       -0.13101169]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3267391682614639
{'scaleFactor': 20, 'currentState': array([26.42788296, 21.42425518, 12.32918594,  0.57557524,  0.81042745,
        0.10918101]), 'targetState': array([25., 25., 15.])}
episode index:1523
target thresh 22.71424393832422
model initialize at round 1523
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.03747602, 14.90639367,  0.99485349,  0.03765975,
       -0.09406524]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.32713636391739925
{'scaleFactor': 20, 'currentState': array([28.38423697, 21.18367715, 11.58745463,  0.5114653 ,  0.85879079,
       -0.02969232]), 'targetState': array([25., 25., 15.])}
episode index:1524
target thresh 22.72197212751449
model initialize at round 1524
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87801462,  0.98091354,  0.15231577,
       -0.12086577]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.32754544830165017
{'scaleFactor': 20, 'currentState': array([25.03580663, 20.07460593, 12.24630808,  0.60562964,  0.78311051,
       -0.14124682]), 'targetState': array([25., 25., 15.])}
episode index:1525
target thresh 22.729699543924486
model initialize at round 1525
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3279477646195397
{'scaleFactor': 20, 'currentState': array([26.20270112, 21.61759105, 11.741056  ,  0.51667108,  0.8554548 ,
       -0.03532815]), 'targetState': array([25., 25., 15.])}
episode index:1526
target thresh 22.73742618763146
model initialize at round 1526
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.92967516,  0.9857324 ,  0.15306404,
       -0.07002169]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.32835578183321384
{'scaleFactor': 20, 'currentState': array([25.08292655, 20.12380688, 12.57526261,  0.58139727,  0.80527255,
       -0.1162469 ]), 'targetState': array([25., 25., 15.])}
episode index:1527
target thresh 22.745152058712716
model initialize at round 1527
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86730157,  0.97960244,  0.15211218,
       -0.13130475]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3287632649929434
{'scaleFactor': 20, 'currentState': array([24.87963106, 20.01026624, 11.73680913,  0.54497917,  0.75894272,
       -0.35637572]), 'targetState': array([25., 25., 15.])}
episode index:1528
target thresh 22.75287715724548
model initialize at round 1528
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.05847521, 14.84627329,  0.986479  ,  0.05826724,
       -0.15317997]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3285482465070095
{'scaleFactor': 20, 'currentState': array([ 2.68673662e+01,  5.47695868e+01, -1.90984123e+01, -2.32734901e-02,
        8.60506541e-01, -5.08907494e-01]), 'targetState': array([25., 25., 15.])}
episode index:1529
target thresh 22.760601483307006
model initialize at round 1529
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12969222, 14.87431588,  0.9837647 ,  0.12887538,
       -0.12489252]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.32894885559386833
{'scaleFactor': 20, 'currentState': array([2.65354814e+01, 2.12864107e+01, 1.24564830e+01, 5.16561655e-01,
       8.56161765e-01, 1.22918513e-02]), 'targetState': array([25., 25., 15.])}
episode index:1530
target thresh 22.768325036974556
model initialize at round 1530
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3293489413507639
{'scaleFactor': 20, 'currentState': array([25.84107641, 21.5718678 , 10.80166152,  0.45531051,  0.83940368,
       -0.29680599]), 'targetState': array([25., 25., 15.])}
episode index:1531
target thresh 22.776047818325353
model initialize at round 1531
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.32975471230934694
{'scaleFactor': 20, 'currentState': array([25.15022599, 20.17961959, 13.0036939 ,  0.59003111,  0.80394249,
        0.07442957]), 'targetState': array([25., 25., 15.])}
episode index:1532
target thresh 22.78376982743664
model initialize at round 1532
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15222007, 14.92092723,  0.9853193 ,  0.15150038,
       -0.07869891]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3301537504287805
{'scaleFactor': 20, 'currentState': array([26.66919846, 21.43452516, 13.61875302,  0.56022847,  0.81988183,
        0.11805863]), 'targetState': array([25., 25., 15.])}
episode index:1533
target thresh 22.791491064385603
model initialize at round 1533
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08243132, 14.89409174,  0.99093614,  0.08250927,
       -0.1060084 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3305522682899097
{'scaleFactor': 20, 'currentState': array([27.15350104, 20.22004435, 12.73120697,  0.60881572,  0.78857072,
        0.08660048]), 'targetState': array([25., 25., 15.])}
episode index:1534
target thresh 22.799211529249487
model initialize at round 1534
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86056402,  0.97872433,  0.15197583,
       -0.13784786]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.330950266909526
{'scaleFactor': 20, 'currentState': array([26.63301841, 21.28949909, 12.45288287,  0.54069292,  0.83931052,
        0.05664814]), 'targetState': array([25., 25., 15.])}
episode index:1535
target thresh 22.806931222105487
model initialize at round 1535
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.88675528,  0.98190503,  0.15246972,
       -0.11231875]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.33135393864324375
{'scaleFactor': 20, 'currentState': array([25.22466583, 20.17017514, 13.33418298,  0.60196498,  0.7945995 ,
        0.07905571]), 'targetState': array([25., 25., 15.])}
episode index:1536
target thresh 22.8146501430308
model initialize at round 1536
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13804043, 14.97320616,  0.99006284,  0.13804919,
       -0.02679554]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.331750897791427
{'scaleFactor': 20, 'currentState': array([27.41620868, 20.62715277, 15.13058606,  0.65387511,  0.71617122,
        0.24402073]), 'targetState': array([25., 25., 15.])}
episode index:1537
target thresh 22.822368292102613
model initialize at round 1537
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.51537267e+01,  1.49858712e+01,  9.88059615e-01,
        1.53425406e-01, -1.41011469e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3321535240281686
{'scaleFactor': 20, 'currentState': array([25.48403374, 20.05517316, 14.43538341,  0.62441879,  0.77546645,
        0.09355728]), 'targetState': array([25., 25., 15.])}
episode index:1538
target thresh 22.830085669398102
model initialize at round 1538
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.98086333,  0.98797765,  0.15341268,
       -0.01909758]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.33255562703393327
{'scaleFactor': 20, 'currentState': array([25.39214962, 20.16887849, 14.55549198,  0.59943509,  0.79620832,
       -0.08203586]), 'targetState': array([25., 25., 15.])}
episode index:1539
target thresh 22.837802274994456
model initialize at round 1539
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.33295720782800214
{'scaleFactor': 20, 'currentState': array([24.95709763, 20.14503144, 12.17778086,  0.57775677,  0.81117088,
       -0.09054782]), 'targetState': array([25., 25., 15.])}
episode index:1540
target thresh 22.84551810896882
model initialize at round 1540
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.33335826742701063
{'scaleFactor': 20, 'currentState': array([25.0920292 , 20.14823268, 12.65544943,  0.61359002,  0.7884537 ,
        0.04298896]), 'targetState': array([25., 25., 15.])}
episode index:1541
target thresh 22.85323317139838
model initialize at round 1541
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.06275947, 14.91233219,  0.99412203,  0.06302077,
       -0.08803283]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3331420817801708
{'scaleFactor': 20, 'currentState': array([ 15.77133919,  22.2757006 , -23.65122878,  -0.03448565,
        -0.1477035 ,  -0.98843028]), 'targetState': array([25., 25., 15.])}
episode index:1542
target thresh 22.860947462360258
model initialize at round 1542
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14354991, 14.84627329,  0.978168  ,  0.14183427,
       -0.15188944]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.33353633846689845
{'scaleFactor': 20, 'currentState': array([25.88713711, 21.65307151, 11.19295453,  0.4270855 ,  0.87087198,
       -0.24326935]), 'targetState': array([25., 25., 15.])}
episode index:1543
target thresh 22.868660981931622
model initialize at round 1543
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.33393624372041736
{'scaleFactor': 20, 'currentState': array([24.98085053, 20.15331865, 12.30039757,  0.58621095,  0.80910307,
       -0.04133941]), 'targetState': array([25., 25., 15.])}
episode index:1544
target thresh 22.87637373018958
model initialize at round 1544
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12048779, 14.84627329,  0.98108843,  0.11940321,
       -0.15234292]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.33432947602182866
{'scaleFactor': 20, 'currentState': array([26.81453108, 20.66450074, 12.22136303,  0.58638291,  0.80056007,
        0.1235259 ]), 'targetState': array([25., 25., 15.])}
episode index:1545
target thresh 22.884085707211288
model initialize at round 1545
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10893517, 14.95579658,  0.99302299,  0.1092678 ,
       -0.0443384 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.33472219961392385
{'scaleFactor': 20, 'currentState': array([27.16713299, 20.75931039, 14.01829609,  0.5924943 ,  0.79577319,
        0.12528183]), 'targetState': array([25., 25., 15.])}
episode index:1546
target thresh 22.891796913073847
model initialize at round 1546
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.33512056280092195
{'scaleFactor': 20, 'currentState': array([ 2.50305107e+01,  2.01650130e+01,  1.24827100e+01,  5.85317839e-01,
        8.10754924e-01, -8.91520003e-03]), 'targetState': array([25., 25., 15.])}
episode index:1547
target thresh 22.899507347854374
model initialize at round 1547
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.90139134,  0.98340596,  0.15270279,
       -0.09795187]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3355122679602243
{'scaleFactor': 20, 'currentState': array([27.04135678, 21.07408373, 14.06460885,  0.59346226,  0.78368781,
        0.18340111]), 'targetState': array([25., 25., 15.])}
episode index:1548
target thresh 22.907217011629978
model initialize at round 1548
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09295531, 14.90965128,  0.9915363 ,  0.09309956,
       -0.09048893]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3359034673672228
{'scaleFactor': 20, 'currentState': array([27.2240755 , 20.684919  , 14.54777536,  0.67221878,  0.70449388,
        0.22761874]), 'targetState': array([25., 25., 15.])}
episode index:1549
target thresh 22.914925904477755
model initialize at round 1549
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.50455839e+01, 1.50136539e+01, 9.98846851e-01,
       4.59912237e-02, 1.37759259e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.33628808793531306
{'scaleFactor': 20, 'currentState': array([28.76244256, 21.52984564, 15.39059281,  0.50579218,  0.84744178,
        0.16129691]), 'targetState': array([25., 25., 15.])}
episode index:1550
target thresh 22.922634026474785
model initialize at round 1550
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.33668441415192474
{'scaleFactor': 20, 'currentState': array([24.77818249, 20.08208937, 11.60396456,  0.5608449 ,  0.81373389,
       -0.15261114]), 'targetState': array([25., 25., 15.])}
episode index:1551
target thresh 22.93034137769815
model initialize at round 1551
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87028825,  0.97997851,  0.15217058,
       -0.12839871]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.33708022963887585
{'scaleFactor': 20, 'currentState': array([25.21352638, 20.18376323, 13.46099402,  0.58825738,  0.79489553,
        0.14864167]), 'targetState': array([25., 25., 15.])}
episode index:1552
target thresh 22.938047958224928
model initialize at round 1552
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.93743698,  0.98623678,  0.15314236,
       -0.06232521]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.33747553538276587
{'scaleFactor': 20, 'currentState': array([25.42597873, 20.12587958, 14.54487901,  0.60587497,  0.7884634 ,
        0.10602354]), 'targetState': array([25., 25., 15.])}
episode index:1553
target thresh 22.945753768132192
model initialize at round 1553
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.95009592,  0.98693425,  0.15325066,
       -0.04974954]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3378703323676547
{'scaleFactor': 20, 'currentState': array([2.53993534e+01, 2.01137419e+01, 1.39764767e+01, 6.59711931e-01,
       7.51249628e-01, 2.01038267e-02]), 'targetState': array([25., 25., 15.])}
episode index:1554
target thresh 22.953458807496986
model initialize at round 1554
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.07417517, 14.84627329,  0.98546065,  0.07383507,
       -0.15302184]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.33825245134870896
{'scaleFactor': 20, 'currentState': array([28.71053855, 21.07372807, 13.5907834 ,  0.51835603,  0.80356646,
        0.2925542 ]), 'targetState': array([25., 25., 15.])}
episode index:1555
target thresh 22.961163076396375
model initialize at round 1555
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3386462415791404
{'scaleFactor': 20, 'currentState': array([25.22134689, 20.18172608, 13.37157523,  0.5915153 ,  0.79818527,
        0.11406104]), 'targetState': array([25., 25., 15.])}
episode index:1556
target thresh 22.968866574907388
model initialize at round 1556
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15143177, 14.91423714,  0.98489822,  0.15065139,
       -0.0853209 ]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.3390273713841037
{'scaleFactor': 20, 'currentState': array([29.11304279, 21.33458959, 14.92139952,  0.61904965,  0.72312515,
        0.30637811]), 'targetState': array([25., 25., 15.])}
episode index:1557
target thresh 22.976569303107077
model initialize at round 1557
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89583943,  0.98286023,  0.15261805,
       -0.10340937]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.33941405481030196
{'scaleFactor': 20, 'currentState': array([26.34399997, 21.47743911, 12.34833114,  0.50541813,  0.86200293,
        0.03877443]), 'targetState': array([25., 25., 15.])}
episode index:1558
target thresh 22.984271261072443
model initialize at round 1558
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.88343858,  0.98153713,  0.1524126 ,
       -0.11556501]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.33980634217084704
{'scaleFactor': 20, 'currentState': array([25.27776517, 20.14694121, 13.43978911,  0.62870541,  0.77578574,
        0.05372137]), 'targetState': array([25., 25., 15.])}
episode index:1559
target thresh 22.991972448880528
model initialize at round 1559
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14768234, 14.92534553,  0.9863164 ,  0.14713284,
       -0.0743767 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.340192030508815
{'scaleFactor': 20, 'currentState': array([27.23085724, 20.62154656, 14.25480624,  0.58940158,  0.77517202,
        0.22740737]), 'targetState': array([25., 25., 15.])}
episode index:1560
target thresh 22.999672866608336
model initialize at round 1560
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.96017977,  0.98737826,  0.15331961,
       -0.03971478]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3405833168761381
{'scaleFactor': 20, 'currentState': array([25.38492651, 20.15646501, 15.11611056,  0.59028595,  0.78169359,
        0.2012899 ]), 'targetState': array([25., 25., 15.])}
episode index:1561
target thresh 23.007372514332868
model initialize at round 1561
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.92229363,  0.98519891,  0.1529812 ,
       -0.07732953]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3409741022365887
{'scaleFactor': 20, 'currentState': array([25.34301338, 20.1801627 , 14.22501029,  0.59822915,  0.79736869,
        0.07953028]), 'targetState': array([25., 25., 15.])}
episode index:1562
target thresh 23.015071392131137
model initialize at round 1562
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.88268946,  0.98145262,  0.15239947,
       -0.11629771]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3413583031624776
{'scaleFactor': 20, 'currentState': array([26.91513379, 21.30614271, 14.39611859,  0.55644268,  0.81982815,
        0.13510495]), 'targetState': array([25., 25., 15.])}
episode index:1563
target thresh 23.02276950008011
model initialize at round 1563
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.341748093281875
{'scaleFactor': 20, 'currentState': array([25.1526418 , 20.18054087, 13.00733151,  0.59143519,  0.80590828,
        0.02676295]), 'targetState': array([25., 25., 15.])}
episode index:1564
target thresh 23.03046683825678
model initialize at round 1564
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.34213738526693455
{'scaleFactor': 20, 'currentState': array([24.88279736, 20.1171686 , 11.90390915,  0.56815986,  0.80956294,
       -0.14765572]), 'targetState': array([25., 25., 15.])}
episode index:1565
target thresh 23.03816340673811
model initialize at round 1565
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.34252010733853994
{'scaleFactor': 20, 'currentState': array([26.21076061, 21.41039857, 11.26933579,  0.4819036 ,  0.83461694,
       -0.26680233]), 'targetState': array([25., 25., 15.])}
episode index:1566
target thresh 23.045859205601083
model initialize at round 1566
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3423015239898874
{'scaleFactor': 20, 'currentState': array([ 1.89106805e+01,  3.56301378e+01, -6.45029401e+01, -5.32870083e-02,
        1.07852230e-01, -9.92737826e-01]), 'targetState': array([25., 25., 15.])}
episode index:1567
target thresh 23.053554234922647
model initialize at round 1567
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.06787672, 14.86045039,  0.9879367 ,  0.06773526,
       -0.13925877]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3420832194465265
{'scaleFactor': 20, 'currentState': array([ 24.56435287,  45.26475401, -39.10185895,  -0.04556876,
        -0.08196577,  -0.99559284]), 'targetState': array([25., 25., 15.])}
episode index:1568
target thresh 23.06124849477974
model initialize at round 1568
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.07787539, 14.85928033,  0.98705968,  0.0776441 ,
       -0.14030173]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.3424592437476485
{'scaleFactor': 20, 'currentState': array([29.02250865, 20.98914458, 12.91452115,  0.69942212,  0.68551925,
        0.20216836]), 'targetState': array([25., 25., 15.])}
episode index:1569
target thresh 23.068941985249335
model initialize at round 1569
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.04464288, 14.86021577,  0.98919284,  0.04460648,
       -0.13967026]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3422411168408029
{'scaleFactor': 20, 'currentState': array([ 1.73222773e+01,  4.27132065e+01, -2.03077207e+01, -2.14425732e-02,
        6.06440293e-02, -9.97929115e-01]), 'targetState': array([25., 25., 15.])}
episode index:1570
target thresh 23.07663470640834
model initialize at round 1570
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.07008525, 14.88877783,  0.9912983 ,  0.07017717,
       -0.11136803]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.342622554799148
{'scaleFactor': 20, 'currentState': array([27.34840593, 20.14228306, 14.20611486,  0.59568763,  0.76777701,
        0.2359549 ]), 'targetState': array([25., 25., 15.])}
episode index:1571
target thresh 23.084326658333698
model initialize at round 1571
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.8866786 ,  0.98189664,  0.15246842,
       -0.11239384]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.34300350746746977
{'scaleFactor': 20, 'currentState': array([26.47730634, 21.59109157, 13.22231396,  0.50140228,  0.85574225,
        0.12767521]), 'targetState': array([25., 25., 15.])}
episode index:1572
target thresh 23.092017841102308
model initialize at round 1572
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.34339002148045933
{'scaleFactor': 20, 'currentState': array([2.51265284e+01, 2.01570187e+01, 1.27611549e+01, 6.10629945e-01,
       7.91800071e-01, 1.35542604e-02]), 'targetState': array([25., 25., 15.])}
episode index:1573
target thresh 23.099708254791107
model initialize at round 1573
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3437760443701795
{'scaleFactor': 20, 'currentState': array([25.28632461, 20.08766205, 13.20005293,  0.6296292 ,  0.77617155,
        0.03353789]), 'targetState': array([25., 25., 15.])}
episode index:1574
target thresh 23.10739789947699
model initialize at round 1574
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3441615770721032
{'scaleFactor': 20, 'currentState': array([25.18543898, 20.18942571, 13.27535465,  0.59134402,  0.8017225 ,
        0.08690962]), 'targetState': array([25., 25., 15.])}
episode index:1575
target thresh 23.115086775236836
model initialize at round 1575
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11831703, 14.89647909,  0.9876249 ,  0.11803318,
       -0.10327255]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.34454058631850476
{'scaleFactor': 20, 'currentState': array([26.68240586, 21.18267523, 15.43300242,  0.47684191,  0.80748661,
        0.34725663]), 'targetState': array([25., 25., 15.])}
episode index:1576
target thresh 23.122774882147567
model initialize at round 1576
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.95119002,  0.98698722,  0.15325889,
       -0.04866144]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3449251452681443
{'scaleFactor': 20, 'currentState': array([25.36369014, 20.17336759, 14.5996871 ,  0.59731839,  0.7946729 ,
        0.10819301]), 'targetState': array([25., 25., 15.])}
episode index:1577
target thresh 23.13046222028604
model initialize at round 1577
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86938712,  0.9798659 ,  0.15215309,
       -0.12927586]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.34530921681734067
{'scaleFactor': 20, 'currentState': array([25.36928148, 20.12420495, 14.49498652,  0.60320646,  0.7619469 ,
        0.23575174]), 'targetState': array([25., 25., 15.])}
episode index:1578
target thresh 23.13814878972913
model initialize at round 1578
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11516429, 14.91889753,  0.99002949,  0.11516772,
       -0.08110489]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.3456808166470365
{'scaleFactor': 20, 'currentState': array([29.67570455, 20.02350092, 15.26569339,  0.74247193,  0.59608388,
        0.30564594]), 'targetState': array([25., 25., 15.])}
episode index:1579
target thresh 23.145834590553715
model initialize at round 1579
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13379102, 14.9125437 ,  0.98721571,  0.13341474,
       -0.08721033]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.3460519460972011
{'scaleFactor': 20, 'currentState': array([29.16557427, 20.89240062, 16.50654888,  0.55618716,  0.7336028 ,
        0.39049042]), 'targetState': array([25., 25., 15.])}
episode index:1580
target thresh 23.153519622836647
model initialize at round 1580
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86340073,  0.97909905,  0.15203401,
       -0.13509517]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3464345761438822
{'scaleFactor': 20, 'currentState': array([ 2.52562937e+01,  2.01582874e+01,  1.32754347e+01,  6.20004123e-01,
        7.84416490e-01, -1.69014208e-02]), 'targetState': array([25., 25., 15.])}
episode index:1581
target thresh 23.161203886654768
model initialize at round 1581
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3468167224610479
{'scaleFactor': 20, 'currentState': array([25.29269445, 20.10118009, 13.24502085,  0.63449944,  0.76896919,
        0.07808229]), 'targetState': array([25., 25., 15.])}
episode index:1582
target thresh 23.168887382084925
model initialize at round 1582
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13385805, 14.92530349,  0.988224  ,  0.13361792,
       -0.07456251]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.3471864310052336
{'scaleFactor': 20, 'currentState': array([29.52172565, 20.5673646 , 16.43645266,  0.76638688,  0.48038655,
        0.42647381]), 'targetState': array([25., 25., 15.])}
episode index:1583
target thresh 23.176570109203965
model initialize at round 1583
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.05481951, 15.06822249,  0.99611525,  0.05515813,
        0.0686439 ]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3469672476523263
{'scaleFactor': 20, 'currentState': array([ 4.14910394e+01,  4.69497858e+01,  2.20104419e+01,  4.96576956e-01,
       -3.75045278e-02, -8.67182067e-01]), 'targetState': array([25., 25., 15.])}
episode index:1584
target thresh 23.184252068088696
model initialize at round 1584
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08317366, 14.84627329,  0.98477011,  0.08273428,
       -0.15291461]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3473423346565841
{'scaleFactor': 20, 'currentState': array([26.95475211, 20.17507894, 11.51748112,  0.60231177,  0.78819124,
       -0.12639266]), 'targetState': array([25., 25., 15.])}
episode index:1585
target thresh 23.191933258815943
model initialize at round 1585
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.0981151 , 14.84627329,  0.98345308,  0.09746626,
       -0.1527101 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.34771694866335856
{'scaleFactor': 20, 'currentState': array([26.98306015, 20.31272565, 11.44652488,  0.66616491,  0.73519508,
       -0.12534957]), 'targetState': array([25., 25., 15.])}
episode index:1586
target thresh 23.199613681462537
model initialize at round 1586
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.05971278, 14.84627329,  0.98640738,  0.05949609,
       -0.15316885]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.34749784535607225
{'scaleFactor': 20, 'currentState': array([ 2.90836253e+01,  4.93726321e+01, -2.91712995e+01,  3.43876729e-02,
        9.86119692e-01, -1.62435962e-01]), 'targetState': array([25., 25., 15.])}
episode index:1587
target thresh 23.207293336105252
model initialize at round 1587
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.05936075, 15.08744423,  0.99434976,  0.05962157,
        0.08782843]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3472790179975357
{'scaleFactor': 20, 'currentState': array([ 14.87417202,  31.93866289, -18.09451055,  -0.06630781,
        -0.13816501,  -0.98818708]), 'targetState': array([25., 25., 15.])}
episode index:1588
target thresh 23.214972222820908
model initialize at round 1588
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85371664,  0.97778995,  0.15183074,
       -0.14447919]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.34765894942101117
{'scaleFactor': 20, 'currentState': array([25.23470992, 20.18735248, 13.58606674,  0.59013504,  0.79547764,
        0.13768063]), 'targetState': array([25., 25., 15.])}
episode index:1589
target thresh 23.22265034168628
model initialize at round 1589
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87583364,  0.98065515,  0.15227564,
       -0.12299432]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3480324218738287
{'scaleFactor': 20, 'currentState': array([27.33255508, 20.64135078, 13.73389755,  0.69219509,  0.70167246,
        0.16888376]), 'targetState': array([25., 25., 15.])}
episode index:1590
target thresh 23.230327692778165
model initialize at round 1590
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12109504, 14.85889239,  0.98281468,  0.12021614,
       -0.14008347]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3484054248452474
{'scaleFactor': 20, 'currentState': array([27.0749575 , 20.89477631, 13.32390273,  0.60117425,  0.79787672,
        0.04452255]), 'targetState': array([25., 25., 15.])}
episode index:1591
target thresh 23.238004276173317
model initialize at round 1591
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.1492738 , 14.84627329,  0.97736871,  0.14736924,
       -0.15176533]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.34877795921996835
{'scaleFactor': 20, 'currentState': array([27.28853953, 20.55367455, 13.39280708,  0.72546315,  0.66130752,
        0.19072383]), 'targetState': array([25., 25., 15.])}
episode index:1592
target thresh 23.24568009194852
model initialize at round 1592
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.04804349, 14.85115907,  0.98774961,  0.04793428,
       -0.1485026 ]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3485590151149966
{'scaleFactor': 20, 'currentState': array([16.49075656, 38.61355282, -5.59292457,  0.15516032,  0.04379682,
       -0.98691799]), 'targetState': array([25., 25., 15.])}
episode index:1593
target thresh 23.25335514018051
model initialize at round 1593
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87131387,  0.98010578,  0.15219034,
       -0.12740002]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3489309857136703
{'scaleFactor': 20, 'currentState': array([26.75198183, 21.38057977, 15.39294599,  0.64990386,  0.69817895,
        0.30028506]), 'targetState': array([25., 25., 15.])}
episode index:1594
target thresh 23.261029420946066
model initialize at round 1594
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.02882326, 14.94538158,  0.99805996,  0.02905792,
       -0.05506309]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3487122202053859
{'scaleFactor': 20, 'currentState': array([ 3.05021397e+01,  5.25938594e+01, -2.13671680e+01, -4.76165857e-02,
       -1.45090606e-01, -9.88271914e-01]), 'targetState': array([25., 25., 15.])}
episode index:1595
target thresh 23.268702934321894
model initialize at round 1595
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3490895872665981
{'scaleFactor': 20, 'currentState': array([2.52278312e+01, 2.01900223e+01, 1.34257402e+01, 5.95523178e-01,
       8.03014175e-01, 2.28118378e-02]), 'targetState': array([25., 25., 15.])}
episode index:1596
target thresh 23.276375680384774
model initialize at round 1596
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.34946648173286826
{'scaleFactor': 20, 'currentState': array([24.94799009, 20.1052791 , 12.01042101,  0.56585843,  0.80255688,
       -0.18896215]), 'targetState': array([25., 25., 15.])}
episode index:1597
target thresh 23.284047659211403
model initialize at round 1597
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3498429044914209
{'scaleFactor': 20, 'currentState': array([24.92818189, 20.08041633, 11.90206466,  0.55178279,  0.78988698,
       -0.26760851]), 'targetState': array([25., 25., 15.])}
episode index:1598
target thresh 23.29171887087851
model initialize at round 1598
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.35021885642726125
{'scaleFactor': 20, 'currentState': array([25.24770399, 20.09528746, 13.06394602,  0.6283241 ,  0.77305523,
        0.08714611]), 'targetState': array([25., 25., 15.])}
episode index:1599
target thresh 23.299389315462793
model initialize at round 1599
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3505943384231817
{'scaleFactor': 20, 'currentState': array([25.2275876 , 20.1867356 , 13.68029535,  0.58898308,  0.79458837,
        0.14740508]), 'targetState': array([25., 25., 15.])}
episode index:1600
target thresh 23.307058993040975
model initialize at round 1600
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.35096935135976937
{'scaleFactor': 20, 'currentState': array([25.20300748, 20.18597577, 13.20951823,  0.59357778,  0.80343924,
        0.04637682]), 'targetState': array([25., 25., 15.])}
episode index:1601
target thresh 23.314727903689757
model initialize at round 1601
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3513438961154125
{'scaleFactor': 20, 'currentState': array([ 2.51605227e+01,  2.01791452e+01,  1.29403314e+01,  5.91457166e-01,
        8.06154988e-01, -1.71042471e-02]), 'targetState': array([25., 25., 15.])}
episode index:1602
target thresh 23.322396047485803
model initialize at round 1602
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.1318381 , 14.84841246,  0.98002507,  0.13050974,
       -0.15006019]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.35112471714091753
{'scaleFactor': 20, 'currentState': array([ 2.50141865e+01,  4.21632313e+01, -4.65123485e+01,  9.55498325e-03,
        9.76059489e-02, -9.95179271e-01]), 'targetState': array([25., 25., 15.])}
episode index:1603
target thresh 23.33006342450581
model initialize at round 1603
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08734044, 14.84627329,  0.98442414,  0.08684852,
       -0.15286089]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.35090581145691446
{'scaleFactor': 20, 'currentState': array([ 2.54215718e+01,  4.30463131e+01, -4.52097202e+01, -2.30851317e-02,
       -1.20295521e-01, -9.92469679e-01]), 'targetState': array([25., 25., 15.])}
episode index:1604
target thresh 23.337730034826453
model initialize at round 1604
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10966939, 14.8482856 ,  0.9825875 ,  0.10884825,
       -0.15057845]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3512737705459762
{'scaleFactor': 20, 'currentState': array([26.78812984, 21.18605999, 14.86018537,  0.55473103,  0.7754327 ,
        0.30162496]), 'targetState': array([25., 25., 15.])}
episode index:1605
target thresh 23.34539587852441
model initialize at round 1605
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89375119,  0.98264748,  0.15258501,
       -0.10545972]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.35164127140454093
{'scaleFactor': 20, 'currentState': array([26.66701631, 21.31301664, 15.93709046,  0.52016012,  0.80051226,
        0.29768031]), 'targetState': array([25., 25., 15.])}
episode index:1606
target thresh 23.35306095567631
model initialize at round 1606
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.05666852, 14.87984957,  0.9911169 ,  0.05673246,
       -0.12028598]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.35200245626857485
{'scaleFactor': 20, 'currentState': array([28.96299351, 20.97949137, 14.4070011 ,  0.56679688,  0.77031939,
        0.29214608]), 'targetState': array([25., 25., 15.])}
episode index:1607
target thresh 23.360725266358816
model initialize at round 1607
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.1476996 , 14.84627329,  0.97759145,  0.14584835,
       -0.15179991]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.35236904687375664
{'scaleFactor': 20, 'currentState': array([26.62492077, 21.32900503, 13.48786055,  0.50338151,  0.83570323,
        0.2195613 ]), 'targetState': array([25., 25., 15.])}
episode index:1608
target thresh 23.368388810648575
model initialize at round 1608
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.92445417,  0.98536048,  0.15300629,
       -0.07519179]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3527351818038543
{'scaleFactor': 20, 'currentState': array([27.5416576 , 20.08655225, 16.41334894,  0.74680425,  0.52507519,
        0.40814147]), 'targetState': array([25., 25., 15.])}
episode index:1609
target thresh 23.376051588622225
model initialize at round 1609
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.03012981, 14.93966403,  0.99768775,  0.03036378,
       -0.0608045 ]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3525160916288209
{'scaleFactor': 20, 'currentState': array([ 47.85152272, -21.22262435,  64.01146749,   0.69176449,
        -0.70298808,   0.16513524]), 'targetState': array([25., 25., 15.])}
episode index:1610
target thresh 23.383713600356405
model initialize at round 1610
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.02570839, 14.84627329,  0.98783269,  0.02565211,
       -0.15339017]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.352297273446556
{'scaleFactor': 20, 'currentState': array([ 17.52407433,  38.3788508 , -33.89000923,   0.17714992,
        -0.14122465,  -0.97399872]), 'targetState': array([25., 25., 15.])}
episode index:1611
target thresh 23.391374845927693
model initialize at round 1611
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.92784397,  0.98560494,  0.15304424,
       -0.0718357 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3526627715085624
{'scaleFactor': 20, 'currentState': array([26.85522801, 21.2613426 , 15.36340491,  0.52597768,  0.79781794,
        0.29467613]), 'targetState': array([25., 25., 15.])}
episode index:1612
target thresh 23.399035325412743
model initialize at round 1612
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.35303371216472573
{'scaleFactor': 20, 'currentState': array([25.32254534, 20.17856216, 14.29203122,  0.59163536,  0.79096182,
        0.15603526]), 'targetState': array([25., 25., 15.])}
episode index:1613
target thresh 23.40669503888815
model initialize at round 1613
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.35339830103538017
{'scaleFactor': 20, 'currentState': array([26.46007878, 21.56790462, 13.81995565,  0.46905738,  0.83496618,
        0.28777883]), 'targetState': array([25., 25., 15.])}
episode index:1614
target thresh 23.41435398643049
model initialize at round 1614
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.90936565,  0.98413895,  0.15281661,
       -0.09009777]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.35376832688607035
{'scaleFactor': 20, 'currentState': array([25.33808666, 20.1485108 , 15.008138  ,  0.57890433,  0.77666769,
        0.24830843]), 'targetState': array([25., 25., 15.])}
episode index:1615
target thresh 23.42201216811639
model initialize at round 1615
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87679414,  0.98076948,  0.1522934 ,
       -0.12205712]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.35413789478397506
{'scaleFactor': 20, 'currentState': array([25.35336877, 20.15680816, 15.01086636,  0.58625098,  0.78339612,
        0.20639843]), 'targetState': array([25., 25., 15.])}
episode index:1616
target thresh 23.429669584022406
model initialize at round 1616
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89414908,  0.98268833,  0.15259136,
       -0.10506916]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.35450700557872833
{'scaleFactor': 20, 'currentState': array([25.32765662, 20.14519823, 15.05044795,  0.58381484,  0.78315974,
        0.21405853]), 'targetState': array([25., 25., 15.])}
episode index:1617
target thresh 23.437326234225107
model initialize at round 1617
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.35487566011786387
{'scaleFactor': 20, 'currentState': array([25.29052402, 20.1442166 , 14.68131728,  0.57460774,  0.76578086,
        0.28880032]), 'targetState': array([25., 25., 15.])}
episode index:1618
target thresh 23.444982118801082
model initialize at round 1618
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13845373, 14.84627329,  0.97885491,  0.13689506,
       -0.1519961 ]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3552438592468214
{'scaleFactor': 20, 'currentState': array([25.40608606, 20.03789403, 14.26324403,  0.60762553,  0.78537492,
        0.11822629]), 'targetState': array([25., 25., 15.])}
episode index:1619
target thresh 23.452637237826856
model initialize at round 1619
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.35561160380895296
{'scaleFactor': 20, 'currentState': array([25.32694247, 20.14931282, 14.13726377,  0.6236766 ,  0.76971373,
        0.13626546]), 'targetState': array([25., 25., 15.])}
episode index:1620
target thresh 23.460291591379033
model initialize at round 1620
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.1154941 , 14.8576654 ,  0.98328835,  0.11471112,
       -0.14136965]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.35597302795799185
{'scaleFactor': 20, 'currentState': array([2.66487561e+01, 2.14789284e+01, 1.39639666e+01, 5.03062515e-01,
       8.64185751e-01, 1.05401515e-02]), 'targetState': array([25., 25., 15.])}
episode index:1621
target thresh 23.467945179534098
model initialize at round 1621
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.3563282020146805
{'scaleFactor': 20, 'currentState': array([28.64602685, 21.03979917, 10.10162568,  0.70172523,  0.59046304,
       -0.39866665]), 'targetState': array([25., 25., 15.])}
episode index:1622
target thresh 23.475598002368624
model initialize at round 1622
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15320362, 14.84627329,  0.97680304,  0.15116138,
       -0.15167749]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.35669459871701287
{'scaleFactor': 20, 'currentState': array([25.34130971, 20.06633983, 13.78581925,  0.61292932,  0.76472245,
        0.19878938]), 'targetState': array([25., 25., 15.])}
episode index:1623
target thresh 23.483250059959136
model initialize at round 1623
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87290904,  0.98030181,  0.15222078,
       -0.12584596]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.35706054419187927
{'scaleFactor': 20, 'currentState': array([25.27427806, 20.09789712, 15.46599865,  0.55025557,  0.75153836,
        0.36388034]), 'targetState': array([25., 25., 15.])}
episode index:1624
target thresh 23.490901352382142
model initialize at round 1624
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.94656767,  0.9867555 ,  0.1532229 ,
       -0.05325722]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.35742603927231503
{'scaleFactor': 20, 'currentState': array([25.31163988, 20.11411187, 15.38430451,  0.56225709,  0.76103585,
        0.32356051]), 'targetState': array([25., 25., 15.])}
episode index:1625
target thresh 23.49855187971417
model initialize at round 1625
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89255153,  0.9825234 ,  0.15256575,
       -0.10663701]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.35779108478930627
{'scaleFactor': 20, 'currentState': array([25.33125689, 20.13341116, 15.46906268,  0.57259348,  0.77029195,
        0.28069026]), 'targetState': array([25., 25., 15.])}
episode index:1626
target thresh 23.506201642031698
model initialize at round 1626
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.06651934, 14.9017108 ,  0.99289075,  0.06671357,
       -0.0985762 ]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3575711763167867
{'scaleFactor': 20, 'currentState': array([ 28.73117762,  45.22159762, -31.65449037,  -0.05740482,
         0.14164183,  -0.98825213]), 'targetState': array([25., 25., 15.])}
episode index:1627
target thresh 23.51385063941126
model initialize at round 1627
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10865205, 14.86331096,  0.98479963,  0.10808131,
       -0.13597102]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3579298427621701
{'scaleFactor': 20, 'currentState': array([26.72710703, 20.89979365, 16.01985623,  0.47472724,  0.78175703,
        0.40433896]), 'targetState': array([25., 25., 15.])}
episode index:1628
target thresh 23.521498871929314
model initialize at round 1628
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.51537267e+01,  1.49934327e+01,  9.88136634e-01,
        1.53437366e-01, -6.55489303e-03]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3582939067321749
{'scaleFactor': 20, 'currentState': array([25.25748684, 20.07221253, 16.41484785,  0.54085217,  0.74628541,
        0.38799101]), 'targetState': array([25., 25., 15.])}
episode index:1629
target thresh 23.529146339662365
model initialize at round 1629
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.51537267e+01,  1.49945662e+01,  9.88143330e-01,
        1.53438405e-01, -5.42360328e-03]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3586575239979221
{'scaleFactor': 20, 'currentState': array([25.35559505, 20.13184427, 15.61894113,  0.57378783,  0.77083537,
        0.27673156]), 'targetState': array([25., 25., 15.])}
episode index:1630
target thresh 23.536793042686877
model initialize at round 1630
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.1483051 , 14.96300431,  0.98829021,  0.14804897,
       -0.03693179]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.35902069538106257
{'scaleFactor': 20, 'currentState': array([25.31715719, 20.0552481 , 16.21413024,  0.57228527,  0.76960657,
        0.28318774]), 'targetState': array([25., 25., 15.])}
episode index:1631
target thresh 23.544438981079317
model initialize at round 1631
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.97842274,  0.98792877,  0.15340509,
       -0.02153212]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.35937759455631985
{'scaleFactor': 20, 'currentState': array([27.06553094, 20.39536962, 17.68339324,  0.58100909,  0.70752681,
        0.40228628]), 'targetState': array([25., 25., 15.])}
episode index:1632
target thresh 23.55208415491614
model initialize at round 1632
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.94126521,  0.9864641 ,  0.15317766,
       -0.05852501]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.35973405662297303
{'scaleFactor': 20, 'currentState': array([26.68218377, 21.35869334, 16.43828032,  0.50069974,  0.77431819,
        0.38695105]), 'targetState': array([25., 25., 15.])}
episode index:1633
target thresh 23.55972856427382
model initialize at round 1633
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87821958,  0.9809376 ,  0.1523195 ,
       -0.12066564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.36009008238354706
{'scaleFactor': 20, 'currentState': array([26.92101989, 21.31632334, 15.38445322,  0.62195601,  0.75558925,
        0.2055617 ]), 'targetState': array([25., 25., 15.])}
episode index:1634
target thresh 23.567372209228765
model initialize at round 1634
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10471325, 14.85677965,  0.9843187 ,  0.10411233,
       -0.14239845]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.35986984380104947
{'scaleFactor': 20, 'currentState': array([ 28.26074976,  43.96373566, -30.28045185,  -0.27216561,
         0.26102672,  -0.92617003]), 'targetState': array([25., 25., 15.])}
episode index:1635
target thresh 23.575015089857445
model initialize at round 1635
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.93697391,  0.98620832,  0.15313794,
       -0.0627847 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3602253513228098
{'scaleFactor': 20, 'currentState': array([27.27539376, 20.97437653, 15.58622779,  0.72869648,  0.66367408,
        0.16893238]), 'targetState': array([25., 25., 15.])}
episode index:1636
target thresh 23.58265720623627
model initialize at round 1636
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.0469091 , 14.86022085,  0.98909111,  0.04686603,
       -0.13965082]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3600052991839443
{'scaleFactor': 20, 'currentState': array([ 3.45440270e+01,  4.96669801e+01, -9.95664487e+00,  3.17338284e-02,
        7.57494297e-02, -9.96621788e-01]), 'targetState': array([25., 25., 15.])}
episode index:1637
target thresh 23.59029855844167
model initialize at round 1637
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.0331082 , 14.84627329,  0.98761873,  0.03302857,
       -0.15335695]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.3603545421929328
{'scaleFactor': 20, 'currentState': array([28.417214  , 21.46030451, 15.6709529 ,  0.45773435,  0.83245107,
        0.31225708]), 'targetState': array([25., 25., 15.])}
episode index:1638
target thresh 23.59793914655005
model initialize at round 1638
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3607091032711561
{'scaleFactor': 20, 'currentState': array([27.44101672, 20.44800415, 15.54539516,  0.70153499,  0.66034574,
        0.26794059]), 'targetState': array([25., 25., 15.])}
episode index:1639
target thresh 23.60557897063783
model initialize at round 1639
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3610632319578206
{'scaleFactor': 20, 'currentState': array([26.73654684, 21.21479529, 12.94654566,  0.54011345,  0.83305776,
        0.1195501 ]), 'targetState': array([25., 25., 15.])}
episode index:1640
target thresh 23.61321803078139
model initialize at round 1640
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14315142, 14.84627329,  0.97822255,  0.14144844,
       -0.15189791]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.36141692904340444
{'scaleFactor': 20, 'currentState': array([26.87354416, 20.96565339, 12.11767161,  0.60605773,  0.76263293,
       -0.22602001]), 'targetState': array([25., 25., 15.])}
episode index:1641
target thresh 23.620856327057126
model initialize at round 1641
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3617759869732806
{'scaleFactor': 20, 'currentState': array([24.99842268, 20.09896614, 12.11388442,  0.55917459,  0.79044131,
       -0.25005262]), 'targetState': array([25., 25., 15.])}
episode index:1642
target thresh 23.628493859541443
model initialize at round 1642
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13444229, 14.84627329,  0.97937911,  0.13299997,
       -0.1520775 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3621288196953912
{'scaleFactor': 20, 'currentState': array([26.67568359, 21.37303797, 13.99506859,  0.53582271,  0.81614407,
        0.21633975]), 'targetState': array([25., 25., 15.])}
episode index:1643
target thresh 23.63613062831068
model initialize at round 1643
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85541575,  0.97802573,  0.15186735,
       -0.14283547]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.36248700779162274
{'scaleFactor': 20, 'currentState': array([25.2869673 , 20.11467338, 15.32689561,  0.56852634,  0.77053708,
        0.28818468]), 'targetState': array([25., 25., 15.])}
episode index:1644
target thresh 23.64376663344123
model initialize at round 1644
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.36283897930627884
{'scaleFactor': 20, 'currentState': array([ 2.74040559e+01,  2.04993873e+01,  1.30507955e+01,  7.35370225e-01,
        6.77328343e-01, -2.13763417e-02]), 'targetState': array([25., 25., 15.])}
episode index:1645
target thresh 23.651401875009448
model initialize at round 1645
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12379303, 14.84627329,  0.98069969,  0.12263009,
       -0.15228256]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.36261854250232606
{'scaleFactor': 20, 'currentState': array([43.82165177, 22.94103695, 25.39382365,  0.91140613,  0.13454018,
        0.38889306]), 'targetState': array([25., 25., 15.])}
episode index:1646
target thresh 23.65903635309168
model initialize at round 1646
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3629700067445232
{'scaleFactor': 20, 'currentState': array([26.54290214, 21.36530924, 16.09104283,  0.4649269 ,  0.81081266,
        0.35556407]), 'targetState': array([25., 25., 15.])}
episode index:1647
target thresh 23.666670067764272
model initialize at round 1647
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14590396, 14.84627329,  0.97784282,  0.14411227,
       -0.15183895]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.36332104445244573
{'scaleFactor': 20, 'currentState': array([27.10237569, 20.46714607, 16.9949445 ,  0.62903278,  0.63091542,
        0.45416241]), 'targetState': array([25., 25., 15.])}
episode index:1648
target thresh 23.674303019103572
model initialize at round 1648
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.06641409, 14.90170857,  0.99289751,  0.06660847,
       -0.09857911]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3631007163478657
{'scaleFactor': 20, 'currentState': array([ 14.3031604 ,  35.69578102, -10.7109305 ,  -0.09564643,
         0.11784183,  -0.98841543]), 'targetState': array([25., 25., 15.])}
episode index:1649
target thresh 23.6819352071859
model initialize at round 1649
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.872015  ,  0.98019223,  0.15220376,
       -0.12671707]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3634512493375949
{'scaleFactor': 20, 'currentState': array([26.81230951, 21.25537657, 15.65493872,  0.54761597,  0.76541115,
        0.33802739]), 'targetState': array([25., 25., 15.])}
episode index:1650
target thresh 23.689566632087566
model initialize at round 1650
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09745517, 14.85443786,  0.98470381,  0.09693382,
       -0.14478342]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.3637956552119555
{'scaleFactor': 20, 'currentState': array([28.48563553, 21.39650298, 17.41806264,  0.48645394,  0.74835117,
        0.4509247 ]), 'targetState': array([25., 25., 15.])}
episode index:1651
target thresh 23.69719729388491
model initialize at round 1651
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85727211,  0.97828038,  0.15190689,
       -0.14103828]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.36414534316243313
{'scaleFactor': 20, 'currentState': array([26.86761907, 21.42328129, 14.69825418,  0.56169599,  0.81547909,
        0.13961186]), 'targetState': array([25., 25., 15.])}
episode index:1652
target thresh 23.704827192654232
model initialize at round 1652
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3645003611338412
{'scaleFactor': 20, 'currentState': array([25.28787252, 20.10134422, 15.60877307,  0.56336568,  0.76582219,
        0.31005723]), 'targetState': array([25., 25., 15.])}
episode index:1653
target thresh 23.71245632847182
model initialize at round 1653
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84692306,  0.97682149,  0.15168036,
       -0.15103923]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3648492001835795
{'scaleFactor': 20, 'currentState': array([26.30869232, 21.43326601, 16.92235707,  0.42050325,  0.78580029,
        0.45353602]), 'targetState': array([25., 25., 15.])}
episode index:1654
target thresh 23.720084701413967
model initialize at round 1654
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10351211, 14.96142371,  0.99383221,  0.1039128 ,
       -0.03872562]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.36519192897374475
{'scaleFactor': 20, 'currentState': array([28.67639805, 21.3205633 , 18.01020525,  0.62581348,  0.69341481,
        0.35711818]), 'targetState': array([25., 25., 15.])}
episode index:1655
target thresh 23.72771231155696
model initialize at round 1655
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.06143925, 14.85583651,  0.98770237,  0.06129666,
       -0.1438289 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.36553992910685296
{'scaleFactor': 20, 'currentState': array([26.79109225, 20.51732594, 17.12960552,  0.47677552,  0.76013091,
        0.44145907]), 'targetState': array([25., 25., 15.])}
episode index:1656
target thresh 23.735339158977077
model initialize at round 1656
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09801028, 14.97675394,  0.99486364,  0.09849178,
       -0.02336026]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3658875092035905
{'scaleFactor': 20, 'currentState': array([27.27291278, 20.10350779, 17.61678862,  0.67953139,  0.58034607,
        0.4488157 ]), 'targetState': array([25., 25., 15.])}
episode index:1657
target thresh 23.74296524375058
model initialize at round 1657
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08486963, 14.8982779 ,  0.99116519,  0.08496952,
       -0.10184182]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3656668291618513
{'scaleFactor': 20, 'currentState': array([ 2.40108932e+01,  4.97599338e+01, -1.81436820e+01, -8.06765313e-02,
       -3.25048088e-02, -9.96210186e-01]), 'targetState': array([25., 25., 15.])}
episode index:1658
target thresh 23.750590565953743
model initialize at round 1658
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14593438, 14.93106989,  0.9869706 ,  0.14548783,
       -0.06871918]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.36601391374306835
{'scaleFactor': 20, 'currentState': array([26.95841458, 20.44636396, 17.77179446,  0.5461954 ,  0.71199898,
        0.44128   ]), 'targetState': array([25., 25., 15.])}
episode index:1659
target thresh 23.75821512566282
model initialize at round 1659
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.91317303,  0.98446766,  0.15286765,
       -0.08634176]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.36636058015009115
{'scaleFactor': 20, 'currentState': array([26.55979976, 21.5327718 , 16.16991335,  0.45203248,  0.80859379,
        0.37662013]), 'targetState': array([25., 25., 15.])}
episode index:1660
target thresh 23.765838922954032
model initialize at round 1660
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86531654,  0.97934801,  0.15207267,
       -0.13323432]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.36671255454488344
{'scaleFactor': 20, 'currentState': array([25.18539299, 20.02231141, 16.43572766,  0.53154808,  0.74331499,
        0.4061274 ]), 'targetState': array([25., 25., 15.])}
episode index:1661
target thresh 23.77346195790363
model initialize at round 1661
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.90482016,  0.9837285 ,  0.15275287,
       -0.09457689]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3670641053844473
{'scaleFactor': 20, 'currentState': array([25.28218273, 20.09019697, 15.95998275,  0.55044409,  0.75310883,
        0.36033095]), 'targetState': array([25., 25., 15.])}
episode index:1662
target thresh 23.781084230587858
model initialize at round 1662
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.93649237,  0.98617851,  0.15313331,
       -0.06326248]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.3674038535759822
{'scaleFactor': 20, 'currentState': array([28.33352431, 21.36024866, 18.71235487,  0.45460023,  0.74519419,
        0.48787729]), 'targetState': array([25., 25., 15.])}
episode index:1663
target thresh 23.78870574108293
model initialize at round 1663
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.50697199e+01,  1.49918645e+01,  9.97495893e-01,
        7.02477877e-02, -8.19707931e-03]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.36774319341632544
{'scaleFactor': 20, 'currentState': array([28.84705878, 20.27434169, 18.74453951,  0.55065504,  0.72788367,
        0.40861277]), 'targetState': array([25., 25., 15.])}
episode index:1664
target thresh 23.79632648946505
model initialize at round 1664
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.36809349182862794
{'scaleFactor': 20, 'currentState': array([25.30495556, 20.10358162, 15.61686037,  0.55932989,  0.75959024,
        0.3319228 ]), 'targetState': array([25., 25., 15.])}
episode index:1665
target thresh 23.803946475810434
model initialize at round 1665
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86927667,  0.97985205,  0.15215094,
       -0.12938336]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3684433697146252
{'scaleFactor': 20, 'currentState': array([25.20969637, 20.04568232, 16.3853593 ,  0.54181079,  0.75176538,
        0.37588546]), 'targetState': array([25., 25., 15.])}
episode index:1666
target thresh 23.81156570019528
model initialize at round 1666
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14343945, 14.89946457,  0.98470556,  0.14267235,
       -0.09999778]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3687871230317736
{'scaleFactor': 20, 'currentState': array([26.40117254, 20.92849651, 18.19239611,  0.51273597,  0.74563549,
        0.42559317]), 'targetState': array([25., 25., 15.])}
episode index:1667
target thresh 23.819184162695784
model initialize at round 1667
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89240118,  0.98250776,  0.15256332,
       -0.10678452]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.36913046417468076
{'scaleFactor': 20, 'currentState': array([26.58495503, 20.98892713, 17.92421674,  0.5233584 ,  0.70369137,
        0.48053558]), 'targetState': array([25., 25., 15.])}
episode index:1668
target thresh 23.826801863388138
model initialize at round 1668
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.51358360e+01,  1.49875053e+01,  9.90640384e-01,
        1.35923909e-01, -1.25027864e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3694733938842231
{'scaleFactor': 20, 'currentState': array([26.88049268, 20.41732147, 18.34473016,  0.67065452,  0.60248332,
        0.43270817]), 'targetState': array([25., 25., 15.])}
episode index:1669
target thresh 23.8344188023485
model initialize at round 1669
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.02927559, 14.98045917,  0.99936857,  0.02955263,
       -0.01972575]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.36925215233099906
{'scaleFactor': 20, 'currentState': array([ 23.76297234,  41.64349064, -37.14148228,   0.1081257 ,
        -0.04564998,  -0.99308857]), 'targetState': array([25., 25., 15.])}
episode index:1670
target thresh 23.84203497965306
model initialize at round 1670
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14617815, 14.85905505,  0.97960592,  0.14464342,
       -0.13946516]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3696002899118303
{'scaleFactor': 20, 'currentState': array([25.34311565, 20.01371757, 15.86685676,  0.56917241,  0.75672547,
        0.32157321]), 'targetState': array([25., 25., 15.])}
episode index:1671
target thresh 23.849650395377953
model initialize at round 1671
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.36994232332061566
{'scaleFactor': 20, 'currentState': array([26.02317305, 21.54568003, 17.61301073,  0.39511582,  0.82952553,
        0.39467819]), 'targetState': array([25., 25., 15.])}
episode index:1672
target thresh 23.857265049599363
model initialize at round 1672
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.97281958,  0.98779441,  0.15338422,
       -0.02711987]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3702896321828867
{'scaleFactor': 20, 'currentState': array([25.12062623, 20.03197245, 17.19552406,  0.5317667 ,  0.75055623,
        0.39228755]), 'targetState': array([25., 25., 15.])}
episode index:1673
target thresh 23.864878942393418
model initialize at round 1673
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.92330891,  0.98527539,  0.15299307,
       -0.07632509]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3706365261002805
{'scaleFactor': 20, 'currentState': array([25.35150893, 20.13891514, 15.72306005,  0.57826797,  0.77684901,
        0.24922233]), 'targetState': array([25., 25., 15.])}
episode index:1674
target thresh 23.87249207383626
model initialize at round 1674
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.37097732826344504
{'scaleFactor': 20, 'currentState': array([26.97111053, 20.98018136, 16.54677868,  0.60824512,  0.71621098,
        0.34216912]), 'targetState': array([25., 25., 15.])}
episode index:1675
target thresh 23.880104444004026
model initialize at round 1675
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14558943, 14.84627329,  0.97788656,  0.14380803,
       -0.15184574]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3713177237414507
{'scaleFactor': 20, 'currentState': array([26.94012525, 21.28954377, 13.99353351,  0.67047759,  0.73707564,
        0.08473074]), 'targetState': array([25., 25., 15.])}
episode index:1676
target thresh 23.88771605297283
model initialize at round 1676
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08930187, 14.84627329,  0.98425556,  0.0887837 ,
       -0.15283471]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3716577132618201
{'scaleFactor': 20, 'currentState': array([27.315094  , 20.01533558, 16.03561658,  0.56962067,  0.72146087,
        0.39373406]), 'targetState': array([25., 25., 15.])}
episode index:1677
target thresh 23.8953269008188
model initialize at round 1677
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.88854834,  0.98209967,  0.15249995,
       -0.11056226]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3720029649523077
{'scaleFactor': 20, 'currentState': array([25.2487922 , 20.06165746, 16.18406753,  0.53081402,  0.7343784 ,
        0.42299508]), 'targetState': array([25., 25., 15.])}
episode index:1678
target thresh 23.90293698761804
model initialize at round 1678
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10135727, 14.98205921,  0.99463829,  0.10183215,
       -0.01802484]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3723421413575779
{'scaleFactor': 20, 'currentState': array([26.81363563, 20.35443583, 18.05641278,  0.50742703,  0.7583699 ,
        0.40913679]), 'targetState': array([25., 25., 15.])}
episode index:1679
target thresh 23.910546313446634
model initialize at round 1679
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13172398, 14.85756657,  0.98133456,  0.130571  ,
       -0.14118672]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.37268091398141323
{'scaleFactor': 20, 'currentState': array([26.69388669, 20.91144471, 17.37298201,  0.54208896,  0.73355429,
        0.40992397]), 'targetState': array([25., 25., 15.])}
episode index:1680
target thresh 23.918154878380715
model initialize at round 1680
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.05188067, 14.91386489,  0.99488149,  0.05213648,
       -0.08655982]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.37245921206946714
{'scaleFactor': 20, 'currentState': array([ 25.19307796,  40.48120396, -36.83120546,  -0.11320129,
        -0.08787574,  -0.98967839]), 'targetState': array([25., 25., 15.])}
episode index:1681
target thresh 23.92576268249632
model initialize at round 1681
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11725833, 14.84627329,  0.98145852,  0.11624666,
       -0.15240039]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.37279751227002095
{'scaleFactor': 20, 'currentState': array([26.68786902, 21.31069076, 13.10028822,  0.50248049,  0.84578189,
       -0.17934978]), 'targetState': array([25., 25., 15.])}
episode index:1682
target thresh 23.933369725869568
model initialize at round 1682
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.37314106101489913
{'scaleFactor': 20, 'currentState': array([24.90123761, 20.02798902, 11.77873095,  0.52671104,  0.76636058,
       -0.36778654]), 'targetState': array([25., 25., 15.])}
episode index:1683
target thresh 23.94097600857651
model initialize at round 1683
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3734785545353184
{'scaleFactor': 20, 'currentState': array([26.53279156, 21.30471059, 16.29670288,  0.49592754,  0.70309361,
        0.50962265]), 'targetState': array([25., 25., 15.])}
episode index:1684
target thresh 23.948581530693204
model initialize at round 1684
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10467397, 14.98154992,  0.99428614,  0.10512715,
       -0.01852996]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.37381564746995677
{'scaleFactor': 20, 'currentState': array([26.21580245, 20.80082114, 18.78010464,  0.45423977,  0.72518394,
        0.51746931]), 'targetState': array([25., 25., 15.])}
episode index:1685
target thresh 23.956186292295722
model initialize at round 1685
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.51128483e+01,  1.49861023e+01,  9.93469351e-01,
        1.13243747e-01, -1.39463916e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.3741467564263251
{'scaleFactor': 20, 'currentState': array([28.71996228, 20.15467705, 19.33594106,  0.48839425,  0.59632178,
        0.63708037]), 'targetState': array([25., 25., 15.])}
episode index:1686
target thresh 23.963790293460097
model initialize at round 1686
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08503265, 15.06686917,  0.99408311,  0.08538336,
        0.06714496]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3739249741166474
{'scaleFactor': 20, 'currentState': array([ 18.54293977,  40.31640957, -25.10199401,   0.07732927,
        -0.13733081,  -0.98750212]), 'targetState': array([25., 25., 15.])}
episode index:1687
target thresh 23.971393534262376
model initialize at round 1687
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.37426683731320154
{'scaleFactor': 20, 'currentState': array([25.35688968, 20.17931485, 14.4001656 ,  0.59771235,  0.79556183,
        0.09910264]), 'targetState': array([25., 25., 15.])}
episode index:1688
target thresh 23.978996014778588
model initialize at round 1688
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3746082956983921
{'scaleFactor': 20, 'currentState': array([25.44294112, 20.12309091, 14.57661311,  0.61917264,  0.78068189,
        0.08462282]), 'targetState': array([25., 25., 15.])}
episode index:1689
target thresh 23.986597735084757
model initialize at round 1689
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14679929, 14.84627329,  0.97771785,  0.14497807,
       -0.15181954]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.37494934999081914
{'scaleFactor': 20, 'currentState': array([2.53993994e+01, 2.01177888e+01, 1.43304211e+01, 6.06736338e-01,
       7.94621142e-01, 2.11720721e-02]), 'targetState': array([25., 25., 15.])}
episode index:1690
target thresh 23.99419869525691
model initialize at round 1690
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3752900009073828
{'scaleFactor': 20, 'currentState': array([25.27676303, 20.16283577, 13.33660203,  0.59288494,  0.79938599,
       -0.09731125]), 'targetState': array([25., 25., 15.])}
episode index:1691
target thresh 24.00179889537104
model initialize at round 1691
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.37562462865471946
{'scaleFactor': 20, 'currentState': array([26.72631988, 21.5856392 , 14.65638667,  0.53027751,  0.83983694,
        0.11610201]), 'targetState': array([25., 25., 15.])}
episode index:1692
target thresh 24.009398335503175
model initialize at round 1692
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3759588610946168
{'scaleFactor': 20, 'currentState': array([27.54882431, 20.32133298, 14.14747807,  0.65786464,  0.74782197,
        0.08931078]), 'targetState': array([25., 25., 15.])}
episode index:1693
target thresh 24.01699701572927
model initialize at round 1693
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.3762871411930893
{'scaleFactor': 20, 'currentState': array([29.29152647, 21.08693791, 15.08532247,  0.66719938,  0.67125245,
        0.32290113]), 'targetState': array([25., 25., 15.])}
episode index:1694
target thresh 24.024594936125354
model initialize at round 1694
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08163483, 14.88823694,  0.99036887,  0.08166525,
       -0.11180471]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.3766150339404132
{'scaleFactor': 20, 'currentState': array([29.10193221, 20.62396114, 17.17050876,  0.70783842,  0.58953056,
        0.38912529]), 'targetState': array([25., 25., 15.])}
episode index:1695
target thresh 24.032192096767368
model initialize at round 1695
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.0433909 , 14.84627329,  0.98723239,  0.0432696 ,
       -0.15329695]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.37639297318926906
{'scaleFactor': 20, 'currentState': array([28.2197528 , 30.79132887, 49.87066897, -0.81678807, -0.47174207,
       -0.33213955]), 'targetState': array([25., 25., 15.])}
episode index:1696
target thresh 24.03978849773132
model initialize at round 1696
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.04979084, 14.8827117 ,  0.99181884,  0.04988232,
       -0.11750379]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.37617117414790824
{'scaleFactor': 20, 'currentState': array([ 1.79458977e+01,  4.96641818e+01, -1.55739903e+01, -2.76002938e-02,
        1.00114138e-01, -9.94593074e-01]), 'targetState': array([25., 25., 15.])}
episode index:1697
target thresh 24.047384139093154
model initialize at round 1697
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.045458  , 14.90974344,  0.99483035,  0.04567979,
       -0.09069694]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.375949636353946
{'scaleFactor': 20, 'currentState': array([ 17.81009736,  32.38442899, -21.77034418,  -0.04513551,
        -0.14486277,  -0.98842175]), 'targetState': array([25., 25., 15.])}
episode index:1698
target thresh 24.054979020928823
model initialize at round 1698
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86625959,  0.97946933,  0.15209151,
       -0.13231781]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.37628809451377304
{'scaleFactor': 20, 'currentState': array([25.35328506, 20.14140818, 15.35752276,  0.580133  ,  0.77778282,
        0.24186688]), 'targetState': array([25., 25., 15.])}
episode index:1699
target thresh 24.06257314331427
model initialize at round 1699
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3766205604284125
{'scaleFactor': 20, 'currentState': array([26.57308151, 20.91828285, 17.47859399,  0.49313522,  0.6938297 ,
        0.52480283]), 'targetState': array([25., 25., 15.])}
episode index:1700
target thresh 24.070166506325464
model initialize at round 1700
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.05991487, 15.08592566,  0.99444867,  0.0601841 ,
        0.08631178]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3763991491641983
{'scaleFactor': 20, 'currentState': array([ 18.18825555,  35.13596842, -16.94825904,  -0.12775403,
        -0.08592358,  -0.98807694]), 'targetState': array([25., 25., 15.])}
episode index:1701
target thresh 24.077759110038322
model initialize at round 1701
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.37673115915258654
{'scaleFactor': 20, 'currentState': array([26.49281429, 21.33061842, 17.0745104 ,  0.53528552,  0.75463457,
        0.37946814]), 'targetState': array([25., 25., 15.])}
episode index:1702
target thresh 24.08535095452876
model initialize at round 1702
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13060247, 14.84627329,  0.97986721,  0.12926573,
       -0.15215329]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3770627792290682
{'scaleFactor': 20, 'currentState': array([26.40855863, 21.43703057, 16.38368141,  0.4346267 ,  0.80453252,
        0.40475554]), 'targetState': array([25., 25., 15.])}
episode index:1703
target thresh 24.09294203987272
model initialize at round 1703
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.88778031,  0.98201666,  0.15248706,
       -0.11131476]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.377399591007631
{'scaleFactor': 20, 'currentState': array([25.19034378, 20.04406344, 16.6373829 ,  0.54821626,  0.76150549,
        0.34578652]), 'targetState': array([25., 25., 15.])}
episode index:1704
target thresh 24.100532366146087
model initialize at round 1704
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86668753,  0.97952412,  0.15210002,
       -0.1319018 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3777304300448118
{'scaleFactor': 20, 'currentState': array([26.54451191, 21.31137622, 16.82970833,  0.45540199,  0.78600312,
        0.41810061]), 'targetState': array([25., 25., 15.])}
episode index:1705
target thresh 24.108121933424798
model initialize at round 1705
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.93455143,  0.98605606,  0.1531143 ,
       -0.06518783]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3780608812284907
{'scaleFactor': 20, 'currentState': array([25.83521024, 21.44994859, 18.48869452,  0.35031301,  0.78593738,
        0.50949311]), 'targetState': array([25., 25., 15.])}
episode index:1706
target thresh 24.115710741784714
model initialize at round 1706
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.51537267e+01, 1.50133585e+01, 9.88070035e-01,
       1.53427024e-01, 1.33324511e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3783909452403082
{'scaleFactor': 20, 'currentState': array([26.59983738, 21.2454693 , 17.56620186,  0.52924113,  0.78846168,
        0.31341985]), 'targetState': array([25., 25., 15.])}
episode index:1707
target thresh 24.12329879130173
model initialize at round 1707
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87741034,  0.98084239,  0.15230472,
       -0.12145569]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.37872062276030855
{'scaleFactor': 20, 'currentState': array([26.61467916, 21.17878682, 17.51326281,  0.61279944,  0.7070872 ,
        0.352852  ]), 'targetState': array([25., 25., 15.])}
episode index:1708
target thresh 24.130886082051738
model initialize at round 1708
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.50101591e+01,  1.48462733e+01,  9.88107064e-01,
        1.01396934e-02, -1.53432774e-01]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3784990191191381
{'scaleFactor': 20, 'currentState': array([32.76882659, 55.06109864, -6.80648397,  0.10220893,  0.07264278,
       -0.99210703]), 'targetState': array([25., 25., 15.])}
episode index:1709
target thresh 24.138472614110608
model initialize at round 1709
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.151224  , 14.84627329,  0.97708971,  0.14925193,
       -0.151722  ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.37882824785029706
{'scaleFactor': 20, 'currentState': array([26.77050027, 21.0686048 , 16.92842205,  0.52417001,  0.7273558 ,
        0.44294395]), 'targetState': array([25., 25., 15.])}
episode index:1710
target thresh 24.146058387554202
model initialize at round 1710
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.02174344,  0.98792522,  0.15340454,
        0.02169787]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3791570917436639
{'scaleFactor': 20, 'currentState': array([26.10189654, 21.55556489, 18.25921725,  0.44573992,  0.81058298,
        0.37983044]), 'targetState': array([25., 25., 15.])}
episode index:1711
target thresh 24.15364340245838
model initialize at round 1711
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12377677, 14.84627329,  0.98070163,  0.12261422,
       -0.15228286]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3789356214797949
{'scaleFactor': 20, 'currentState': array([54.56390926, 40.07691596, 74.2257917 ,  0.78904885,  0.53664357,
        0.29902439]), 'targetState': array([25., 25., 15.])}
episode index:1712
target thresh 24.161227658898998
model initialize at round 1712
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3792695703580321
{'scaleFactor': 20, 'currentState': array([25.39374191, 20.1759176 , 14.53906051,  0.59789224,  0.79159532,
        0.12610199]), 'targetState': array([25., 25., 15.])}
episode index:1713
target thresh 24.168811156951886
model initialize at round 1713
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3796031295642993
{'scaleFactor': 20, 'currentState': array([25.216049  , 20.04252889, 15.97764246,  0.51809168,  0.7224414 ,
        0.45788583]), 'targetState': array([25., 25., 15.])}
episode index:1714
target thresh 24.176393896692883
model initialize at round 1714
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89264083,  0.98253269,  0.15256719,
       -0.10654939]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.37993075464875214
{'scaleFactor': 20, 'currentState': array([25.91277717, 21.48843648, 18.15395938,  0.36928434,  0.80518382,
        0.46401304]), 'targetState': array([25., 25., 15.])}
episode index:1715
target thresh 24.183975878197817
model initialize at round 1715
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.9706481 ,  0.98773405,  0.15337485,
       -0.02928472]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.380263539785845
{'scaleFactor': 20, 'currentState': array([25.22425632, 20.0663347 , 16.66898776,  0.5513883 ,  0.76013374,
        0.34375522]), 'targetState': array([25., 25., 15.])}
episode index:1716
target thresh 24.191557101542514
model initialize at round 1716
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.9020939 ,  0.98347296,  0.15271319,
       -0.09726061]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.38059039861497435
{'scaleFactor': 20, 'currentState': array([25.97461367, 21.49330311, 18.07627821,  0.37286892,  0.79892497,
        0.47189794]), 'targetState': array([25., 25., 15.])}
episode index:1717
target thresh 24.199137566802786
model initialize at round 1717
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09272893, 14.88246206,  0.988758  ,  0.0926126 ,
       -0.11739048]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.38091139683924213
{'scaleFactor': 20, 'currentState': array([28.80888449, 20.64599812, 17.80187567,  0.52061154,  0.66714943,
        0.53279946]), 'targetState': array([25., 25., 15.])}
episode index:1718
target thresh 24.206717274054423
model initialize at round 1718
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.1184619 , 14.91104225,  0.98898843,  0.11834085,
       -0.08886686]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.38123202159262654
{'scaleFactor': 20, 'currentState': array([28.48189769, 20.69709824, 19.42071246,  0.61569361,  0.58538547,
        0.52748956]), 'targetState': array([25., 25., 15.])}
episode index:1719
target thresh 24.214296223373232
model initialize at round 1719
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.49834746e+01,  1.49563172e+01,  9.98889072e-01,
       -1.66737553e-02, -4.40750227e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.38101037506844476
{'scaleFactor': 20, 'currentState': array([ 1.58906882e+01,  3.42239196e+01, -3.05143163e+01,  4.99566846e-03,
        1.53447841e-01, -9.88144121e-01]), 'targetState': array([25., 25., 15.])}
episode index:1720
target thresh 24.22187441483501
model initialize at round 1720
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11585634, 14.86515147,  0.98425551,  0.11518408,
       -0.13406607]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.38133604024818474
{'scaleFactor': 20, 'currentState': array([26.57510636, 21.1248712 , 16.63336058,  0.44831904,  0.78585344,
        0.42596293]), 'targetState': array([25., 25., 15.])}
episode index:1721
target thresh 24.229451848515527
model initialize at round 1721
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85712532,  0.97826036,  0.15190378,
       -0.14118044]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3816668497775993
{'scaleFactor': 20, 'currentState': array([25.20638875, 20.00415402, 16.44373961,  0.54217037,  0.71476019,
        0.44177954]), 'targetState': array([25., 25., 15.])}
episode index:1722
target thresh 24.23702852449057
model initialize at round 1722
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.92013794,  0.98503325,  0.15295547,
       -0.0794614 ]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3819972753145247
{'scaleFactor': 20, 'currentState': array([25.15316228, 20.00869359, 16.91780256,  0.5049877 ,  0.71633237,
        0.48151361]), 'targetState': array([25., 25., 15.])}
episode index:1723
target thresh 24.244604442835882
model initialize at round 1723
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14501724, 14.93729653,  0.98750392,  0.14465161,
       -0.06254537]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.38232180134357713
{'scaleFactor': 20, 'currentState': array([26.5548998 , 20.67438095, 18.14611772,  0.44964129,  0.67777716,
        0.58175668]), 'targetState': array([25., 25., 15.])}
episode index:1724
target thresh 24.252179603627244
model initialize at round 1724
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.95803091,  0.98729197,  0.15330621,
       -0.04185428]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.38264595111056693
{'scaleFactor': 20, 'currentState': array([25.8725713 , 21.48336086, 18.47653531,  0.36839064,  0.80043292,
        0.47285884]), 'targetState': array([25., 25., 15.])}
episode index:1725
target thresh 24.259754006940405
model initialize at round 1725
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13309392, 14.86979997,  0.98277077,  0.13212204,
       -0.12924927]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3829697252694837
{'scaleFactor': 20, 'currentState': array([26.4116116 , 21.14286812, 17.23625629,  0.42945356,  0.76826834,
        0.47469296]), 'targetState': array([25., 25., 15.])}
episode index:1726
target thresh 24.2673276528511
model initialize at round 1726
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.92411057,  0.98533508,  0.15300234,
       -0.07553183]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.38329312447280245
{'scaleFactor': 20, 'currentState': array([25.91797156, 21.29603782, 18.50174142,  0.40235158,  0.7333691 ,
        0.5479808 ]), 'targetState': array([25., 25., 15.])}
episode index:1727
target thresh 24.274900541435073
model initialize at round 1727
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.07635561, 14.95217456,  0.99588441,  0.07680945,
       -0.04810971]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3836161493714877
{'scaleFactor': 20, 'currentState': array([26.77232893, 20.13761126, 17.87526901,  0.4505179 ,  0.70311699,
        0.55014555]), 'targetState': array([25., 25., 15.])}
episode index:1728
target thresh 24.282472672768062
model initialize at round 1728
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.93678462,  0.98619663,  0.15313612,
       -0.06297252]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3839388006149981
{'scaleFactor': 20, 'currentState': array([26.15644692, 21.24963431, 18.10151797,  0.41322767,  0.77651989,
        0.47566769]), 'targetState': array([25., 25., 15.])}
episode index:1729
target thresh 24.290044046925765
model initialize at round 1729
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89593064,  0.98286943,  0.15261948,
       -0.10331979]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.38426107885129057
{'scaleFactor': 20, 'currentState': array([26.942228  , 21.05292474, 16.94669954,  0.62834337,  0.68843332,
        0.36227639]), 'targetState': array([25., 25., 15.])}
episode index:1730
target thresh 24.2976146639839
model initialize at round 1730
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.38458298472682473
{'scaleFactor': 20, 'currentState': array([27.15231134, 20.12797139, 17.29391981,  0.60455356,  0.59652054,
        0.52789985]), 'targetState': array([25., 25., 15.])}
episode index:1731
target thresh 24.30518452401821
model initialize at round 1731
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.93934973,  0.98635214,  0.15316027,
       -0.06042679]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.38491000959124344
{'scaleFactor': 20, 'currentState': array([25.36965123, 20.1512684 , 15.62409704,  0.58689997,  0.78472256,
        0.19939639]), 'targetState': array([25., 25., 15.])}
episode index:1732
target thresh 24.312753627104332
model initialize at round 1732
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3852366570467015
{'scaleFactor': 20, 'currentState': array([25.32533696, 20.1774259 , 13.71482138,  0.59778748,  0.79921035,
       -0.06255351]), 'targetState': array([25., 25., 15.])}
episode index:1733
target thresh 24.320321973318016
model initialize at round 1733
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3855629277461555
{'scaleFactor': 20, 'currentState': array([25.30706225, 20.13928148, 14.91573424,  0.56231993,  0.75976757,
        0.32641925]), 'targetState': array([25., 25., 15.])}
episode index:1734
target thresh 24.327889562734896
model initialize at round 1734
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14434916, 14.91060772,  0.98561018,  0.14370909,
       -0.0889959 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.38588334113039463
{'scaleFactor': 20, 'currentState': array([26.22828665, 21.52926924, 17.2862074 ,  0.39380737,  0.79102355,
        0.46818533]), 'targetState': array([25., 25., 15.])}
episode index:1735
target thresh 24.33545639543069
model initialize at round 1735
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85537167,  0.97801965,  0.15186641,
       -0.14287813]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.386208863428073
{'scaleFactor': 20, 'currentState': array([25.31517988, 20.09975395, 15.88564304,  0.59284562,  0.77060639,
        0.23388002]), 'targetState': array([25., 25., 15.])}
episode index:1736
target thresh 24.343022471481035
model initialize at round 1736
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13377238, 14.84627329,  0.97946523,  0.13234889,
       -0.15209087]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3865285360164281
{'scaleFactor': 20, 'currentState': array([27.55119945, 20.38421192, 14.29780131,  0.78116184,  0.56789403,
        0.25938879]), 'targetState': array([25., 25., 15.])}
episode index:1737
target thresh 24.350587790961608
model initialize at round 1737
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10670094, 14.84627329,  0.98260087,  0.10590347,
       -0.15257778]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.38684784074219597
{'scaleFactor': 20, 'currentState': array([27.24369409, 20.41799361, 15.06641392,  0.55559185,  0.74440052,
        0.37038571]), 'targetState': array([25., 25., 15.])}
episode index:1738
target thresh 24.35815235394806
model initialize at round 1738
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86822744,  0.97971989,  0.15213042,
       -0.13040424]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3871722468429193
{'scaleFactor': 20, 'currentState': array([25.28396301, 20.09119928, 15.80330554,  0.54852841,  0.74995804,
        0.36970195]), 'targetState': array([25., 25., 15.])}
episode index:1739
target thresh 24.365716160516026
model initialize at round 1739
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3874962800630671
{'scaleFactor': 20, 'currentState': array([25.28788056, 20.09759121, 15.68081438,  0.54834767,  0.74811345,
        0.37368584]), 'targetState': array([25., 25., 15.])}
episode index:1740
target thresh 24.373279210741174
model initialize at round 1740
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85664367,  0.97819452,  0.15189356,
       -0.14164685]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3878199410451676
{'scaleFactor': 20, 'currentState': array([25.35499023, 20.14728361, 15.2950804 ,  0.5871968 ,  0.78529658,
        0.19623761]), 'targetState': array([25., 25., 15.])}
episode index:1741
target thresh 24.38084150469909
model initialize at round 1741
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.38813236665186207
{'scaleFactor': 20, 'currentState': array([28.57776137, 20.42915219, 18.56078649,  0.44577692,  0.67015292,
        0.59344587]), 'targetState': array([25., 25., 15.])}
episode index:1742
target thresh 24.388403042465434
model initialize at round 1742
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84944719,  0.97718611,  0.15173697,
       -0.14860415]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3884552913123602
{'scaleFactor': 20, 'currentState': array([25.2906824 , 20.05939153, 15.8498906 ,  0.56964131,  0.73140255,
        0.3749121 ]), 'targetState': array([25., 25., 15.])}
episode index:1743
target thresh 24.395963824115807
model initialize at round 1743
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87371516,  0.98039998,  0.15223602,
       -0.12506026]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.38877784564641277
{'scaleFactor': 20, 'currentState': array([25.19686644, 20.02118881, 16.55746347,  0.55216243,  0.74752194,
        0.36922569]), 'targetState': array([25., 25., 15.])}
episode index:1744
target thresh 24.403523849725815
model initialize at round 1744
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13673404, 14.84627329,  0.97908141,  0.13522601,
       -0.15203128]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.38909458049097123
{'scaleFactor': 20, 'currentState': array([26.95276825, 21.18831216, 14.05813882,  0.54863693,  0.82933942,
        0.10580001]), 'targetState': array([25., 25., 15.])}
episode index:1745
target thresh 24.411083119371057
model initialize at round 1745
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86731049,  0.97960358,  0.15211236,
       -0.13129608]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.389416399201973
{'scaleFactor': 20, 'currentState': array([25.15093661, 20.0043492 , 16.67612417,  0.51534156,  0.72832626,
        0.45162366]), 'targetState': array([25., 25., 15.])}
episode index:1746
target thresh 24.418641633127137
model initialize at round 1746
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87553316,  0.98061921,  0.15227006,
       -0.12328745]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3897324059279026
{'scaleFactor': 20, 'currentState': array([26.64034816, 21.20211119, 17.24956408,  0.60649785,  0.66557947,
        0.43493025]), 'targetState': array([25., 25., 15.])}
episode index:1747
target thresh 24.426199391069623
model initialize at round 1747
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.50165646e+01,  1.48462733e+01,  9.88022827e-01,
        1.65315204e-02, -1.53419694e-01]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.38950944688560973
{'scaleFactor': 20, 'currentState': array([ 14.42754922,  38.50861628, -16.46846985,  -0.11008794,
        -0.0478356 ,  -0.99277006]), 'targetState': array([25., 25., 15.])}
episode index:1748
target thresh 24.43375639327411
model initialize at round 1748
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.50107125e+01,  1.48462733e+01,  9.88101379e-01,
        1.06919992e-02, -1.53431891e-01]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.38981965609145386
{'scaleFactor': 20, 'currentState': array([2.92940478e+01, 2.01277439e+01, 1.27153833e+01, 6.21029032e-01,
       7.83561336e-01, 1.88301179e-02]), 'targetState': array([25., 25., 15.])}
episode index:1749
target thresh 24.44131263981617
model initialize at round 1749
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.39014032488791595
{'scaleFactor': 20, 'currentState': array([24.88999319, 20.01394058, 11.76513364,  0.53390003,  0.77696016,
       -0.33359205]), 'targetState': array([25., 25., 15.])}
episode index:1750
target thresh 24.448868130771338
model initialize at round 1750
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11530468, 14.84627329,  0.98167773,  0.11433539,
       -0.15243443]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3904551962896938
{'scaleFactor': 20, 'currentState': array([26.9607803 , 20.33769308, 11.5678982 ,  0.61431171,  0.74829089,
       -0.25036349]), 'targetState': array([25., 25., 15.])}
episode index:1751
target thresh 24.45642286621519
model initialize at round 1751
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12726326, 14.84627329,  0.98028074,  0.12601386,
       -0.15221751]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3907697082492322
{'scaleFactor': 20, 'currentState': array([26.50524928, 21.14238742, 16.99912573,  0.44005366,  0.76509208,
        0.47009242]), 'targetState': array([25., 25., 15.])}
episode index:1752
target thresh 24.46397684622328
model initialize at round 1752
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13510334, 14.85726783,  0.98085911,  0.1338559 ,
       -0.14141429]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3910838613816633
{'scaleFactor': 20, 'currentState': array([27.36450372, 20.71612243, 14.7478543 ,  0.68727179,  0.70345241,
        0.18114137]), 'targetState': array([25., 25., 15.])}
episode index:1753
target thresh 24.47153007087113
model initialize at round 1753
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.05295803, 14.84627329,  0.98678023,  0.05278579,
       -0.15322674]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3908608945279679
{'scaleFactor': 20, 'currentState': array([ 22.59979074,  39.10859653, -27.66633052,   0.12729366,
        -0.05801307,  -0.99016706]), 'targetState': array([25., 25., 15.])}
episode index:1754
target thresh 24.479082540234277
model initialize at round 1754
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.06465589, 14.97449853,  0.99754468,  0.06514862,
       -0.02569582]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3911746376931377
{'scaleFactor': 20, 'currentState': array([27.21694048, 20.23299016, 16.7258791 ,  0.53606608,  0.71676139,
        0.44596667]), 'targetState': array([25., 25., 15.])}
episode index:1755
target thresh 24.48663425438825
model initialize at round 1755
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.91868111,  0.98491878,  0.1529377 ,
       -0.08090152]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.39148266201558296
{'scaleFactor': 20, 'currentState': array([28.63962721, 20.56595684, 19.02869265,  0.60248225,  0.49398208,
        0.6268946 ]), 'targetState': array([25., 25., 15.])}
episode index:1756
target thresh 24.49418521340857
model initialize at round 1756
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.06347284, 15.06098604,  0.99607057,  0.06386205,
        0.06136   ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.39179569416548926
{'scaleFactor': 20, 'currentState': array([26.34033562, 20.55759865, 18.90040867,  0.40582505,  0.73283929,
        0.54612508]), 'targetState': array([25., 25., 15.])}
episode index:1757
target thresh 24.50173541737073
model initialize at round 1757
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.93857765,  0.986306  ,  0.15315311,
       -0.06119317]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.3921030147876403
{'scaleFactor': 20, 'currentState': array([28.82110143, 20.98635947, 18.68557806,  0.6927122 ,  0.53468759,
        0.48400309]), 'targetState': array([25., 25., 15.])}
episode index:1758
target thresh 24.509284866350267
model initialize at round 1758
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.04880552, 14.89760322,  0.99349977,  0.04897805,
       -0.10275876]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.39240998598327387
{'scaleFactor': 20, 'currentState': array([29.0794053 , 20.58692257, 17.02748024,  0.64033518,  0.68156864,
        0.35416811]), 'targetState': array([25., 25., 15.])}
episode index:1759
target thresh 24.516833560422626
model initialize at round 1759
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.07081203, 14.84627329,  0.9856988 ,  0.07050438,
       -0.15305882]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.3921870257639652
{'scaleFactor': 20, 'currentState': array([  9.60990126,  26.84086474, -16.31206259,  -0.14021283,
        -0.05784413,  -0.98843028]), 'targetState': array([25., 25., 15.])}
episode index:1760
target thresh 24.52438149966334
model initialize at round 1760
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.39250434718596183
{'scaleFactor': 20, 'currentState': array([25.41221523, 20.07624848, 15.25377717,  0.59982232,  0.7790568 ,
        0.18243818]), 'targetState': array([25., 25., 15.])}
episode index:1761
target thresh 24.531928684147864
model initialize at round 1761
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.39282130842473256
{'scaleFactor': 20, 'currentState': array([25.36611094, 20.16269812, 14.03967766,  0.62189481,  0.78048114,
        0.0640002 ]), 'targetState': array([25., 25., 15.])}
episode index:1762
target thresh 24.53947511395166
model initialize at round 1762
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86153109,  0.97885289,  0.15199579,
       -0.13690979]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.39313791009318144
{'scaleFactor': 20, 'currentState': array([25.2068243 , 20.0371936 , 16.13005939,  0.52603227,  0.73355721,
        0.43032996]), 'targetState': array([25., 25., 15.])}
episode index:1763
target thresh 24.54702078915023
model initialize at round 1763
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87280506,  0.9802891 ,  0.1522188 ,
       -0.12594729]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3934541528028225
{'scaleFactor': 20, 'currentState': array([25.3385337 , 20.14514594, 15.06984178,  0.57670715,  0.77459988,
        0.25962259]), 'targetState': array([25., 25., 15.])}
episode index:1764
target thresh 24.554565709818988
model initialize at round 1764
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.88930423,  0.98218082,  0.15251255,
       -0.10982148]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3937700371637841
{'scaleFactor': 20, 'currentState': array([25.22213616, 20.05419764, 16.35612094,  0.54021159,  0.74858241,
        0.38444221]), 'targetState': array([25., 25., 15.])}
episode index:1765
target thresh 24.5621098760334
model initialize at round 1765
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3940855637848126
{'scaleFactor': 20, 'currentState': array([25.2186968 , 20.03950707, 16.0909408 ,  0.5225917 ,  0.72806332,
        0.44364594]), 'targetState': array([25., 25., 15.])}
episode index:1766
target thresh 24.56965328786892
model initialize at round 1766
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89671531,  0.98294825,  0.15263172,
       -0.102549  ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.39439535132619125
{'scaleFactor': 20, 'currentState': array([25.84094246, 21.35158748, 18.21698911,  0.30268341,  0.71247026,
        0.63306309]), 'targetState': array([25., 25., 15.])}
episode index:1767
target thresh 24.577195945400977
model initialize at round 1767
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.04319377,  0.98724077,  0.15329826,
        0.04307339]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3947047884291747
{'scaleFactor': 20, 'currentState': array([26.3483236 , 21.28274543, 18.17714656,  0.51712445,  0.72397751,
        0.45655105]), 'targetState': array([25., 25., 15.])}
episode index:1768
target thresh 24.584737848704986
model initialize at round 1768
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.07045017, 14.84627329,  0.98572378,  0.07014587,
       -0.1530627 ]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.3950085535843346
{'scaleFactor': 20, 'currentState': array([29.5772303 , 20.2327171 , 14.2510484 ,  0.73522387,  0.61870152,
        0.27686511]), 'targetState': array([25., 25., 15.])}
episode index:1769
target thresh 24.592278997856376
model initialize at round 1769
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.07301302, 14.84627329,  0.98554418,  0.0726844 ,
       -0.15303481]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.39531197550203107
{'scaleFactor': 20, 'currentState': array([28.70553701, 20.68861609, 17.16980561,  0.44292004,  0.67993516,
        0.58438859]), 'targetState': array([25., 25., 15.])}
episode index:1770
target thresh 24.599819392930556
model initialize at round 1770
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14399567, 14.90660608,  0.98530284,  0.14331247,
       -0.0929508 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3956203708571405
{'scaleFactor': 20, 'currentState': array([26.55006566, 21.04611533, 17.28405349,  0.46491016,  0.79360629,
        0.39248898]), 'targetState': array([25., 25., 15.])}
episode index:1771
target thresh 24.60735903400292
model initialize at round 1771
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.39593378489723247
{'scaleFactor': 20, 'currentState': array([25.31265234, 20.13998794, 14.98168382,  0.56889662,  0.76731595,
        0.29594402]), 'targetState': array([25., 25., 15.])}
episode index:1772
target thresh 24.61489792114888
model initialize at round 1772
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.396241481662322
{'scaleFactor': 20, 'currentState': array([27.14286883, 20.76348277, 15.48143697,  0.55968405,  0.74528153,
        0.36236612]), 'targetState': array([25., 25., 15.])}
episode index:1773
target thresh 24.62243605444382
model initialize at round 1773
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09259754, 14.84627329,  0.98396408,  0.09203298,
       -0.15278945]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.39601812118787877
{'scaleFactor': 20, 'currentState': array([52.66668247,  5.81270459, 77.9736221 ,  0.67598962, -0.58356724,
        0.44998591]), 'targetState': array([25., 25., 15.])}
episode index:1774
target thresh 24.629973433963116
model initialize at round 1774
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11797604, 14.84627329,  0.98137711,  0.11694847,
       -0.15238775]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3963254237389847
{'scaleFactor': 20, 'currentState': array([27.5260156 , 20.16487496, 13.91469946,  0.70723535,  0.67403886,
        0.21328335]), 'targetState': array([25., 25., 15.])}
episode index:1775
target thresh 24.63751005978214
model initialize at round 1775
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.49980417e+01,  1.48686689e+01,  9.91313525e-01,
       -1.96086819e-03, -1.31505325e-01]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.39610226753192446
{'scaleFactor': 20, 'currentState': array([4.52591002e+01, 1.39279847e+01, 8.64971807e+01, 9.86501616e-01,
       1.10649343e-02, 1.63377262e-01]), 'targetState': array([25., 25., 15.])}
episode index:1776
target thresh 24.645045931976284
model initialize at round 1776
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.0995517 , 14.91826926,  0.9916423 ,  0.09971685,
       -0.08186632]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3964091768633083
{'scaleFactor': 20, 'currentState': array([26.96626102, 20.94895765, 15.94956238,  0.55192602,  0.781247  ,
        0.2916004 ]), 'targetState': array([25., 25., 15.])}
episode index:1777
target thresh 24.65258105062087
model initialize at round 1777
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.39671574096484796
{'scaleFactor': 20, 'currentState': array([27.14367372, 21.04413367, 14.26023871,  0.71959284,  0.68135195,
        0.13396147]), 'targetState': array([25., 25., 15.])}
episode index:1778
target thresh 24.660115415791275
model initialize at round 1778
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.07244945, 14.84627329,  0.98558421,  0.07212629,
       -0.15304103]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.39702196041871873
{'scaleFactor': 20, 'currentState': array([26.9916014 , 20.87100592, 14.01146315,  0.54930314,  0.81209966,
        0.19687613]), 'targetState': array([25., 25., 15.])}
episode index:1779
target thresh 24.66764902756282
model initialize at round 1779
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85812359,  0.97839615,  0.15192487,
       -0.14021346]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3973331784465173
{'scaleFactor': 20, 'currentState': array([25.26075056, 20.08286614, 15.76026053,  0.55113473,  0.75512209,
        0.35502273]), 'targetState': array([25., 25., 15.])}
episode index:1780
target thresh 24.675181886010865
model initialize at round 1780
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89419766,  0.98269331,  0.15259213,
       -0.10502147]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.39764404698747935
{'scaleFactor': 20, 'currentState': array([25.34370847, 20.15895861, 14.8111344 ,  0.58045915,  0.777351  ,
        0.24247186]), 'targetState': array([25., 25., 15.])}
episode index:1781
target thresh 24.682713991210736
model initialize at round 1781
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86065686,  0.97873671,  0.15197775,
       -0.13775783]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3979492299854667
{'scaleFactor': 20, 'currentState': array([26.60624235, 21.3911037 , 16.15260044,  0.50882575,  0.76656964,
        0.39174908]), 'targetState': array([25., 25., 15.])}
episode index:1782
target thresh 24.690245343237738
model initialize at round 1782
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12508936, 14.84627329,  0.98054448,  0.12389463,
       -0.15225846]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.3982487903432466
{'scaleFactor': 20, 'currentState': array([29.05173903, 21.14497809, 13.91934118,  0.56535031,  0.78164321,
        0.26346332]), 'targetState': array([25., 25., 15.])}
episode index:1783
target thresh 24.697775942167187
model initialize at round 1783
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12744537, 14.84759398,  0.98045279,  0.12621633,
       -0.15093627]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3985532922261265
{'scaleFactor': 20, 'currentState': array([26.33931647, 21.16414202, 17.07116358,  0.40089986,  0.70780137,
        0.58163263]), 'targetState': array([25., 25., 15.])}
episode index:1784
target thresh 24.705305788074405
model initialize at round 1784
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.51537267e+01, 1.50147961e+01, 9.88050117e-01,
       1.53423931e-01, 1.47669616e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3988574529304261
{'scaleFactor': 20, 'currentState': array([26.87111864, 20.81693903, 17.56336558,  0.55196321,  0.68899837,
        0.46969975]), 'targetState': array([25., 25., 15.])}
episode index:1785
target thresh 24.712834881034674
model initialize at round 1785
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.1419533 , 14.97693479,  0.98961277,  0.14189778,
       -0.02305618]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3991612730292338
{'scaleFactor': 20, 'currentState': array([26.74406203, 21.15838834, 16.79886647,  0.55499092,  0.71348373,
        0.42769855]), 'targetState': array([25., 25., 15.])}
episode index:1786
target thresh 24.720363221123286
model initialize at round 1786
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08449523, 14.92543773,  0.99358387,  0.08480111,
       -0.07483219]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.39893790354236797
{'scaleFactor': 20, 'currentState': array([ 8.07805049e+00,  2.48282089e+01, -1.50455322e+01, -8.08441236e-02,
       -7.03338374e-03, -9.96701941e-01]), 'targetState': array([25., 25., 15.])}
episode index:1787
target thresh 24.72789080841554
model initialize at round 1787
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12118411, 14.84627329,  0.98100737,  0.12008334,
       -0.15233034]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.3992360732539813
{'scaleFactor': 20, 'currentState': array([29.28172906, 20.55658569, 16.78900608,  0.72302727,  0.50520379,
        0.4711695 ]), 'targetState': array([25., 25., 15.])}
episode index:1788
target thresh 24.7354176429867
model initialize at round 1788
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.04786969, 15.01734442,  0.99868013,  0.0482894 ,
        0.0174965 ]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.39901291167027314
{'scaleFactor': 20, 'currentState': array([ 2.77681397e+01,  2.99845140e+01,  7.96081592e+01, -1.23878663e-02,
       -8.83739675e-01,  4.67814844e-01]), 'targetState': array([25., 25., 15.])}
episode index:1789
target thresh 24.742943724912024
model initialize at round 1789
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.98210923,  0.98800034,  0.1534162 ,
       -0.01785463]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3993212787866026
{'scaleFactor': 20, 'currentState': array([25.16185067, 20.02692877, 16.90983032,  0.52588528,  0.74047664,
        0.41849615]), 'targetState': array([25., 25., 15.])}
episode index:1790
target thresh 24.750469054266798
model initialize at round 1790
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87089231,  0.98005358,  0.15218223,
       -0.12781056]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.39962930155104337
{'scaleFactor': 20, 'currentState': array([25.31127317, 20.1220129 , 15.267976  ,  0.55492197,  0.75246662,
        0.35476132]), 'targetState': array([25., 25., 15.])}
episode index:1791
target thresh 24.75799363112626
model initialize at round 1791
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.90443393,  0.98369273,  0.15274732,
       -0.09495722]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3999369805400774
{'scaleFactor': 20, 'currentState': array([ 2.53452488e+01,  2.01818828e+01,  1.40010893e+01,  6.00038800e-01,
        7.99939560e-01, -7.08083316e-03]), 'targetState': array([25., 25., 15.])}
episode index:1792
target thresh 24.765517455565657
model initialize at round 1792
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4002443163289006
{'scaleFactor': 20, 'currentState': array([25.37217122, 20.06076066, 13.56727341,  0.66899498,  0.73348794,
        0.12017136]), 'targetState': array([25., 25., 15.])}
episode index:1793
target thresh 24.77304052766023
model initialize at round 1793
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13965439, 14.87263762,  0.98225862,  0.13856236,
       -0.12636646]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.400546008543545
{'scaleFactor': 20, 'currentState': array([26.73515608, 20.79818086, 17.02173054,  0.49003365,  0.69495297,
        0.52621991]), 'targetState': array([25., 25., 15.])}
episode index:1794
target thresh 24.7805628474852
model initialize at round 1794
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14146285, 15.02628727,  0.98960287,  0.14140611,
        0.02627672]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.40084736461087506
{'scaleFactor': 20, 'currentState': array([26.17732311, 21.49984816, 17.88885584,  0.39341005,  0.79404278,
        0.46338386]), 'targetState': array([25., 25., 15.])}
episode index:1795
target thresh 24.788084415115808
model initialize at round 1795
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4011536801372053
{'scaleFactor': 20, 'currentState': array([25.31301667, 20.11580766, 15.43252487,  0.55509875,  0.75258206,
        0.35423949]), 'targetState': array([25., 25., 15.])}
episode index:1796
target thresh 24.79560523062725
model initialize at round 1796
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14993027, 14.85537207,  0.97857035,  0.1481993 ,
       -0.14295819]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4014596547447528
{'scaleFactor': 20, 'currentState': array([25.27893657, 20.03961186, 15.95749056,  0.54181491,  0.73949317,
        0.39948273]), 'targetState': array([25., 25., 15.])}
episode index:1797
target thresh 24.80312529409474
model initialize at round 1797
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4017652890023475
{'scaleFactor': 20, 'currentState': array([25.29794828, 20.10199521, 15.51598431,  0.54678826,  0.74521449,
        0.38167783]), 'targetState': array([25., 25., 15.])}
episode index:1798
target thresh 24.81064460559349
model initialize at round 1798
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.98040901,  0.98796899,  0.15341133,
       -0.0195508 ]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.40207058347755464
{'scaleFactor': 20, 'currentState': array([25.1791693 , 20.03664753, 16.80852493,  0.52983471,  0.74225672,
        0.41028056]), 'targetState': array([25., 25., 15.])}
episode index:1799
target thresh 24.81816316519869
model initialize at round 1799
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.93480767,  0.98607244,  0.15311684,
       -0.0649337 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4023702554586232
{'scaleFactor': 20, 'currentState': array([25.97983108, 21.47535942, 17.96130724,  0.33943572,  0.73919266,
        0.58170233]), 'targetState': array([25., 25., 15.])}
episode index:1800
target thresh 24.82568097298552
model initialize at round 1800
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.97282867,  0.98779465,  0.15338426,
       -0.02711081]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4026695946557039
{'scaleFactor': 20, 'currentState': array([26.62960519, 21.33686726, 17.25201522,  0.53265613,  0.78189182,
        0.32391762]), 'targetState': array([25., 25., 15.])}
episode index:1801
target thresh 24.83319802902916
model initialize at round 1801
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.40297387903708254
{'scaleFactor': 20, 'currentState': array([25.3798918 , 20.10007193, 15.2892931 ,  0.61241093,  0.76570852,
        0.19657902]), 'targetState': array([25., 25., 15.])}
episode index:1802
target thresh 24.84071433340477
model initialize at round 1802
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08004532, 14.84627329,  0.98501896,  0.07964258,
       -0.15295326]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.4032673296576427
{'scaleFactor': 20, 'currentState': array([28.79237605, 20.97800599, 16.42626072,  0.47047572,  0.6939286 ,
        0.5450832 ]), 'targetState': array([25., 25., 15.])}
episode index:1803
target thresh 24.84822988618752
model initialize at round 1803
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.05259915,  0.9867988 ,  0.15322963,
        0.05242907]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.40356567379275543
{'scaleFactor': 20, 'currentState': array([26.26893076, 21.16933567, 18.60065412,  0.47048831,  0.70933029,
        0.52487264]), 'targetState': array([25., 25., 15.])}
episode index:1804
target thresh 24.855744687452574
model initialize at round 1804
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12188691, 14.96029902,  0.99172085,  0.12209877,
       -0.03976999]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.40386368735264916
{'scaleFactor': 20, 'currentState': array([27.51813315, 20.18948088, 16.28383972,  0.66058563,  0.66052005,
        0.35684715]), 'targetState': array([25., 25., 15.])}
episode index:1805
target thresh 24.863258737275086
model initialize at round 1805
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15254778, 14.84627329,  0.9768984 ,  0.15052897,
       -0.1516923 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4041613708864522
{'scaleFactor': 20, 'currentState': array([26.61667395, 21.15493595, 16.17495839,  0.47150936,  0.73479996,
        0.48759404]), 'targetState': array([25., 25., 15.])}
episode index:1806
target thresh 24.87077203573017
model initialize at round 1806
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13044394, 14.97997316,  0.99123153,  0.13060621,
       -0.02005175]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.40445872494207724
{'scaleFactor': 20, 'currentState': array([26.73419223, 20.93744186, 17.19766453,  0.47741852,  0.77481409,
        0.41440884]), 'targetState': array([25., 25., 15.])}
episode index:1807
target thresh 24.878284582892974
model initialize at round 1807
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.8569766 ,  0.97824005,  0.15190063,
       -0.14132446]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.40476100996694336
{'scaleFactor': 20, 'currentState': array([25.30811791, 20.05574253, 15.93476912,  0.58598683,  0.72857986,
        0.35467001]), 'targetState': array([25., 25., 15.])}
episode index:1808
target thresh 24.88579637883863
model initialize at round 1808
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.03805826, 14.85384589,  0.98856295,  0.03800302,
       -0.14594196]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.4050524993743177
{'scaleFactor': 20, 'currentState': array([29.27692377, 20.18271663, 16.06073245,  0.5456922 ,  0.70109938,
        0.45899856]), 'targetState': array([25., 25., 15.])}
episode index:1809
target thresh 24.89330742364224
model initialize at round 1809
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15307086, 14.91211074,  0.98447526,  0.15221664,
       -0.08739879]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4053488682417357
{'scaleFactor': 20, 'currentState': array([26.71343215, 21.19230774, 16.94703892,  0.54738046,  0.73846142,
        0.39376309]), 'targetState': array([25., 25., 15.])}
episode index:1810
target thresh 24.900817717378942
model initialize at round 1810
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12625533, 14.84627329,  0.98040357,  0.12503149,
       -0.15223658]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.4051250422515415
{'scaleFactor': 20, 'currentState': array([51.61582819, 24.23955381, 79.88320958,  0.78778893, -0.55345552,
        0.27032499]), 'targetState': array([25., 25., 15.])}
episode index:1811
target thresh 24.908327260123798
model initialize at round 1811
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.0719952 , 14.84627329,  0.98561626,  0.0716764 ,
       -0.153046  ]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.4054158481597399
{'scaleFactor': 20, 'currentState': array([29.01662275, 21.12334895, 13.65132121,  0.63322575,  0.73453828,
        0.24388249]), 'targetState': array([25., 25., 15.])}
episode index:1812
target thresh 24.915836051951946
model initialize at round 1812
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.49834748e+01,  1.48462733e+01,  9.88023469e-01,
       -1.64921914e-02, -1.53419793e-01]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.4051922321375889
{'scaleFactor': 20, 'currentState': array([ 5.61930088e+01,  2.18446525e+01,  7.18437264e+01, -2.35696441e-01,
        4.76403324e-02,  9.70658326e-01]), 'targetState': array([25., 25., 15.])}
episode index:1813
target thresh 24.923344092938436
model initialize at round 1813
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.96001193,  0.98737169,  0.15331858,
       -0.0398819 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.40548787046022583
{'scaleFactor': 20, 'currentState': array([26.01104509, 21.59186855, 17.99056979,  0.39972756,  0.83657404,
        0.37464885]), 'targetState': array([25., 25., 15.])}
episode index:1814
target thresh 24.93085138315838
model initialize at round 1814
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.90692902,  0.98392136,  0.15278282,
       -0.09249952]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4057884226252064
{'scaleFactor': 20, 'currentState': array([25.29594166, 20.07179662, 16.09713277,  0.56350377,  0.75712835,
        0.33048476]), 'targetState': array([25., 25., 15.])}
episode index:1815
target thresh 24.938357922686837
model initialize at round 1815
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14671658, 14.85268098,  0.97865051,  0.1450346 ,
       -0.14563013]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.40608864378560006
{'scaleFactor': 20, 'currentState': array([25.34114199, 20.0371853 , 15.6880537 ,  0.55509962,  0.74454086,
        0.37084138]), 'targetState': array([25., 25., 15.])}
episode index:1816
target thresh 24.94586371159887
model initialize at round 1816
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87715394,  0.98081209,  0.15230001,
       -0.12170596]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.40638330064064426
{'scaleFactor': 20, 'currentState': array([26.200461  , 21.452313  , 17.66641585,  0.42469525,  0.73928011,
        0.52258862]), 'targetState': array([25., 25., 15.])}
episode index:1817
target thresh 24.953368749969542
model initialize at round 1817
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.9740663 ,  0.98782697,  0.15338928,
       -0.02587678]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4066776333407324
{'scaleFactor': 20, 'currentState': array([26.48133802, 21.44502837, 17.08664029,  0.4515095 ,  0.77232822,
        0.44682021]), 'targetState': array([25., 25., 15.])}
episode index:1818
target thresh 24.96087303787389
model initialize at round 1818
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89916754,  0.98319085,  0.15266939,
       -0.10013894]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4069768705131125
{'scaleFactor': 20, 'currentState': array([25.17845986, 20.02342535, 16.5618837 ,  0.52461223,  0.73636955,
        0.42724922]), 'targetState': array([25., 25., 15.])}
episode index:1819
target thresh 24.968376575386962
model initialize at round 1819
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11102116, 14.95916972,  0.99293708,  0.11135053,
       -0.04095141]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.40726538066552675
{'scaleFactor': 20, 'currentState': array([28.89696172, 21.13376388, 17.9177562 ,  0.64986946,  0.63900202,
        0.41151683]), 'targetState': array([25., 25., 15.])}
episode index:1820
target thresh 24.975879362583818
model initialize at round 1820
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.07911684, 14.95412596,  0.99576025,  0.07957718,
       -0.04614096]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4075587440750465
{'scaleFactor': 20, 'currentState': array([26.90301895, 21.03222298, 15.94811085,  0.53601896,  0.83270318,
        0.13888515]), 'targetState': array([25., 25., 15.])}
episode index:1821
target thresh 24.98338139953946
model initialize at round 1821
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.40785700494542243
{'scaleFactor': 20, 'currentState': array([25.33476867, 20.16360488, 14.67580083,  0.57830922,  0.77465259,
        0.25587461]), 'targetState': array([25., 25., 15.])}
episode index:1822
target thresh 24.99088268632892
model initialize at round 1822
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.91185816,  0.9843557 ,  0.15285026,
       -0.08763932]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.40814972197474525
{'scaleFactor': 20, 'currentState': array([26.59022569, 21.27628773, 17.1186075 ,  0.53727077,  0.72951133,
        0.4232651 ]), 'targetState': array([25., 25., 15.])}
episode index:1823
target thresh 24.998383223027197
model initialize at round 1823
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11604684, 14.8683472 ,  0.98464854,  0.11541955,
       -0.13094115]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.40844211804241315
{'scaleFactor': 20, 'currentState': array([26.4997129 , 21.30119456, 16.77976555,  0.44274204,  0.8047971 ,
        0.39532406]), 'targetState': array([25., 25., 15.])}
episode index:1824
target thresh 25.005883009709308
model initialize at round 1824
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.40873419367603425
{'scaleFactor': 20, 'currentState': array([26.38264526, 21.52440929, 16.68477415,  0.43097989,  0.80406783,
        0.40955006]), 'targetState': array([25., 25., 15.])}
episode index:1825
target thresh 25.01338204645026
model initialize at round 1825
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.40902079343191106
{'scaleFactor': 20, 'currentState': array([29.45163689, 20.66643362, 16.92898802,  0.8045157 ,  0.50262618,
        0.31641969]), 'targetState': array([25., 25., 15.])}
episode index:1826
target thresh 25.020880333325024
model initialize at round 1826
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08716232, 14.84627329,  0.98443927,  0.08667273,
       -0.15286324]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.4087969177923752
{'scaleFactor': 20, 'currentState': array([42.33454896, 16.62788756, 41.66208439,  0.70752168,  0.33772778,
        0.62076808]), 'targetState': array([25., 25., 15.])}
episode index:1827
target thresh 25.02837787040858
model initialize at round 1827
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.03724921, 14.86592062,  0.99026504,  0.03725919,
       -0.13411528]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.4085732870933641
{'scaleFactor': 20, 'currentState': array([ 2.52753793e+01,  2.64390918e+01,  6.50290228e+01,  9.27558222e-01,
       -3.70104501e-01, -5.15597002e-02]), 'targetState': array([25., 25., 15.])}
episode index:1828
target thresh 25.035874657775935
model initialize at round 1828
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.90042491,  0.98331305,  0.15268836,
       -0.09890251]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.40886985175318186
{'scaleFactor': 20, 'currentState': array([25.3610581 , 20.14923846, 15.35851257,  0.58486339,  0.78262481,
        0.21315071]), 'targetState': array([25., 25., 15.])}
episode index:1829
target thresh 25.04337069550202
model initialize at round 1829
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4091660922986173
{'scaleFactor': 20, 'currentState': array([25.3491496 , 20.17379377, 14.51290285,  0.58808291,  0.78454963,
        0.19657154]), 'targetState': array([25., 25., 15.])}
episode index:1830
target thresh 25.050865983661808
model initialize at round 1830
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.40945167354144
{'scaleFactor': 20, 'currentState': array([29.24981226, 21.14487524, 16.56668524,  0.71434112,  0.60726355,
        0.34777544]), 'targetState': array([25., 25., 15.])}
episode index:1831
target thresh 25.05836052233027
model initialize at round 1831
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.06166079, 14.88885705,  0.99185909,  0.06177658,
       -0.11135166]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.409736943014347
{'scaleFactor': 20, 'currentState': array([29.21108395, 20.59164257, 16.44541768,  0.54870205,  0.72465587,
        0.41689319]), 'targetState': array([25., 25., 15.])}
episode index:1832
target thresh 25.065854311582324
model initialize at round 1832
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13064969, 14.84627329,  0.97986129,  0.12931169,
       -0.15215237]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4100270375077385
{'scaleFactor': 20, 'currentState': array([26.61369283, 21.60800745, 15.2002629 ,  0.48896285,  0.86572524,
        0.10693526]), 'targetState': array([25., 25., 15.])}
episode index:1833
target thresh 25.073347351492934
model initialize at round 1833
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.41031168216989733
{'scaleFactor': 20, 'currentState': array([29.73381465, 20.50423132, 15.05817578,  0.896234  ,  0.39154789,
        0.20845833]), 'targetState': array([25., 25., 15.])}
episode index:1834
target thresh 25.080839642137008
model initialize at round 1834
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09974303, 14.84627329,  0.98329682,  0.09906768,
       -0.15268584]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4106011472746554
{'scaleFactor': 20, 'currentState': array([27.53304367, 20.04219184, 14.3726683 ,  0.65720005,  0.72786872,
        0.19569167]), 'targetState': array([25., 25., 15.])}
episode index:1835
target thresh 25.088331183589474
model initialize at round 1835
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.1345136 , 14.84627329,  0.97936992,  0.13306927,
       -0.15207607]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.41089029705794855
{'scaleFactor': 20, 'currentState': array([26.49762208, 21.37264875, 16.01162255,  0.45191659,  0.76598261,
        0.45721115]), 'targetState': array([25., 25., 15.])}
episode index:1836
target thresh 25.095821975925258
model initialize at round 1836
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10182324, 14.94674346,  0.99333114,  0.10216585,
       -0.05343574]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.41066662242699703
{'scaleFactor': 20, 'currentState': array([ 3.83609042e+01,  5.92852569e+00,  5.93652080e+01,  9.76230519e-01,
       -2.12036557e-01, -4.48828733e-02]), 'targetState': array([25., 25., 15.])}
episode index:1837
target thresh 25.10331201921926
model initialize at round 1837
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08840628, 14.84627329,  0.98433299,  0.08790022,
       -0.15284674]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.41095029964434204
{'scaleFactor': 20, 'currentState': array([29.41109835, 20.3568188 , 16.3752004 ,  0.67429919,  0.65669305,
        0.33774967]), 'targetState': array([25., 25., 15.])}
episode index:1838
target thresh 25.11080131354637
model initialize at round 1838
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09064003, 14.84627329,  0.98413845,  0.09010337,
       -0.15281653]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4112387878715071
{'scaleFactor': 20, 'currentState': array([27.17087997, 20.37457719, 15.85799087,  0.57101987,  0.74972153,
        0.33444572]), 'targetState': array([25., 25., 15.])}
episode index:1839
target thresh 25.118289858981512
model initialize at round 1839
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.07149044, 14.87432058,  0.98950231,  0.0714545 ,
       -0.12561624]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.41152696252451226
{'scaleFactor': 20, 'currentState': array([27.44505081, 20.07312613, 15.57932796,  0.59889405,  0.73685733,
        0.31363543]), 'targetState': array([25., 25., 15.])}
episode index:1840
target thresh 25.125777655599535
model initialize at round 1840
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.41180971015372597
{'scaleFactor': 20, 'currentState': array([29.46995319, 20.9455066 , 16.18953165,  0.81756025,  0.4771552 ,
        0.32236339]), 'targetState': array([25., 25., 15.])}
episode index:1841
target thresh 25.133264703475355
model initialize at round 1841
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.97557495, 14.87649634,  0.99201099, -0.02447467,
       -0.12375453]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.41158614353583584
{'scaleFactor': 20, 'currentState': array([57.46708214, 15.00826425, 78.01522804,  0.63808973, -0.66263592,
        0.39211622]), 'targetState': array([25., 25., 15.])}
episode index:1842
target thresh 25.140751002683803
model initialize at round 1842
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10470343, 14.88868317,  0.98829457,  0.10452306,
       -0.11112506]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4118736606307165
{'scaleFactor': 20, 'currentState': array([27.52172999, 20.23060732, 14.69313787,  0.64131302,  0.74579677,
        0.18029086]), 'targetState': array([25., 25., 15.])}
episode index:1843
target thresh 25.148236553299764
model initialize at round 1843
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4121608658849303
{'scaleFactor': 20, 'currentState': array([26.91584822, 21.23867996, 15.24604604,  0.53484971,  0.79867156,
        0.27578891]), 'targetState': array([25., 25., 15.])}
episode index:1844
target thresh 25.155721355398097
model initialize at round 1844
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84722367,  0.97686521,  0.15168714,
       -0.15074938]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.41245291422314984
{'scaleFactor': 20, 'currentState': array([25.42847824, 20.06705219, 15.11248881,  0.63721301,  0.75174828,
        0.16980606]), 'targetState': array([25., 25., 15.])}
episode index:1845
target thresh 25.163205409053635
model initialize at round 1845
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15148418, 14.84627329,  0.97705223,  0.14950299,
       -0.15171618]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.41273949452389624
{'scaleFactor': 20, 'currentState': array([26.71684341, 21.3436643 , 15.29094135,  0.47347921,  0.78788474,
        0.39377033]), 'targetState': array([25., 25., 15.])}
episode index:1846
target thresh 25.170688714341228
model initialize at round 1846
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.92705837,  0.98554927,  0.1530356 ,
       -0.07261371]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4130309133411004
{'scaleFactor': 20, 'currentState': array([25.29054297, 20.10162355, 16.28862925,  0.55496554,  0.75710642,
        0.34467828]), 'targetState': array([25., 25., 15.])}
episode index:1847
target thresh 25.178171271335703
model initialize at round 1847
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87435295,  0.98047724,  0.15224802,
       -0.12443846]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4133220167699743
{'scaleFactor': 20, 'currentState': array([25.38301699, 20.06927495, 15.71976006,  0.57210461,  0.75020786,
        0.33148829]), 'targetState': array([25., 25., 15.])}
episode index:1848
target thresh 25.1856530801119
model initialize at round 1848
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14285015, 14.97998281,  0.98955141,  0.14278542,
       -0.02000812]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4136076620553345
{'scaleFactor': 20, 'currentState': array([26.89697397, 21.05420786, 17.00852936,  0.60987423,  0.71334949,
        0.34523315]), 'targetState': array([25., 25., 15.])}
episode index:1849
target thresh 25.193134140744622
model initialize at round 1849
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.06727632, 14.8837122 ,  0.99091754,  0.06733867,
       -0.11639557]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.41389299853498074
{'scaleFactor': 20, 'currentState': array([27.15597404, 20.45515881, 16.00554304,  0.55922266,  0.75199583,
        0.34895885]), 'targetState': array([25., 25., 15.])}
episode index:1850
target thresh 25.200614453308688
model initialize at round 1850
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12900865, 14.87682416,  0.98415401,  0.12824685,
       -0.12244848]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4141780267094086
{'scaleFactor': 20, 'currentState': array([27.77657189, 20.04683219, 15.83539218,  0.84678662,  0.48461936,
        0.21930913]), 'targetState': array([25., 25., 15.])}
episode index:1851
target thresh 25.208094017878892
model initialize at round 1851
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.04711837, 14.93503342,  0.99673032,  0.0474387 ,
       -0.06540824]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.413954388466045
{'scaleFactor': 20, 'currentState': array([35.53098644, 37.59548302, 77.07351907, -0.5677373 , -0.48381884,
        0.6660283 ]), 'targetState': array([25., 25., 15.])}
episode index:1852
target thresh 25.215572834530043
model initialize at round 1852
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.41424420803508655
{'scaleFactor': 20, 'currentState': array([25.35080467, 20.15382708, 15.02286121,  0.58229184,  0.77918936,
        0.23194858]), 'targetState': array([25., 25., 15.])}
episode index:1853
target thresh 25.22305090333692
model initialize at round 1853
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89457253,  0.98273164,  0.15259808,
       -0.10465345]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4145337149616588
{'scaleFactor': 20, 'currentState': array([25.3067982 , 20.10823005, 15.80461724,  0.56273938,  0.76412258,
        0.31534278]), 'targetState': array([25., 25., 15.])}
episode index:1854
target thresh 25.230528224374304
model initialize at round 1854
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.41482290975138303
{'scaleFactor': 20, 'currentState': array([25.34787414, 20.13774363, 15.24009467,  0.57655295,  0.77353599,
        0.26311362]), 'targetState': array([25., 25., 15.])}
episode index:1855
target thresh 25.23800479771697
model initialize at round 1855
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4151117929087907
{'scaleFactor': 20, 'currentState': array([25.32432903, 20.18454425, 14.00624505,  0.59789214,  0.79841436,
        0.07113012]), 'targetState': array([25., 25., 15.])}
episode index:1856
target thresh 25.245480623439676
model initialize at round 1856
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4153952438277418
{'scaleFactor': 20, 'currentState': array([26.70741453, 21.4969394 , 14.30655791,  0.5262135 ,  0.8110126 ,
        0.25565195]), 'targetState': array([25., 25., 15.])}
episode index:1857
target thresh 25.252955701617196
model initialize at round 1857
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.41568350798601533
{'scaleFactor': 20, 'currentState': array([25.17963593, 20.13664917, 12.80413847,  0.58538993,  0.79688386,
       -0.14931422]), 'targetState': array([25., 25., 15.])}
episode index:1858
target thresh 25.260430032324265
model initialize at round 1858
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10444366, 14.84627329,  0.98283163,  0.10368741,
       -0.15261361]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.41596128197198684
{'scaleFactor': 20, 'currentState': array([29.22150036, 20.91797762, 15.99221068,  0.69305532,  0.66279432,
        0.28351017]), 'targetState': array([25., 25., 15.])}
episode index:1859
target thresh 25.267903615635646
model initialize at round 1859
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.50162119e+01,  1.48462733e+01,  9.88028516e-01,
        1.61795676e-02, -1.53420577e-01]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.41573764687415243
{'scaleFactor': 20, 'currentState': array([ 7.93133187e+01,  2.12092466e+01,  6.29601109e+01, -3.28918809e-02,
        5.40534490e-01,  8.40678648e-01]), 'targetState': array([25., 25., 15.])}
episode index:1860
target thresh 25.275376451626062
model initialize at round 1860
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.1203614 , 14.93882582,  0.99082811,  0.12046208,
       -0.06122535]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4160201522489653
{'scaleFactor': 20, 'currentState': array([27.12065036, 20.83822726, 16.35384074,  0.6565002 ,  0.69602293,
        0.29079128]), 'targetState': array([25., 25., 15.])}
episode index:1861
target thresh 25.282848540370228
model initialize at round 1861
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.05925603, 14.86419741,  0.98898502,  0.05919528,
       -0.13566336]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.4157967257439981
{'scaleFactor': 20, 'currentState': array([ 2.22228224, 14.86469357,  8.97424741,  0.84669334, -0.4962106 ,
       -0.19205579]), 'targetState': array([25., 25., 15.])}
episode index:1862
target thresh 25.290319881942892
model initialize at round 1862
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11389085, 15.04380559,  0.99248928,  0.11417722,
        0.04391574]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.4160738425567534
{'scaleFactor': 20, 'currentState': array([28.96168915, 21.092838  , 17.61938232,  0.54729644,  0.71535179,
        0.43444036]), 'targetState': array([25., 25., 15.])}
episode index:1863
target thresh 25.297790476418747
model initialize at round 1863
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.9667318 ,  0.98761351,  0.15335614,
       -0.03318801]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.41636081477099335
{'scaleFactor': 20, 'currentState': array([25.35822214, 20.10295261, 15.86349889,  0.59442158,  0.75142052,
        0.28640913]), 'targetState': array([25., 25., 15.])}
episode index:1864
target thresh 25.305260323872503
model initialize at round 1864
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10888329, 14.84830473,  0.98267346,  0.10807749,
       -0.15057265]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.4161375650043601
{'scaleFactor': 20, 'currentState': array([ 3.57790665e+01,  4.15872507e+00,  4.37045459e+01,  9.98453044e-01,
       -4.78596668e-02,  2.83014228e-02]), 'targetState': array([25., 25., 15.])}
episode index:1865
target thresh 25.312729424378865
model initialize at round 1865
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.41641909907959945
{'scaleFactor': 20, 'currentState': array([26.59983182, 21.52914764, 15.44579506,  0.47125935,  0.81956204,
        0.32593356]), 'targetState': array([25., 25., 15.])}
episode index:1866
target thresh 25.32019777801252
model initialize at round 1866
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.41670033156504205
{'scaleFactor': 20, 'currentState': array([26.6295712 , 21.51781463, 16.0122799 ,  0.50165704,  0.8028603 ,
        0.3221111 ]), 'targetState': array([25., 25., 15.])}
episode index:1867
target thresh 25.327665384848164
model initialize at round 1867
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86495705,  0.97930154,  0.15206546,
       -0.13358361]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4169863538981978
{'scaleFactor': 20, 'currentState': array([25.31089502, 20.11169424, 15.79246768,  0.57411032,  0.77619297,
        0.26061813]), 'targetState': array([25., 25., 15.])}
episode index:1868
target thresh 25.335132244960445
model initialize at round 1868
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.41726698193217465
{'scaleFactor': 20, 'currentState': array([27.02713118, 21.2971937 , 14.90280848,  0.68905713,  0.69772816,
        0.19589713]), 'targetState': array([25., 25., 15.])}
episode index:1869
target thresh 25.342598358424052
model initialize at round 1869
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10943036, 14.84627329,  0.98231549,  0.10858095,
       -0.15253346]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4175473098292168
{'scaleFactor': 20, 'currentState': array([26.88558048, 21.00394488, 15.39780539,  0.50821628,  0.80164114,
        0.31478197]), 'targetState': array([25., 25., 15.])}
episode index:1870
target thresh 25.350063725313642
model initialize at round 1870
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.88840364,  0.98208407,  0.15249753,
       -0.11070405]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4178324208607886
{'scaleFactor': 20, 'currentState': array([25.40049463, 20.13765124, 15.15368698,  0.60341037,  0.77298144,
        0.19594799]), 'targetState': array([25., 25., 15.])}
episode index:1871
target thresh 25.357528345703873
model initialize at round 1871
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13452583, 14.84627329,  0.97936834,  0.13308115,
       -0.15207583]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.41811214721150447
{'scaleFactor': 20, 'currentState': array([26.45492326, 21.53583768, 16.06721012,  0.43848807,  0.81841282,
        0.37138749]), 'targetState': array([25., 25., 15.])}
episode index:1872
target thresh 25.36499221966939
model initialize at round 1872
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4183966522316265
{'scaleFactor': 20, 'currentState': array([25.25391956, 20.07120108, 15.94857897,  0.54784496,  0.75269106,
        0.36513295]), 'targetState': array([25., 25., 15.])}
episode index:1873
target thresh 25.372455347284816
model initialize at round 1873
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.90454168,  0.98370272,  0.15274887,
       -0.09485112]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.41868085361778895
{'scaleFactor': 20, 'currentState': array([25.25876704, 20.07419806, 16.33265549,  0.54718081,  0.75223728,
        0.36705889]), 'targetState': array([25., 25., 15.])}
episode index:1874
target thresh 25.3799177286248
model initialize at round 1874
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89945015,  0.98321845,  0.15267367,
       -0.09986108]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4189647518558062
{'scaleFactor': 20, 'currentState': array([25.28018498, 20.08656841, 16.06499536,  0.55790811,  0.76227335,
        0.32814307]), 'targetState': array([25., 25., 15.])}
episode index:1875
target thresh 25.387379363763962
model initialize at round 1875
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.51537267e+01,  1.49871631e+01,  9.88076758e-01,
        1.53428068e-01, -1.28119978e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4192432781871202
{'scaleFactor': 20, 'currentState': array([26.67863206, 21.43806372, 16.39453181,  0.55710164,  0.77321673,
        0.30294165]), 'targetState': array([25., 25., 15.])}
episode index:1876
target thresh 25.39484025277693
model initialize at round 1876
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14330335, 14.85092571,  0.97887516,  0.14169302,
       -0.14739911]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.41951649186304985
{'scaleFactor': 20, 'currentState': array([29.87979421, 20.01531747, 16.45760153,  0.88989704,  0.39777726,
        0.22328571]), 'targetState': array([25., 25., 15.])}
episode index:1877
target thresh 25.402300395738287
model initialize at round 1877
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.05557641, 14.89629092,  0.99301125,  0.05574546,
       -0.10402453]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4197944277829316
{'scaleFactor': 20, 'currentState': array([27.01884434, 20.52253937, 16.35200222,  0.51569145,  0.77383705,
        0.36774795]), 'targetState': array([25., 25., 15.])}
episode index:1878
target thresh 25.409759792722642
model initialize at round 1878
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89289084,  0.98255863,  0.15257122,
       -0.10630407]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4200771290187576
{'scaleFactor': 20, 'currentState': array([25.25366213, 20.00794914, 16.46087561,  0.565001  ,  0.72978711,
        0.3849476 ]), 'targetState': array([25., 25., 15.])}
episode index:1879
target thresh 25.4172184438046
model initialize at round 1879
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08314714, 14.91818834,  0.99313002,  0.08341002,
       -0.08207032]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.42035447105087576
{'scaleFactor': 20, 'currentState': array([27.33788946, 20.43099994, 14.26157382,  0.59699038,  0.79176291,
        0.12928255]), 'targetState': array([25., 25., 15.])}
episode index:1880
target thresh 25.42467634905874
model initialize at round 1880
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.42063657396360793
{'scaleFactor': 20, 'currentState': array([25.38688774, 20.12253473, 14.86658669,  0.59521643,  0.77817634,
        0.20039709]), 'targetState': array([25., 25., 15.])}
episode index:1881
target thresh 25.43213350855964
model initialize at round 1881
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4209133240036915
{'scaleFactor': 20, 'currentState': array([26.68058643, 21.50167828, 15.47597113,  0.5215011 ,  0.80446975,
        0.28436777]), 'targetState': array([25., 25., 15.])}
episode index:1882
target thresh 25.439589922381888
model initialize at round 1882
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.06339063, 14.89095422,  0.9919813 ,  0.06351749,
       -0.10926402]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.42068979063990836
{'scaleFactor': 20, 'currentState': array([33.69386253, 16.21454844, 33.40287671,  0.87998875,  0.44456598,
        0.1672749 ]), 'targetState': array([25., 25., 15.])}
episode index:1883
target thresh 25.447045590600027
model initialize at round 1883
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.51537267e+01,  1.49874232e+01,  9.88080012e-01,
        1.53428573e-01, -1.25524027e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.42096621864349704
{'scaleFactor': 20, 'currentState': array([26.52766474, 21.41217601, 17.31682432,  0.52190234,  0.75493529,
        0.39710284]), 'targetState': array([25., 25., 15.])}
episode index:1884
target thresh 25.454500513288615
model initialize at round 1884
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.06874198, 14.97935055,  0.99738208,  0.06925457,
       -0.02080343]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.42123735876512225
{'scaleFactor': 20, 'currentState': array([28.5816127 , 20.65493211, 18.92799009,  0.51819654,  0.77144931,
        0.36924017]), 'targetState': array([25., 25., 15.])}
episode index:1885
target thresh 25.461954690522216
model initialize at round 1885
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14924747, 14.9765506 ,  0.98855545,  0.1490297 ,
       -0.02341519]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4215132032988634
{'scaleFactor': 20, 'currentState': array([26.84553786, 20.99565354, 16.80472595,  0.5324726 ,  0.76591232,
        0.36034878]), 'targetState': array([25., 25., 15.])}
episode index:1886
target thresh 25.46940812237536
model initialize at round 1886
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11323931, 14.85219307,  0.98276884,  0.11241219,
       -0.14672732]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.42178875546955874
{'scaleFactor': 20, 'currentState': array([26.87431131, 20.85638878, 16.35988421,  0.50510418,  0.79228363,
        0.3422812 ]), 'targetState': array([25., 25., 15.])}
episode index:1887
target thresh 25.476860808922574
model initialize at round 1887
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.42206401574176816
{'scaleFactor': 20, 'currentState': array([27.29479319, 20.63720719, 16.19552778,  0.63362888,  0.72224433,
        0.27726803]), 'targetState': array([25., 25., 15.])}
episode index:1888
target thresh 25.484312750238413
model initialize at round 1888
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.88047921,  0.98120026,  0.15236029,
       -0.11845841]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4223440189361346
{'scaleFactor': 20, 'currentState': array([25.31804928, 20.11954079, 15.76702214,  0.57162497,  0.77226045,
        0.27723401]), 'targetState': array([25., 25., 15.])}
episode index:1889
target thresh 25.491763946397374
model initialize at round 1889
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.8853709 ,  0.98175271,  0.15244607,
       -0.11367418]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4226237258308245
{'scaleFactor': 20, 'currentState': array([25.41312625, 20.02319805, 15.88719886,  0.62392329,  0.7244121 ,
        0.29316691]), 'targetState': array([25., 25., 15.])}
episode index:1890
target thresh 25.499214397473967
model initialize at round 1890
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14277698, 14.84627329,  0.97827368,  0.14108583,
       -0.15190585]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.42289810786338405
{'scaleFactor': 20, 'currentState': array([27.72258032, 20.11149211, 14.37492725,  0.70037193,  0.71213076,
        0.0484659 ]), 'targetState': array([25., 25., 15.])}
episode index:1891
target thresh 25.506664103542708
model initialize at round 1891
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4231721998515118
{'scaleFactor': 20, 'currentState': array([27.6002463 , 20.36203126, 15.63889036,  0.71874071,  0.65088511,
        0.24445933]), 'targetState': array([25., 25., 15.])}
episode index:1892
target thresh 25.51411306467809
model initialize at round 1892
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.88116162,  0.98127866,  0.15237246,
       -0.11779148]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4234460022548659
{'scaleFactor': 20, 'currentState': array([26.76004387, 21.28485528, 16.40413003,  0.5654492 ,  0.77316953,
        0.2871865 ]), 'targetState': array([25., 25., 15.])}
episode index:1893
target thresh 25.521561280954607
model initialize at round 1893
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08693486, 14.89345437,  0.99049059,  0.08697794,
       -0.10659843]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.42371951553213416
{'scaleFactor': 20, 'currentState': array([27.14947521, 20.44774287, 16.17068384,  0.54439165,  0.74786297,
        0.37991934]), 'targetState': array([25., 25., 15.])}
episode index:1894
target thresh 25.529008752446735
model initialize at round 1894
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.51537267e+01,  1.49913299e+01,  9.88120863e-01,
        1.53434917e-01, -8.65367459e-03]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.42399775855818583
{'scaleFactor': 20, 'currentState': array([25.2077235 , 20.06550469, 16.82992335,  0.55128102,  0.76384271,
        0.33560921]), 'targetState': array([25., 25., 15.])}
episode index:1895
target thresh 25.536455479228948
model initialize at round 1895
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14422192, 14.9180655 ,  0.98625284,  0.14367603,
       -0.08162438]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.42427069230863035
{'scaleFactor': 20, 'currentState': array([26.84722005, 21.10091419, 16.3816637 ,  0.56000473,  0.74430683,
        0.36387092]), 'targetState': array([25., 25., 15.])}
episode index:1896
target thresh 25.543901461375707
model initialize at round 1896
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11237009, 14.84627329,  0.98200034,  0.11146209,
       -0.15248453]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.4245383753110544
{'scaleFactor': 20, 'currentState': array([29.20191488, 21.02759884, 14.79640697,  0.64046045,  0.70567258,
        0.30304558]), 'targetState': array([25., 25., 15.])}
episode index:1897
target thresh 25.551346698961485
model initialize at round 1897
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.05721332, 14.84627329,  0.98655051,  0.05701397,
       -0.15319107]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.4248057762449827
{'scaleFactor': 20, 'currentState': array([29.36965972, 20.77375401, 13.96289411,  0.63807069,  0.7621501 ,
        0.10951264]), 'targetState': array([25., 25., 15.])}
episode index:1898
target thresh 25.558791192060724
model initialize at round 1898
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11597576, 14.84627329,  0.98160283,  0.11499205,
       -0.1524228 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4250778533240538
{'scaleFactor': 20, 'currentState': array([27.21905072, 20.676086  , 15.14066595,  0.5838489 ,  0.78503656,
        0.20697357]), 'targetState': array([25., 25., 15.])}
episode index:1899
target thresh 25.56623494074788
model initialize at round 1899
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4253546492169885
{'scaleFactor': 20, 'currentState': array([25.35942439, 20.17337215, 14.6456685 ,  0.59360787,  0.79042624,
        0.15118224]), 'targetState': array([25., 25., 15.])}
episode index:1900
target thresh 25.573677945097394
model initialize at round 1900
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4256311538990943
{'scaleFactor': 20, 'currentState': array([25.36789719, 20.12557957, 14.86283842,  0.6039554 ,  0.74839861,
        0.27411201]), 'targetState': array([25., 25., 15.])}
episode index:1901
target thresh 25.581120205183673
model initialize at round 1901
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11590923, 14.98298515,  0.99307113,  0.1162688 ,
       -0.01706764]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.4254073730610821
{'scaleFactor': 20, 'currentState': array([39.07270827, 24.06613676, 34.24423029,  0.36554629,  0.8201169 ,
        0.44020924]), 'targetState': array([25., 25., 15.])}
episode index:1902
target thresh 25.58856172108116
model initialize at round 1902
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85680549,  0.97821666,  0.151897  ,
       -0.14149015]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.425683559438822
{'scaleFactor': 20, 'currentState': array([25.30799801, 20.11195235, 15.57282997,  0.56884836,  0.77007482,
        0.2887842 ]), 'targetState': array([25., 25., 15.])}
episode index:1903
target thresh 25.596002492864255
model initialize at round 1903
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4259594557048205
{'scaleFactor': 20, 'currentState': array([25.38803941, 20.13815442, 14.77092175,  0.62284534,  0.76312671,
        0.17234068]), 'targetState': array([25., 25., 15.])}
episode index:1904
target thresh 25.603442520607388
model initialize at round 1904
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12374714, 14.84627329,  0.98070516,  0.12258531,
       -0.15228341]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.42623007024219384
{'scaleFactor': 20, 'currentState': array([26.95364614, 20.92927276, 15.10737824,  0.516247  ,  0.77124834,
        0.37237755]), 'targetState': array([25., 25., 15.])}
episode index:1905
target thresh 25.61088180438493
model initialize at round 1905
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.07272496, 14.88402398,  0.99057502,  0.0727672 ,
       -0.11604338]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.4260064448118464
{'scaleFactor': 20, 'currentState': array([ 4.92635593e+01,  2.39163219e+01,  5.11269285e+01,  8.70896338e-01,
        4.91463394e-01, -1.81656602e-03]), 'targetState': array([25., 25., 15.])}
episode index:1906
target thresh 25.618320344271307
model initialize at round 1906
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86758361,  0.9796383 ,  0.15211775,
       -0.13103047]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.42627181392726077
{'scaleFactor': 20, 'currentState': array([29.21713036, 21.27894132, 15.08656048,  0.63974831,  0.75892782,
        0.12145235]), 'targetState': array([25., 25., 15.])}
episode index:1907
target thresh 25.62575814034088
model initialize at round 1907
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08034985, 14.84627329,  0.98499515,  0.07994365,
       -0.15294956]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.4265369048779839
{'scaleFactor': 20, 'currentState': array([28.37248233, 21.49935042, 17.06372698,  0.44125453,  0.79394219,
        0.41827054]), 'targetState': array([25., 25., 15.])}
episode index:1908
target thresh 25.633195192668033
model initialize at round 1908
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87522303,  0.98058203,  0.15226429,
       -0.12358995]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.426811631512359
{'scaleFactor': 20, 'currentState': array([25.37523185, 20.16905432, 14.81569623,  0.58867545,  0.78389293,
        0.19741602]), 'targetState': array([25., 25., 15.])}
episode index:1909
target thresh 25.640631501327128
model initialize at round 1909
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4270860704748657
{'scaleFactor': 20, 'currentState': array([25.33636641, 20.09941696, 15.60057111,  0.57741112,  0.77110859,
        0.26830568]), 'targetState': array([25., 25., 15.])}
episode index:1910
target thresh 25.648067066392557
model initialize at round 1910
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.42736022221710807
{'scaleFactor': 20, 'currentState': array([25.33514955, 20.18038897, 14.23688378,  0.58890312,  0.78612603,
        0.1876139 ]), 'targetState': array([25., 25., 15.])}
episode index:1911
target thresh 25.655501887938637
model initialize at round 1911
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.91071127,  0.9842567 ,  0.15283489,
       -0.08877074]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.42763408718974555
{'scaleFactor': 20, 'currentState': array([25.32868514, 20.11025975, 15.64224494,  0.56463696,  0.75803123,
        0.32645635]), 'targetState': array([25., 25., 15.])}
episode index:1912
target thresh 25.662935966039747
model initialize at round 1912
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.94815139,  0.98683723,  0.1532356 ,
       -0.05168297]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4279026946451618
{'scaleFactor': 20, 'currentState': array([26.67732868, 21.3003593 , 16.58112829,  0.51971261,  0.7764536 ,
        0.3563967 ]), 'targetState': array([25., 25., 15.])}
episode index:1913
target thresh 25.67036930077021
model initialize at round 1913
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13051628, 14.91491778,  0.9878422 ,  0.13023181,
       -0.08489677]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.4281661025099799
{'scaleFactor': 20, 'currentState': array([29.11821154, 21.05843263, 16.89232437,  0.6263831 ,  0.66329356,
        0.40949464]), 'targetState': array([25., 25., 15.])}
episode index:1914
target thresh 25.677801892204364
model initialize at round 1914
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11344355, 14.92664078,  0.99081726,  0.1135372 ,
       -0.07341978]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.42842923527520027
{'scaleFactor': 20, 'currentState': array([28.80749239, 21.33852602, 16.28726292,  0.50292519,  0.79438075,
        0.34062512]), 'targetState': array([25., 25., 15.])}
episode index:1915
target thresh 25.685233740416546
model initialize at round 1915
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14817771, 14.86041422,  0.97950652,  0.1466071 ,
       -0.13810625]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4286970071510488
{'scaleFactor': 20, 'currentState': array([26.64276393, 21.43795372, 15.94835492,  0.47122744,  0.80277682,
        0.36536841]), 'targetState': array([25., 25., 15.])}
episode index:1916
target thresh 25.69266484548105
model initialize at round 1916
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15068317, 14.92320819,  0.98572022,  0.15003177,
       -0.07645984]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4289644996613513
{'scaleFactor': 20, 'currentState': array([26.3952091 , 21.31688109, 17.44724955,  0.42385835,  0.77696755,
        0.46547344]), 'targetState': array([25., 25., 15.])}
episode index:1917
target thresh 25.700095207472216
model initialize at round 1917
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.51392835e+01, 1.50000509e+01, 9.90247651e-01,
       1.39318298e-01, 5.09030650e-05]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.42922680458744394
{'scaleFactor': 20, 'currentState': array([29.33068131, 20.80927007, 17.59586131,  0.79109097,  0.52865963,
        0.30772401]), 'targetState': array([25., 25., 15.])}
episode index:1918
target thresh 25.707524826464322
model initialize at round 1918
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.04844719, 14.93727521,  0.99681079,  0.04878048,
       -0.06315631]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.4290031324641571
{'scaleFactor': 20, 'currentState': array([38.06678961, 25.86425376, 64.73328471,  0.76244183, -0.59121743,
       -0.26295323]), 'targetState': array([25., 25., 15.])}
episode index:1919
target thresh 25.714953702531684
model initialize at round 1919
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14480318, 14.84627329,  0.9779955 ,  0.14304733,
       -0.15186266]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.429270047577145
{'scaleFactor': 20, 'currentState': array([26.79914256, 21.50442788, 14.83406434,  0.57179048,  0.80451199,
        0.16067391]), 'targetState': array([25., 25., 15.])}
episode index:1920
target thresh 25.722381835748585
model initialize at round 1920
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09045107, 14.84627329,  0.98415509,  0.08991705,
       -0.15281911]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.42953178380844637
{'scaleFactor': 20, 'currentState': array([29.14014065, 21.13306756, 15.43412232,  0.6314573 ,  0.7498906 ,
        0.19729616]), 'targetState': array([25., 25., 15.])}
episode index:1921
target thresh 25.729809226189293
model initialize at round 1921
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.42979814612144973
{'scaleFactor': 20, 'currentState': array([27.05951679, 21.0788999 , 13.88145218,  0.58719171,  0.79606321,
        0.14659216]), 'targetState': array([25., 25., 15.])}
episode index:1922
target thresh 25.73723587392811
model initialize at round 1922
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11002698, 14.84627329,  0.98225218,  0.1091659 ,
       -0.15252363]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.4300593355139539
{'scaleFactor': 20, 'currentState': array([29.67856615, 20.13752861, 15.26398829,  0.69540998,  0.63461735,
        0.33714354]), 'targetState': array([25., 25., 15.])}
episode index:1923
target thresh 25.74466177903926
model initialize at round 1923
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85464968,  0.97791975,  0.15185089,
       -0.14357671]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.43032514674778294
{'scaleFactor': 20, 'currentState': array([27.0490985 , 20.80109279, 16.28449826,  0.53924935,  0.76565866,
        0.35068072]), 'targetState': array([25., 25., 15.])}
episode index:1924
target thresh 25.752086941597053
model initialize at round 1924
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.88772871,  0.98201106,  0.15248619,
       -0.1113653 ]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.43059562202214774
{'scaleFactor': 20, 'currentState': array([25.33424974, 20.12900048, 15.6642931 ,  0.57347667,  0.77243887,
        0.27287855]), 'targetState': array([25., 25., 15.])}
episode index:1925
target thresh 25.759511361675692
model initialize at round 1925
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87128435,  0.98010213,  0.15218977,
       -0.12742877]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4308608787861035
{'scaleFactor': 20, 'currentState': array([27.18487482, 20.80124442, 15.98992763,  0.58394702,  0.74718235,
        0.31737109]), 'targetState': array([25., 25., 15.])}
episode index:1926
target thresh 25.76693503934946
model initialize at round 1926
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10031282, 14.93703835,  0.99292009,  0.1006087 ,
       -0.06314736]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.43112586024464783
{'scaleFactor': 20, 'currentState': array([27.30005091, 20.5482049 , 16.14027819,  0.66033233,  0.69438847,
        0.28598227]), 'targetState': array([25., 25., 15.])}
episode index:1927
target thresh 25.774357974692563
model initialize at round 1927
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.07065219, 14.84627329,  0.98570985,  0.07034602,
       -0.15306054]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.43138568363036484
{'scaleFactor': 20, 'currentState': array([29.21987078, 20.35135331, 16.46458882,  0.55906403,  0.73505833,
        0.38358397]), 'targetState': array([25., 25., 15.])}
episode index:1928
target thresh 25.781780167779267
model initialize at round 1928
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13538068, 14.84627329,  0.97925779,  0.1339117 ,
       -0.15205866]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.43164523762947143
{'scaleFactor': 20, 'currentState': array([29.11257541, 21.4501199 , 14.75594977,  0.59772178,  0.80027082,
        0.04790918]), 'targetState': array([25., 25., 15.])}
episode index:1929
target thresh 25.789201618683755
model initialize at round 1929
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4319094007961924
{'scaleFactor': 20, 'currentState': array([27.06779545, 21.08417008, 15.41439162,  0.67385207,  0.69820348,
        0.24173393]), 'targetState': array([25., 25., 15.])}
episode index:1930
target thresh 25.796622327480268
model initialize at round 1930
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11767625, 14.84627329,  0.98141117,  0.11665534,
       -0.15239304]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4321732903604621
{'scaleFactor': 20, 'currentState': array([26.66207921, 21.49758748, 14.02957192,  0.50183492,  0.86453241,
       -0.0273024 ]), 'targetState': array([25., 25., 15.])}
episode index:1931
target thresh 25.80404229424299
model initialize at round 1931
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.43244182905587597
{'scaleFactor': 20, 'currentState': array([25.11135093, 20.14939634, 12.60632049,  0.58263524,  0.80365546,
       -0.12113665]), 'targetState': array([25., 25., 15.])}
episode index:1932
target thresh 25.81146151904614
model initialize at round 1932
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4327100899047348
{'scaleFactor': 20, 'currentState': array([25.31501039, 20.10582324, 15.91352823,  0.57128019,  0.77199962,
        0.27866743]), 'targetState': array([25., 25., 15.])}
episode index:1933
target thresh 25.81888000196392
model initialize at round 1933
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.9250419 ,  0.98540365,  0.15301299,
       -0.07461008]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.43297807333803123
{'scaleFactor': 20, 'currentState': array([25.16217227, 20.0133629 , 16.73930626,  0.51065974,  0.72223231,
        0.46648378]), 'targetState': array([25., 25., 15.])}
episode index:1934
target thresh 25.82629774307048
model initialize at round 1934
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.02533085,  0.98784217,  0.15339164,
        0.02527564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4332457797858669
{'scaleFactor': 20, 'currentState': array([25.17204625, 20.04454911, 17.01110837,  0.5358494 ,  0.75044467,
        0.38690854]), 'targetState': array([25., 25., 15.])}
episode index:1935
target thresh 25.833714742440016
model initialize at round 1935
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.97087254,  0.98774051,  0.15337585,
       -0.02906098]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4335132096774548
{'scaleFactor': 20, 'currentState': array([25.28901077, 20.09440528, 16.22251132,  0.5658919 ,  0.76346712,
        0.31126246]), 'targetState': array([25., 25., 15.])}
episode index:1936
target thresh 25.84113100014671
model initialize at round 1936
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15335144, 14.87278548,  0.98034209,  0.15185542,
       -0.12597348]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4337803634411216
{'scaleFactor': 20, 'currentState': array([25.34115555, 20.12287841, 15.59215065,  0.58003442,  0.77916105,
        0.23763021]), 'targetState': array([25., 25., 15.])}
episode index:1937
target thresh 25.848546516264715
model initialize at round 1937
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4340472415043099
{'scaleFactor': 20, 'currentState': array([25.25991312, 20.06945406, 15.9418663 ,  0.53651128,  0.73885728,
        0.40773222]), 'targetState': array([25., 25., 15.])}
episode index:1938
target thresh 25.85596129086818
model initialize at round 1938
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.98222345,  0.98800235,  0.15341651,
       -0.01774068]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4343138442935805
{'scaleFactor': 20, 'currentState': array([25.28159053, 20.09565002, 16.32961159,  0.55267118,  0.75642734,
        0.34981745]), 'targetState': array([25., 25., 15.])}
episode index:1939
target thresh 25.863375324031256
model initialize at round 1939
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.90297027,  0.98355587,  0.15272607,
       -0.09639815]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.43458017223461476
{'scaleFactor': 20, 'currentState': array([25.27731759, 20.08872314, 16.26657049,  0.56144519,  0.76641392,
        0.3120721 ]), 'targetState': array([25., 25., 15.])}
episode index:1940
target thresh 25.870788615828076
model initialize at round 1940
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.434841326267158
{'scaleFactor': 20, 'currentState': array([27.38201494, 20.77889395, 15.2990356 ,  0.76281884,  0.61300346,
        0.2057527 ]), 'targetState': array([25., 25., 15.])}
episode index:1941
target thresh 25.878201166332794
model initialize at round 1941
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09408351, 14.84627329,  0.98382929,  0.09349708,
       -0.15276852]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.43509736335348126
{'scaleFactor': 20, 'currentState': array([29.64519907, 20.18833768, 15.5846858 ,  0.71358914,  0.54480677,
        0.4404272 ]), 'targetState': array([25., 25., 15.])}
episode index:1942
target thresh 25.88561297561952
model initialize at round 1942
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.49923933e+01,  1.49586043e+01,  9.99097508e-01,
       -7.67658567e-03, -4.17760693e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.4348734326466601
{'scaleFactor': 20, 'currentState': array([42.58289135, 11.59577631, 39.38666216,  0.50560676,  0.74365629,
        0.43742098]), 'targetState': array([25., 25., 15.])}
episode index:1943
target thresh 25.89302404376238
model initialize at round 1943
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12503799, 14.85265279,  0.98147575,  0.12396137,
       -0.1460785 ]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.4351291898047159
{'scaleFactor': 20, 'currentState': array([28.99371749, 21.26892627, 16.09837235,  0.54125157,  0.76587739,
        0.34710022]), 'targetState': array([25., 25., 15.])}
episode index:1944
target thresh 25.90043437083548
model initialize at round 1944
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10188434, 14.85875425,  0.98487681,  0.10135709,
       -0.14051481]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4353895244883129
{'scaleFactor': 20, 'currentState': array([26.88040009, 21.07631265, 14.96343903,  0.5226486 ,  0.79465874,
        0.30879754]), 'targetState': array([25., 25., 15.])}
episode index:1945
target thresh 25.907843956912913
model initialize at round 1945
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85022176,  0.97729687,  0.15175417,
       -0.14785636]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4356544785095934
{'scaleFactor': 20, 'currentState': array([25.27835981, 20.09059048, 15.82354308,  0.55955868,  0.76313527,
        0.32329344]), 'targetState': array([25., 25., 15.])}
episode index:1946
target thresh 25.91525280206879
model initialize at round 1946
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.43591916036444206
{'scaleFactor': 20, 'currentState': array([25.34230931, 20.14231804, 15.11564713,  0.56981954,  0.76576159,
        0.298186  ]), 'targetState': array([25., 25., 15.])}
episode index:1947
target thresh 25.922660906377192
model initialize at round 1947
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.43617868859290027
{'scaleFactor': 20, 'currentState': array([26.57348165, 21.29305451, 16.51927126,  0.45248445,  0.77790972,
        0.43602098]), 'targetState': array([25., 25., 15.])}
episode index:1948
target thresh 25.93006826991221
model initialize at round 1948
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.1483924 , 14.95625999,  0.98800944,  0.14809404,
       -0.04365207]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.43643795050198597
{'scaleFactor': 20, 'currentState': array([26.37039327, 21.45685629, 17.0739136 ,  0.42412634,  0.80774151,
        0.40947589]), 'targetState': array([25., 25., 15.])}
episode index:1949
target thresh 25.937474892747904
model initialize at round 1949
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.51537267e+01,  1.49840629e+01,  9.88032863e-01,
        1.53421252e-01, -1.59053917e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.43670182337347213
{'scaleFactor': 20, 'currentState': array([25.40387752, 20.06629131, 15.84813239,  0.59146102,  0.77316253,
        0.22889641]), 'targetState': array([25., 25., 15.])}
episode index:1950
target thresh 25.944880774958346
model initialize at round 1950
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84922806,  0.97715468,  0.15173209,
       -0.14881567]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4369605513724611
{'scaleFactor': 20, 'currentState': array([26.61819398, 21.45212209, 16.22002597,  0.48131263,  0.79219558,
        0.37518572]), 'targetState': array([25., 25., 15.])}
episode index:1951
target thresh 25.9522859166176
model initialize at round 1951
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84973823,  0.97722779,  0.15174345,
       -0.14832321]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.43722388615654284
{'scaleFactor': 20, 'currentState': array([25.32223336, 20.12283756, 15.40044339,  0.55941415,  0.75659244,
        0.33856119]), 'targetState': array([25., 25., 15.])}
episode index:1952
target thresh 25.959690317799712
model initialize at round 1952
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.95233211,  0.98704127,  0.15326728,
       -0.04752543]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4374820818878508
{'scaleFactor': 20, 'currentState': array([26.38600794, 21.57202318, 16.81792066,  0.42239216,  0.80771543,
        0.41131575]), 'targetState': array([25., 25., 15.])}
episode index:1953
target thresh 25.967093978578713
model initialize at round 1953
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.90175842,  0.98344102,  0.15270823,
       -0.09759071]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.437744880233814
{'scaleFactor': 20, 'currentState': array([25.37208877, 20.15875518, 15.21431442,  0.59231085,  0.78936441,
        0.1614673 ]), 'targetState': array([25., 25., 15.])}
episode index:1954
target thresh 25.974496899028665
model initialize at round 1954
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.43800254533313226
{'scaleFactor': 20, 'currentState': array([26.94314413, 21.19022033, 16.02417256,  0.64545348,  0.69830629,
        0.30944811]), 'targetState': array([25., 25., 15.])}
episode index:1955
target thresh 25.98189907922359
model initialize at round 1955
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.0383867 , 14.87818864,  0.99178108,  0.03845576,
       -0.12203051]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.43777861765146914
{'scaleFactor': 20, 'currentState': array([38.39129463, -1.95502983, 38.1254523 ,  0.9893313 , -0.08166299,
        0.12064299]), 'targetState': array([25., 25., 15.])}
episode index:1956
target thresh 25.98930051923749
model initialize at round 1956
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.0919905 , 14.86750807,  0.98698622,  0.09171046,
       -0.1320886 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4380360021848107
{'scaleFactor': 20, 'currentState': array([27.03092638, 20.44972655, 16.91480056,  0.53734941,  0.72185879,
        0.43609116]), 'targetState': array([25., 25., 15.])}
episode index:1957
target thresh 25.996701219144402
model initialize at round 1957
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14426855, 14.94691001,  0.98815783,  0.14400009,
       -0.0529912 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4382931238126024
{'scaleFactor': 20, 'currentState': array([27.18209955, 20.49126933, 16.23566513,  0.54512683,  0.75256964,
        0.36942614]), 'targetState': array([25., 25., 15.])}
episode index:1958
target thresh 26.004101179018335
model initialize at round 1958
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12706747, 14.9098725 ,  0.98784435,  0.12679079,
       -0.08993125]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.438545177015305
{'scaleFactor': 20, 'currentState': array([29.64195079, 20.558665  , 16.3754139 ,  0.78189383,  0.56874837,
        0.25527893]), 'targetState': array([25., 25., 15.])}
episode index:1959
target thresh 26.01150039893326
model initialize at round 1959
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11722449, 14.89389319,  0.987485  ,  0.1169267 ,
       -0.10583725]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.438801776491012
{'scaleFactor': 20, 'currentState': array([27.35587397, 20.53723577, 15.59111163,  0.62362548,  0.71852359,
        0.30792061]), 'targetState': array([25., 25., 15.])}
episode index:1960
target thresh 26.018898878963213
model initialize at round 1960
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10805314, 14.89420513,  0.98853409,  0.10789314,
       -0.10563821]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.439058114264041
{'scaleFactor': 20, 'currentState': array([26.35484441, 21.04217382, 17.51927265,  0.42291189,  0.78045046,
        0.46048086]), 'targetState': array([25., 25., 15.])}
episode index:1961
target thresh 26.026296619182144
model initialize at round 1961
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.9424702 ,  0.98653272,  0.15318831,
       -0.05732831]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4393190377786363
{'scaleFactor': 20, 'currentState': array([25.28534401, 20.091289  , 15.98145908,  0.55544982,  0.75881744,
        0.34010528]), 'targetState': array([25., 25., 15.])}
episode index:1962
target thresh 26.033693619664035
model initialize at round 1962
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.95400795,  0.98711828,  0.15327924,
       -0.04585818]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4395748508767628
{'scaleFactor': 20, 'currentState': array([27.2519297 , 20.65589815, 16.69159793,  0.67562896,  0.64777966,
        0.35200429]), 'targetState': array([25., 25., 15.])}
episode index:1963
target thresh 26.041089880482858
model initialize at round 1963
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.51483802e+01,  1.49988452e+01,  9.88953247e-01,
        1.48223295e-01, -1.15356995e-03]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4398304034727527
{'scaleFactor': 20, 'currentState': array([27.33485225, 20.53395224, 16.95489781,  0.71544936,  0.64500689,
        0.26851132]), 'targetState': array([25., 25., 15.])}
episode index:1964
target thresh 26.048485401712583
model initialize at round 1964
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12398558, 14.92342423,  0.98933921,  0.12390282,
       -0.07652465]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.44008569596431923
{'scaleFactor': 20, 'currentState': array([26.92807976, 21.10064114, 16.28990784,  0.57052345,  0.78487997,
        0.2417983 ]), 'targetState': array([25., 25., 15.])}
episode index:1965
target thresh 26.05588018342716
model initialize at round 1965
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.06206778, 14.84627329,  0.98626699,  0.06183374,
       -0.15314705]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.4403359399378404
{'scaleFactor': 20, 'currentState': array([28.84934073, 21.28264014, 14.85024858,  0.55224456,  0.79615603,
        0.24730855]), 'targetState': array([25., 25., 15.])}
episode index:1966
target thresh 26.06327422570055
model initialize at round 1966
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4405907158450408
{'scaleFactor': 20, 'currentState': array([26.49907961, 21.38535605, 16.34785712,  0.45287771,  0.80288097,
        0.38766471]), 'targetState': array([25., 25., 15.])}
episode index:1967
target thresh 26.070667528606673
model initialize at round 1967
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.90284535,  0.98354409,  0.15272424,
       -0.09652109]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4408452328336363
{'scaleFactor': 20, 'currentState': array([27.03993277, 20.85938722, 16.26874755,  0.54563454,  0.74103884,
        0.39133667]), 'targetState': array([25., 25., 15.])}
episode index:1968
target thresh 26.078060092219467
model initialize at round 1968
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.96772073,  0.98764537,  0.15336108,
       -0.0322025 ]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4411043211104603
{'scaleFactor': 20, 'currentState': array([25.29303274, 20.06325176, 16.19537988,  0.55791358,  0.7501703 ,
        0.35493232]), 'targetState': array([25., 25., 15.])}
episode index:1969
target thresh 26.085451916612868
model initialize at round 1969
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.93559967,  0.98612264,  0.15312463,
       -0.0641481 ]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.44136314635350066
{'scaleFactor': 20, 'currentState': array([25.37945156, 20.15773214, 15.42803528,  0.58947307,  0.7858567 ,
        0.18695117]), 'targetState': array([25., 25., 15.])}
episode index:1970
target thresh 26.09284300186078
model initialize at round 1970
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4416217089631133
{'scaleFactor': 20, 'currentState': array([25.37459787, 20.15669416, 14.45453856,  0.61734131,  0.77646941,
        0.12643169]), 'targetState': array([25., 25., 15.])}
episode index:1971
target thresh 26.10023334803713
model initialize at round 1971
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.441880009338842
{'scaleFactor': 20, 'currentState': array([25.30717253, 20.12262258, 15.18903193,  0.55530505,  0.75285408,
        0.353337  ]), 'targetState': array([25., 25., 15.])}
episode index:1972
target thresh 26.107622955215813
model initialize at round 1972
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.91652193,  0.98474539,  0.15291077,
       -0.083035  ]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4421380478794204
{'scaleFactor': 20, 'currentState': array([25.3020843 , 20.10251074, 15.96434332,  0.55241335,  0.75293023,
        0.35768081]), 'targetState': array([25., 25., 15.])}
episode index:1973
target thresh 26.115011823470713
model initialize at round 1973
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87867317,  0.9809907 ,  0.15232775,
       -0.12022272]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4423958249827743
{'scaleFactor': 20, 'currentState': array([25.36885374, 20.15646598, 15.36181995,  0.59611276,  0.79382945,
        0.12035107]), 'targetState': array([25., 25., 15.])}
episode index:1974
target thresh 26.122399952875753
model initialize at round 1974
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.44265334104602355
{'scaleFactor': 20, 'currentState': array([25.15730839, 20.11385014, 12.67289772,  0.56154175,  0.77761646,
       -0.28281355]), 'targetState': array([25., 25., 15.])}
episode index:1975
target thresh 26.129787343504773
model initialize at round 1975
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4429105964654841
{'scaleFactor': 20, 'currentState': array([25.13827732, 20.1449092 , 12.66515704,  0.57854512,  0.79689241,
       -0.17391962]), 'targetState': array([25., 25., 15.])}
episode index:1976
target thresh 26.137173995431674
model initialize at round 1976
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.44316759163667
{'scaleFactor': 20, 'currentState': array([25.33542253, 20.16553788, 14.61367301,  0.58284676,  0.78027601,
        0.22684577]), 'targetState': array([25., 25., 15.])}
episode index:1977
target thresh 26.1445599087303
model initialize at round 1977
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86718128,  0.97958713,  0.1521098 ,
       -0.13142172]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.44341951911784505
{'scaleFactor': 20, 'currentState': array([ 2.66493679e+01,  2.14544423e+01,  1.28372013e+01,  5.68807300e-01,
        8.22451438e-01, -5.64699062e-03]), 'targetState': array([25., 25., 15.])}
episode index:1978
target thresh 26.151945083474537
model initialize at round 1978
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.91193749,  0.9843625 ,  0.15285132,
       -0.08756104]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.443675997405254
{'scaleFactor': 20, 'currentState': array([25.25320382, 20.06045775, 16.39643573,  0.55380194,  0.75971603,
        0.3407858 ]), 'targetState': array([25., 25., 15.])}
episode index:1979
target thresh 26.15932951973823
model initialize at round 1979
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.88015531,  0.9811629 ,  0.15235449,
       -0.11877492]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.44393221662368565
{'scaleFactor': 20, 'currentState': array([25.21608872, 20.05875271, 16.45744885,  0.54874942,  0.75819188,
        0.35216352]), 'targetState': array([25., 25., 15.])}
episode index:1980
target thresh 26.166713217595206
model initialize at round 1980
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89773588,  0.9830499 ,  0.1526475 ,
       -0.10154619]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.44417862405997205
{'scaleFactor': 20, 'currentState': array([29.27673875, 20.93763966, 16.50761046,  0.62259952,  0.66763032,
        0.40821513]), 'targetState': array([25., 25., 15.])}
episode index:1981
target thresh 26.17409617711932
model initialize at round 1981
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.51537267e+01,  1.49967645e+01,  9.88152710e-01,
        1.53439862e-01, -3.22950305e-03]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4444343311365816
{'scaleFactor': 20, 'currentState': array([25.18217581, 20.04524374, 16.88396274,  0.54248325,  0.75723639,
        0.36373751]), 'targetState': array([25., 25., 15.])}
episode index:1982
target thresh 26.181478398384396
model initialize at round 1982
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.51537267e+01,  1.49829818e+01,  9.88015332e-01,
        1.53418530e-01, -1.69840822e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4446897803139711
{'scaleFactor': 20, 'currentState': array([25.22626569, 20.06496143, 16.6443993 ,  0.53371493,  0.74063717,
        0.40817271]), 'targetState': array([25., 25., 15.])}
episode index:1983
target thresh 26.188859881464243
model initialize at round 1983
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.91165095,  0.98433791,  0.1528475 ,
       -0.08784375]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.44494497198210925
{'scaleFactor': 20, 'currentState': array([25.27677713, 20.08151445, 15.97013543,  0.54125001,  0.74332907,
        0.39307801]), 'targetState': array([25., 25., 15.])}
episode index:1984
target thresh 26.19624062643271
model initialize at round 1984
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.96836912,  0.98766574,  0.15336424,
       -0.0315563 ]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.44519990653017877
{'scaleFactor': 20, 'currentState': array([25.19895327, 20.04934389, 16.8182039 ,  0.53717346,  0.74876987,
        0.38831477]), 'targetState': array([25., 25., 15.])}
episode index:1985
target thresh 26.203620633363567
model initialize at round 1985
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.94463971,  0.98665271,  0.15320694,
       -0.05517311]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4454545843465785
{'scaleFactor': 20, 'currentState': array([25.21372153, 20.04710809, 16.57880082,  0.52616573,  0.73395373,
        0.42948987]), 'targetState': array([25., 25., 15.])}
episode index:1986
target thresh 26.210999902330634
model initialize at round 1986
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.96531244,  0.98756612,  0.15334878,
       -0.03460228]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4457090058189255
{'scaleFactor': 20, 'currentState': array([25.28892123, 20.10212706, 16.23829074,  0.57084932,  0.77610783,
        0.26793227]), 'targetState': array([25., 25., 15.])}
episode index:1987
target thresh 26.218378433407697
model initialize at round 1987
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.44596317133405683
{'scaleFactor': 20, 'currentState': array([25.33075998, 20.13179621, 15.25276873,  0.56552748,  0.76255344,
        0.3141511 ]), 'targetState': array([25., 25., 15.])}
episode index:1988
target thresh 26.22575622666854
model initialize at round 1988
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86653148,  0.97950416,  0.15209692,
       -0.1320535 ]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.44621708127803167
{'scaleFactor': 20, 'currentState': array([25.31936077, 20.06041917, 15.81921375,  0.59472005,  0.73440429,
        0.32704496]), 'targetState': array([25., 25., 15.])}
episode index:1989
target thresh 26.233133282186948
model initialize at round 1989
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09945142, 14.85135113,  0.9840706 ,  0.09885578,
       -0.14775857]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.4464612261356342
{'scaleFactor': 20, 'currentState': array([28.93862941, 21.04968049, 16.20027317,  0.52348383,  0.69689468,
        0.49020657]), 'targetState': array([25., 25., 15.])}
episode index:1990
target thresh 26.2405096000367
model initialize at round 1990
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13841995, 14.96020774,  0.98958273,  0.13836161,
       -0.03977548]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.4462369864439538
{'scaleFactor': 20, 'currentState': array([16.57521222, 13.0518233 , 47.75759206,  0.64228897, -0.46945302,
       -0.60587024]), 'targetState': array([25., 25., 15.])}
episode index:1991
target thresh 26.24788518029153
model initialize at round 1991
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12370802, 14.84627329,  0.98070982,  0.12254714,
       -0.15228413]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.4464808761836441
{'scaleFactor': 20, 'currentState': array([28.72236301, 21.52087571, 16.44963618,  0.50447704,  0.80092329,
        0.32252875]), 'targetState': array([25., 25., 15.])}
episode index:1992
target thresh 26.25526002302522
model initialize at round 1992
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.44673401676252844
{'scaleFactor': 20, 'currentState': array([25.25079648, 20.07863313, 15.62997758,  0.54163071,  0.74459938,
        0.39013834]), 'targetState': array([25., 25., 15.])}
episode index:1993
target thresh 26.26263412831151
model initialize at round 1993
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.9001523 ,  0.98328668,  0.15268427,
       -0.09917062]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.44698690343912695
{'scaleFactor': 20, 'currentState': array([25.3932524 , 20.13731254, 15.13882641,  0.6154199 ,  0.76775434,
        0.17835814]), 'targetState': array([25., 25., 15.])}
episode index:1994
target thresh 26.270007496224135
model initialize at round 1994
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.44723953659524773
{'scaleFactor': 20, 'currentState': array([25.32838169, 20.1460479 , 14.92526468,  0.56797298,  0.76434788,
        0.30525236]), 'targetState': array([25., 25., 15.])}
episode index:1995
target thresh 26.277380126836835
model initialize at round 1995
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89361088,  0.98263303,  0.15258277,
       -0.10559744]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4474919166119335
{'scaleFactor': 20, 'currentState': array([25.29578829, 20.10041354, 15.73342285,  0.55365658,  0.75471865,
        0.35194339]), 'targetState': array([25., 25., 15.])}
episode index:1996
target thresh 26.284752020223333
model initialize at round 1996
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.44774404386946387
{'scaleFactor': 20, 'currentState': array([25.40165863, 20.12602805, 14.52425364,  0.60135067,  0.78852295,
        0.12887566]), 'targetState': array([25., 25., 15.])}
episode index:1997
target thresh 26.29212317645736
model initialize at round 1997
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84899709,  0.97712151,  0.15172694,
       -0.14903858]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.447995918747357
{'scaleFactor': 20, 'currentState': array([25.36638027, 20.17780149, 14.47499476,  0.59750618,  0.79452269,
        0.1082592 ]), 'targetState': array([25., 25., 15.])}
episode index:1998
target thresh 26.29949359561261
model initialize at round 1998
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4482427842954579
{'scaleFactor': 20, 'currentState': array([27.46680216, 20.35961596, 14.01169765,  0.6872041 ,  0.66770561,
        0.28621624]), 'targetState': array([25., 25., 15.])}
episode index:1999
target thresh 26.306863277762815
model initialize at round 1999
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.1359287 , 14.86918407,  0.98232395,  0.13487476,
       -0.12980164]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4484894029780106
{'scaleFactor': 20, 'currentState': array([26.61002043, 21.27992052, 16.5786808 ,  0.55441272,  0.74130581,
        0.37827534]), 'targetState': array([25., 25., 15.])}
episode index:2000
target thresh 26.314232222981637
model initialize at round 2000
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09706841, 14.86750251,  0.98651495,  0.09672671,
       -0.13203107]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4487357751651285
{'scaleFactor': 20, 'currentState': array([26.76731051, 21.01337263, 15.84691588,  0.47611933,  0.78339727,
        0.39949855]), 'targetState': array([25., 25., 15.])}
episode index:2001
target thresh 26.321600431342773
model initialize at round 2001
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87932466,  0.98106664,  0.15233954,
       -0.11958642]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4489866514262349
{'scaleFactor': 20, 'currentState': array([25.29152371, 20.0932651 , 15.85072994,  0.55621615,  0.75848858,
        0.33958603]), 'targetState': array([25., 25., 15.])}
episode index:2002
target thresh 26.32896790291992
model initialize at round 2002
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85235526,  0.97759917,  0.15180111,
       -0.14579533]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4492372771868309
{'scaleFactor': 20, 'currentState': array([25.36388309, 20.15598959, 14.99716724,  0.58158418,  0.77705695,
        0.24071214]), 'targetState': array([25., 25., 15.])}
episode index:2003
target thresh 26.33633463778674
model initialize at round 2003
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4494876528219173
{'scaleFactor': 20, 'currentState': array([25.26357938, 20.08220012, 16.05763728,  0.56204319,  0.76769627,
        0.3078147 ]), 'targetState': array([25., 25., 15.])}
episode index:2004
target thresh 26.34370063601691
model initialize at round 2004
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4497377787057468
{'scaleFactor': 20, 'currentState': array([25.38436759, 20.11090349, 15.39960571,  0.59078974,  0.74766938,
        0.30324576]), 'targetState': array([25., 25., 15.])}
episode index:2005
target thresh 26.3510658976841
model initialize at round 2005
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.92116854,  0.98511301,  0.15296786,
       -0.07844232]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4499829144837604
{'scaleFactor': 20, 'currentState': array([26.3958957 , 21.57495707, 16.69747642,  0.43450473,  0.82343489,
        0.36491179]), 'targetState': array([25., 25., 15.])}
episode index:2006
target thresh 26.358430422861932
model initialize at round 2006
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.45022780598097867
{'scaleFactor': 20, 'currentState': array([26.61361972, 21.36494438, 16.36885756,  0.54649443,  0.72126943,
        0.4255752 ]), 'targetState': array([25., 25., 15.])}
episode index:2007
target thresh 26.36579421162407
model initialize at round 2007
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.03461633, 14.90647879,  0.99496507,  0.03478994,
       -0.09399024]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.45000358894612763
{'scaleFactor': 20, 'currentState': array([35.90208416,  7.9467755 , 27.82697345,  0.73318539,  0.67004282,
        0.11611117]), 'targetState': array([25., 25., 15.])}
episode index:2008
target thresh 26.373157264044156
model initialize at round 2008
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12797255, 14.84627329,  0.98019376,  0.12670495,
       -0.152204  ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4502482263580016
{'scaleFactor': 20, 'currentState': array([26.52937464, 21.56991918, 13.16523272,  0.47948799,  0.85998197,
       -0.17470626]), 'targetState': array([25., 25., 15.])}
episode index:2009
target thresh 26.380519580195806
model initialize at round 2009
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.45049735164334587
{'scaleFactor': 20, 'currentState': array([25.32196427, 20.1709376 , 14.41504715,  0.58045434,  0.77781259,
        0.24099864]), 'targetState': array([25., 25., 15.])}
episode index:2010
target thresh 26.38788116015265
model initialize at round 2010
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87536966,  0.98059962,  0.15226702,
       -0.12344693]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.45074150022502546
{'scaleFactor': 20, 'currentState': array([26.42952508, 21.53091259, 16.70214198,  0.44913275,  0.81930141,
        0.35640563]), 'targetState': array([25., 25., 15.])}
episode index:2011
target thresh 26.395242003988308
model initialize at round 2011
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4509901327049832
{'scaleFactor': 20, 'currentState': array([25.29497375, 20.10453656, 15.70148325,  0.56140562,  0.76262411,
        0.32129146]), 'targetState': array([25., 25., 15.])}
episode index:2012
target thresh 26.402602111776385
model initialize at round 2012
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.45123851815813526
{'scaleFactor': 20, 'currentState': array([25.25582052, 20.06849056, 16.02151929,  0.55193398,  0.75751057,
        0.34863536]), 'targetState': array([25., 25., 15.])}
episode index:2013
target thresh 26.409961483590482
model initialize at round 2013
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.45148665695244605
{'scaleFactor': 20, 'currentState': array([25.34375018, 20.14438739, 15.06943112,  0.57008189,  0.76576976,
        0.29766309]), 'targetState': array([25., 25., 15.])}
episode index:2014
target thresh 26.417320119504197
model initialize at round 2014
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.91448325,  0.98457759,  0.15288472,
       -0.08504836]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.45173454945514957
{'scaleFactor': 20, 'currentState': array([25.34670802, 20.13292278, 15.57770382,  0.56975132,  0.76730394,
        0.29432651]), 'targetState': array([25., 25., 15.])}
episode index:2015
target thresh 26.42467801959111
model initialize at round 2015
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4519821960327512
{'scaleFactor': 20, 'currentState': array([25.38532609, 20.17510416, 14.69245854,  0.59908882,  0.7944416 ,
        0.09977537]), 'targetState': array([25., 25., 15.])}
episode index:2016
target thresh 26.432035183924807
model initialize at round 2016
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15135283, 14.84627329,  0.97707116,  0.14937625,
       -0.15171912]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.45222959705102944
{'scaleFactor': 20, 'currentState': array([25.40391854, 20.03653223, 15.07913864,  0.57616586,  0.75399927,
        0.31546472]), 'targetState': array([25., 25., 15.])}
episode index:2017
target thresh 26.439391612578856
model initialize at round 2017
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09770625, 14.93180357,  0.99283498,  0.09798605,
       -0.06839172]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.4524673749255865
{'scaleFactor': 20, 'currentState': array([29.54759086, 20.17204657, 16.01714719,  0.64299587,  0.65417995,
        0.39825231]), 'targetState': array([25., 25., 15.])}
episode index:2018
target thresh 26.446747305626815
model initialize at round 2018
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11590028, 14.87129874,  0.98503957,  0.11531956,
       -0.1280564 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4527095803611859
{'scaleFactor': 20, 'currentState': array([26.62707217, 21.28487804, 15.94325118,  0.50568663,  0.79677668,
        0.33079896]), 'targetState': array([25., 25., 15.])}
episode index:2019
target thresh 26.454102263142243
model initialize at round 2019
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11275434, 14.84627329,  0.98195855,  0.11183848,
       -0.15247804]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.45295154598942344
{'scaleFactor': 20, 'currentState': array([27.65153452, 20.02397347, 15.98355316,  0.73242316,  0.63168656,
        0.2540244 ]), 'targetState': array([25., 25., 15.])}
episode index:2020
target thresh 26.46145648519871
model initialize at round 2020
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14290468, 14.84627329,  0.97825626,  0.14120949,
       -0.15190315]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4531932721662723
{'scaleFactor': 20, 'currentState': array([27.17006751, 20.59264312, 16.05888967,  0.59778891,  0.70494493,
        0.38170809]), 'targetState': array([25., 25., 15.])}
episode index:2021
target thresh 26.46880997186971
model initialize at round 2021
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12997711, 14.8853795 ,  0.9850225 ,  0.12932362,
       -0.11404421]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4534347592470016
{'scaleFactor': 20, 'currentState': array([26.41043874, 21.36994101, 16.85227594,  0.43073197,  0.80710123,
        0.40380388]), 'targetState': array([25., 25., 15.])}
episode index:2022
target thresh 26.476162723228835
model initialize at round 2022
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87531388,  0.98059293,  0.15226598,
       -0.12350134]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4536807084761924
{'scaleFactor': 20, 'currentState': array([25.31198717, 20.11232825, 15.47925106,  0.55122318,  0.7489893 ,
        0.36765207]), 'targetState': array([25., 25., 15.])}
episode index:2023
target thresh 26.48351473934958
model initialize at round 2023
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.91268513,  0.98442631,  0.15286123,
       -0.08682329]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.45392171610510784
{'scaleFactor': 20, 'currentState': array([26.78707402, 21.22966481, 16.65492738,  0.52493421,  0.77048231,
        0.36166431]), 'targetState': array([25., 25., 15.])}
episode index:2024
target thresh 26.49086602030547
model initialize at round 2024
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11569634, 14.84627329,  0.98163407,  0.11471865,
       -0.15242765]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.4541578364171088
{'scaleFactor': 20, 'currentState': array([28.97255596, 21.09534469, 16.36180629,  0.55132156,  0.76460559,
        0.3338006 ]), 'targetState': array([25., 25., 15.])}
episode index:2025
target thresh 26.49821656617002
model initialize at round 2025
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11429399, 14.84707233,  0.98190806,  0.11335979,
       -0.15167769]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4543983706288481
{'scaleFactor': 20, 'currentState': array([26.94864875, 21.08982094, 13.50840619,  0.55980852,  0.82804328,
        0.03096352]), 'targetState': array([25., 25., 15.])}
episode index:2026
target thresh 26.50556637701674
model initialize at round 2026
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4546433591238018
{'scaleFactor': 20, 'currentState': array([25.12663599, 20.15729341, 12.68844896,  0.5862539 ,  0.80559877,
       -0.0855394 ]), 'targetState': array([25., 25., 15.])}
episode index:2027
target thresh 26.512915452919117
model initialize at round 2027
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4548834167126959
{'scaleFactor': 20, 'currentState': array([26.82790177, 21.39250465, 14.91880871,  0.5175705 ,  0.82706489,
        0.21928167]), 'targetState': array([25., 25., 15.])}
episode index:2028
target thresh 26.520263793950647
model initialize at round 2028
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4551279246639957
{'scaleFactor': 20, 'currentState': array([25.39959219, 20.02823529, 15.53135829,  0.59900093,  0.74465954,
        0.29441478]), 'targetState': array([25., 25., 15.])}
episode index:2029
target thresh 26.527611400184814
model initialize at round 2029
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4553721917207622
{'scaleFactor': 20, 'currentState': array([25.33531417, 20.13959472, 15.1994022 ,  0.57776963,  0.77623683,
        0.25226698]), 'targetState': array([25., 25., 15.])}
episode index:2030
target thresh 26.534958271695107
model initialize at round 2030
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.455611535865361
{'scaleFactor': 20, 'currentState': array([26.56674382, 21.41254994, 16.05864578,  0.46310627,  0.80931997,
        0.36129457]), 'targetState': array([25., 25., 15.])}
episode index:2031
target thresh 26.542304408554973
model initialize at round 2031
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85094802,  0.97740023,  0.15177022,
       -0.14715499]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4558553245041576
{'scaleFactor': 20, 'currentState': array([25.26438614, 20.07683354, 15.94380009,  0.54902176,  0.75300651,
        0.36270691]), 'targetState': array([25., 25., 15.])}
episode index:2032
target thresh 26.549649810837884
model initialize at round 2032
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89465573,  0.98274013,  0.1525994 ,
       -0.10457176]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.45609887331153387
{'scaleFactor': 20, 'currentState': array([25.47370428, 20.0361661 , 14.70514584,  0.61482912,  0.77683902,
        0.13603784]), 'targetState': array([25., 25., 15.])}
episode index:2033
target thresh 26.55699447861728
model initialize at round 2033
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.05904472, 14.84627329,  0.98644623,  0.05883277,
       -0.15317488]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.45633287846128584
{'scaleFactor': 20, 'currentState': array([29.41099814, 20.33792873, 14.92042307,  0.61440481,  0.76180874,
        0.20531481]), 'targetState': array([25., 25., 15.])}
episode index:2034
target thresh 26.564338411966638
model initialize at round 2034
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4565759532384056
{'scaleFactor': 20, 'currentState': array([25.36789758, 20.06063891, 14.02085461,  0.59991003,  0.77788779,
        0.18707898]), 'targetState': array([25., 25., 15.])}
episode index:2035
target thresh 26.571681610959374
model initialize at round 2035
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85479015,  0.97793922,  0.15185392,
       -0.14344082]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4568187892387306
{'scaleFactor': 20, 'currentState': array([25.35621833, 20.18077343, 14.0952175 ,  0.5999418 ,  0.79840624,
        0.05115975]), 'targetState': array([25., 25., 15.])}
episode index:2036
target thresh 26.579024075668922
model initialize at round 2036
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4570613868139202
{'scaleFactor': 20, 'currentState': array([25.23363252, 20.18677707, 13.509251  ,  0.58941456,  0.79503673,
        0.1432029 ]), 'targetState': array([25., 25., 15.])}
episode index:2037
target thresh 26.58636580616871
model initialize at round 2037
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87669572,  0.98075781,  0.15229158,
       -0.12215317]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4572990800242181
{'scaleFactor': 20, 'currentState': array([26.40991078, 21.47837482, 16.48204644,  0.47724359,  0.76024768,
        0.44075167]), 'targetState': array([25., 25., 15.])}
episode index:2038
target thresh 26.593706802532157
model initialize at round 2038
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.04291133, 14.91100918,  0.99505742,  0.04313054,
       -0.08944543]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.45753192272548476
{'scaleFactor': 20, 'currentState': array([29.23636248, 20.38069483, 16.47094763,  0.60817758,  0.73481115,
        0.30028754]), 'targetState': array([25., 25., 15.])}
episode index:2039
target thresh 26.601047064832674
model initialize at round 2039
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13346294, 14.84627329,  0.97950487,  0.13204809,
       -0.15209703]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4577691522483649
{'scaleFactor': 20, 'currentState': array([26.66153189, 21.04515304, 16.08614015,  0.43855466,  0.74657705,
        0.50029243]), 'targetState': array([25., 25., 15.])}
episode index:2040
target thresh 26.608386593143653
model initialize at round 2040
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.51537267e+01, 1.50127385e+01, 9.88077997e-01,
       1.53428260e-01, 1.27137779e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4580108087391301
{'scaleFactor': 20, 'currentState': array([25.25811078, 20.09597963, 16.6268172 ,  0.55285684,  0.75931866,
        0.34319744]), 'targetState': array([25., 25., 15.])}
episode index:2041
target thresh 26.615725387538514
model initialize at round 2041
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4582475713937147
{'scaleFactor': 20, 'currentState': array([26.87535995, 20.91250664, 16.62289347,  0.53294484,  0.71478934,
        0.45282005]), 'targetState': array([25., 25., 15.])}
episode index:2042
target thresh 26.623063448090612
model initialize at round 2042
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.95402633,  0.98711911,  0.15327937,
       -0.04583989]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4584841022689018
{'scaleFactor': 20, 'currentState': array([26.45205397, 21.27603568, 17.18474891,  0.42543387,  0.75365711,
        0.50100596]), 'targetState': array([25., 25., 15.])}
episode index:2043
target thresh 26.63040077487335
model initialize at round 2043
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.92646388,  0.98550674,  0.153029  ,
       -0.07320236]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4587204017048764
{'scaleFactor': 20, 'currentState': array([26.3527732 , 21.26389554, 17.59700986,  0.40442095,  0.74740405,
        0.52709666]), 'targetState': array([25., 25., 15.])}
episode index:2044
target thresh 26.637737367960092
model initialize at round 2044
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.04078073,  0.98734025,  0.1533137 ,
        0.04067117]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4589611203592505
{'scaleFactor': 20, 'currentState': array([25.16473753, 20.05473989, 17.10814718,  0.53412879,  0.74857805,
        0.3928579 ]), 'targetState': array([25., 25., 15.])}
episode index:2045
target thresh 26.64507322742421
model initialize at round 2045
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.88645367,  0.98187199,  0.1524646 ,
       -0.11261411]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4592016037070222
{'scaleFactor': 20, 'currentState': array([25.33044901, 20.01872101, 16.0375212 ,  0.58795623,  0.74444487,
        0.31640054]), 'targetState': array([25., 25., 15.])}
episode index:2046
target thresh 26.652408353339062
model initialize at round 2046
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11746718, 14.88198051,  0.98614816,  0.11701015,
       -0.1175603 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.45943720631849944
{'scaleFactor': 20, 'currentState': array([27.3293832 , 20.45082869, 16.10212485,  0.61019534,  0.71745816,
        0.33602893]), 'targetState': array([25., 25., 15.])}
episode index:2047
target thresh 26.659742745777994
model initialize at round 2047
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.91628238,  0.98472588,  0.15290775,
       -0.08327163]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4596772223554045
{'scaleFactor': 20, 'currentState': array([25.28802222, 20.08766933, 16.05963335,  0.54119667,  0.7419701 ,
        0.39571016]), 'targetState': array([25., 25., 15.])}
episode index:2048
target thresh 26.66707640481435
model initialize at round 2048
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.92130624,  0.98512359,  0.1529695 ,
       -0.07830614]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4599170041160412
{'scaleFactor': 20, 'currentState': array([25.27467993, 20.08756037, 16.28053679,  0.55494337,  0.75955442,
        0.33928594]), 'targetState': array([25., 25., 15.])}
episode index:2049
target thresh 26.674409330521478
model initialize at round 2049
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4601565519432529
{'scaleFactor': 20, 'currentState': array([25.43480507, 20.099457  , 14.55052979,  0.62974099,  0.76911133,
        0.10905987]), 'targetState': array([25., 25., 15.])}
episode index:2050
target thresh 26.68174152297269
model initialize at round 2050
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08862916, 14.84627329,  0.98431379,  0.0881201 ,
       -0.15284376]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4603912294651728
{'scaleFactor': 20, 'currentState': array([26.6983368 , 20.95587098, 12.17944501,  0.5447609 ,  0.83565507,
       -0.07011544]), 'targetState': array([25., 25., 15.])}
episode index:2051
target thresh 26.689072982241324
model initialize at round 2051
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.46063031271099875
{'scaleFactor': 20, 'currentState': array([25.46649239, 20.00310166, 14.8370937 ,  0.60263394,  0.76186431,
        0.23747655]), 'targetState': array([25., 25., 15.])}
episode index:2052
target thresh 26.696403708400673
model initialize at round 2052
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12060767, 14.90618433,  0.98829784,  0.12040031,
       -0.09365437]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.46085994497363686
{'scaleFactor': 20, 'currentState': array([29.2940191 , 20.90321244, 16.53747327,  0.73685978,  0.61957493,
        0.2704895 ]), 'targetState': array([25., 25., 15.])}
episode index:2053
target thresh 26.70373370152408
model initialize at round 2053
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.06515874, 14.84627329,  0.98607458,  0.06490038,
       -0.15311717]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.46063557304326996
{'scaleFactor': 20, 'currentState': array([ 7.62587401, 17.03437294, 17.83020229,  0.55570498, -0.59599287,
       -0.57964168]), 'targetState': array([25., 25., 15.])}
episode index:2054
target thresh 26.711062961684807
model initialize at round 2054
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.96226092, 14.84627329,  0.98745754, -0.03764216,
       -0.15333192]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.46041141947974523
{'scaleFactor': 20, 'currentState': array([59.58389731,  5.37143772, 47.7340049 ,  0.56306794,  0.65575175,
        0.50293552]), 'targetState': array([25., 25., 15.])}
episode index:2055
target thresh 26.71839148895616
model initialize at round 2055
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.046919  , 14.89628498,  0.99345419,  0.04708271,
       -0.10407688]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.4601874839644341
{'scaleFactor': 20, 'currentState': array([44.22238529, 21.35784735, 35.29142046,  0.33136671,  0.82814709,
        0.45207134]), 'targetState': array([25., 25., 15.])}
episode index:2056
target thresh 26.725719283411443
model initialize at round 2056
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12181747, 14.8479089 ,  0.9811742 ,  0.12073147,
       -0.15073521]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.46042146192526856
{'scaleFactor': 20, 'currentState': array([27.43908403, 20.22326302, 15.85114762,  0.65328147,  0.69673011,
        0.29629457]), 'targetState': array([25., 25., 15.])}
episode index:2057
target thresh 26.733046345123903
model initialize at round 2057
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15238984, 14.84627329,  0.9769213 ,  0.15037665,
       -0.15169585]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.46065521250227326
{'scaleFactor': 20, 'currentState': array([27.17257525, 20.84289679, 14.06628617,  0.60205544,  0.78062332,
        0.16779891]), 'targetState': array([25., 25., 15.])}
episode index:2058
target thresh 26.740372674166835
model initialize at round 2058
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09537629, 14.84627329,  0.98371032,  0.09477035,
       -0.15275005]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.4604314848614271
{'scaleFactor': 20, 'currentState': array([19.72228008, 14.0503239 , 22.66464071,  0.90832564,  0.40095123,
       -0.11909093]), 'targetState': array([25., 25., 15.])}
episode index:2059
target thresh 26.747698270613498
model initialize at round 2059
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.9365705 ,  0.98618336,  0.15313406,
       -0.06318496]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.460669620087174
{'scaleFactor': 20, 'currentState': array([25.38123054, 20.16150951, 15.30353192,  0.58975834,  0.78585983,
        0.18603611]), 'targetState': array([25., 25., 15.])}
episode index:2060
target thresh 26.755023134537137
model initialize at round 2060
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4609029100092088
{'scaleFactor': 20, 'currentState': array([26.63622874, 21.42183183, 16.36288651,  0.50641453,  0.77542798,
        0.3771681 ]), 'targetState': array([25., 25., 15.])}
episode index:2061
target thresh 26.762347266011
model initialize at round 2061
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86802774,  0.97969463,  0.15212649,
       -0.1305985 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.46113597365585857
{'scaleFactor': 20, 'currentState': array([25.99997402, 21.48026802, 17.75348377,  0.36024335,  0.7662032 ,
        0.53212535]), 'targetState': array([25., 25., 15.])}
episode index:2062
target thresh 26.769670665108347
model initialize at round 2062
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14328041, 15.029868  ,  0.98924778,  0.14317154,
        0.0298453 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.46136881135617125
{'scaleFactor': 20, 'currentState': array([27.14405455, 20.8119382 , 17.03044929,  0.66760433,  0.69920446,
        0.25576862]), 'targetState': array([25., 25., 15.])}
episode index:2063
target thresh 26.77699333190239
model initialize at round 2063
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85966995,  0.97860472,  0.15195725,
       -0.1387148 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.46160142343855726
{'scaleFactor': 20, 'currentState': array([26.89281698, 21.18599562, 15.01965256,  0.51721967,  0.77905254,
        0.35434582]), 'targetState': array([25., 25., 15.])}
episode index:2064
target thresh 26.784315266466376
model initialize at round 2064
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89253044,  0.98252121,  0.15256541,
       -0.1066577 ]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4618384155094829
{'scaleFactor': 20, 'currentState': array([25.28550253, 20.0968387 , 15.6661756 ,  0.55063845,  0.75183229,
        0.36269203]), 'targetState': array([25., 25., 15.])}
episode index:2065
target thresh 26.791636468873502
model initialize at round 2065
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89736095,  0.98301267,  0.15264172,
       -0.10191464]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4620751781592363
{'scaleFactor': 20, 'currentState': array([25.46591085, 20.06028135, 15.23035259,  0.628391  ,  0.76264072,
        0.15330977]), 'targetState': array([25., 25., 15.])}
episode index:2066
target thresh 26.798956939196994
model initialize at round 2066
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13525508, 14.84627329,  0.97927407,  0.13378969,
       -0.15206119]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.46185162945185404
{'scaleFactor': 20, 'currentState': array([ 3.23103729e+01,  4.79139194e+00,  2.82721437e+01,  9.98669063e-01,
        3.12733742e-02, -4.10131518e-02]), 'targetState': array([25., 25., 15.])}
episode index:2067
target thresh 26.806276677510066
model initialize at round 2067
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.46208355813654894
{'scaleFactor': 20, 'currentState': array([26.6658088 , 21.29232239, 16.51124177,  0.56061151,  0.71380627,
        0.41975629]), 'targetState': array([25., 25., 15.])}
episode index:2068
target thresh 26.813595683885904
model initialize at round 2068
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10621463, 14.91991639,  0.99109332,  0.10633193,
       -0.08017205]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.46186022147239403
{'scaleFactor': 20, 'currentState': array([66.93791954, 78.76097265, 47.5056379 , -0.68914163,  0.3753987 ,
        0.61980611]), 'targetState': array([25., 25., 15.])}
episode index:2069
target thresh 26.820913958397686
model initialize at round 2069
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.92365481,  0.98530122,  0.15299708,
       -0.07598284]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4620965160754992
{'scaleFactor': 20, 'currentState': array([25.3233956 , 20.12288879, 15.77420248,  0.57987032,  0.78175497,
        0.22936776]), 'targetState': array([25., 25., 15.])}
episode index:2070
target thresh 26.828231501118605
model initialize at round 2070
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.46233258248487846
{'scaleFactor': 20, 'currentState': array([25.29727273, 20.13163   , 15.04054942,  0.56845376,  0.76820906,
        0.29447438]), 'targetState': array([25., 25., 15.])}
episode index:2071
target thresh 26.835548312121848
model initialize at round 2071
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.46256842103092827
{'scaleFactor': 20, 'currentState': array([25.29560338, 20.10822055, 15.48567035,  0.55955164,  0.76022586,
        0.33008878]), 'targetState': array([25., 25., 15.])}
episode index:2072
target thresh 26.84286439148057
model initialize at round 2072
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09038739, 14.84937751,  0.98462045,  0.08989624,
       -0.14980402]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.4627949029059288
{'scaleFactor': 20, 'currentState': array([28.80377441, 21.27245054, 16.53301124,  0.50291699,  0.76166551,
        0.4085831 ]), 'targetState': array([25., 25., 15.])}
episode index:2073
target thresh 26.850179739267944
model initialize at round 2073
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86067119,  0.97873862,  0.15197805,
       -0.13774393]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.46303029111566557
{'scaleFactor': 20, 'currentState': array([25.31454203, 20.04214089, 15.55739635,  0.5575291 ,  0.74874867,
        0.3585202 ]), 'targetState': array([25., 25., 15.])}
episode index:2074
target thresh 26.857494355557098
model initialize at round 2074
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86061912,  0.97873168,  0.15197697,
       -0.13779443]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.46326545244520023
{'scaleFactor': 20, 'currentState': array([25.32891002, 20.17476966, 14.3936343 ,  0.5906075 ,  0.78960179,
        0.16646858]), 'targetState': array([25., 25., 15.])}
episode index:2075
target thresh 26.864808240421212
model initialize at round 2075
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14913087, 14.84627329,  0.97738902,  0.14723119,
       -0.15176848]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.46349580634546794
{'scaleFactor': 20, 'currentState': array([27.62101635, 20.28290929, 14.1278332 ,  0.73606712,  0.66248244,
        0.13900435]), 'targetState': array([25., 25., 15.])}
episode index:2076
target thresh 26.87212139393339
model initialize at round 2076
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12023698, 14.84627329,  0.98111752,  0.11915819,
       -0.15234744]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.46372593843167664
{'scaleFactor': 20, 'currentState': array([27.14654283, 20.81067016, 14.2434875 ,  0.63129146,  0.71639957,
        0.29705682]), 'targetState': array([25., 25., 15.])}
episode index:2077
target thresh 26.8794338161668
model initialize at round 2077
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.1169445 , 14.90442247,  0.98856215,  0.11677466,
       -0.09543871]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.4639513183207408
{'scaleFactor': 20, 'currentState': array([29.61221175, 20.25396703, 16.55236752,  0.75449715,  0.59576641,
        0.27531153]), 'targetState': array([25., 25., 15.])}
episode index:2078
target thresh 26.886745507194544
model initialize at round 2078
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09120496, 14.86626072,  0.98689393,  0.09091881,
       -0.13331968]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.464181009918182
{'scaleFactor': 20, 'currentState': array([27.21184507, 20.72771724, 14.51475689,  0.6317725 ,  0.74700141,
        0.20700821]), 'targetState': array([25., 25., 15.])}
episode index:2079
target thresh 26.894056467089722
model initialize at round 2079
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.02768595, 14.84627329,  0.98778077,  0.02762388,
       -0.15338211]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.46395784597110595
{'scaleFactor': 20, 'currentState': array([36.97913394,  8.36695336, 26.80382413,  0.85390086,  0.03761947,
       -0.51907428]), 'targetState': array([25., 25., 15.])}
episode index:2080
target thresh 26.90136669592549
model initialize at round 2080
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.46419188355108143
{'scaleFactor': 20, 'currentState': array([25.24478962, 20.18204127, 13.5565246 ,  0.59078763,  0.79415703,
        0.14242397]), 'targetState': array([25., 25., 15.])}
episode index:2081
target thresh 26.908676193774905
model initialize at round 2081
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.92862414,  0.98565964,  0.15305274,
       -0.07106293]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4644256963110953
{'scaleFactor': 20, 'currentState': array([25.29226028, 20.09420163, 15.86552847,  0.55121391,  0.75290544,
        0.3595784 ]), 'targetState': array([25., 25., 15.])}
episode index:2082
target thresh 26.915984960711093
model initialize at round 2082
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87307212,  0.98032172,  0.15222387,
       -0.12568703]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4646592845749402
{'scaleFactor': 20, 'currentState': array([25.29728502, 20.10314822, 15.69791386,  0.55801724,  0.75915354,
        0.33511588]), 'targetState': array([25., 25., 15.])}
episode index:2083
target thresh 26.923292996807124
model initialize at round 2083
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.1358401 , 14.90628839,  0.98638932,  0.13534467,
       -0.09336983]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.4648835677147349
{'scaleFactor': 20, 'currentState': array([28.86269151, 21.35172473, 16.42983385,  0.50387581,  0.75107398,
        0.42661112]), 'targetState': array([25., 25., 15.])}
episode index:2084
target thresh 26.93060030213609
model initialize at round 2084
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.46510763571482716
{'scaleFactor': 20, 'currentState': array([29.15468237, 21.23900435, 15.74424778,  0.62197498,  0.66257142,
        0.41730831]), 'targetState': array([25., 25., 15.])}
episode index:2085
target thresh 26.937906876771066
model initialize at round 2085
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14426928, 14.97488073,  0.98923631,  0.14415799,
       -0.0250999 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4653360022122798
{'scaleFactor': 20, 'currentState': array([26.83896327, 20.92981957, 17.12634079,  0.61613194,  0.68136387,
        0.39512619]), 'targetState': array([25., 25., 15.])}
episode index:2086
target thresh 26.945212720785094
model initialize at round 2086
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11297731, 14.91749159,  0.99016264,  0.11299587,
       -0.08252196]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.46511303335640425
{'scaleFactor': 20, 'currentState': array([37.28992303, 19.15977115, 29.52469435,  0.45188825,  0.79355431,
        0.40751511]), 'targetState': array([25., 25., 15.])}
episode index:2087
target thresh 26.952517834251253
model initialize at round 2087
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14411702, 14.93204479,  0.98729475,  0.14372321,
       -0.06776952]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.46534117852692364
{'scaleFactor': 20, 'currentState': array([27.0145941 , 20.89167227, 16.18141518,  0.59182349,  0.72881069,
        0.34435436]), 'targetState': array([25., 25., 15.])}
episode index:2088
target thresh 26.95982221724259
model initialize at round 2088
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11630781, 14.84947911,  0.98203653,  0.11537224,
       -0.14931011]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.465569105272196
{'scaleFactor': 20, 'currentState': array([26.52979887, 21.30189823, 16.13362741,  0.47416683,  0.80085017,
        0.36579341]), 'targetState': array([25., 25., 15.])}
episode index:2089
target thresh 26.967125869832152
model initialize at round 2089
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15156645, 14.84627329,  0.97704036,  0.14958237,
       -0.15171434]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4658013640973768
{'scaleFactor': 20, 'currentState': array([25.32743371, 20.1635946 , 14.09311678,  0.59765874,  0.79488708,
        0.10468311]), 'targetState': array([25., 25., 15.])}
episode index:2090
target thresh 26.974428792092976
model initialize at round 2090
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.46603340077160094
{'scaleFactor': 20, 'currentState': array([25.30805863, 20.14784503, 14.85343699,  0.56995128,  0.76737918,
        0.29374261]), 'targetState': array([25., 25., 15.])}
episode index:2091
target thresh 26.981730984098075
model initialize at round 2091
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85737139,  0.97829391,  0.15190899,
       -0.14094212]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4662652156134406
{'scaleFactor': 20, 'currentState': array([25.43354443, 20.08092545, 14.56301407,  0.62051914,  0.76021813,
        0.19241723]), 'targetState': array([25., 25., 15.])}
episode index:2092
target thresh 26.98903244592049
model initialize at round 2092
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4664922652712464
{'scaleFactor': 20, 'currentState': array([26.96649123, 21.08417326, 13.06872231,  0.59930532,  0.79992438,
       -0.03088878]), 'targetState': array([25., 25., 15.])}
episode index:2093
target thresh 26.996333177633225
model initialize at round 2093
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4667236395714512
{'scaleFactor': 20, 'currentState': array([25.39807985, 20.08436194, 14.42722348,  0.59567712,  0.77081745,
        0.22585224]), 'targetState': array([25., 25., 15.])}
episode index:2094
target thresh 27.003633179309304
model initialize at round 2094
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13289145, 14.88169921,  0.98423197,  0.13211719,
       -0.11761153]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.46695025365728865
{'scaleFactor': 20, 'currentState': array([27.51974696, 20.36977732, 15.25135723,  0.65931658,  0.70955258,
        0.24867004]), 'targetState': array([25., 25., 15.])}
episode index:2095
target thresh 27.010932451021695
model initialize at round 2095
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13588388, 14.84627329,  0.9791924 ,  0.13440047,
       -0.15204851]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4671766515083114
{'scaleFactor': 20, 'currentState': array([26.81292827, 21.28869758, 14.97869377,  0.5166707 ,  0.78887811,
        0.33275024]), 'targetState': array([25., 25., 15.])}
episode index:2096
target thresh 27.018230992843417
model initialize at round 2096
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87291969,  0.98030311,  0.15222098,
       -0.12583558]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.46740736843649056
{'scaleFactor': 20, 'currentState': array([25.33235786, 20.1510485 , 14.51739974,  0.5882412 ,  0.78138798,
        0.20833893]), 'targetState': array([25., 25., 15.])}
episode index:2097
target thresh 27.025528804847454
model initialize at round 2097
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4676378654247954
{'scaleFactor': 20, 'currentState': array([25.1729109 , 20.14269449, 12.81336874,  0.5884739 ,  0.80076276,
       -0.1117026 ]), 'targetState': array([25., 25., 15.])}
episode index:2098
target thresh 27.03282588710678
model initialize at round 2098
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4678681427875754
{'scaleFactor': 20, 'currentState': array([25.20025538, 20.18859982, 13.28965667,  0.59062594,  0.79946795,
        0.10959925]), 'targetState': array([25., 25., 15.])}
episode index:2099
target thresh 27.04012223969435
model initialize at round 2099
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89180151,  0.98244515,  0.1525536 ,
       -0.10737281]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.46809820083858134
{'scaleFactor': 20, 'currentState': array([25.33582399, 20.15987805, 14.7134258 ,  0.5749209 ,  0.77106078,
        0.27373569]), 'targetState': array([25., 25., 15.])}
episode index:2100
target thresh 27.047417862683165
model initialize at round 2100
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.91737757,  0.98481463,  0.15292153,
       -0.08218967]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.46832351352233303
{'scaleFactor': 20, 'currentState': array([26.90367078, 21.32868908, 14.51385141,  0.55065213,  0.82741327,
        0.11031551]), 'targetState': array([25., 25., 15.])}
episode index:2101
target thresh 27.054712756146138
model initialize at round 2101
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.468553136042018
{'scaleFactor': 20, 'currentState': array([25.26619562, 20.15031775, 13.35575786,  0.60294205,  0.7969125 ,
        0.03730075]), 'targetState': array([25., 25., 15.])}
episode index:2102
target thresh 27.062006920156247
model initialize at round 2102
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10985867, 14.84627329,  0.98227007,  0.10900089,
       -0.15252641]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.46877354127828286
{'scaleFactor': 20, 'currentState': array([29.68318752, 20.31583193, 15.16879394,  0.77067341,  0.57432381,
        0.27607001]), 'targetState': array([25., 25., 15.])}
episode index:2103
target thresh 27.069300354786417
model initialize at round 2103
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.04207914, 14.91200178,  0.99518129,  0.04229937,
       -0.08845877]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.4689937370038669
{'scaleFactor': 20, 'currentState': array([29.70003623, 20.0393134 , 14.62148365,  0.66773598,  0.72846927,
        0.15317043]), 'targetState': array([25., 25., 15.])}
episode index:2104
target thresh 27.076593060109598
model initialize at round 2104
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4692227138746014
{'scaleFactor': 20, 'currentState': array([ 2.53937465e+01,  2.00530799e+01,  1.34381549e+01,  6.69844028e-01,
        7.42441158e-01, -9.49242777e-03]), 'targetState': array([25., 25., 15.])}
episode index:2105
target thresh 27.08388503619871
model initialize at round 2105
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14198198, 14.84627329,  0.97838183,  0.14031575,
       -0.15192264]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.46944695767114764
{'scaleFactor': 20, 'currentState': array([27.65028903, 20.03992177, 13.26644042,  0.72309554,  0.68520422,
        0.08733854]), 'targetState': array([25., 25., 15.])}
episode index:2106
target thresh 27.09117628312666
model initialize at round 2106
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86920121,  0.97984258,  0.15214947,
       -0.12945679]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4696709886116933
{'scaleFactor': 20, 'currentState': array([26.52192261, 21.46049774, 15.42824051,  0.44133361,  0.78187401,
        0.44033813]), 'targetState': array([25., 25., 15.])}
episode index:2107
target thresh 27.09846680096638
model initialize at round 2107
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.1231373 , 14.84792129,  0.98102026,  0.12202039,
       -0.15069929]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.46989480699916447
{'scaleFactor': 20, 'currentState': array([ 2.67321697e+01,  2.11712785e+01,  1.27042103e+01,  5.91894321e-01,
        8.05892307e-01, -1.40961632e-02]), 'targetState': array([25., 25., 15.])}
episode index:2108
target thresh 27.105756589790776
model initialize at round 2108
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.05370743, 14.84627329,  0.98674105,  0.05353063,
       -0.15322066]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4701184131359126
{'scaleFactor': 20, 'currentState': array([27.16873331, 20.13655848, 12.11010451,  0.6402156 ,  0.76742259,
       -0.03444638]), 'targetState': array([25., 25., 15.])}
episode index:2109
target thresh 27.113045649672717
model initialize at round 2109
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.47034631438556385
{'scaleFactor': 20, 'currentState': array([25.23675518, 20.18457791, 13.7527437 ,  0.58339397,  0.78676781,
        0.2016132 ]), 'targetState': array([25., 25., 15.])}
episode index:2110
target thresh 27.12033398068513
model initialize at round 2110
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89493631,  0.98276872,  0.15260384,
       -0.10429627]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.470573999717404
{'scaleFactor': 20, 'currentState': array([25.27319931, 20.09110262, 15.54816567,  0.54170906,  0.7418876 ,
        0.39516338]), 'targetState': array([25., 25., 15.])}
episode index:2111
target thresh 27.127621582900886
model initialize at round 2111
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.88258115,  0.98144036,  0.15239757,
       -0.11640363]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.47079696664433746
{'scaleFactor': 20, 'currentState': array([26.55065582, 21.48109096, 16.11846363,  0.5092224 ,  0.75180787,
        0.41890033]), 'targetState': array([25., 25., 15.])}
episode index:2112
target thresh 27.134908456392836
model initialize at round 2112
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09475211, 14.90745548,  0.99116905,  0.094864  ,
       -0.0926538 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4710197225282734
{'scaleFactor': 20, 'currentState': array([26.83495231, 21.05801143, 14.39257034,  0.50664334,  0.80931272,
        0.29719597]), 'targetState': array([25., 25., 15.])}
episode index:2113
target thresh 27.142194601233882
model initialize at round 2113
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84923695,  0.97715596,  0.15173229,
       -0.14880708]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4712467662025268
{'scaleFactor': 20, 'currentState': array([25.30733131, 20.1526233 , 14.73114088,  0.57534874,  0.77411785,
        0.26403671]), 'targetState': array([25., 25., 15.])}
episode index:2114
target thresh 27.149480017496884
model initialize at round 2114
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85870381,  0.97847466,  0.15193706,
       -0.13965125]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4714735951782703
{'scaleFactor': 20, 'currentState': array([25.29843213, 20.05742021, 15.43659297,  0.58098295,  0.71288326,
        0.39275471]), 'targetState': array([25., 25., 15.])}
episode index:2115
target thresh 27.156764705254666
model initialize at round 2115
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10611736, 14.97917311,  0.99408681,  0.10655542,
       -0.02091287]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.47169571547799743
{'scaleFactor': 20, 'currentState': array([26.75661003, 21.27320783, 15.62711881,  0.50609657,  0.81146576,
        0.29221496]), 'targetState': array([25., 25., 15.])}
episode index:2116
target thresh 27.164048664580108
model initialize at round 2116
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09861062, 14.86130916,  0.98554593,  0.09816697,
       -0.13806686]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4719176259333224
{'scaleFactor': 20, 'currentState': array([27.30780299, 20.47412148, 13.81210558,  0.69018262,  0.69882711,
        0.18785264]), 'targetState': array([25., 25., 15.])}
episode index:2117
target thresh 27.171331895546036
model initialize at round 2117
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.02817155, 14.84627329,  0.98776743,  0.02810802,
       -0.15338004]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.47213488170384826
{'scaleFactor': 20, 'currentState': array([29.52182861, 20.00072322, 14.19695335,  0.65649413,  0.70820818,
        0.25972415]), 'targetState': array([25., 25., 15.])}
episode index:2118
target thresh 27.178614398225275
model initialize at round 2118
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85676705,  0.9782114 ,  0.15189618,
       -0.14152738]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.47235637545925035
{'scaleFactor': 20, 'currentState': array([27.3653415 , 20.53926666, 13.43186161,  0.65236805,  0.7553955 ,
        0.06159194]), 'targetState': array([25., 25., 15.])}
episode index:2119
target thresh 27.185896172690672
model initialize at round 2119
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.47258214606040166
{'scaleFactor': 20, 'currentState': array([25.16491157, 20.17488767, 12.91518867,  0.59116315,  0.80579415,
       -0.03495584]), 'targetState': array([25., 25., 15.])}
episode index:2120
target thresh 27.19317721901502
model initialize at round 2120
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84704901,  0.97683982,  0.1516832 ,
       -0.1509178 ]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.47280770377083997
{'scaleFactor': 20, 'currentState': array([25.27056882, 20.16548295, 14.30155827,  0.57538853,  0.77572679,
        0.25918331]), 'targetState': array([25., 25., 15.])}
episode index:2121
target thresh 27.200457537271127
model initialize at round 2121
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4730285673173198
{'scaleFactor': 20, 'currentState': array([26.74556943, 21.41062534, 12.76369748,  0.65577005,  0.75187016,
       -0.06824154]), 'targetState': array([25., 25., 15.])}
episode index:2122
target thresh 27.20773712753183
model initialize at round 2122
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08146739, 14.84627329,  0.984907  ,  0.08104829,
       -0.15293587]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.4728057559337506
{'scaleFactor': 20, 'currentState': array([ 6.65892847, 10.37769453, 22.71118927,  0.55249529,  0.08882286,
       -0.82876984]), 'targetState': array([25., 25., 15.])}
episode index:2123
target thresh 27.215015989869883
model initialize at round 2123
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.06845321, 14.84627329,  0.98585934,  0.0681669 ,
       -0.15308375]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.47258315435374415
{'scaleFactor': 20, 'currentState': array([36.32709149, 24.30272647, 24.20217058,  0.79804409,  0.59323335,
        0.10582923]), 'targetState': array([25., 25., 15.])}
episode index:2124
target thresh 27.222294124358115
model initialize at round 2124
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.02432087, 14.91583007,  0.99610688,  0.0244709 ,
       -0.08468914]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.47236076228110707
{'scaleFactor': 20, 'currentState': array([25.48732205, 37.86352679, 70.91928691, -0.74362546, -0.58111378,
        0.33064778]), 'targetState': array([25., 25., 15.])}
episode index:2125
target thresh 27.229571531069286
model initialize at round 2125
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89174552,  0.98243929,  0.15255268,
       -0.10742773]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.47258589364875475
{'scaleFactor': 20, 'currentState': array([25.29801866, 20.11285655, 15.31502391,  0.55081762,  0.74871791,
        0.36881085]), 'targetState': array([25., 25., 15.])}
episode index:2126
target thresh 27.236848210076147
model initialize at round 2126
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.93469836,  0.98606546,  0.15311575,
       -0.06504211]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4728108133272932
{'scaleFactor': 20, 'currentState': array([25.37611234, 20.17700907, 14.62239962,  0.59846189,  0.79515325,
        0.0978503 ]), 'targetState': array([25., 25., 15.])}
episode index:2127
target thresh 27.244124161451523
model initialize at round 2127
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.47303552161515633
{'scaleFactor': 20, 'currentState': array([25.25462295, 20.17082826, 14.12566447,  0.57505571,  0.77573444,
        0.25989806]), 'targetState': array([25., 25., 15.])}
episode index:2128
target thresh 27.251399385268115
model initialize at round 2128
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.8980338 ,  0.98307939,  0.15265208,
       -0.1012534 ]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.47326001881021734
{'scaleFactor': 20, 'currentState': array([25.3230439 , 20.1219407 , 15.40532174,  0.55575111,  0.75290814,
        0.35251955]), 'targetState': array([25., 25., 15.])}
episode index:2129
target thresh 27.258673881598718
model initialize at round 2129
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.96069158,  0.98739815,  0.15332269,
       -0.03920511]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.47348430520979
{'scaleFactor': 20, 'currentState': array([25.41633558, 20.10232607, 15.50565406,  0.59204491,  0.77539348,
        0.21965377]), 'targetState': array([25., 25., 15.])}
episode index:2130
target thresh 27.265947650516043
model initialize at round 2130
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.47370838111063013
{'scaleFactor': 20, 'currentState': array([25.24697157, 20.18855077, 13.62797969,  0.59266694,  0.79746932,
        0.11308662]), 'targetState': array([25., 25., 15.])}
episode index:2131
target thresh 27.27322069209286
model initialize at round 2131
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13998859, 14.84627329,  0.97865049,  0.13838374,
       -0.15196436]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4739322468089366
{'scaleFactor': 20, 'currentState': array([25.29911873, 20.05676497, 13.60788423,  0.60438167,  0.7790973 ,
        0.16652384]), 'targetState': array([25., 25., 15.])}
episode index:2132
target thresh 27.280493006401862
model initialize at round 2132
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10543907, 14.9439317 ,  0.99280314,  0.10573762,
       -0.05622706]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.47414703025999055
{'scaleFactor': 20, 'currentState': array([28.69054981, 21.35052594, 17.06187591,  0.48227306,  0.72386488,
        0.49338862]), 'targetState': array([25., 25., 15.])}
episode index:2133
target thresh 27.287764593515806
model initialize at round 2133
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09197406, 14.91524756,  0.99211436,  0.09217049,
       -0.08493344]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.47436161241446434
{'scaleFactor': 20, 'currentState': array([29.39955683, 20.87934195, 15.47944831,  0.77901059,  0.57134557,
        0.25827647]), 'targetState': array([25., 25., 15.])}
episode index:2134
target thresh 27.2950354535074
model initialize at round 2134
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12382239, 14.86217378,  0.98293448,  0.12293868,
       -0.13684257]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.4745759935552103
{'scaleFactor': 20, 'currentState': array([29.00632725, 21.13958237, 15.85268992,  0.57167708,  0.73615287,
        0.36230411]), 'targetState': array([25., 25., 15.])}
episode index:2135
target thresh 27.30230558644934
model initialize at round 2135
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10011875, 14.89596823,  0.98953188,  0.10007141,
       -0.10398258]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4747945816431531
{'scaleFactor': 20, 'currentState': array([26.85559332, 20.98205701, 14.99455942,  0.49394365,  0.78000357,
        0.3842058 ]), 'targetState': array([25., 25., 15.])}
episode index:2136
target thresh 27.309574992414344
model initialize at round 2136
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14452535, 14.85903515,  0.97983373,  0.14304123,
       -0.13951729]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.47501741527359614
{'scaleFactor': 20, 'currentState': array([25.3561999 , 20.07458066, 14.6518855 ,  0.59373143,  0.78088838,
        0.19415543]), 'targetState': array([25., 25., 15.])}
episode index:2137
target thresh 27.316843671475088
model initialize at round 2137
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.47524004045349627
{'scaleFactor': 20, 'currentState': array([25.22747636, 20.18988619, 13.48152972,  0.59386757,  0.80096888,
        0.07596158]), 'targetState': array([25., 25., 15.])}
episode index:2138
target thresh 27.324111623704272
model initialize at round 2138
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4754624574752104
{'scaleFactor': 20, 'currentState': array([25.27342431, 20.15423571, 14.41602726,  0.5730004 ,  0.76496589,
        0.29410497]), 'targetState': array([25., 25., 15.])}
episode index:2139
target thresh 27.33137884917458
model initialize at round 2139
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.93016685,  0.98576607,  0.15306927,
       -0.06953449]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.47568466663054904
{'scaleFactor': 20, 'currentState': array([25.40324431, 20.02858158, 14.93521386,  0.5810584 ,  0.75459072,
        0.30489995]), 'targetState': array([25., 25., 15.])}
episode index:2140
target thresh 27.338645347958668
model initialize at round 2140
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.96829721,  0.9876635 ,  0.1533639 ,
       -0.03162797]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4759066682107777
{'scaleFactor': 20, 'currentState': array([25.36802381, 20.15093812, 15.29464738,  0.58007107,  0.7763178 ,
        0.24667436]), 'targetState': array([25., 25., 15.])}
episode index:2141
target thresh 27.34591112012921
model initialize at round 2141
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86925973,  0.97984992,  0.15215061,
       -0.12939984]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.47612846250661767
{'scaleFactor': 20, 'currentState': array([25.30672179, 20.17303466, 14.31564452,  0.58117032,  0.77938924,
        0.23408007]), 'targetState': array([25., 25., 15.])}
episode index:2142
target thresh 27.353176165758853
model initialize at round 2142
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86949739,  0.97987972,  0.15215524,
       -0.12916855]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.47635004980824786
{'scaleFactor': 20, 'currentState': array([25.29064342, 20.17934979, 14.07869061,  0.58747508,  0.78753054,
        0.18619527]), 'targetState': array([25., 25., 15.])}
episode index:2143
target thresh 27.360440484920268
model initialize at round 2143
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.47656699481738624
{'scaleFactor': 20, 'currentState': array([26.71923545, 21.44200141, 14.35267268,  0.58638609,  0.74795836,
        0.31098175]), 'targetState': array([25., 25., 15.])}
episode index:2144
target thresh 27.367704077686085
model initialize at round 2144
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.4767793483619502
{'scaleFactor': 20, 'currentState': array([29.3854015 , 20.87279332, 12.16809007,  0.86976984,  0.49212735,
        0.03620916]), 'targetState': array([25., 25., 15.])}
episode index:2145
target thresh 27.374966944128943
model initialize at round 2145
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.50028386e+01,  1.48568187e+01,  9.89698716e-01,
        2.83777956e-03, -1.43137693e-01]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.4765571771837759
{'scaleFactor': 20, 'currentState': array([60.88758663, 56.34628056, 43.23845704, -0.39901048, -0.54608811,
        0.73659922]), 'targetState': array([25., 25., 15.])}
episode index:2146
target thresh 27.382229084321473
model initialize at round 2146
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86953979,  0.97988503,  0.15215606,
       -0.12912728]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4767737225830387
{'scaleFactor': 20, 'currentState': array([27.25861833, 20.7831998 , 15.00311909,  0.66286862,  0.68563605,
        0.30084614]), 'targetState': array([25., 25., 15.])}
episode index:2147
target thresh 27.38949049833629
model initialize at round 2147
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10693923, 14.903445  ,  0.98957513,  0.10689334,
       -0.09651356]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4769900663571625
{'scaleFactor': 20, 'currentState': array([26.76631387, 21.2813416 , 14.32044245,  0.50547181,  0.83511151,
        0.21699542]), 'targetState': array([25., 25., 15.])}
episode index:2148
target thresh 27.396751186246004
model initialize at round 2148
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.90731181,  0.98395592,  0.15278819,
       -0.09212231]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.47721063405541414
{'scaleFactor': 20, 'currentState': array([25.35282776, 20.09672903, 15.24309575,  0.57922579,  0.74010359,
        0.34167843]), 'targetState': array([25., 25., 15.])}
episode index:2149
target thresh 27.404011148123242
model initialize at round 2149
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12280789, 14.96138651,  0.9916511 ,  0.1230127 ,
       -0.03867788]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.47742657336487726
{'scaleFactor': 20, 'currentState': array([27.21668727, 20.58517656, 15.32063241,  0.5648376 ,  0.7395052 ,
        0.36618375]), 'targetState': array([25., 25., 15.])}
episode index:2150
target thresh 27.411270384040577
model initialize at round 2150
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15297352, 14.9071695 ,  0.98405537,  0.15205497,
       -0.09227309]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.47764231189395034
{'scaleFactor': 20, 'currentState': array([27.24144945, 20.64741115, 15.53772327,  0.56975475,  0.73165046,
        0.37425544]), 'targetState': array([25., 25., 15.])}
episode index:2151
target thresh 27.418528894070626
model initialize at round 2151
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.92563037,  0.98544655,  0.15301965,
       -0.07402757]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.47786226902127654
{'scaleFactor': 20, 'currentState': array([25.38577056, 20.10387987, 14.74185935,  0.64090249,  0.7337781 ,
        0.22541894]), 'targetState': array([25., 25., 15.])}
episode index:2152
target thresh 27.425786678285956
model initialize at round 2152
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09422275, 14.84627329,  0.98381655,  0.09363424,
       -0.15276655]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4780776047762137
{'scaleFactor': 20, 'currentState': array([26.92009109, 20.89716088, 13.86104431,  0.53505861,  0.8131126 ,
        0.22926007]), 'targetState': array([25., 25., 15.])}
episode index:2153
target thresh 27.433043736759167
model initialize at round 2153
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14913019, 14.86060848,  0.97939676,  0.14753295,
       -0.13789859]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.47829715558639185
{'scaleFactor': 20, 'currentState': array([25.40040716, 20.05689598, 13.7687637 ,  0.65196442,  0.75452888,
        0.07502369]), 'targetState': array([25., 25., 15.])}
episode index:2154
target thresh 27.440300069562795
model initialize at round 2154
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.05110845, 14.84627329,  0.9868746 ,  0.0509471 ,
       -0.1532414 ]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.4785077208728515
{'scaleFactor': 20, 'currentState': array([28.95742424, 20.08187383, 10.71477418,  0.64219533,  0.74907125,
       -0.16271882]), 'targetState': array([25., 25., 15.])}
episode index:2155
target thresh 27.44755567676944
model initialize at round 2155
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.47872686852082325
{'scaleFactor': 20, 'currentState': array([25.25755796, 20.17099973, 14.14383753,  0.57497558,  0.77572292,
        0.26010966]), 'targetState': array([25., 25., 15.])}
episode index:2156
target thresh 27.454810558451637
model initialize at round 2156
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.88646013,  0.9818727 ,  0.15246471,
       -0.11260778]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4789458129720885
{'scaleFactor': 20, 'currentState': array([25.31536145, 20.14645317, 14.85838677,  0.57550334,  0.77374135,
        0.26480224]), 'targetState': array([25., 25., 15.])}
episode index:2157
target thresh 27.462064714681922
model initialize at round 2157
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.47916455450912643
{'scaleFactor': 20, 'currentState': array([25.36633988, 20.02885448, 14.36010038,  0.58686288,  0.76123441,
        0.27588791]), 'targetState': array([25., 25., 15.])}
episode index:2158
target thresh 27.469318145532874
model initialize at round 2158
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84778782,  0.97694704,  0.15169985,
       -0.1502053 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4793786886429346
{'scaleFactor': 20, 'currentState': array([26.39749206, 21.5289341 , 15.20198436,  0.42358255,  0.79050071,
        0.44236462]), 'targetState': array([25., 25., 15.])}
episode index:2159
target thresh 27.476570851077
model initialize at round 2159
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.90492829,  0.9837385 ,  0.15275442,
       -0.09447041]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.47959702723610914
{'scaleFactor': 20, 'currentState': array([25.34979834, 20.1369641 , 14.36735785,  0.61669828,  0.74990759,
        0.23941981]), 'targetState': array([25., 25., 15.])}
episode index:2160
target thresh 27.483822831386828
model initialize at round 2160
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.91110961,  0.98429123,  0.15284025,
       -0.08837781]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4798151637574714
{'scaleFactor': 20, 'currentState': array([25.35537807, 20.16303796, 14.80006871,  0.58353976,  0.78007645,
        0.22574782]), 'targetState': array([25., 25., 15.])}
episode index:2161
target thresh 27.491074086534883
model initialize at round 2161
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.48003309848741704
{'scaleFactor': 20, 'currentState': array([ 2.52057761e+01,  2.00108577e+01,  1.26393265e+01,  6.11579866e-01,
        7.90833361e-01, -2.35087796e-02]), 'targetState': array([25., 25., 15.])}
episode index:2162
target thresh 27.498324616593685
model initialize at round 2162
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.48025083170582317
{'scaleFactor': 20, 'currentState': array([25.26539962, 20.18789217, 13.74893861,  0.59118337,  0.79389294,
        0.14225407]), 'targetState': array([25., 25., 15.])}
episode index:2163
target thresh 27.505574421635735
model initialize at round 2163
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4804639690984735
{'scaleFactor': 20, 'currentState': array([27.29956709, 20.43392565, 15.78639619,  0.69852547,  0.56896297,
        0.43398537]), 'targetState': array([25., 25., 15.])}
episode index:2164
target thresh 27.51282350173353
model initialize at round 2164
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.50127753e+01,  1.49900563e+01,  9.99866324e-01,
        1.29026251e-02, -1.00427527e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.4802420457871116
{'scaleFactor': 20, 'currentState': array([3.69416111e+01, 2.38649645e+01, 2.98282442e+01, 1.95432629e-02,
       8.53695249e-01, 5.20406074e-01]), 'targetState': array([25., 25., 15.])}
episode index:2165
target thresh 27.52007185695955
model initialize at round 2165
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.1157748 , 14.93021955,  0.99080629,  0.11586909,
       -0.06983728]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4804549904332861
{'scaleFactor': 20, 'currentState': array([27.45658683, 20.49115677, 14.86191249,  0.690853  ,  0.68444419,
        0.23293408]), 'targetState': array([25., 25., 15.])}
episode index:2166
target thresh 27.527319487386304
model initialize at round 2166
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12326068, 14.84627329,  0.98076298,  0.12211062,
       -0.15229239]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4806677385454078
{'scaleFactor': 20, 'currentState': array([26.9034765 , 20.91110771, 14.64613039,  0.51382448,  0.78605215,
        0.34366614]), 'targetState': array([25., 25., 15.])}
episode index:2167
target thresh 27.534566393086234
model initialize at round 2167
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14559034, 14.86829945,  0.98089946,  0.144252  ,
       -0.1304899 ]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4808846768809034
{'scaleFactor': 20, 'currentState': array([25.29493507, 20.11050019, 13.49414035,  0.60169808,  0.7961772 ,
        0.06372819]), 'targetState': array([25., 25., 15.])}
episode index:2168
target thresh 27.54181257413184
model initialize at round 2168
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.48110141518105054
{'scaleFactor': 20, 'currentState': array([25.29677885, 20.17426849, 14.28242631,  0.58084001,  0.77960281,
        0.23418867]), 'targetState': array([25., 25., 15.])}
episode index:2169
target thresh 27.549058030595564
model initialize at round 2169
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.93931948,  0.98635034,  0.15315999,
       -0.06045682]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4813179537223956
{'scaleFactor': 20, 'currentState': array([25.35276618, 20.14154027, 15.2528403 ,  0.56686661,  0.76206552,
        0.31291914]), 'targetState': array([25., 25., 15.])}
episode index:2170
target thresh 27.556302762549866
model initialize at round 2170
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.51537267e+01,  1.49964709e+01,  9.88151733e-01,
        1.53439710e-01, -3.52251956e-03]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4815342927809758
{'scaleFactor': 20, 'currentState': array([25.37218759, 20.07461832, 15.94486491,  0.59699456,  0.71654895,
        0.36077015]), 'targetState': array([25., 25., 15.])}
episode index:2171
target thresh 27.563546770067205
model initialize at round 2171
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.04373394, 14.98232886,  0.99886688,  0.04412564,
       -0.01782941]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.4813125919095297
{'scaleFactor': 20, 'currentState': array([38.44659917, 24.95317394, 26.84026227,  0.5132998 ,  0.8136236 ,
        0.27302005]), 'targetState': array([25., 25., 15.])}
episode index:2172
target thresh 27.570790053219994
model initialize at round 2172
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.0876568 , 14.86974665,  0.98765727,  0.08744937,
       -0.12994512]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.4815200252993122
{'scaleFactor': 20, 'currentState': array([29.45762278, 20.45068689, 14.10213621,  0.66311752,  0.72230235,
        0.19635294]), 'targetState': array([25., 25., 15.])}
episode index:2173
target thresh 27.578032612080694
model initialize at round 2173
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4817315984934712
{'scaleFactor': 20, 'currentState': array([27.33564928, 20.7080347 , 14.4892524 ,  0.68350272,  0.67788984,
        0.27072015]), 'targetState': array([25., 25., 15.])}
episode index:2174
target thresh 27.58527444672172
model initialize at round 2174
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84801952,  0.97698057,  0.15170506,
       -0.14998179]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4819429771375667
{'scaleFactor': 20, 'currentState': array([27.16310007, 20.93204698, 14.75571911,  0.67577961,  0.67032764,
        0.30656608]), 'targetState': array([25., 25., 15.])}
episode index:2175
target thresh 27.592515557215492
model initialize at round 2175
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11605862, 14.90528411,  0.98874474,  0.11591146,
       -0.0945958 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4821541614998201
{'scaleFactor': 20, 'currentState': array([27.24888515, 20.07004083, 12.01764105,  0.63850305,  0.75356515,
       -0.15637587]), 'targetState': array([25., 25., 15.])}
episode index:2176
target thresh 27.59975594363442
model initialize at round 2176
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08324891, 14.84627329,  0.984764  ,  0.08280862,
       -0.15291367]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4823651518479603
{'scaleFactor': 20, 'currentState': array([ 2.66649998e+01,  2.11241506e+01,  1.27105906e+01,  5.22242413e-01,
        8.52720627e-01, -1.14190190e-02]), 'targetState': array([25., 25., 15.])}
episode index:2177
target thresh 27.606995606050898
model initialize at round 2177
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4825803147947243
{'scaleFactor': 20, 'currentState': array([25.28616564, 20.13469787, 14.12946995,  0.5824499 ,  0.77013927,
        0.26007232]), 'targetState': array([25., 25., 15.])}
episode index:2178
target thresh 27.614234544537332
model initialize at round 2178
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89099655,  0.98236059,  0.15254046,
       -0.10816232]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4827952802536987
{'scaleFactor': 20, 'currentState': array([25.28936207, 20.16685734, 14.30169174,  0.57653302,  0.77530204,
        0.25790779]), 'targetState': array([25., 25., 15.])}
episode index:2179
target thresh 27.62147275916612
model initialize at round 2179
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86354551,  0.97911798,  0.15203695,
       -0.13495459]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4830100484966557
{'scaleFactor': 20, 'currentState': array([25.24776672, 20.18199842, 13.84146556,  0.58642636,  0.78993227,
        0.17919582]), 'targetState': array([25., 25., 15.])}
episode index:2180
target thresh 27.628710250009636
model initialize at round 2180
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85278806,  0.97766   ,  0.15181056,
       -0.14537699]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.48322025945534636
{'scaleFactor': 20, 'currentState': array([26.95164508, 21.1888154 , 14.50369827,  0.57969713,  0.76228565,
        0.28787469]), 'targetState': array([25., 25., 15.])}
episode index:2181
target thresh 27.63594701714024
model initialize at round 2181
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12759925, 14.88155752,  0.98488684,  0.12694022,
       -0.11783075]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4834302777367147
{'scaleFactor': 20, 'currentState': array([27.01395309, 20.91514411, 14.42842809,  0.56025459,  0.76212949,
        0.32445868]), 'targetState': array([25., 25., 15.])}
episode index:2182
target thresh 27.643183060630317
model initialize at round 2182
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4836444599502572
{'scaleFactor': 20, 'currentState': array([25.2737538 , 20.17061904, 13.94544525,  0.60111024,  0.78072809,
        0.1706755 ]), 'targetState': array([25., 25., 15.])}
episode index:2183
target thresh 27.65041838055223
model initialize at round 2183
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86474526,  0.97927412,  0.1520612 ,
       -0.13378936]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.48385844602624145
{'scaleFactor': 20, 'currentState': array([25.29465678, 20.1265848 , 14.81119196,  0.56252116,  0.75687959,
        0.33272094]), 'targetState': array([25., 25., 15.])}
episode index:2184
target thresh 27.65765297697833
model initialize at round 2184
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.90164245,  0.98342996,  0.15270652,
       -0.09770481]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.48406788387675626
{'scaleFactor': 20, 'currentState': array([26.92799933, 21.27584498, 14.98425754,  0.64627539,  0.68741001,
        0.33135419]), 'targetState': array([25., 25., 15.])}
episode index:2185
target thresh 27.664886849980952
model initialize at round 2185
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.04446379, 14.84627329,  0.98718612,  0.04433741,
       -0.15328977]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.48384644385668457
{'scaleFactor': 20, 'currentState': array([ 1.17516153, 43.87736722, 42.0808246 , -0.37402154, -0.79789106,
       -0.47273432]), 'targetState': array([25., 25., 15.])}
episode index:2186
target thresh 27.67211999963245
model initialize at round 2186
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.48406004404234676
{'scaleFactor': 20, 'currentState': array([25.26503459, 20.15043872, 14.50532489,  0.5651428 ,  0.7643062 ,
        0.31056344]), 'targetState': array([25., 25., 15.])}
episode index:2187
target thresh 27.679352426005146
model initialize at round 2187
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89995054,  0.98326712,  0.15268123,
       -0.09936904]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4842734489810385
{'scaleFactor': 20, 'currentState': array([25.3177619 , 20.12430421, 15.26064101,  0.55616187,  0.75323085,
        0.35117981]), 'targetState': array([25., 25., 15.])}
episode index:2188
target thresh 27.686584129171344
model initialize at round 2188
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.51537267e+01,  1.49921035e+01,  9.88127172e-01,
        1.53435896e-01, -7.88152106e-03]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.48448665894034365
{'scaleFactor': 20, 'currentState': array([25.47329511, 20.07214135, 15.11016666,  0.6410082 ,  0.7318482 ,
        0.23131515]), 'targetState': array([25., 25., 15.])}
episode index:2189
target thresh 27.693815109203403
model initialize at round 2189
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.1505777 , 14.91588854,  0.98516077,  0.14984166,
       -0.08370031]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.48469103277092196
{'scaleFactor': 20, 'currentState': array([29.75206053, 20.27209709, 14.81297379,  0.78300402,  0.54760779,
        0.29500917]), 'targetState': array([25., 25., 15.])}
episode index:2190
target thresh 27.701045366173616
model initialize at round 2190
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.50113094e+01,  1.48670172e+01,  9.91035015e-01,
        1.13212063e-02, -1.33121860e-01]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.48446981367791836
{'scaleFactor': 20, 'currentState': array([45.82190892, 30.61348874, 40.73046365, -0.51391767,  0.24656493,
        0.82164126]), 'targetState': array([25., 25., 15.])}
episode index:2191
target thresh 27.708274900154272
model initialize at round 2191
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.96251734,  0.98746701,  0.15333339,
       -0.03738676]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4846826422528372
{'scaleFactor': 20, 'currentState': array([25.36995714, 20.15419143, 15.11210364,  0.57524952,  0.76930247,
        0.27795987]), 'targetState': array([25., 25., 15.])}
episode index:2192
target thresh 27.715503711217682
model initialize at round 2192
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.90638487,  0.983872  ,  0.15277516,
       -0.09303566]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4848909402497128
{'scaleFactor': 20, 'currentState': array([26.71870529, 21.44473463, 15.42277146,  0.51031084,  0.79210169,
        0.33489964]), 'targetState': array([25., 25., 15.])}
episode index:2193
target thresh 27.72273179943612
model initialize at round 2193
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13492409, 14.84627329,  0.97931692,  0.13346813,
       -0.15206784]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.48510338287033733
{'scaleFactor': 20, 'currentState': array([25.29606217, 20.01636502, 13.31528983,  0.6068441 ,  0.78979464,
        0.08924496]), 'targetState': array([25., 25., 15.])}
episode index:2194
target thresh 27.72995916488189
model initialize at round 2194
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86046218,  0.97871074,  0.15197372,
       -0.13794663]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.48531129939267476
{'scaleFactor': 20, 'currentState': array([26.60502284, 21.49984011, 15.19595288,  0.46407476,  0.79606599,
        0.38847593]), 'targetState': array([25., 25., 15.])}
episode index:2195
target thresh 27.737185807627228
model initialize at round 2195
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84901376,  0.9771239 ,  0.15172731,
       -0.14902249]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.485523357111485
{'scaleFactor': 20, 'currentState': array([25.38675143, 20.01187331, 14.58013819,  0.62688658,  0.71281504,
        0.31449632]), 'targetState': array([25., 25., 15.])}
episode index:2196
target thresh 27.744411727744446
model initialize at round 2196
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13066232, 14.92179274,  0.98837594,  0.13044797,
       -0.07807896]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.48573089320265
{'scaleFactor': 20, 'currentState': array([26.90906952, 21.15397717, 14.86856684,  0.55102313,  0.78695792,
        0.27761618]), 'targetState': array([25., 25., 15.])}
episode index:2197
target thresh 27.751636925305768
model initialize at round 2197
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4859382404529678
{'scaleFactor': 20, 'currentState': array([26.88600484, 21.31804352, 13.59821815,  0.66826441,  0.72318933,
        0.17441295]), 'targetState': array([25., 25., 15.])}
episode index:2198
target thresh 27.758861400383473
model initialize at round 2198
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11567588, 14.84627329,  0.98163635,  0.11469864,
       -0.152428  ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4861453991200656
{'scaleFactor': 20, 'currentState': array([26.49915418, 21.38759685, 14.82132255,  0.44586593,  0.7991    ,
        0.40328993]), 'targetState': array([25., 25., 15.])}
episode index:2199
target thresh 27.76608515304977
model initialize at round 2199
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89194553,  0.98246022,  0.15255593,
       -0.10723153]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.48635669214314736
{'scaleFactor': 20, 'currentState': array([25.30935605, 20.16749893, 14.40886994,  0.58198132,  0.78046445,
        0.22841406]), 'targetState': array([25., 25., 15.])}
episode index:2200
target thresh 27.773308183376933
model initialize at round 2200
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86918235,  0.97984021,  0.1521491 ,
       -0.12947514]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.48656779316893417
{'scaleFactor': 20, 'currentState': array([25.32472748, 20.17517493, 14.34855158,  0.58803553,  0.78640866,
        0.18914447]), 'targetState': array([25., 25., 15.])}
episode index:2201
target thresh 27.780530491437172
model initialize at round 2201
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.48677870245900273
{'scaleFactor': 20, 'currentState': array([25.20421878, 20.18695996, 13.21534254,  0.5937082 ,  0.80355192,
        0.04260149]), 'targetState': array([25., 25., 15.])}
episode index:2202
target thresh 27.78775207730272
model initialize at round 2202
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4869851034789492
{'scaleFactor': 20, 'currentState': array([26.50211125, 21.55141762, 14.96678776,  0.44765329,  0.8023671 ,
        0.39473228]), 'targetState': array([25., 25., 15.])}
episode index:2203
target thresh 27.79497294104578
model initialize at round 2203
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.51537267e+01,  1.49939774e+01,  9.88140010e-01,
        1.53437890e-01, -6.01126372e-03]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4871956320390313
{'scaleFactor': 20, 'currentState': array([25.2815877 , 20.07989386, 16.20847987,  0.53535769,  0.7365207 ,
        0.41343609]), 'targetState': array([25., 25., 15.])}
episode index:2204
target thresh 27.80219308273858
model initialize at round 2204
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.51537267e+01, 1.50098759e+01, 9.88109857e-01,
       1.53433208e-01, 9.85707643e-03]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.48740596964350336
{'scaleFactor': 20, 'currentState': array([25.36529249, 20.14137258, 15.68038276,  0.56760244,  0.76235884,
        0.31086407]), 'targetState': array([25., 25., 15.])}
episode index:2205
target thresh 27.809412502453313
model initialize at round 2205
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.88127519,  0.98129166,  0.15237448,
       -0.11768047]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.48761611655205117
{'scaleFactor': 20, 'currentState': array([25.29639639, 20.1387427 , 14.85578489,  0.56570892,  0.76417739,
        0.3098489 ]), 'targetState': array([25., 25., 15.])}
episode index:2206
target thresh 27.816631200262155
model initialize at round 2206
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.91886112,  0.98493304,  0.15293991,
       -0.08072359]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4878260730238898
{'scaleFactor': 20, 'currentState': array([25.34713895, 20.13651336, 15.34334452,  0.56399145,  0.75968085,
        0.32372621]), 'targetState': array([25., 25., 15.])}
episode index:2207
target thresh 27.823849176237314
model initialize at round 2207
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12569807, 14.87851563,  0.98476587,  0.12503351,
       -0.12084209]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4880315322976113
{'scaleFactor': 20, 'currentState': array([26.70665836, 21.39514485, 14.73436347,  0.53105279,  0.80447931,
        0.26607513]), 'targetState': array([25., 25., 15.])}
episode index:2208
target thresh 27.831066430450967
model initialize at round 2208
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11977873, 14.84627329,  0.98117051,  0.11871046,
       -0.15235567]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.48823680555116655
{'scaleFactor': 20, 'currentState': array([26.58368312, 21.30881087, 15.19163017,  0.45616144,  0.79698121,
        0.39590112]), 'targetState': array([25., 25., 15.])}
episode index:2209
target thresh 27.83828296297528
model initialize at round 2209
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.48844619615946916
{'scaleFactor': 20, 'currentState': array([25.28735279, 20.1376761 , 14.81604653,  0.56064532,  0.75866359,
        0.33182283]), 'targetState': array([25., 25., 15.])}
episode index:2210
target thresh 27.845498773882426
model initialize at round 2210
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85007382,  0.97727575,  0.15175089,
       -0.14799921]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.48865109618354946
{'scaleFactor': 20, 'currentState': array([26.84436235, 21.1208213 , 14.70667248,  0.50969112,  0.77869495,
        0.36585399]), 'targetState': array([25., 25., 15.])}
episode index:2211
target thresh 27.85271386324455
model initialize at round 2211
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87787667,  0.98089733,  0.15231325,
       -0.12100046]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.48886011017709213
{'scaleFactor': 20, 'currentState': array([25.33206983, 20.17445281, 14.34864318,  0.58477141,  0.78123594,
        0.21843261]), 'targetState': array([25., 25., 15.])}
episode index:2212
target thresh 27.859928231133825
model initialize at round 2212
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85974009,  0.97861413,  0.15195872,
       -0.1386468 ]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4890689352741201
{'scaleFactor': 20, 'currentState': array([25.26672847, 20.1789164 , 14.00399322,  0.58180237,  0.78269072,
        0.22113625]), 'targetState': array([25., 25., 15.])}
episode index:2213
target thresh 27.86714187762237
model initialize at round 2213
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13357434, 14.84985541,  0.98001286,  0.13222684,
       -0.14862993]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4892732763825785
{'scaleFactor': 20, 'currentState': array([26.53315041, 21.51511425, 14.6011319 ,  0.46889629,  0.82411571,
        0.31775707]), 'targetState': array([25., 25., 15.])}
episode index:2214
target thresh 27.874354802782342
model initialize at round 2214
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85075795,  0.97737322,  0.15176603,
       -0.14733856]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4894774329843927
{'scaleFactor': 20, 'currentState': array([26.80736579, 21.25471211, 14.56871436,  0.51643136,  0.7847508 ,
        0.34273142]), 'targetState': array([25., 25., 15.])}
episode index:2215
target thresh 27.88156700668586
model initialize at round 2215
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87448732,  0.98049346,  0.15225054,
       -0.12430744]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.48968140532934606
{'scaleFactor': 20, 'currentState': array([27.62403545, 20.12642528, 13.56225781,  0.76120451,  0.62032606,
        0.18911178]), 'targetState': array([25., 25., 15.])}
episode index:2216
target thresh 27.88877848940504
model initialize at round 2216
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.02099329, 14.89732987,  0.99444422,  0.02108753,
       -0.10313103]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.4894605296390757
{'scaleFactor': 20, 'currentState': array([48.20272756,  7.2750345 , 27.15833   ,  0.95471351,  0.2088382 ,
        0.21191679]), 'targetState': array([25., 25., 15.])}
episode index:2217
target thresh 27.89598925101201
model initialize at round 2217
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.90916264,  0.98412104,  0.15281383,
       -0.09029794]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4896686132821149
{'scaleFactor': 20, 'currentState': array([25.38707873, 20.09012273, 14.27210184,  0.61214037,  0.75888177,
        0.22222202]), 'targetState': array([25., 25., 15.])}
episode index:2218
target thresh 27.903199291578872
model initialize at round 2218
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.1088145 , 14.88017899,  0.9868973 ,  0.10847347,
       -0.11944549]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.48987222370848665
{'scaleFactor': 20, 'currentState': array([26.68413054, 20.9167404 , 11.95715798,  0.52240595,  0.82310571,
       -0.22268592]), 'targetState': array([25., 25., 15.])}
episode index:2219
target thresh 27.91040861117773
model initialize at round 2219
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4900756507020419
{'scaleFactor': 20, 'currentState': array([26.10539686, 21.48297979, 11.09696069,  0.49588613,  0.81049624,
       -0.31175757]), 'targetState': array([25., 25., 15.])}
episode index:2220
target thresh 27.917617209880675
model initialize at round 2220
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10011533, 14.84627329,  0.98326073,  0.09943381,
       -0.15268024]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.48985499529875415
{'scaleFactor': 20, 'currentState': array([30.92075024, 23.04028415, 18.89317672,  0.3177632 ,  0.93553291,
       -0.15428777]), 'targetState': array([25., 25., 15.])}
episode index:2221
target thresh 27.924825087759785
model initialize at round 2221
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15370325, 14.84627329,  0.97673014,  0.15164303,
       -0.15166617]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.49005824694326466
{'scaleFactor': 20, 'currentState': array([27.57658624, 20.14831484, 13.02443586,  0.77236035,  0.62409505,
        0.11817301]), 'targetState': array([25., 25., 15.])}
episode index:2222
target thresh 27.93203224488715
model initialize at round 2222
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11640993, 14.84627329,  0.98155415,  0.11541682,
       -0.15241524]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4902613157252969
{'scaleFactor': 20, 'currentState': array([26.6648701 , 21.2239629 , 15.09648067,  0.55881796,  0.7272563 ,
        0.39852323]), 'targetState': array([25., 25., 15.])}
episode index:2223
target thresh 27.93923868133483
model initialize at round 2223
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.0699582 , 14.86460791,  0.98835814,  0.06984218,
       -0.13516755]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.49045996861746494
{'scaleFactor': 20, 'currentState': array([28.97256638, 21.07541347, 13.9810397 ,  0.58399814,  0.73074669,
        0.35349037]), 'targetState': array([25., 25., 15.])}
episode index:2224
target thresh 27.946444397174897
model initialize at round 2224
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.91331116,  0.98447933,  0.15286946,
       -0.08620542]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.49066694842927727
{'scaleFactor': 20, 'currentState': array([25.32621449, 20.16407647, 14.53923963,  0.57749579,  0.77429739,
        0.25877047]), 'targetState': array([25., 25., 15.])}
episode index:2225
target thresh 27.953649392479406
model initialize at round 2225
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.94355984,  0.98659355,  0.15319776,
       -0.05624596]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.49087374227540065
{'scaleFactor': 20, 'currentState': array([25.35349638, 20.1607112 , 14.82886155,  0.58280336,  0.77904859,
        0.23113531]), 'targetState': array([25., 25., 15.])}
episode index:2226
target thresh 27.960853667320418
model initialize at round 2226
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4910803504063502
{'scaleFactor': 20, 'currentState': array([25.33247694, 20.10449769, 13.89564046,  0.60591017,  0.77835997,
        0.16440386]), 'targetState': array([25., 25., 15.])}
episode index:2227
target thresh 27.96805722176996
model initialize at round 2227
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4912867730721911
{'scaleFactor': 20, 'currentState': array([25.27058089, 20.18055813, 13.99356474,  0.58691188,  0.78846395,
        0.18400826]), 'targetState': array([25., 25., 15.])}
episode index:2228
target thresh 27.975260055900076
model initialize at round 2228
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85053015,  0.97734081,  0.151761  ,
       -0.14755857]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.49149301052254
{'scaleFactor': 20, 'currentState': array([25.14238487, 20.17838899, 12.92431812,  0.59021744,  0.80533212,
        0.0555297 ]), 'targetState': array([25., 25., 15.])}
episode index:2229
target thresh 27.982462169782796
model initialize at round 2229
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.49169479847719405
{'scaleFactor': 20, 'currentState': array([27.64362554, 20.00243055, 13.5280479 ,  0.77439359,  0.59486948,
        0.2155107 ]), 'targetState': array([25., 25., 15.])}
episode index:2230
target thresh 27.98966356349013
model initialize at round 2230
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.07155519, 14.86452365,  0.9882356 ,  0.07142766,
       -0.1352349 ]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.49189218554551756
{'scaleFactor': 20, 'currentState': array([29.34688882, 20.40519585, 14.36910263,  0.60689318,  0.72380255,
        0.32831468]), 'targetState': array([25., 25., 15.])}
episode index:2231
target thresh 27.996864237094098
model initialize at round 2231
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.92648786,  0.98550846,  0.15302926,
       -0.07317862]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.49209787455284476
{'scaleFactor': 20, 'currentState': array([25.36360756, 20.11239631, 14.33085743,  0.59119136,  0.7773473 ,
        0.21499757]), 'targetState': array([25., 25., 15.])}
episode index:2232
target thresh 28.0040641906667
model initialize at round 2232
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.96215452,  0.98745359,  0.1533313 ,
       -0.03774813]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4923033793335645
{'scaleFactor': 20, 'currentState': array([25.36490295, 20.15262917, 15.20420994,  0.58534214,  0.78243816,
        0.21252083]), 'targetState': array([25., 25., 15.])}
episode index:2233
target thresh 28.011263424279953
model initialize at round 2233
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.49250870013507136
{'scaleFactor': 20, 'currentState': array([25.01006483, 20.12436264, 12.21156013,  0.5667002 ,  0.79635973,
       -0.211334  ]), 'targetState': array([25., 25., 15.])}
episode index:2234
target thresh 28.018461938005846
model initialize at round 2234
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4927138372043174
{'scaleFactor': 20, 'currentState': array([25.10858403, 20.06374297, 12.31315688,  0.59743163,  0.78135922,
       -0.18042507]), 'targetState': array([25., 25., 15.])}
episode index:2235
target thresh 28.025659731916353
model initialize at round 2235
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.492914537701722
{'scaleFactor': 20, 'currentState': array([25.64286041, 21.56536773, 10.53730224,  0.37706364,  0.83269669,
       -0.40551109]), 'targetState': array([25., 25., 15.])}
episode index:2236
target thresh 28.032856806083462
model initialize at round 2236
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4931150587619363
{'scaleFactor': 20, 'currentState': array([2.67016256e+01, 2.12106069e+01, 1.23116708e+01, 6.01718960e-01,
       7.98445661e-01, 2.04650852e-02]), 'targetState': array([25., 25., 15.])}
episode index:2237
target thresh 28.040053160579127
model initialize at round 2237
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09584746, 14.84627329,  0.98366657,  0.09523428,
       -0.15274326]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.49331119383304667
{'scaleFactor': 20, 'currentState': array([28.49928185, 21.52257371, 14.78734643,  0.44912938,  0.7854353 ,
        0.42588048]), 'targetState': array([25., 25., 15.])}
episode index:2238
target thresh 28.047248795475323
model initialize at round 2238
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4935113586189189
{'scaleFactor': 20, 'currentState': array([26.7842609 , 21.3583392 , 13.32584282,  0.6005855 ,  0.77784022,
        0.18509902]), 'targetState': array([25., 25., 15.])}
episode index:2239
target thresh 28.054443710844012
model initialize at round 2239
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12473228, 14.84627329,  0.98058739,  0.12354637,
       -0.15226512]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4937113446862324
{'scaleFactor': 20, 'currentState': array([26.44326162, 21.5248627 , 14.32829002,  0.45211573,  0.82030703,
        0.35026811]), 'targetState': array([25., 25., 15.])}
episode index:2240
target thresh 28.06163790675714
model initialize at round 2240
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86909772,  0.97982958,  0.15214745,
       -0.1295575 ]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4939153958710667
{'scaleFactor': 20, 'currentState': array([25.39240283, 20.07228208, 14.1283435 ,  0.62188195,  0.75653946,
        0.20226437]), 'targetState': array([25., 25., 15.])}
episode index:2241
target thresh 28.068831383286643
model initialize at round 2241
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85123659,  0.97744117,  0.15177658,
       -0.14687624]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.49411926502986636
{'scaleFactor': 20, 'currentState': array([25.25855074, 20.17999928, 13.94397367,  0.5813785 ,  0.78289565,
        0.22152527]), 'targetState': array([25., 25., 15.])}
episode index:2242
target thresh 28.07602414050446
model initialize at round 2242
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.494318712593117
{'scaleFactor': 20, 'currentState': array([26.85964803, 21.23922094, 14.5991297 ,  0.60107252,  0.72114077,
        0.34448197]), 'targetState': array([25., 25., 15.])}
episode index:2243
target thresh 28.083216178482516
model initialize at round 2243
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13442474, 14.84627329,  0.97938137,  0.13298291,
       -0.15207785]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.49451798239561606
{'scaleFactor': 20, 'currentState': array([27.42763713, 20.45677678, 13.84772307,  0.6963315 ,  0.67186603,
        0.2524252 ]), 'targetState': array([25., 25., 15.])}
episode index:2244
target thresh 28.090407497292734
model initialize at round 2244
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12288498, 14.91088937,  0.98844865,  0.12269242,
       -0.08897099]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.49471707467490583
{'scaleFactor': 20, 'currentState': array([26.99366824, 20.85711778, 15.14222367,  0.51519638,  0.76190655,
        0.39251892]), 'targetState': array([25., 25., 15.])}
episode index:2245
target thresh 28.097598097007026
model initialize at round 2245
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84722716,  0.97686572,  0.15168722,
       -0.15074601]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4949202238179268
{'scaleFactor': 20, 'currentState': array([ 2.52714567e+01,  2.01565596e+01,  1.33470431e+01,  6.24868293e-01,
        7.80728550e-01, -1.59603077e-03]), 'targetState': array([25., 25., 15.])}
episode index:2246
target thresh 28.1047879776973
model initialize at round 2246
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13190213, 14.84627329,  0.9797035 ,  0.13053028,
       -0.15212787]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4951189598773763
{'scaleFactor': 20, 'currentState': array([26.40225451, 21.66112771, 13.406473  ,  0.47916925,  0.87081886,
        0.10986969]), 'targetState': array([25., 25., 15.])}
episode index:2247
target thresh 28.111977139435464
model initialize at round 2247
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4953175191253851
{'scaleFactor': 20, 'currentState': array([27.1541816 , 20.7741448 , 13.48623198,  0.6517746 ,  0.74451231,
        0.14453821]), 'targetState': array([25., 25., 15.])}
episode index:2248
target thresh 28.11916558229337
model initialize at round 2248
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10617003, 14.84627329,  0.98265558,  0.1053824 ,
       -0.15258627]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4955159017978064
{'scaleFactor': 20, 'currentState': array([26.70981373, 20.94389197, 12.49793475,  0.53770171,  0.83702432,
        0.10132695]), 'targetState': array([25., 25., 15.])}
episode index:2249
target thresh 28.126353306342956
model initialize at round 2249
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89540417,  0.98281622,  0.15261121,
       -0.10383685]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4957183347525185
{'scaleFactor': 20, 'currentState': array([25.29493151, 20.1817418 , 13.94399758,  0.59096858,  0.79203903,
        0.15306962]), 'targetState': array([25., 25., 15.])}
episode index:2250
target thresh 28.13354031165606
model initialize at round 2250
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.49592058784676435
{'scaleFactor': 20, 'currentState': array([25.13992233, 20.17265124, 12.81717996,  0.5897959 ,  0.80675198,
       -0.03594495]), 'targetState': array([25., 25., 15.])}
episode index:2251
target thresh 28.14072659830458
model initialize at round 2251
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.49611843845136216
{'scaleFactor': 20, 'currentState': array([26.63003862, 21.52327218, 14.38062552,  0.52038184,  0.80477396,
        0.28555492]), 'targetState': array([25., 25., 15.])}
episode index:2252
target thresh 28.147912166360356
model initialize at round 2252
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.8559506 ,  0.97809942,  0.15187879,
       -0.14231781]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.49631611342293325
{'scaleFactor': 20, 'currentState': array([27.3076853 , 20.75938722, 14.06788656,  0.68999713,  0.70313244,
        0.17178105]), 'targetState': array([25., 25., 15.])}
episode index:2253
target thresh 28.155097015895258
model initialize at round 2253
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08760121, 14.88086549,  0.98902777,  0.08751519,
       -0.11901752]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.4965094360646742
{'scaleFactor': 20, 'currentState': array([29.01350289, 20.9165265 , 14.45671036,  0.53192323,  0.76862007,
        0.35536019]), 'targetState': array([25., 25., 15.])}
episode index:2254
target thresh 28.162281146981126
model initialize at round 2254
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.8509778 ,  0.97740446,  0.15177088,
       -0.14712623]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.49671097957413546
{'scaleFactor': 20, 'currentState': array([24.96079654, 20.09649565, 12.02382211,  0.55992859,  0.79521802,
       -0.23261184]), 'targetState': array([25., 25., 15.])}
episode index:2255
target thresh 28.169464559689807
model initialize at round 2255
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.496908129028846
{'scaleFactor': 20, 'currentState': array([ 2.63939167e+01,  2.15170256e+01,  1.20747921e+01,  5.17517986e-01,
        8.55413341e-01, -2.10511156e-02]), 'targetState': array([25., 25., 15.])}
episode index:2256
target thresh 28.176647254093133
model initialize at round 2256
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14109208, 14.84627329,  0.97850221,  0.13945344,
       -0.15194134]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4971093172968438
{'scaleFactor': 20, 'currentState': array([25.30981801, 20.07372821, 13.54762467,  0.6058338 ,  0.7942595 ,
        0.04601366]), 'targetState': array([25., 25., 15.])}
episode index:2257
target thresh 28.183829230262923
model initialize at round 2257
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4973103273644271
{'scaleFactor': 20, 'currentState': array([25.12732495, 20.16947094, 12.7501795 ,  0.58899183,  0.807205  ,
       -0.03884218]), 'targetState': array([25., 25., 15.])}
episode index:2258
target thresh 28.19101048827102
model initialize at round 2258
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4975111594682498
{'scaleFactor': 20, 'currentState': array([25.26823239, 20.18360966, 13.93158823,  0.58632305,  0.78797289,
        0.18794683]), 'targetState': array([25., 25., 15.])}
episode index:2259
target thresh 28.198191028189214
model initialize at round 2259
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4977076059239723
{'scaleFactor': 20, 'currentState': array([26.58641225, 21.53558162, 13.92862695,  0.52734854,  0.79470405,
        0.3005811 ]), 'targetState': array([25., 25., 15.])}
episode index:2260
target thresh 28.205370850089317
model initialize at round 2260
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14987719, 14.89332418,  0.98316961,  0.14884313,
       -0.10593982]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4979080846696494
{'scaleFactor': 20, 'currentState': array([25.34289053, 20.13859788, 14.38171668,  0.59341433,  0.78719484,
        0.16788006]), 'targetState': array([25., 25., 15.])}
episode index:2261
target thresh 28.21254995404312
model initialize at round 2261
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4981083861573728
{'scaleFactor': 20, 'currentState': array([25.22063317, 20.18623487, 13.65637433,  0.58368281,  0.78850348,
        0.19384695]), 'targetState': array([25., 25., 15.])}
episode index:2262
target thresh 28.21972834012243
model initialize at round 2262
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.93070749,  0.98580283,  0.15307497,
       -0.06899874]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.49830430827988437
{'scaleFactor': 20, 'currentState': array([26.931288  , 21.35542071, 15.19105859,  0.55542329,  0.79335598,
        0.24918119]), 'targetState': array([25., 25., 15.])}
episode index:2263
target thresh 28.226906008399034
model initialize at round 2263
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.49850425781240204
{'scaleFactor': 20, 'currentState': array([25.25908683, 20.17128987, 14.145161  ,  0.57545856,  0.77622962,
        0.25751703]), 'targetState': array([25., 25., 15.])}
episode index:2264
target thresh 28.234082958944683
model initialize at round 2264
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89818432,  0.98309426,  0.15265439,
       -0.10110547]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.49870403078904113
{'scaleFactor': 20, 'currentState': array([25.33676185, 20.16824664, 14.45166972,  0.58563809,  0.77642233,
        0.23280117]), 'targetState': array([25., 25., 15.])}
episode index:2265
target thresh 28.24125919183116
model initialize at round 2265
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.49890362744354727
{'scaleFactor': 20, 'currentState': array([25.25535684, 20.16981259, 14.10068213,  0.5781396 ,  0.77469743,
        0.25612203]), 'targetState': array([25., 25., 15.])}
episode index:2266
target thresh 28.248434707130233
model initialize at round 2266
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12270003, 14.93391317,  0.99023632,  0.12272932,
       -0.0661026 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.499098853081817
{'scaleFactor': 20, 'currentState': array([26.75817919, 21.281466  , 14.2182557 ,  0.51732726,  0.82255234,
        0.23617823]), 'targetState': array([25., 25., 15.])}
episode index:2267
target thresh 28.255609504913657
model initialize at round 2267
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13926142, 14.94913766,  0.98897165,  0.13911676,
       -0.05080951]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4992980996412606
{'scaleFactor': 20, 'currentState': array([25.41497821, 20.02397648, 14.10772298,  0.62188982,  0.76980617,
        0.14370631]), 'targetState': array([25., 25., 15.])}
episode index:2268
target thresh 28.26278358525317
model initialize at round 2268
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.4994971705757069
{'scaleFactor': 20, 'currentState': array([25.2648269 , 20.15610368, 14.20765123,  0.58358677,  0.7643419 ,
        0.27424067]), 'targetState': array([25., 25., 15.])}
episode index:2269
target thresh 28.26995694822051
model initialize at round 2269
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.50721948e+01, 1.50058597e+01, 9.97334225e-01,
       7.27296163e-02, 5.90307396e-03]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.611117239532865
running average episode reward sum: 0.49954634241225193
{'scaleFactor': 20, 'currentState': array([22.45945931, 21.15752044, 14.2889553 ,  0.06433296,  0.96266028,
        0.26295712]), 'targetState': array([25., 25., 15.])}
episode index:2270
target thresh 28.27712959388743
model initialize at round 2270
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.88213204,  0.9813894 ,  0.15238966,
       -0.1168428 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4997409411823923
{'scaleFactor': 20, 'currentState': array([27.06457124, 20.85243661, 13.40416456,  0.58784868,  0.79622697,
        0.14302637]), 'targetState': array([25., 25., 15.])}
episode index:2271
target thresh 28.284301522325638
model initialize at round 2271
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.1492237 , 14.84629419,  0.97737889,  0.14732131,
       -0.15174627]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.4999353686507984
{'scaleFactor': 20, 'currentState': array([26.67863897, 21.31938519, 14.41045837,  0.48655735,  0.80305241,
        0.34404762]), 'targetState': array([25., 25., 15.])}
episode index:2272
target thresh 28.29147273360687
model initialize at round 2272
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5001338088977184
{'scaleFactor': 20, 'currentState': array([25.05748472, 20.1538304 , 12.46337593,  0.58251791,  0.80770892,
       -0.09099002]), 'targetState': array([25., 25., 15.])}
episode index:2273
target thresh 28.298643227802835
model initialize at round 2273
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5003320746149578
{'scaleFactor': 20, 'currentState': array([25.18468331, 20.18988439, 13.22154102,  0.59046123,  0.80047574,
        0.10292778]), 'targetState': array([25., 25., 15.])}
episode index:2274
target thresh 28.305813004985204
model initialize at round 2274
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89216116,  0.98248274,  0.15255943,
       -0.10702   ]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5005301660326655
{'scaleFactor': 20, 'currentState': array([25.35455864, 20.15981967, 14.05272136,  0.60281268,  0.79702421,
        0.03700385]), 'targetState': array([25., 25., 15.])}
episode index:2275
target thresh 28.312982065225732
model initialize at round 2275
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5007239050411754
{'scaleFactor': 20, 'currentState': array([26.75109429, 21.37189559, 13.79736687,  0.59425671,  0.75020726,
        0.28991038]), 'targetState': array([25., 25., 15.])}
episode index:2276
target thresh 28.320150408596056
model initialize at round 2276
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12985169, 14.90774059,  0.98730181,  0.12949779,
       -0.09200796]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.5009133391399306
{'scaleFactor': 20, 'currentState': array([29.07095768, 21.29129069, 13.80311675,  0.63128562,  0.74316602,
        0.22177179]), 'targetState': array([25., 25., 15.])}
episode index:2277
target thresh 28.327318035167902
model initialize at round 2277
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08170244, 14.84627329,  0.98488831,  0.08128059,
       -0.15293297]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5011067398468055
{'scaleFactor': 20, 'currentState': array([27.34081882, 20.1893738 , 13.19340959,  0.61956464,  0.78332615,
       -0.05039639]), 'targetState': array([25., 25., 15.])}
episode index:2278
target thresh 28.334484945012917
model initialize at round 2278
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5013041436686806
{'scaleFactor': 20, 'currentState': array([25.2135166 , 20.18905129, 13.28498306,  0.59457212,  0.80359072,
        0.02694343]), 'targetState': array([25., 25., 15.])}
episode index:2279
target thresh 28.341651138202785
model initialize at round 2279
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5015013743293083
{'scaleFactor': 20, 'currentState': array([25.25979497, 20.17707677, 14.01793808,  0.58187305,  0.78327647,
        0.21886462]), 'targetState': array([25., 25., 15.])}
episode index:2280
target thresh 28.34881661480916
model initialize at round 2280
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5016984320564326
{'scaleFactor': 20, 'currentState': array([25.24447711, 20.1825654 , 13.86266629,  0.5821186 ,  0.78462015,
        0.21332873]), 'targetState': array([25., 25., 15.])}
episode index:2281
target thresh 28.355981374903706
model initialize at round 2281
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5018953170773982
{'scaleFactor': 20, 'currentState': array([25.24302476, 20.17089741, 13.32201399,  0.61355453,  0.78620422,
        0.07371405]), 'targetState': array([25., 25., 15.])}
episode index:2282
target thresh 28.363145418558055
model initialize at round 2282
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10178225, 14.85979776,  0.98503011,  0.1012713 ,
       -0.13949841]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5020878640911186
{'scaleFactor': 20, 'currentState': array([27.37538102, 20.20857531, 13.30687273,  0.64625822,  0.7503968 ,
        0.13876225]), 'targetState': array([25., 25., 15.])}
episode index:2283
target thresh 28.370308745843875
model initialize at round 2283
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5022802424997482
{'scaleFactor': 20, 'currentState': array([26.8959913 , 20.92062268, 11.79547418,  0.68845279,  0.66485841,
       -0.28982071]), 'targetState': array([25., 25., 15.])}
episode index:2284
target thresh 28.37747135683277
model initialize at round 2284
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.06498387, 14.84627329,  0.98608571,  0.06472693,
       -0.1531189 ]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.5024683322614144
{'scaleFactor': 20, 'currentState': array([29.02105016, 20.80148723, 14.93411176,  0.53855634,  0.71981259,
        0.43798049]), 'targetState': array([25., 25., 15.])}
episode index:2285
target thresh 28.38463325159638
model initialize at round 2285
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14737738, 14.92170276,  0.98608779,  0.14679499,
       -0.07798784]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.5022485298413526
{'scaleFactor': 20, 'currentState': array([30.2151609 ,  7.39621486, 27.15313405,  0.82463493,  0.15391224,
       -0.54432367]), 'targetState': array([25., 25., 15.])}
episode index:2286
target thresh 28.39179443020633
model initialize at round 2286
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08504695, 14.84981731,  0.98514153,  0.08462958,
       -0.14944566]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5024405856435212
{'scaleFactor': 20, 'currentState': array([26.88911396, 20.71462463, 12.85688156,  0.5583456 ,  0.82116002,
        0.11809496]), 'targetState': array([25., 25., 15.])}
episode index:2287
target thresh 28.398954892734206
model initialize at round 2287
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5026366299897872
{'scaleFactor': 20, 'currentState': array([25.08198724, 20.1475277 , 12.49169584,  0.58089366,  0.80425169,
       -0.1254662 ]), 'targetState': array([25., 25., 15.])}
episode index:2288
target thresh 28.406114639251644
model initialize at round 2288
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5028325030434831
{'scaleFactor': 20, 'currentState': array([25.14919224, 20.17058231, 12.81963385,  0.5877965 ,  0.80404867,
       -0.08944836]), 'targetState': array([25., 25., 15.])}
episode index:2289
target thresh 28.413273669830218
model initialize at round 2289
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.50302820502901
{'scaleFactor': 20, 'currentState': array([2.51729333e+01, 2.01807300e+01, 1.30156275e+01, 5.92336709e-01,
       8.05682675e-01, 3.55674558e-03]), 'targetState': array([25., 25., 15.])}
episode index:2290
target thresh 28.42043198454155
model initialize at round 2290
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84903091,  0.97712637,  0.1517277 ,
       -0.14900594]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5032237361703766
{'scaleFactor': 20, 'currentState': array([25.06577624, 20.15023252, 12.46663105,  0.58089477,  0.80553617,
       -0.1169305 ]), 'targetState': array([25., 25., 15.])}
episode index:2291
target thresh 28.42758958345718
model initialize at round 2291
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.503419096691201
{'scaleFactor': 20, 'currentState': array([25.24768395, 20.17954441, 13.92687477,  0.58014145,  0.78206305,
        0.2276253 ]), 'targetState': array([25., 25., 15.])}
episode index:2292
target thresh 28.434746466648708
model initialize at round 2292
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.92068511,  0.98507572,  0.15296207,
       -0.07892037]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5036101394529585
{'scaleFactor': 20, 'currentState': array([26.94845751, 21.30452357, 14.63286839,  0.61114534,  0.74182797,
        0.27603013]), 'targetState': array([25., 25., 15.])}
episode index:2293
target thresh 28.4419026341877
model initialize at round 2293
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13330986, 14.92179061,  0.98803171,  0.13304482,
       -0.0780539 ]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.5037969115577772
{'scaleFactor': 20, 'currentState': array([29.57328343, 20.68594611, 15.15161716,  0.83494458,  0.44901093,
        0.31820864]), 'targetState': array([25., 25., 15.])}
episode index:2294
target thresh 28.44905808614572
model initialize at round 2294
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.49857224e+01,  1.49620251e+01,  9.99161375e-01,
       -1.44096936e-02, -3.83263359e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.5035773922063358
{'scaleFactor': 20, 'currentState': array([38.61300571, 41.40376209, 56.52727664, -0.56217488,  0.82343785,
        0.07687337]), 'targetState': array([25., 25., 15.])}
episode index:2295
target thresh 28.456212822594317
model initialize at round 2295
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.04770099, 14.89967745,  0.99376355,  0.04788233,
       -0.10070394]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.5033580640738418
{'scaleFactor': 20, 'currentState': array([ 4.01107300e+01,  6.55312091e+00,  2.64599683e+01,  8.59535593e-01,
        5.09668294e-01, -3.79050778e-02]), 'targetState': array([25., 25., 15.])}
episode index:2296
target thresh 28.463366843605055
model initialize at round 2296
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.90019958,  0.98329126,  0.15268498,
       -0.09912412]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5035529408634918
{'scaleFactor': 20, 'currentState': array([25.32243812, 20.13185856, 15.17873122,  0.55984387,  0.75673184,
        0.3375378 ]), 'targetState': array([25., 25., 15.])}
episode index:2297
target thresh 28.470520149249445
model initialize at round 2297
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.97620347,  0.98787924,  0.1533974 ,
       -0.02374555]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5037476480475808
{'scaleFactor': 20, 'currentState': array([25.39956723, 20.1784173 , 14.76046953,  0.6010472 ,  0.79668516,
        0.06352177]), 'targetState': array([25., 25., 15.])}
episode index:2298
target thresh 28.477672739599036
model initialize at round 2298
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5039421858474296
{'scaleFactor': 20, 'currentState': array([25.1561768 , 20.16584179, 12.81105738,  0.5855031 ,  0.80121496,
       -0.12345325]), 'targetState': array([25., 25., 15.])}
episode index:2299
target thresh 28.48482461472537
model initialize at round 2299
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5041365544839741
{'scaleFactor': 20, 'currentState': array([24.91838347, 20.06675104, 11.84898664,  0.54004024,  0.77770754,
       -0.32175692]), 'targetState': array([25., 25., 15.])}
episode index:2300
target thresh 28.49197577469993
model initialize at round 2300
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5043307541777663
{'scaleFactor': 20, 'currentState': array([25.26351657, 20.17036913, 13.69627758,  0.60216704,  0.78634319,
        0.1380552 ]), 'targetState': array([25., 25., 15.])}
episode index:2301
target thresh 28.499126219594263
model initialize at round 2301
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5045247851489748
{'scaleFactor': 20, 'currentState': array([25.03348366, 20.13935   , 12.3307715 ,  0.57597441,  0.80374584,
       -0.14915128]), 'targetState': array([25., 25., 15.])}
episode index:2302
target thresh 28.506275949479853
model initialize at round 2302
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14984729, 14.84627329,  0.97728702,  0.14792304,
       -0.15175264]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5047145182641516
{'scaleFactor': 20, 'currentState': array([26.774203  , 21.36144452, 14.26926534,  0.66528219,  0.70966362,
        0.23189902]), 'targetState': array([25., 25., 15.])}
episode index:2303
target thresh 28.51342496442819
model initialize at round 2303
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.01986719, 14.84627329,  0.98796363,  0.01982632,
       -0.1534105 ]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.504900000395073
{'scaleFactor': 20, 'currentState': array([28.84921545, 20.77034248, 15.03554295,  0.55972464,  0.7195694 ,
        0.41100877]), 'targetState': array([25., 25., 15.])}
episode index:2304
target thresh 28.520573264510794
model initialize at round 2304
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5050894060996309
{'scaleFactor': 20, 'currentState': array([26.49352031, 21.58125499, 14.47606376,  0.4596973 ,  0.81663055,
        0.34898845]), 'targetState': array([25., 25., 15.])}
episode index:2305
target thresh 28.52772084979912
model initialize at round 2305
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12473837, 14.8765585 ,  0.98464945,  0.12406421,
       -0.12277435]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.5052745647907876
{'scaleFactor': 20, 'currentState': array([29.21615841, 20.7717412 , 12.49696371,  0.73318188,  0.67620789,
        0.07202237]), 'targetState': array([25., 25., 15.])}
episode index:2306
target thresh 28.534867720364655
model initialize at round 2306
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.04193277, 14.84627329,  0.98729346,  0.04181814,
       -0.15330644]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.5054595629629229
{'scaleFactor': 20, 'currentState': array([29.42445938, 20.1562638 , 12.97566747,  0.66680209,  0.73275893,
        0.13579148]), 'targetState': array([25., 25., 15.])}
episode index:2307
target thresh 28.542013876278872
model initialize at round 2307
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5056484800281041
{'scaleFactor': 20, 'currentState': array([26.59187875, 21.39331518, 12.28453438,  0.58184144,  0.81211607,
       -0.04390941]), 'targetState': array([25., 25., 15.])}
episode index:2308
target thresh 28.549159317613228
model initialize at round 2308
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12217299, 14.85521269,  0.98217882,  0.1212078 ,
       -0.14364346]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5058372334578888
{'scaleFactor': 20, 'currentState': array([26.5957975 , 21.37693991, 14.76316595,  0.47053944,  0.81870329,
        0.32911633]), 'targetState': array([25., 25., 15.])}
episode index:2309
target thresh 28.556304044439162
model initialize at round 2309
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.8629453 ,  0.97903938,  0.15202475,
       -0.13553732]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5060299403048334
{'scaleFactor': 20, 'currentState': array([25.2388542 , 20.18570652, 13.60124542,  0.58812041,  0.79289701,
        0.15946382]), 'targetState': array([25., 25., 15.])}
episode index:2310
target thresh 28.563448056828157
model initialize at round 2310
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.97994929,  0.98796003,  0.15340994,
       -0.02000939]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5062224803782195
{'scaleFactor': 20, 'currentState': array([25.36359412, 20.14421129, 15.29317644,  0.56965287,  0.76391733,
        0.30319288]), 'targetState': array([25., 25., 15.])}
episode index:2311
target thresh 28.570591354851615
model initialize at round 2311
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.03120052,  0.98767903,  0.15336631,
        0.03112737]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5064148538944486
{'scaleFactor': 20, 'currentState': array([25.37826787, 20.15221051, 15.73614843,  0.58343447,  0.77318295,
        0.24858065]), 'targetState': array([25., 25., 15.])}
episode index:2312
target thresh 28.577733938580984
model initialize at round 2312
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09747169, 14.92880426,  0.99264916,  0.09773251,
       -0.07138626]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.5065988791836888
{'scaleFactor': 20, 'currentState': array([29.1846603 , 21.00051337, 14.43215517,  0.57975463,  0.75007762,
        0.31822655]), 'targetState': array([25., 25., 15.])}
episode index:2313
target thresh 28.584875808087705
model initialize at round 2313
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.9163102 ,  0.98472815,  0.1529081 ,
       -0.08324414]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5067868140454941
{'scaleFactor': 20, 'currentState': array([27.48301841, 20.41322203, 15.00176214,  0.69149957,  0.66040664,
        0.29273095]), 'targetState': array([25., 25., 15.])}
episode index:2314
target thresh 28.59201696344318
model initialize at round 2314
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12033524, 14.88534289,  0.98619725,  0.11987301,
       -0.11421669]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5069745865445677
{'scaleFactor': 20, 'currentState': array([27.23529695, 20.59070797, 14.96717651,  0.6438538 ,  0.67880955,
        0.35308622]), 'targetState': array([25., 25., 15.])}
episode index:2315
target thresh 28.599157404718824
model initialize at round 2315
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.07517455, 14.97951421,  0.99691724,  0.07569981,
       -0.02062892]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.5067556856004639
{'scaleFactor': 20, 'currentState': array([19.92946205, 24.65030689, 22.40295772,  0.6199399 , -0.51046486,
       -0.5959028 ]), 'targetState': array([25., 25., 15.])}
episode index:2316
target thresh 28.606297131986036
model initialize at round 2316
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.9382631 ,  0.98628704,  0.15315016,
       -0.06150536]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5069474138543696
{'scaleFactor': 20, 'currentState': array([25.39657807, 20.1137486 , 14.21488657,  0.60529962,  0.79072725,
        0.09144827]), 'targetState': array([25., 25., 15.])}
episode index:2317
target thresh 28.613436145316218
model initialize at round 2317
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.507130812445419
{'scaleFactor': 20, 'currentState': array([29.11610493, 21.08231936, 12.73217204,  0.65732566,  0.73325781,
        0.17394242]), 'targetState': array([25., 25., 15.])}
episode index:2318
target thresh 28.620574444780765
model initialize at round 2318
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5073181127200872
{'scaleFactor': 20, 'currentState': array([26.81282725, 21.30010986, 13.757517  ,  0.6360543 ,  0.7170147 ,
        0.28517513]), 'targetState': array([25., 25., 15.])}
episode index:2319
target thresh 28.627712030451058
model initialize at round 2319
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.06498041, 14.93925616,  0.99598782,  0.06537343,
       -0.06111123]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.5070994411197769
{'scaleFactor': 20, 'currentState': array([12.29461957, 19.89264457, 27.59468556,  0.88537824, -0.24039398,
       -0.39788957]), 'targetState': array([25., 25., 15.])}
episode index:2320
target thresh 28.634848902398467
model initialize at round 2320
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.95679128,  0.98724013,  0.15329816,
       -0.04308826]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5072906908435081
{'scaleFactor': 20, 'currentState': array([25.35534671, 20.17165565, 14.44929801,  0.588633  ,  0.78426408,
        0.19606388]), 'targetState': array([25., 25., 15.])}
episode index:2321
target thresh 28.641985060694363
model initialize at round 2321
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.90197741,  0.98346188,  0.15271147,
       -0.09737523]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5074817758387951
{'scaleFactor': 20, 'currentState': array([25.31970618, 20.14224823, 14.94662821,  0.56475658,  0.76156801,
        0.31790593]), 'targetState': array([25., 25., 15.])}
episode index:2322
target thresh 28.64912050541011
model initialize at round 2322
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.03326409,  0.98761365,  0.15335616,
        0.03318391]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5076686025170397
{'scaleFactor': 20, 'currentState': array([27.26910614, 20.76954769, 15.94217911,  0.58348084,  0.76153579,
        0.28215837]), 'targetState': array([25., 25., 15.])}
episode index:2323
target thresh 28.656255236617067
model initialize at round 2323
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.93144041,  0.98585222,  0.15308264,
       -0.06827235]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5078593604548121
{'scaleFactor': 20, 'currentState': array([25.3444237 , 20.1432253 , 14.70262961,  0.58846346,  0.7589598 ,
        0.27873066]), 'targetState': array([25., 25., 15.])}
episode index:2324
target thresh 28.663389254386573
model initialize at round 2324
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.94216067,  0.98651523,  0.15318559,
       -0.05763574]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5080499542997347
{'scaleFactor': 20, 'currentState': array([25.41717037, 20.05601669, 14.82671403,  0.61734378,  0.73240753,
        0.28716872]), 'targetState': array([25., 25., 15.])}
episode index:2325
target thresh 28.67052255878997
model initialize at round 2325
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12689803, 14.95275828,  0.99077564,  0.12699745,
       -0.04727874]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.5082322481061006
{'scaleFactor': 20, 'currentState': array([29.52976442, 20.80060624, 14.94738577,  0.68651986,  0.66682772,
        0.28988147]), 'targetState': array([25., 25., 15.])}
episode index:2326
target thresh 28.677655149898595
model initialize at round 2326
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.51537267e+01, 1.50154841e+01, 9.88039867e-01,
       1.53422340e-01, 1.54534004e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5084184311320116
{'scaleFactor': 20, 'currentState': array([26.86939433, 21.28834514, 16.19422   ,  0.52743102,  0.75444651,
        0.39067505]), 'targetState': array([25., 25., 15.])}
episode index:2327
target thresh 28.684787027783763
model initialize at round 2327
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.95385459,  0.98711135,  0.15327816,
       -0.04601077]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5086085392156747
{'scaleFactor': 20, 'currentState': array([25.36783504, 20.14961412, 14.92787374,  0.57812216,  0.77117987,
        0.26656403]), 'targetState': array([25., 25., 15.])}
episode index:2328
target thresh 28.69191819251681
model initialize at round 2328
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.88722776,  0.98195661,  0.15247773,
       -0.11185601]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5087984840463678
{'scaleFactor': 20, 'currentState': array([25.31337429, 20.17926694, 14.14158922,  0.59165292,  0.79176101,
        0.15185958]), 'targetState': array([25., 25., 15.])}
episode index:2329
target thresh 28.699048644169032
model initialize at round 2329
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86777646,  0.97966278,  0.15212155,
       -0.13084291]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5089882658342878
{'scaleFactor': 20, 'currentState': array([25.21079115, 20.16922782, 13.08287053,  0.59530728,  0.79932243,
       -0.08181011]), 'targetState': array([25., 25., 15.])}
episode index:2330
target thresh 28.706178382811732
model initialize at round 2330
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09657492, 14.84627329,  0.98359861,  0.09595046,
       -0.1527327 ]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.5091697660839972
{'scaleFactor': 20, 'currentState': array([28.93095484, 20.50833446, 10.70672371,  0.70883984,  0.69109404,
       -0.14119175]), 'targetState': array([25., 25., 15.])}
episode index:2331
target thresh 28.71330740851623
model initialize at round 2331
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11309731, 14.84627329,  0.98192114,  0.11217438,
       -0.15247223]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.5089514257040298
{'scaleFactor': 20, 'currentState': array([11.413872  , 31.57651154,  9.27070126,  0.10816126,  0.50187438,
       -0.85815107]), 'targetState': array([25., 25., 15.])}
episode index:2332
target thresh 28.720435721353788
model initialize at round 2332
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5091368216421769
{'scaleFactor': 20, 'currentState': array([26.46659775, 21.51503361, 12.2163902 ,  0.57697845,  0.81485625,
       -0.05572398]), 'targetState': array([25., 25., 15.])}
episode index:2333
target thresh 28.72756332139572
model initialize at round 2333
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.07594178, 14.84627329,  0.9853312 ,  0.07558364,
       -0.15300174]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.5093180249524873
{'scaleFactor': 20, 'currentState': array([28.86110125, 20.87660586, 14.33323682,  0.50912161,  0.75639063,
        0.41069259]), 'targetState': array([25., 25., 15.])}
episode index:2334
target thresh 28.734690208713275
model initialize at round 2334
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.51299899e+01,  1.49858743e+01,  9.91390450e-01,
        1.30172492e-01, -1.41455817e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5095031050914375
{'scaleFactor': 20, 'currentState': array([27.10981791, 21.07135147, 15.07951682,  0.63451328,  0.74492612,
        0.20610186]), 'targetState': array([25., 25., 15.])}
episode index:2335
target thresh 28.741816383377728
model initialize at round 2335
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10096835, 14.84627329,  0.98317756,  0.10027254,
       -0.15266732]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5096880267713646
{'scaleFactor': 20, 'currentState': array([2.75315899e+01, 2.00491068e+01, 1.30343839e+01, 7.41044259e-01,
       6.71408455e-01, 8.00572458e-03]), 'targetState': array([25., 25., 15.])}
episode index:2336
target thresh 28.74894184546035
model initialize at round 2336
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.07856215, 14.84627329,  0.98513368,  0.07817598,
       -0.15297107]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.509872790195682
{'scaleFactor': 20, 'currentState': array([ 2.66457311e+01,  2.09338061e+01,  1.20644081e+01,  5.91092297e-01,
        8.06236080e-01, -2.43573427e-02]), 'targetState': array([25., 25., 15.])}
episode index:2337
target thresh 28.756066595032394
model initialize at round 2337
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11329721, 14.84627329,  0.98189928,  0.11237016,
       -0.15246883]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.5100533687062513
{'scaleFactor': 20, 'currentState': array([29.32514755, 20.77760604, 12.89236812,  0.67274226,  0.72415361,
        0.15172149]), 'targetState': array([25., 25., 15.])}
episode index:2338
target thresh 28.76319063216509
model initialize at round 2338
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87074234,  0.98003498,  0.15217934,
       -0.12795659]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5102378179498146
{'scaleFactor': 20, 'currentState': array([27.09076034, 20.95658149, 15.30608437,  0.58958733,  0.73693716,
        0.33062123]), 'targetState': array([25., 25., 15.])}
episode index:2339
target thresh 28.770313956929705
model initialize at round 2339
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.98042754,  0.98796935,  0.15341139,
       -0.01953232]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.510426173604494
{'scaleFactor': 20, 'currentState': array([25.39380854, 20.1200828 , 15.18187182,  0.60918307,  0.7493228 ,
        0.2596369 ]), 'targetState': array([25., 25., 15.])}
episode index:2340
target thresh 28.77743656939745
model initialize at round 2340
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.06513543, 14.88681526,  0.99141208,  0.06522834,
       -0.11334618]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.5106062843154306
{'scaleFactor': 20, 'currentState': array([28.95662599, 21.06159694, 14.36902769,  0.62455102,  0.69250216,
        0.36107726]), 'targetState': array([25., 25., 15.])}
episode index:2341
target thresh 28.784558469639563
model initialize at round 2341
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13817007, 14.93369085,  0.98822877,  0.13792287,
       -0.06619052]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5107902612006081
{'scaleFactor': 20, 'currentState': array([26.52783047, 21.55124782, 15.54235615,  0.48637331,  0.78623492,
        0.38115044]), 'targetState': array([25., 25., 15.])}
episode index:2342
target thresh 28.791679657727254
model initialize at round 2342
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.88372805,  0.98156964,  0.15241765,
       -0.11528184]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5109781398983031
{'scaleFactor': 20, 'currentState': array([2.53167727e+01, 2.01363303e+01, 1.35050845e+01, 6.18069927e-01,
       7.85924458e-01, 1.76723696e-02]), 'targetState': array([25., 25., 15.])}
episode index:2343
target thresh 28.79880013373176
model initialize at round 2343
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10772951, 14.84627329,  0.98249415,  0.10691274,
       -0.1525612 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5111618011651557
{'scaleFactor': 20, 'currentState': array([27.12971826, 20.50241022, 12.75286064,  0.66883519,  0.73877739,
        0.08287011]), 'targetState': array([25., 25., 15.])}
episode index:2344
target thresh 28.80591989772424
model initialize at round 2344
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13205242, 14.84627329,  0.97968447,  0.13067647,
       -0.15212492]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5113453057912691
{'scaleFactor': 20, 'currentState': array([26.41484453, 21.25786286, 11.49080327,  0.55986081,  0.80197125,
       -0.20832185]), 'targetState': array([25., 25., 15.])}
episode index:2345
target thresh 28.813038949775937
model initialize at round 2345
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.0859238 , 14.84627329,  0.98454362,  0.08545023,
       -0.15287944]), 'targetState': array([25., 25., 15.])}
done in step count: 46
reward sum = 0.6298236312032323
running average episode reward sum: 0.5113958080612657
{'scaleFactor': 20, 'currentState': array([24.03392394, 20.86498793, 13.64369868,  0.84538259,  0.5281699 ,
       -0.07977991]), 'targetState': array([25., 25., 15.])}
episode index:2346
target thresh 28.820157289958015
model initialize at round 2346
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5115831085477756
{'scaleFactor': 20, 'currentState': array([25.27501933, 20.15706726, 14.26213609,  0.57832498,  0.77298363,
        0.26083814]), 'targetState': array([25., 25., 15.])}
episode index:2347
target thresh 28.827274918341683
model initialize at round 2347
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.90915485,  0.98412035,  0.15281372,
       -0.09030562]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.511770249493837
{'scaleFactor': 20, 'currentState': array([25.31492494, 20.16483097, 14.4668991 ,  0.58038543,  0.77853915,
        0.2388086 ]), 'targetState': array([25., 25., 15.])}
episode index:2348
target thresh 28.834391834998087
model initialize at round 2348
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84877998,  0.97709028,  0.15172209,
       -0.14924809]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5119572311032052
{'scaleFactor': 20, 'currentState': array([25.29291635, 20.18328455, 14.0302763 ,  0.58660577,  0.78662848,
        0.19263773]), 'targetState': array([25., 25., 15.])}
episode index:2349
target thresh 28.8415080399984
model initialize at round 2349
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.88617949,  0.98184189,  0.15245992,
       -0.11288257]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5121440535792889
{'scaleFactor': 20, 'currentState': array([25.31922633, 20.16778323, 14.48668951,  0.58545491,  0.78442165,
        0.20475648]), 'targetState': array([25., 25., 15.])}
episode index:2350
target thresh 28.848623533413797
model initialize at round 2350
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14701888, 14.84627329,  0.97768708,  0.14519036,
       -0.15181476]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5123266720802765
{'scaleFactor': 20, 'currentState': array([27.51121221, 20.1414085 , 12.46760127,  0.73248538,  0.67648613,
       -0.07636549]), 'targetState': array([25., 25., 15.])}
episode index:2351
target thresh 28.85573831531544
model initialize at round 2351
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5125131786184651
{'scaleFactor': 20, 'currentState': array([25.24060937, 20.18684648, 13.69671803,  0.58603807,  0.78957811,
        0.18200491]), 'targetState': array([25., 25., 15.])}
episode index:2352
target thresh 28.862852385774453
model initialize at round 2352
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.88366901,  0.98156302,  0.15241662,
       -0.11533959]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5126954850233877
{'scaleFactor': 20, 'currentState': array([27.48447229, 20.56760376, 14.96831398,  0.76360125,  0.60577143,
        0.22350415]), 'targetState': array([25., 25., 15.])}
episode index:2353
target thresh 28.869965744861993
model initialize at round 2353
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.50041581e+01,  1.49571398e+01,  9.99055374e-01,
        4.19615150e-03, -4.32521975e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.5124776874511602
{'scaleFactor': 20, 'currentState': array([41.95609913,  7.83374416, 23.01168498,  0.95809817,  0.19056816,
       -0.21384965]), 'targetState': array([25., 25., 15.])}
episode index:2354
target thresh 28.877078392649192
model initialize at round 2354
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09255631, 14.84627329,  0.98396779,  0.09199235,
       -0.15279003]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.5126558563091033
{'scaleFactor': 20, 'currentState': array([2.83753229e+01, 2.16406178e+01, 1.18569705e+01, 5.01889819e-01,
       8.64908402e-01, 6.32974787e-03]), 'targetState': array([25., 25., 15.])}
episode index:2355
target thresh 28.88419032920716
model initialize at round 2355
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87396268,  0.98043001,  0.15224068,
       -0.12481896]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5128419064761622
{'scaleFactor': 20, 'currentState': array([25.3218096 , 20.12754772, 14.2859492 ,  0.59326172,  0.76763129,
        0.24245149]), 'targetState': array([25., 25., 15.])}
episode index:2356
target thresh 28.89130155460705
model initialize at round 2356
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11150684, 14.88706678,  0.98739293,  0.1112132 ,
       -0.11263582]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.5126243239956887
{'scaleFactor': 20, 'currentState': array([24.48030397, 34.32043844, 17.51496037,  0.80806771,  0.06235108,
       -0.58578061]), 'targetState': array([25., 25., 15.])}
episode index:2357
target thresh 28.898412068919942
model initialize at round 2357
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5128102297318652
{'scaleFactor': 20, 'currentState': array([25.24076825, 20.1827836 , 13.82173435,  0.5819529 ,  0.78503883,
        0.21223775]), 'targetState': array([25., 25., 15.])}
episode index:2358
target thresh 28.905521872216966
model initialize at round 2358
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5129959778540221
{'scaleFactor': 20, 'currentState': array([2.51741208e+01, 2.01823646e+01, 1.30381176e+01, 5.92398615e-01,
       8.05319493e-01, 2.28996710e-02]), 'targetState': array([25., 25., 15.])}
episode index:2359
target thresh 28.912630964569207
model initialize at round 2359
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5131775389436607
{'scaleFactor': 20, 'currentState': array([26.76986755, 21.36864274, 14.33746799,  0.63087897,  0.71327927,
        0.30532671]), 'targetState': array([25., 25., 15.])}
episode index:2360
target thresh 28.919739346047756
model initialize at round 2360
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.50153361e+01,  1.48462733e+01,  9.88042111e-01,
        1.53057485e-02, -1.53422688e-01]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.5129601829339429
{'scaleFactor': 20, 'currentState': array([ 1.02413796,  9.69713983, 25.40078434, -0.78064826, -0.62443251,
       -0.02592953]), 'targetState': array([25., 25., 15.])}
episode index:2361
target thresh 28.926847016723688
model initialize at round 2361
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.97739375, 14.96074778,  0.99895492, -0.02281073,
       -0.03960727]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.5127430109682638
{'scaleFactor': 20, 'currentState': array([24.31400424, 20.6002289 ,  7.21026204,  0.81989009, -0.55782893,
        0.12886862]), 'targetState': array([25., 25., 15.])}
episode index:2362
target thresh 28.933953976668093
model initialize at round 2362
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10677286, 14.84627329,  0.98259344,  0.10597405,
       -0.15257662]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5129244486061956
{'scaleFactor': 20, 'currentState': array([26.70695671, 21.14727639, 13.83928445,  0.50205766,  0.81648342,
        0.28511914]), 'targetState': array([25., 25., 15.])}
episode index:2363
target thresh 28.941060225952054
model initialize at round 2363
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.90858349,  0.98406972,  0.15280586,
       -0.0908689 ]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5131097555441371
{'scaleFactor': 20, 'currentState': array([25.36993604, 20.07870057, 14.30858078,  0.59197227,  0.76807175,
        0.244202  ]), 'targetState': array([25., 25., 15.])}
episode index:2364
target thresh 28.948165764646593
model initialize at round 2364
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.9616939 ,  0.98743636,  0.15332863,
       -0.03820691]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5132949057743087
{'scaleFactor': 20, 'currentState': array([25.34130729, 20.14478448, 15.00339133,  0.56889367,  0.76416912,
        0.30398283]), 'targetState': array([25., 25., 15.])}
episode index:2365
target thresh 28.955270592822792
model initialize at round 2365
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.91327816,  0.98447655,  0.15286903,
       -0.086238  ]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.51347989949541
{'scaleFactor': 20, 'currentState': array([25.32267661, 20.16811259, 14.45649845,  0.58307844,  0.7809836 ,
        0.22379487]), 'targetState': array([25., 25., 15.])}
episode index:2366
target thresh 28.962374710551707
model initialize at round 2366
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15262875, 14.86818277,  0.97987565,  0.15106788,
       -0.13046918]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5136607192038619
{'scaleFactor': 20, 'currentState': array([27.5883524 , 20.17229457, 13.10647031,  0.86851342,  0.47436654,
        0.14373873]), 'targetState': array([25., 25., 15.])}
episode index:2367
target thresh 28.96947811790437
model initialize at round 2367
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.50100917e+01,  1.48723766e+01,  9.91742254e-01,
        1.01094580e-02, -1.27847955e-01]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.5134438016704144
{'scaleFactor': 20, 'currentState': array([27.24496291, 11.04810504, 10.21726395,  0.86654163, -0.49814163,
        0.03099234]), 'targetState': array([25., 25., 15.])}
episode index:2368
target thresh 28.976580814951802
model initialize at round 2368
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.03538844, 14.84627329,  0.98754198,  0.03530057,
       -0.15334503]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.5132270672670077
{'scaleFactor': 20, 'currentState': array([2.96811130e+01, 1.15443994e+01, 1.28672203e+01, 9.47760761e-01,
       3.17607701e-01, 2.95785018e-02]), 'targetState': array([25., 25., 15.])}
episode index:2369
target thresh 28.983682801765042
model initialize at round 2369
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5134077647700178
{'scaleFactor': 20, 'currentState': array([27.52655986, 20.2670387 , 13.95572464,  0.71751794,  0.653988  ,
        0.23972423]), 'targetState': array([25., 25., 15.])}
episode index:2370
target thresh 28.99078407841512
model initialize at round 2370
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08976916, 14.93179382,  0.99357807,  0.0900936 ,
       -0.06845269]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5135883098499973
{'scaleFactor': 20, 'currentState': array([27.43038283, 20.18553254, 15.64845606,  0.59075517,  0.72922643,
        0.34530733]), 'targetState': array([25., 25., 15.])}
episode index:2371
target thresh 28.997884644973038
model initialize at round 2371
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15047231, 14.97851241,  0.988418  ,  0.15023186,
       -0.02145325]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5137727119326491
{'scaleFactor': 20, 'currentState': array([25.39651048, 20.08897834, 14.70724622,  0.58817399,  0.76867077,
        0.25138936]), 'targetState': array([25., 25., 15.])}
episode index:2372
target thresh 29.00498450150979
model initialize at round 2372
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14352768, 14.92632738,  0.98698058,  0.14308993,
       -0.07344792]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.5139489835870841
{'scaleFactor': 20, 'currentState': array([29.5094084 , 20.75572629, 14.86072006,  0.64508635,  0.71962231,
        0.25691892]), 'targetState': array([25., 25., 15.])}
episode index:2373
target thresh 29.0120836480964
model initialize at round 2373
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5141330783917651
{'scaleFactor': 20, 'currentState': array([25.22211509, 20.1143149 , 13.17431628,  0.59883109,  0.79279775,
        0.11345952]), 'targetState': array([25., 25., 15.])}
episode index:2374
target thresh 29.01918208480384
model initialize at round 2374
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11608432, 14.86058321,  0.98362095,  0.11533633,
       -0.13851846]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5143130140006111
{'scaleFactor': 20, 'currentState': array([26.8387267 , 20.94800548, 14.72530178,  0.50733895,  0.79398872,
        0.33494641]), 'targetState': array([25., 25., 15.])}
episode index:2375
target thresh 29.026279811703105
model initialize at round 2375
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84974754,  0.97722912,  0.15174365,
       -0.14831422]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5144927981485069
{'scaleFactor': 20, 'currentState': array([27.21768416, 20.82121364, 14.37582034,  0.68238052,  0.67063995,
        0.29085888]), 'targetState': array([25., 25., 15.])}
episode index:2376
target thresh 29.033376828865155
model initialize at round 2376
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14111149, 14.91230984,  0.98620939,  0.14057118,
       -0.0873544 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5146724310266105
{'scaleFactor': 20, 'currentState': array([27.27806916, 20.6045693 , 14.47357842,  0.60146759,  0.73801455,
        0.30589419]), 'targetState': array([25., 25., 15.])}
episode index:2377
target thresh 29.04047313636098
model initialize at round 2377
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.93539372,  0.98610965,  0.15312262,
       -0.0643524 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5148519128257588
{'scaleFactor': 20, 'currentState': array([26.73199735, 21.53125466, 14.73957387,  0.56997491,  0.80190241,
        0.17911206]), 'targetState': array([25., 25., 15.])}
episode index:2378
target thresh 29.047568734261542
model initialize at round 2378
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.50118486e+01,  1.48462733e+01,  9.88088766e-01,
        1.18256951e-02, -1.53429933e-01]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.515027286274721
{'scaleFactor': 20, 'currentState': array([29.07225805, 20.31663221, 13.37939208,  0.56282558,  0.77117055,
        0.29752875]), 'targetState': array([25., 25., 15.])}
episode index:2379
target thresh 29.054663622637776
model initialize at round 2379
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.90296137,  0.98355503,  0.15272594,
       -0.0964069 ]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5152104639064963
{'scaleFactor': 20, 'currentState': array([25.3395684 , 20.16103895, 14.72941891,  0.57661432,  0.77281223,
        0.26509846]), 'targetState': array([25., 25., 15.])}
episode index:2380
target thresh 29.06175780156066
model initialize at round 2380
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.92065391,  0.98507331,  0.15296169,
       -0.07895123]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5153934876721381
{'scaleFactor': 20, 'currentState': array([25.35685115, 20.15153987, 15.18551728,  0.5800802 ,  0.77708746,
        0.24421718]), 'targetState': array([25., 25., 15.])}
episode index:2381
target thresh 29.068851271101114
model initialize at round 2381
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5155763577654326
{'scaleFactor': 20, 'currentState': array([25.27174113, 20.12578644, 14.93096148,  0.55402012,  0.75292368,
        0.35520085]), 'targetState': array([25., 25., 15.])}
episode index:2382
target thresh 29.07594403133008
model initialize at round 2382
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14916239, 14.95619696,  0.98789402,  0.14884509,
       -0.04370986]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5157550836536557
{'scaleFactor': 20, 'currentState': array([26.44029406, 21.52287625, 16.69830987,  0.44336467,  0.80788181,
        0.38827149]), 'targetState': array([25., 25., 15.])}
episode index:2383
target thresh 29.083036082318493
model initialize at round 2383
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87271421,  0.98027799,  0.15221708,
       -0.12603582]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5159336596040531
{'scaleFactor': 20, 'currentState': array([26.99267188, 21.17348314, 14.71029486,  0.61764499,  0.71399419,
        0.32973773]), 'targetState': array([25., 25., 15.])}
episode index:2384
target thresh 29.090127424137258
model initialize at round 2384
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.06711392, 14.88085353,  0.99059446,  0.06715422,
       -0.11921801]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5161120858052258
{'scaleFactor': 20, 'currentState': array([27.25259957, 20.20984052, 15.02304198,  0.55941073,  0.74447788,
        0.36443426]), 'targetState': array([25., 25., 15.])}
episode index:2385
target thresh 29.0972180568573
model initialize at round 2385
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.93256373,  0.9859269 ,  0.15309424,
       -0.06715882]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5162903624454588
{'scaleFactor': 20, 'currentState': array([27.03132823, 21.07205697, 14.7460529 ,  0.56774899,  0.79547423,
        0.21185335]), 'targetState': array([25., 25., 15.])}
episode index:2386
target thresh 29.104307980549528
model initialize at round 2386
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5164684897127213
{'scaleFactor': 20, 'currentState': array([27.62265191, 20.06186379, 12.86704654,  0.85754029,  0.5110002 ,
        0.05918994]), 'targetState': array([25., 25., 15.])}
episode index:2387
target thresh 29.111397195284816
model initialize at round 2387
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.49957295e+01,  1.48462733e+01,  9.88148887e-01,
       -4.26249659e-03, -1.53439268e-01]), 'targetState': array([25., 25., 15.])}
done in step count: 45
reward sum = 0.6361854860638709
running average episode reward sum: 0.516518622458262
{'scaleFactor': 20, 'currentState': array([28.07352107, 21.34951008, 10.01533113,  0.61569868,  0.71944681,
        0.32142094]), 'targetState': array([25., 25., 15.])}
episode index:2388
target thresh 29.1184857011341
model initialize at round 2388
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.94190379,  0.98650064,  0.15318333,
       -0.05789086]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5167004857598282
{'scaleFactor': 20, 'currentState': array([25.31497853, 20.10881089, 15.70020178,  0.55244197,  0.75122326,
        0.36120835]), 'targetState': array([25., 25., 15.])}
episode index:2389
target thresh 29.125573498168222
model initialize at round 2389
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13310964, 14.9534574 ,  0.99000773,  0.13311067,
       -0.04654296]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5168782178366655
{'scaleFactor': 20, 'currentState': array([26.64196429, 21.42146763, 15.95620788,  0.52933292,  0.76955601,
        0.3571977 ]), 'targetState': array([25., 25., 15.])}
episode index:2390
target thresh 29.13266058645808
model initialize at round 2390
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.06056695, 14.9478258 ,  0.99675573,  0.06098025,
       -0.05253024]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.5166620412503683
{'scaleFactor': 20, 'currentState': array([ 2.69337152, -1.8497125 , 15.17093034,  0.14473076, -0.98281559,
       -0.11457102]), 'targetState': array([25., 25., 15.])}
episode index:2391
target thresh 29.139746966074554
model initialize at round 2391
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08798915, 14.97536328,  0.99576773,  0.08850177,
       -0.02478026]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5168396407939095
{'scaleFactor': 20, 'currentState': array([26.83775514, 20.93505316, 16.43600542,  0.49668762,  0.77039968,
        0.39973208]), 'targetState': array([25., 25., 15.])}
episode index:2392
target thresh 29.146832637088494
model initialize at round 2392
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11442322, 14.92401944,  0.99051237,  0.11448243,
       -0.07601988]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5170170919049029
{'scaleFactor': 20, 'currentState': array([27.04853798, 20.92004348, 15.40758257,  0.60908281,  0.72392621,
        0.32395829]), 'targetState': array([25., 25., 15.])}
episode index:2393
target thresh 29.153917599570754
model initialize at round 2393
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14905718, 14.84890732,  0.97778217,  0.14721763,
       -0.14922801]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.517198367158869
{'scaleFactor': 20, 'currentState': array([25.33160644, 20.07823015, 14.52822303,  0.5761099 ,  0.76189485,
        0.29599596]), 'targetState': array([25., 25., 15.])}
episode index:2394
target thresh 29.161001853592193
model initialize at round 2394
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.92309058,  0.98525903,  0.15299053,
       -0.07654112]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5173794910347526
{'scaleFactor': 20, 'currentState': array([25.49763568, 20.02562034, 14.39116356,  0.65223414,  0.75050581,
        0.10645025]), 'targetState': array([25., 25., 15.])}
episode index:2395
target thresh 29.168085399223642
model initialize at round 2395
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14822306, 14.89583936,  0.98366615,  0.14727475,
       -0.10349424]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5175604637220919
{'scaleFactor': 20, 'currentState': array([25.37987367, 20.07651968, 14.47405514,  0.60232998,  0.76282893,
        0.23513959]), 'targetState': array([25., 25., 15.])}
episode index:2396
target thresh 29.175168236535963
model initialize at round 2396
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11348807, 14.85515271,  0.98316118,  0.1127041 ,
       -0.1438467 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5177373179922958
{'scaleFactor': 20, 'currentState': array([26.56832505, 21.45622222, 13.80481796,  0.49154378,  0.85288391,
        0.17599362]), 'targetState': array([25., 25., 15.])}
episode index:2397
target thresh 29.18225036559995
model initialize at round 2397
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5179179905243674
{'scaleFactor': 20, 'currentState': array([25.30735583, 20.1343767 , 13.37522251,  0.61574727,  0.7872468 ,
       -0.03313281]), 'targetState': array([25., 25., 15.])}
episode index:2398
target thresh 29.18933178648645
model initialize at round 2398
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5180985124332359
{'scaleFactor': 20, 'currentState': array([25.20163595, 20.17899767, 13.17617057,  0.60114952,  0.79583394,
        0.0725782 ]), 'targetState': array([25., 25., 15.])}
episode index:2399
target thresh 29.196412499266255
model initialize at round 2399
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5182749214486392
{'scaleFactor': 20, 'currentState': array([27.14748904, 20.88857085, 14.78101511,  0.61648158,  0.73791349,
        0.27465277]), 'targetState': array([25., 25., 15.])}
episode index:2400
target thresh 29.203492504010185
model initialize at round 2400
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5184551443259616
{'scaleFactor': 20, 'currentState': array([25.2754413 , 20.18739632, 13.76975761,  0.59421427,  0.79760134,
        0.10364129]), 'targetState': array([25., 25., 15.])}
episode index:2401
target thresh 29.210571800789054
model initialize at round 2401
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5186352171426036
{'scaleFactor': 20, 'currentState': array([24.93700891, 20.04906434, 11.86869819,  0.52662277,  0.76082925,
       -0.37921935]), 'targetState': array([25., 25., 15.])}
episode index:2402
target thresh 29.217650389673633
model initialize at round 2402
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5188111825742551
{'scaleFactor': 20, 'currentState': array([26.47332143, 20.89420459, 10.86502608,  0.62077222,  0.73400781,
       -0.27545305]), 'targetState': array([25., 25., 15.])}
episode index:2403
target thresh 29.224728270734712
model initialize at round 2403
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09450025, 14.84627329,  0.98379111,  0.09390759,
       -0.1527626 ]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.5189830853052586
{'scaleFactor': 20, 'currentState': array([29.31904594, 20.49389846, 15.20198716,  0.66162714,  0.637837  ,
        0.39422518]), 'targetState': array([25., 25., 15.])}
episode index:2404
target thresh 29.23180544404308
model initialize at round 2404
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08044081, 14.85506347,  0.98627041,  0.08013776,
       -0.14439052]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.5187672919225953
{'scaleFactor': 20, 'currentState': array([1.98993615e+01, 2.18857203e+01, 3.30322138e+00, 7.48505789e-01,
       6.62858436e-01, 1.89150407e-02]), 'targetState': array([25., 25., 15.])}
episode index:2405
target thresh 29.23888190966949
model initialize at round 2405
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5189469356291527
{'scaleFactor': 20, 'currentState': array([25.06992896, 20.1409952 , 12.43020696,  0.57923948,  0.80390878,
       -0.13495293]), 'targetState': array([25., 25., 15.])}
episode index:2406
target thresh 29.24595766768473
model initialize at round 2406
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13557127, 14.84627329,  0.97923305,  0.13409683,
       -0.15205482]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5191224791330048
{'scaleFactor': 20, 'currentState': array([26.7420921 , 21.21171286, 13.09348828,  0.58242919,  0.807448  ,
        0.09382947]), 'targetState': array([25., 25., 15.])}
episode index:2407
target thresh 29.253032718159545
model initialize at round 2407
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5193018261308316
{'scaleFactor': 20, 'currentState': array([25.01664427, 20.14070716, 12.29525027,  0.57829398,  0.80770041,
       -0.11487442]), 'targetState': array([25., 25., 15.])}
episode index:2408
target thresh 29.260107061164675
model initialize at round 2408
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5194810242311924
{'scaleFactor': 20, 'currentState': array([25.22678794, 20.16385869, 13.25433438,  0.61921923,  0.78208846,
        0.07003699]), 'targetState': array([25., 25., 15.])}
episode index:2409
target thresh 29.26718069677089
model initialize at round 2409
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14888171, 14.84627329,  0.9774244 ,  0.14699052,
       -0.15177397]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5196600736194367
{'scaleFactor': 20, 'currentState': array([25.32982913, 20.07883387, 14.21244889,  0.61151638,  0.74417899,
        0.26878494]), 'targetState': array([25., 25., 15.])}
episode index:2410
target thresh 29.274253625048896
model initialize at round 2410
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14712348, 14.95933292,  0.98832171,  0.14687407,
       -0.04059814]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5198350301004743
{'scaleFactor': 20, 'currentState': array([26.73479411, 21.35028451, 15.98376133,  0.57850373,  0.71633708,
        0.39012129]), 'targetState': array([25., 25., 15.])}
episode index:2411
target thresh 29.28132584606945
model initialize at round 2411
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14728805, 14.96495136,  0.9885074 ,  0.14706599,
       -0.0349958 ]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.52001378425462
{'scaleFactor': 20, 'currentState': array([25.38389594, 20.01371199, 15.61674332,  0.56857591,  0.74637646,
        0.34589538]), 'targetState': array([25., 25., 15.])}
episode index:2412
target thresh 29.28839735990326
model initialize at round 2412
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84675977,  0.97679771,  0.15167666,
       -0.15119667]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5201923902494999
{'scaleFactor': 20, 'currentState': array([25.28356417, 20.16426194, 14.37528587,  0.57349168,  0.77234352,
        0.27311679]), 'targetState': array([25., 25., 15.])}
episode index:2413
target thresh 29.295468166621042
model initialize at round 2413
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89377197,  0.98264961,  0.15258534,
       -0.10543933]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5203708482692391
{'scaleFactor': 20, 'currentState': array([25.30005604, 20.11726874, 15.29198159,  0.55622435,  0.75524716,
        0.34672208]), 'targetState': array([25., 25., 15.])}
episode index:2414
target thresh 29.30253826629351
model initialize at round 2414
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87053766,  0.98000955,  0.1521754 ,
       -0.12815589]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5205491584976576
{'scaleFactor': 20, 'currentState': array([25.44127468, 20.00926531, 14.69968281,  0.64434308,  0.7024955 ,
        0.30219541]), 'targetState': array([25., 25., 15.])}
episode index:2415
target thresh 29.309607658991354
model initialize at round 2415
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.05861395, 14.89195319,  0.99237975,  0.05875484,
       -0.10830654]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.5207194880462541
{'scaleFactor': 20, 'currentState': array([28.97865916, 21.13910645, 14.9539686 ,  0.55583354,  0.73682248,
        0.3848918 ]), 'targetState': array([25., 25., 15.])}
episode index:2416
target thresh 29.316676344785275
model initialize at round 2416
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5208975064830988
{'scaleFactor': 20, 'currentState': array([25.25609604, 20.18898089, 13.67351418,  0.59372016,  0.79790492,
        0.10413506]), 'targetState': array([25., 25., 15.])}
episode index:2417
target thresh 29.32374432374596
model initialize at round 2417
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89228743,  0.98249591,  0.15256148,
       -0.10689612]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.521075377675579
{'scaleFactor': 20, 'currentState': array([25.34796458, 20.17460917, 14.45225864,  0.58920275,  0.786472  ,
        0.18520775]), 'targetState': array([25., 25., 15.])}
episode index:2418
target thresh 29.330811595944073
model initialize at round 2418
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5212531018063042
{'scaleFactor': 20, 'currentState': array([25.22313486, 20.18570206, 13.68269468,  0.58330511,  0.78783591,
        0.19766063]), 'targetState': array([25., 25., 15.])}
episode index:2419
target thresh 29.337878161450316
model initialize at round 2419
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87860185,  0.98098236,  0.15232645,
       -0.12029237]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5214306790575827
{'scaleFactor': 20, 'currentState': array([25.30910322, 20.11065242, 15.09549344,  0.55846749,  0.75125705,
        0.35174835]), 'targetState': array([25., 25., 15.])}
episode index:2420
target thresh 29.34494402033534
model initialize at round 2420
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.51537267e+01,  1.49836005e+01,  9.88025506e-01,
        1.53420110e-01, -1.63667439e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5216041815236477
{'scaleFactor': 20, 'currentState': array([27.12029159, 20.99771699, 16.41273237,  0.71427387,  0.66130737,
        0.22909693]), 'targetState': array([25., 25., 15.])}
episode index:2421
target thresh 29.352009172669803
model initialize at round 2421
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.06385759, 14.89260428,  0.99212959,  0.06399496,
       -0.10762674]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.5213888205899054
{'scaleFactor': 20, 'currentState': array([17.77155172, 38.28947244, -0.87566074, -0.39362496,  0.91608539,
       -0.0764653 ]), 'targetState': array([25., 25., 15.])}
episode index:2422
target thresh 29.359073618524356
model initialize at round 2422
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.52156612196395
{'scaleFactor': 20, 'currentState': array([25.14815562, 20.15434388, 12.72307876,  0.58217245,  0.79906253,
       -0.15024748]), 'targetState': array([25., 25., 15.])}
episode index:2423
target thresh 29.366137357969645
model initialize at round 2423
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5217432770497322
{'scaleFactor': 20, 'currentState': array([25.2187797 , 20.18815444, 13.55216246,  0.58629883,  0.79185997,
        0.17091364]), 'targetState': array([25., 25., 15.])}
episode index:2424
target thresh 29.373200391076303
model initialize at round 2424
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15189441, 14.84627329,  0.97699301,  0.14989876,
       -0.15170699]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5219202860282272
{'scaleFactor': 20, 'currentState': array([25.34098408, 20.15114767, 14.46988731,  0.58676153,  0.77802737,
        0.22446451]), 'targetState': array([25., 25., 15.])}
episode index:2425
target thresh 29.380262717914974
model initialize at round 2425
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13542243, 14.89782406,  0.98563387,  0.13482519,
       -0.10172532]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.5220893482961079
{'scaleFactor': 20, 'currentState': array([28.78407928, 21.4019635 , 15.82472228,  0.52765372,  0.75472678,
        0.38983207]), 'targetState': array([25., 25., 15.])}
episode index:2426
target thresh 29.387324338556276
model initialize at round 2426
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.93116674,  0.98583384,  0.15307979,
       -0.0685436 ]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5222660688159282
{'scaleFactor': 20, 'currentState': array([25.35679239, 20.17083813, 14.6433103 ,  0.59233777,  0.78975413,
        0.15945025]), 'targetState': array([25., 25., 15.])}
episode index:2427
target thresh 29.394385253070798
model initialize at round 2427
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5224426437669513
{'scaleFactor': 20, 'currentState': array([2.52634558e+01, 2.01724111e+01, 1.34260689e+01, 6.01876000e-01,
       7.98322856e-01, 2.06373070e-02]), 'targetState': array([25., 25., 15.])}
episode index:2428
target thresh 29.401445461529185
model initialize at round 2428
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5226190733289656
{'scaleFactor': 20, 'currentState': array([25.22773686, 20.18970318, 13.43188481,  0.59192439,  0.79823305,
        0.11157742]), 'targetState': array([25., 25., 15.])}
episode index:2429
target thresh 29.408504964002024
model initialize at round 2429
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.8616025 ,  0.97886235,  0.15199726,
       -0.13684051]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.522791444142164
{'scaleFactor': 20, 'currentState': array([27.23162674, 20.73151492, 14.62892729,  0.67402741,  0.64811748,
        0.35444434]), 'targetState': array([25., 25., 15.])}
episode index:2430
target thresh 29.415563760559916
model initialize at round 2430
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10396311, 14.94447952,  0.992988  ,  0.10427689,
       -0.05568805]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.5229598003345807
{'scaleFactor': 20, 'currentState': array([29.28042316, 20.80554417, 15.5878371 ,  0.6477876 ,  0.66428377,
        0.37295885]), 'targetState': array([25., 25., 15.])}
episode index:2431
target thresh 29.422621851273444
model initialize at round 2431
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.51364021e+01,  1.49986258e+01,  9.90640446e-01,
        1.36490354e-01, -1.37511130e-03]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.5231280180761811
{'scaleFactor': 20, 'currentState': array([29.04380781, 21.37611775, 15.63353063,  0.59057095,  0.71056457,
        0.38252312]), 'targetState': array([25., 25., 15.])}
episode index:2432
target thresh 29.42967923621319
model initialize at round 2432
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15051389, 14.9054294 ,  0.98425979,  0.14964118,
       -0.09402226]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5233038758779993
{'scaleFactor': 20, 'currentState': array([25.35271457, 20.14302405, 14.40330099,  0.58910348,  0.78156207,
        0.20522628]), 'targetState': array([25., 25., 15.])}
episode index:2433
target thresh 29.43673591544973
model initialize at round 2433
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15110224, 14.84627329,  0.97710723,  0.14913443,
       -0.15172472]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5234756820709012
{'scaleFactor': 20, 'currentState': array([27.17209302, 20.73372903, 14.91326341,  0.59549258,  0.71135915,
        0.37330518]), 'targetState': array([25., 25., 15.])}
episode index:2434
target thresh 29.443791889053617
model initialize at round 2434
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.0696936 , 14.91834432,  0.99417192,  0.06998729,
       -0.08199978]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.5236434807016348
{'scaleFactor': 20, 'currentState': array([29.11296834, 20.81958087, 15.74441608,  0.62651867,  0.64060079,
        0.44396507]), 'targetState': array([25., 25., 15.])}
episode index:2435
target thresh 29.45084715709544
model initialize at round 2435
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.07463484, 15.01842334,  0.99699868,  0.07516246,
        0.01855358]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.5234285203236785
{'scaleFactor': 20, 'currentState': array([25.26224775, 21.8744388 ,  5.53497447,  0.99712678,  0.03257385,
       -0.0683896 ]), 'targetState': array([25., 25., 15.])}
episode index:2436
target thresh 29.45790171964572
model initialize at round 2436
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11980449, 14.84627329,  0.98116754,  0.11873563,
       -0.15235521]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5236000638727459
{'scaleFactor': 20, 'currentState': array([26.8471454 , 21.03741082, 14.72167349,  0.50608868,  0.78730786,
        0.35216557]), 'targetState': array([25., 25., 15.])}
episode index:2437
target thresh 29.46495557677502
model initialize at round 2437
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.07163334, 14.84627329,  0.98564165,  0.07131798,
       -0.15304995]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5237714666969987
{'scaleFactor': 20, 'currentState': array([27.38946725, 20.22203515, 13.83452351,  0.63890751,  0.74944389,
        0.17358298]), 'targetState': array([25., 25., 15.])}
episode index:2438
target thresh 29.472008728553877
model initialize at round 2438
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08438847, 14.84627329,  0.98467095,  0.08393422,
       -0.15289922]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.5239388688623163
{'scaleFactor': 20, 'currentState': array([28.82303223, 21.28583803, 15.67037951,  0.6134334 ,  0.71781197,
        0.32931055]), 'targetState': array([25., 25., 15.])}
episode index:2439
target thresh 29.479061175052813
model initialize at round 2439
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.1203289 , 14.88879029,  0.98657922,  0.11991313,
       -0.11082545]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.5237241398177006
{'scaleFactor': 20, 'currentState': array([28.73672356, 15.55913804,  9.45649316,  0.86334608, -0.44425411,
        0.23931533]), 'targetState': array([25., 25., 15.])}
episode index:2440
target thresh 29.48611291634238
model initialize at round 2440
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.03355014, 14.90310805,  0.9946792 ,  0.03370871,
       -0.09734991]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.5235095867083939
{'scaleFactor': 20, 'currentState': array([33.86197348, 20.97848172, 12.52612998,  0.78971212,  0.45014346,
        0.41680407]), 'targetState': array([25., 25., 15.])}
episode index:2441
target thresh 29.493163952493052
model initialize at round 2441
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09444658, 14.89223692,  0.9896868 ,  0.0944167 ,
       -0.10772899]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.5236768904599084
{'scaleFactor': 20, 'currentState': array([29.24806918, 21.04903381, 14.42349311,  0.62652439,  0.76257826,
        0.16106391]), 'targetState': array([25., 25., 15.])}
episode index:2442
target thresh 29.500214283575378
model initialize at round 2442
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5238479110325409
{'scaleFactor': 20, 'currentState': array([ 2.68293710e+01,  2.11496951e+01,  1.24929056e+01,  6.17734093e-01,
        7.86105107e-01, -2.10558970e-02]), 'targetState': array([25., 25., 15.])}
episode index:2443
target thresh 29.50726390965984
model initialize at round 2443
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14006503, 14.84627329,  0.97864025,  0.13845785,
       -0.15196277]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.5240149394437006
{'scaleFactor': 20, 'currentState': array([28.98923344, 21.28983957, 13.05446329,  0.59595883,  0.77098845,
        0.22452146]), 'targetState': array([25., 25., 15.])}
episode index:2444
target thresh 29.514312830816948
model initialize at round 2444
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5241895713907175
{'scaleFactor': 20, 'currentState': array([25.37366019, 20.00606857, 13.3674031 ,  0.62423022,  0.78051638,
       -0.03362744]), 'targetState': array([25., 25., 15.])}
episode index:2445
target thresh 29.521361047117168
model initialize at round 2445
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.1183441 , 14.84627329,  0.98133517,  0.11730831,
       -0.15238124]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5243601726082197
{'scaleFactor': 20, 'currentState': array([26.38273474, 21.3051623 , 11.68124712,  0.53624223,  0.79678988,
       -0.27851419]), 'targetState': array([25., 25., 15.])}
episode index:2446
target thresh 29.528408558631014
model initialize at round 2446
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.06243434, 14.84627329,  0.98624465,  0.06219751,
       -0.15314358]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.5241458856557848
{'scaleFactor': 20, 'currentState': array([31.40256112, 27.83809175,  9.25266601,  0.93150233,  0.11160198,
        0.34619129]), 'targetState': array([25., 25., 15.])}
episode index:2447
target thresh 29.53545536542893
model initialize at round 2447
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.92699459,  0.98554472,  0.15303489,
       -0.07267687]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5243163653386873
{'scaleFactor': 20, 'currentState': array([26.94127037, 21.32455377, 14.57004038,  0.61817043,  0.76229864,
        0.19174489]), 'targetState': array([25., 25., 15.])}
episode index:2448
target thresh 29.542501467581417
model initialize at round 2448
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09727052, 14.84627329,  0.98353316,  0.09663513,
       -0.15272254]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.5244828614524351
{'scaleFactor': 20, 'currentState': array([29.24795151, 20.69532503, 13.84465698,  0.64848672,  0.68834501,
        0.32503249]), 'targetState': array([25., 25., 15.])}
episode index:2449
target thresh 29.549546865158906
model initialize at round 2449
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11718898, 14.93622352,  0.99104079,  0.11731218,
       -0.06384353]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.524653064427108
{'scaleFactor': 20, 'currentState': array([26.60790003, 21.38259336, 16.15720067,  0.46152645,  0.81902082,
        0.34087861]), 'targetState': array([25., 25., 15.])}
episode index:2450
target thresh 29.556591558231872
model initialize at round 2450
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87758038,  0.98086244,  0.15230783,
       -0.12128971]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5248270085256281
{'scaleFactor': 20, 'currentState': array([25.31414483, 20.15367537, 14.73681092,  0.57203559,  0.76969692,
        0.28344653]), 'targetState': array([25., 25., 15.])}
episode index:2451
target thresh 29.56363554687075
model initialize at round 2451
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.121424  , 14.9450338 ,  0.99105849,  0.12155382,
       -0.05502497]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5249969323188073
{'scaleFactor': 20, 'currentState': array([26.72229984, 21.40888592, 15.50131206,  0.50133773,  0.82170014,
        0.27105233]), 'targetState': array([25., 25., 15.])}
episode index:2452
target thresh 29.57067883114597
model initialize at round 2452
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5251705944132146
{'scaleFactor': 20, 'currentState': array([25.26315053, 20.18739479, 13.73716425,  0.59156393,  0.79510929,
        0.13361638]), 'targetState': array([25., 25., 15.])}
episode index:2453
target thresh 29.57772141112799
model initialize at round 2453
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5253402397086456
{'scaleFactor': 20, 'currentState': array([26.65858139, 21.50991062, 13.64597946,  0.59385264,  0.76913144,
        0.23616918]), 'targetState': array([25., 25., 15.])}
episode index:2454
target thresh 29.584763286887217
model initialize at round 2454
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11459845, 14.86215271,  0.98399884,  0.11390378,
       -0.13701169]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.5251262518309638
{'scaleFactor': 20, 'currentState': array([33.29506337, 12.92548258, 13.08182174,  0.97602767,  0.17525655,
        0.12905475]), 'targetState': array([25., 25., 15.])}
episode index:2455
target thresh 29.591804458494074
model initialize at round 2455
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5252996491428812
{'scaleFactor': 20, 'currentState': array([25.16733168, 20.16202602, 12.82279671,  0.58441271,  0.79913234,
       -0.14088751]), 'targetState': array([25., 25., 15.])}
episode index:2456
target thresh 29.598844926018998
model initialize at round 2456
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5254690347758719
{'scaleFactor': 20, 'currentState': array([27.12780228, 20.8896195 , 13.44709608,  0.62844196,  0.76694893,
        0.1298077 ]), 'targetState': array([25., 25., 15.])}
episode index:2457
target thresh 29.605884689532335
model initialize at round 2457
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5256421515436197
{'scaleFactor': 20, 'currentState': array([25.18416716, 20.1674187 , 12.91474312,  0.586889  ,  0.79993413,
       -0.12516666]), 'targetState': array([25., 25., 15.])}
episode index:2458
target thresh 29.612923749104546
model initialize at round 2458
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.525815127508791
{'scaleFactor': 20, 'currentState': array([25.22457052, 20.16152273, 13.19644979,  0.62069019,  0.78005771,
        0.07908009]), 'targetState': array([25., 25., 15.])}
episode index:2459
target thresh 29.619962104805985
model initialize at round 2459
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.0713483 , 14.8960501 ,  0.99198787,  0.07149157,
       -0.10415863]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.5259802698748065
{'scaleFactor': 20, 'currentState': array([28.68741495, 21.54747861, 13.79065028,  0.51680869,  0.84969758,
        0.10451218]), 'targetState': array([25., 25., 15.])}
episode index:2460
target thresh 29.62699975670705
model initialize at round 2460
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5261491036332486
{'scaleFactor': 20, 'currentState': array([26.50937349, 21.3158672 , 12.41432827,  0.51123559,  0.85743167,
        0.0587291 ]), 'targetState': array([25., 25., 15.])}
episode index:2461
target thresh 29.63403670487811
model initialize at round 2461
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.88901422,  0.98214975,  0.15250772,
       -0.11010571]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5263216629128046
{'scaleFactor': 20, 'currentState': array([25.31750055, 20.1453072 , 14.881712  ,  0.56804843,  0.7653566 ,
        0.30257273]), 'targetState': array([25., 25., 15.])}
episode index:2462
target thresh 29.641072949389525
model initialize at round 2462
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.92048065,  0.98505989,  0.15295961,
       -0.07912254]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.526490220966596
{'scaleFactor': 20, 'currentState': array([27.09076991, 20.97870114, 15.43984762,  0.60250301,  0.72610267,
        0.33130807]), 'targetState': array([25., 25., 15.])}
episode index:2463
target thresh 29.648108490311675
model initialize at round 2463
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12195467, 14.91941452,  0.98927465,  0.12186532,
       -0.08052643]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.5266548212616204
{'scaleFactor': 20, 'currentState': array([29.45950426, 20.59340052, 15.39485257,  0.64127551,  0.69775412,
        0.31922548]), 'targetState': array([25., 25., 15.])}
episode index:2464
target thresh 29.655143327714917
model initialize at round 2464
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89339101,  0.98261037,  0.15257925,
       -0.10581323]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5268269653706016
{'scaleFactor': 20, 'currentState': array([25.30353165, 20.1183056 , 15.28144435,  0.55250373,  0.75046697,
        0.362683  ]), 'targetState': array([25., 25., 15.])}
episode index:2465
target thresh 29.662177461669582
model initialize at round 2465
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.93873155,  0.98631524,  0.15315454,
       -0.06104041]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5269989698655445
{'scaleFactor': 20, 'currentState': array([25.34569293, 20.13665031, 15.33148878,  0.56892587,  0.76577256,
        0.29985953]), 'targetState': array([25., 25., 15.])}
episode index:2466
target thresh 29.669210892246024
model initialize at round 2466
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.92030585,  0.98504632,  0.1529575 ,
       -0.07929539]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5271669800720851
{'scaleFactor': 20, 'currentState': array([27.2964639 , 20.66204788, 15.45142674,  0.63882778,  0.71280578,
        0.28949438]), 'targetState': array([25., 25., 15.])}
episode index:2467
target thresh 29.676243619514576
model initialize at round 2467
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11565035, 14.84850621,  0.98196825,  0.11471209,
       -0.15026474]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5273348541277288
{'scaleFactor': 20, 'currentState': array([26.52752098, 21.48007308, 13.76514852,  0.48955536,  0.8559318 ,
        0.16648214]), 'targetState': array([25., 25., 15.])}
episode index:2468
target thresh 29.68327564354556
model initialize at round 2468
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5275064439194551
{'scaleFactor': 20, 'currentState': array([2.51604345e+01, 2.01813734e+01, 1.29749491e+01, 5.91721434e-01,
       8.06142399e-01, 4.21634951e-04]), 'targetState': array([25., 25., 15.])}
episode index:2469
target thresh 29.69030696440931
model initialize at round 2469
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5276778947720788
{'scaleFactor': 20, 'currentState': array([25.3854195 , 20.02814539, 14.12574514,  0.61269064,  0.74840134,
        0.25397954]), 'targetState': array([25., 25., 15.])}
episode index:2470
target thresh 29.697337582176107
model initialize at round 2470
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11680643, 14.94000005,  0.99131748,  0.11696187,
       -0.0600798 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5278453582502776
{'scaleFactor': 20, 'currentState': array([27.09017097, 20.91838451, 13.67817847,  0.59390937,  0.80076197,
        0.07779422]), 'targetState': array([25., 25., 15.])}
episode index:2471
target thresh 29.704367496916305
model initialize at round 2471
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5280165332873527
{'scaleFactor': 20, 'currentState': array([25.36553403, 20.06025888, 14.1060809 ,  0.60048803,  0.77092026,
        0.21235836]), 'targetState': array([25., 25., 15.])}
episode index:2472
target thresh 29.711396708700168
model initialize at round 2472
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14107212, 14.84627329,  0.9785049 ,  0.1394341 ,
       -0.15194175]), 'targetState': array([25., 25., 15.])}
done in step count: 46
reward sum = 0.6298236312032323
running average episode reward sum: 0.5280577007349531
{'scaleFactor': 20, 'currentState': array([25.36090415, 29.97623729, 12.83629026,  0.70352005, -0.67231281,
       -0.23033676]), 'targetState': array([25., 25., 15.])}
episode index:2473
target thresh 29.71842521759799
model initialize at round 2473
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5282248076260873
{'scaleFactor': 20, 'currentState': array([26.90751936, 21.02309197, 14.68389142,  0.55244377,  0.74042572,
        0.38285197]), 'targetState': array([25., 25., 15.])}
episode index:2474
target thresh 29.72545302368007
model initialize at round 2474
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12665514, 14.91972833,  0.98872287,  0.12649175,
       -0.08016812]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.5280113834613899
{'scaleFactor': 20, 'currentState': array([18.02085532, 11.14448666, 13.43769706,  0.62379534, -0.77485038,
       -0.10240244]), 'targetState': array([25., 25., 15.])}
episode index:2475
target thresh 29.73248012701668
model initialize at round 2475
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87824662,  0.98094077,  0.15232   ,
       -0.12063924]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5281822149098707
{'scaleFactor': 20, 'currentState': array([25.3219559 , 20.1457749 , 14.93581807,  0.57048812,  0.76817974,
        0.29059112]), 'targetState': array([25., 25., 15.])}
episode index:2476
target thresh 29.739506527678085
model initialize at round 2476
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11656677, 14.84930905,  0.98198264,  0.11562277,
       -0.14947061]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5283490691426084
{'scaleFactor': 20, 'currentState': array([26.71609053, 21.27180753, 13.18255663,  0.52803778,  0.84456643,
        0.08878994]), 'targetState': array([25., 25., 15.])}
episode index:2477
target thresh 29.74653222573457
model initialize at round 2477
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5285157887068773
{'scaleFactor': 20, 'currentState': array([27.38026487, 20.5169566 , 14.25278619,  0.68619938,  0.67956989,
        0.25945169]), 'targetState': array([25., 25., 15.])}
episode index:2478
target thresh 29.753557221256365
model initialize at round 2478
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15351998, 14.86068145,  0.97877037,  0.15177859,
       -0.13773825]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5286862099497951
{'scaleFactor': 20, 'currentState': array([25.2977121 , 20.15606266, 14.56291838,  0.57148976,  0.76942705,
        0.28527437]), 'targetState': array([25., 25., 15.])}
episode index:2479
target thresh 29.760581514313735
model initialize at round 2479
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85641155,  0.97816272,  0.15188862,
       -0.14187159]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5288526591189288
{'scaleFactor': 20, 'currentState': array([26.68918771, 21.48796839, 12.94454203,  0.59461392,  0.79905058,
       -0.08917653]), 'targetState': array([25., 25., 15.])}
episode index:2480
target thresh 29.767605104976912
model initialize at round 2480
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.07170139, 14.84627329,  0.98563688,  0.07138539,
       -0.15304921]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.5290151793481863
{'scaleFactor': 20, 'currentState': array([29.57165899, 20.18277973, 14.27132286,  0.77173523,  0.55689787,
        0.30706595]), 'targetState': array([25., 25., 15.])}
episode index:2481
target thresh 29.774627993316148
model initialize at round 2481
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.02789788, 14.90192949,  0.99473822,  0.0280314 ,
       -0.09853989]), 'targetState': array([25., 25., 15.])}
done in step count: 42
reward sum = 0.6556592205741436
running average episode reward sum: 0.5290662043446512
{'scaleFactor': 20, 'currentState': array([20.2802427 , 26.55101653, 10.28532794,  0.65752745, -0.74819841,
       -0.08863854]), 'targetState': array([25., 25., 15.])}
episode index:2482
target thresh 29.781650179401666
model initialize at round 2482
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5292322993688383
{'scaleFactor': 20, 'currentState': array([26.66300356, 21.44338872, 14.75989909,  0.48443906,  0.80836856,
        0.3344534 ]), 'targetState': array([25., 25., 15.])}
episode index:2483
target thresh 29.788671663303667
model initialize at round 2483
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84635558,  0.97673874,  0.15166751,
       -0.15158632]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5294020891234804
{'scaleFactor': 20, 'currentState': array([25.29492202, 20.15421156, 14.61961333,  0.56917228,  0.76732314,
        0.29539484]), 'targetState': array([25., 25., 15.])}
episode index:2484
target thresh 29.795692445092403
model initialize at round 2484
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.1523491 , 14.86996519,  0.98014071,  0.15083188,
       -0.12873981]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5295679153046786
{'scaleFactor': 20, 'currentState': array([27.66451712, 20.17373781, 14.20427697,  0.74856511,  0.64081296,
        0.17032036]), 'targetState': array([25., 25., 15.])}
episode index:2485
target thresh 29.80271252483806
model initialize at round 2485
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12977153, 14.84627329,  0.97997107,  0.12845691,
       -0.15216942]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5297336080778469
{'scaleFactor': 20, 'currentState': array([26.99309183, 20.83582424, 15.61874042,  0.57252362,  0.73889458,
        0.35531886]), 'targetState': array([25., 25., 15.])}
episode index:2486
target thresh 29.809731902610835
model initialize at round 2486
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.07583929, 14.90095425,  0.99215449,  0.07600433,
       -0.0992613 ]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.5298953819981641
{'scaleFactor': 20, 'currentState': array([28.96329826, 21.08711241, 14.80997008,  0.55232671,  0.7518686 ,
        0.36004001]), 'targetState': array([25., 25., 15.])}
episode index:2487
target thresh 29.81675057848093
model initialize at round 2487
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84998527,  0.97726311,  0.15174893,
       -0.14808471]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5300646322666134
{'scaleFactor': 20, 'currentState': array([25.25489854, 20.17540924, 14.03877812,  0.58005266,  0.78166732,
        0.2292054 ]), 'targetState': array([25., 25., 15.])}
episode index:2488
target thresh 29.823768552518537
model initialize at round 2488
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5302299257648595
{'scaleFactor': 20, 'currentState': array([26.58619566, 21.47591016, 13.80744416,  0.49141023,  0.83330225,
        0.25322588]), 'targetState': array([25., 25., 15.])}
episode index:2489
target thresh 29.830785824793814
model initialize at round 2489
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5303989057343916
{'scaleFactor': 20, 'currentState': array([25.30554554, 20.14950191, 14.77514929,  0.57759581,  0.77706209,
        0.25011516]), 'targetState': array([25., 25., 15.])}
episode index:2490
target thresh 29.837802395376954
model initialize at round 2490
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5305677500315276
{'scaleFactor': 20, 'currentState': array([25.35879431, 20.03997768, 13.84610307,  0.60336657,  0.77486849,
        0.18848771]), 'targetState': array([25., 25., 15.])}
episode index:2491
target thresh 29.844818264338137
model initialize at round 2491
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14471121, 14.96003208,  0.98869639,  0.14452066,
       -0.03991529]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.530732642647647
{'scaleFactor': 20, 'currentState': array([26.75678151, 21.2855242 , 16.55123655,  0.55902442,  0.74510932,
        0.3637359 ]), 'targetState': array([25., 25., 15.])}
episode index:2492
target thresh 29.851833431747476
model initialize at round 2492
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12043427, 14.97272201,  0.99231056,  0.12071535,
       -0.02734165]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5308974029792769
{'scaleFactor': 20, 'currentState': array([26.97087693, 20.92064315, 16.03353918,  0.54122671,  0.78514293,
        0.30103858]), 'targetState': array([25., 25., 15.])}
episode index:2493
target thresh 29.85884789767517
model initialize at round 2493
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5310658442972082
{'scaleFactor': 20, 'currentState': array([25.29308203, 20.13405544, 14.92601047,  0.55872668,  0.75689148,
        0.33902771]), 'targetState': array([25., 25., 15.])}
episode index:2494
target thresh 29.865861662191328
model initialize at round 2494
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.90071332,  0.98334087,  0.15269268,
       -0.09861884]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5312341505920389
{'scaleFactor': 20, 'currentState': array([25.31444453, 20.14101627, 14.83668893,  0.56677769,  0.76175024,
        0.31384649]), 'targetState': array([25., 25., 15.])}
episode index:2495
target thresh 29.872874725366106
model initialize at round 2495
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14910863, 14.88785916,  0.98270158,  0.14800938,
       -0.11131412]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5313985119697668
{'scaleFactor': 20, 'currentState': array([26.71752938, 21.41462245, 14.98073747,  0.49103054,  0.82564319,
        0.27785307]), 'targetState': array([25., 25., 15.])}
episode index:2496
target thresh 29.87988708726963
model initialize at round 2496
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85890914,  0.97850237,  0.15194136,
       -0.13945226]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5315665502308522
{'scaleFactor': 20, 'currentState': array([25.35605192, 20.14793927, 13.96887206,  0.63875076,  0.76571102,
        0.07539293]), 'targetState': array([25., 25., 15.])}
episode index:2497
target thresh 29.886898747972023
model initialize at round 2497
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12637926, 14.84627329,  0.98038851,  0.12515229,
       -0.15223424]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.531730646947894
{'scaleFactor': 20, 'currentState': array([26.97447766, 20.38551942, 11.32390672,  0.67254661,  0.68038519,
       -0.29113064]), 'targetState': array([25., 25., 15.])}
episode index:2498
target thresh 29.893909707543397
model initialize at round 2498
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10107593, 14.84627329,  0.98316702,  0.1003783 ,
       -0.15266569]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.5315178695781669
{'scaleFactor': 20, 'currentState': array([37.07187537, 31.79463999, 24.0389116 , -0.19548024, -0.9793338 ,
        0.05189205]), 'targetState': array([25., 25., 15.])}
episode index:2499
target thresh 29.900919966053884
model initialize at round 2499
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.49898447e+01,  1.49326789e+01,  9.97643665e-01,
       -1.02336958e-02, -6.78409102e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.5313052624303356
{'scaleFactor': 20, 'currentState': array([55.03659499, 44.42580842, 34.35623495, -0.76962171, -0.46859894,
        0.43370203]), 'targetState': array([25., 25., 15.])}
episode index:2500
target thresh 29.90792952357356
model initialize at round 2500
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.03862849,  0.98742418,  0.15332674,
        0.03852798]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5314692667833827
{'scaleFactor': 20, 'currentState': array([26.91330741, 21.21152155, 16.78905283,  0.63910277,  0.72359515,
        0.26068699]), 'targetState': array([25., 25., 15.])}
episode index:2501
target thresh 29.91493838017253
model initialize at round 2501
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13775926, 14.84627329,  0.9789467 ,  0.13622118,
       -0.15201036]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5316331400378262
{'scaleFactor': 20, 'currentState': array([27.36516601, 20.42684404, 13.26985599,  0.64211977,  0.7600945 ,
        0.09969229]), 'targetState': array([25., 25., 15.])}
episode index:2502
target thresh 29.921946535920885
model initialize at round 2502
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.0976142 , 14.84627329,  0.98350065,  0.09697337,
       -0.15271749]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.5317931209438866
{'scaleFactor': 20, 'currentState': array([28.98588636, 20.97456178, 13.7083308 ,  0.54925881,  0.78279214,
        0.29249139]), 'targetState': array([25., 25., 15.])}
episode index:2503
target thresh 29.928953990888708
model initialize at round 2503
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86455902,  0.97924997,  0.15205745,
       -0.13397028]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5319605318580065
{'scaleFactor': 20, 'currentState': array([25.27599953, 20.18252543, 13.49480352,  0.59691074,  0.80169732,
        0.03128864]), 'targetState': array([25., 25., 15.])}
episode index:2504
target thresh 29.935960745146073
model initialize at round 2504
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85157934,  0.9774897 ,  0.15178411,
       -0.14654512]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5321278091107179
{'scaleFactor': 20, 'currentState': array([25.29733023, 20.16394587, 14.02817828,  0.58685322,  0.78125848,
        0.21269341]), 'targetState': array([25., 25., 15.])}
episode index:2505
target thresh 29.942966798763038
model initialize at round 2505
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89415579,  0.98268902,  0.15259146,
       -0.10506257]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5322949528620304
{'scaleFactor': 20, 'currentState': array([25.34365863, 20.06065765, 15.34772694,  0.56030434,  0.74533625,
        0.3612934 ]), 'targetState': array([25., 25., 15.])}
episode index:2506
target thresh 29.949972151809668
model initialize at round 2506
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.90938761,  0.98414089,  0.15281691,
       -0.09007612]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5324619632716985
{'scaleFactor': 20, 'currentState': array([25.25377588, 20.05406638, 15.98478813,  0.5466023 ,  0.73382341,
        0.40339699]), 'targetState': array([25., 25., 15.])}
episode index:2507
target thresh 29.956976804356017
model initialize at round 2507
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.51471165e+01,  1.49889766e+01,  9.89078226e-01,
        1.46979503e-01, -1.10131289e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.5326212947647747
{'scaleFactor': 20, 'currentState': array([29.53179832, 20.97177188, 15.1884644 ,  0.8090827 ,  0.5796598 ,
        0.09684888]), 'targetState': array([25., 25., 15.])}
episode index:2508
target thresh 29.963980756472143
model initialize at round 2508
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.50025212e+01,  1.48462733e+01,  9.88154735e-01,
        2.51652551e-03, -1.53440176e-01]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.5324090104703288
{'scaleFactor': 20, 'currentState': array([21.71002675, 33.1699501 , 15.32294164,  0.41393659, -0.90398477,
       -0.10708893]), 'targetState': array([25., 25., 15.])}
episode index:2509
target thresh 29.970984008228076
model initialize at round 2509
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89267392,  0.98253612,  0.15256772,
       -0.10651692]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5325757758246833
{'scaleFactor': 20, 'currentState': array([25.29382346, 20.1226981 , 15.10359092,  0.55448026,  0.7524405 ,
        0.3555066 ]), 'targetState': array([25., 25., 15.])}
episode index:2510
target thresh 29.977986559693846
model initialize at round 2510
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.88760704,  0.98199786,  0.15248414,
       -0.11148449]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5327424083511968
{'scaleFactor': 20, 'currentState': array([25.38735671, 20.01771285, 15.18835707,  0.58048674,  0.75865836,
        0.29575774]), 'targetState': array([25., 25., 15.])}
episode index:2511
target thresh 29.984988410939472
model initialize at round 2511
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.532905122420086
{'scaleFactor': 20, 'currentState': array([26.64473278, 21.4438761 , 15.34925513,  0.55698983,  0.77176595,
        0.30682186]), 'targetState': array([25., 25., 15.])}
episode index:2512
target thresh 29.991989562034995
model initialize at round 2512
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13122285, 14.84627329,  0.97978926,  0.12986944,
       -0.15214119]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5330677069911092
{'scaleFactor': 20, 'currentState': array([26.29573876, 21.53584504, 12.05132113,  0.48049599,  0.87071226,
       -0.10480348]), 'targetState': array([25., 25., 15.])}
episode index:2513
target thresh 29.99899001305041
model initialize at round 2513
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5332339449954484
{'scaleFactor': 20, 'currentState': array([25.25540897, 20.17845885, 13.97346517,  0.58098668,  0.78258116,
        0.22365421]), 'targetState': array([25., 25., 15.])}
episode index:2514
target thresh 30.00598976405572
model initialize at round 2514
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.92641334,  0.98550311,  0.15302843,
       -0.07325241]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5334000508025675
{'scaleFactor': 20, 'currentState': array([25.32326504, 20.14308502, 14.93029138,  0.56599163,  0.76244765,
        0.31357145]), 'targetState': array([25., 25., 15.])}
episode index:2515
target thresh 30.012988815120924
model initialize at round 2515
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.93850036,  0.98630135,  0.15315238,
       -0.06126988]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5335660245700942
{'scaleFactor': 20, 'currentState': array([25.32590267, 20.13011777, 15.23928768,  0.56799861,  0.76605121,
        0.30090385]), 'targetState': array([25., 25., 15.])}
episode index:2516
target thresh 30.01998716631602
model initialize at round 2516
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.8764616 ,  0.98073   ,  0.15228727,
       -0.12238163]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5337280881874287
{'scaleFactor': 20, 'currentState': array([26.38307587, 21.58822242, 16.06398363,  0.44116151,  0.83386653,
        0.3317275 ]), 'targetState': array([25., 25., 15.])}
episode index:2517
target thresh 30.02698481771099
model initialize at round 2517
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.88996654,  0.98225149,  0.15252352,
       -0.10917225]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5338937998481564
{'scaleFactor': 20, 'currentState': array([25.36379668, 20.17656485, 14.60914689,  0.59787261,  0.79541265,
        0.09933308]), 'targetState': array([25., 25., 15.])}
episode index:2518
target thresh 30.033981769375796
model initialize at round 2518
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.534059379939483
{'scaleFactor': 20, 'currentState': array([25.19320928, 20.18952204, 13.35810122,  0.5896781 ,  0.79867809,
        0.11997105]), 'targetState': array([25., 25., 15.])}
episode index:2519
target thresh 30.040978021380425
model initialize at round 2519
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5342248286180388
{'scaleFactor': 20, 'currentState': array([25.27412566, 20.18719559, 13.74950929,  0.5914608 ,  0.79360229,
        0.14272183]), 'targetState': array([25., 25., 15.])}
episode index:2520
target thresh 30.04797357379485
model initialize at round 2520
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.91750503,  0.98482489,  0.15292312,
       -0.08206374]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5343901460402053
{'scaleFactor': 20, 'currentState': array([25.30642021, 20.12750683, 15.08496433,  0.55776994,  0.75496273,
        0.34485356]), 'targetState': array([25., 25., 15.])}
episode index:2521
target thresh 30.054968426688987
model initialize at round 2521
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89747751,  0.98302426,  0.15264352,
       -0.1018001 ]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5345553323621164
{'scaleFactor': 20, 'currentState': array([25.32787024, 20.12919965, 14.82717157,  0.57485266,  0.76667991,
        0.28591317]), 'targetState': array([25., 25., 15.])}
episode index:2522
target thresh 30.061962580132818
model initialize at round 2522
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84653331,  0.97676468,  0.15167153,
       -0.151415  ]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5347203877396581
{'scaleFactor': 20, 'currentState': array([25.28084428, 20.1420456 , 14.72999821,  0.56167379,  0.76026345,
        0.32637715]), 'targetState': array([25., 25., 15.])}
episode index:2523
target thresh 30.068956034196283
model initialize at round 2523
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.90434318,  0.9836843 ,  0.15274601,
       -0.09504658]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5348853123284696
{'scaleFactor': 20, 'currentState': array([25.30702303, 20.17564219, 14.1763143 ,  0.58538307,  0.78441477,
        0.20498814]), 'targetState': array([25., 25., 15.])}
episode index:2524
target thresh 30.07594878894929
model initialize at round 2524
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87718616,  0.9808159 ,  0.15230061,
       -0.12167451]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5350501062839434
{'scaleFactor': 20, 'currentState': array([2.52041838e+01, 2.01778065e+01, 1.31556649e+01, 5.93658114e-01,
       8.04695095e-01, 5.98726701e-03]), 'targetState': array([25., 25., 15.])}
episode index:2525
target thresh 30.082940844461792
model initialize at round 2525
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5352147697612262
{'scaleFactor': 20, 'currentState': array([25.2577221 , 20.15934601, 13.92308355,  0.59857945,  0.76556216,
        0.23583304]), 'targetState': array([25., 25., 15.])}
episode index:2526
target thresh 30.089932200803716
model initialize at round 2526
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10666607, 14.8826027 ,  0.98740664,  0.10638665,
       -0.11708977]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5353755395988359
{'scaleFactor': 20, 'currentState': array([26.91044993, 20.90526885, 15.07087448,  0.54404589,  0.7574019 ,
        0.36104908]), 'targetState': array([25., 25., 15.])}
episode index:2527
target thresh 30.096922858044937
model initialize at round 2527
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.07002221, 14.92055354,  0.99432736,  0.07032829,
       -0.07979373]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.5351637612999439
{'scaleFactor': 20, 'currentState': array([26.35745513, 32.14998181, 16.34893008, -0.08647536, -0.96479808,
        0.24836802]), 'targetState': array([25., 25., 15.])}
episode index:2528
target thresh 30.103912816255395
model initialize at round 2528
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12458609, 14.84857119,  0.98094241,  0.12344624,
       -0.15004337]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.5353207014290886
{'scaleFactor': 20, 'currentState': array([29.28062181, 20.89339365, 13.87782029,  0.6793184 ,  0.71577077,
        0.16186017]), 'targetState': array([25., 25., 15.])}
episode index:2529
target thresh 30.110902075504985
model initialize at round 2529
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09758658, 14.84627329,  0.98350327,  0.09694618,
       -0.1527179 ]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.5354775174948901
{'scaleFactor': 20, 'currentState': array([29.44783857, 20.08292996, 14.35121095,  0.62181024,  0.70327807,
        0.34460409]), 'targetState': array([25., 25., 15.])}
episode index:2530
target thresh 30.1178906358636
model initialize at round 2530
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5356416868083651
{'scaleFactor': 20, 'currentState': array([25.27325907, 20.12957889, 14.88387741,  0.55732783,  0.75644492,
        0.34231094]), 'targetState': array([25., 25., 15.])}
episode index:2531
target thresh 30.12487849740111
model initialize at round 2531
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.94406755,  0.9866215 ,  0.1532021 ,
       -0.05574158]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5358057264462369
{'scaleFactor': 20, 'currentState': array([25.30425538, 20.10413314, 15.85247813,  0.55807662,  0.7593506 ,
        0.3345701 ]), 'targetState': array([25., 25., 15.])}
episode index:2532
target thresh 30.131865660187408
model initialize at round 2532
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.91656749,  0.9847491 ,  0.15291135,
       -0.08298999]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5359696365620892
{'scaleFactor': 20, 'currentState': array([25.47254568, 20.05052659, 14.8110033 ,  0.66003584,  0.73187987,
        0.16942418]), 'targetState': array([25., 25., 15.])}
episode index:2533
target thresh 30.13885212429236
model initialize at round 2533
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5361334173092628
{'scaleFactor': 20, 'currentState': array([25.21690908, 20.18803801, 13.38213924,  0.59037897,  0.79765343,
        0.12329511]), 'targetState': array([25., 25., 15.])}
episode index:2534
target thresh 30.14583788978583
model initialize at round 2534
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.88416599,  0.98161869,  0.15242526,
       -0.11485336]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5362970688408567
{'scaleFactor': 20, 'currentState': array([25.3049151 , 20.14455964, 14.78255315,  0.56844644,  0.76583184,
        0.30061642]), 'targetState': array([25., 25., 15.])}
episode index:2535
target thresh 30.15282295673769
model initialize at round 2535
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.88374868,  0.98157196,  0.15241801,
       -0.11526165]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5364605913097286
{'scaleFactor': 20, 'currentState': array([25.33344192, 20.17312405, 14.46540141,  0.58457127,  0.78187113,
        0.21668865]), 'targetState': array([25., 25., 15.])}
episode index:2536
target thresh 30.15980732521777
model initialize at round 2536
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13953162, 14.86485509,  0.98128889,  0.13830387,
       -0.13395576]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5366202363858387
{'scaleFactor': 20, 'currentState': array([26.86641582, 20.89499605, 12.07312338,  0.55620275,  0.78229304,
       -0.28045696]), 'targetState': array([25., 25., 15.])}
episode index:2537
target thresh 30.166790995295923
model initialize at round 2537
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.536783502663819
{'scaleFactor': 20, 'currentState': array([24.83857191, 20.03728481, 11.62618182,  0.53279789,  0.7789381 ,
       -0.33072925]), 'targetState': array([25., 25., 15.])}
episode index:2538
target thresh 30.173773967041985
model initialize at round 2538
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5369428948051098
{'scaleFactor': 20, 'currentState': array([26.45263185, 21.57453537, 12.48623957,  0.49802144,  0.85970418,
       -0.11350495]), 'targetState': array([25., 25., 15.])}
episode index:2539
target thresh 30.180756240525785
model initialize at round 2539
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5371059054960919
{'scaleFactor': 20, 'currentState': array([2.53615495e+01, 2.00313823e+01, 1.33265191e+01, 6.51961809e-01,
       7.58136917e-01, 1.31990396e-02]), 'targetState': array([25., 25., 15.])}
episode index:2540
target thresh 30.18773781581715
model initialize at round 2540
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.07307669, 14.84627329,  0.98553963,  0.07274745,
       -0.1530341 ]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.5372613401448172
{'scaleFactor': 20, 'currentState': array([2.87067034e+01, 2.13527393e+01, 1.25645396e+01, 5.55340716e-01,
       8.31503803e-01, 1.40753389e-02]), 'targetState': array([25., 25., 15.])}
episode index:2541
target thresh 30.194718692985887
model initialize at round 2541
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5374240973083716
{'scaleFactor': 20, 'currentState': array([25.38556511, 20.01953286, 13.40759559,  0.64227858,  0.76515202,
        0.04495126]), 'targetState': array([25., 25., 15.])}
episode index:2542
target thresh 30.201698872101822
model initialize at round 2542
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14511043, 14.84627329,  0.97795299,  0.14334462,
       -0.15185605]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5375867264678649
{'scaleFactor': 20, 'currentState': array([25.2535024 , 20.10557807, 13.18716853,  0.60069937,  0.79878089,
       -0.03330684]), 'targetState': array([25., 25., 15.])}
episode index:2543
target thresh 30.208678353234742
model initialize at round 2543
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5377492277742454
{'scaleFactor': 20, 'currentState': array([ 2.51732826e+01,  2.01756888e+01,  1.29409766e+01,  5.92342362e-01,
        8.05686359e-01, -1.28792777e-04]), 'targetState': array([25., 25., 15.])}
episode index:2544
target thresh 30.215657136454443
model initialize at round 2544
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13832936, 14.84627329,  0.97887138,  0.13677439,
       -0.15199866]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5379078646786175
{'scaleFactor': 20, 'currentState': array([27.39291794, 20.39657907, 13.59682782,  0.63321567,  0.75948213,
        0.14907991]), 'targetState': array([25., 25., 15.])}
episode index:2545
target thresh 30.222635221830718
model initialize at round 2545
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.8690127 ,  0.9798189 ,  0.15214579,
       -0.12964023]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5380701121983431
{'scaleFactor': 20, 'currentState': array([25.31481995, 20.15709456, 14.52341161,  0.58302346,  0.77101018,
        0.25617757]), 'targetState': array([25., 25., 15.])}
episode index:2546
target thresh 30.229612609433342
model initialize at round 2546
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5382322323152263
{'scaleFactor': 20, 'currentState': array([25.23225423, 20.1877023 , 13.34691062,  0.5949586 ,  0.80213044,
        0.05109805]), 'targetState': array([25., 25., 15.])}
episode index:2547
target thresh 30.236589299332085
model initialize at round 2547
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5383942251792706
{'scaleFactor': 20, 'currentState': array([25.27890598, 20.17389601, 13.69103813,  0.59535112,  0.79423533,
        0.12143838]), 'targetState': array([25., 25., 15.])}
episode index:2548
target thresh 30.24356529159672
model initialize at round 2548
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5385523601044262
{'scaleFactor': 20, 'currentState': array([26.99367643, 21.15844641, 13.6311948 ,  0.62318806,  0.76061784,
        0.1819262 ]), 'targetState': array([25., 25., 15.])}
episode index:2549
target thresh 30.250540586297024
model initialize at round 2549
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86337106,  0.97909517,  0.15203341,
       -0.13512397]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5387103710021895
{'scaleFactor': 20, 'currentState': array([26.48674236, 21.50910835, 15.65818826,  0.45063356,  0.80832638,
        0.3788639 ]), 'targetState': array([25., 25., 15.])}
episode index:2550
target thresh 30.257515183502715
model initialize at round 2550
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11709023, 14.84855682,  0.98181381,  0.11612203,
       -0.15019091]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.538868258018418
{'scaleFactor': 20, 'currentState': array([26.79655549, 21.15514665, 15.35128371,  0.57455511,  0.75214525,
        0.32274439]), 'targetState': array([25., 25., 15.])}
episode index:2551
target thresh 30.264489083283564
model initialize at round 2551
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.05771652, 14.84627329,  0.98652218,  0.05751377,
       -0.15318667]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.5386571027448998
{'scaleFactor': 20, 'currentState': array([ 6.35305318e+00,  4.50322810e+01,  2.82369554e+00,  1.09848047e-01,
       -9.93725585e-01, -2.10444264e-02]), 'targetState': array([25., 25., 15.])}
episode index:2552
target thresh 30.271462285709305
model initialize at round 2552
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.02725048, 14.84627329,  0.98779253,  0.02718972,
       -0.15338393]), 'targetState': array([25., 25., 15.])}
done in step count: 48
reward sum = 0.617290140942288
running average episode reward sum: 0.5386879029948791
{'scaleFactor': 20, 'currentState': array([20.42642975, 24.58562967, 15.44627728,  0.75394061, -0.53989227,
       -0.37428584]), 'targetState': array([25., 25., 15.])}
episode index:2553
target thresh 30.278434790849662
model initialize at round 2553
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5388493368816861
{'scaleFactor': 20, 'currentState': array([25.17523425, 20.17602821, 12.95893886,  0.59167375,  0.80544729,
       -0.03430496]), 'targetState': array([25., 25., 15.])}
episode index:2554
target thresh 30.28540659877438
model initialize at round 2554
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5390069223268992
{'scaleFactor': 20, 'currentState': array([27.37663126, 20.57355406, 13.33518079,  0.77603664,  0.60075745,
        0.19198338]), 'targetState': array([25., 25., 15.])}
episode index:2555
target thresh 30.292377709553143
model initialize at round 2555
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.02835961, 14.84922703,  0.9882047 ,  0.02830818,
       -0.15049955]), 'targetState': array([25., 25., 15.])}
done in step count: 45
reward sum = 0.6361854860638709
running average episode reward sum: 0.5390449421092689
{'scaleFactor': 20, 'currentState': array([ 2.01587532e+01,  2.11602108e+01,  1.07796356e+01,  9.86029088e-01,
       -1.66224038e-01,  1.07799614e-02]), 'targetState': array([25., 25., 15.])}
episode index:2556
target thresh 30.299348123255697
model initialize at round 2556
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.90334758,  0.98359134,  0.15273157,
       -0.09602675]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5392060469617486
{'scaleFactor': 20, 'currentState': array([25.31111054, 20.10716022, 15.28637669,  0.55411422,  0.74850394,
        0.36427913]), 'targetState': array([25., 25., 15.])}
episode index:2557
target thresh 30.306317839951735
model initialize at round 2557
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87126046,  0.98009917,  0.15218931,
       -0.12745204]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.539363308143312
{'scaleFactor': 20, 'currentState': array([26.70170706, 21.41062101, 13.53896913,  0.53322486,  0.84526114,
        0.03471101]), 'targetState': array([25., 25., 15.])}
episode index:2558
target thresh 30.313286859710942
model initialize at round 2558
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14895681, 14.84627329,  0.97741374,  0.14706306,
       -0.15177232]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5395204464165664
{'scaleFactor': 20, 'currentState': array([27.25498791, 20.08764506, 11.71541325,  0.65094182,  0.73267786,
       -0.19864012]), 'targetState': array([25., 25., 15.])}
episode index:2559
target thresh 30.320255182603017
model initialize at round 2559
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5396774619255447
{'scaleFactor': 20, 'currentState': array([26.46303661, 21.58991267, 12.98585802,  0.50707692,  0.84975658,
        0.14417609]), 'targetState': array([25., 25., 15.])}
episode index:2560
target thresh 30.32722280869764
model initialize at round 2560
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.88325645,  0.98151663,  0.15240941,
       -0.11574317]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5398380681684085
{'scaleFactor': 20, 'currentState': array([25.28083223, 20.17004808, 14.20963861,  0.57952385,  0.77937428,
        0.23817608]), 'targetState': array([25., 25., 15.])}
episode index:2561
target thresh 30.3341897380645
model initialize at round 2561
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85560707,  0.97805212,  0.15187145,
       -0.14265032]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.539998549035595
{'scaleFactor': 20, 'currentState': array([25.30477214, 20.17863783, 14.19338408,  0.59078862,  0.79025926,
        0.16266256]), 'targetState': array([25., 25., 15.])}
episode index:2562
target thresh 30.341155970773247
model initialize at round 2562
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.1393391 , 14.84627329,  0.97873725,  0.13775391,
       -0.15197783]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5401551942171655
{'scaleFactor': 20, 'currentState': array([26.24599904, 21.54428019, 11.74791329,  0.48759025,  0.83962388,
       -0.23934806]), 'targetState': array([25., 25., 15.])}
episode index:2563
target thresh 30.348121506893566
model initialize at round 2563
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.540311717210607
{'scaleFactor': 20, 'currentState': array([27.05758269, 20.17775417, 10.88837266,  0.76933534,  0.54781884,
       -0.3286604 ]), 'targetState': array([25., 25., 15.])}
episode index:2564
target thresh 30.355086346495096
model initialize at round 2564
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.02884119, 14.84627329,  0.98774866,  0.02877561,
       -0.15337712]), 'targetState': array([25., 25., 15.])}
done in step count: 47
reward sum = 0.6235253948912
running average episode reward sum: 0.5403441591902095
{'scaleFactor': 20, 'currentState': array([21.2498154 , 21.0674787 , 11.69330861,  0.88251142, -0.37168116,
       -0.28814356]), 'targetState': array([25., 25., 15.])}
episode index:2565
target thresh 30.362050489647487
model initialize at round 2565
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12714289, 14.84627329,  0.98029546,  0.12589656,
       -0.15221979]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5405004865441498
{'scaleFactor': 20, 'currentState': array([26.50500699, 21.61122227, 13.56151391,  0.48815889,  0.86819882,
        0.08906014]), 'targetState': array([25., 25., 15.])}
episode index:2566
target thresh 30.369013936420373
model initialize at round 2566
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5406566921003855
{'scaleFactor': 20, 'currentState': array([26.46398002, 21.51829933, 14.93559958,  0.44727709,  0.81184239,
        0.37530673]), 'targetState': array([25., 25., 15.])}
episode index:2567
target thresh 30.375976686883412
model initialize at round 2567
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89057468,  0.98231602,  0.15253354,
       -0.10857601]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5408127760012035
{'scaleFactor': 20, 'currentState': array([27.05390839, 21.17626828, 14.97977658,  0.66835821,  0.72040278,
        0.18524884]), 'targetState': array([25., 25., 15.])}
episode index:2568
target thresh 30.382938741106212
model initialize at round 2568
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10005108, 14.84627329,  0.98326697,  0.09937062,
       -0.15268121]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5409687383886693
{'scaleFactor': 20, 'currentState': array([27.14485798, 20.50319791, 14.9447149 ,  0.6035555 ,  0.72714477,
        0.32707986]), 'targetState': array([25., 25., 15.])}
episode index:2569
target thresh 30.389900099158396
model initialize at round 2569
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10275054, 14.88016966,  0.9875259 ,  0.10249375,
       -0.11953087]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5411245794046274
{'scaleFactor': 20, 'currentState': array([26.64319231, 21.2038235 , 16.03049804,  0.4816734 ,  0.81641757,
        0.31851701]), 'targetState': array([25., 25., 15.])}
episode index:2570
target thresh 30.39686076110958
model initialize at round 2570
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12002849, 14.92151323,  0.98966999,  0.11998848,
       -0.07846061]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5412802991907015
{'scaleFactor': 20, 'currentState': array([27.12872468, 20.92839616, 15.64790768,  0.72746495,  0.644252  ,
        0.23608071]), 'targetState': array([25., 25., 15.])}
episode index:2571
target thresh 30.403820727029363
model initialize at round 2571
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.50044143e+01,  1.48682333e+01,  9.91248796e-01,
        4.41985119e-03, -1.31932898e-01]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.541069848063489
{'scaleFactor': 20, 'currentState': array([30.84642227, 20.60959125, 11.97429487,  0.40001046,  0.82084649,
        0.40767962]), 'targetState': array([25., 25., 15.])}
episode index:2572
target thresh 30.41077999698737
model initialize at round 2572
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5412291641155047
{'scaleFactor': 20, 'currentState': array([25.27634178, 20.1688581 , 14.26550782,  0.58093668,  0.78103941,
        0.22910699]), 'targetState': array([25., 25., 15.])}
episode index:2573
target thresh 30.417738571053164
model initialize at round 2573
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85074465,  0.97737133,  0.15176573,
       -0.14735141]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5413883563788242
{'scaleFactor': 20, 'currentState': array([25.36652086, 20.11362555, 14.61905598,  0.59825301,  0.765478  ,
        0.23693197]), 'targetState': array([25., 25., 15.])}
episode index:2574
target thresh 30.424696449296363
model initialize at round 2574
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.8665577 ,  0.97950751,  0.15209744,
       -0.13202802]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5415437318324251
{'scaleFactor': 20, 'currentState': array([26.8214371 , 21.47405402, 14.8005848 ,  0.5965007 ,  0.77850492,
        0.19523578]), 'targetState': array([25., 25., 15.])}
episode index:2575
target thresh 30.431653631786503
model initialize at round 2575
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.07672574, 14.84627329,  0.9852728 ,  0.07635938,
       -0.15299267]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.5416953318386651
{'scaleFactor': 20, 'currentState': array([28.76839907, 21.14251697, 15.2559472 ,  0.5521311 ,  0.72687528,
        0.40841593]), 'targetState': array([25., 25., 15.])}
episode index:2576
target thresh 30.43861011859319
model initialize at round 2576
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.97562058,  0.98786543,  0.15339525,
       -0.02432686]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5418541578837025
{'scaleFactor': 20, 'currentState': array([25.4025724 , 20.08074236, 15.31925806,  0.58301483,  0.76742708,
        0.26673842]), 'targetState': array([25., 25., 15.])}
episode index:2577
target thresh 30.445565909785966
model initialize at round 2577
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.93054413,  0.98579176,  0.15307325,
       -0.06916063]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5420128607122581
{'scaleFactor': 20, 'currentState': array([25.34997776, 20.15492185, 14.9190924 ,  0.57355922,  0.76892191,
        0.2824693 ]), 'targetState': array([25., 25., 15.])}
episode index:2578
target thresh 30.45252100543442
model initialize at round 2578
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.94529592,  0.9866881 ,  0.15321244,
       -0.05452107]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5421677530304778
{'scaleFactor': 20, 'currentState': array([26.55329139, 21.52978939, 15.8324552 ,  0.46786597,  0.81628295,
        0.33879726]), 'targetState': array([25., 25., 15.])}
episode index:2579
target thresh 30.45947540560807
model initialize at round 2579
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89887042,  0.98316176,  0.15266487,
       -0.10043104]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5423262112850783
{'scaleFactor': 20, 'currentState': array([25.32740653, 20.14876481, 14.92461959,  0.57434977,  0.77209545,
        0.27201277]), 'targetState': array([25., 25., 15.])}
episode index:2580
target thresh 30.46642911037647
model initialize at round 2580
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5424808621716014
{'scaleFactor': 20, 'currentState': array([26.6339743 , 21.51020755, 13.06092289,  0.57790042,  0.8131887 ,
        0.06895827]), 'targetState': array([25., 25., 15.])}
episode index:2581
target thresh 30.473382119809177
model initialize at round 2581
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13790299, 14.84627329,  0.97892774,  0.13636067,
       -0.15200741]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.542635393266578
{'scaleFactor': 20, 'currentState': array([27.12369062, 20.72307992, 13.79656276,  0.5733483 ,  0.78310423,
        0.24087237]), 'targetState': array([25., 25., 15.])}
episode index:2582
target thresh 30.480334433975685
model initialize at round 2582
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.9201949 ,  0.98503769,  0.15295616,
       -0.07940508]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5427934864360062
{'scaleFactor': 20, 'currentState': array([25.32626917, 20.12793213, 15.33346378,  0.56232965,  0.76001313,
        0.32583033]), 'targetState': array([25., 25., 15.])}
episode index:2583
target thresh 30.48728605294555
model initialize at round 2583
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14478457, 14.87034951,  0.98127029,  0.14350787,
       -0.12850724]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5429477769402496
{'scaleFactor': 20, 'currentState': array([26.82551548, 21.05857514, 15.96917293,  0.49797384,  0.79066096,
        0.3561984 ]), 'targetState': array([25., 25., 15.])}
episode index:2584
target thresh 30.49423697678827
model initialize at round 2584
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.9324619 ,  0.98592018,  0.1530932 ,
       -0.06725977]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5431019480707954
{'scaleFactor': 20, 'currentState': array([26.96733973, 21.23754988, 15.81765052,  0.65007113,  0.71404175,
        0.25990749]), 'targetState': array([25., 25., 15.])}
episode index:2585
target thresh 30.501187205573366
model initialize at round 2585
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.02486192, 14.8724784 ,  0.99149836,  0.02489955,
       -0.12771461]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.542891931849577
{'scaleFactor': 20, 'currentState': array([19.79904262, 23.53729284, 12.0280746 ,  0.61432999, -0.78685058,
       -0.05886282]), 'targetState': array([25., 25., 15.])}
episode index:2586
target thresh 30.50813673937033
model initialize at round 2586
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.49939678e+01,  1.48462733e+01,  9.88139953e-01,
       -6.02084797e-03, -1.53437881e-01]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.5426820779911117
{'scaleFactor': 20, 'currentState': array([ 3.18859743e-01,  2.15444562e+01,  3.35685873e+00, -9.73123906e-03,
       -8.91606045e-01,  4.52707371e-01]), 'targetState': array([25., 25., 15.])}
episode index:2587
target thresh 30.515085578248645
model initialize at round 2587
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.88857401,  0.98210243,  0.15250038,
       -0.11053711]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5428398476865942
{'scaleFactor': 20, 'currentState': array([25.43269368, 20.06274293, 14.35529164,  0.61118271,  0.76691279,
        0.19570505]), 'targetState': array([25., 25., 15.])}
episode index:2588
target thresh 30.52203372227783
model initialize at round 2588
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.88117567,  0.98128026,  0.15237271,
       -0.11777775]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5429938223106631
{'scaleFactor': 20, 'currentState': array([26.69861545, 21.44083594, 15.51714614,  0.53373634,  0.80358077,
        0.26340741]), 'targetState': array([25., 25., 15.])}
episode index:2589
target thresh 30.52898117152736
model initialize at round 2589
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5431513498116628
{'scaleFactor': 20, 'currentState': array([25.24784639, 20.18940241, 13.50831629,  0.59517498,  0.80069026,
        0.06827771]), 'targetState': array([25., 25., 15.])}
episode index:2590
target thresh 30.535927926066687
model initialize at round 2590
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5433087557167529
{'scaleFactor': 20, 'currentState': array([25.22438425, 20.18672828, 13.45779556,  0.59498816,  0.79631776,
        0.10893629]), 'targetState': array([25., 25., 15.])}
episode index:2591
target thresh 30.54287398596529
model initialize at round 2591
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14156827, 14.87591195,  0.98239649,  0.14048098,
       -0.12313502]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5434660401666692
{'scaleFactor': 20, 'currentState': array([25.36391367, 20.07321762, 13.82498732,  0.60618161,  0.79120021,
        0.08090791]), 'targetState': array([25., 25., 15.])}
episode index:2592
target thresh 30.54981935129264
model initialize at round 2592
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5436232033019308
{'scaleFactor': 20, 'currentState': array([25.37862208, 20.03408951, 13.47108189,  0.67166472,  0.73770913,
        0.06820362]), 'targetState': array([25., 25., 15.])}
episode index:2593
target thresh 30.556764022118188
model initialize at round 2593
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13912334, 14.84627329,  0.97876598,  0.13754464,
       -0.1519823 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.543776579148538
{'scaleFactor': 20, 'currentState': array([26.97115566, 21.16113889, 15.11705789,  0.65794954,  0.70682487,
        0.25980957]), 'targetState': array([25., 25., 15.])}
episode index:2594
target thresh 30.56370799851137
model initialize at round 2594
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.04821855, 14.89660141,  0.99342513,  0.04838537,
       -0.10375632]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.5439262087318747
{'scaleFactor': 20, 'currentState': array([28.62415442, 21.21845024, 15.61993818,  0.46345998,  0.78094968,
        0.41871523]), 'targetState': array([25., 25., 15.])}
episode index:2595
target thresh 30.57065128054163
model initialize at round 2595
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.96959403,  0.98770309,  0.15337004,
       -0.03033542]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5440793496951525
{'scaleFactor': 20, 'currentState': array([26.44363662, 21.54445969, 16.38186323,  0.4436214 ,  0.81609258,
        0.37039567]), 'targetState': array([25., 25., 15.])}
episode index:2596
target thresh 30.577593868278406
model initialize at round 2596
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.90423641,  0.98367438,  0.15274447,
       -0.09515171]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5442360346008916
{'scaleFactor': 20, 'currentState': array([25.42346942, 20.00810757, 15.07043339,  0.59247864,  0.75202049,
        0.28884987]), 'targetState': array([25., 25., 15.])}
episode index:2597
target thresh 30.58453576179112
model initialize at round 2597
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.544392598886996
{'scaleFactor': 20, 'currentState': array([25.22563715, 20.18795645, 13.34392666,  0.59377017,  0.80154975,
        0.07039169]), 'targetState': array([25., 25., 15.])}
episode index:2598
target thresh 30.591476961149176
model initialize at round 2598
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5445490426926954
{'scaleFactor': 20, 'currentState': array([25.26805408, 20.18118799, 13.96128444,  0.58274338,  0.78390163,
        0.21426243]), 'targetState': array([25., 25., 15.])}
episode index:2599
target thresh 30.598417466422024
model initialize at round 2599
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85204832,  0.97755593,  0.1517944 ,
       -0.14609196]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5447053661570059
{'scaleFactor': 20, 'currentState': array([25.29666904, 20.15202526, 14.64638994,  0.56745193,  0.76551352,
        0.30329416]), 'targetState': array([25., 25., 15.])}
episode index:2600
target thresh 30.605357277679033
model initialize at round 2600
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.91192468,  0.98436141,  0.15285115,
       -0.08757368]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5448579131709407
{'scaleFactor': 20, 'currentState': array([26.91022108, 21.08617917, 15.76473651,  0.60263221,  0.71530609,
        0.35379602]), 'targetState': array([25., 25., 15.])}
episode index:2601
target thresh 30.612296394989624
model initialize at round 2601
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09118716, 14.93710646,  0.99379825,  0.09153701,
       -0.06313484]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.5450067246370192
{'scaleFactor': 20, 'currentState': array([29.37258754, 20.91023558, 14.4534253 ,  0.68100588,  0.72171304,
        0.12394064]), 'targetState': array([25., 25., 15.])}
episode index:2602
target thresh 30.61923481842316
model initialize at round 2602
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13943781, 14.84627329,  0.97872409,  0.13784964,
       -0.15197579]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5451590386688149
{'scaleFactor': 20, 'currentState': array([26.94301571, 20.94799649, 13.49444422,  0.55859192,  0.80248138,
        0.20975869]), 'targetState': array([25., 25., 15.])}
episode index:2603
target thresh 30.62617254804906
model initialize at round 2603
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.545314887751469
{'scaleFactor': 20, 'currentState': array([25.27029232, 20.13471018, 13.32269678,  0.63325408,  0.77206048,
        0.05396188]), 'targetState': array([25., 25., 15.])}
episode index:2604
target thresh 30.63310958393668
model initialize at round 2604
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10588382, 14.87443761,  0.98651522,  0.10551111,
       -0.12512041]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5454669665467279
{'scaleFactor': 20, 'currentState': array([27.4929953 , 20.2637319 , 14.7502601 ,  0.68219735,  0.68356811,
        0.25950223]), 'targetState': array([25., 25., 15.])}
episode index:2605
target thresh 30.64004592615539
model initialize at round 2605
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08859716, 14.8805633 ,  0.9889056 ,  0.08849922,
       -0.11930467]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.5456153158872346
{'scaleFactor': 20, 'currentState': array([29.49860918, 20.5102706 , 13.62827702,  0.72644288,  0.67962973,
        0.10190277]), 'targetState': array([25., 25., 15.])}
episode index:2606
target thresh 30.646981574774568
model initialize at round 2606
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.07518577, 14.84627329,  0.98538697,  0.07483543,
       -0.1530104 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5457671627738911
{'scaleFactor': 20, 'currentState': array([27.33870278, 20.19841327, 13.00174107,  0.66444229,  0.7426147 ,
        0.08390384]), 'targetState': array([25., 25., 15.])}
episode index:2607
target thresh 30.653916529863558
model initialize at round 2607
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12281545, 14.84627329,  0.98081571,  0.12167608,
       -0.15230058]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5459188932135488
{'scaleFactor': 20, 'currentState': array([26.78228418, 21.08594012, 14.23442328,  0.50168594,  0.80300142,
        0.32171407]), 'targetState': array([25., 25., 15.])}
episode index:2608
target thresh 30.66085079149171
model initialize at round 2608
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86912613,  0.97983315,  0.152148  ,
       -0.12952985]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5460741523767095
{'scaleFactor': 20, 'currentState': array([25.29310591, 20.17785836, 14.12224104,  0.58559596,  0.7854269 ,
        0.20045436]), 'targetState': array([25., 25., 15.])}
episode index:2609
target thresh 30.66778435972838
model initialize at round 2609
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14850925, 14.91002844,  0.98496498,  0.14775395,
       -0.08951398]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5462256489272936
{'scaleFactor': 20, 'currentState': array([27.19879246, 20.78424587, 13.55734146,  0.64888045,  0.76014324,
        0.03371085]), 'targetState': array([25., 25., 15.])}
episode index:2610
target thresh 30.674717234642877
model initialize at round 2610
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12670824, 14.85965632,  0.98224566,  0.12571577,
       -0.13924441]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5463770294330286
{'scaleFactor': 20, 'currentState': array([27.10620347, 20.81146672, 14.73685351,  0.58934334,  0.75440304,
        0.28905099]), 'targetState': array([25., 25., 15.])}
episode index:2611
target thresh 30.68164941630456
model initialize at round 2611
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13625546, 14.85354722,  0.98019131,  0.13490547,
       -0.14500176]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.546528294027197
{'scaleFactor': 20, 'currentState': array([26.21054263, 21.64510288, 12.06630588,  0.46331959,  0.87867631,
       -0.11516463]), 'targetState': array([25., 25., 15.])}
episode index:2612
target thresh 30.688580904782725
model initialize at round 2612
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85310658,  0.97770467,  0.15181749,
       -0.14506907]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.546683082299632
{'scaleFactor': 20, 'currentState': array([25.30166066, 20.18764482, 13.89118753,  0.59244225,  0.79289576,
        0.14257804]), 'targetState': array([25., 25., 15.])}
episode index:2613
target thresh 30.695511700146692
model initialize at round 2613
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.90306199,  0.9835645 ,  0.15272741,
       -0.09630786]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5468341140774061
{'scaleFactor': 20, 'currentState': array([27.39407753, 20.61579327, 15.19441547,  0.63922907,  0.71282253,
        0.28856582]), 'targetState': array([25., 25., 15.])}
episode index:2614
target thresh 30.702441802465795
model initialize at round 2614
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89406298,  0.9826795 ,  0.15258998,
       -0.10515367]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5469886670165351
{'scaleFactor': 20, 'currentState': array([25.34948657, 20.14580475, 14.39413189,  0.61509772,  0.76227013,
        0.20149204]), 'targetState': array([25., 25., 15.])}
episode index:2615
target thresh 30.709371211809312
model initialize at round 2615
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14760123, 14.84627329,  0.9776053 ,  0.14575328,
       -0.15180206]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5471394665128595
{'scaleFactor': 20, 'currentState': array([27.01735052, 20.98785158, 14.50451973,  0.55359994,  0.78270979,
        0.28441606]), 'targetState': array([25., 25., 15.])}
episode index:2616
target thresh 30.716299928246528
model initialize at round 2616
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12662732, 14.88723041,  0.9856474 ,  0.1260706 ,
       -0.11227379]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5472901507631033
{'scaleFactor': 20, 'currentState': array([26.34458363, 21.55048269, 12.35719535,  0.4737666 ,  0.86984738,
       -0.13751633]), 'targetState': array([25., 25., 15.])}
episode index:2617
target thresh 30.723227951846745
model initialize at round 2617
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5474443524052487
{'scaleFactor': 20, 'currentState': array([25.01963817, 20.11878603, 12.21829974,  0.57322599,  0.80310769,
       -0.16257309]), 'targetState': array([25., 25., 15.])}
episode index:2618
target thresh 30.73015528267925
model initialize at round 2618
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5475984362912719
{'scaleFactor': 20, 'currentState': array([25.11573529, 20.16057331, 12.65582062,  0.58612107,  0.80595793,
       -0.0830296 ]), 'targetState': array([25., 25., 15.])}
episode index:2619
target thresh 30.737081920813303
model initialize at round 2619
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.90610555,  0.98384656,  0.1527712 ,
       -0.09331084]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.547752402556008
{'scaleFactor': 20, 'currentState': array([25.32295549, 20.1817641 , 14.04296075,  0.59259697,  0.79185105,
        0.14765074]), 'targetState': array([25., 25., 15.])}
episode index:2620
target thresh 30.744007866318167
model initialize at round 2620
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.8564283 ,  0.97816501,  0.15188898,
       -0.14185537]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5479062513340865
{'scaleFactor': 20, 'currentState': array([25.28181096, 20.18282411, 13.97744991,  0.58897436,  0.78977809,
        0.17134696]), 'targetState': array([25., 25., 15.])}
episode index:2621
target thresh 30.750933119263124
model initialize at round 2621
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5480563557955919
{'scaleFactor': 20, 'currentState': array([27.52024248, 20.28653902, 13.70983242,  0.67667848,  0.72394797,
        0.13418482]), 'targetState': array([25., 25., 15.])}
episode index:2622
target thresh 30.757857679717404
model initialize at round 2622
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85718316,  0.97826825,  0.15190501,
       -0.14112443]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5482099713861769
{'scaleFactor': 20, 'currentState': array([25.33332341, 20.11455591, 13.72528363,  0.62103759,  0.77391207,
        0.12398554]), 'targetState': array([25., 25., 15.])}
episode index:2623
target thresh 30.764781547750264
model initialize at round 2623
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.548363469891708
{'scaleFactor': 20, 'currentState': array([25.24625669, 20.18242006, 13.84079018,  0.58233837,  0.78469386,
        0.21245605]), 'targetState': array([25., 25., 15.])}
episode index:2624
target thresh 30.771704723430936
model initialize at round 2624
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89037701,  0.98229509,  0.15253029,
       -0.10876983]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5485168514459968
{'scaleFactor': 20, 'currentState': array([25.34298233, 20.17829419, 14.38578432,  0.59540611,  0.79396126,
        0.12295154]), 'targetState': array([25., 25., 15.])}
episode index:2625
target thresh 30.778627206828656
model initialize at round 2625
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.548670116182651
{'scaleFactor': 20, 'currentState': array([2.52119882e+01, 2.01873080e+01, 1.32639464e+01, 5.94566327e-01,
       8.04008909e-01, 7.78184221e-03]), 'targetState': array([25., 25., 15.])}
episode index:2626
target thresh 30.785548998012647
model initialize at round 2626
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.548819644173979
{'scaleFactor': 20, 'currentState': array([26.77186591, 21.22273517, 12.67985876,  0.62208658,  0.7741562 ,
        0.1170063 ]), 'targetState': array([25., 25., 15.])}
episode index:2627
target thresh 30.792470097052128
model initialize at round 2627
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.07656784, 14.87459149,  0.98916454,  0.07650323,
       -0.12530268]), 'targetState': array([25., 25., 15.])}
done in step count: 48
reward sum = 0.617290140942288
running average episode reward sum: 0.5488456983964936
{'scaleFactor': 20, 'currentState': array([21.2243765 , 26.38070523, 12.47189937,  0.8581269 , -0.43843773,
       -0.26719014]), 'targetState': array([25., 25., 15.])}
episode index:2628
target thresh 30.7993905040163
model initialize at round 2628
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12394929, 14.84627329,  0.98068106,  0.12278255,
       -0.15227967]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5489950458483781
{'scaleFactor': 20, 'currentState': array([26.67260026, 21.36863523, 13.64701515,  0.5112628 ,  0.85274857,
        0.10691221]), 'targetState': array([25., 25., 15.])}
episode index:2629
target thresh 30.806310218974385
model initialize at round 2629
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5491478956598046
{'scaleFactor': 20, 'currentState': array([25.30029719, 20.11890859, 14.20962178,  0.58934124,  0.75992198,
        0.27421795]), 'targetState': array([25., 25., 15.])}
episode index:2630
target thresh 30.813229241995575
model initialize at round 2630
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86629354,  0.97947368,  0.15209219,
       -0.1322848 ]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5493006292798122
{'scaleFactor': 20, 'currentState': array([25.33911086, 20.17201894, 14.52871664,  0.59573984,  0.79177588,
        0.13485174]), 'targetState': array([25., 25., 15.])}
episode index:2631
target thresh 30.820147573149047
model initialize at round 2631
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.549453246840838
{'scaleFactor': 20, 'currentState': array([25.20860518, 20.19012017, 13.34623281,  0.59070895,  0.7984729 ,
        0.11620655]), 'targetState': array([25., 25., 15.])}
episode index:2632
target thresh 30.827065212504003
model initialize at round 2632
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5496057484751179
{'scaleFactor': 20, 'currentState': array([25.434908  , 20.01645866, 14.25921344,  0.62191151,  0.75366973,
        0.21262176]), 'targetState': array([25., 25., 15.])}
episode index:2633
target thresh 30.8339821601296
model initialize at round 2633
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5497581343146869
{'scaleFactor': 20, 'currentState': array([25.24494216, 20.18816546, 13.58075029,  0.5915128 ,  0.79600752,
        0.1283925 ]), 'targetState': array([25., 25., 15.])}
episode index:2634
target thresh 30.84089841609503
model initialize at round 2634
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5499104044913796
{'scaleFactor': 20, 'currentState': array([25.37332323, 20.08618233, 14.00572751,  0.61626538,  0.76720775,
        0.17778989]), 'targetState': array([25., 25., 15.])}
episode index:2635
target thresh 30.84781398046944
model initialize at round 2635
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5500625591368306
{'scaleFactor': 20, 'currentState': array([25.1520624 , 20.16348021, 12.77766372,  0.58872391,  0.80505077,
       -0.07278332]), 'targetState': array([25., 25., 15.])}
episode index:2636
target thresh 30.854728853321976
model initialize at round 2636
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5502109920493312
{'scaleFactor': 20, 'currentState': array([26.82688522, 21.23983417, 14.14786493,  0.55810944,  0.79483138,
        0.23823712]), 'targetState': array([25., 25., 15.])}
episode index:2637
target thresh 30.86164303472182
model initialize at round 2637
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85447912,  0.97789608,  0.15184722,
       -0.14374172]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5503629173934748
{'scaleFactor': 20, 'currentState': array([25.21225629, 20.18322027, 13.19924211,  0.59417746,  0.80383457,
        0.02833945]), 'targetState': array([25., 25., 15.])}
episode index:2638
target thresh 30.86855652473809
model initialize at round 2638
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5505147275990474
{'scaleFactor': 20, 'currentState': array([24.99935962, 20.10994786, 12.14287791,  0.56583753,  0.79744177,
       -0.20955792]), 'targetState': array([25., 25., 15.])}
episode index:2639
target thresh 30.87546932343993
model initialize at round 2639
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12749651, 14.84627329,  0.98025219,  0.12624114,
       -0.15221307]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.550659254349164
{'scaleFactor': 20, 'currentState': array([2.89018645e+01, 2.12879999e+01, 1.20846264e+01, 6.35981407e-01,
       7.71564714e-01, 1.46813390e-02]), 'targetState': array([25., 25., 15.])}
episode index:2640
target thresh 30.882381430896444
model initialize at round 2640
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10686036, 14.84627329,  0.9825844 ,  0.10605992,
       -0.15257522]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5508072365131367
{'scaleFactor': 20, 'currentState': array([27.15076891, 20.68936809, 14.23823047,  0.62945512,  0.69955213,
        0.33825   ]), 'targetState': array([25., 25., 15.])}
episode index:2641
target thresh 30.889292847176787
model initialize at round 2641
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10159569, 14.90353965,  0.99013552,  0.1016096 ,
       -0.09647355]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5509551066542752
{'scaleFactor': 20, 'currentState': array([27.42191258, 20.20360576, 13.67529312,  0.66410728,  0.73253851,
        0.14949535]), 'targetState': array([25., 25., 15.])}
episode index:2642
target thresh 30.896203572350032
model initialize at round 2642
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.05342824, 14.84627329,  0.98675571,  0.05325316,
       -0.15322294]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.5507466484224726
{'scaleFactor': 20, 'currentState': array([-18.86902024,  41.12900851,  -2.33797281,  -0.71870756,
        -0.6159833 ,  -0.32252755]), 'targetState': array([25., 25., 15.])}
episode index:2643
target thresh 30.903113606485345
model initialize at round 2643
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11345915, 14.84627329,  0.98188155,  0.11252873,
       -0.15246608]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5508944296255659
{'scaleFactor': 20, 'currentState': array([27.26042278, 20.51129655, 13.58199098,  0.67367119,  0.72536286,
        0.14147734]), 'targetState': array([25., 25., 15.])}
episode index:2644
target thresh 30.910022949651783
model initialize at round 2644
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5510456945103577
{'scaleFactor': 20, 'currentState': array([25.20844493, 20.19069614, 13.3989446 ,  0.59044014,  0.7981277 ,
        0.1198858 ]), 'targetState': array([25., 25., 15.])}
episode index:2645
target thresh 30.916931601918442
model initialize at round 2645
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.5511896928676504
{'scaleFactor': 20, 'currentState': array([29.76083566, 20.49090226, 13.97956012,  0.82484886,  0.54492955,
        0.15058602]), 'targetState': array([25., 25., 15.])}
episode index:2646
target thresh 30.923839563354427
model initialize at round 2646
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.07578706, 14.84627329,  0.98534266,  0.07543053,
       -0.15300352]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.5509814610229705
{'scaleFactor': 20, 'currentState': array([ 9.42846388, 19.8308169 ,  6.81796925,  0.97192957, -0.22501853,
       -0.0686992 ]), 'targetState': array([25., 25., 15.])}
episode index:2647
target thresh 30.9307468340288
model initialize at round 2647
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.9076706 ,  0.98398818,  0.1527932 ,
       -0.09176872]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5511325216683168
{'scaleFactor': 20, 'currentState': array([25.31368832, 20.11611093, 15.49364289,  0.56025355,  0.75968326,
        0.33014739]), 'targetState': array([25., 25., 15.])}
episode index:2648
target thresh 30.937653414010637
model initialize at round 2648
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.9351609 ,  0.9860949 ,  0.15312033,
       -0.06458334]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5512834682625907
{'scaleFactor': 20, 'currentState': array([25.34313149, 20.14558975, 15.07101861,  0.57120208,  0.76753177,
        0.2909006 ]), 'targetState': array([25., 25., 15.])}
episode index:2649
target thresh 30.94455930336901
model initialize at round 2649
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5514343009349066
{'scaleFactor': 20, 'currentState': array([2.52789305e+01, 2.01865768e+01, 1.35782874e+01, 5.97657979e-01,
       8.01609240e-01, 1.50852822e-02]), 'targetState': array([25., 25., 15.])}
episode index:2650
target thresh 30.95146450217299
model initialize at round 2650
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14894555, 14.84627329,  0.97741534,  0.14705219,
       -0.15177257]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5515814325261802
{'scaleFactor': 20, 'currentState': array([27.31829191, 20.51640494, 14.60796412,  0.6068381 ,  0.71192057,
        0.35343547]), 'targetState': array([25., 25., 15.])}
episode index:2651
target thresh 30.958369010491605
model initialize at round 2651
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.9065335 ,  0.98388551,  0.15277725,
       -0.09288922]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5517320390938173
{'scaleFactor': 20, 'currentState': array([25.3107152 , 20.14914313, 14.74374283,  0.56797025,  0.76512284,
        0.30330981]), 'targetState': array([25., 25., 15.])}
episode index:2652
target thresh 30.965272828393896
model initialize at round 2652
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.92064119,  0.98507232,  0.15296154,
       -0.07896381]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5518825321246527
{'scaleFactor': 20, 'currentState': array([25.355671  , 20.17276111, 14.6083779 ,  0.59179411,  0.78886681,
        0.16573738]), 'targetState': array([25., 25., 15.])}
episode index:2653
target thresh 30.972175955948934
model initialize at round 2653
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5520293285139806
{'scaleFactor': 20, 'currentState': array([26.87574265, 20.80567636, 12.20458019,  0.57046132,  0.81889695,
       -0.06310045]), 'targetState': array([25., 25., 15.])}
episode index:2654
target thresh 30.979078393225723
model initialize at round 2654
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5521795962056514
{'scaleFactor': 20, 'currentState': array([25.27923995, 20.15063795, 14.3793333 ,  0.5804996 ,  0.76128042,
        0.28891579]), 'targetState': array([25., 25., 15.])}
episode index:2655
target thresh 30.98598014029329
model initialize at round 2655
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.51537267e+01, 1.50165493e+01, 9.88023076e-01,
       1.53419732e-01, 1.65162441e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5523297507439399
{'scaleFactor': 20, 'currentState': array([25.21161051, 20.05749387, 16.77990267,  0.5395439 ,  0.75037083,
        0.3818848 ]), 'targetState': array([25., 25., 15.])}
episode index:2656
target thresh 30.99288119722067
model initialize at round 2656
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.97523252,  0.98785605,  0.1533938 ,
       -0.02471384]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.552476213069366
{'scaleFactor': 20, 'currentState': array([2.70164547e+01, 2.13493261e+01, 1.50436501e+01, 6.25035694e-01,
       7.80503932e-01, 1.19997284e-02]), 'targetState': array([25., 25., 15.])}
episode index:2657
target thresh 30.999781564076855
model initialize at round 2657
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.0759421 , 14.84627329,  0.98533118,  0.07558395,
       -0.15300174]), 'targetState': array([25., 25., 15.])}
done in step count: 46
reward sum = 0.6298236312032323
running average episode reward sum: 0.5525053129256993
{'scaleFactor': 20, 'currentState': array([20.43111447, 28.69191885, 18.01726016,  0.82555339, -0.5575727 ,
        0.08703035]), 'targetState': array([25., 25., 15.])}
episode index:2658
target thresh 31.006681240930845
model initialize at round 2658
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.94363522,  0.98659772,  0.1531984 ,
       -0.05617108]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.55265517555713
{'scaleFactor': 20, 'currentState': array([25.3859007 , 20.1343414 , 15.03291915,  0.6028943 ,  0.75278751,
        0.26425258]), 'targetState': array([25., 25., 15.])}
episode index:2659
target thresh 31.013580227851666
model initialize at round 2659
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.1479876 , 14.84627329,  0.97755087,  0.14612667,
       -0.15179361]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5528049255098904
{'scaleFactor': 20, 'currentState': array([25.37329278, 20.00784957, 14.10318731,  0.61995398,  0.74137822,
        0.25693461]), 'targetState': array([25., 25., 15.])}
episode index:2660
target thresh 31.020478524908267
model initialize at round 2660
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09036683, 14.91599338,  0.99232313,  0.09057888,
       -0.08420375]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.5529474510350301
{'scaleFactor': 20, 'currentState': array([29.22721843, 20.62732128, 15.02677247,  0.57021082,  0.76495544,
        0.29950426]), 'targetState': array([25., 25., 15.])}
episode index:2661
target thresh 31.02737613216967
model initialize at round 2661
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15008641, 14.88433312,  0.98217149,  0.14889959,
       -0.11475223]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5530969786829883
{'scaleFactor': 20, 'currentState': array([25.36496006, 20.09251296, 14.02777589,  0.61483718,  0.76492185,
        0.19201515]), 'targetState': array([25., 25., 15.])}
episode index:2662
target thresh 31.03427304970483
model initialize at round 2662
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13630039, 14.86779367,  0.98209825,  0.1352125 ,
       -0.13115111]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5532428229078168
{'scaleFactor': 20, 'currentState': array([26.75274643, 21.28508069, 14.2882453 ,  0.51341784,  0.81636031,
        0.26449569]), 'targetState': array([25., 25., 15.])}
episode index:2663
target thresh 31.041169277582725
model initialize at round 2663
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5533921274224535
{'scaleFactor': 20, 'currentState': array([25.11917872, 20.01757543, 12.21780992,  0.60485412,  0.76767385,
       -0.21172709]), 'targetState': array([25., 25., 15.])}
episode index:2664
target thresh 31.048064815872312
model initialize at round 2664
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5535413198886739
{'scaleFactor': 20, 'currentState': array([25.23091217, 20.18836478, 13.4605905 ,  0.59330643,  0.79977957,
        0.09132431]), 'targetState': array([25., 25., 15.])}
episode index:2665
target thresh 31.054959664642535
model initialize at round 2665
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5536904004325641
{'scaleFactor': 20, 'currentState': array([25.28308844, 20.17719427, 14.10357993,  0.58089961,  0.78080402,
        0.23000158]), 'targetState': array([25., 25., 15.])}
episode index:2666
target thresh 31.06185382396236
model initialize at round 2666
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.92006849,  0.98502784,  0.15295463,
       -0.07953006]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5538358034130547
{'scaleFactor': 20, 'currentState': array([27.14919934, 20.95896187, 15.31467545,  0.58067091,  0.76777958,
        0.27080586]), 'targetState': array([25., 25., 15.])}
episode index:2667
target thresh 31.06874729390072
model initialize at round 2667
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5539846618262807
{'scaleFactor': 20, 'currentState': array([25.3215019 , 20.15302881, 14.796754  ,  0.57128187,  0.76822197,
        0.28891526]), 'targetState': array([25., 25., 15.])}
episode index:2668
target thresh 31.075640074526557
model initialize at round 2668
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.1206086 , 14.86571739,  0.98378331,  0.11985124,
       -0.13343939]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5541298455983207
{'scaleFactor': 20, 'currentState': array([27.13053813, 20.77948965, 14.29350803,  0.64008913,  0.73210954,
        0.23302688]), 'targetState': array([25., 25., 15.])}
episode index:2669
target thresh 31.082532165908795
model initialize at round 2669
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10400817, 14.84627329,  0.9828756 ,  0.10325969,
       -0.15262043]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.5542713944755898
{'scaleFactor': 20, 'currentState': array([28.94631364, 21.20708125, 14.50562791,  0.53553439,  0.7761162 ,
        0.33293627]), 'targetState': array([25., 25., 15.])}
episode index:2670
target thresh 31.08942356811635
model initialize at round 2670
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13430405, 14.9779025 ,  0.99068089,  0.13439642,
       -0.0221127 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5544163621861572
{'scaleFactor': 20, 'currentState': array([26.93143113, 20.99715251, 15.61211045,  0.53812075,  0.77918381,
        0.32140108]), 'targetState': array([25., 25., 15.])}
episode index:2671
target thresh 31.096314281218127
model initialize at round 2671
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5545647804824573
{'scaleFactor': 20, 'currentState': array([25.29568497, 20.15050302, 13.73271304,  0.60546247,  0.78567702,
        0.1269914 ]), 'targetState': array([25., 25., 15.])}
episode index:2672
target thresh 31.10320430528307
model initialize at round 2672
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5547130877287788
{'scaleFactor': 20, 'currentState': array([25.23015016, 20.188985  , 13.42505754,  0.59435238,  0.80146672,
        0.06630498]), 'targetState': array([25., 25., 15.])}
episode index:2673
target thresh 31.110093640380043
model initialize at round 2673
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5548612840497105
{'scaleFactor': 20, 'currentState': array([25.25669249, 20.17908615, 13.97081248,  0.58051015,  0.78216247,
        0.22634009]), 'targetState': array([25., 25., 15.])}
episode index:2674
target thresh 31.116982286577965
model initialize at round 2674
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85927341,  0.97855144,  0.15194898,
       -0.1390992 ]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5550093695696544
{'scaleFactor': 20, 'currentState': array([25.24999533, 20.18405135, 13.77109454,  0.58511251,  0.78782476,
        0.19229016]), 'targetState': array([25., 25., 15.])}
episode index:2675
target thresh 31.123870243945685
model initialize at round 2675
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.91899798,  0.98494385,  0.15294159,
       -0.08058832]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5551573444128272
{'scaleFactor': 20, 'currentState': array([25.34725539, 20.16158765, 14.7846398 ,  0.58518233,  0.78251987,
        0.21266003]), 'targetState': array([25., 25., 15.])}
episode index:2676
target thresh 31.130757512552123
model initialize at round 2676
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5553052087032594
{'scaleFactor': 20, 'currentState': array([25.26810195, 20.18535582, 13.81036103,  0.5892447 ,  0.79112036,
        0.16407091]), 'targetState': array([25., 25., 15.])}
episode index:2677
target thresh 31.137644092466132
model initialize at round 2677
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.1485354 , 14.84627329,  0.97747346,  0.14665597,
       -0.15178159]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.5554458958351502
{'scaleFactor': 20, 'currentState': array([29.19615459, 21.26875111, 14.9863297 ,  0.6725441 ,  0.68830837,
        0.271875  ]), 'targetState': array([25., 25., 15.])}
episode index:2678
target thresh 31.144529983756584
model initialize at round 2678
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09505241, 14.94778844,  0.99405356,  0.0954416 ,
       -0.05242534]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.555589992234391
{'scaleFactor': 20, 'currentState': array([27.02768999, 20.71879584, 15.78809438,  0.53494079,  0.79024245,
        0.29892343]), 'targetState': array([25., 25., 15.])}
episode index:2679
target thresh 31.151415186492336
model initialize at round 2679
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11330091, 14.9222479 ,  0.99050405,  0.11335859,
       -0.07779169]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.5557304681133733
{'scaleFactor': 20, 'currentState': array([29.62356294, 20.56050887, 15.19364555,  0.80936465,  0.55182708,
        0.20103663]), 'targetState': array([25., 25., 15.])}
episode index:2680
target thresh 31.15829970074224
model initialize at round 2680
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.05707898, 14.90704589,  0.99398468,  0.05730872,
       -0.09332824]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.5558708391987122
{'scaleFactor': 20, 'currentState': array([28.95892852, 21.19701719, 15.70720866,  0.64761844,  0.71390358,
        0.2663307 ]), 'targetState': array([25., 25., 15.])}
episode index:2681
target thresh 31.165183526575134
model initialize at round 2681
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.0604409 , 14.8735209 ,  0.99012374,  0.06044846,
       -0.12649491]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.5560111056076266
{'scaleFactor': 20, 'currentState': array([28.83744284, 21.17742958, 13.96944946,  0.53164162,  0.81579334,
        0.22768053]), 'targetState': array([25., 25., 15.])}
episode index:2682
target thresh 31.172066664059862
model initialize at round 2682
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09691459, 14.84627329,  0.98356671,  0.09628481,
       -0.15272775]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5561547765147431
{'scaleFactor': 20, 'currentState': array([26.97631199, 20.83220063, 13.98874702,  0.55464127,  0.7884115 ,
        0.26604579]), 'targetState': array([25., 25., 15.])}
episode index:2683
target thresh 31.178949113265265
model initialize at round 2683
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5563018835465557
{'scaleFactor': 20, 'currentState': array([25.23653728, 20.18108156, 13.86294228,  0.58027826,  0.78313876,
        0.22354154]), 'targetState': array([25., 25., 15.])}
episode index:2684
target thresh 31.185830874260155
model initialize at round 2684
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86091291,  0.97877081,  0.15198305,
       -0.13750948]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.556448881001436
{'scaleFactor': 20, 'currentState': array([25.36669771, 20.07144358, 14.96045636,  0.61523108,  0.72342626,
        0.31328129]), 'targetState': array([25., 25., 15.])}
episode index:2685
target thresh 31.19271194711336
model initialize at round 2685
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.03451529, 14.92090695,  0.9962224 ,  0.03473223,
       -0.07959017]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.5562417146272731
{'scaleFactor': 20, 'currentState': array([ 9.14509802, 20.52716465, 10.25861143,  0.77643152, -0.61222048,
       -0.14946632]), 'targetState': array([25., 25., 15.])}
episode index:2686
target thresh 31.199592331893676
model initialize at round 2686
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11672413, 14.92160332,  0.99006408,  0.11673168,
       -0.07840175]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5563850858348555
{'scaleFactor': 20, 'currentState': array([27.54329273, 20.25779839, 14.2023284 ,  0.67763088,  0.72367841,
        0.13078975]), 'targetState': array([25., 25., 15.])}
episode index:2687
target thresh 31.206472028669907
model initialize at round 2687
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.556531888276844
{'scaleFactor': 20, 'currentState': array([25.28171822, 20.17544576, 14.18390958,  0.5870678 ,  0.78803985,
        0.18532295]), 'targetState': array([25., 25., 15.])}
episode index:2688
target thresh 31.21335103751086
model initialize at round 2688
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14871835, 14.84627329,  0.97744755,  0.14683272,
       -0.15177757]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5566785815314453
{'scaleFactor': 20, 'currentState': array([ 2.52079481e+01,  2.01368721e+01,  1.30644793e+01,  5.96832726e-01,
        8.02361147e-01, -2.69950647e-03]), 'targetState': array([25., 25., 15.])}
episode index:2689
target thresh 31.22022935848533
model initialize at round 2689
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.55682516572043
{'scaleFactor': 20, 'currentState': array([2.51622303e+01, 2.01613518e+01, 1.28798610e+01, 6.04308258e-01,
       7.96745488e-01, 2.85607053e-03]), 'targetState': array([25., 25., 15.])}
episode index:2690
target thresh 31.22710699166209
model initialize at round 2690
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.91678524,  0.98476677,  0.1529141 ,
       -0.08277488]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.5569646083745312
{'scaleFactor': 20, 'currentState': array([29.67057667, 20.71155072, 15.62432598,  0.82693721,  0.53654255,
        0.16821695]), 'targetState': array([25., 25., 15.])}
episode index:2691
target thresh 31.233983937109933
model initialize at round 2691
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.49883896e+01,  1.49284643e+01,  9.97331322e-01,
       -1.16963977e-02, -7.20654510e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 42
reward sum = 0.6556592205741436
running average episode reward sum: 0.5570012705633126
{'scaleFactor': 20, 'currentState': array([20.01671564, 21.22030117, 18.11284122,  0.51882988, -0.82183595,
       -0.23537464]), 'targetState': array([25., 25., 15.])}
episode index:2692
target thresh 31.24086019489759
model initialize at round 2692
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.91392609,  0.98453105,  0.15287749,
       -0.08559842]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5571475716325055
{'scaleFactor': 20, 'currentState': array([25.34494876, 20.18150128, 14.20410569,  0.59684505,  0.79568555,
        0.10324967]), 'targetState': array([25., 25., 15.])}
episode index:2693
target thresh 31.247735765093864
model initialize at round 2693
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5572937640891749
{'scaleFactor': 20, 'currentState': array([25.27626835, 20.18811417, 13.6203667 ,  0.59621003,  0.80025519,
        0.06422799]), 'targetState': array([25., 25., 15.])}
episode index:2694
target thresh 31.25461064776749
model initialize at round 2694
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5574398480542253
{'scaleFactor': 20, 'currentState': array([25.25715158, 20.18121335, 13.94550333,  0.58606014,  0.78867876,
        0.18579377]), 'targetState': array([25., 25., 15.])}
episode index:2695
target thresh 31.26148484298722
model initialize at round 2695
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5575822962372174
{'scaleFactor': 20, 'currentState': array([27.50699993, 20.12180091, 13.50490346,  0.65696456,  0.7262358 ,
        0.20243301]), 'targetState': array([25., 25., 15.])}
episode index:2696
target thresh 31.268358350821813
model initialize at round 2696
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87385726,  0.98041723,  0.1522387 ,
       -0.12492173]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5577246387856652
{'scaleFactor': 20, 'currentState': array([ 2.77596906e+01,  2.00538627e+01,  1.34751922e+01,  8.14860177e-01,
        5.79635243e-01, -5.08691966e-03]), 'targetState': array([25., 25., 15.])}
episode index:2697
target thresh 31.27523117133998
model initialize at round 2697
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5578704006133577
{'scaleFactor': 20, 'currentState': array([25.00946247, 20.11404988, 12.17783578,  0.5666272 ,  0.79710256,
       -0.20871303]), 'targetState': array([25., 25., 15.])}
episode index:2698
target thresh 31.28210330461045
model initialize at round 2698
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5580125309389552
{'scaleFactor': 20, 'currentState': array([26.55781653, 21.55491792, 13.38074021,  0.50207808,  0.85486482,
        0.13085774]), 'targetState': array([25., 25., 15.])}
episode index:2699
target thresh 31.28897475070196
model initialize at round 2699
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5581580781682
{'scaleFactor': 20, 'currentState': array([25.34473339, 20.09143724, 14.52400589,  0.58669615,  0.76566341,
        0.26371798]), 'targetState': array([25., 25., 15.])}
episode index:2700
target thresh 31.295845509683218
model initialize at round 2700
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.93504018,  0.98608724,  0.15311914,
       -0.06470308]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5582999967432584
{'scaleFactor': 20, 'currentState': array([26.69486299, 21.41039652, 15.54784155,  0.48108148,  0.79688527,
        0.3654237 ]), 'targetState': array([25., 25., 15.])}
episode index:2701
target thresh 31.30271558162292
model initialize at round 2701
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12959419, 14.95397832,  0.9904891 ,  0.12965821,
       -0.04604441]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.5584383258887667
{'scaleFactor': 20, 'currentState': array([29.28269075, 21.13108186, 16.37410793,  0.7028827 ,  0.67182847,
        0.23367162]), 'targetState': array([25., 25., 15.])}
episode index:2702
target thresh 31.30958496658979
model initialize at round 2702
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14498105, 14.95748902,  0.98855446,  0.14476935,
       -0.0424489 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5585800357753787
{'scaleFactor': 20, 'currentState': array([26.47905616, 21.5900356 , 16.67002299,  0.47054831,  0.84146725,
        0.26555065]), 'targetState': array([25., 25., 15.])}
episode index:2703
target thresh 31.3164536646525
model initialize at round 2703
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.9369267 ,  0.98620541,  0.15313749,
       -0.06283155]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5587251578220225
{'scaleFactor': 20, 'currentState': array([25.36276428, 20.16951129, 14.71308316,  0.59115554,  0.78805567,
        0.17176548]), 'targetState': array([25., 25., 15.])}
episode index:2704
target thresh 31.323321675879747
model initialize at round 2704
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.558870172569556
{'scaleFactor': 20, 'currentState': array([2.52120287e+01, 2.01502160e+01, 1.30377435e+01, 6.04651064e-01,
       7.96139681e-01, 2.36368042e-02]), 'targetState': array([25., 25., 15.])}
episode index:2705
target thresh 31.330189000340212
model initialize at round 2705
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87281102,  0.98028983,  0.15221892,
       -0.12594148]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.559015080136936
{'scaleFactor': 20, 'currentState': array([25.29075017, 20.13289652, 14.92421308,  0.55883402,  0.75687793,
        0.33888101]), 'targetState': array([25., 25., 15.])}
episode index:2706
target thresh 31.337055638102573
model initialize at round 2706
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.94796461,  0.98682772,  0.15323412,
       -0.05186865]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5591598806429438
{'scaleFactor': 20, 'currentState': array([25.35678645, 20.14320783, 15.49482272,  0.57722666,  0.77463725,
        0.25835347]), 'targetState': array([25., 25., 15.])}
episode index:2707
target thresh 31.343921589235492
model initialize at round 2707
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10629847, 14.89314247,  0.98860808,  0.10614902,
       -0.1067073 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5593010624260892
{'scaleFactor': 20, 'currentState': array([27.22086841, 20.52893369, 14.13837838,  0.57546722,  0.77906963,
        0.24877299]), 'targetState': array([25., 25., 15.])}
episode index:2708
target thresh 31.350786853807612
model initialize at round 2708
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.880755  ,  0.98123199,  0.15236522,
       -0.1181889 ]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5594456504613324
{'scaleFactor': 20, 'currentState': array([25.33054479, 20.16247939, 14.64362049,  0.57763686,  0.77455152,
        0.25769282]), 'targetState': array([25., 25., 15.])}
episode index:2709
target thresh 31.35765143188761
model initialize at round 2709
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5595901317895385
{'scaleFactor': 20, 'currentState': array([25.23232343, 20.18924085, 13.53358467,  0.59137254,  0.79719157,
        0.12150771]), 'targetState': array([25., 25., 15.])}
episode index:2710
target thresh 31.36451532354412
model initialize at round 2710
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.88834956,  0.98207823,  0.15249662,
       -0.11075704]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5597345065287899
{'scaleFactor': 20, 'currentState': array([25.28067124, 20.1707929 , 14.18995952,  0.57824964,  0.77784985,
        0.24612388]), 'targetState': array([25., 25., 15.])}
episode index:2711
target thresh 31.371378528845774
model initialize at round 2711
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.92225392,  0.9851959 ,  0.15298073,
       -0.07736881]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5598787747969945
{'scaleFactor': 20, 'currentState': array([25.3271541 , 20.12620588, 15.50521293,  0.57056383,  0.7700958 ,
        0.28532328]), 'targetState': array([25., 25., 15.])}
episode index:2712
target thresh 31.378241047861223
model initialize at round 2712
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14596885, 14.92475993,  0.98651979,  0.14545571,
       -0.07497558]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5600194314039256
{'scaleFactor': 20, 'currentState': array([26.69926294, 21.47208864, 14.89411059,  0.52132049,  0.82033061,
        0.2351226 ]), 'targetState': array([25., 25., 15.])}
episode index:2713
target thresh 31.385102880659076
model initialize at round 2713
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13563431, 14.84627329,  0.97922486,  0.13415806,
       -0.15205355]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5601599843582356
{'scaleFactor': 20, 'currentState': array([26.42525774, 21.65602108, 13.01645986,  0.50467211,  0.86231106,
        0.04154152]), 'targetState': array([25., 25., 15.])}
episode index:2714
target thresh 31.39196402730796
model initialize at round 2714
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5603039365002399
{'scaleFactor': 20, 'currentState': array([25.18392866, 20.18627035, 13.09671288,  0.59245833,  0.80362813,
        0.05634673]), 'targetState': array([25., 25., 15.])}
episode index:2715
target thresh 31.398824487876485
model initialize at round 2715
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.8957618 ,  0.98285239,  0.15261683,
       -0.10348562]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5604477826391941
{'scaleFactor': 20, 'currentState': array([25.29427318, 20.10582298, 15.49864323,  0.55235253,  0.75235257,
        0.35898786]), 'targetState': array([25., 25., 15.])}
episode index:2716
target thresh 31.405684262433255
model initialize at round 2716
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.92637394,  0.98550028,  0.15302799,
       -0.07329142]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5605915228921425
{'scaleFactor': 20, 'currentState': array([25.31710092, 20.12457537, 15.26416167,  0.55663181,  0.75372797,
        0.34936396]), 'targetState': array([25., 25., 15.])}
episode index:2717
target thresh 31.412543351046864
model initialize at round 2717
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.90422162,  0.983673  ,  0.15274425,
       -0.09516627]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.560735157375957
{'scaleFactor': 20, 'currentState': array([25.31387881, 20.13193328, 15.0653185 ,  0.56037205,  0.75713778,
        0.33574625]), 'targetState': array([25., 25., 15.])}
episode index:2718
target thresh 31.419401753785902
model initialize at round 2718
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.51537267e+01,  1.49841376e+01,  9.88034031e-01,
        1.53421433e-01, -1.58309183e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5608786862073377
{'scaleFactor': 20, 'currentState': array([25.38539421, 20.17103128, 14.84551852,  0.59122116,  0.7859901 ,
        0.18076809]), 'targetState': array([25., 25., 15.])}
episode index:2719
target thresh 31.426259470718964
model initialize at round 2719
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86397381,  0.97917387,  0.15204563,
       -0.13453868]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.561022109502813
{'scaleFactor': 20, 'currentState': array([25.27987379, 20.16029832, 14.41380714,  0.57096087,  0.7699848 ,
        0.28482818]), 'targetState': array([25., 25., 15.])}
episode index:2720
target thresh 31.433116501914615
model initialize at round 2720
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.97740263,  0.9879066 ,  0.15340165,
       -0.02254959]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5611654273787399
{'scaleFactor': 20, 'currentState': array([25.29713967, 20.09313681, 15.92902684,  0.55313265,  0.75473066,
        0.35274057]), 'targetState': array([25., 25., 15.])}
episode index:2721
target thresh 31.43997284744143
model initialize at round 2721
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.0218004 ,  0.987924  ,  0.15340435,
        0.02175468]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5613086399513046
{'scaleFactor': 20, 'currentState': array([25.2794582 , 20.09479874, 16.41967831,  0.56119475,  0.76690213,
        0.31132231]), 'targetState': array([25., 25., 15.])}
episode index:2722
target thresh 31.446828507367986
model initialize at round 2722
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89977905,  0.98325047,  0.15267864,
       -0.09953767]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5614482549015248
{'scaleFactor': 20, 'currentState': array([27.42143899, 20.62056851, 15.50388121,  0.70907463,  0.65977221,
        0.24882486]), 'targetState': array([25., 25., 15.])}
episode index:2723
target thresh 31.453683481762805
model initialize at round 2723
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13450187, 14.91318401,  0.98717688,  0.13411832,
       -0.08656842]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5615877673444395
{'scaleFactor': 20, 'currentState': array([26.71032322, 21.18338944, 15.85497399,  0.51551111,  0.79437489,
        0.32127377]), 'targetState': array([25., 25., 15.])}
episode index:2724
target thresh 31.460537770694476
model initialize at round 2724
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09727789, 14.84648692,  0.98356432,  0.09664552,
       -0.15251514]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5617271773929006
{'scaleFactor': 20, 'currentState': array([27.04816302, 20.69347692, 13.38764401,  0.5755152 ,  0.80011864,
        0.16909292]), 'targetState': array([25., 25., 15.])}
episode index:2725
target thresh 31.467391374231525
model initialize at round 2725
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.90820425,  0.98403594,  0.15280061,
       -0.09124274]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5618699737511204
{'scaleFactor': 20, 'currentState': array([25.41412857, 20.08313763, 14.90541719,  0.63123963,  0.74288117,
        0.22285444]), 'targetState': array([25., 25., 15.])}
episode index:2726
target thresh 31.474244292442478
model initialize at round 2726
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09917205, 14.86798397,  0.98637516,  0.09880894,
       -0.13153266]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5620091780692905
{'scaleFactor': 20, 'currentState': array([27.49352687, 20.18814146, 14.04256755,  0.66317531,  0.72965044,
        0.16675955]), 'targetState': array([25., 25., 15.])}
episode index:2727
target thresh 31.48109652539587
model initialize at round 2727
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5621517663654161
{'scaleFactor': 20, 'currentState': array([25.28364201, 20.18843287, 13.71002039,  0.59372042,  0.79610568,
        0.11709739]), 'targetState': array([25., 25., 15.])}
episode index:2728
target thresh 31.487948073160233
model initialize at round 2728
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11974754, 14.89506158,  0.98731247,  0.11942247,
       -0.10465354]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5622907654064698
{'scaleFactor': 20, 'currentState': array([27.30741591, 20.62108103, 15.14226347,  0.66159646,  0.68218577,
        0.31130804]), 'targetState': array([25., 25., 15.])}
episode index:2729
target thresh 31.49479893580408
model initialize at round 2729
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.88402473,  0.98160289,  0.15242281,
       -0.11499158]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.5624262139714883
{'scaleFactor': 20, 'currentState': array([29.48876723, 20.66003405, 15.15650785,  0.70515553,  0.62430187,
        0.33615897]), 'targetState': array([25., 25., 15.])}
episode index:2730
target thresh 31.501649113395914
model initialize at round 2730
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.50693107e+01,  1.49953654e+01,  9.97547340e-01,
        6.98390701e-02, -4.66995383e-03]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.5625615633431233
{'scaleFactor': 20, 'currentState': array([29.16745388, 21.03969839, 16.08206404,  0.6334138 ,  0.7389772 ,
        0.22956405]), 'targetState': array([25., 25., 15.])}
episode index:2731
target thresh 31.508498606004242
model initialize at round 2731
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5627037406808089
{'scaleFactor': 20, 'currentState': array([25.21155361, 20.18264651, 13.16318313,  0.59372589,  0.80381831,
       -0.03695542]), 'targetState': array([25., 25., 15.])}
episode index:2732
target thresh 31.515347413697537
model initialize at round 2732
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5628458139736077
{'scaleFactor': 20, 'currentState': array([25.28023087, 20.15029088, 13.51581891,  0.61419398,  0.78506231,
        0.08026784]), 'targetState': array([25., 25., 15.])}
episode index:2733
target thresh 31.522195536544316
model initialize at round 2733
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14752845, 14.84627329,  0.97761553,  0.14568293,
       -0.15180365]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5629877833356876
{'scaleFactor': 20, 'currentState': array([25.12824234, 20.10653999, 12.61842526,  0.58955903,  0.8022723 ,
       -0.09369799]), 'targetState': array([25., 25., 15.])}
episode index:2734
target thresh 31.529042974613063
model initialize at round 2734
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5631296488810492
{'scaleFactor': 20, 'currentState': array([25.30458095, 20.14442521, 14.21480443,  0.59966309,  0.77623557,
        0.19458294]), 'targetState': array([25., 25., 15.])}
episode index:2735
target thresh 31.535889727972233
model initialize at round 2735
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14447354, 14.84627329,  0.97804101,  0.14272833,
       -0.15186972]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5632679348827013
{'scaleFactor': 20, 'currentState': array([26.67714679, 21.32479167, 14.60565474,  0.50688317,  0.80812869,
        0.2999958 ]), 'targetState': array([25., 25., 15.])}
episode index:2736
target thresh 31.54273579669028
model initialize at round 2736
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5634061198350281
{'scaleFactor': 20, 'currentState': array([27.26335669, 20.75888719, 14.46985804,  0.75258945,  0.59028302,
        0.29184771]), 'targetState': array([25., 25., 15.])}
episode index:2737
target thresh 31.549581180835705
model initialize at round 2737
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.03719897, 14.85343741,  0.9885359 ,  0.03714396,
       -0.14634584]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.5632003469643798
{'scaleFactor': 20, 'currentState': array([15.43020673, 17.12983853,  9.25424527,  0.99459707,  0.09256087,
       -0.0470016 ]), 'targetState': array([25., 25., 15.])}
episode index:2738
target thresh 31.556425880476937
model initialize at round 2738
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13726346, 14.91045917,  0.98657326,  0.13678834,
       -0.0892309 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5633384556910819
{'scaleFactor': 20, 'currentState': array([26.53598012, 21.49800124, 15.75678311,  0.468379  ,  0.83295298,
        0.29463614]), 'targetState': array([25., 25., 15.])}
episode index:2739
target thresh 31.56326989568243
model initialize at round 2739
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5634799343750997
{'scaleFactor': 20, 'currentState': array([25.37576212, 20.05571523, 13.83655605,  0.61165261,  0.77902157,
        0.13786395]), 'targetState': array([25., 25., 15.])}
episode index:2740
target thresh 31.57011322652061
model initialize at round 2740
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5636213098276809
{'scaleFactor': 20, 'currentState': array([25.24556386, 20.18612995, 13.76322426,  0.58539053,  0.78837302,
        0.18917162]), 'targetState': array([25., 25., 15.])}
episode index:2741
target thresh 31.57695587305993
model initialize at round 2741
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85453675,  0.97790408,  0.15184846,
       -0.14368597]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5637625821617699
{'scaleFactor': 20, 'currentState': array([25.2349538 , 20.18760723, 13.38509566,  0.594198  ,  0.80100626,
        0.0729226 ]), 'targetState': array([25., 25., 15.])}
episode index:2742
target thresh 31.58379783536881
model initialize at round 2742
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10023505, 14.85679777,  0.98476807,  0.09970533,
       -0.14244544]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5639002845194948
{'scaleFactor': 20, 'currentState': array([26.63173791, 21.2266944 , 14.7720637 ,  0.48466969,  0.79702735,
        0.36033692]), 'targetState': array([25., 25., 15.])}
episode index:2743
target thresh 31.59063911351566
model initialize at round 2743
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15345293, 14.85086767,  0.97742888,  0.15150437,
       -0.14723863]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5640413522182486
{'scaleFactor': 20, 'currentState': array([25.31522866, 20.18408099, 13.97319191,  0.59815449,  0.79884082,
        0.06375388]), 'targetState': array([25., 25., 15.])}
episode index:2744
target thresh 31.59747970756891
model initialize at round 2744
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5641823171354368
{'scaleFactor': 20, 'currentState': array([25.26277265, 20.17422138, 14.09778489,  0.57725853,  0.77812648,
        0.24757175]), 'targetState': array([25., 25., 15.])}
episode index:2745
target thresh 31.604319617596953
model initialize at round 2745
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86906369,  0.9798253 ,  0.15214679,
       -0.12959062]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5643231793833481
{'scaleFactor': 20, 'currentState': array([25.29259317, 20.17470405, 14.18497169,  0.58062591,  0.77997028,
        0.23349501]), 'targetState': array([25., 25., 15.])}
episode index:2746
target thresh 31.611158843668186
model initialize at round 2746
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87017771,  0.97996474,  0.15216844,
       -0.12850633]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5644639390741076
{'scaleFactor': 20, 'currentState': array([25.38162186, 20.03882977, 14.51302695,  0.60018315,  0.74231125,
        0.29791642]), 'targetState': array([25., 25., 15.])}
episode index:2747
target thresh 31.617997385851005
model initialize at round 2747
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.1397741 , 14.84627329,  0.97867918,  0.13817576,
       -0.15196882]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.564601135657196
{'scaleFactor': 20, 'currentState': array([26.65267451, 21.3640766 , 12.91401399,  0.58767589,  0.80700335,
        0.05816055]), 'targetState': array([25., 25., 15.])}
episode index:2748
target thresh 31.624835244213813
model initialize at round 2748
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09576642, 14.84627329,  0.98367411,  0.09515449,
       -0.15274443]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5647382324246547
{'scaleFactor': 20, 'currentState': array([27.09720806, 20.61784311, 15.20904329,  0.56230075,  0.76816618,
        0.30616759]), 'targetState': array([25., 25., 15.])}
episode index:2749
target thresh 31.631672418824962
model initialize at round 2749
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5648786876310093
{'scaleFactor': 20, 'currentState': array([2.51930937e+01, 2.01846440e+01, 1.31342546e+01, 5.93433321e-01,
       8.04705192e-01, 1.69247523e-02]), 'targetState': array([25., 25., 15.])}
episode index:2750
target thresh 31.638508909752836
model initialize at round 2750
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5650190407252547
{'scaleFactor': 20, 'currentState': array([25.38664668, 20.03173448, 14.18396477,  0.60515164,  0.77850911,
        0.16647839]), 'targetState': array([25., 25., 15.])}
episode index:2751
target thresh 31.645344717065793
model initialize at round 2751
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5651592918187048
{'scaleFactor': 20, 'currentState': array([25.25704013, 20.18749619, 13.78100892,  0.59016851,  0.79326879,
        0.14975231]), 'targetState': array([25., 25., 15.])}
episode index:2752
target thresh 31.652179840832208
model initialize at round 2752
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09914118, 14.84627329,  0.98335488,  0.09847572,
       -0.15269486]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5652959866452877
{'scaleFactor': 20, 'currentState': array([27.43574887, 20.12543445, 13.99245311,  0.62263398,  0.72884867,
        0.28479212]), 'targetState': array([25., 25., 15.])}
episode index:2753
target thresh 31.659014281120413
model initialize at round 2753
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.8912213 ,  0.98238426,  0.15254414,
       -0.10794191]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.5654291636101613
{'scaleFactor': 20, 'currentState': array([29.52855232, 21.00140251, 15.00639964,  0.80496336,  0.58015422,
        0.12431843]), 'targetState': array([25., 25., 15.])}
episode index:2754
target thresh 31.665848037998757
model initialize at round 2754
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10390012, 14.84627329,  0.98288648,  0.10315356,
       -0.15262212]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.5655622438948426
{'scaleFactor': 20, 'currentState': array([29.43368666, 20.52035112, 13.78982862,  0.67758713,  0.69357781,
        0.24459254]), 'targetState': array([25., 25., 15.])}
episode index:2755
target thresh 31.672681111535596
model initialize at round 2755
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5657020943324351
{'scaleFactor': 20, 'currentState': array([25.27690428, 20.11132709, 15.23043674,  0.55401886,  0.7544165 ,
        0.3520211 ]), 'targetState': array([25., 25., 15.])}
episode index:2756
target thresh 31.67951350179924
model initialize at round 2756
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.90730263,  0.98395509,  0.15278806,
       -0.09213136]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5658418433188578
{'scaleFactor': 20, 'currentState': array([25.31555978, 20.12211829, 15.39184021,  0.56664812,  0.76643082,
        0.30247926]), 'targetState': array([25., 25., 15.])}
episode index:2757
target thresh 31.686345208858015
model initialize at round 2757
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.90064339,  0.98333413,  0.15269164,
       -0.09868762]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5659814909644637
{'scaleFactor': 20, 'currentState': array([25.39111701, 20.08775766, 13.91715485,  0.61645033,  0.78117498,
        0.09876562]), 'targetState': array([25., 25., 15.])}
episode index:2758
target thresh 31.693176232780228
model initialize at round 2758
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5661175905144589
{'scaleFactor': 20, 'currentState': array([26.86429334, 21.1341392 , 13.04911236,  0.64948281,  0.7501311 ,
        0.12440022]), 'targetState': array([25., 25., 15.])}
episode index:2759
target thresh 31.70000657363422
model initialize at round 2759
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5662535914415917
{'scaleFactor': 20, 'currentState': array([26.36357289, 21.06088943, 10.82595616,  0.57465901,  0.75692935,
       -0.31116713]), 'targetState': array([25., 25., 15.])}
episode index:2760
target thresh 31.70683623148828
model initialize at round 2760
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13625239, 14.84627329,  0.97914437,  0.13475835,
       -0.15204105]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5663894938530222
{'scaleFactor': 20, 'currentState': array([27.09155601, 20.89874416, 13.19108894,  0.71995142,  0.67632879,
        0.15572193]), 'targetState': array([25., 25., 15.])}
episode index:2761
target thresh 31.71366520641068
model initialize at round 2761
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.05506857, 14.84627329,  0.98666849,  0.05488326,
       -0.15320939]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.5661844288661094
{'scaleFactor': 20, 'currentState': array([19.72587283, 20.9983196 , 11.97540915,  0.9927301 , -0.11541586,
       -0.03414865]), 'targetState': array([25., 25., 15.])}
episode index:2762
target thresh 31.72049349846975
model initialize at round 2762
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.90663093,  0.98389436,  0.15277863,
       -0.09279323]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.566323699811109
{'scaleFactor': 20, 'currentState': array([25.35607379, 20.16954566, 14.65067758,  0.587353  ,  0.78393714,
        0.20114429]), 'targetState': array([25., 25., 15.])}
episode index:2763
target thresh 31.72732110773375
model initialize at round 2763
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85058517,  0.97734865,  0.15176221,
       -0.14750544]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5664594293514816
{'scaleFactor': 20, 'currentState': array([27.23281151, 20.89129087, 14.43658995,  0.66742808,  0.72011571,
        0.18966582]), 'targetState': array([25., 25., 15.])}
episode index:2764
target thresh 31.73414803427096
model initialize at round 2764
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10748741, 14.84627329,  0.98251936,  0.10667521,
       -0.15256512]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5665950607149716
{'scaleFactor': 20, 'currentState': array([26.91087751, 20.92965847, 14.35207904,  0.53874926,  0.80941005,
        0.2336763 ]), 'targetState': array([25., 25., 15.])}
episode index:2765
target thresh 31.740974278149647
model initialize at round 2765
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.03263233, 14.84627329,  0.98763411,  0.03255435,
       -0.15335933]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.5663902179598324
{'scaleFactor': 20, 'currentState': array([21.44475466, 19.6306968 , 10.09700914,  0.95975902,  0.27855232,
       -0.03565432]), 'targetState': array([25., 25., 15.])}
episode index:2766
target thresh 31.747799839438084
model initialize at round 2766
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.566529213200866
{'scaleFactor': 20, 'currentState': array([25.2357897 , 20.18343404, 13.79625066,  0.58249382,  0.785842  ,
        0.20773373]), 'targetState': array([25., 25., 15.])}
episode index:2767
target thresh 31.754624718204518
model initialize at round 2767
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5666681080118122
{'scaleFactor': 20, 'currentState': array([25.28051844, 20.15517728, 14.46705616,  0.57254866,  0.7672198 ,
        0.28907058]), 'targetState': array([25., 25., 15.])}
episode index:2768
target thresh 31.76144891451719
model initialize at round 2768
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10527268, 14.85211403,  0.98360154,  0.10459229,
       -0.14693016]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5668034680845422
{'scaleFactor': 20, 'currentState': array([27.4816716 , 20.32854024, 14.13165695,  0.72416233,  0.66838033,
        0.16987248]), 'targetState': array([25., 25., 15.])}
episode index:2769
target thresh 31.768272428444355
model initialize at round 2769
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11963883, 14.84627329,  0.98118665,  0.11857376,
       -0.15235818]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5669387304243676
{'scaleFactor': 20, 'currentState': array([26.76059202, 21.19660421, 12.90937066,  0.56197945,  0.82383447,
        0.07399907]), 'targetState': array([25., 25., 15.])}
episode index:2770
target thresh 31.775095260054254
model initialize at round 2770
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10762644, 14.86771182,  0.98548518,  0.10713562,
       -0.13168489]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5670738951370983
{'scaleFactor': 20, 'currentState': array([26.98584191, 20.81919399, 14.86503035,  0.54762972,  0.80222834,
        0.23776329]), 'targetState': array([25., 25., 15.])}
episode index:2771
target thresh 31.781917409415094
model initialize at round 2771
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12490853, 14.84627329,  0.98056623,  0.12371827,
       -0.15226184]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5672089623283911
{'scaleFactor': 20, 'currentState': array([27.36946484, 20.35195816, 13.62553294,  0.64706261,  0.74175569,
        0.17637595]), 'targetState': array([25., 25., 15.])}
episode index:2772
target thresh 31.78873887659511
model initialize at round 2772
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5673473615666066
{'scaleFactor': 20, 'currentState': array([25.27988688, 20.16062187, 14.4305788 ,  0.57695281,  0.77698765,
        0.25182462]), 'targetState': array([25., 25., 15.])}
episode index:2773
target thresh 31.79555966166251
model initialize at round 2773
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85045128,  0.97732958,  0.15175925,
       -0.14763473]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5674856610216654
{'scaleFactor': 20, 'currentState': array([25.30214903, 20.14644395, 14.76981029,  0.56515908,  0.76288516,
        0.31400868]), 'targetState': array([25., 25., 15.])}
episode index:2774
target thresh 31.802379764685497
model initialize at round 2774
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.51537267e+01,  1.49984186e+01,  9.88156633e-01,
        1.53440471e-01, -1.57841267e-03]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5676238608014413
{'scaleFactor': 20, 'currentState': array([25.35433529, 20.13396275, 15.68237246,  0.5685082 ,  0.76524567,
        0.30198921]), 'targetState': array([25., 25., 15.])}
episode index:2775
target thresh 31.809199185732307
model initialize at round 2775
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15267896, 14.9774215 ,  0.98806496,  0.15238053,
       -0.02253437]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5677619610136526
{'scaleFactor': 20, 'currentState': array([25.27225525, 20.01667673, 16.33280798,  0.52790547,  0.72361282,
        0.44463502]), 'targetState': array([25., 25., 15.])}
episode index:2776
target thresh 31.816017924871087
model initialize at round 2776
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.97618933,  0.98787891,  0.15339735,
       -0.02375965]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5678999617658623
{'scaleFactor': 20, 'currentState': array([25.36578552, 20.1038622 , 15.74805801,  0.58582189,  0.7531484 ,
        0.29929951]), 'targetState': array([25., 25., 15.])}
episode index:2777
target thresh 31.822835982170062
model initialize at round 2777
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.97097824,  0.98774353,  0.15337632,
       -0.02895561]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5680378631654787
{'scaleFactor': 20, 'currentState': array([25.35366556, 20.14447805, 15.15284819,  0.56916233,  0.76395077,
        0.30402871]), 'targetState': array([25., 25., 15.])}
episode index:2778
target thresh 31.829653357697385
model initialize at round 2778
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.92271915,  0.98523109,  0.15298619,
       -0.07690858]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5681756653197552
{'scaleFactor': 20, 'currentState': array([25.34078298, 20.16617708, 14.60304247,  0.5824926 ,  0.77932643,
        0.230982  ]), 'targetState': array([25., 25., 15.])}
episode index:2779
target thresh 31.83647005152124
model initialize at round 2779
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5683133683357912
{'scaleFactor': 20, 'currentState': array([25.01129685, 20.08298844, 12.10513174,  0.57689964,  0.7784127 ,
       -0.24750854]), 'targetState': array([25., 25., 15.])}
episode index:2780
target thresh 31.843286063709797
model initialize at round 2780
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10674773, 14.84627329,  0.98259604,  0.10594939,
       -0.15257702]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5684475527230854
{'scaleFactor': 20, 'currentState': array([27.52314803, 20.1627039 , 13.2029168 ,  0.7415412 ,  0.66461657,
        0.09165951]), 'targetState': array([25., 25., 15.])}
episode index:2781
target thresh 31.85010139433122
model initialize at round 2781
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5685850590125091
{'scaleFactor': 20, 'currentState': array([25.18946876, 20.18936003, 13.36695524,  0.58708342,  0.79551938,
        0.14993989]), 'targetState': array([25., 25., 15.])}
episode index:2782
target thresh 31.856916043453644
model initialize at round 2782
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.95446007,  0.98713859,  0.15328239,
       -0.04540831]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5687224664831837
{'scaleFactor': 20, 'currentState': array([25.38601486, 20.16633018, 15.12475871,  0.58590551,  0.78055299,
        0.21783425]), 'targetState': array([25., 25., 15.])}
episode index:2783
target thresh 31.863730011145243
model initialize at round 2783
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5688597752415948
{'scaleFactor': 20, 'currentState': array([25.30109062, 20.13787123, 14.9132155 ,  0.56140902,  0.75908004,
        0.32957156]), 'targetState': array([25., 25., 15.])}
episode index:2784
target thresh 31.87054329747413
model initialize at round 2784
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86298411,  0.97904447,  0.15202554,
       -0.13549965]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5689969853940753
{'scaleFactor': 20, 'currentState': array([25.29052026, 20.1608804 , 14.4606735 ,  0.57347026,  0.77244415,
        0.27287707]), 'targetState': array([25., 25., 15.])}
episode index:2785
target thresh 31.87735590250845
model initialize at round 2785
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89441588,  0.98271564,  0.1525956 ,
       -0.10480724]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5691340970468053
{'scaleFactor': 20, 'currentState': array([25.44880643, 20.02441341, 14.86892253,  0.64234971,  0.71576531,
        0.27398333]), 'targetState': array([25., 25., 15.])}
episode index:2786
target thresh 31.884167826316347
model initialize at round 2786
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87857479,  0.9809792 ,  0.15232596,
       -0.12031879]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5692711103058125
{'scaleFactor': 20, 'currentState': array([25.29967773, 20.14522434, 14.79150845,  0.57548862,  0.77501525,
        0.26108276]), 'targetState': array([25., 25., 15.])}
episode index:2787
target thresh 31.890979068965898
model initialize at round 2787
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.8537293 ,  0.97779172,  0.15183101,
       -0.14446695]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5694080252769725
{'scaleFactor': 20, 'currentState': array([25.32211874, 20.18490765, 14.05304281,  0.59604329,  0.79552347,
        0.1089716 ]), 'targetState': array([25., 25., 15.])}
episode index:2788
target thresh 31.897789630525253
model initialize at round 2788
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5695448420660091
{'scaleFactor': 20, 'currentState': array([25.2240004 , 20.10227378, 12.86075549,  0.63342643,  0.773365  ,
       -0.02602948]), 'targetState': array([25., 25., 15.])}
episode index:2789
target thresh 31.904599511062493
model initialize at round 2789
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08851801, 14.84627329,  0.98432337,  0.08801045,
       -0.15284524]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.569674777731185
{'scaleFactor': 20, 'currentState': array([29.22830395, 20.69053937, 14.36339276,  0.60626059,  0.74833179,
        0.26916096]), 'targetState': array([25., 25., 15.])}
episode index:2790
target thresh 31.911408710645738
model initialize at round 2790
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5698114009028685
{'scaleFactor': 20, 'currentState': array([25.19280463, 20.16491632, 13.08503097,  0.61438354,  0.78552861,
        0.07401133]), 'targetState': array([25., 25., 15.])}
episode index:2791
target thresh 31.91821722934307
model initialize at round 2791
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11526355, 14.84627329,  0.98168231,  0.11429514,
       -0.15243514]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.5699411480185577
{'scaleFactor': 20, 'currentState': array([29.43072452, 20.87561163, 14.60710848,  0.70818866,  0.6799452 ,
        0.19011404]), 'targetState': array([25., 25., 15.])}
episode index:2792
target thresh 31.925025067222556
model initialize at round 2792
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13474495, 14.84627329,  0.97934007,  0.13329407,
       -0.15207144]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5700741730817093
{'scaleFactor': 20, 'currentState': array([27.27097222, 20.70072567, 13.7727486 ,  0.64084445,  0.74856134,
        0.17021841]), 'targetState': array([25., 25., 15.])}
episode index:2793
target thresh 31.93183222435231
model initialize at round 2793
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5702105066095612
{'scaleFactor': 20, 'currentState': array([25.27769882, 20.15005984, 14.07597918,  0.58091333,  0.77562665,
        0.24686636]), 'targetState': array([25., 25., 15.])}
episode index:2794
target thresh 31.938638700800382
model initialize at round 2794
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85574557,  0.9780712 ,  0.15187441,
       -0.14251626]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5703467425821159
{'scaleFactor': 20, 'currentState': array([25.29174421, 20.16354825, 14.43319829,  0.57871862,  0.77836346,
        0.24338259]), 'targetState': array([25., 25., 15.])}
episode index:2795
target thresh 31.945444496634835
model initialize at round 2795
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5704828811040464
{'scaleFactor': 20, 'currentState': array([25.30271033, 20.15211385, 14.68627067,  0.57172123,  0.77028112,
        0.28249217]), 'targetState': array([25., 25., 15.])}
episode index:2796
target thresh 31.952249611923733
model initialize at round 2796
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.8522981 ,  0.97759113,  0.15179986,
       -0.14585058]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5706189222798762
{'scaleFactor': 20, 'currentState': array([25.29357007, 20.15828697, 14.52333424,  0.57444985,  0.77295074,
        0.26935946]), 'targetState': array([25., 25., 15.])}
episode index:2797
target thresh 31.959054046735126
model initialize at round 2797
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5707548662139792
{'scaleFactor': 20, 'currentState': array([25.26261084, 20.16660817, 14.22383915,  0.57346052,  0.77329243,
        0.27048449]), 'targetState': array([25., 25., 15.])}
episode index:2798
target thresh 31.965857801137076
model initialize at round 2798
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.96982467,  0.98770996,  0.15337111,
       -0.03010553]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5708907130105801
{'scaleFactor': 20, 'currentState': array([25.42354847, 20.03181926, 15.80081064,  0.60277118,  0.73797828,
        0.3034056 ]), 'targetState': array([25., 25., 15.])}
episode index:2799
target thresh 31.97266087519758
model initialize at round 2799
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.93539688,  0.98610985,  0.15312265,
       -0.06434926]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5710230663807196
{'scaleFactor': 20, 'currentState': array([26.72404452, 21.3188811 , 15.66549054,  0.48736309,  0.82201021,
        0.29457841]), 'targetState': array([25., 25., 15.])}
episode index:2800
target thresh 31.97946326898471
model initialize at round 2800
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.9031339 ,  0.98357127,  0.15272846,
       -0.09623708]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5711553252464892
{'scaleFactor': 20, 'currentState': array([26.85505758, 21.33236245, 15.59185922,  0.63968417,  0.72914623,
        0.24320761]), 'targetState': array([25., 25., 15.])}
episode index:2801
target thresh 31.98626498256646
model initialize at round 2801
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.05053072, 14.84627329,  0.98690339,  0.05037267,
       -0.15324587]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.5709514868006481
{'scaleFactor': 20, 'currentState': array([17.62692885, 11.6711035 ,  8.08254122,  0.96743093,  0.1665193 ,
        0.19065338]), 'targetState': array([25., 25., 15.])}
episode index:2802
target thresh 31.993066016010864
model initialize at round 2802
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86304852,  0.97905292,  0.15202685,
       -0.13543712]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5710870695916218
{'scaleFactor': 20, 'currentState': array([25.30137105, 20.17039679, 14.34231048,  0.58461902,  0.78427066,
        0.20770203]), 'targetState': array([25., 25., 15.])}
episode index:2803
target thresh 31.99986636938592
model initialize at round 2803
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5712191641279305
{'scaleFactor': 20, 'currentState': array([27.73775814, 20.04018807, 13.92706419,  0.80722077,  0.56179556,
        0.18105353]), 'targetState': array([25., 25., 15.])}
episode index:2804
target thresh 32.006666042759655
model initialize at round 2804
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.03942646, 14.84627329,  0.98739359,  0.03932266,
       -0.15332199]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.5710155209321629
{'scaleFactor': 20, 'currentState': array([22.75218426, 14.86662502, 12.02050823,  0.94019425,  0.126358  ,
       -0.31633593]), 'targetState': array([25., 25., 15.])}
episode index:2805
target thresh 32.01346503620004
model initialize at round 2805
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5711509359460503
{'scaleFactor': 20, 'currentState': array([25.06175851, 20.14330168, 12.41691418,  0.57855714,  0.80381897,
       -0.13837161]), 'targetState': array([25., 25., 15.])}
episode index:2806
target thresh 32.02026334977508
model initialize at round 2806
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5712862544761371
{'scaleFactor': 20, 'currentState': array([25.16741121, 20.17690829, 12.94374415,  0.59126937,  0.80561332,
       -0.0372519 ]), 'targetState': array([25., 25., 15.])}
episode index:2807
target thresh 32.027060983552744
model initialize at round 2807
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5714214766255046
{'scaleFactor': 20, 'currentState': array([25.27014174, 20.18218812, 13.97756769,  0.58796501,  0.7898409 ,
        0.17449499]), 'targetState': array([25., 25., 15.])}
episode index:2808
target thresh 32.03385793760102
model initialize at round 2808
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14685288, 14.84664798,  0.97776521,  0.14503801,
       -0.15145684]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5715532169860512
{'scaleFactor': 20, 'currentState': array([27.4261687 , 20.42411025, 14.41675749,  0.66577373,  0.71651233,
        0.20821965]), 'targetState': array([25., 25., 15.])}
episode index:2809
target thresh 32.04065421198787
model initialize at round 2809
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.1430724 , 14.87857816,  0.98250603,  0.14198939,
       -0.12050271]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5716848635812167
{'scaleFactor': 20, 'currentState': array([26.65855756, 21.33218883, 15.13229143,  0.46863164,  0.80434158,
        0.36526568]), 'targetState': array([25., 25., 15.])}
episode index:2810
target thresh 32.04744980678128
model initialize at round 2810
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.91499088,  0.98461975,  0.15289126,
       -0.08454713]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5718164165110707
{'scaleFactor': 20, 'currentState': array([26.53800841, 21.57440983, 14.80057359,  0.47477268,  0.83788924,
        0.26931862]), 'targetState': array([25., 25., 15.])}
episode index:2811
target thresh 32.05424472204918
model initialize at round 2811
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14565933, 14.84627329,  0.97787685,  0.14387564,
       -0.15184423]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5719478758755409
{'scaleFactor': 20, 'currentState': array([26.51124116, 21.52218569, 13.82807908,  0.47672037,  0.83360688,
        0.27899328]), 'targetState': array([25., 25., 15.])}
episode index:2812
target thresh 32.06103895785952
model initialize at round 2812
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.88235578,  0.98141481,  0.1523936 ,
       -0.11662402]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5720826224713547
{'scaleFactor': 20, 'currentState': array([25.32055961, 20.16496228, 14.50534466,  0.57825075,  0.77580471,
        0.2524938 ]), 'targetState': array([25., 25., 15.])}
episode index:2813
target thresh 32.06783251428025
model initialize at round 2813
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.8851971 ,  0.98173346,  0.15244308,
       -0.11384429]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5722172732984437
{'scaleFactor': 20, 'currentState': array([25.30855315, 20.16626928, 14.43125284,  0.57830762,  0.77656155,
        0.25002491]), 'targetState': array([25., 25., 15.])}
episode index:2814
target thresh 32.07462539137931
model initialize at round 2814
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89619543,  0.98289609,  0.15262362,
       -0.10305971]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5723518284588706
{'scaleFactor': 20, 'currentState': array([25.30322324, 20.12275134, 15.19032009,  0.55446034,  0.75226831,
        0.35590184]), 'targetState': array([25., 25., 15.])}
episode index:2815
target thresh 32.081417589224614
model initialize at round 2815
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.95302301,  0.98707335,  0.15327226,
       -0.04683812]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5724862880545527
{'scaleFactor': 20, 'currentState': array([25.29901073, 20.09153578, 15.97398208,  0.54088696,  0.74034454,
        0.39916318]), 'targetState': array([25., 25., 15.])}
episode index:2816
target thresh 32.088209107884104
model initialize at round 2816
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.51537267e+01,  1.49837825e+01,  9.88028426e-01,
        1.53420563e-01, -1.61851809e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5726206521872632
{'scaleFactor': 20, 'currentState': array([25.37060724, 20.15102175, 15.30936162,  0.57500678,  0.76980764,
        0.27706209]), 'targetState': array([25., 25., 15.])}
episode index:2817
target thresh 32.09499994742567
model initialize at round 2817
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.91162161,  0.98433538,  0.15284711,
       -0.0878727 ]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5727549209586303
{'scaleFactor': 20, 'currentState': array([25.32322431, 20.15796012, 14.64560263,  0.57472963,  0.7716715 ,
        0.2724132 ]), 'targetState': array([25., 25., 15.])}
episode index:2818
target thresh 32.10179010791725
model initialize at round 2818
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.92283358,  0.98523971,  0.15298753,
       -0.07679538]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5728890944701385
{'scaleFactor': 20, 'currentState': array([25.36798914, 20.07242153, 15.20875444,  0.57243272,  0.74433369,
        0.34393043]), 'targetState': array([25., 25., 15.])}
episode index:2819
target thresh 32.108579589426725
model initialize at round 2819
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.95126074,  0.98699061,  0.15325941,
       -0.0485911 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5730198005179863
{'scaleFactor': 20, 'currentState': array([27.2236451 , 20.91082032, 15.68235599,  0.64735355,  0.71805423,
        0.25560029]), 'targetState': array([25., 25., 15.])}
episode index:2820
target thresh 32.11536839202199
model initialize at round 2820
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15079902, 14.95942212,  0.98778643,  0.15046184,
       -0.04048715]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5731504138993699
{'scaleFactor': 20, 'currentState': array([26.58120596, 21.49833241, 16.02392307,  0.46377911,  0.81000916,
        0.35887895]), 'targetState': array([25., 25., 15.])}
episode index:2821
target thresh 32.12215651577095
model initialize at round 2821
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.93516056,  0.98609488,  0.15312032,
       -0.06458367]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5732809347128007
{'scaleFactor': 20, 'currentState': array([26.90687711, 21.19582996, 14.30923837,  0.53499197,  0.82927107,
        0.16153356]), 'targetState': array([25., 25., 15.])}
episode index:2822
target thresh 32.128943960741466
model initialize at round 2822
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5734147317780459
{'scaleFactor': 20, 'currentState': array([25.34927889, 20.13259447, 14.35586492,  0.60719009,  0.77560935,
        0.17248284]), 'targetState': array([25., 25., 15.])}
episode index:2823
target thresh 32.13573072700142
model initialize at round 2823
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5735484340861627
{'scaleFactor': 20, 'currentState': array([25.24092304, 20.1606316 , 13.47444392,  0.61674601,  0.77868762,
        0.11519523]), 'targetState': array([25., 25., 15.])}
episode index:2824
target thresh 32.14251681461868
model initialize at round 2824
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09338069, 14.84627329,  0.9838933 ,  0.09280468,
       -0.15277846]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5736786754013184
{'scaleFactor': 20, 'currentState': array([26.89019178, 20.91447668, 14.03193133,  0.54812099,  0.77833529,
        0.30619855]), 'targetState': array([25., 25., 15.])}
episode index:2825
target thresh 32.14930222366112
model initialize at round 2825
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12649496, 14.87064971,  0.98370841,  0.12569107,
       -0.12852825]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.5738054930490557
{'scaleFactor': 20, 'currentState': array([29.00671574, 21.19582071, 13.71016624,  0.62273548,  0.73083487,
        0.27942964]), 'targetState': array([25., 25., 15.])}
episode index:2826
target thresh 32.156086954196574
model initialize at round 2826
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.0944244 , 14.89070772,  0.98952476,  0.09437908,
       -0.10923982]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.5739322209779053
{'scaleFactor': 20, 'currentState': array([29.2170533 , 20.89191459, 15.08663039,  0.63227009,  0.72868791,
        0.26315104]), 'targetState': array([25., 25., 15.])}
episode index:2827
target thresh 32.16287100629289
model initialize at round 2827
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.05356396, 14.89324804,  0.99280113,  0.05371552,
       -0.10705401]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.5740588592830429
{'scaleFactor': 20, 'currentState': array([29.08944246, 20.6552902 , 14.66886352,  0.55422354,  0.78981262,
        0.26273995]), 'targetState': array([25., 25., 15.])}
episode index:2828
target thresh 32.16965438001792
model initialize at round 2828
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86137065,  0.97883162,  0.15199249,
       -0.13706545]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5741920975971528
{'scaleFactor': 20, 'currentState': array([25.24813782, 20.1788504 , 13.57940139,  0.59997717,  0.78859108,
        0.13472751]), 'targetState': array([25., 25., 15.])}
episode index:2829
target thresh 32.17643707543949
model initialize at round 2829
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.57432524174991
{'scaleFactor': 20, 'currentState': array([25.18988869, 20.10793067, 12.70759357,  0.60165112,  0.78156167,
       -0.16485534]), 'targetState': array([25., 25., 15.])}
episode index:2830
target thresh 32.183219092625436
model initialize at round 2830
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12489325, 14.84627329,  0.98056806,  0.12370336,
       -0.15226212]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.574451607029372
{'scaleFactor': 20, 'currentState': array([29.08167796, 20.30403036, 10.34509057,  0.75001966,  0.59416867,
       -0.29057545]), 'targetState': array([25., 25., 15.])}
episode index:2831
target thresh 32.19000043164358
model initialize at round 2831
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.1219399 , 14.84627329,  0.98091888,  0.12082137,
       -0.1523166 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5745812075033734
{'scaleFactor': 20, 'currentState': array([26.4644883 , 21.52791827, 13.29950392,  0.5118898 ,  0.84477037,
        0.15598669]), 'targetState': array([25., 25., 15.])}
episode index:2832
target thresh 32.19678109256172
model initialize at round 2832
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12870384, 14.84627329,  0.98010359,  0.12741727,
       -0.15219   ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5747107164839232
{'scaleFactor': 20, 'currentState': array([26.67796682, 21.40507993, 13.72856307,  0.54194666,  0.82434986,
        0.16352716]), 'targetState': array([25., 25., 15.])}
episode index:2833
target thresh 32.20356107544767
model initialize at round 2833
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10078914, 14.84627329,  0.98319509,  0.10009635,
       -0.15267004]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5748401340678743
{'scaleFactor': 20, 'currentState': array([26.40612852, 21.29831952, 12.0670235 ,  0.49732818,  0.86710006,
       -0.0283227 ]), 'targetState': array([25., 25., 15.])}
episode index:2834
target thresh 32.21034038036923
model initialize at round 2834
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14529884, 14.84627329,  0.97792689,  0.14352691,
       -0.151852  ]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5749728148141995
{'scaleFactor': 20, 'currentState': array([25.25152212, 20.11325325, 13.31008225,  0.59851018,  0.79491434,
        0.09948244]), 'targetState': array([25., 25., 15.])}
episode index:2835
target thresh 32.21711900739419
model initialize at round 2835
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5751054019915922
{'scaleFactor': 20, 'currentState': array([2.52195674e+01, 2.01873836e+01, 1.32954827e+01, 5.94835503e-01,
       8.03587912e-01, 2.04252909e-02]), 'targetState': array([25., 25., 15.])}
episode index:2836
target thresh 32.223896956590345
model initialize at round 2836
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15285442, 14.84627329,  0.97685386,  0.15082467,
       -0.15168538]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5752345436015356
{'scaleFactor': 20, 'currentState': array([26.95945296, 20.9870358 , 13.42760726,  0.56874888,  0.81025296,
        0.14147386]), 'targetState': array([25., 25., 15.])}
episode index:2837
target thresh 32.23067422802547
model initialize at round 2837
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12497364, 14.84627329,  0.9805584 ,  0.12378177,
       -0.15226062]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5753635942025925
{'scaleFactor': 20, 'currentState': array([26.44123522, 21.57197224, 13.66318582,  0.47453372,  0.85220489,
        0.22037372]), 'targetState': array([25., 25., 15.])}
episode index:2838
target thresh 32.23745082176733
model initialize at round 2838
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5754925538909329
{'scaleFactor': 20, 'currentState': array([27.33351594, 20.58882715, 13.77129097,  0.71128366,  0.66564812,
        0.22580554]), 'targetState': array([25., 25., 15.])}
episode index:2839
target thresh 32.24422673788369
model initialize at round 2839
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08401014, 14.84642853,  0.98472522,  0.08356253,
       -0.15275323]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.5756181076916427
{'scaleFactor': 20, 'currentState': array([29.69981956, 20.06625461, 14.91278155,  0.82143113,  0.53171757,
        0.20622156]), 'targetState': array([25., 25., 15.])}
episode index:2840
target thresh 32.25100197644234
model initialize at round 2840
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.07364088, 14.84627329,  0.98549921,  0.07330609,
       -0.15302783]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.5757435731053052
{'scaleFactor': 20, 'currentState': array([28.96686021, 20.98317878, 12.5754582 ,  0.68952904,  0.69737676,
        0.1954875 ]), 'targetState': array([25., 25., 15.])}
episode index:2841
target thresh 32.257776537511
model initialize at round 2841
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14027558, 14.88050916,  0.98311512,  0.13930004,
       -0.11865985]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5758722629632559
{'scaleFactor': 20, 'currentState': array([26.59818972, 21.39876284, 15.46944046,  0.52525086,  0.77863692,
        0.3432726 ]), 'targetState': array([25., 25., 15.])}
episode index:2842
target thresh 32.26455042115741
model initialize at round 2842
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.05691038, 14.95230007,  0.9971988 ,  0.05732421,
       -0.04804678]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5760008622901774
{'scaleFactor': 20, 'currentState': array([27.41441672, 20.02679004, 15.6186956 ,  0.57911478,  0.75060713,
        0.31814306]), 'targetState': array([25., 25., 15.])}
episode index:2843
target thresh 32.27132362744934
model initialize at round 2843
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.93185629,  0.98588001,  0.15308696,
       -0.06786012]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5761293711815666
{'scaleFactor': 20, 'currentState': array([27.41681923, 20.69478279, 15.29536802,  0.80322601,  0.55622389,
        0.21317353]), 'targetState': array([25., 25., 15.])}
episode index:2844
target thresh 32.2780961564545
model initialize at round 2844
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.06728625, 14.84627329,  0.98593678,  0.06701009,
       -0.15309577]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.5759268652514501
{'scaleFactor': 20, 'currentState': array([18.99315697, 27.07669455, 15.67730806,  0.78189643, -0.61203613,
       -0.11853166]), 'targetState': array([25., 25., 15.])}
episode index:2845
target thresh 32.28486800824063
model initialize at round 2845
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10605023, 14.9521915 ,  0.99316714,  0.1063895 ,
       -0.04796145]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5760553098347774
{'scaleFactor': 20, 'currentState': array([26.69111553, 21.29321245, 15.37940191,  0.4767825 ,  0.81785693,
        0.32216221]), 'targetState': array([25., 25., 15.])}
episode index:2846
target thresh 32.29163918287543
model initialize at round 2846
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86797653,  0.97968814,  0.15212549,
       -0.13064831]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5761870045098969
{'scaleFactor': 20, 'currentState': array([25.27727262, 20.11242116, 15.17539678,  0.54878855,  0.74767616,
        0.37391375]), 'targetState': array([25., 25., 15.])}
episode index:2847
target thresh 32.29840968042662
model initialize at round 2847
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12839576, 14.95271025,  0.99058373,  0.12847146,
       -0.04731763]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5763152675523446
{'scaleFactor': 20, 'currentState': array([26.6412127 , 21.4357824 , 15.17478493,  0.47368551,  0.82560614,
        0.30658855]), 'targetState': array([25., 25., 15.])}
episode index:2848
target thresh 32.3051795009619
model initialize at round 2848
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.88776347,  0.98201483,  0.15248678,
       -0.11133125]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5764467785324596
{'scaleFactor': 20, 'currentState': array([25.31752342, 20.15183891, 14.76052031,  0.57212124,  0.76964235,
        0.28342184]), 'targetState': array([25., 25., 15.])}
episode index:2849
target thresh 32.31194864454899
model initialize at round 2849
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14284702, 14.84627329,  0.97826413,  0.14115365,
       -0.15190437]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5765781972241675
{'scaleFactor': 20, 'currentState': array([25.35103103, 20.06976382, 14.28576484,  0.58979069,  0.77278511,
        0.23441442]), 'targetState': array([25., 25., 15.])}
episode index:2850
target thresh 32.31871711125556
model initialize at round 2850
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86874717,  0.97978548,  0.1521406 ,
       -0.12989861]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5767095237245798
{'scaleFactor': 20, 'currentState': array([25.31179799, 20.03028128, 15.36747653,  0.54945524,  0.73636292,
        0.39480195]), 'targetState': array([25., 25., 15.])}
episode index:2851
target thresh 32.3254849011493
model initialize at round 2851
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.96599042,  0.987589  ,  0.15335233,
       -0.03392675]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5768407581306721
{'scaleFactor': 20, 'currentState': array([25.38831937, 20.06064178, 15.66288365,  0.57334078,  0.75569363,
        0.31655566]), 'targetState': array([25., 25., 15.])}
episode index:2852
target thresh 32.33225201429789
model initialize at round 2852
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11614303, 14.9154826 ,  0.98963766,  0.11610052,
       -0.08448647]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5769685672408266
{'scaleFactor': 20, 'currentState': array([26.72707093, 21.25841322, 15.54086473,  0.54648756,  0.77471127,
        0.31807827]), 'targetState': array([25., 25., 15.])}
episode index:2853
target thresh 32.339018450769
model initialize at round 2853
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14112478, 14.88293308,  0.98327727,  0.14016645,
       -0.11627196]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5770962867860825
{'scaleFactor': 20, 'currentState': array([27.25226353, 20.75526626, 14.70077641,  0.69657413,  0.64379984,
        0.31671162]), 'targetState': array([25., 25., 15.])}
episode index:2854
target thresh 32.34578421063029
model initialize at round 2854
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13189191, 14.85369444,  0.98077468,  0.13066288,
       -0.14494221]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5772239168605535
{'scaleFactor': 20, 'currentState': array([26.47436944, 21.48418338, 15.17904621,  0.43855164,  0.80310745,
        0.40334958]), 'targetState': array([25., 25., 15.])}
episode index:2855
target thresh 32.35254929394943
model initialize at round 2855
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84679796,  0.97680327,  0.15167753,
       -0.15115985]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5773547873553152
{'scaleFactor': 20, 'currentState': array([25.30293863, 20.17043745, 14.37288699,  0.58051668,  0.77940261,
        0.2356522 ]), 'targetState': array([25., 25., 15.])}
episode index:2856
target thresh 32.359313700794054
model initialize at round 2856
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14498977, 14.84627329,  0.9779697 ,  0.14322788,
       -0.15185865]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5774822376045438
{'scaleFactor': 20, 'currentState': array([26.83613883, 21.06554513, 12.99268992,  0.59352332,  0.78734328,
        0.16679518]), 'targetState': array([25., 25., 15.])}
episode index:2857
target thresh 32.36607743123182
model initialize at round 2857
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12694563, 14.84627329,  0.98031955,  0.12570432,
       -0.15222353]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5776095986653543
{'scaleFactor': 20, 'currentState': array([27.04214627, 20.94882355, 14.59412089,  0.66019746,  0.67102352,
        0.33744147]), 'targetState': array([25., 25., 15.])}
episode index:2858
target thresh 32.37284048533034
model initialize at round 2858
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.0737025 , 14.89085079,  0.99126685,  0.07379681,
       -0.10928888]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.5774075666266466
{'scaleFactor': 20, 'currentState': array([38.37230655, 58.58267867,  5.502641  , -0.43736065, -0.86916663,
        0.23079217]), 'targetState': array([25., 25., 15.])}
episode index:2859
target thresh 32.37960286315729
model initialize at round 2859
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5775381898725463
{'scaleFactor': 20, 'currentState': array([25.21301021, 20.18938732, 13.33658119,  0.59181517,  0.79959362,
        0.10200413]), 'targetState': array([25., 25., 15.])}
episode index:2860
target thresh 32.38636456478026
model initialize at round 2860
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13539533, 14.9171193 ,  0.98738634,  0.13503788,
       -0.08266189]), 'targetState': array([25., 25., 15.])}
done in step count: 42
reward sum = 0.6556592205741436
running average episode reward sum: 0.5775654953708692
{'scaleFactor': 20, 'currentState': array([23.32393303, 29.37691828, 15.83736123,  0.52957532, -0.84563632,
       -0.06670225]), 'targetState': array([25., 25., 15.])}
episode index:2861
target thresh 32.39312559026687
model initialize at round 2861
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15065273, 14.84627329,  0.97717179,  0.1487006 ,
       -0.15173475]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5776926493380357
{'scaleFactor': 20, 'currentState': array([26.48383907, 21.49811221, 15.21646994,  0.49672309,  0.79198771,
        0.35499526]), 'targetState': array([25., 25., 15.])}
episode index:2862
target thresh 32.39988593968474
model initialize at round 2862
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14873492, 14.91380519,  0.98525675,  0.14802231,
       -0.08578184]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5778197144795176
{'scaleFactor': 20, 'currentState': array([26.54188771, 21.43468394, 15.8315811 ,  0.47411653,  0.84177877,
        0.25811241]), 'targetState': array([25., 25., 15.])}
episode index:2863
target thresh 32.40664561310146
model initialize at round 2863
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.88134918,  0.98130013,  0.1523758 ,
       -0.11760815]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5779500113843432
{'scaleFactor': 20, 'currentState': array([25.32901118, 20.17941234, 14.23295174,  0.589224  ,  0.78751285,
        0.18066152]), 'targetState': array([25., 25., 15.])}
episode index:2864
target thresh 32.41340461058464
model initialize at round 2864
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.88849821,  0.98209426,  0.15249911,
       -0.11061138]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5780802173314691
{'scaleFactor': 20, 'currentState': array([25.28409616, 20.07403852, 13.04152086,  0.60893042,  0.78799867,
       -0.09089464]), 'targetState': array([25., 25., 15.])}
episode index:2865
target thresh 32.420162932201876
model initialize at round 2865
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5782103324161056
{'scaleFactor': 20, 'currentState': array([2.52377720e+01, 2.01370468e+01, 1.31355686e+01, 6.48051477e-01,
       7.61317410e-01, 2.06175818e-02]), 'targetState': array([25., 25., 15.])}
episode index:2866
target thresh 32.426920578020734
model initialize at round 2866
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08983183, 14.84627329,  0.98420938,  0.0893064 ,
       -0.15282754]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.5783337558606438
{'scaleFactor': 20, 'currentState': array([29.60868833, 20.16505741, 12.8482441 ,  0.80650157,  0.56609636,
        0.17055828]), 'targetState': array([25., 25., 15.])}
episode index:2867
target thresh 32.4336775481088
model initialize at round 2867
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.02260728, 14.84627329,  0.98790638,  0.02255947,
       -0.15340161]), 'targetState': array([25., 25., 15.])}
done in step count: 48
reward sum = 0.617290140942288
running average episode reward sum: 0.5783473389795705
{'scaleFactor': 20, 'currentState': array([28.22262293, 20.94733288, 14.20886082,  0.58322338,  0.74294352,
        0.32845916]), 'targetState': array([25., 25., 15.])}
episode index:2868
target thresh 32.440433842533636
model initialize at round 2868
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11265375, 14.84627329,  0.98196951,  0.11173995,
       -0.15247974]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5784739101926836
{'scaleFactor': 20, 'currentState': array([27.28614294, 20.33779358, 15.06082615,  0.61064478,  0.68100676,
        0.40415684]), 'targetState': array([25., 25., 15.])}
episode index:2869
target thresh 32.44718946136281
model initialize at round 2869
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89728846,  0.98300546,  0.1526406 ,
       -0.10198586]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5786003932028607
{'scaleFactor': 20, 'currentState': array([26.59268634, 21.48952763, 15.47271732,  0.49679552,  0.7966506 ,
        0.34429934]), 'targetState': array([25., 25., 15.])}
episode index:2870
target thresh 32.45394440466388
model initialize at round 2870
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.93719608,  0.986222  ,  0.15314006,
       -0.06256425]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5787301005023024
{'scaleFactor': 20, 'currentState': array([25.42269744, 20.08771404, 14.98519626,  0.59803822,  0.77624089,
        0.1995003 ]), 'targetState': array([25., 25., 15.])}
episode index:2871
target thresh 32.46069867250439
model initialize at round 2871
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5788597174763267
{'scaleFactor': 20, 'currentState': array([25.25011968, 20.18839402, 13.5777633 ,  0.59295806,  0.79814097,
        0.1066383 ]), 'targetState': array([25., 25., 15.])}
episode index:2872
target thresh 32.46745226495189
model initialize at round 2872
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5789892442192517
{'scaleFactor': 20, 'currentState': array([25.24366622, 20.1846741 , 13.77500458,  0.5854679 ,  0.78878272,
        0.18721421]), 'targetState': array([25., 25., 15.])}
episode index:2873
target thresh 32.47420518207392
model initialize at round 2873
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85010099,  0.97727963,  0.1517515 ,
       -0.14797298]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5791186808252644
{'scaleFactor': 20, 'currentState': array([25.32201497, 20.17214611, 14.42231695,  0.58611075,  0.78459155,
        0.20221344]), 'targetState': array([25., 25., 15.])}
episode index:2874
target thresh 32.48095742393799
model initialize at round 2874
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85061402,  0.97735275,  0.15176285,
       -0.14747757]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5792480273884207
{'scaleFactor': 20, 'currentState': array([25.25189292, 20.16082791, 13.59571612,  0.60631966,  0.77597484,
        0.17389514]), 'targetState': array([25., 25., 15.])}
episode index:2875
target thresh 32.48770899061163
model initialize at round 2875
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08949502, 14.90193132,  0.99112714,  0.08959692,
       -0.09818033]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.5793707037863757
{'scaleFactor': 20, 'currentState': array([29.08601289, 21.1907661 , 14.84777055,  0.58746429,  0.75590128,
        0.28896187]), 'targetState': array([25., 25., 15.])}
episode index:2876
target thresh 32.494459882162374
model initialize at round 2876
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86531221,  0.97934745,  0.15207259,
       -0.13323852]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5794998728326438
{'scaleFactor': 20, 'currentState': array([25.28972481, 20.17083309, 14.28213224,  0.57949949,  0.77879218,
        0.24013139]), 'targetState': array([25., 25., 15.])}
episode index:2877
target thresh 32.50121009865771
model initialize at round 2877
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85795852,  0.97837375,  0.15192139,
       -0.14037339]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.57962895211585
{'scaleFactor': 20, 'currentState': array([25.30243409, 20.144027  , 14.82311699,  0.56442555,  0.76212297,
        0.31716301]), 'targetState': array([25., 25., 15.])}
episode index:2878
target thresh 32.50795964016514
model initialize at round 2878
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.93628669,  0.9861657 ,  0.15313132,
       -0.06346654]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5797579417295298
{'scaleFactor': 20, 'currentState': array([25.29328643, 20.09733256, 15.64286038,  0.54947667,  0.74966014,
        0.36889708]), 'targetState': array([25., 25., 15.])}
episode index:2879
target thresh 32.514708506752164
model initialize at round 2879
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.93840413,  0.98629555,  0.15315148,
       -0.06136539]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5798868417670889
{'scaleFactor': 20, 'currentState': array([25.37007731, 20.16006703, 15.09601566,  0.58211762,  0.77770846,
        0.23729438]), 'targetState': array([25., 25., 15.])}
episode index:2880
target thresh 32.52145669848628
model initialize at round 2880
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86490957,  0.9792954 ,  0.1520645 ,
       -0.13362973]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5800156523218035
{'scaleFactor': 20, 'currentState': array([25.29917699, 20.13596738, 14.93362361,  0.56010198,  0.75794105,
        0.33438173]), 'targetState': array([25., 25., 15.])}
episode index:2881
target thresh 32.52820421543496
model initialize at round 2881
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.92014584,  0.98503387,  0.15295557,
       -0.07945359]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5801410737295339
{'scaleFactor': 20, 'currentState': array([26.60280791, 21.44251626, 16.28889757,  0.50276147,  0.81871468,
        0.27737551]), 'targetState': array([25., 25., 15.])}
episode index:2882
target thresh 32.53495105766569
model initialize at round 2882
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84792432,  0.9769668 ,  0.15170292,
       -0.15007362]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.580269706742427
{'scaleFactor': 20, 'currentState': array([25.33630836, 20.08326314, 14.91882557,  0.57473125,  0.76151556,
        0.29962984]), 'targetState': array([25., 25., 15.])}
episode index:2883
target thresh 32.54169722524591
model initialize at round 2883
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87894602,  0.98102255,  0.15233269,
       -0.11995624]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5803949530817677
{'scaleFactor': 20, 'currentState': array([26.97932682, 21.1996688 , 14.79303905,  0.59523782,  0.7431153 ,
        0.30573122]), 'targetState': array([25., 25., 15.])}
episode index:2884
target thresh 32.54844271824312
model initialize at round 2884
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14259246, 14.89187715,  0.98405305,  0.14173591,
       -0.10747335]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5805234089212195
{'scaleFactor': 20, 'currentState': array([25.3918818 , 20.07114152, 14.45126   ,  0.59433571,  0.77646061,
        0.2094612 ]), 'targetState': array([25., 25., 15.])}
episode index:2885
target thresh 32.55518753672475
model initialize at round 2885
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15114609, 14.85152648,  0.9778573 ,  0.14929223,
       -0.14665244]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5806484805568674
{'scaleFactor': 20, 'currentState': array([26.81763825, 21.35205196, 13.88586552,  0.58150593,  0.80013363,
        0.1470953 ]), 'targetState': array([25., 25., 15.])}
episode index:2886
target thresh 32.56193168075826
model initialize at round 2886
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5807734655478075
{'scaleFactor': 20, 'currentState': array([26.80799998, 21.22707995, 13.96973123,  0.53793116,  0.79319751,
        0.2854256 ]), 'targetState': array([25., 25., 15.])}
episode index:2887
target thresh 32.56867515041109
model initialize at round 2887
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89871808,  0.98314681,  0.15266255,
       -0.1005808 ]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5809016568858796
{'scaleFactor': 20, 'currentState': array([25.30844111, 20.13873522, 14.92850103,  0.56232116,  0.75962269,
        0.32675416]), 'targetState': array([25., 25., 15.])}
episode index:2888
target thresh 32.575417945750665
model initialize at round 2888
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.91985729,  0.98501136,  0.15295207,
       -0.07973887]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5810264677174874
{'scaleFactor': 20, 'currentState': array([27.10794917, 20.92399081, 15.81569976,  0.60823643,  0.72766064,
        0.3171095 ]), 'targetState': array([25., 25., 15.])}
episode index:2889
target thresh 32.5821600668444
model initialize at round 2889
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11927395, 14.84627329,  0.98122867,  0.11821719,
       -0.1523647 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5811511921748174
{'scaleFactor': 20, 'currentState': array([27.43351201, 20.13523506, 14.90426133,  0.64215166,  0.67867689,
        0.3564252 ]), 'targetState': array([25., 25., 15.])}
episode index:2890
target thresh 32.58890151375976
model initialize at round 2890
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11039433, 14.89213217,  0.98806412,  0.11017846,
       -0.1076569 ]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.581272573757568
{'scaleFactor': 20, 'currentState': array([29.69371464, 20.19684426, 14.33365215,  0.69368906,  0.66538524,
        0.2757861 ]), 'targetState': array([25., 25., 15.])}
episode index:2891
target thresh 32.59564228656413
model initialize at round 2891
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5813971268611792
{'scaleFactor': 20, 'currentState': array([26.81828481, 21.23391125, 15.30918831,  0.5409262 ,  0.78730693,
        0.29588281]), 'targetState': array([25., 25., 15.])}
episode index:2892
target thresh 32.602382385324916
model initialize at round 2892
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.8477349 ,  0.97693938,  0.15169866,
       -0.15025634]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5815248810689354
{'scaleFactor': 20, 'currentState': array([25.27458861, 20.18711448, 13.73154427,  0.59269466,  0.7957196 ,
        0.12467298]), 'targetState': array([25., 25., 15.])}
episode index:2893
target thresh 32.60912181010952
model initialize at round 2893
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.1505306 , 14.84627329,  0.97718929,  0.14858271,
       -0.15173747]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.581649260912865
{'scaleFactor': 20, 'currentState': array([26.51433345, 21.44357449, 15.89755689,  0.49413977,  0.79787927,
        0.3452746 ]), 'targetState': array([25., 25., 15.])}
episode index:2894
target thresh 32.615860560985354
model initialize at round 2894
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08621127, 14.87491906,  0.98843081,  0.08607462,
       -0.12488268]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5817735548294412
{'scaleFactor': 20, 'currentState': array([26.87618981, 20.78241451, 15.33512687,  0.49996189,  0.7750554 ,
        0.38642881]), 'targetState': array([25., 25., 15.])}
episode index:2895
target thresh 32.62259863801978
model initialize at round 2895
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85571214,  0.9780666 ,  0.1518737 ,
       -0.14254862]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5819010467130981
{'scaleFactor': 20, 'currentState': array([25.3082188 , 20.1865314 , 13.82207217,  0.59749247,  0.79905898,
        0.0671379 ]), 'targetState': array([25., 25., 15.])}
episode index:2896
target thresh 32.62933604128021
model initialize at round 2896
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5820251679083649
{'scaleFactor': 20, 'currentState': array([26.56232877, 21.4766855 , 15.16052369,  0.50123906,  0.75084144,
        0.43011224]), 'targetState': array([25., 25., 15.])}
episode index:2897
target thresh 32.63607277083399
model initialize at round 2897
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08580333, 14.98131552,  0.99608912,  0.08633107,
       -0.0187994 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5821492034437316
{'scaleFactor': 20, 'currentState': array([26.96587246, 20.8507757 , 16.04143352,  0.56189191,  0.75627086,
        0.33515946]), 'targetState': array([25., 25., 15.])}
episode index:2898
target thresh 32.64280882674849
model initialize at round 2898
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.0918027 , 14.86741969,  0.98699166,  0.09152374,
       -0.13217743]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.5819483930941477
{'scaleFactor': 20, 'currentState': array([2.13205392e+01, 1.21742414e+01, 9.27160145e+00, 9.97258329e-01,
       8.04970302e-03, 7.35596820e-02]), 'targetState': array([25., 25., 15.])}
episode index:2899
target thresh 32.6495442090911
model initialize at round 2899
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12459866, 14.84627329,  0.98060341,  0.12341603,
       -0.15226761]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5820723695618397
{'scaleFactor': 20, 'currentState': array([27.34422786, 20.32861492, 13.21953101,  0.6362162 ,  0.76361758,
        0.11007791]), 'targetState': array([25., 25., 15.])}
episode index:2900
target thresh 32.65627891792913
model initialize at round 2900
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14561474, 14.84627329,  0.97788304,  0.14383251,
       -0.15184519]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5821962605579925
{'scaleFactor': 20, 'currentState': array([26.81270331, 20.74970562, 11.83975422,  0.57160916,  0.81305481,
       -0.11047552]), 'targetState': array([25., 25., 15.])}
episode index:2901
target thresh 32.663012953329954
model initialize at round 2901
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.582323343186987
{'scaleFactor': 20, 'currentState': array([25.35029124, 20.11067884, 13.64617435,  0.65037402,  0.75370476,
        0.0945662 ]), 'targetState': array([25., 25., 15.])}
episode index:2902
target thresh 32.669746315360904
model initialize at round 2902
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12051423, 14.84627329,  0.98108536,  0.11942904,
       -0.15234245]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5824470623761754
{'scaleFactor': 20, 'currentState': array([26.62744281, 21.38562997, 14.66760726,  0.47795458,  0.8135765 ,
        0.33113848]), 'targetState': array([25., 25., 15.])}
episode index:2903
target thresh 32.67647900408932
model initialize at round 2903
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86908503,  0.97982799,  0.1521472 ,
       -0.12956985]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5825739711184357
{'scaleFactor': 20, 'currentState': array([25.28149066, 20.11999544, 15.07717627,  0.55222353,  0.75080287,
        0.36241444]), 'targetState': array([25., 25., 15.])}
episode index:2904
target thresh 32.68321101958254
model initialize at round 2904
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.91060568,  0.98424752,  0.15283347,
       -0.08887489]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5827007924880678
{'scaleFactor': 20, 'currentState': array([25.35040281, 20.17773225, 14.41036008,  0.59601275,  0.79401776,
        0.11960186]), 'targetState': array([25., 25., 15.])}
episode index:2905
target thresh 32.68994236190784
model initialize at round 2905
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5828242540699374
{'scaleFactor': 20, 'currentState': array([27.07157423, 21.04170433, 14.19118164,  0.64883509,  0.71234193,
        0.26754811]), 'targetState': array([25., 25., 15.])}
episode index:2906
target thresh 32.69667303113258
model initialize at round 2906
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09334792, 14.84627329,  0.98389628,  0.09277239,
       -0.15277892]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.5829443920451135
{'scaleFactor': 20, 'currentState': array([29.08300482, 20.81526142, 14.40681848,  0.58439934,  0.72307663,
        0.36829009]), 'targetState': array([25., 25., 15.])}
episode index:2907
target thresh 32.70340302732405
model initialize at round 2907
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5830709552011847
{'scaleFactor': 20, 'currentState': array([25.27820372, 20.12224454, 15.06056975,  0.56089308,  0.76125055,
        0.3254175 ]), 'targetState': array([25., 25., 15.])}
episode index:2908
target thresh 32.71013235054956
model initialize at round 2908
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85116127,  0.97743049,  0.15177492,
       -0.146949  ]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5831974313423668
{'scaleFactor': 20, 'currentState': array([25.29283794, 20.16947522, 14.32888163,  0.58258904,  0.78275569,
        0.21882308]), 'targetState': array([25., 25., 15.])}
episode index:2909
target thresh 32.716861000876385
model initialize at round 2909
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15288617, 14.84627329,  0.97684924,  0.15085529,
       -0.15168467]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5833205525513216
{'scaleFactor': 20, 'currentState': array([27.55019177, 20.25104585, 14.9784503 ,  0.65578489,  0.67397386,
        0.34015498]), 'targetState': array([25., 25., 15.])}
episode index:2910
target thresh 32.72358897837181
model initialize at round 2910
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.91136187,  0.98431301,  0.15284364,
       -0.08812895]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5834468560543613
{'scaleFactor': 20, 'currentState': array([25.3407828 , 20.14150782, 15.1588727 ,  0.56607559,  0.76208002,
        0.3143127 ]), 'targetState': array([25., 25., 15.])}
episode index:2911
target thresh 32.73031628310312
model initialize at round 2911
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89622163,  0.98289873,  0.15262403,
       -0.10303396]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5835730728104895
{'scaleFactor': 20, 'currentState': array([25.34626566, 20.04729744, 15.31018176,  0.5585829 ,  0.74439896,
        0.36586244]), 'targetState': array([25., 25., 15.])}
episode index:2912
target thresh 32.73704291513761
model initialize at round 2912
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14263667, 14.98105413,  0.98960218,  0.14257936,
       -0.01893825]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5836959382676096
{'scaleFactor': 20, 'currentState': array([26.66066516, 21.2603891 , 16.50456677,  0.49099699,  0.79652302,
        0.35280737]), 'targetState': array([25., 25., 15.])}
episode index:2913
target thresh 32.743768874542525
model initialize at round 2913
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11565377, 14.91917233,  0.98999559,  0.11565326,
       -0.08082731]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5838187193970308
{'scaleFactor': 20, 'currentState': array([26.79689768, 21.13299837, 15.36006693,  0.48928332,  0.80376981,
        0.3384611 ]), 'targetState': array([25., 25., 15.])}
episode index:2914
target thresh 32.75049416138513
model initialize at round 2914
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5839414162855399
{'scaleFactor': 20, 'currentState': array([26.59763881, 21.34452195, 15.84707552,  0.48846825,  0.75644077,
        0.43496681]), 'targetState': array([25., 25., 15.])}
episode index:2915
target thresh 32.75721877573267
model initialize at round 2915
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.94636431,  0.98674482,  0.15322125,
       -0.05345933]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5840672903025544
{'scaleFactor': 20, 'currentState': array([25.36090536, 20.03208448, 15.76988432,  0.60745299,  0.7054508 ,
        0.36515756]), 'targetState': array([25., 25., 15.])}
episode index:2916
target thresh 32.7639427176524
model initialize at round 2916
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.0930522 , 14.86923726,  0.98711316,  0.09278086,
       -0.13038144]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5841898178510969
{'scaleFactor': 20, 'currentState': array([27.07440819, 20.72080033, 15.06030047,  0.55561724,  0.79036483,
        0.2580948 ]), 'targetState': array([25., 25., 15.])}
episode index:2917
target thresh 32.770665987211544
model initialize at round 2917
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14102546, 14.84627329,  0.97851119,  0.13938888,
       -0.15194273]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.58431226141914
{'scaleFactor': 20, 'currentState': array([26.49524189, 21.59564122, 13.04305629,  0.50019683,  0.86489203,
        0.04201092]), 'targetState': array([25., 25., 15.])}
episode index:2918
target thresh 32.777388584477364
model initialize at round 2918
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5844346210929947
{'scaleFactor': 20, 'currentState': array([26.78924124, 21.25692436, 14.33649024,  0.54797402,  0.76931467,
        0.32845001]), 'targetState': array([25., 25., 15.])}
episode index:2919
target thresh 32.78411050951706
model initialize at round 2919
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11098013, 14.87345137,  0.98585279,  0.11051522,
       -0.12601851]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.5845536727117666
{'scaleFactor': 20, 'currentState': array([29.20417459, 20.77942051, 15.74113241,  0.63309824,  0.72018279,
        0.28376639]), 'targetState': array([25., 25., 15.])}
episode index:2920
target thresh 32.79083176239786
model initialize at round 2920
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.93045912,  0.98578598,  0.15307236,
       -0.06924488]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5846791216597941
{'scaleFactor': 20, 'currentState': array([25.27310055, 20.07357243, 15.81985081,  0.5484367 ,  0.74222868,
        0.38511526]), 'targetState': array([25., 25., 15.])}
episode index:2921
target thresh 32.797552343186986
model initialize at round 2921
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10689501, 14.95742382,  0.99331362,  0.1072528 ,
       -0.04271869]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5848012301566254
{'scaleFactor': 20, 'currentState': array([27.0904886 , 20.69990037, 16.32914374,  0.61900249,  0.71635385,
        0.32198305]), 'targetState': array([25., 25., 15.])}
episode index:2922
target thresh 32.80427225195163
model initialize at round 2922
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12945854, 14.88003595,  0.98447737,  0.12873637,
       -0.11929484]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5849232551033392
{'scaleFactor': 20, 'currentState': array([26.39165997, 21.42816845, 16.23173781,  0.43574614,  0.81916049,
        0.37296299]), 'targetState': array([25., 25., 15.])}
episode index:2923
target thresh 32.81099148875899
model initialize at round 2923
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14555337, 14.94160795,  0.98768392,  0.14521285,
       -0.05825544]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5850451965856571
{'scaleFactor': 20, 'currentState': array([26.51684135, 21.40061684, 16.39816238,  0.4576924 ,  0.78903984,
        0.40979726]), 'targetState': array([25., 25., 15.])}
episode index:2924
target thresh 32.817710053676265
model initialize at round 2924
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12569254, 14.92893755,  0.98953083,  0.12563297,
       -0.07102877]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5851670546891837
{'scaleFactor': 20, 'currentState': array([26.54806816, 21.32768237, 16.26085656,  0.46113835,  0.79632341,
        0.39143383]), 'targetState': array([25., 25., 15.])}
episode index:2925
target thresh 32.82442794677064
model initialize at round 2925
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.94727366,  0.98679223,  0.15322861,
       -0.05255549]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5852888294994065
{'scaleFactor': 20, 'currentState': array([26.5861779 , 21.51567163, 15.6124237 ,  0.47255221,  0.7940628 ,
        0.38230704]), 'targetState': array([25., 25., 15.])}
episode index:2926
target thresh 32.8311451681093
model initialize at round 2926
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85852212,  0.97845011,  0.15193325,
       -0.13982732]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5854137701281734
{'scaleFactor': 20, 'currentState': array([25.23085555, 20.18877315, 13.53920709,  0.58936131,  0.79474226,
        0.14504475]), 'targetState': array([25., 25., 15.])}
episode index:2927
target thresh 32.837861717759424
model initialize at round 2927
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5855386254149807
{'scaleFactor': 20, 'currentState': array([25.28338723, 20.1458013 , 14.68134463,  0.56387702,  0.76229899,
        0.31771521]), 'targetState': array([25., 25., 15.])}
episode index:2928
target thresh 32.84457759578814
model initialize at round 2928
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5856633954472391
{'scaleFactor': 20, 'currentState': array([25.20881023, 20.18788827, 13.552456  ,  0.5848642 ,  0.79095832,
        0.17977428]), 'targetState': array([25., 25., 15.])}
episode index:2929
target thresh 32.851292802262634
model initialize at round 2929
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89375506,  0.98264787,  0.15258507,
       -0.10545593]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5857880803122401
{'scaleFactor': 20, 'currentState': array([25.33032838, 20.18320158, 14.03402792,  0.59799701,  0.7975794 ,
        0.07916231]), 'targetState': array([25., 25., 15.])}
episode index:2930
target thresh 32.85800733725006
model initialize at round 2930
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5859126800971557
{'scaleFactor': 20, 'currentState': array([25.23439674, 20.18478203, 13.74088982,  0.58336762,  0.78694524,
        0.20099606]), 'targetState': array([25., 25., 15.])}
episode index:2931
target thresh 32.86472120081757
model initialize at round 2931
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.88426673,  0.98162994,  0.15242701,
       -0.11475479]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5860371948890394
{'scaleFactor': 20, 'currentState': array([25.31298138, 20.17401329, 14.29805518,  0.58257361,  0.78086889,
        0.22550336]), 'targetState': array([25., 25., 15.])}
episode index:2932
target thresh 32.87143439303228
model initialize at round 2932
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.88479854,  0.98168921,  0.15243621,
       -0.11423437]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5861616247748256
{'scaleFactor': 20, 'currentState': array([25.30411061, 20.12850778, 15.10781723,  0.55825388,  0.75620493,
        0.34133079]), 'targetState': array([25., 25., 15.])}
episode index:2933
target thresh 32.878146913961345
model initialize at round 2933
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.95734457,  0.98726345,  0.15330178,
       -0.04253752]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5862859698413304
{'scaleFactor': 20, 'currentState': array([25.2314529 , 20.04541697, 16.34413154,  0.51868895,  0.72342574,
        0.45565005]), 'targetState': array([25., 25., 15.])}
episode index:2934
target thresh 32.884858763671865
model initialize at round 2934
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.03766564,  0.98746026,  0.15333234,
        0.03756901]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5864102301752516
{'scaleFactor': 20, 'currentState': array([25.27764363, 20.00948852, 16.98031657,  0.59461448,  0.75633426,
        0.27274916]), 'targetState': array([25., 25., 15.])}
episode index:2935
target thresh 32.89156994223097
model initialize at round 2935
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5865344058631687
{'scaleFactor': 20, 'currentState': array([25.28743462, 20.1722087 , 14.25911692,  0.5783649 ,  0.77755453,
        0.2467853 ]), 'targetState': array([25., 25., 15.])}
episode index:2936
target thresh 32.89828044970579
model initialize at round 2936
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89391876,  0.9826647 ,  0.15258769,
       -0.10529524]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5866584969915436
{'scaleFactor': 20, 'currentState': array([25.32072179, 20.13442746, 15.16153749,  0.57000454,  0.768828  ,
        0.28982466]), 'targetState': array([25., 25., 15.])}
episode index:2937
target thresh 32.904990286163404
model initialize at round 2937
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15113546, 14.87110664,  0.98045976,  0.14967903,
       -0.12765127]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.58678250364672
{'scaleFactor': 20, 'currentState': array([25.31541671, 20.10627195, 15.09496238,  0.56754601,  0.7633095 ,
        0.30862622]), 'targetState': array([25., 25., 15.])}
episode index:2938
target thresh 32.91169945167093
model initialize at round 2938
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5869064259149246
{'scaleFactor': 20, 'currentState': array([25.26838365, 20.09731153, 15.41518695,  0.54813704,  0.74936917,
        0.37147225]), 'targetState': array([25., 25., 15.])}
episode index:2939
target thresh 32.91840794629544
model initialize at round 2939
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.88229669,  0.9814081 ,  0.15239256,
       -0.1166818 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5870270292222328
{'scaleFactor': 20, 'currentState': array([26.50488228, 21.42243144, 16.19930404,  0.47712141,  0.77008106,
        0.4234741 ]), 'targetState': array([25., 25., 15.])}
episode index:2940
target thresh 32.92511577010402
model initialize at round 2940
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15019737, 14.97205299,  0.98830144,  0.14993967,
       -0.02789906]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5871507840745545
{'scaleFactor': 20, 'currentState': array([25.52865848, 20.00390061, 14.91384954,  0.67122117,  0.72688749,
        0.14524711]), 'targetState': array([25., 25., 15.])}
episode index:2941
target thresh 32.931822923163764
model initialize at round 2941
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09123132, 14.854946  ,  0.9853484 ,  0.09080267,
       -0.14437245]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.5872680221995825
{'scaleFactor': 20, 'currentState': array([28.66617096, 21.55594814, 12.62320805,  0.53454403,  0.84436564,
       -0.036185  ]), 'targetState': array([25., 25., 15.])}
episode index:2942
target thresh 32.93852940554175
model initialize at round 2942
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5873916110639047
{'scaleFactor': 20, 'currentState': array([25.08725244, 20.1335737 , 12.44990725,  0.5715302 ,  0.79401084,
       -0.2071232 ]), 'targetState': array([25., 25., 15.])}
episode index:2943
target thresh 32.945235217305026
model initialize at round 2943
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5875151159684007
{'scaleFactor': 20, 'currentState': array([25.04518385, 20.13318284, 12.32989918,  0.57307137,  0.79980824,
       -0.17859447]), 'targetState': array([25., 25., 15.])}
episode index:2944
target thresh 32.95194035852064
model initialize at round 2944
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5876385369985981
{'scaleFactor': 20, 'currentState': array([25.12747374, 20.17083013, 12.75826752,  0.58926012,  0.80732344,
       -0.03164454]), 'targetState': array([25., 25., 15.])}
episode index:2945
target thresh 32.95864482925567
model initialize at round 2945
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5877618742399088
{'scaleFactor': 20, 'currentState': array([25.28328542, 20.17692591, 14.10784707,  0.58084231,  0.78052902,
        0.23107717]), 'targetState': array([25., 25., 15.])}
episode index:2946
target thresh 32.96534862957713
model initialize at round 2946
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87951206,  0.98108841,  0.15234292,
       -0.11940336]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5878819008008729
{'scaleFactor': 20, 'currentState': array([26.67959105, 21.3513747 , 15.60123106,  0.48560606,  0.78990098,
        0.37449058]), 'targetState': array([25., 25., 15.])}
episode index:2947
target thresh 32.97205175955209
model initialize at round 2947
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14285433, 14.91142938,  0.98589142,  0.14226147,
       -0.08820305]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5880050718148142
{'scaleFactor': 20, 'currentState': array([25.3680363 , 20.05127308, 14.7234785 ,  0.57842903,  0.76102557,
        0.29370043]), 'targetState': array([25., 25., 15.])}
episode index:2948
target thresh 32.97875421924756
model initialize at round 2948
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5881249345064339
{'scaleFactor': 20, 'currentState': array([26.67921103, 21.5180129 , 14.10795322,  0.5306216 ,  0.82778413,
        0.18224749]), 'targetState': array([25., 25., 15.])}
episode index:2949
target thresh 32.98545600873059
model initialize at round 2949
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5882447159352117
{'scaleFactor': 20, 'currentState': array([26.50931629, 21.62328252, 13.98267071,  0.49552564,  0.84513388,
        0.200507  ]), 'targetState': array([25., 25., 15.])}
episode index:2950
target thresh 32.99215712806816
model initialize at round 2950
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14554326, 14.84627329,  0.97789297,  0.14376336,
       -0.15184673]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.5883612258071099
{'scaleFactor': 20, 'currentState': array([29.35389576, 20.99266577, 14.4247809 ,  0.68147978,  0.67578162,
        0.28089948]), 'targetState': array([25., 25., 15.])}
episode index:2951
target thresh 32.9988575773273
model initialize at round 2951
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09103691, 14.84627329,  0.98410339,  0.09049468,
       -0.15281109]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5884808460386797
{'scaleFactor': 20, 'currentState': array([27.59432287, 20.0305555 , 13.97178982,  0.73047402,  0.67622519,
        0.09553641]), 'targetState': array([25., 25., 15.])}
episode index:2952
target thresh 33.005557356575025
model initialize at round 2952
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.07623728, 14.84627329,  0.98530926,  0.07587605,
       -0.15299833]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.588281563666164
{'scaleFactor': 20, 'currentState': array([ 2.71025074e+01,  1.33822074e+01,  1.21405268e+01,  9.54174471e-01,
       -2.99032140e-01, -1.14392972e-02]), 'targetState': array([25., 25., 15.])}
episode index:2953
target thresh 33.01225646587832
model initialize at round 2953
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.5883979427400438
{'scaleFactor': 20, 'currentState': array([29.64908331, 20.65312475, 14.79201137,  0.77152636,  0.62186269,
        0.13429024]), 'targetState': array([25., 25., 15.])}
episode index:2954
target thresh 33.01895490530418
model initialize at round 2954
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09120687, 14.84627329,  0.98408833,  0.09066224,
       -0.15280875]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.588517429104396
{'scaleFactor': 20, 'currentState': array([27.14843953, 20.65619469, 12.99702721,  0.64969936,  0.75872015,
        0.04727029]), 'targetState': array([25., 25., 15.])}
episode index:2955
target thresh 33.025652674919584
model initialize at round 2955
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.1291271 , 14.84627329,  0.98005118,  0.12782946,
       -0.15218186]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5886368346254706
{'scaleFactor': 20, 'currentState': array([26.39703999, 21.62110096, 13.29364092,  0.47910768,  0.86681212,
        0.13817587]), 'targetState': array([25., 25., 15.])}
episode index:2956
target thresh 33.03234977479151
model initialize at round 2956
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5887593754490331
{'scaleFactor': 20, 'currentState': array([25.28297937, 20.14478418, 13.62024425,  0.62501983,  0.76833664,
        0.13787321]), 'targetState': array([25., 25., 15.])}
episode index:2957
target thresh 33.039046204986946
model initialize at round 2957
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09865936, 14.84627329,  0.98340111,  0.09800174,
       -0.15270204]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5888786184422556
{'scaleFactor': 20, 'currentState': array([27.08175724, 20.69296238, 14.204699  ,  0.58071969,  0.75096649,
        0.31434689]), 'targetState': array([25., 25., 15.])}
episode index:2958
target thresh 33.04574196557284
model initialize at round 2958
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.1311502 , 14.8816926 ,  0.98445491,  0.13041562,
       -0.11764475]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5889977808386595
{'scaleFactor': 20, 'currentState': array([27.4589889 , 20.35444023, 13.69804394,  0.71881262,  0.66966104,
        0.18671507]), 'targetState': array([25., 25., 15.])}
episode index:2959
target thresh 33.05243705661616
model initialize at round 2959
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.07808441, 14.84627329,  0.98517018,  0.07770347,
       -0.15297674]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.5891136820437501
{'scaleFactor': 20, 'currentState': array([29.4772117 , 20.1242265 , 12.7493102 ,  0.68009075,  0.73161523,
        0.04707163]), 'targetState': array([25., 25., 15.])}
episode index:2960
target thresh 33.059131478183836
model initialize at round 2960
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14288008, 14.84627329,  0.97825962,  0.14118567,
       -0.15190367]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5892358962848363
{'scaleFactor': 20, 'currentState': array([ 2.51992064e+01,  2.00780531e+01,  1.28681487e+01,  5.99445011e-01,
        8.00404398e-01, -4.29862325e-03]), 'targetState': array([25., 25., 15.])}
episode index:2961
target thresh 33.06582523034284
model initialize at round 2961
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5893548173696156
{'scaleFactor': 20, 'currentState': array([26.98778043, 21.20543084, 13.77117793,  0.6789597 ,  0.72043275,
        0.14138732]), 'targetState': array([25., 25., 15.])}
episode index:2962
target thresh 33.07251831316008
model initialize at round 2962
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.07018497, 14.84627329,  0.985742  ,  0.06988311,
       -0.15306553]), 'targetState': array([25., 25., 15.])}
done in step count: 48
reward sum = 0.617290140942288
running average episode reward sum: 0.5893642454234707
{'scaleFactor': 20, 'currentState': array([27.47508012, 28.74385328, 14.83559671,  0.59937784, -0.79055753,
       -0.12555874]), 'targetState': array([25., 25., 15.])}
episode index:2963
target thresh 33.07921072670251
model initialize at round 2963
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12099675, 14.84627329,  0.98102923,  0.11990035,
       -0.15233373]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5894830429619247
{'scaleFactor': 20, 'currentState': array([26.4999617 , 21.33277986, 12.46981882,  0.5089411 ,  0.85691292,
        0.08172634]), 'targetState': array([25., 25., 15.])}
episode index:2964
target thresh 33.085902471037045
model initialize at round 2964
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86525595,  0.97934018,  0.15207146,
       -0.13329319]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.589604967753472
{'scaleFactor': 20, 'currentState': array([25.26572162, 20.18774759, 13.6706092 ,  0.596039  ,  0.80042928,
        0.06364339]), 'targetState': array([25., 25., 15.])}
episode index:2965
target thresh 33.09259354623061
model initialize at round 2965
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5897268103300555
{'scaleFactor': 20, 'currentState': array([25.24035295, 20.17866824, 13.65407677,  0.59693359,  0.78542802,
        0.1636249 ]), 'targetState': array([25., 25., 15.])}
episode index:2966
target thresh 33.0992839523501
model initialize at round 2966
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09540618, 14.85853193,  0.98546959,  0.09496959,
       -0.14082068]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.589845365550504
{'scaleFactor': 20, 'currentState': array([27.09776532, 20.60627299, 12.97677786,  0.5921615 ,  0.80251272,
        0.07292531]), 'targetState': array([25., 25., 15.])}
episode index:2967
target thresh 33.10597368946243
model initialize at round 2967
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12552715, 14.87539613,  0.98441298,  0.12481874,
       -0.12390067]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.58996384088199
{'scaleFactor': 20, 'currentState': array([26.49568814, 21.518547  , 14.67185304,  0.45209808,  0.81717607,
        0.35753406]), 'targetState': array([25., 25., 15.])}
episode index:2968
target thresh 33.1126627576345
model initialize at round 2968
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.96498132,  0.98755478,  0.15334701,
       -0.03493219]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5900854394704097
{'scaleFactor': 20, 'currentState': array([25.36598854, 20.14808449, 15.41282031,  0.57308165,  0.76835828,
        0.28496136]), 'targetState': array([25., 25., 15.])}
episode index:2969
target thresh 33.119351156933206
model initialize at round 2969
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.91366334,  0.98450899,  0.15287407,
       -0.0858578 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5902037541875581
{'scaleFactor': 20, 'currentState': array([27.01096244, 21.07530271, 15.7208445 ,  0.62266421,  0.7364992 ,
        0.26430703]), 'targetState': array([25., 25., 15.])}
episode index:2970
target thresh 33.126038887425416
model initialize at round 2970
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13867171, 14.85351885,  0.97986833,  0.13725254,
       -0.14498206]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5903219892583133
{'scaleFactor': 20, 'currentState': array([26.66578791, 21.22643516, 15.29913784,  0.52336095,  0.76457792,
        0.37618337]), 'targetState': array([25., 25., 15.])}
episode index:2971
target thresh 33.13272594917801
model initialize at round 2971
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.06187127, 14.8476167 ,  0.98648024,  0.0616513 ,
       -0.15184153]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.5901233614019006
{'scaleFactor': 20, 'currentState': array([-0.93471796, 27.46215965,  6.64536419,  0.43424374, -0.8816723 ,
       -0.18462485]), 'targetState': array([25., 25., 15.])}
episode index:2972
target thresh 33.13941234225787
model initialize at round 2972
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.590241543974386
{'scaleFactor': 20, 'currentState': array([26.59501469, 21.4955162 , 14.48147461,  0.50851063,  0.79399342,
        0.33315371]), 'targetState': array([25., 25., 15.])}
episode index:2973
target thresh 33.146098066731845
model initialize at round 2973
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5903628447497477
{'scaleFactor': 20, 'currentState': array([25.26304867, 20.17217205, 14.13024935,  0.57682906,  0.77701793,
        0.25201463]), 'targetState': array([25., 25., 15.])}
episode index:2974
target thresh 33.152783122666804
model initialize at round 2974
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.92318821,  0.98526635,  0.15299167,
       -0.07644451]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5904840639783696
{'scaleFactor': 20, 'currentState': array([25.31420561, 20.1170592 , 15.40817561,  0.55304487,  0.75051719,
        0.36175312]), 'targetState': array([25., 25., 15.])}
episode index:2975
target thresh 33.159467510129595
model initialize at round 2975
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.91509595,  0.98462844,  0.15289261,
       -0.08444338]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5906020062113745
{'scaleFactor': 20, 'currentState': array([26.80361783, 21.18501906, 16.13037723,  0.56726857,  0.76106791,
        0.31461407]), 'targetState': array([25., 25., 15.])}
episode index:2976
target thresh 33.16615122918706
model initialize at round 2976
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10693837, 14.91085454,  0.99025615,  0.10696604,
       -0.08916853]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5907198692087509
{'scaleFactor': 20, 'currentState': array([27.35900579, 20.40375419, 14.29772749,  0.60680857,  0.75837425,
        0.23801651]), 'targetState': array([25., 25., 15.])}
episode index:2977
target thresh 33.17283427990604
model initialize at round 2977
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13980495, 14.91893436,  0.98693683,  0.13937238,
       -0.08081481]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5908408464353093
{'scaleFactor': 20, 'currentState': array([25.38816594, 20.0123173 , 14.95349624,  0.57507436,  0.75346003,
        0.31872788]), 'targetState': array([25., 25., 15.])}
episode index:2978
target thresh 33.17951666235335
model initialize at round 2978
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.51537267e+01,  1.49847518e+01,  9.88043433e-01,
        1.53422893e-01, -1.52180620e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5909617424418433
{'scaleFactor': 20, 'currentState': array([25.38882707, 20.10334529, 14.12292765,  0.61934628,  0.77517178,
        0.12457489]), 'targetState': array([25., 25., 15.])}
episode index:2979
target thresh 33.18619837659583
model initialize at round 2979
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10474104, 14.84627329,  0.9828015 ,  0.10397945,
       -0.15260893]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5910793660683397
{'scaleFactor': 20, 'currentState': array([27.20795681, 20.43252202, 14.04140842,  0.57055618,  0.77210285,
        0.27986218]), 'targetState': array([25., 25., 15.])}
episode index:2980
target thresh 33.19287942270031
model initialize at round 2980
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11326345, 14.84627329,  0.98190298,  0.11233709,
       -0.15246941]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5911969107792865
{'scaleFactor': 20, 'currentState': array([27.31292046, 20.20806405, 14.96433874,  0.57725237,  0.70300643,
        0.41540542]), 'targetState': array([25., 25., 15.])}
episode index:2981
target thresh 33.19955980073357
model initialize at round 2981
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.90553401,  0.98379426,  0.15276308,
       -0.09387383]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5913175657555174
{'scaleFactor': 20, 'currentState': array([25.25013104, 20.0653614 , 15.88002619,  0.52785463,  0.72998869,
        0.43414974]), 'targetState': array([25., 25., 15.])}
episode index:2982
target thresh 33.20623951076242
model initialize at round 2982
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.95274784,  0.98706063,  0.15327028,
       -0.04711187]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5914349518043426
{'scaleFactor': 20, 'currentState': array([26.47284988, 21.37249711, 16.55744266,  0.4486012 ,  0.81854504,
        0.35880494]), 'targetState': array([25., 25., 15.])}
episode index:2983
target thresh 33.21291855285368
model initialize at round 2983
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12625144, 14.89576424,  0.98659986,  0.12581783,
       -0.10387776]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5915522591761914
{'scaleFactor': 20, 'currentState': array([26.75799368, 21.16127059, 15.64806239,  0.52127594,  0.76064724,
        0.38689425]), 'targetState': array([25., 25., 15.])}
episode index:2984
target thresh 33.219596927074114
model initialize at round 2984
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13550423, 14.84627329,  0.97924176,  0.13403172,
       -0.15205617]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5916694879501361
{'scaleFactor': 20, 'currentState': array([27.11071722, 20.88535459, 13.94485249,  0.62019139,  0.76457732,
        0.17545414]), 'targetState': array([25., 25., 15.])}
episode index:2985
target thresh 33.226274633490526
model initialize at round 2985
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.0973168 , 14.84627329,  0.98352879,  0.09668068,
       -0.15272186]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5917866382051431
{'scaleFactor': 20, 'currentState': array([26.83864299, 20.90253545, 13.18753976,  0.54401097,  0.82506784,
        0.15269289]), 'targetState': array([25., 25., 15.])}
episode index:2986
target thresh 33.232951672169676
model initialize at round 2986
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84655203,  0.97676741,  0.15167196,
       -0.15139695]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.591906893783213
{'scaleFactor': 20, 'currentState': array([25.29262439, 20.126617  , 14.45660925,  0.59625337,  0.74278688,
        0.30454813]), 'targetState': array([25., 25., 15.])}
episode index:2987
target thresh 33.23962804317835
model initialize at round 2987
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15241974, 14.84655117,  0.97695757,  0.15041174,
       -0.15142727]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5920238861713046
{'scaleFactor': 20, 'currentState': array([26.53672996, 21.48691617, 15.31362935,  0.48119071,  0.76676691,
        0.42488117]), 'targetState': array([25., 25., 15.])}
episode index:2988
target thresh 33.246303746583294
model initialize at round 2988
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12685628, 14.84627329,  0.98033045,  0.12561725,
       -0.15222522]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5921408002774371
{'scaleFactor': 20, 'currentState': array([26.48334047, 21.53850938, 13.7855262 ,  0.47731521,  0.84716724,
        0.23340493]), 'targetState': array([25., 25., 15.])}
episode index:2989
target thresh 33.25297878245128
model initialize at round 2989
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5922608167488828
{'scaleFactor': 20, 'currentState': array([25.26840467, 20.10868503, 13.26175443,  0.60839176,  0.78778385,
        0.09620848]), 'targetState': array([25., 25., 15.])}
episode index:2990
target thresh 33.259653150849054
model initialize at round 2990
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13404563, 14.84627329,  0.97943015,  0.13261447,
       -0.15208543]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5923775734632433
{'scaleFactor': 20, 'currentState': array([27.13975432, 20.84186308, 14.5475316 ,  0.69124401,  0.663894  ,
        0.28535326]), 'targetState': array([25., 25., 15.])}
episode index:2991
target thresh 33.26632685184335
model initialize at round 2991
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.03288809, 14.85868237,  0.9894301 ,  0.03286916,
       -0.14123628]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.5924911054734183
{'scaleFactor': 20, 'currentState': array([28.59919059, 21.3341591 , 12.9358184 ,  0.53005334,  0.83511   ,
        0.14708754]), 'targetState': array([25., 25., 15.])}
episode index:2992
target thresh 33.27299988550093
model initialize at round 2992
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5926108846062036
{'scaleFactor': 20, 'currentState': array([25.01760399, 20.11575608, 12.20560084,  0.56615486,  0.7957178 ,
       -0.21517865]), 'targetState': array([25., 25., 15.])}
episode index:2993
target thresh 33.279672251888506
model initialize at round 2993
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5927305837262082
{'scaleFactor': 20, 'currentState': array([25.26483639, 20.17774092, 13.89150791,  0.5876271 ,  0.78661718,
        0.1895463 ]), 'targetState': array([25., 25., 15.])}
episode index:2994
target thresh 33.286343951072794
model initialize at round 2994
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5928502029135784
{'scaleFactor': 20, 'currentState': array([25.20167431, 20.17524107, 13.24885987,  0.60496755,  0.78799929,
        0.11433017]), 'targetState': array([25., 25., 15.])}
episode index:2995
target thresh 33.293014983120514
model initialize at round 2995
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09848293, 14.91476049,  0.9914562 ,  0.09862779,
       -0.08536489]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5929665680492552
{'scaleFactor': 20, 'currentState': array([27.06076925, 20.51886711, 16.49505533,  0.61285462,  0.70127807,
        0.36416793]), 'targetState': array([25., 25., 15.])}
episode index:2996
target thresh 33.29968534809839
model initialize at round 2996
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.07949064, 14.91525158,  0.99318276,  0.07974619,
       -0.08502088]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.5930797141219472
{'scaleFactor': 20, 'currentState': array([29.05392051, 20.81941577, 15.65960964,  0.57013649,  0.71041496,
        0.41261964]), 'targetState': array([25., 25., 15.])}
episode index:2997
target thresh 33.306355046073136
model initialize at round 2997
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13277264, 14.92888593,  0.98862391,  0.13258809,
       -0.07101522]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5931959250743417
{'scaleFactor': 20, 'currentState': array([27.29198229, 20.44865965, 15.45936626,  0.59347847,  0.7095602 ,
        0.37987844]), 'targetState': array([25., 25., 15.])}
episode index:2998
target thresh 33.31302407711142
model initialize at round 2998
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85043282,  0.97732695,  0.15175884,
       -0.14765256]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5933152295507756
{'scaleFactor': 20, 'currentState': array([25.29735269, 20.17224235, 14.26785186,  0.57881618,  0.77747595,
        0.24597354]), 'targetState': array([25., 25., 15.])}
episode index:2999
target thresh 33.31969244127995
model initialize at round 2999
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.593434454490892
{'scaleFactor': 20, 'currentState': array([25.31543559, 20.14395724, 14.32164609,  0.5905852 ,  0.77791535,
        0.21460856]), 'targetState': array([25., 25., 15.])}
episode index:3000
target thresh 33.32636013864539
model initialize at round 3000
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89413937,  0.98268733,  0.1525912 ,
       -0.10507869]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5935535999742007
{'scaleFactor': 20, 'currentState': array([25.29296004, 20.08475436, 15.48118128,  0.55768019,  0.73197995,
        0.39140537]), 'targetState': array([25., 25., 15.])}
episode index:3001
target thresh 33.333027169274445
model initialize at round 3001
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14644532, 14.92138802,  0.98619761,  0.14588286,
       -0.07831005]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5936694982251756
{'scaleFactor': 20, 'currentState': array([26.58428933, 21.22371102, 16.60125347,  0.47348906,  0.76800085,
        0.43125725]), 'targetState': array([25., 25., 15.])}
episode index:3002
target thresh 33.33969353323376
model initialize at round 3002
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13534328, 14.93480932,  0.98868216,  0.13516312,
       -0.0651039 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5937853192878382
{'scaleFactor': 20, 'currentState': array([27.03629781, 20.74146989, 15.94917555,  0.55955944,  0.7350787 ,
        0.38282182]), 'targetState': array([25., 25., 15.])}
episode index:3003
target thresh 33.346359230590004
model initialize at round 3003
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10362489, 14.8734527 ,  0.98662543,  0.10327167,
       -0.12611595]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.593901063239274
{'scaleFactor': 20, 'currentState': array([26.9736449 , 20.79509419, 14.89464298,  0.51703064,  0.77222461,
        0.36925395]), 'targetState': array([25., 25., 15.])}
episode index:3004
target thresh 33.35302426140986
model initialize at round 3004
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89666313,  0.98294303,  0.1526309 ,
       -0.10260025]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5940198948488117
{'scaleFactor': 20, 'currentState': array([25.2941929 , 20.10273726, 15.43464584,  0.55395445,  0.74734954,
        0.36688299]), 'targetState': array([25., 25., 15.])}
episode index:3005
target thresh 33.359688625759944
model initialize at round 3005
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.90169607,  0.98343508,  0.15270731,
       -0.09765205]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5941386473954022
{'scaleFactor': 20, 'currentState': array([25.3047195 , 20.12250385, 15.20468623,  0.55451743,  0.75224068,
        0.3558713 ]), 'targetState': array([25., 25., 15.])}
episode index:3006
target thresh 33.36635232370691
model initialize at round 3006
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.51537267e+01,  1.49923457e+01,  9.88129025e-01,
        1.53436184e-01, -7.63980175e-03]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5942541583704624
{'scaleFactor': 20, 'currentState': array([26.646426  , 21.3461811 , 16.68034641,  0.52354323,  0.77099431,
        0.36258829]), 'targetState': array([25., 25., 15.])}
episode index:3007
target thresh 33.37301535531741
model initialize at round 3007
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.03902108, 14.85704166,  0.98898201,  0.03898096,
       -0.14281133]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.5940566004720679
{'scaleFactor': 20, 'currentState': array([ 9.2909303 , 46.61147595,  6.28371618,  0.0872434 , -0.94247956,
        0.32267764]), 'targetState': array([25., 25., 15.])}
episode index:3008
target thresh 33.379677720658066
model initialize at round 3008
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.91799199,  0.98486393,  0.15292918,
       -0.08158255]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5941720619373152
{'scaleFactor': 20, 'currentState': array([27.2889531 , 20.56838507, 15.59257453,  0.60526882,  0.7068373 ,
        0.36610202]), 'targetState': array([25., 25., 15.])}
episode index:3009
target thresh 33.38633941979548
model initialize at round 3009
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.0993425 , 14.84627329,  0.98333549,  0.09867374,
       -0.15269185]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.594284318842953
{'scaleFactor': 20, 'currentState': array([29.11635132, 21.05206331, 14.8524495 ,  0.57883195,  0.74159261,
        0.33910761]), 'targetState': array([25., 25., 15.])}
episode index:3010
target thresh 33.393000452796315
model initialize at round 3010
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5944027863723641
{'scaleFactor': 20, 'currentState': array([2.51729263e+01, 2.01791043e+01, 1.29877282e+01, 5.92315515e-01,
       8.05705265e-01, 1.16510054e-03]), 'targetState': array([25., 25., 15.])}
episode index:3011
target thresh 33.39966081972713
model initialize at round 3011
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13839255, 14.84627329,  0.97886301,  0.13683571,
       -0.15199736]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5945211752380771
{'scaleFactor': 20, 'currentState': array([25.35201597, 20.00882074, 14.57670606,  0.5770071 ,  0.75557459,
        0.31011263]), 'targetState': array([25., 25., 15.])}
episode index:3012
target thresh 33.40632052065457
model initialize at round 3012
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.93986043,  0.98638234,  0.15316496,
       -0.0599198 ]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5946394855184163
{'scaleFactor': 20, 'currentState': array([25.32590515, 20.14200548, 14.95167562,  0.56606995,  0.76225208,
        0.31390537]), 'targetState': array([25., 25., 15.])}
episode index:3013
target thresh 33.41297955564521
model initialize at round 3013
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.88464169,  0.98167176,  0.1524335 ,
       -0.11438787]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5947577172916019
{'scaleFactor': 20, 'currentState': array([25.30555846, 20.12242344, 15.2447431 ,  0.55593704,  0.75397291,
        0.34994122]), 'targetState': array([25., 25., 15.])}
episode index:3014
target thresh 33.41963792476563
model initialize at round 3014
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87456115,  0.98050237,  0.15225192,
       -0.12423544]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5948758706357505
{'scaleFactor': 20, 'currentState': array([25.27955565, 20.13810478, 14.73287377,  0.56123568,  0.75929933,
        0.32936158]), 'targetState': array([25., 25., 15.])}
episode index:3015
target thresh 33.42629562808245
model initialize at round 3015
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5949939456288753
{'scaleFactor': 20, 'currentState': array([25.27314761, 20.1414303 , 14.69537369,  0.56105748,  0.75988816,
        0.32830547]), 'targetState': array([25., 25., 15.])}
episode index:3016
target thresh 33.43295266566221
model initialize at round 3016
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.93924555,  0.98634594,  0.15315931,
       -0.0605302 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5951087902439804
{'scaleFactor': 20, 'currentState': array([26.39667605, 21.379667  , 17.00946538,  0.46033556,  0.78573296,
        0.41317658]), 'targetState': array([25., 25., 15.])}
episode index:3017
target thresh 33.43960903757151
model initialize at round 3017
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14093221, 14.9220024 ,  0.98702097,  0.14050813,
       -0.0777629 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5952235587526475
{'scaleFactor': 20, 'currentState': array([27.07103513, 20.99910802, 14.94694003,  0.61849424,  0.71721108,
        0.32105007]), 'targetState': array([25., 25., 15.])}
episode index:3018
target thresh 33.44626474387689
model initialize at round 3018
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12990743, 14.86021999,  0.98192525,  0.12884786,
       -0.13863992]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.595338251230504
{'scaleFactor': 20, 'currentState': array([26.87367554, 21.13943039, 15.09832433,  0.61707029,  0.72378282,
        0.3088085 ]), 'targetState': array([25., 25., 15.])}
episode index:3019
target thresh 33.452919784644905
model initialize at round 3019
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.06100612, 14.84627329,  0.98633094,  0.06078003,
       -0.15315698]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.5954497502691386
{'scaleFactor': 20, 'currentState': array([29.44478789, 20.04682718, 15.38501895,  0.76625892,  0.52800036,
        0.36614599]), 'targetState': array([25., 25., 15.])}
episode index:3020
target thresh 33.45957415994213
model initialize at round 3020
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.0453575 , 14.86984484,  0.99044696,  0.04537798,
       -0.13021392]), 'targetState': array([25., 25., 15.])}
done in step count: 45
reward sum = 0.6361854860638709
running average episode reward sum: 0.5954632344584119
{'scaleFactor': 20, 'currentState': array([26.24063247, 29.82803565, 12.72677199,  0.27706028, -0.95891532,
        0.06098374]), 'targetState': array([25., 25., 15.])}
episode index:3021
target thresh 33.466227869835095
model initialize at round 3021
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5955777337684525
{'scaleFactor': 20, 'currentState': array([26.67435172, 21.46998054, 13.46104897,  0.53726172,  0.82366788,
        0.18144165]), 'targetState': array([25., 25., 15.])}
episode index:3022
target thresh 33.472880914390345
model initialize at round 3022
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86805663,  0.97969828,  0.15212706,
       -0.1305704 ]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5956953031750458
{'scaleFactor': 20, 'currentState': array([25.27872784, 20.10507654, 15.34407902,  0.5488916 ,  0.74887969,
        0.37134515]), 'targetState': array([25., 25., 15.])}
episode index:3023
target thresh 33.4795332936744
model initialize at round 3023
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89093956,  0.98235458,  0.15253953,
       -0.10821821]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5958127948240951
{'scaleFactor': 20, 'currentState': array([25.29541599, 20.10294483, 15.43710098,  0.54934983,  0.74286628,
        0.38257607]), 'targetState': array([25., 25., 15.])}
episode index:3024
target thresh 33.486185007753775
model initialize at round 3024
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14732121, 14.94646361,  0.98769657,  0.14697843,
       -0.05341183]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.5959239526928828
{'scaleFactor': 20, 'currentState': array([29.19884116, 20.97614706, 16.79808211,  0.75176079,  0.59525784,
        0.2837672 ]), 'targetState': array([25., 25., 15.])}
episode index:3025
target thresh 33.49283605669502
model initialize at round 3025
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.50130976e+01,  1.48926357e+01,  9.94084811e-01,
        1.31516230e-02, -1.07807342e-01]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.5957270181414311
{'scaleFactor': 20, 'currentState': array([ 1.22861226e+01,  1.29367987e+01,  5.18271542e+00,  7.72143109e-01,
       -6.35443583e-01, -2.54417995e-03]), 'targetState': array([25., 25., 15.])}
episode index:3026
target thresh 33.49948644056461
model initialize at round 3026
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10441586, 14.84627329,  0.98283444,  0.10366011,
       -0.15261404]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5958412411778565
{'scaleFactor': 20, 'currentState': array([27.16487254, 20.4032966 , 12.46129033,  0.61399729,  0.78387287,
       -0.09246966]), 'targetState': array([25., 25., 15.])}
episode index:3027
target thresh 33.506136159429076
model initialize at round 3027
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09758723, 14.84627329,  0.98350321,  0.09694682,
       -0.15271789]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.5959522795222189
{'scaleFactor': 20, 'currentState': array([29.30927744, 20.4533892 , 14.51663421,  0.63150133,  0.6868588 ,
        0.35976528]), 'targetState': array([25., 25., 15.])}
episode index:3028
target thresh 33.51278521335489
model initialize at round 3028
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13577312, 14.84627329,  0.97920682,  0.1342929 ,
       -0.15205075]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5960663527707758
{'scaleFactor': 20, 'currentState': array([ 2.68790577e+01,  2.09879788e+01,  1.27140002e+01,  6.23988945e-01,
        7.81414590e-01, -5.38842689e-03]), 'targetState': array([25., 25., 15.])}
episode index:3029
target thresh 33.519433602408554
model initialize at round 3029
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.04425318, 14.84627329,  0.98719529,  0.04412781,
       -0.15329119]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.5958696312022046
{'scaleFactor': 20, 'currentState': array([-5.1454239 , 34.08175374, -2.67586573,  0.20823417, -0.97208308,
       -0.10813424]), 'targetState': array([25., 25., 15.])}
episode index:3030
target thresh 33.526081326656566
model initialize at round 3030
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.595986793992933
{'scaleFactor': 20, 'currentState': array([25.35795603, 20.05236047, 14.10345972,  0.59619128,  0.7698256 ,
        0.22786949]), 'targetState': array([25., 25., 15.])}
episode index:3031
target thresh 33.53272838616539
model initialize at round 3031
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85965915,  0.97860327,  0.15195703,
       -0.13872527]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5961038794994986
{'scaleFactor': 20, 'currentState': array([25.41162625, 20.06968889, 14.40758577,  0.62120916,  0.75746075,
        0.20087905]), 'targetState': array([25., 25., 15.])}
episode index:3032
target thresh 33.5393747810015
model initialize at round 3032
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5962208877983448
{'scaleFactor': 20, 'currentState': array([25.27652636, 20.14664225, 14.02876036,  0.58733723,  0.77078122,
        0.24684263]), 'targetState': array([25., 25., 15.])}
episode index:3033
target thresh 33.54602051123135
model initialize at round 3033
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.07354784, 14.95070667,  0.99602469,  0.07399542,
       -0.0495933 ]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.5963315814239574
{'scaleFactor': 20, 'currentState': array([28.62404109, 21.16945969, 16.63285468,  0.46508723,  0.7861516 ,
        0.40701294]), 'targetState': array([25., 25., 15.])}
episode index:3034
target thresh 33.55266557692139
model initialize at round 3034
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.88491277,  0.98170191,  0.15243818,
       -0.11412258]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5964453041811162
{'scaleFactor': 20, 'currentState': array([26.70040346, 21.24348473, 15.62690184,  0.51177134,  0.7180521 ,
        0.4716898 ]), 'targetState': array([25., 25., 15.])}
episode index:3035
target thresh 33.55930997813811
model initialize at round 3035
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11125091, 14.89759496,  0.98853629,  0.11108642,
       -0.10225364]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5965589520220976
{'scaleFactor': 20, 'currentState': array([26.82753115, 20.98352905, 14.73475832,  0.49428601,  0.7865527 ,
        0.37015698]), 'targetState': array([25., 25., 15.])}
episode index:3036
target thresh 33.565953714947916
model initialize at round 3036
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.02217933,  0.98791581,  0.15340308,
        0.02213264]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5966756563677933
{'scaleFactor': 20, 'currentState': array([25.21481006, 20.03564386, 16.63685025,  0.51710548,  0.72405414,
        0.45645102]), 'targetState': array([25., 25., 15.])}
episode index:3037
target thresh 33.57259678741726
model initialize at round 3037
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.51537267e+01,  1.49857821e+01,  9.88058373e-01,
        1.53425213e-01, -1.41899806e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5967891535676068
{'scaleFactor': 20, 'currentState': array([26.2063948 , 21.48891879, 17.66873447,  0.42332314,  0.83542341,
        0.3505214 ]), 'targetState': array([25., 25., 15.])}
episode index:3038
target thresh 33.57923919561257
model initialize at round 3038
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.93942315,  0.98635649,  0.15316095,
       -0.06035391]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.596905705359753
{'scaleFactor': 20, 'currentState': array([25.3497469 , 20.08920374, 15.51561724,  0.58652731,  0.7288198 ,
        0.35328091]), 'targetState': array([25., 25., 15.])}
episode index:3039
target thresh 33.58588093960028
model initialize at round 3039
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12095776, 14.8594446 ,  0.98290612,  0.12009103,
       -0.13954825]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5970190522163455
{'scaleFactor': 20, 'currentState': array([26.54017321, 21.44308705, 15.09086788,  0.46123288,  0.80969784,
        0.36284107]), 'targetState': array([25., 25., 15.])}
episode index:3040
target thresh 33.592522019446804
model initialize at round 3040
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5971323245271594
{'scaleFactor': 20, 'currentState': array([26.98956756, 20.91396764, 15.28529466,  0.56227259,  0.69767927,
        0.44395176]), 'targetState': array([25., 25., 15.])}
episode index:3041
target thresh 33.599162435218524
model initialize at round 3041
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15362127, 14.94024464,  0.98642076,  0.15306587,
       -0.05953932]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5972486485657434
{'scaleFactor': 20, 'currentState': array([25.39237292, 20.10180543, 14.46785625,  0.59855615,  0.78253246,
        0.17138694]), 'targetState': array([25., 25., 15.])}
episode index:3042
target thresh 33.60580218698188
model initialize at round 3042
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5973648961508023
{'scaleFactor': 20, 'currentState': array([25.36522844, 20.06141244, 14.38574814,  0.61384544,  0.73647594,
        0.28424807]), 'targetState': array([25., 25., 15.])}
episode index:3043
target thresh 33.61244127480326
model initialize at round 3043
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09941721, 14.9570939 ,  0.99407175,  0.0998261 ,
       -0.04308256]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5974779432116598
{'scaleFactor': 20, 'currentState': array([27.23803471, 20.52759209, 15.77305332,  0.57526303,  0.69660539,
        0.42873461]), 'targetState': array([25., 25., 15.])}
episode index:3044
target thresh 33.619079698749054
model initialize at round 3044
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.92483089,  0.98538819,  0.15301059,
       -0.07481894]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5975909160215742
{'scaleFactor': 20, 'currentState': array([26.9214566 , 21.10633023, 15.74442225,  0.61245863,  0.66309279,
        0.43035146]), 'targetState': array([25., 25., 15.])}
episode index:3045
target thresh 33.62571745888564
model initialize at round 3045
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.04743245, 14.84627329,  0.98705226,  0.04729122,
       -0.15326898]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.5977007237799082
{'scaleFactor': 20, 'currentState': array([29.21285046, 20.45541517, 15.10359238,  0.5686644 ,  0.72553472,
        0.38758247]), 'targetState': array([25., 25., 15.])}
episode index:3046
target thresh 33.6323545552794
model initialize at round 3046
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.597816670391697
{'scaleFactor': 20, 'currentState': array([25.21478065, 20.16737705, 13.08308193,  0.60656388,  0.79458225,
       -0.02681975]), 'targetState': array([25., 25., 15.])}
episode index:3047
target thresh 33.6389909879967
model initialize at round 3047
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09283489, 14.84627329,  0.98394269,  0.09226688,
       -0.15278613]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5979294208769362
{'scaleFactor': 20, 'currentState': array([27.28929626, 20.26019855, 13.49984531,  0.60230757,  0.77140785,
        0.2053181 ]), 'targetState': array([25., 25., 15.])}
episode index:3048
target thresh 33.64562675710392
model initialize at round 3048
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89432628,  0.98270647,  0.15259417,
       -0.10489521]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5980452164259763
{'scaleFactor': 20, 'currentState': array([25.30342452, 20.13295942, 14.9999814 ,  0.55935353,  0.75693386,
        0.33789755]), 'targetState': array([25., 25., 15.])}
episode index:3049
target thresh 33.6522618626674
model initialize at round 3049
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.92054989,  0.98506525,  0.15296044,
       -0.07905409]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5981609360435087
{'scaleFactor': 20, 'currentState': array([25.33165839, 20.0717679 , 15.53992988,  0.55299753,  0.74281398,
        0.37738722]), 'targetState': array([25., 25., 15.])}
episode index:3050
target thresh 33.6588963047535
model initialize at round 3050
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.90602247,  0.98383897,  0.15277003,
       -0.09339269]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5982765798041958
{'scaleFactor': 20, 'currentState': array([25.35833145, 20.07392823, 15.31658437,  0.5766778 ,  0.74509285,
        0.33508111]), 'targetState': array([25., 25., 15.])}
episode index:3051
target thresh 33.665530083428564
model initialize at round 3051
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87191535,  0.98017997,  0.15220186,
       -0.12681415]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.598392147782602
{'scaleFactor': 20, 'currentState': array([25.3996028 , 20.04436255, 14.55749764,  0.59953152,  0.77559689,
        0.1975131 ]), 'targetState': array([25., 25., 15.])}
episode index:3052
target thresh 33.67216319875893
model initialize at round 3052
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5985076400531939
{'scaleFactor': 20, 'currentState': array([25.28479997, 20.14971402, 14.34378093,  0.58722943,  0.76073547,
        0.27648353]), 'targetState': array([25., 25., 15.])}
episode index:3053
target thresh 33.67879565081093
model initialize at round 3053
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89068714,  0.98232792,  0.15253539,
       -0.10846573]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.598619942774002
{'scaleFactor': 20, 'currentState': array([27.21134904, 20.67041294, 16.04201184,  0.68706606,  0.64257873,
        0.33916487]), 'targetState': array([25., 25., 15.])}
episode index:3054
target thresh 33.68542743965087
model initialize at round 3054
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10612325, 14.88239121,  0.98743896,  0.10584872,
       -0.11730455]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5987321719742073
{'scaleFactor': 20, 'currentState': array([27.27863486, 20.23791269, 15.68462029,  0.61690215,  0.62969483,
        0.47213997]), 'targetState': array([25., 25., 15.])}
episode index:3055
target thresh 33.69205856534509
model initialize at round 3055
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.07202416, 14.93673734,  0.9953446 ,  0.07241299,
       -0.06360419]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.5985362517608649
{'scaleFactor': 20, 'currentState': array([62.15424726, 71.07178523,  5.80417371, -0.85730163,  0.41809566,
       -0.30038298]), 'targetState': array([25., 25., 15.])}
episode index:3056
target thresh 33.69868902795991
model initialize at round 3056
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11769258, 14.84627329,  0.98140932,  0.1166713 ,
       -0.15239275]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5986484349135113
{'scaleFactor': 20, 'currentState': array([27.18926075, 20.50687542, 14.61973375,  0.58857471,  0.71059408,
        0.38553321]), 'targetState': array([25., 25., 15.])}
episode index:3057
target thresh 33.70531882756161
model initialize at round 3057
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89430008,  0.98270379,  0.15259376,
       -0.10492092]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5987636545390791
{'scaleFactor': 20, 'currentState': array([25.31774898, 20.15795759, 14.66132412,  0.58125274,  0.78001274,
        0.23178736]), 'targetState': array([25., 25., 15.])}
episode index:3058
target thresh 33.71194796421649
model initialize at round 3058
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5988787988330839
{'scaleFactor': 20, 'currentState': array([25.19587739, 20.18861481, 13.23496515,  0.5934203 ,  0.80386152,
        0.04073078]), 'targetState': array([25., 25., 15.])}
episode index:3059
target thresh 33.718576437990855
model initialize at round 3059
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5989938678693802
{'scaleFactor': 20, 'currentState': array([25.20462692, 20.19006238, 13.3758117 ,  0.59017839,  0.79823451,
        0.12046217]), 'targetState': array([25., 25., 15.])}
episode index:3060
target thresh 33.72520424895099
model initialize at round 3060
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5991088617217261
{'scaleFactor': 20, 'currentState': array([25.26912454, 20.11246082, 15.13052816,  0.54811331,  0.74741605,
        0.37542116]), 'targetState': array([25., 25., 15.])}
episode index:3061
target thresh 33.73183139716316
model initialize at round 3061
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.94870963,  0.98686546,  0.15323998,
       -0.05112797]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.599223780463783
{'scaleFactor': 20, 'currentState': array([25.28944882, 20.08915462, 15.78590323,  0.5394324 ,  0.73897375,
        0.40364649]), 'targetState': array([25., 25., 15.])}
episode index:3062
target thresh 33.73845788269365
model initialize at round 3062
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.8673835 ,  0.97961287,  0.1521138 ,
       -0.13122508]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5993355194023848
{'scaleFactor': 20, 'currentState': array([26.8862039 , 21.35712274, 15.07832915,  0.7050204 ,  0.66924693,
        0.23463755]), 'targetState': array([25., 25., 15.])}
episode index:3063
target thresh 33.7450837056087
model initialize at round 3063
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.0202921 , 14.84627329,  0.98795524,  0.02025019,
       -0.1534092 ]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.5991399138151126
{'scaleFactor': 20, 'currentState': array([17.42385233, 30.27788261,  7.62472879,  0.32305086, -0.92780705,
        0.18658031]), 'targetState': array([25., 25., 15.])}
episode index:3064
target thresh 33.75170886597461
model initialize at round 3064
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.06634205, 14.84627329,  0.98599847,  0.0660739 ,
       -0.15310535]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.5992485354901833
{'scaleFactor': 20, 'currentState': array([28.9686484 , 20.75559977, 15.33611865,  0.56474493,  0.71318809,
        0.41524199]), 'targetState': array([25., 25., 15.])}
episode index:3065
target thresh 33.758333363857595
model initialize at round 3065
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5993632587499387
{'scaleFactor': 20, 'currentState': array([25.14322378, 20.06172019, 12.476344  ,  0.60838276,  0.78132226,
       -0.13930525]), 'targetState': array([25., 25., 15.])}
episode index:3066
target thresh 33.764957199323916
model initialize at round 3066
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09991536, 14.84627329,  0.98328013,  0.09923716,
       -0.15268325]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5994748064808324
{'scaleFactor': 20, 'currentState': array([26.92663818, 20.81025052, 14.10505924,  0.52623977,  0.78740803,
        0.32103005]), 'targetState': array([25., 25., 15.])}
episode index:3067
target thresh 33.771580372439814
model initialize at round 3067
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.88863536,  0.98210904,  0.1525014 ,
       -0.11047699]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5995862814948221
{'scaleFactor': 20, 'currentState': array([26.4277251 , 21.45537595, 16.09310525,  0.44822791,  0.74640809,
        0.49190111]), 'targetState': array([25., 25., 15.])}
episode index:3068
target thresh 33.77820288327151
model initialize at round 3068
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09541493, 14.8539645 ,  0.98482827,  0.09491649,
       -0.14527261]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5996976838629897
{'scaleFactor': 20, 'currentState': array([27.04758685, 20.48990819, 15.42346908,  0.51460581,  0.72541085,
        0.45712138]), 'targetState': array([25., 25., 15.])}
episode index:3069
target thresh 33.78482473188523
model initialize at round 3069
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.93986293,  0.98638248,  0.15316498,
       -0.05991733]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5998090136563247
{'scaleFactor': 20, 'currentState': array([26.59908522, 21.25149002, 16.21135368,  0.4339073 ,  0.75549195,
        0.49087306]), 'targetState': array([25., 25., 15.])}
episode index:3070
target thresh 33.79144591834719
model initialize at round 3070
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.92995395,  0.98575152,  0.15306701,
       -0.06974545]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.5999202709457239
{'scaleFactor': 20, 'currentState': array([27.08169789, 20.92501696, 15.72893786,  0.58806171,  0.7270577 ,
        0.35435933]), 'targetState': array([25., 25., 15.])}
episode index:3071
target thresh 33.79806644272363
model initialize at round 3071
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13914816, 14.84627329,  0.97876268,  0.13756871,
       -0.15198178]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6000314558019919
{'scaleFactor': 20, 'currentState': array([27.36329126, 20.51514822, 14.20766029,  0.64487034,  0.71337618,
        0.27429303]), 'targetState': array([25., 25., 15.])}
episode index:3072
target thresh 33.80468630508072
model initialize at round 3072
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.88718216,  0.98195164,  0.15247696,
       -0.11190067]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6001456629591991
{'scaleFactor': 20, 'currentState': array([25.27594036, 20.09326315, 15.53346504,  0.54037346,  0.74021978,
        0.40008899]), 'targetState': array([25., 25., 15.])}
episode index:3073
target thresh 33.81130550548468
model initialize at round 3073
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.88046947,  0.98119914,  0.15236011,
       -0.11846793]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6002597958111642
{'scaleFactor': 20, 'currentState': array([25.26374198, 20.18378644, 13.72939853,  0.58935899,  0.79203899,
        0.15915473]), 'targetState': array([25., 25., 15.])}
episode index:3074
target thresh 33.81792404400169
model initialize at round 3074
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11160093, 14.84627329,  0.98208358,  0.11070852,
       -0.15249745]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.611117239532865
running average episode reward sum: 0.6002633266871713
{'scaleFactor': 20, 'currentState': array([28.58482289, 21.42070172, 10.92302805,  0.7803861 ,  0.28269188,
        0.557748  ]), 'targetState': array([25., 25., 15.])}
episode index:3075
target thresh 33.82454192069794
model initialize at round 3075
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09689263, 14.84627329,  0.98356877,  0.0962632 ,
       -0.15272807]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6003742554331771
{'scaleFactor': 20, 'currentState': array([27.15956954, 20.45830078, 14.07877335,  0.5624005 ,  0.76595366,
        0.31148141]), 'targetState': array([25., 25., 15.])}
episode index:3076
target thresh 33.83115913563961
model initialize at round 3076
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.88938953,  0.98218995,  0.15251397,
       -0.10973787]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6004882027176968
{'scaleFactor': 20, 'currentState': array([25.28716505, 20.1028182 , 15.58199637,  0.55998273,  0.76187485,
        0.32552427]), 'targetState': array([25., 25., 15.])}
episode index:3077
target thresh 33.837775688892854
model initialize at round 3077
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6005989863261059
{'scaleFactor': 20, 'currentState': array([26.66062244, 21.40976445, 15.31857643,  0.55990782,  0.7282085 ,
        0.39524121]), 'targetState': array([25., 25., 15.])}
episode index:3078
target thresh 33.84439158052389
model initialize at round 3078
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09360838, 14.88363529,  0.98881252,  0.0934961 ,
       -0.11622513]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.6004039233230769
{'scaleFactor': 20, 'currentState': array([27.26354985, 27.01400596,  2.22790216,  0.80301718, -0.58467868,
        0.11538737]), 'targetState': array([25., 25., 15.])}
episode index:3079
target thresh 33.85100681059882
model initialize at round 3079
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14090128, 14.84627329,  0.97852792,  0.13926852,
       -0.15194533]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6005177499875499
{'scaleFactor': 20, 'currentState': array([25.36122868, 20.0010119 , 13.50397083,  0.63694584,  0.76160305,
        0.11941851]), 'targetState': array([25., 25., 15.])}
episode index:3080
target thresh 33.85762137918381
model initialize at round 3080
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84729772,  0.97687597,  0.15168881,
       -0.15067796]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6006284161347143
{'scaleFactor': 20, 'currentState': array([26.78209484, 21.35273476, 15.09912296,  0.53654652,  0.77716264,
        0.32884049]), 'targetState': array([25., 25., 15.])}
episode index:3081
target thresh 33.86423528634502
model initialize at round 3081
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85961657,  0.97859756,  0.15195614,
       -0.13876655]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.600739010467377
{'scaleFactor': 20, 'currentState': array([26.32599066, 21.50277073, 16.14493617,  0.39348888,  0.76282092,
        0.51309915]), 'targetState': array([25., 25., 15.])}
episode index:3082
target thresh 33.87084853214859
model initialize at round 3082
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.92085079,  0.98508853,  0.15296406,
       -0.07875655]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6008495330554191
{'scaleFactor': 20, 'currentState': array([26.77733045, 21.14653506, 16.22080686,  0.55527412,  0.69525204,
        0.45639374]), 'targetState': array([25., 25., 15.])}
episode index:3083
target thresh 33.87746111666065
model initialize at round 3083
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.06361713, 14.86843229,  0.98927947,  0.06357083,
       -0.13147196]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6009569311795603
{'scaleFactor': 20, 'currentState': array([29.16646475, 20.73678636, 14.4104623 ,  0.58235414,  0.77628967,
        0.24132551]), 'targetState': array([25., 25., 15.])}
episode index:3084
target thresh 33.8840730399473
model initialize at round 3084
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14406888, 14.84627329,  0.97809674,  0.14233667,
       -0.15187838]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6010673114772009
{'scaleFactor': 20, 'currentState': array([26.51090739, 21.44493513, 15.19166133,  0.44580401,  0.78941717,
        0.42199444]), 'targetState': array([25., 25., 15.])}
episode index:3085
target thresh 33.89068430207469
model initialize at round 3085
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87007529,  0.97995197,  0.15216645,
       -0.12860604]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6011807018655427
{'scaleFactor': 20, 'currentState': array([25.28947285, 20.18674627, 13.79361484,  0.59568308,  0.79829853,
        0.08877573]), 'targetState': array([25., 25., 15.])}
episode index:3086
target thresh 33.89729490310892
model initialize at round 3086
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14144956, 14.84627329,  0.97845394,  0.13979987,
       -0.15193384]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6012909381621205
{'scaleFactor': 20, 'currentState': array([26.49601334, 21.60702635, 13.50836754,  0.51354848,  0.83077423,
        0.21466751]), 'targetState': array([25., 25., 15.])}
episode index:3087
target thresh 33.90390484311611
model initialize at round 3087
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12935204, 14.84627329,  0.98002326,  0.1280485 ,
       -0.15217752]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6014011030621331
{'scaleFactor': 20, 'currentState': array([26.93686304, 20.88780366, 14.56447066,  0.51647471,  0.78292261,
        0.34682282]), 'targetState': array([25., 25., 15.])}
episode index:3088
target thresh 33.910514122162326
model initialize at round 3088
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.88246343,  0.98142702,  0.1523955 ,
       -0.11651875]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.60151119663492
{'scaleFactor': 20, 'currentState': array([26.38912238, 21.38871561, 16.53704062,  0.42935053,  0.7355388 ,
        0.52406183]), 'targetState': array([25., 25., 15.])}
episode index:3089
target thresh 33.9171227403137
model initialize at round 3089
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15048305, 14.86760047,  0.98011406,  0.14898036,
       -0.13107742]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6016212189497311
{'scaleFactor': 20, 'currentState': array([26.81737117, 21.42484635, 14.53993753,  0.56658667,  0.80302991,
        0.18472276]), 'targetState': array([25., 25., 15.])}
episode index:3090
target thresh 33.9237306976363
model initialize at round 3090
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13013763, 14.84627329,  0.97992539,  0.1288133 ,
       -0.15216233]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6017311700757264
{'scaleFactor': 20, 'currentState': array([26.33630819, 21.63741495, 13.06492146,  0.47084485,  0.86210228,
        0.18730933]), 'targetState': array([25., 25., 15.])}
episode index:3091
target thresh 33.930337994196194
model initialize at round 3091
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.88410238,  0.98161157,  0.15242416,
       -0.1149156 ]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6018441257289684
{'scaleFactor': 20, 'currentState': array([25.30473153, 20.18412293, 13.9595365 ,  0.59771878,  0.79890662,
        0.0669364 ]), 'targetState': array([25., 25., 15.])}
episode index:3092
target thresh 33.93694463005947
model initialize at round 3092
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6019570083426674
{'scaleFactor': 20, 'currentState': array([25.22512727, 20.18853805, 13.59244763,  0.58663287,  0.79170899,
        0.17046625]), 'targetState': array([25., 25., 15.])}
episode index:3093
target thresh 33.9435506052922
model initialize at round 3093
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.88638537,  0.9818645 ,  0.15246343,
       -0.11268098]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6020667443287884
{'scaleFactor': 20, 'currentState': array([26.40623777, 21.41482572, 16.40971009,  0.44839898,  0.71610566,
        0.53491218]), 'targetState': array([25., 25., 15.])}
episode index:3094
target thresh 33.95015591996044
model initialize at round 3094
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.07908127, 14.89510209,  0.99131068,  0.07918597,
       -0.10503678]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6021733674640317
{'scaleFactor': 20, 'currentState': array([28.7376631 , 21.25850292, 15.21940756,  0.47775213,  0.78249335,
        0.39932075]), 'targetState': array([25., 25., 15.])}
episode index:3095
target thresh 33.95676057413023
model initialize at round 3095
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84885023,  0.97710039,  0.15172366,
       -0.14918031]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6022860343511234
{'scaleFactor': 20, 'currentState': array([25.31624235, 20.16404286, 14.56625966,  0.57716559,  0.77464089,
        0.25847896]), 'targetState': array([25., 25., 15.])}
episode index:3096
target thresh 33.96336456786763
model initialize at round 3096
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15086985, 14.84627329,  0.97714062,  0.14891016,
       -0.15172991]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6023955577980236
{'scaleFactor': 20, 'currentState': array([26.4437846 , 21.52083667, 15.00159672,  0.43521516,  0.79870677,
        0.41551806]), 'targetState': array([25., 25., 15.])}
episode index:3097
target thresh 33.96996790123866
model initialize at round 3097
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.8988057 ,  0.98315541,  0.15266388,
       -0.10049467]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6025050105390187
{'scaleFactor': 20, 'currentState': array([26.43361959, 21.38766271, 16.61090518,  0.4645664 ,  0.71175325,
        0.52686372]), 'targetState': array([25., 25., 15.])}
episode index:3098
target thresh 33.976570574309385
model initialize at round 3098
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14644617, 14.90986757,  0.98524762,  0.14574318,
       -0.08969976]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.602614392642556
{'scaleFactor': 20, 'currentState': array([26.20979518, 21.51956866, 16.85215174,  0.38841207,  0.7888263 ,
        0.47632881]), 'targetState': array([25., 25., 15.])}
episode index:3099
target thresh 33.983172587145816
model initialize at round 3099
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.92188557,  0.9851679 ,  0.15297638,
       -0.07773316]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6027267718868327
{'scaleFactor': 20, 'currentState': array([25.30285908, 20.10968932, 15.44329021,  0.54886059,  0.74699523,
        0.37516686]), 'targetState': array([25., 25., 15.])}
episode index:3100
target thresh 33.98977393981397
model initialize at round 3100
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89057444,  0.982316  ,  0.15253354,
       -0.10857624]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6028390786517515
{'scaleFactor': 20, 'currentState': array([25.29641118, 20.11318741, 15.35528196,  0.55844208,  0.75833848,
        0.33625169]), 'targetState': array([25., 25., 15.])}
episode index:3101
target thresh 33.996374632379855
model initialize at round 3101
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84894762,  0.97711439,  0.15172584,
       -0.14908632]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6029513130074085
{'scaleFactor': 20, 'currentState': array([25.29333285, 20.18774502, 13.83778623,  0.59653603,  0.79890143,
        0.0768197 ]), 'targetState': array([25., 25., 15.])}
episode index:3102
target thresh 34.00297466490949
model initialize at round 3102
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6030634750238095
{'scaleFactor': 20, 'currentState': array([24.94400719, 20.04663464, 11.86301988,  0.57524818,  0.76529283,
       -0.288819  ]), 'targetState': array([25., 25., 15.])}
episode index:3103
target thresh 34.00957403746887
model initialize at round 3103
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.07188771, 14.84627329,  0.98562382,  0.07156994,
       -0.15304718]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.6028691891104642
{'scaleFactor': 20, 'currentState': array([27.04305984,  9.40595764, 11.75042796,  0.77962251,  0.29687715,
        0.55140974]), 'targetState': array([25., 25., 15.])}
episode index:3104
target thresh 34.016172750124
model initialize at round 3104
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.95586699,  0.98720051,  0.153292  ,
       -0.04400821]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6029813053297199
{'scaleFactor': 20, 'currentState': array([25.21233566, 20.03266691, 16.41841694,  0.51256594,  0.71865211,
        0.46990988]), 'targetState': array([25., 25., 15.])}
episode index:3105
target thresh 34.02277080294084
model initialize at round 3105
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.97804113,  0.98792059,  0.15340382,
       -0.02191275]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6030933493556601
{'scaleFactor': 20, 'currentState': array([25.40974644, 20.09129834, 15.26524686,  0.61880381,  0.72376374,
        0.3053652 ]), 'targetState': array([25., 25., 15.])}
episode index:3106
target thresh 34.0293681959854
model initialize at round 3106
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.06349994, 14.86000766,  0.98815875,  0.06338184,
       -0.13973197]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6031992302692588
{'scaleFactor': 20, 'currentState': array([28.76684661, 21.05897126, 15.3018048 ,  0.46992946,  0.75757208,
        0.45304618]), 'targetState': array([25., 25., 15.])}
episode index:3107
target thresh 34.03596492932364
model initialize at round 3107
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13173905, 14.8542303 ,  0.98086941,  0.13052405,
       -0.14442529]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6033080722638315
{'scaleFactor': 20, 'currentState': array([26.58406429, 21.33063254, 15.26191604,  0.46171613,  0.7748261 ,
        0.4318133 ]), 'targetState': array([25., 25., 15.])}
episode index:3108
target thresh 34.04256100302152
model initialize at round 3108
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85505796,  0.9779763 ,  0.15185967,
       -0.1431817 ]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6034199030704047
{'scaleFactor': 20, 'currentState': array([25.28245993, 20.11658738, 15.17931646,  0.5528217 ,  0.75193292,
        0.35914489]), 'targetState': array([25., 25., 15.])}
episode index:3109
target thresh 34.04915641714502
model initialize at round 3109
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13652721, 14.87020792,  0.98237412,  0.13547556,
       -0.1287923 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6035286041142409
{'scaleFactor': 20, 'currentState': array([26.30939182, 21.43163251, 16.33019636,  0.38515354,  0.7574368 ,
        0.52720608]), 'targetState': array([25., 25., 15.])}
episode index:3110
target thresh 34.05575117176007
model initialize at round 3110
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.95508189,  0.98716619,  0.15328668,
       -0.04478954]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6036342089820624
{'scaleFactor': 20, 'currentState': array([29.1944513 , 20.97027793, 17.36940104,  0.78222237,  0.53229203,
        0.32371802]), 'targetState': array([25., 25., 15.])}
episode index:3111
target thresh 34.062345266932645
model initialize at round 3111
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.05445341, 14.86258866,  0.98903761,  0.05440047,
       -0.13727777]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6037397459804316
{'scaleFactor': 20, 'currentState': array([29.33306391, 20.29403765, 15.39371757,  0.66287407,  0.58374232,
        0.46887405]), 'targetState': array([25., 25., 15.])}
episode index:3112
target thresh 34.068938702728666
model initialize at round 3112
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.02080733, 14.84627329,  0.98794482,  0.02076413,
       -0.15340758]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.603545804526535
{'scaleFactor': 20, 'currentState': array([16.43461693, 18.65759924,  7.29660701,  0.60731564, -0.79388083,
       -0.03034698]), 'targetState': array([25., 25., 15.])}
episode index:3113
target thresh 34.07553147921407
model initialize at round 3113
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6036513021319879
{'scaleFactor': 20, 'currentState': array([29.39503906, 20.88863098, 14.60237852,  0.72537712,  0.58314165,
        0.36575107]), 'targetState': array([25., 25., 15.])}
episode index:3114
target thresh 34.08212359645481
model initialize at round 3114
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13492704, 14.85698056,  0.98084251,  0.13367896,
       -0.14169651]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.603759754410405
{'scaleFactor': 20, 'currentState': array([26.37326142, 21.53345911, 15.38544869,  0.41558669,  0.78935071,
        0.4518995 ]), 'targetState': array([25., 25., 15.])}
episode index:3115
target thresh 34.08871505451676
model initialize at round 3115
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11146482, 14.93687306,  0.99173237,  0.11165987,
       -0.0632374 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6038681370788872
{'scaleFactor': 20, 'currentState': array([27.43456488, 20.03590356, 16.02678146,  0.65191138,  0.60004399,
        0.46363645]), 'targetState': array([25., 25., 15.])}
episode index:3116
target thresh 34.095305853465874
model initialize at round 3116
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.1125205 , 14.89200919,  0.98781791,  0.11227249,
       -0.10775279]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6039734297355532
{'scaleFactor': 20, 'currentState': array([29.04278165, 20.84726491, 16.98250184,  0.67044376,  0.6136504 ,
        0.41705917]), 'targetState': array([25., 25., 15.])}
episode index:3117
target thresh 34.10189599336804
model initialize at round 3117
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09434526, 14.8471394 ,  0.98393435,  0.09376721,
       -0.15192404]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6040786548536327
{'scaleFactor': 20, 'currentState': array([29.33285968, 20.17333207, 15.69351593,  0.60192559,  0.61289607,
        0.51190232]), 'targetState': array([25., 25., 15.])}
episode index:3118
target thresh 34.10848547428916
model initialize at round 3118
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10315346, 14.9446415 ,  0.99308075,  0.10347446,
       -0.05553077]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6041838124980871
{'scaleFactor': 20, 'currentState': array([29.07754031, 20.97446112, 16.46616655,  0.65157539,  0.64207412,
        0.40396823]), 'targetState': array([25., 25., 15.])}
episode index:3119
target thresh 34.11507429629515
model initialize at round 3119
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.03141682, 14.84627329,  0.98767237,  0.03134295,
       -0.15336527]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6042889027337951
{'scaleFactor': 20, 'currentState': array([29.06948439, 20.45135944, 14.37057694,  0.53887958,  0.74754389,
        0.38831292]), 'targetState': array([25., 25., 15.])}
episode index:3120
target thresh 34.12166245945186
model initialize at round 3120
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.93847779,  0.98629999,  0.15315217,
       -0.06129228]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6043999892916824
{'scaleFactor': 20, 'currentState': array([25.35999394, 20.152746  , 14.75558294,  0.58230747,  0.7746628 ,
        0.24660811]), 'targetState': array([25., 25., 15.])}
episode index:3121
target thresh 34.128249963825205
model initialize at round 3121
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6045110046858554
{'scaleFactor': 20, 'currentState': array([25.2872868 , 20.12212026, 14.84023619,  0.57468004,  0.75177476,
        0.32338454]), 'targetState': array([25., 25., 15.])}
episode index:3122
target thresh 34.13483680948105
model initialize at round 3122
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.07297031, 14.87018442,  0.98887493,  0.07288738,
       -0.12966805]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6046189038676406
{'scaleFactor': 20, 'currentState': array([27.25468737, 20.35316892, 14.46798153,  0.64614402,  0.67919136,
        0.34813359]), 'targetState': array([25., 25., 15.])}
episode index:3123
target thresh 34.14142299648527
model initialize at round 3123
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.04733696, 14.85596716,  0.98847583,  0.04726409,
       -0.14381109]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6047237202709823
{'scaleFactor': 20, 'currentState': array([29.34216033, 20.30100667, 14.82882065,  0.59611821,  0.73278178,
        0.32813708]), 'targetState': array([25., 25., 15.])}
episode index:3124
target thresh 34.14800852490371
model initialize at round 3124
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85282985,  0.97766587,  0.15181147,
       -0.1453366 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6048314823283039
{'scaleFactor': 20, 'currentState': array([27.05746521, 21.1640342 , 13.58436718,  0.74958699,  0.65707206,
        0.07984766]), 'targetState': array([25., 25., 15.])}
episode index:3125
target thresh 34.154593394802234
model initialize at round 3125
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.50050808e+01,  1.48462733e+01,  9.88145157e-01,
        5.07124937e-03, -1.53438689e-01]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.6046379981688897
{'scaleFactor': 20, 'currentState': array([20.62325109, 44.11815141,  5.44612714,  0.37141083, -0.89977886,
        0.22902399]), 'targetState': array([25., 25., 15.])}
episode index:3126
target thresh 34.161177606246696
model initialize at round 3126
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.92340758,  0.98528277,  0.15299422,
       -0.07622747]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6047457187161338
{'scaleFactor': 20, 'currentState': array([27.37753   , 20.32196118, 16.47468949,  0.67158493,  0.62259787,
        0.40167844]), 'targetState': array([25., 25., 15.])}
episode index:3127
target thresh 34.167761159302934
model initialize at round 3127
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10499305, 14.84627329,  0.98277591,  0.1042269 ,
       -0.15260495]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6048533703883477
{'scaleFactor': 20, 'currentState': array([27.39202102, 20.25592812, 13.07252531,  0.68852816,  0.7173064 ,
        0.10677317]), 'targetState': array([25., 25., 15.])}
episode index:3128
target thresh 34.17434405403679
model initialize at round 3128
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.07589787, 14.86754148,  0.98831845,  0.07576895,
       -0.13223353]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6049579443664618
{'scaleFactor': 20, 'currentState': array([29.37125867, 20.15245581, 15.1894935 ,  0.58792857,  0.69337131,
        0.4166248 ]), 'targetState': array([25., 25., 15.])}
episode index:3129
target thresh 34.180926290514066
model initialize at round 3129
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6050654594479425
{'scaleFactor': 20, 'currentState': array([26.61328118, 21.43283324, 14.9497964 ,  0.47247072,  0.80418937,
        0.36062568]), 'targetState': array([25., 25., 15.])}
episode index:3130
target thresh 34.187507868800616
model initialize at round 3130
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12632436, 14.86963035,  0.98360081,  0.12550782,
       -0.12952696]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6051729058516325
{'scaleFactor': 20, 'currentState': array([27.31440604, 20.17322851, 12.01939795,  0.7088608 ,  0.6928287 ,
       -0.13230557]), 'targetState': array([25., 25., 15.])}
episode index:3131
target thresh 34.194088788962254
model initialize at round 3131
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09339718, 14.84627329,  0.98389181,  0.09282093,
       -0.15277823]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.605280283643315
{'scaleFactor': 20, 'currentState': array([26.85407768, 20.73146517, 15.42481373,  0.49741558,  0.73412726,
        0.46220657]), 'targetState': array([25., 25., 15.])}
episode index:3132
target thresh 34.20066905106477
model initialize at round 3132
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.51537267e+01, 1.50049898e+01, 9.88145608e-01,
       1.53438759e-01, 4.98049928e-03]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6053875928886894
{'scaleFactor': 20, 'currentState': array([26.39116675, 21.4055651 , 17.27207686,  0.46350257,  0.78094314,
        0.41868027]), 'targetState': array([25., 25., 15.])}
episode index:3133
target thresh 34.20724865517397
model initialize at round 3133
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10366125, 14.84627329,  0.9829105 ,  0.10291892,
       -0.15262585]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6054948336533711
{'scaleFactor': 20, 'currentState': array([26.65175532, 21.27873072, 13.01877135,  0.52092092,  0.8531849 ,
        0.02677546]), 'targetState': array([25., 25., 15.])}
episode index:3134
target thresh 34.21382760135565
model initialize at round 3134
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13208062, 14.84627329,  0.9796809 ,  0.1307039 ,
       -0.15212436]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6056020060028918
{'scaleFactor': 20, 'currentState': array([26.394916  , 21.60511055, 14.28143269,  0.44936851,  0.82843293,
        0.33431546]), 'targetState': array([25., 25., 15.])}
episode index:3135
target thresh 34.22040588967562
model initialize at round 3135
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6057121424964814
{'scaleFactor': 20, 'currentState': array([25.3382281 , 20.11509276, 13.63177487,  0.61502501,  0.78614134,
        0.06104117]), 'targetState': array([25., 25., 15.])}
episode index:3136
target thresh 34.22698352019965
model initialize at round 3136
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6058222087723512
{'scaleFactor': 20, 'currentState': array([25.19889115, 20.18593345, 13.19101399,  0.59225479,  0.80158201,
        0.08185679]), 'targetState': array([25., 25., 15.])}
episode index:3137
target thresh 34.23356049299351
model initialize at round 3137
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6059291743366051
{'scaleFactor': 20, 'currentState': array([27.15465099, 20.87484213, 13.68582091,  0.61164861,  0.77581523,
        0.1549087 ]), 'targetState': array([25., 25., 15.])}
episode index:3138
target thresh 34.240136808122976
model initialize at round 3138
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6060360717482216
{'scaleFactor': 20, 'currentState': array([27.52614182, 20.26280092, 14.75690559,  0.69626998,  0.62638106,
        0.35050662]), 'targetState': array([25., 25., 15.])}
episode index:3139
target thresh 34.24671246565379
model initialize at round 3139
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6061429010723148
{'scaleFactor': 20, 'currentState': array([26.91305427, 21.12072744, 13.61607849,  0.57847735,  0.79418738,
        0.18609235]), 'targetState': array([25., 25., 15.])}
episode index:3140
target thresh 34.25328746565175
model initialize at round 3140
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6062496623739159
{'scaleFactor': 20, 'currentState': array([27.06396127, 20.92607537, 14.31476108,  0.63573457,  0.69172874,
        0.34256812]), 'targetState': array([25., 25., 15.])}
episode index:3141
target thresh 34.25986180818259
model initialize at round 3141
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08895995, 14.92088832,  0.99284733,  0.08921581,
       -0.07933922]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6063563557179729
{'scaleFactor': 20, 'currentState': array([27.2119561 , 20.26792918, 16.25423221,  0.55922655,  0.66180515,
        0.49927909]), 'targetState': array([25., 25., 15.])}
episode index:3142
target thresh 34.266435493312045
model initialize at round 3142
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.98215616,  0.98800117,  0.15341633,
       -0.01780782]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6064660069092493
{'scaleFactor': 20, 'currentState': array([25.25766142, 20.06085615, 16.19908113,  0.52618818,  0.7285903 ,
        0.4384999 ]), 'targetState': array([25., 25., 15.])}
episode index:3143
target thresh 34.273008521105844
model initialize at round 3143
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15322845, 14.8924421 ,  0.98258603,  0.15208095,
       -0.10675242]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6065725635703473
{'scaleFactor': 20, 'currentState': array([26.45329303, 21.29934154, 16.58140693,  0.40762806,  0.73969188,
        0.53543934]), 'targetState': array([25., 25., 15.])}
episode index:3144
target thresh 34.27958089162972
model initialize at round 3144
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11315062, 14.94733009,  0.99214676,  0.11339598,
       -0.05278412]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6066760588912811
{'scaleFactor': 20, 'currentState': array([29.33587099, 20.22120801, 17.28574954,  0.67123462,  0.59177818,
        0.44636607]), 'targetState': array([25., 25., 15.])}
episode index:3145
target thresh 34.286152604949415
model initialize at round 3145
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10553466, 14.93924762,  0.99252002,  0.1058033 ,
       -0.06090702]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6067824810433821
{'scaleFactor': 20, 'currentState': array([27.37651683, 20.30106336, 15.77272691,  0.58042001,  0.72803516,
        0.36479778]), 'targetState': array([25., 25., 15.])}
episode index:3146
target thresh 34.292723661130644
model initialize at round 3146
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11211489, 14.85334965,  0.98305658,  0.11132857,
       -0.14562181]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6068888355614493
{'scaleFactor': 20, 'currentState': array([27.33253239, 20.31391762, 15.41919011,  0.66016929,  0.60244046,
        0.44860005]), 'targetState': array([25., 25., 15.])}
episode index:3147
target thresh 34.29929406023909
model initialize at round 3147
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.07895377, 14.95562118,  0.99584122,  0.07941962,
       -0.04464066]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6069921317851932
{'scaleFactor': 20, 'currentState': array([29.35504371, 20.05669364, 16.70534073,  0.5988188 ,  0.63123557,
        0.49290739]), 'targetState': array([25., 25., 15.])}
episode index:3148
target thresh 34.30586380234048
model initialize at round 3148
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08387452, 14.87839574,  0.98904972,  0.08379401,
       -0.12148753]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6070953624032058
{'scaleFactor': 20, 'currentState': array([29.05073895, 20.90596794, 15.45923763,  0.61707222,  0.60402636,
        0.50435505]), 'targetState': array([25., 25., 15.])}
episode index:3149
target thresh 34.31243288750052
model initialize at round 3149
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13810418, 14.87978486,  0.98332404,  0.13717289,
       -0.11940448]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6072015163038401
{'scaleFactor': 20, 'currentState': array([26.47926251, 21.33919423, 16.05009904,  0.45543539,  0.73123849,
        0.50780792]), 'targetState': array([25., 25., 15.])}
episode index:3150
target thresh 34.31900131578488
model initialize at round 3150
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.06224816, 14.89737477,  0.9927304 ,  0.06241984,
       -0.10290826]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.6070088150926995
{'scaleFactor': 20, 'currentState': array([10.19974325, 22.12352037,  0.09454801,  0.84626225, -0.38172282,
        0.37165562]), 'targetState': array([25., 25., 15.])}
episode index:3151
target thresh 34.325569087259254
model initialize at round 3151
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6071179461951131
{'scaleFactor': 20, 'currentState': array([25.26956975, 20.14002862, 14.69210233,  0.56041599,  0.75927308,
        0.33081461]), 'targetState': array([25., 25., 15.])}
episode index:3152
target thresh 34.33213620198933
model initialize at round 3152
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13628356, 14.86555771,  0.98181247,  0.13515646,
       -0.13333042]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6072239919303511
{'scaleFactor': 20, 'currentState': array([26.42775011, 21.4772691 , 15.48850814,  0.44356436,  0.76656948,
        0.46435104]), 'targetState': array([25., 25., 15.])}
episode index:3153
target thresh 34.33870266004075
model initialize at round 3153
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84858959,  0.97706286,  0.15171784,
       -0.14943181]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6073329856075768
{'scaleFactor': 20, 'currentState': array([25.35717846, 20.00006441, 15.30994746,  0.59660978,  0.69807243,
        0.39591876]), 'targetState': array([25., 25., 15.])}
episode index:3154
target thresh 34.34526846147921
model initialize at round 3154
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.0626671 , 14.91323936,  0.99420715,  0.06293342,
       -0.08712934]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.60743591187138
{'scaleFactor': 20, 'currentState': array([28.70798437, 21.29920417, 15.67262738,  0.51145329,  0.77243979,
        0.37650007]), 'targetState': array([25., 25., 15.])}
episode index:3155
target thresh 34.35183360637034
model initialize at round 3155
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12355825, 14.84627329,  0.98072764,  0.122401  ,
       -0.1522869 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6075417560531068
{'scaleFactor': 20, 'currentState': array([26.76259881, 21.12913124, 13.62198719,  0.51834751,  0.82526951,
        0.22415639]), 'targetState': array([25., 25., 15.])}
episode index:3156
target thresh 34.35839809477981
model initialize at round 3156
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87068912,  0.98002837,  0.15217832,
       -0.12800842]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6076505455031691
{'scaleFactor': 20, 'currentState': array([25.26841596, 20.18420145, 13.8364901 ,  0.58743433,  0.78928235,
        0.17875761]), 'targetState': array([25., 25., 15.])}
episode index:3157
target thresh 34.36496192677326
model initialize at round 3157
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6077562546874307
{'scaleFactor': 20, 'currentState': array([27.01348827, 21.06735289, 13.91235395,  0.66452192,  0.6878685 ,
        0.29197181]), 'targetState': array([25., 25., 15.])}
episode index:3158
target thresh 34.371525102416335
model initialize at round 3158
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.0653013 , 14.84627329,  0.98606548,  0.06504177,
       -0.15311576]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.6075638658761969
{'scaleFactor': 20, 'currentState': array([ 9.82995901, 19.05310718,  4.76340153,  0.13919202, -0.98559329,
       -0.0960804 ]), 'targetState': array([25., 25., 15.])}
episode index:3159
target thresh 34.378087621774654
model initialize at round 3159
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.06542625, 14.84627329,  0.98605749,  0.0651657 ,
       -0.15311452]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.6073715988300336
{'scaleFactor': 20, 'currentState': array([18.16001105, 30.41532453,  5.85256812,  0.33315628, -0.9324109 ,
       -0.14005998]), 'targetState': array([25., 25., 15.])}
episode index:3160
target thresh 34.384649484913865
model initialize at round 3160
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11533118, 14.84627329,  0.98167478,  0.11436132,
       -0.15243397]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6074772959355605
{'scaleFactor': 20, 'currentState': array([26.87786233, 20.98556664, 14.69507809,  0.54259417,  0.74369432,
        0.3905257 ]), 'targetState': array([25., 25., 15.])}
episode index:3161
target thresh 34.391210691899545
model initialize at round 3161
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.06671093, 14.89921351,  0.99262985,  0.06688815,
       -0.10105422]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6075799487034199
{'scaleFactor': 20, 'currentState': array([29.04123448, 20.7855177 , 15.40162612,  0.52666924,  0.74978464,
        0.40055274]), 'targetState': array([25., 25., 15.])}
episode index:3162
target thresh 34.39777124279734
model initialize at round 3162
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6076885197123344
{'scaleFactor': 20, 'currentState': array([25.2478657 , 20.17757293, 13.96911595,  0.57873313,  0.78043309,
        0.23662663]), 'targetState': array([25., 25., 15.])}
episode index:3163
target thresh 34.40433113767285
model initialize at round 3163
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6077940164347392
{'scaleFactor': 20, 'currentState': array([26.89520607, 21.18264187, 14.68863211,  0.5690125 ,  0.74708161,
        0.34364784]), 'targetState': array([25., 25., 15.])}
episode index:3164
target thresh 34.410890376591674
model initialize at round 3164
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.1128538 , 14.84627329,  0.98194772,  0.11193589,
       -0.15247635]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6078964718317288
{'scaleFactor': 20, 'currentState': array([28.38041086, 21.42873442, 16.13583813,  0.41593703,  0.74047923,
        0.52790804]), 'targetState': array([25., 25., 15.])}
episode index:3165
target thresh 34.4174489596194
model initialize at round 3165
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6080048399865198
{'scaleFactor': 20, 'currentState': array([25.1779518 , 20.114055  , 12.72054553,  0.63404676,  0.76934387,
       -0.07806868]), 'targetState': array([25., 25., 15.])}
episode index:3166
target thresh 34.424006886821616
model initialize at round 3166
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.03152256, 14.84627329,  0.9876691 ,  0.03144834,
       -0.15336477]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.607812858666663
{'scaleFactor': 20, 'currentState': array([30.7446984 , 30.55110117,  9.50712654,  0.9150936 , -0.24502614,
        0.32025911]), 'targetState': array([25., 25., 15.])}
episode index:3167
target thresh 34.4305641582639
model initialize at round 3167
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89365604,  0.98263768,  0.15258349,
       -0.10555311]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6079211848002594
{'scaleFactor': 20, 'currentState': array([25.28121972, 20.09551779, 15.5398635 ,  0.54153211,  0.74112639,
        0.39683075]), 'targetState': array([25., 25., 15.])}
episode index:3168
target thresh 34.43712077401182
model initialize at round 3168
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87933775,  0.98106816,  0.15233978,
       -0.11957363]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6080294425677254
{'scaleFactor': 20, 'currentState': array([25.29471148, 20.13491869, 14.91517597,  0.560136  ,  0.75801841,
        0.33414929]), 'targetState': array([25., 25., 15.])}
episode index:3169
target thresh 34.443676734130946
model initialize at round 3169
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.88258279,  0.98144054,  0.1523976 ,
       -0.11640203]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6081376320337608
{'scaleFactor': 20, 'currentState': array([25.31411438, 20.17016742, 14.41023851,  0.58432873,  0.78278327,
        0.21403336]), 'targetState': array([25., 25., 15.])}
episode index:3170
target thresh 34.45023203868685
model initialize at round 3170
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14694659, 14.84627329,  0.97769722,  0.14512048,
       -0.15181634]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6082427542404361
{'scaleFactor': 20, 'currentState': array([27.47614477, 20.34164034, 14.18952022,  0.7475532 ,  0.60273056,
        0.27907003]), 'targetState': array([25., 25., 15.])}
episode index:3171
target thresh 34.45678668774506
model initialize at round 3171
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08177204, 14.84627329,  0.98488276,  0.08134937,
       -0.15293211]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.6080510005348116
{'scaleFactor': 20, 'currentState': array([31.63487422, 19.0194214 , 10.82609288,  0.87885356, -0.37597972,
        0.29369316]), 'targetState': array([25., 25., 15.])}
episode index:3172
target thresh 34.46334068137114
model initialize at round 3172
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.03596813, 14.90094987,  0.99438264,  0.03612736,
       -0.09948861]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6081531166228583
{'scaleFactor': 20, 'currentState': array([28.82212156, 20.85236891, 15.27047693,  0.47687602,  0.75009539,
        0.45819882]), 'targetState': array([25., 25., 15.])}
episode index:3173
target thresh 34.46989401963063
model initialize at round 3173
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12888689, 14.87245526,  0.98363703,  0.1280585 ,
       -0.12672498]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6082551683655438
{'scaleFactor': 20, 'currentState': array([29.18855071, 21.04717093, 14.04388547,  0.65146822,  0.66685237,
        0.36179701]), 'targetState': array([25., 25., 15.])}
episode index:3174
target thresh 34.47644670258906
model initialize at round 3174
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.92429946,  0.98534906,  0.15300451,
       -0.0753449 ]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6083631163597278
{'scaleFactor': 20, 'currentState': array([25.32306839, 20.07331965, 15.56436924,  0.54982571,  0.74266938,
        0.38227461]), 'targetState': array([25., 25., 15.])}
episode index:3175
target thresh 34.482998730311955
model initialize at round 3175
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.51537267e+01,  1.49979303e+01,  9.88155755e-01,
        1.53440335e-01, -2.06586180e-03]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.608468002075421
{'scaleFactor': 20, 'currentState': array([26.37253551, 21.2380814 , 17.64721765,  0.41978737,  0.74284602,
        0.52149627]), 'targetState': array([25., 25., 15.])}
episode index:3176
target thresh 34.48955010286484
model initialize at round 3176
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.9448907 ,  0.98666629,  0.15320905,
       -0.05492373]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6085758151216358
{'scaleFactor': 20, 'currentState': array([25.25561706, 20.06316085, 16.04809377,  0.52702634,  0.72929252,
        0.43632059]), 'targetState': array([25., 25., 15.])}
episode index:3177
target thresh 34.49610082031322
model initialize at round 3177
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 15.09262892,  0.98396126,  0.15278901,
        0.09206391]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6086805679014594
{'scaleFactor': 20, 'currentState': array([25.73760185, 21.5325121 , 19.13810417,  0.37164215,  0.82758168,
        0.4207026 ]), 'targetState': array([25., 25., 15.])}
episode index:3178
target thresh 34.50265088272262
model initialize at round 3178
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.95031813,  0.9869451 ,  0.15325235,
       -0.04952856]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.608788246253771
{'scaleFactor': 20, 'currentState': array([25.31905455, 20.11458591, 15.49945634,  0.55209358,  0.7492953 ,
        0.36571742]), 'targetState': array([25., 25., 15.])}
episode index:3179
target thresh 34.5092002901585
model initialize at round 3179
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6088958568838485
{'scaleFactor': 20, 'currentState': array([25.30567553, 20.13555385, 14.03835044,  0.5878963 ,  0.77672204,
        0.22601065]), 'targetState': array([25., 25., 15.])}
episode index:3180
target thresh 34.51574904268641
model initialize at round 3180
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.90071545,  0.98334108,  0.15269271,
       -0.09861674]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6090004102609367
{'scaleFactor': 20, 'currentState': array([26.7396643 , 21.27790597, 15.48981818,  0.48746483,  0.75957546,
        0.4306079 ]), 'targetState': array([25., 25., 15.])}
episode index:3181
target thresh 34.52229714037179
model initialize at round 3181
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14303964, 14.84627329,  0.97823783,  0.14134019,
       -0.15190028]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6091078865776051
{'scaleFactor': 20, 'currentState': array([25.34956084, 20.00288088, 13.95773743,  0.59674138,  0.76577198,
        0.23977699]), 'targetState': array([25., 25., 15.])}
episode index:3182
target thresh 34.52884458328016
model initialize at round 3182
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86944759,  0.97987348,  0.15215427,
       -0.12921701]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6092152953628147
{'scaleFactor': 20, 'currentState': array([25.27717208, 20.18168179, 13.96700513,  0.58868634,  0.79044804,
        0.16923443]), 'targetState': array([25., 25., 15.])}
episode index:3183
target thresh 34.53539137147696
model initialize at round 3183
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14058983, 14.88905103,  0.98402777,  0.13974171,
       -0.11027967]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6093196499023996
{'scaleFactor': 20, 'currentState': array([27.05134049, 20.96455229, 15.20304222,  0.61696435,  0.71668588,
        0.32514051]), 'targetState': array([25., 25., 15.])}
episode index:3184
target thresh 34.54193750502769
model initialize at round 3184
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6094269247532622
{'scaleFactor': 20, 'currentState': array([25.18462009, 20.1872739 , 13.13610723,  0.59255022,  0.80380189,
        0.05278985]), 'targetState': array([25., 25., 15.])}
episode index:3185
target thresh 34.548482983997786
model initialize at round 3185
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6095341322627245
{'scaleFactor': 20, 'currentState': array([25.27019419, 20.13823253, 14.72401998,  0.55960397,  0.75843975,
        0.33408464]), 'targetState': array([25., 25., 15.])}
episode index:3186
target thresh 34.5550278084527
model initialize at round 3186
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10265086, 14.91321246,  0.99090745,  0.10274495,
       -0.08686709]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6096382885279075
{'scaleFactor': 20, 'currentState': array([26.66692697, 21.22486091, 15.0606576 ,  0.48692104,  0.77807941,
        0.39686311]), 'targetState': array([25., 25., 15.])}
episode index:3187
target thresh 34.56157197845789
model initialize at round 3187
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13829169, 14.94737052,  0.98901422,  0.13815399,
       -0.05257707]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6097423794503896
{'scaleFactor': 20, 'currentState': array([27.15522358, 20.75034794, 15.08661877,  0.559108  ,  0.74670362,
        0.360322  ]), 'targetState': array([25., 25., 15.])}
episode index:3188
target thresh 34.568115494078825
model initialize at round 3188
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10443847, 14.84627329,  0.98283215,  0.10368231,
       -0.15261369]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6098464050916409
{'scaleFactor': 20, 'currentState': array([26.97440676, 20.9541954 , 13.83619925,  0.61019567,  0.75162009,
        0.25045656]), 'targetState': array([25., 25., 15.])}
episode index:3189
target thresh 34.57465835538089
model initialize at round 3189
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12906979, 14.84627329,  0.98005828,  0.12777365,
       -0.15218296]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6099503655130545
{'scaleFactor': 20, 'currentState': array([26.58289014, 21.34563692, 13.98929669,  0.48268087,  0.81727647,
        0.31476714]), 'targetState': array([25., 25., 15.])}
episode index:3190
target thresh 34.58120056242956
model initialize at round 3190
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.88230153,  0.98140865,  0.15239265,
       -0.11667707]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6100572410017373
{'scaleFactor': 20, 'currentState': array([25.29107814, 20.16110521, 14.43753321,  0.5726189 ,  0.77111742,
        0.27836221]), 'targetState': array([25., 25., 15.])}
episode index:3191
target thresh 34.58774211529022
model initialize at round 3191
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.90598737,  0.98383577,  0.15276953,
       -0.09342726]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6101640495258281
{'scaleFactor': 20, 'currentState': array([25.32195955, 20.16448096, 14.3143861 ,  0.58960705,  0.77435616,
        0.22964334]), 'targetState': array([25., 25., 15.])}
episode index:3192
target thresh 34.594283014028306
model initialize at round 3192
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13316679, 14.84627329,  0.97954273,  0.13176017,
       -0.15210291]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.610264864213702
{'scaleFactor': 20, 'currentState': array([29.17807615, 20.91283623, 12.96756276,  0.74213754,  0.60779916,
        0.28251028]), 'targetState': array([25., 25., 15.])}
episode index:3193
target thresh 34.60082325870921
model initialize at round 3193
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.03012094, 14.84627329,  0.98771157,  0.03005131,
       -0.15337136]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.6100737981948499
{'scaleFactor': 20, 'currentState': array([28.33181025, 19.93793359,  8.8836201 ,  0.80187161, -0.59459195,
        0.05884157]), 'targetState': array([25., 25., 15.])}
episode index:3194
target thresh 34.607362849398356
model initialize at round 3194
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89896064,  0.9831706 ,  0.15266624,
       -0.10034235]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6101805012470267
{'scaleFactor': 20, 'currentState': array([25.30414047, 20.1512535 , 13.95287256,  0.59502219,  0.77853238,
        0.19958941]), 'targetState': array([25., 25., 15.])}
episode index:3195
target thresh 34.613901786161136
model initialize at round 3195
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89505934,  0.98278123,  0.15260578,
       -0.10417547]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6102871375263299
{'scaleFactor': 20, 'currentState': array([25.34538038, 20.11562418, 14.74437834,  0.58539527,  0.75203344,
        0.30291596]), 'targetState': array([25., 25., 15.])}
episode index:3196
target thresh 34.620440069062916
model initialize at round 3196
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.1013295 , 14.89157496,  0.98895046,  0.10122208,
       -0.10831009]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6103877875764959
{'scaleFactor': 20, 'currentState': array([28.66732453, 21.51792377, 14.0343882 ,  0.51383058,  0.81903903,
        0.25525124]), 'targetState': array([25., 25., 15.])}
episode index:3197
target thresh 34.626977698169114
model initialize at round 3197
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6104942923489548
{'scaleFactor': 20, 'currentState': array([25.33007024, 20.05911865, 13.59714416,  0.66391199,  0.72276422,
        0.19191859]), 'targetState': array([25., 25., 15.])}
episode index:3198
target thresh 34.63351467354507
model initialize at round 3198
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.06705157, 14.92758012,  0.99506757,  0.06739479,
       -0.07279058]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.6103034532453759
{'scaleFactor': 20, 'currentState': array([33.79620583, 14.84314711,  7.79379842,  0.93000636,  0.14940873,
        0.3358053 ]), 'targetState': array([25., 25., 15.])}
episode index:3199
target thresh 34.6400509952562
model initialize at round 3199
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6104099178068305
{'scaleFactor': 20, 'currentState': array([24.97985162, 20.13217136, 12.1829046 ,  0.57783678,  0.80702597,
       -0.12171175]), 'targetState': array([25., 25., 15.])}
episode index:3200
target thresh 34.64658666336782
model initialize at round 3200
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14566706, 14.84627329,  0.97787577,  0.14388312,
       -0.15184406]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6105163158487215
{'scaleFactor': 20, 'currentState': array([25.20809767, 20.11617377, 13.27345385,  0.59301433,  0.79214738,
        0.14434864]), 'targetState': array([25., 25., 15.])}
episode index:3201
target thresh 34.65312167794531
model initialize at round 3201
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.610622647433372
{'scaleFactor': 20, 'currentState': array([25.27673346, 20.15814467, 14.07640207,  0.58357574,  0.77400636,
        0.24566949]), 'targetState': array([25., 25., 15.])}
episode index:3202
target thresh 34.65965603905401
model initialize at round 3202
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14069689, 14.84627329,  0.97855543,  0.13907042,
       -0.1519496 ]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6107289126230275
{'scaleFactor': 20, 'currentState': array([25.2606849 , 20.02818174, 13.12989515,  0.63409863,  0.76520942,
        0.11123608]), 'targetState': array([25., 25., 15.])}
episode index:3203
target thresh 34.66618974675928
model initialize at round 3203
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.1016241 , 14.90491398,  0.99026304,  0.10165111,
       -0.09511128]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.6105382981059791
{'scaleFactor': 20, 'currentState': array([24.91026398, 11.74029989,  3.16322324,  0.86105844,  0.05532913,
        0.50548694]), 'targetState': array([25., 25., 15.])}
episode index:3204
target thresh 34.67272280112644
model initialize at round 3204
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6106445233015467
{'scaleFactor': 20, 'currentState': array([25.10044529, 20.02814068, 12.25364367,  0.66059216,  0.74878462,
       -0.05421797]), 'targetState': array([25., 25., 15.])}
episode index:3205
target thresh 34.679255202220816
model initialize at round 3205
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.0975505 , 14.86207159,  0.98575055,  0.09713178,
       -0.13733637]), 'targetState': array([25., 25., 15.])}
done in step count: 46
reward sum = 0.6298236312032323
running average episode reward sum: 0.6106505055560388
{'scaleFactor': 20, 'currentState': array([28.40794434, 21.89409143, 10.02606109,  0.43319777,  0.35976885,
        0.82638131]), 'targetState': array([25., 25., 15.])}
episode index:3206
target thresh 34.68578695010777
model initialize at round 3206
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14289268, 14.95339877,  0.98867113,  0.14270088,
       -0.04653868]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6107536641602936
{'scaleFactor': 20, 'currentState': array([26.65890356, 21.40503275, 15.88918687,  0.51735118,  0.73461306,
        0.43896628]), 'targetState': array([25., 25., 15.])}
episode index:3207
target thresh 34.69231804485258
model initialize at round 3207
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09329309, 14.87825867,  0.98821071,  0.09312447,
       -0.1215213 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6108567584512041
{'scaleFactor': 20, 'currentState': array([27.01055249, 20.60107017, 12.39248159,  0.64098836,  0.76011969,
       -0.10654564]), 'targetState': array([25., 25., 15.])}
episode index:3208
target thresh 34.69884848652056
model initialize at round 3208
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14895529, 14.84627329,  0.97741395,  0.1470616 ,
       -0.15177235]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6109627519979317
{'scaleFactor': 20, 'currentState': array([24.85614251, 20.04850318, 11.72019971,  0.56211437,  0.80261521,
       -0.19959023]), 'targetState': array([25., 25., 15.])}
episode index:3209
target thresh 34.70537827517703
model initialize at round 3209
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6110686795050663
{'scaleFactor': 20, 'currentState': array([25.17419342, 20.18947051, 13.26698611,  0.58940305,  0.8000135 ,
        0.11217149]), 'targetState': array([25., 25., 15.])}
episode index:3210
target thresh 34.7119074108873
model initialize at round 3210
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6111745410343079
{'scaleFactor': 20, 'currentState': array([25.0878279 , 20.17880207, 12.7571052 ,  0.58769616,  0.80712625,
        0.05621777]), 'targetState': array([25., 25., 15.])}
episode index:3211
target thresh 34.718435893716624
model initialize at round 3211
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.611277375906153
{'scaleFactor': 20, 'currentState': array([26.78264631, 21.3328254 , 13.16414052,  0.66073593,  0.737519  ,
        0.13962   ]), 'targetState': array([25., 25., 15.])}
episode index:3212
target thresh 34.724963723730305
model initialize at round 3212
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08133936, 14.87147842,  0.9884031 ,  0.08120815,
       -0.12831427]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6113772165448088
{'scaleFactor': 20, 'currentState': array([28.59435122, 21.50627729, 12.58062884,  0.54283443,  0.82656782,
        0.14871587]), 'targetState': array([25., 25., 15.])}
episode index:3213
target thresh 34.731490900993634
model initialize at round 3213
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87360921,  0.98038711,  0.15223402,
       -0.12516354]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6114828832633387
{'scaleFactor': 20, 'currentState': array([ 2.51352422e+01,  2.00647900e+01,  1.25743125e+01,  6.00662613e-01,
        7.99415269e-01, -1.18174920e-02]), 'targetState': array([25., 25., 15.])}
episode index:3214
target thresh 34.73801742557187
model initialize at round 3214
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85869049,  0.97847286,  0.15193678,
       -0.13966416]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6115884842482956
{'scaleFactor': 20, 'currentState': array([25.13323539, 20.18332383, 13.01261945,  0.58884499,  0.80338923,
        0.08847219]), 'targetState': array([25., 25., 15.])}
episode index:3215
target thresh 34.74454329753027
model initialize at round 3215
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6116940195609982
{'scaleFactor': 20, 'currentState': array([25.0660488 , 20.1646366 , 12.54832321,  0.58527408,  0.80884878,
       -0.05672653]), 'targetState': array([25., 25., 15.])}
episode index:3216
target thresh 34.75106851693411
model initialize at round 3216
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6117994892626889
{'scaleFactor': 20, 'currentState': array([25.12690687, 20.10595935, 12.55472593,  0.62904687,  0.7763071 ,
       -0.04058721]), 'targetState': array([25., 25., 15.])}
episode index:3217
target thresh 34.75759308384864
model initialize at round 3217
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09979245, 14.84920945,  0.98372597,  0.09916002,
       -0.14983493]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6118990125251638
{'scaleFactor': 20, 'currentState': array([29.19393627, 20.81239614, 13.27327569,  0.70646116,  0.63826197,
        0.30583376]), 'targetState': array([25., 25., 15.])}
episode index:3218
target thresh 34.76411699833909
model initialize at round 3218
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09607162, 14.91160381,  0.99141693,  0.09620913,
       -0.08852271]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6119984739527443
{'scaleFactor': 20, 'currentState': array([29.13614265, 21.12964786, 13.46154968,  0.69472472,  0.69571144,
        0.18260108]), 'targetState': array([25., 25., 15.])}
episode index:3219
target thresh 34.77064026047071
model initialize at round 3219
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.07338995, 14.84627329,  0.98551723,  0.07305763,
       -0.15303063]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6121007974544364
{'scaleFactor': 20, 'currentState': array([26.75586187, 20.6265109 , 11.86433997,  0.5763881 ,  0.81555912,
       -0.0513817 ]), 'targetState': array([25., 25., 15.])}
episode index:3220
target thresh 34.77716287030874
model initialize at round 3220
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10727513, 14.84627329,  0.98254142,  0.10646693,
       -0.15256854]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6122001344772406
{'scaleFactor': 20, 'currentState': array([28.95655309, 20.73527346, 12.63626389,  0.59030034,  0.76517288,
        0.25701356]), 'targetState': array([25., 25., 15.])}
episode index:3221
target thresh 34.78368482791839
model initialize at round 3221
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.90036523,  0.98330728,  0.15268747,
       -0.09896121]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6123023318747962
{'scaleFactor': 20, 'currentState': array([26.58396667, 21.50990971, 13.44063667,  0.51568529,  0.84602739,
        0.13530089]), 'targetState': array([25., 25., 15.])}
episode index:3222
target thresh 34.79020613336489
model initialize at round 3222
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11134036, 14.86107468,  0.98421169,  0.11068937,
       -0.13811305]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6124015447249458
{'scaleFactor': 20, 'currentState': array([29.12956858, 20.97176307, 13.19585274,  0.70540902,  0.65196925,
        0.27809029]), 'targetState': array([25., 25., 15.])}
episode index:3223
target thresh 34.79672678671345
model initialize at round 3223
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13097688, 14.90856949,  0.98723248,  0.13061074,
       -0.09117491]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6125006960286623
{'scaleFactor': 20, 'currentState': array([29.36915218, 20.64906561, 14.51828566,  0.65100506,  0.63637293,
        0.4137897 ]), 'targetState': array([25., 25., 15.])}
episode index:3224
target thresh 34.803246788029284
model initialize at round 3224
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.1157475 , 14.87125581,  0.98505144,  0.11516893,
       -0.12810066]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.612602705161491
{'scaleFactor': 20, 'currentState': array([27.27167282, 20.37049834, 13.91863818,  0.59296245,  0.7495423 ,
        0.29424798]), 'targetState': array([25., 25., 15.])}
episode index:3225
target thresh 34.809766137377586
model initialize at round 3225
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85001561,  0.97726744,  0.1517496 ,
       -0.14805542]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6127075989447329
{'scaleFactor': 20, 'currentState': array([25.19070484, 20.18882928, 13.39332244,  0.58714493,  0.79549428,
        0.14983218]), 'targetState': array([25., 25., 15.])}
episode index:3226
target thresh 34.81628483482354
model initialize at round 3226
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6128124277178829
{'scaleFactor': 20, 'currentState': array([25.1973214 , 20.18858447, 13.3966221 ,  0.58748532,  0.79544631,
        0.14874868]), 'targetState': array([25., 25., 15.])}
episode index:3227
target thresh 34.822802880432334
model initialize at round 3227
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87164742,  0.98014696,  0.15219673,
       -0.12707514]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6129171915413594
{'scaleFactor': 20, 'currentState': array([25.15296781, 20.17651533, 12.98940126,  0.59070288,  0.80495011,
        0.05590543]), 'targetState': array([25., 25., 15.])}
episode index:3228
target thresh 34.82932027426917
model initialize at round 3228
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84791679,  0.97696571,  0.15170275,
       -0.15008089]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6130218904755057
{'scaleFactor': 20, 'currentState': array([25.31843263, 20.05777572, 13.55609116,  0.60511385,  0.77847437,
        0.16677794]), 'targetState': array([25., 25., 15.])}
episode index:3229
target thresh 34.83583701639922
model initialize at round 3229
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6131265245805907
{'scaleFactor': 20, 'currentState': array([24.87279487, 20.07525924, 11.76087902,  0.5478373 ,  0.79061227,
       -0.27350782]), 'targetState': array([25., 25., 15.])}
episode index:3230
target thresh 34.84235310688762
model initialize at round 3230
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6132281505864157
{'scaleFactor': 20, 'currentState': array([26.36657384, 21.48554295, 12.04733666,  0.52256589,  0.85073263,
        0.05638158]), 'targetState': array([25., 25., 15.])}
episode index:3231
target thresh 34.84886854579955
model initialize at round 3231
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84706403,  0.976842  ,  0.15168354,
       -0.15090332]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6133326561245697
{'scaleFactor': 20, 'currentState': array([25.16003512, 20.16248038, 13.04705964,  0.60138535,  0.79345886,
        0.09358788]), 'targetState': array([25., 25., 15.])}
episode index:3232
target thresh 34.85538333320019
model initialize at round 3232
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11483233, 14.84627329,  0.9817302 ,  0.11387309,
       -0.15244258]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6134341555038696
{'scaleFactor': 20, 'currentState': array([26.46414182, 21.4816919 , 13.33952878,  0.48647013,  0.85567048,
        0.17656396]), 'targetState': array([25., 25., 15.])}
episode index:3233
target thresh 34.861897469154634
model initialize at round 3233
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6135385327130211
{'scaleFactor': 20, 'currentState': array([24.95898109, 20.06949315, 12.00377285,  0.58333906,  0.80557989,
       -0.10371392]), 'targetState': array([25., 25., 15.])}
episode index:3234
target thresh 34.86841095372806
model initialize at round 3234
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6136428453922133
{'scaleFactor': 20, 'currentState': array([25.12815505, 20.17533235, 12.93764474,  0.59861964,  0.7960381 ,
        0.08931893]), 'targetState': array([25., 25., 15.])}
episode index:3235
target thresh 34.874923786985605
model initialize at round 3235
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14917178, 14.864294  ,  0.97987708,  0.14764647,
       -0.13431839]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6137441548186684
{'scaleFactor': 20, 'currentState': array([26.3870676 , 21.63289982, 13.13730364,  0.48072805,  0.85681247,
        0.18647502]), 'targetState': array([25., 25., 15.])}
episode index:3236
target thresh 34.88143596899237
model initialize at round 3236
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6138483395252119
{'scaleFactor': 20, 'currentState': array([24.91999179, 20.13583802, 12.05599555,  0.57629468,  0.81352323,
       -0.07787419]), 'targetState': array([25., 25., 15.])}
episode index:3237
target thresh 34.88794749981351
model initialize at round 3237
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85272011,  0.97765046,  0.15180908,
       -0.14544268]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6139524598804851
{'scaleFactor': 20, 'currentState': array([25.16077484, 20.18641613, 13.15637651,  0.59021936,  0.80254696,
        0.08694532]), 'targetState': array([25., 25., 15.])}
episode index:3238
target thresh 34.89445837951411
model initialize at round 3238
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6140565159440909
{'scaleFactor': 20, 'currentState': array([24.98536021, 20.14282159, 12.22902804,  0.57798001,  0.80967724,
       -0.10179332]), 'targetState': array([25., 25., 15.])}
episode index:3239
target thresh 34.9009686081593
model initialize at round 3239
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.1322662 , 14.84627329,  0.97965737,  0.1308844 ,
       -0.15212071]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6141575726210838
{'scaleFactor': 20, 'currentState': array([27.13377103, 20.12356596, 11.56210447,  0.7009039 ,  0.71039484,
       -0.0638193 ]), 'targetState': array([25., 25., 15.])}
episode index:3240
target thresh 34.90747818581419
model initialize at round 3240
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09832795, 14.84627329,  0.98343279,  0.09767569,
       -0.15270695]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6142585669366593
{'scaleFactor': 20, 'currentState': array([26.65447381, 20.92183559, 12.46970557,  0.5340562 ,  0.8331947 ,
        0.14342444]), 'targetState': array([25., 25., 15.])}
episode index:3241
target thresh 34.91398711254384
model initialize at round 3241
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85497032,  0.97796417,  0.15185779,
       -0.1432665 ]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6143624322922926
{'scaleFactor': 20, 'currentState': array([25.14852734, 20.1392827 , 12.87523925,  0.59800807,  0.79975762,
        0.05266973]), 'targetState': array([25., 25., 15.])}
episode index:3242
target thresh 34.920495388413364
model initialize at round 3242
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12268602, 14.87412833,  0.98460169,  0.12201704,
       -0.12518531]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6144633011535657
{'scaleFactor': 20, 'currentState': array([26.41804826, 21.40298938, 12.68536192,  0.50004913,  0.85376817,
        0.14501997]), 'targetState': array([25., 25., 15.])}
episode index:3243
target thresh 34.92700301348785
model initialize at round 3243
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13276239, 14.84627329,  0.9795943 ,  0.13136695,
       -0.15211092]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6145612056069423
{'scaleFactor': 20, 'currentState': array([28.61401654, 21.5370573 , 12.23637689,  0.56497392,  0.81198091,
        0.14659969]), 'targetState': array([25., 25., 15.])}
episode index:3244
target thresh 34.933509987832366
model initialize at round 3244
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.614661951044167
{'scaleFactor': 20, 'currentState': array([ 2.63978348e+01,  2.14742980e+01,  1.21808443e+01,  5.09199543e-01,
        8.60500085e-01, -1.59821538e-02]), 'targetState': array([25., 25., 15.])}
episode index:3245
target thresh 34.94001631151197
model initialize at round 3245
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.614765564136852
{'scaleFactor': 20, 'currentState': array([24.95255808, 20.13515232, 12.11752032,  0.5752236 ,  0.8099411 ,
       -0.11451303]), 'targetState': array([25., 25., 15.])}
episode index:3246
target thresh 34.94652198459175
model initialize at round 3246
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6148691134087224
{'scaleFactor': 20, 'currentState': array([25.0971781 , 20.17736892, 12.8141174 ,  0.58798196,  0.80571918,
        0.07137092]), 'targetState': array([25., 25., 15.])}
episode index:3247
target thresh 34.95302700713674
model initialize at round 3247
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89742933,  0.98301947,  0.15264278,
       -0.10184744]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6149725989187259
{'scaleFactor': 20, 'currentState': array([25.35656099, 20.08202495, 13.92362127,  0.61670262,  0.76391626,
        0.19002588]), 'targetState': array([25., 25., 15.])}
episode index:3248
target thresh 34.959531379212
model initialize at round 3248
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12400217, 14.88143115,  0.98531361,  0.12341518,
       -0.11800758]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6150701959482698
{'scaleFactor': 20, 'currentState': array([28.95515174, 21.03665028, 12.67006814,  0.63073852,  0.74213261,
        0.22673356]), 'targetState': array([25., 25., 15.])}
episode index:3249
target thresh 34.96603510088258
model initialize at round 3249
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10482921, 14.84627329,  0.98279255,  0.10406603,
       -0.15260754]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6151677329181032
{'scaleFactor': 20, 'currentState': array([29.03724895, 20.58537355, 12.10248572,  0.6614588 ,  0.72668439,
        0.18547791]), 'targetState': array([25., 25., 15.])}
episode index:3250
target thresh 34.9725381722135
model initialize at round 3250
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.06253247, 14.84998577,  0.98679095,  0.06232978,
       -0.14952797]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.6149785087615612
{'scaleFactor': 20, 'currentState': array([30.44543401, 20.43886056, 14.48202105, -0.03129641,  0.71069971,
        0.70279901]), 'targetState': array([25., 25., 15.])}
episode index:3251
target thresh 34.97904059326981
model initialize at round 3251
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.91092834,  0.98427553,  0.15283782,
       -0.08855663]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6150818333437071
{'scaleFactor': 20, 'currentState': array([25.30599263, 20.17097836, 14.25352467,  0.5815226 ,  0.77978347,
        0.23188188]), 'targetState': array([25., 25., 15.])}
episode index:3252
target thresh 34.98554236411652
model initialize at round 3252
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.9352993 ,  0.98610367,  0.15312169,
       -0.06444606]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6151850944001339
{'scaleFactor': 20, 'currentState': array([25.27320113, 20.17401936, 13.67775016,  0.59297255,  0.79564383,
        0.12383232]), 'targetState': array([25., 25., 15.])}
episode index:3253
target thresh 34.99204348481866
model initialize at round 3253
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6152882919894086
{'scaleFactor': 20, 'currentState': array([24.89168284, 20.07813633, 11.87248402,  0.57624377,  0.81155084,
       -0.09658341]), 'targetState': array([25., 25., 15.])}
episode index:3254
target thresh 34.99854395544123
model initialize at round 3254
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84895814,  0.97711591,  0.15172607,
       -0.14907617]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6153914261700263
{'scaleFactor': 20, 'currentState': array([25.22937038, 20.06829211, 13.00410453,  0.63917537,  0.76181019,
        0.1053569 ]), 'targetState': array([25., 25., 15.])}
episode index:3255
target thresh 35.00504377604924
model initialize at round 3255
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12802791, 14.88640607,  0.98538212,  0.12743072,
       -0.11306407]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6154915762692987
{'scaleFactor': 20, 'currentState': array([26.52622488, 21.46254992, 13.40325036,  0.4913798 ,  0.847636  ,
        0.2001477 ]), 'targetState': array([25., 25., 15.])}
episode index:3256
target thresh 35.011542946707685
model initialize at round 3256
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85873079,  0.9784783 ,  0.15193762,
       -0.13962511]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6155945847045553
{'scaleFactor': 20, 'currentState': array([25.19375118, 20.18576981, 13.36339546,  0.58786882,  0.79616786,
        0.14327239]), 'targetState': array([25., 25., 15.])}
episode index:3257
target thresh 35.01804146748155
model initialize at round 3257
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87246046,  0.98024692,  0.15221225,
       -0.12628308]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6156975299056588
{'scaleFactor': 20, 'currentState': array([25.11326525, 20.17112383, 12.85765736,  0.58935179,  0.8061886 ,
        0.05219595]), 'targetState': array([25., 25., 15.])}
episode index:3258
target thresh 35.024539338435844
model initialize at round 3258
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85436577,  0.97788034,  0.15184477,
       -0.14385136]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6158004119308182
{'scaleFactor': 20, 'currentState': array([25.08937968, 20.04272985, 12.32093187,  0.58656768,  0.79621405,
       -0.14826175]), 'targetState': array([25., 25., 15.])}
episode index:3259
target thresh 35.03103655963553
model initialize at round 3259
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6159032308381708
{'scaleFactor': 20, 'currentState': array([24.86838392, 20.12236807, 11.90347315,  0.57303483,  0.81561636,
       -0.08000649]), 'targetState': array([25., 25., 15.])}
episode index:3260
target thresh 35.03753313114557
model initialize at round 3260
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6160059866857824
{'scaleFactor': 20, 'currentState': array([25.08639005, 20.18145639, 12.79503712,  0.58781781,  0.80685767,
        0.05874463]), 'targetState': array([25., 25., 15.])}
episode index:3261
target thresh 35.04402905303095
model initialize at round 3261
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6161086795316483
{'scaleFactor': 20, 'currentState': array([2.50523713e+01, 2.01181366e+01, 1.24341653e+01, 6.27583291e-01,
       7.78209164e-01, 2.30154232e-02]), 'targetState': array([25., 25., 15.])}
episode index:3262
target thresh 35.050524325356626
model initialize at round 3262
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15355996, 14.84627329,  0.97675107,  0.15150491,
       -0.15166942]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6162083949683229
{'scaleFactor': 20, 'currentState': array([26.68583512, 21.07898466, 12.80950067,  0.5312191 ,  0.82972197,
        0.17137013]), 'targetState': array([25., 25., 15.])}
episode index:3263
target thresh 35.05701894818753
model initialize at round 3263
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6163109628773092
{'scaleFactor': 20, 'currentState': array([25.17937962, 20.09162162, 12.83151201,  0.640416  ,  0.76349675,
        0.08330706]), 'targetState': array([25., 25., 15.])}
episode index:3264
target thresh 35.06351292158863
model initialize at round 3264
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.07260638, 14.90512766,  0.99279745,  0.07281154,
       -0.09514042]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6164105552774697
{'scaleFactor': 20, 'currentState': array([27.34991107, 20.21828952, 12.76574715,  0.74088952,  0.67068993,
        0.03546462]), 'targetState': array([25., 25., 15.])}
episode index:3265
target thresh 35.07000624562485
model initialize at round 3265
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.0728931 , 14.88792834,  0.99100466,  0.07296707,
       -0.11218539]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6165072040198547
{'scaleFactor': 20, 'currentState': array([28.67116288, 21.41623715, 13.63391201,  0.50665153,  0.80425658,
        0.31060517]), 'targetState': array([25., 25., 15.])}
episode index:3266
target thresh 35.07649892036115
model initialize at round 3266
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12119125, 14.98191624,  0.9924273 ,  0.12148839,
       -0.0181281 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6166066753836078
{'scaleFactor': 20, 'currentState': array([27.37018552, 20.58614937, 14.44209594,  0.67732311,  0.69257933,
        0.24812754]), 'targetState': array([25., 25., 15.])}
episode index:3267
target thresh 35.08299094586243
model initialize at round 3267
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15107206, 14.84627329,  0.97711156,  0.14910531,
       -0.1517254 ]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6167089958776458
{'scaleFactor': 20, 'currentState': array([25.10339023, 20.15914924, 12.83141387,  0.58924424,  0.80367125,
        0.08308876]), 'targetState': array([25., 25., 15.])}
episode index:3268
target thresh 35.08948232219362
model initialize at round 3268
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.90747661,  0.98397075,  0.15279049,
       -0.09195991]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.616811253771198
{'scaleFactor': 20, 'currentState': array([2.52441951e+01, 2.00944131e+01, 1.30872233e+01, 6.11391953e-01,
       7.91169320e-01, 1.58425465e-02]), 'targetState': array([25., 25., 15.])}
episode index:3269
target thresh 35.09597304941963
model initialize at round 3269
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6169105408952439
{'scaleFactor': 20, 'currentState': array([26.38111575, 21.43762273, 12.24971711,  0.51106422,  0.85193725,
        0.11408895]), 'targetState': array([25., 25., 15.])}
episode index:3270
target thresh 35.10246312760537
model initialize at round 3270
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.94166827,  0.98648721,  0.15318124,
       -0.05812475]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6170126746491432
{'scaleFactor': 20, 'currentState': array([25.34541121, 20.16498409, 14.57229668,  0.58133626,  0.77677127,
        0.24222829]), 'targetState': array([25., 25., 15.])}
episode index:3271
target thresh 35.108952556815744
model initialize at round 3271
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89602172,  0.98287861,  0.1526209 ,
       -0.10323033]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6171147459740977
{'scaleFactor': 20, 'currentState': array([25.26305497, 20.17707834, 13.68477057,  0.5900715 ,  0.79244422,
        0.1544273 ]), 'targetState': array([25., 25., 15.])}
episode index:3272
target thresh 35.11544133711564
model initialize at round 3272
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.88908399,  0.98215723,  0.15250889,
       -0.11003733]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6172167549273289
{'scaleFactor': 20, 'currentState': array([25.23201542, 20.18192436, 13.57961945,  0.58815681,  0.79314702,
        0.15808029]), 'targetState': array([25., 25., 15.])}
episode index:3273
target thresh 35.121929468569945
model initialize at round 3273
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.9205984 ,  0.98506901,  0.15296103,
       -0.07900612]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6173187015659888
{'scaleFactor': 20, 'currentState': array([25.34727283, 20.17302398, 14.39628781,  0.58667017,  0.7828025 ,
        0.20745687]), 'targetState': array([25., 25., 15.])}
episode index:3274
target thresh 35.128416951243544
model initialize at round 3274
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.51537267e+01, 1.50072809e+01, 9.88131770e-01,
       1.53436610e-01, 7.26716987e-03]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6174205859471594
{'scaleFactor': 20, 'currentState': array([25.4083718 , 20.15360938, 14.78629827,  0.60157985,  0.77947108,
        0.1747184 ]), 'targetState': array([25., 25., 15.])}
episode index:3275
target thresh 35.134903785201324
model initialize at round 3275
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89954956,  0.98322814,  0.15267518,
       -0.09976333]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6175224081278532
{'scaleFactor': 20, 'currentState': array([25.39574511, 20.05615939, 14.03552513,  0.66125414,  0.71875658,
        0.2147835 ]), 'targetState': array([25., 25., 15.])}
episode index:3276
target thresh 35.14138997050813
model initialize at round 3276
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08437781, 14.89141955,  0.99049075,  0.08441964,
       -0.10863427]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6176183931567757
{'scaleFactor': 20, 'currentState': array([29.22904373, 20.77061704, 14.5402283 ,  0.70039109,  0.60429432,
        0.37984299]), 'targetState': array([25., 25., 15.])}
episode index:3277
target thresh 35.14787550722885
model initialize at round 3277
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.0782745 , 14.84627329,  0.98515568,  0.07789149,
       -0.15297449]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.6174299799800957
{'scaleFactor': 20, 'currentState': array([37.53518066, 22.8975066 , 10.90045564,  0.5779865 ,  0.48281921,
        0.65788845]), 'targetState': array([25., 25., 15.])}
episode index:3278
target thresh 35.1543603954283
model initialize at round 3278
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09649353, 14.84627329,  0.98360624,  0.09587034,
       -0.15273389]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6175259346516196
{'scaleFactor': 20, 'currentState': array([28.87049384, 21.00545825, 12.35976723,  0.66741055,  0.71257243,
        0.21634162]), 'targetState': array([25., 25., 15.])}
episode index:3279
target thresh 35.160844635171365
model initialize at round 3279
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10649197, 14.86408016,  0.9851284 ,  0.10596794,
       -0.135251  ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6176247011805067
{'scaleFactor': 20, 'currentState': array([27.09049014, 20.55938286, 13.14467906,  0.64476877,  0.73245838,
        0.21858167]), 'targetState': array([25., 25., 15.])}
episode index:3280
target thresh 35.167328226522876
model initialize at round 3280
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10266624, 14.89283921,  0.9889504 ,  0.10255739,
       -0.10704717]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6177234075042557
{'scaleFactor': 20, 'currentState': array([26.9561129 , 20.76223792, 13.42266183,  0.55760415,  0.79598755,
        0.23554497]), 'targetState': array([25., 25., 15.])}
episode index:3281
target thresh 35.173811169547676
model initialize at round 3281
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.617824951270982
{'scaleFactor': 20, 'currentState': array([25.01027832, 20.14717011, 12.30258577,  0.57766935,  0.80671386,
       -0.12454264]), 'targetState': array([25., 25., 15.])}
episode index:3282
target thresh 35.18029346431057
model initialize at round 3282
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.617926433177357
{'scaleFactor': 20, 'currentState': array([24.946608  , 20.1380193 , 12.12064784,  0.57616583,  0.81115551,
       -0.10029788]), 'targetState': array([25., 25., 15.])}
episode index:3283
target thresh 35.18677511087641
model initialize at round 3283
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6180278532798913
{'scaleFactor': 20, 'currentState': array([25.05544153, 20.03970655, 12.21934736,  0.60255686,  0.79662155,
       -0.04815953]), 'targetState': array([25., 25., 15.])}
episode index:3284
target thresh 35.19325610931
model initialize at round 3284
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12215905, 14.86676959,  0.98373721,  0.12138627,
       -0.13238759]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6181263166881473
{'scaleFactor': 20, 'currentState': array([27.14754234, 20.41897601, 12.81883573,  0.65161806,  0.74626515,
        0.13594941]), 'targetState': array([25., 25., 15.])}
episode index:3285
target thresh 35.19973645967616
model initialize at round 3285
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11379156, 14.84627329,  0.98184507,  0.11285422,
       -0.15246041]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.6179382076447243
{'scaleFactor': 20, 'currentState': array([28.63720097, 27.28904125,  9.09244778,  0.56781291, -0.81988852,
        0.0732893 ]), 'targetState': array([25., 25., 15.])}
episode index:3286
target thresh 35.206216162039674
model initialize at round 3286
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.05247186, 14.85087533,  0.98748931,  0.05233879,
       -0.14874648]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.6177502130576709
{'scaleFactor': 20, 'currentState': array([35.386244  , 22.80084152,  7.89919573,  0.55040875,  0.54167677,
        0.63532393]), 'targetState': array([25., 25., 15.])}
episode index:3287
target thresh 35.21269521646535
model initialize at round 3287
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6178515633730122
{'scaleFactor': 20, 'currentState': array([25.04301075, 20.1342099 , 12.45609577,  0.59728311,  0.80162241,
        0.02558106]), 'targetState': array([25., 25., 15.])}
episode index:3288
target thresh 35.219173623017966
model initialize at round 3288
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86330215,  0.97908615,  0.15203201,
       -0.13519088]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.617952852058487
{'scaleFactor': 20, 'currentState': array([24.92876207, 20.11790264, 12.03523023,  0.5719546 ,  0.80946743,
       -0.13277954]), 'targetState': array([25., 25., 15.])}
episode index:3289
target thresh 35.22565138176233
model initialize at round 3289
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.618054079170293
{'scaleFactor': 20, 'currentState': array([25.06644601, 20.16849446, 12.67043514,  0.59595423,  0.80085801,
        0.05886429]), 'targetState': array([25., 25., 15.])}
episode index:3290
target thresh 35.232128492763216
model initialize at round 3290
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12446732, 14.85760046,  0.98223676,  0.12349129,
       -0.14128289]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6181523550956138
{'scaleFactor': 20, 'currentState': array([27.39581397, 20.07985083, 12.72845822,  0.74096435,  0.64607705,
        0.18318374]), 'targetState': array([25., 25., 15.])}
episode index:3291
target thresh 35.238604956085375
model initialize at round 3291
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08620509, 14.86827843,  0.98759228,  0.08599544,
       -0.13140122]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6182477114117777
{'scaleFactor': 20, 'currentState': array([29.06366373, 20.82865651, 13.46271376,  0.68077981,  0.68011394,
        0.27199977]), 'targetState': array([25., 25., 15.])}
episode index:3292
target thresh 35.24508077179358
model initialize at round 3292
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09231485, 14.84627329,  0.98398949,  0.09175438,
       -0.1527934 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6183458688481546
{'scaleFactor': 20, 'currentState': array([26.44841565, 21.25061541, 12.71096076,  0.49765791,  0.84731191,
        0.18547003]), 'targetState': array([25., 25., 15.])}
episode index:3293
target thresh 35.251555939952596
model initialize at round 3293
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.96003541,  0.98737261,  0.15331873,
       -0.03985853]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6184468537240051
{'scaleFactor': 20, 'currentState': array([25.35311977, 20.17577118, 14.14072192,  0.59727659,  0.79480619,
        0.10744205]), 'targetState': array([25., 25., 15.])}
episode index:3294
target thresh 35.258030460627175
model initialize at round 3294
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6185477773040282
{'scaleFactor': 20, 'currentState': array([24.94991088, 20.05393163, 11.91415896,  0.61666661,  0.78067612,
       -0.10132668]), 'targetState': array([25., 25., 15.])}
episode index:3295
target thresh 35.26450433388205
model initialize at round 3295
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14225086, 14.88661948,  0.98353462,  0.14132187,
       -0.11264007]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6186457543586693
{'scaleFactor': 20, 'currentState': array([26.70113013, 21.36546313, 14.29791854,  0.49346948,  0.81700803,
        0.29830478]), 'targetState': array([25., 25., 15.])}
episode index:3296
target thresh 35.27097755978198
model initialize at round 3296
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.92136049,  0.98512775,  0.15297015,
       -0.07825249]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6187436719792463
{'scaleFactor': 20, 'currentState': array([27.18645134, 20.87912525, 14.09759863,  0.62877326,  0.73107776,
        0.26489524]), 'targetState': array([25., 25., 15.])}
episode index:3297
target thresh 35.27745013839167
model initialize at round 3297
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12149007, 14.90616095,  0.9881905 ,  0.12126802,
       -0.09366753]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6188415302198229
{'scaleFactor': 20, 'currentState': array([27.17093621, 20.74194184, 13.96486012,  0.67671752,  0.68061337,
        0.28074692]), 'targetState': array([25., 25., 15.])}
episode index:3298
target thresh 35.28392206977586
model initialize at round 3298
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.0847241 , 14.90386748,  0.99172729,  0.08487192,
       -0.09630025]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6189393291343974
{'scaleFactor': 20, 'currentState': array([26.87280313, 20.67515498, 12.76176672,  0.55799132,  0.81667419,
        0.14727172]), 'targetState': array([25., 25., 15.])}
episode index:3299
target thresh 35.29039335399929
model initialize at round 3299
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85354222,  0.9777656 ,  0.15182696,
       -0.14464786]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6190399505649324
{'scaleFactor': 20, 'currentState': array([25.10215747, 20.11760285, 12.5916816 ,  0.62300896,  0.78153175,
        0.0326797 ]), 'targetState': array([25., 25., 15.])}
episode index:3300
target thresh 35.29686399112665
model initialize at round 3300
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.1284847 , 14.84627329,  0.98013066,  0.12720383,
       -0.1521942 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6191376301162308
{'scaleFactor': 20, 'currentState': array([26.83212887, 20.88491677, 12.74371131,  0.56895467,  0.80193931,
        0.18216456]), 'targetState': array([25., 25., 15.])}
episode index:3301
target thresh 35.30333398122263
model initialize at round 3301
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14007259, 14.84627329,  0.97863924,  0.13846518,
       -0.15196261]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.619235250503658
{'scaleFactor': 20, 'currentState': array([26.09689766, 21.59625454, 11.87714758,  0.46945412,  0.8819908 ,
        0.04129227]), 'targetState': array([25., 25., 15.])}
episode index:3302
target thresh 35.30980332435196
model initialize at round 3302
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86731292,  0.97960389,  0.1521124 ,
       -0.13129372]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6193356909515527
{'scaleFactor': 20, 'currentState': array([25.17820261, 20.18300682, 13.23985861,  0.58896346,  0.7989706 ,
        0.12152378]), 'targetState': array([25., 25., 15.])}
episode index:3303
target thresh 35.31627202057932
model initialize at round 3303
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6194360706001448
{'scaleFactor': 20, 'currentState': array([25.2877625 , 20.03274936, 13.35945134,  0.60448338,  0.78249074,
        0.14935892]), 'targetState': array([25., 25., 15.])}
episode index:3304
target thresh 35.322740069969406
model initialize at round 3304
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14686525, 14.90942093,  0.98514828,  0.14614551,
       -0.09013517]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6195335120763327
{'scaleFactor': 20, 'currentState': array([26.30796717, 21.52960035, 12.08609735,  0.52726487,  0.84044688,
       -0.12506317]), 'targetState': array([25., 25., 15.])}
episode index:3305
target thresh 35.3292074725869
model initialize at round 3305
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09133913, 14.84627329,  0.98407659,  0.09079263,
       -0.15280692]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.619630894604259
{'scaleFactor': 20, 'currentState': array([26.55946703, 20.99364532, 12.25845727,  0.52833312,  0.84343558,
        0.09736808]), 'targetState': array([25., 25., 15.])}
episode index:3306
target thresh 35.33567422849645
model initialize at round 3306
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6197282182373999
{'scaleFactor': 20, 'currentState': array([26.48767562, 21.13255881, 11.20301569,  0.67685982,  0.72492838,
       -0.12782657]), 'targetState': array([25., 25., 15.])}
episode index:3307
target thresh 35.34214033776274
model initialize at round 3307
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09420119, 14.84627329,  0.98381853,  0.093613  ,
       -0.15276685]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.6195408759707017
{'scaleFactor': 20, 'currentState': array([32.06188563, 29.47300736, 12.63434919, -0.14708284,  0.65725925,
        0.73917313]), 'targetState': array([25., 25., 15.])}
episode index:3308
target thresh 35.34860580045045
model initialize at round 3308
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13339169, 14.9194575 ,  0.98783878,  0.13310048,
       -0.08036668]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6196381679844309
{'scaleFactor': 20, 'currentState': array([26.45717988, 21.58990843, 13.28855257,  0.4947714 ,  0.86066638,
        0.12022748]), 'targetState': array([25., 25., 15.])}
episode index:3309
target thresh 35.355070616624204
model initialize at round 3309
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.619735401211445
{'scaleFactor': 20, 'currentState': array([26.22730209, 21.56870493, 11.97165551,  0.52023332,  0.85289325,
        0.04393631]), 'targetState': array([25., 25., 15.])}
episode index:3310
target thresh 35.36153478634867
model initialize at round 3310
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14611803, 14.84627329,  0.97781301,  0.1443193 ,
       -0.15183432]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6198325757050087
{'scaleFactor': 20, 'currentState': array([26.78121117, 20.78784428, 11.97206763,  0.59972113,  0.79863745,
        0.05012765]), 'targetState': array([25., 25., 15.])}
episode index:3311
target thresh 35.36799830968849
model initialize at round 3311
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10451957, 14.84627329,  0.98282395,  0.10376195,
       -0.15261241]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6199268488850214
{'scaleFactor': 20, 'currentState': array([29.19775882, 20.70485341, 11.83319363,  0.72992072,  0.68197966,
        0.04603781]), 'targetState': array([25., 25., 15.])}
episode index:3312
target thresh 35.374461186708274
model initialize at round 3312
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6200239069292459
{'scaleFactor': 20, 'currentState': array([25.54487458, 21.60800057, 10.41253843,  0.37209352,  0.84193801,
       -0.39075159]), 'targetState': array([25., 25., 15.])}
episode index:3313
target thresh 35.38092341747269
model initialize at round 3313
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.6198368146217839
{'scaleFactor': 20, 'currentState': array([22.68608888, 30.97306405, 10.5890944 , -0.24183025,  0.48038178,
        0.84306078]), 'targetState': array([25., 25., 15.])}
episode index:3314
target thresh 35.38738500204632
model initialize at round 3314
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08938215, 14.91989037,  0.99273043,  0.08962866,
       -0.08033058]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6199310012079936
{'scaleFactor': 20, 'currentState': array([28.85999643, 21.00001559, 12.41847629,  0.5869619 ,  0.80130555,
        0.11569413]), 'targetState': array([25., 25., 15.])}
episode index:3315
target thresh 35.393845940493804
model initialize at round 3315
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86321599,  0.97907487,  0.15203026,
       -0.13527453]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6200308380743061
{'scaleFactor': 20, 'currentState': array([24.99279302, 20.08070665, 12.12604854,  0.58863808,  0.8041653 ,
       -0.08260376]), 'targetState': array([25., 25., 15.])}
episode index:3316
target thresh 35.40030623287975
model initialize at round 3316
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.620130614743533
{'scaleFactor': 20, 'currentState': array([25.10760436, 20.17911667, 12.86662198,  0.58817453,  0.8048798 ,
        0.07886208]), 'targetState': array([25., 25., 15.])}
episode index:3317
target thresh 35.40676587926876
model initialize at round 3317
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15290641, 14.84917326,  0.97726656,  0.15093971,
       -0.14888679]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6202303312701023
{'scaleFactor': 20, 'currentState': array([ 2.50779704e+01,  2.01362846e+01,  1.25734189e+01,  5.90207114e-01,
        8.07178459e-01, -1.08856663e-02]), 'targetState': array([25., 25., 15.])}
episode index:3318
target thresh 35.41322487972543
model initialize at round 3318
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6203299877083759
{'scaleFactor': 20, 'currentState': array([2.50401587e+01, 2.01659257e+01, 1.25378139e+01, 5.85941283e-01,
       8.09980999e-01, 2.45681746e-02]), 'targetState': array([25., 25., 15.])}
episode index:3319
target thresh 35.41968323431435
model initialize at round 3319
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84791142,  0.97696493,  0.15170263,
       -0.15008607]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6204267196847892
{'scaleFactor': 20, 'currentState': array([26.59197167, 21.29178711, 12.29438923,  0.55185162,  0.83217362,
        0.05428496]), 'targetState': array([25., 25., 15.])}
episode index:3320
target thresh 35.4261409431001
model initialize at round 3320
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6205262569718158
{'scaleFactor': 20, 'currentState': array([24.86309304, 20.11232461, 11.84680853,  0.5693842 ,  0.81304446,
       -0.12149209]), 'targetState': array([25., 25., 15.])}
episode index:3321
target thresh 35.432598006147266
model initialize at round 3321
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6206257343327214
{'scaleFactor': 20, 'currentState': array([25.05797966, 20.17795534, 12.67547705,  0.58639151,  0.80778591,
        0.06022386]), 'targetState': array([25., 25., 15.])}
episode index:3322
target thresh 35.4390544235204
model initialize at round 3322
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6207222899797477
{'scaleFactor': 20, 'currentState': array([2.68674971e+01, 2.08352534e+01, 1.18850128e+01, 7.17055898e-01,
       6.96865515e-01, 1.44669894e-02]), 'targetState': array([25., 25., 15.])}
episode index:3323
target thresh 35.44551019528408
model initialize at round 3323
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.02454603, 14.84627329,  0.98786142,  0.024493  ,
       -0.15339463]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.620535550421992
{'scaleFactor': 20, 'currentState': array([33.85675238, 23.54406952,  7.74047453,  0.3872687 ,  0.5530402 ,
        0.73767845]), 'targetState': array([25., 25., 15.])}
episode index:3324
target thresh 35.451965321502854
model initialize at round 3324
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85888848,  0.97849958,  0.15194093,
       -0.13947229]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6206349352338651
{'scaleFactor': 20, 'currentState': array([25.08651769, 20.15684991, 12.61049284,  0.58696995,  0.808906  ,
       -0.03372489]), 'targetState': array([25., 25., 15.])}
episode index:3325
target thresh 35.458419802241295
model initialize at round 3325
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.620731401022851
{'scaleFactor': 20, 'currentState': array([26.43554876, 21.30672779, 12.10660207,  0.52286554,  0.84774258,
        0.08912994]), 'targetState': array([25., 25., 15.])}
episode index:3326
target thresh 35.46487363756392
model initialize at round 3326
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.620830667223295
{'scaleFactor': 20, 'currentState': array([25.03992979, 20.16090879, 12.55090215,  0.58805059,  0.80767131,
        0.04316885]), 'targetState': array([25., 25., 15.])}
episode index:3327
target thresh 35.471326827535286
model initialize at round 3327
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6209298737685706
{'scaleFactor': 20, 'currentState': array([24.87929079, 20.11232542, 11.87124879,  0.56818956,  0.81017679,
       -0.14413259]), 'targetState': array([25., 25., 15.])}
episode index:3328
target thresh 35.47777937221993
model initialize at round 3328
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.621029020712437
{'scaleFactor': 20, 'currentState': array([2.49914322e+01, 2.01657085e+01, 1.23980212e+01, 5.83684776e-01,
       8.11698508e-01, 2.13919529e-02]), 'targetState': array([25., 25., 15.])}
episode index:3329
target thresh 35.48423127168234
model initialize at round 3329
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89605032,  0.98288149,  0.15262135,
       -0.10320223]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6211281081085895
{'scaleFactor': 20, 'currentState': array([25.26415232, 20.17600415, 13.66639834,  0.59449527,  0.79037451,
        0.14793074]), 'targetState': array([25., 25., 15.])}
episode index:3330
target thresh 35.4906825259871
model initialize at round 3330
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10613219, 14.92053074,  0.9911507 ,  0.10625555,
       -0.07956163]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6212242810420305
{'scaleFactor': 20, 'currentState': array([26.76519138, 21.01914211, 12.98476421,  0.53626933,  0.83807845,
        0.10019845]), 'targetState': array([25., 25., 15.])}
episode index:3331
target thresh 35.497133135198666
model initialize at round 3331
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6213203962486209
{'scaleFactor': 20, 'currentState': array([26.36794792, 21.44634718, 12.0217012 ,  0.58212704,  0.81004611,
        0.0703804 ]), 'targetState': array([25., 25., 15.])}
episode index:3332
target thresh 35.50358309938155
model initialize at round 3332
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12020029, 14.85476434,  0.98234711,  0.11927112,
       -0.14411297]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6214164537803197
{'scaleFactor': 20, 'currentState': array([27.26161045, 20.3665739 , 12.53496599,  0.76039335,  0.63406828,
        0.14056805]), 'targetState': array([25., 25., 15.])}
episode index:3333
target thresh 35.51003241860028
model initialize at round 3333
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08898114, 14.84627329,  0.98428337,  0.08846733,
       -0.15283903]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.6212300661217173
{'scaleFactor': 20, 'currentState': array([21.24983471, 36.70691441,  7.47251748,  0.66448328, -0.73862507,
       -0.113556  ]), 'targetState': array([25., 25., 15.])}
episode index:3334
target thresh 35.51648109291933
model initialize at round 3334
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6213289446775729
{'scaleFactor': 20, 'currentState': array([24.80240871, 20.07786903, 11.62865026,  0.55469829,  0.80485939,
       -0.2109767 ]), 'targetState': array([25., 25., 15.])}
episode index:3335
target thresh 35.5229291224032
model initialize at round 3335
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6214249132641206
{'scaleFactor': 20, 'currentState': array([25.7640109 , 21.6405675 , 10.81993909,  0.46801404,  0.86422199,
       -0.1846164 ]), 'targetState': array([25., 25., 15.])}
episode index:3336
target thresh 35.52937650711634
model initialize at round 3336
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.144506  , 14.84627329,  0.97803653,  0.14275974,
       -0.15186903]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6215208243327861
{'scaleFactor': 20, 'currentState': array([26.09852575, 21.47841456, 11.17776071,  0.52426815,  0.82344714,
       -0.21697401]), 'targetState': array([25., 25., 15.])}
episode index:3337
target thresh 35.535823247123254
model initialize at round 3337
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10670964, 14.84627329,  0.98259998,  0.10591201,
       -0.15257764]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.6213346287592892
{'scaleFactor': 20, 'currentState': array([24.37843814, 19.14887062,  6.1684885 ,  0.87230925, -0.14469545,
        0.46705439]), 'targetState': array([25., 25., 15.])}
episode index:3338
target thresh 35.54226934248841
model initialize at round 3338
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.07409421, 14.89541329,  0.99172296,  0.07422316,
       -0.10476873]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6214276897713131
{'scaleFactor': 20, 'currentState': array([29.08112537, 20.72050931, 12.71698653,  0.66332318,  0.70840147,
        0.24118398]), 'targetState': array([25., 25., 15.])}
episode index:3339
target thresh 35.54871479327624
model initialize at round 3339
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12256579, 14.85804015,  0.98252442,  0.12164028,
       -0.1408879 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6215235138610226
{'scaleFactor': 20, 'currentState': array([ 2.71630989e+01,  2.01844486e+01,  1.20404679e+01,  6.44769390e-01,
        7.64299935e-01, -1.08648121e-02]), 'targetState': array([25., 25., 15.])}
episode index:3340
target thresh 35.55515959955123
model initialize at round 3340
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6216192805882119
{'scaleFactor': 20, 'currentState': array([27.03870029, 20.72037666, 12.49219677,  0.66141994,  0.73354617,
        0.15631279]), 'targetState': array([25., 25., 15.])}
episode index:3341
target thresh 35.561603761377825
model initialize at round 3341
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6217149900043737
{'scaleFactor': 20, 'currentState': array([26.35994839, 21.48772089, 12.61403538,  0.49502855,  0.85116799,
        0.17452734]), 'targetState': array([25., 25., 15.])}
episode index:3342
target thresh 35.568047278820444
model initialize at round 3342
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.950464  ,  0.9869522 ,  0.15325345,
       -0.0493835 ]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6218134868813991
{'scaleFactor': 20, 'currentState': array([ 2.52198482e+01,  2.01536810e+01,  1.32330690e+01,  5.94081788e-01,
        8.04367993e-01, -7.67866062e-03]), 'targetState': array([25., 25., 15.])}
episode index:3343
target thresh 35.57449015194353
model initialize at round 3343
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13129832, 14.84627329,  0.97977975,  0.12994286,
       -0.15213971]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6219062655479738
{'scaleFactor': 20, 'currentState': array([2.92325941e+01, 2.06372059e+01, 1.16458378e+01, 8.07274921e-01,
       5.89688603e-01, 2.39698358e-02]), 'targetState': array([25., 25., 15.])}
episode index:3344
target thresh 35.580932380811525
model initialize at round 3344
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09045787, 14.84627329,  0.98415449,  0.08992376,
       -0.15281902]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6220018033308894
{'scaleFactor': 20, 'currentState': array([ 2.67862846e+01,  2.03795891e+01,  1.14746310e+01,  5.89347626e-01,
        8.07660228e-01, -1.88237174e-02]), 'targetState': array([25., 25., 15.])}
episode index:3345
target thresh 35.587373965488844
model initialize at round 3345
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15368659, 14.84627329,  0.97673257,  0.15162697,
       -0.15166655]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.622100126178041
{'scaleFactor': 20, 'currentState': array([ 2.49696148e+01,  2.01545552e+01,  1.22660541e+01,  5.81815680e-01,
        8.13153873e-01, -1.64709850e-02]), 'targetState': array([25., 25., 15.])}
episode index:3346
target thresh 35.5938149060399
model initialize at round 3346
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6221983902723709
{'scaleFactor': 20, 'currentState': array([24.85222049, 20.10010254, 11.78364577,  0.56210327,  0.80690367,
       -0.18151139]), 'targetState': array([25., 25., 15.])}
episode index:3347
target thresh 35.600255202529105
model initialize at round 3347
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.622296595666525
{'scaleFactor': 20, 'currentState': array([24.9429431 , 20.14917655, 12.17464775,  0.58010854,  0.81404533,
       -0.02835989]), 'targetState': array([25., 25., 15.])}
episode index:3348
target thresh 35.60669485502086
model initialize at round 3348
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6223947424130862
{'scaleFactor': 20, 'currentState': array([25.00151966, 20.12926087, 12.22156973,  0.58131269,  0.79908215,
       -0.15343818]), 'targetState': array([25., 25., 15.])}
episode index:3349
target thresh 35.61313386357956
model initialize at round 3349
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6224928305645749
{'scaleFactor': 20, 'currentState': array([24.70143855, 20.00659196, 11.29485459,  0.52363615,  0.78290992,
       -0.33594231]), 'targetState': array([25., 25., 15.])}
episode index:3350
target thresh 35.619572228269604
model initialize at round 3350
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6225908601734486
{'scaleFactor': 20, 'currentState': array([2.49770067e+01, 2.01622214e+01, 1.23388525e+01, 5.82893207e-01,
       8.12465386e-01, 1.16407095e-02]), 'targetState': array([25., 25., 15.])}
episode index:3351
target thresh 35.62600994915537
model initialize at round 3351
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.92017172,  0.98503588,  0.15295588,
       -0.079428  ]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6226888312921021
{'scaleFactor': 20, 'currentState': array([25.3310097 , 20.17813735, 14.08513601,  0.59206863,  0.79029084,
        0.1577819 ]), 'targetState': array([25., 25., 15.])}
episode index:3352
target thresh 35.63244702630123
model initialize at round 3352
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.93373669,  0.98600358,  0.15310615,
       -0.06599582]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.622786743972868
{'scaleFactor': 20, 'currentState': array([25.25927112, 20.14560381, 13.40491302,  0.60086816,  0.7956    ,
        0.07731812]), 'targetState': array([25., 25., 15.])}
episode index:3353
target thresh 35.63888345977156
model initialize at round 3353
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.90780398,  0.98400014,  0.15279505,
       -0.09163727]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6228845982680162
{'scaleFactor': 20, 'currentState': array([25.27861799, 20.14448654, 13.53045913,  0.5993667 ,  0.79225549,
        0.11441504]), 'targetState': array([25., 25., 15.])}
episode index:3354
target thresh 35.645319249630724
model initialize at round 3354
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6229823942297547
{'scaleFactor': 20, 'currentState': array([25.06401546, 20.17273047, 12.66442659,  0.58695455,  0.80802219,
        0.05083788]), 'targetState': array([25., 25., 15.])}
episode index:3355
target thresh 35.651754395943094
model initialize at round 3355
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.88109084,  0.98127054,  0.1523712 ,
       -0.11786066]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6230801319102285
{'scaleFactor': 20, 'currentState': array([24.99834171, 20.1351054 , 12.3026827 ,  0.5794756 ,  0.80989548,
       -0.09097991]), 'targetState': array([25., 25., 15.])}
episode index:3356
target thresh 35.658188898773005
model initialize at round 3356
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6231778113615213
{'scaleFactor': 20, 'currentState': array([2.50011842e+01, 2.01667551e+01, 1.24282404e+01, 5.84169468e-01,
       8.11496995e-01, 1.47871377e-02]), 'targetState': array([25., 25., 15.])}
episode index:3357
target thresh 35.664622758184784
model initialize at round 3357
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6232754326356543
{'scaleFactor': 20, 'currentState': array([25.12461837, 20.17652971, 12.9394993 ,  0.59034955,  0.80191229,
        0.09178284]), 'targetState': array([25., 25., 15.])}
episode index:3358
target thresh 35.671055974242805
model initialize at round 3358
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.92492318,  0.98539496,  0.15301164,
       -0.0747276 ]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6233729957845869
{'scaleFactor': 20, 'currentState': array([25.23306642, 20.16957844, 13.3402786 ,  0.59497411,  0.80320568,
        0.02943538]), 'targetState': array([25., 25., 15.])}
episode index:3359
target thresh 35.67748854701137
model initialize at round 3359
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86940743,  0.97986845,  0.15215349,
       -0.1292561 ]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6234705008602165
{'scaleFactor': 20, 'currentState': array([25.12635645, 20.06998309, 12.54971715,  0.6071287 ,  0.79400876,
       -0.03073811]), 'targetState': array([25., 25., 15.])}
episode index:3360
target thresh 35.683920476554846
model initialize at round 3360
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6235651184289581
{'scaleFactor': 20, 'currentState': array([26.15089203, 21.6224122 , 11.91578316,  0.49122333,  0.86968127,
        0.04851933]), 'targetState': array([25., 25., 15.])}
episode index:3361
target thresh 35.6903517629375
model initialize at round 3361
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6236625083550352
{'scaleFactor': 20, 'currentState': array([24.8972276 , 20.13361174, 12.00926425,  0.57580769,  0.81508311,
       -0.06391417]), 'targetState': array([25., 25., 15.])}
episode index:3362
target thresh 35.69678240622369
model initialize at round 3362
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85899889,  0.97851447,  0.15194324,
       -0.13936528]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6237598403626312
{'scaleFactor': 20, 'currentState': array([24.94035016, 20.13513121, 12.12574418,  0.57794148,  0.81333491,
       -0.06685783]), 'targetState': array([25., 25., 15.])}
episode index:3363
target thresh 35.70321240647769
model initialize at round 3363
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85518669,  0.9779941 ,  0.15186244,
       -0.14305714]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6238571145033974
{'scaleFactor': 20, 'currentState': array([24.92538048, 20.11858103, 12.02069506,  0.57734009,  0.80850466,
       -0.11401156]), 'targetState': array([25., 25., 15.])}
episode index:3364
target thresh 35.70964176376382
model initialize at round 3364
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14751093, 14.84627329,  0.977618  ,  0.145666  ,
       -0.15180404]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6239515047069331
{'scaleFactor': 20, 'currentState': array([26.04847463, 21.29411556, 10.80566023,  0.4903518 ,  0.84223937,
       -0.2240267 ]), 'targetState': array([25., 25., 15.])}
episode index:3365
target thresh 35.71607047814638
model initialize at round 3365
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.624048664108357
{'scaleFactor': 20, 'currentState': array([24.77634758, 20.07191836, 11.56766247,  0.55719488,  0.81022095,
       -0.18186775]), 'targetState': array([25., 25., 15.])}
episode index:3366
target thresh 35.72249854968963
model initialize at round 3366
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6241429413537661
{'scaleFactor': 20, 'currentState': array([26.05331498, 21.49524033, 11.04267961,  0.53190482,  0.82901023,
       -0.17268269]), 'targetState': array([25., 25., 15.])}
episode index:3367
target thresh 35.72892597845786
model initialize at round 3367
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.06522628, 14.84627329,  0.98607027,  0.06496737,
       -0.1531165 ]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6242343672464483
{'scaleFactor': 20, 'currentState': array([27.89528065, 21.44652613, 10.39764383,  0.4843574 ,  0.86270128,
       -0.14541118]), 'targetState': array([25., 25., 15.])}
episode index:3368
target thresh 35.73535276451536
model initialize at round 3368
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6243313561697649
{'scaleFactor': 20, 'currentState': array([24.89790284, 20.13147001, 11.99370852,  0.57554288,  0.81488924,
       -0.0685997 ]), 'targetState': array([25., 25., 15.])}
episode index:3369
target thresh 35.74177890792638
model initialize at round 3369
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85383993,  0.97780715,  0.15183341,
       -0.14435996]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6244254656039581
{'scaleFactor': 20, 'currentState': array([27.43080126, 20.00888948, 12.08946725,  0.79401387,  0.60529581,
        0.05620456]), 'targetState': array([25., 25., 15.])}
episode index:3370
target thresh 35.74820440875519
model initialize at round 3370
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08065008, 14.85661561,  0.986473  ,  0.08036275,
       -0.14287356]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.6242402311140133
{'scaleFactor': 20, 'currentState': array([35.14598908, 22.89475597, 15.15123712,  0.36308499,  0.74762172,
        0.55608548]), 'targetState': array([25., 25., 15.])}
episode index:3371
target thresh 35.75462926706605
model initialize at round 3371
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11891635, 14.88330527,  0.98613269,  0.11845182,
       -0.11623887]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6243315197014371
{'scaleFactor': 20, 'currentState': array([29.18954147, 20.8577265 , 13.06889419,  0.69783162,  0.66272207,
        0.27171768]), 'targetState': array([25., 25., 15.])}
episode index:3372
target thresh 35.76105348292319
model initialize at round 3372
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13112299, 14.84627329,  0.97980183,  0.12977227,
       -0.15214314]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.624425545384716
{'scaleFactor': 20, 'currentState': array([26.92589083, 20.80784819, 12.73350874,  0.61711791,  0.76431857,
        0.18703637]), 'targetState': array([25., 25., 15.])}
episode index:3373
target thresh 35.767477056390874
model initialize at round 3373
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14055992, 14.86272437,  0.98087052,  0.13926372,
       -0.13600972]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6245195153325571
{'scaleFactor': 20, 'currentState': array([ 2.63605442e+01,  2.15118693e+01,  1.21943191e+01,  5.19736391e-01,
        8.54321648e-01, -2.93359638e-03]), 'targetState': array([25., 25., 15.])}
episode index:3374
target thresh 35.77389998753333
model initialize at round 3374
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84712063,  0.97685023,  0.15168482,
       -0.15084873]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6246134295945033
{'scaleFactor': 20, 'currentState': array([26.70104521, 21.07904729, 12.4106482 ,  0.577496  ,  0.80624532,
        0.12832327]), 'targetState': array([25., 25., 15.])}
episode index:3375
target thresh 35.78032227641478
model initialize at round 3375
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08933687, 14.96347189,  0.99528135,  0.08981346,
       -0.03672298]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.62470449947552
{'scaleFactor': 20, 'currentState': array([29.12648879, 20.78005543, 12.47237548,  0.66190342,  0.73082165,
        0.16668408]), 'targetState': array([25., 25., 15.])}
episode index:3376
target thresh 35.786743923099436
model initialize at round 3376
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89351227,  0.98262287,  0.15258119,
       -0.10569422]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6247983033398745
{'scaleFactor': 20, 'currentState': array([26.52568538, 21.55240636, 13.81915849,  0.4800542 ,  0.83907646,
        0.25592706]), 'targetState': array([25., 25., 15.])}
episode index:3377
target thresh 35.79316492765157
model initialize at round 3377
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86541432,  0.97936062,  0.15207463,
       -0.13313931]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6248948669119765
{'scaleFactor': 20, 'currentState': array([2.50456943e+01, 2.01450837e+01, 1.25065570e+01, 6.04856653e-01,
       7.96187378e-01, 1.52999395e-02]), 'targetState': array([25., 25., 15.])}
episode index:3378
target thresh 35.79958529013532
model initialize at round 3378
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10633119, 14.88822567,  0.98807522,  0.10612445,
       -0.11155701]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6249857726476957
{'scaleFactor': 20, 'currentState': array([ 2.91795935e+01,  2.04356052e+01,  1.15735494e+01,  7.23290881e-01,
        6.90094121e-01, -2.49079542e-02]), 'targetState': array([25., 25., 15.])}
episode index:3379
target thresh 35.806005010614925
model initialize at round 3379
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.1400877 , 14.84627329,  0.97863721,  0.13847983,
       -0.1519623 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6250794100372676
{'scaleFactor': 20, 'currentState': array([27.15761546, 20.46848388, 12.32617761,  0.72879198,  0.6720625 ,
        0.13112681]), 'targetState': array([25., 25., 15.])}
episode index:3380
target thresh 35.81242408915459
model initialize at round 3380
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10545376, 14.92446476,  0.99152511,  0.10561622,
       -0.0756516 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6251729920364878
{'scaleFactor': 20, 'currentState': array([26.5819756 , 21.3030086 , 13.0054301 ,  0.51579319,  0.84685549,
        0.12958843]), 'targetState': array([25., 25., 15.])}
episode index:3381
target thresh 35.818842525818496
model initialize at round 3381
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13973485, 14.89957574,  0.98522785,  0.13906128,
       -0.09994018]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6252665186944903
{'scaleFactor': 20, 'currentState': array([26.72221604, 21.30848225, 13.65250854,  0.56391018,  0.78835526,
        0.2459701 ]), 'targetState': array([25., 25., 15.])}
episode index:3382
target thresh 35.82526032067083
model initialize at round 3382
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08232092, 14.9217581 ,  0.99348403,  0.08261062,
       -0.07851725]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6253599900603509
{'scaleFactor': 20, 'currentState': array([26.8308075 , 21.00878188, 13.48535117,  0.53031898,  0.83154446,
        0.16521378]), 'targetState': array([25., 25., 15.])}
episode index:3383
target thresh 35.831677473775756
model initialize at round 3383
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11018073, 14.89810911,  0.98870488,  0.11003659,
       -0.1017576 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6254534061830874
{'scaleFactor': 20, 'currentState': array([27.0343062 , 20.67657676, 13.31033564,  0.5733601 ,  0.79340357,
        0.20437459]), 'targetState': array([25., 25., 15.])}
episode index:3384
target thresh 35.83809398519746
model initialize at round 3384
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86568867,  0.97939598,  0.15208012,
       -0.1328727 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6255467671116599
{'scaleFactor': 20, 'currentState': array([26.9276    , 21.19175465, 13.81837133,  0.67895872,  0.67838313,
        0.28073365]), 'targetState': array([25., 25., 15.])}
episode index:3385
target thresh 35.844509855000105
model initialize at round 3385
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.03332848, 14.84627329,  0.98761154,  0.03324807,
       -0.15335583]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.6253620220534462
{'scaleFactor': 20, 'currentState': array([30.66130124, 21.40659474, 10.45068492,  0.75570451,  0.32059436,
        0.57107788]), 'targetState': array([25., 25., 15.])}
episode index:3386
target thresh 35.850925083247844
model initialize at round 3386
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.88051803,  0.98120473,  0.15236098,
       -0.11842047]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6254581625990165
{'scaleFactor': 20, 'currentState': array([25.16504497, 20.17342069, 13.07325936,  0.59081973,  0.8032303 ,
        0.07584946]), 'targetState': array([25., 25., 15.])}
episode index:3387
target thresh 35.857339670004826
model initialize at round 3387
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.92497854,  0.98539901,  0.15301227,
       -0.0746728 ]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.625554246391018
{'scaleFactor': 20, 'currentState': array([2.52723176e+01, 2.00838481e+01, 1.31366770e+01, 6.15959588e-01,
       7.87764223e-01, 4.61679690e-03]), 'targetState': array([25., 25., 15.])}
episode index:3388
target thresh 35.86375361533523
model initialize at round 3388
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.88799976,  0.98204043,  0.15249075,
       -0.11109977]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6256502734796899
{'scaleFactor': 20, 'currentState': array([25.23235299, 20.17991316, 13.43769608,  0.59171619,  0.79818741,
        0.11299918]), 'targetState': array([25., 25., 15.])}
episode index:3389
target thresh 35.870166919303145
model initialize at round 3389
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6257462439152122
{'scaleFactor': 20, 'currentState': array([24.98298046, 20.15603827, 12.29400592,  0.58229846,  0.8125449 ,
       -0.02644406]), 'targetState': array([25., 25., 15.])}
episode index:3390
target thresh 35.876579581972734
model initialize at round 3390
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.88831118,  0.98207409,  0.15249598,
       -0.11079464]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6258421577477056
{'scaleFactor': 20, 'currentState': array([25.01946849, 20.07744575, 12.22609633,  0.61055545,  0.78921912,
       -0.06599406]), 'targetState': array([25., 25., 15.])}
episode index:3391
target thresh 35.88299160340813
model initialize at round 3391
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11418132, 14.87717184,  0.985954  ,  0.11371467,
       -0.12232617]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6259324358108421
{'scaleFactor': 20, 'currentState': array([29.28364698, 20.62951029, 13.02831595,  0.68553757,  0.69674577,
        0.21114822]), 'targetState': array([25., 25., 15.])}
episode index:3392
target thresh 35.88940298367342
model initialize at round 3392
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14052549, 14.84627329,  0.97857848,  0.13890426,
       -0.15195318]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6260254354317057
{'scaleFactor': 20, 'currentState': array([25.90872327, 21.6608227 , 11.32612861,  0.44328177,  0.88692699,
       -0.12985291]), 'targetState': array([25., 25., 15.])}
episode index:3393
target thresh 35.895813722832756
model initialize at round 3393
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6261211822244188
{'scaleFactor': 20, 'currentState': array([24.85652182, 20.09860057, 11.79915417,  0.56608082,  0.81108   ,
       -0.14731507]), 'targetState': array([25., 25., 15.])}
episode index:3394
target thresh 35.902223820950226
model initialize at round 3394
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6262168726125413
{'scaleFactor': 20, 'currentState': array([ 2.49925442e+01,  2.01219316e+01,  1.22538507e+01,  6.19867722e-01,
        7.84686997e-01, -5.50669480e-03]), 'targetState': array([25., 25., 15.])}
episode index:3395
target thresh 35.908633278089944
model initialize at round 3395
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13524095, 14.84627329,  0.9792759 ,  0.13377597,
       -0.15206148]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6263097063218429
{'scaleFactor': 20, 'currentState': array([26.7797667 , 21.07173761, 12.89023888,  0.63242444,  0.7470407 ,
        0.20486464]), 'targetState': array([25., 25., 15.])}
episode index:3396
target thresh 35.915042094315986
model initialize at round 3396
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.50595298e+01,  1.49939900e+01,  9.98178686e-01,
        6.00215916e-02, -6.05969483e-03]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6263997138701459
{'scaleFactor': 20, 'currentState': array([29.32750238, 20.55185382, 12.53050778,  0.68573597,  0.72302587,
       -0.08366462]), 'targetState': array([25., 25., 15.])}
episode index:3397
target thresh 35.921450269692436
model initialize at round 3397
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.626495237806588
{'scaleFactor': 20, 'currentState': array([24.86376685, 20.06922035, 11.75940408,  0.56564545,  0.80581809,
       -0.17522108]), 'targetState': array([25., 25., 15.])}
episode index:3398
target thresh 35.927857804283406
model initialize at round 3398
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6265907055359476
{'scaleFactor': 20, 'currentState': array([24.89888432, 20.07471325, 11.82074405,  0.58565705,  0.78869302,
       -0.18700038]), 'targetState': array([25., 25., 15.])}
episode index:3399
target thresh 35.93426469815294
model initialize at round 3399
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09756172, 14.84627329,  0.98350562,  0.09692172,
       -0.15271826]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6266833200782609
{'scaleFactor': 20, 'currentState': array([26.78823857, 20.76457931, 12.26556419,  0.60517281,  0.78960059,
        0.10147306]), 'targetState': array([25., 25., 15.])}
episode index:3400
target thresh 35.94067095136513
model initialize at round 3400
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11046526, 14.84627329,  0.98220546,  0.10959554,
       -0.15251638]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6267758801574501
{'scaleFactor': 20, 'currentState': array([26.92749799, 20.59112916, 12.43363331,  0.59258098,  0.79161364,
        0.14898197]), 'targetState': array([25., 25., 15.])}
episode index:3401
target thresh 35.94707656398403
model initialize at round 3401
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.88238996,  0.98141869,  0.15239421,
       -0.11659059]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6268683858215428
{'scaleFactor': 20, 'currentState': array([26.95320157, 20.8647988 , 12.37830705,  0.64740843,  0.76148237,
        0.03173192]), 'targetState': array([25., 25., 15.])}
episode index:3402
target thresh 35.95348153607368
model initialize at round 3402
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13213119, 14.84627329,  0.97967449,  0.13075309,
       -0.15212337]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6269608371185099
{'scaleFactor': 20, 'currentState': array([26.8221604 , 20.82498461, 12.13560891,  0.6178688 ,  0.77890729,
        0.10743174]), 'targetState': array([25., 25., 15.])}
episode index:3403
target thresh 35.95988586769815
model initialize at round 3403
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.8876033 ,  0.98199745,  0.15248408,
       -0.11148816]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6270532340962662
{'scaleFactor': 20, 'currentState': array([26.19268224, 21.59689862, 12.00959511,  0.48298336,  0.87493923,
       -0.03476219]), 'targetState': array([25., 25., 15.])}
episode index:3404
target thresh 35.96628955892148
model initialize at round 3404
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08842354, 14.84627329,  0.9843315 ,  0.08791725,
       -0.15284651]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6271428118095734
{'scaleFactor': 20, 'currentState': array([28.79381778, 20.3084502 , 10.34872632,  0.64307886,  0.74952928,
       -0.15702051]), 'targetState': array([25., 25., 15.])}
episode index:3405
target thresh 35.97269260980772
model initialize at round 3405
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6272351011042273
{'scaleFactor': 20, 'currentState': array([26.39094417, 21.13371552, 11.3243918 ,  0.55322959,  0.82857277,
       -0.08604756]), 'targetState': array([25., 25., 15.])}
episode index:3406
target thresh 35.97909502042087
model initialize at round 3406
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09234402, 14.84627329,  0.98398687,  0.09178314,
       -0.15279299]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6273273362226003
{'scaleFactor': 20, 'currentState': array([26.74503185, 20.7221396 , 12.30808271,  0.55599727,  0.82314255,
        0.11534024]), 'targetState': array([25., 25., 15.])}
episode index:3407
target thresh 35.98549679082497
model initialize at round 3407
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.8579125 ,  0.97836751,  0.15192042,
       -0.14041797]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6274223076761442
{'scaleFactor': 20, 'currentState': array([25.03976089, 20.17043022, 12.58604328,  0.58592813,  0.80927678,
        0.04194432]), 'targetState': array([25., 25., 15.])}
episode index:3408
target thresh 35.991897921084046
model initialize at round 3408
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6275172234116161
{'scaleFactor': 20, 'currentState': array([24.85509009, 20.10688552, 11.82141467,  0.56808158,  0.8128157 ,
       -0.12889515]), 'targetState': array([25., 25., 15.])}
episode index:3409
target thresh 35.998298411262084
model initialize at round 3409
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85396633,  0.97782476,  0.15183614,
       -0.14423772]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6276120834780351
{'scaleFactor': 20, 'currentState': array([24.90323252, 20.12013218, 11.96648153,  0.57306343,  0.81264462,
       -0.10586327]), 'targetState': array([25., 25., 15.])}
episode index:3410
target thresh 36.00469826142313
model initialize at round 3410
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86640036,  0.97948737,  0.15209431,
       -0.13218097]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6277068879243622
{'scaleFactor': 20, 'currentState': array([25.27630337, 20.18080257, 13.62383409,  0.59309861,  0.79613138,
        0.12003694]), 'targetState': array([25., 25., 15.])}
episode index:3411
target thresh 36.01109747163114
model initialize at round 3411
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86367328,  0.97913467,  0.15203955,
       -0.13483053]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6278016367995017
{'scaleFactor': 20, 'currentState': array([25.13223679, 20.17783824, 12.95003083,  0.58933536,  0.80452672,
        0.07362466]), 'targetState': array([25., 25., 15.])}
episode index:3412
target thresh 36.017496041950125
model initialize at round 3412
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6278963301523001
{'scaleFactor': 20, 'currentState': array([24.91674781, 20.10652497, 11.95919922,  0.59145988,  0.79666576,
       -0.12449447]), 'targetState': array([25., 25., 15.])}
episode index:3413
target thresh 36.023893972444064
model initialize at round 3413
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14100787, 14.84627329,  0.97851356,  0.13937183,
       -0.1519431 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6279881824719393
{'scaleFactor': 20, 'currentState': array([26.41295986, 21.40165016, 12.53146681,  0.52256012,  0.83632869,
        0.16578676]), 'targetState': array([25., 25., 15.])}
episode index:3414
target thresh 36.03029126317696
model initialize at round 3414
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15287635, 14.87738636,  0.98096509,  0.15148118,
       -0.12149464]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.62808276574205
{'scaleFactor': 20, 'currentState': array([25.00906784, 20.12210149, 12.29414647,  0.57935632,  0.80850145,
       -0.1033037 ]), 'targetState': array([25., 25., 15.])}
episode index:3415
target thresh 36.03668791421276
model initialize at round 3415
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.628177293635539
{'scaleFactor': 20, 'currentState': array([ 2.49351395e+01,  2.01484418e+01,  1.21608798e+01,  5.79770438e-01,
        8.14418915e-01, -2.42501569e-02]), 'targetState': array([25., 25., 15.])}
episode index:3416
target thresh 36.04308392561545
model initialize at round 3416
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6282717662010247
{'scaleFactor': 20, 'currentState': array([24.78963896, 20.0250836 , 11.48980003,  0.53853437,  0.78168483,
       -0.3145625 ]), 'targetState': array([25., 25., 15.])}
episode index:3417
target thresh 36.04947929744896
model initialize at round 3417
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6283634011873324
{'scaleFactor': 20, 'currentState': array([26.40336449, 20.73354454, 10.46967967,  0.61045226,  0.72985047,
       -0.30767893]), 'targetState': array([25., 25., 15.])}
episode index:3418
target thresh 36.05587402977727
model initialize at round 3418
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08907324, 14.84627329,  0.9842754 ,  0.08855818,
       -0.15283779]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6284549825702553
{'scaleFactor': 20, 'currentState': array([26.43053223, 20.54253877, 10.7156266 ,  0.54471492,  0.7983769 ,
       -0.25667096]), 'targetState': array([25., 25., 15.])}
episode index:3419
target thresh 36.06226812266431
model initialize at round 3419
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.628546510396814
{'scaleFactor': 20, 'currentState': array([26.28038378, 21.13278796, 10.75075242,  0.64382967,  0.73863653,
       -0.1997484 ]), 'targetState': array([25., 25., 15.])}
episode index:3420
target thresh 36.068661576174044
model initialize at round 3420
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12955697, 14.84627329,  0.97999778,  0.12824802,
       -0.15217357]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.6283627785902086
{'scaleFactor': 20, 'currentState': array([-30.24027198,  56.61124335, -20.96252626,  -0.72291883,
        -0.66276256,  -0.19527968]), 'targetState': array([25., 25., 15.])}
episode index:3421
target thresh 36.0750543903704
model initialize at round 3421
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.51242706e+01,  1.49990788e+01,  9.92213106e-01,
        1.24548380e-01, -9.23299067e-04]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6284542798674765
{'scaleFactor': 20, 'currentState': array([27.24596942, 20.70727503, 13.90452481,  0.64111457,  0.75211998,
        0.15260289]), 'targetState': array([25., 25., 15.])}
episode index:3422
target thresh 36.08144656531728
model initialize at round 3422
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11285283, 14.94593049,  0.99210586,  0.11309288,
       -0.05418452]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6285457276821226
{'scaleFactor': 20, 'currentState': array([27.2583283 , 20.44807364, 13.588324  ,  0.60050816,  0.7793652 ,
        0.17882907]), 'targetState': array([25., 25., 15.])}
episode index:3423
target thresh 36.08783810107863
model initialize at round 3423
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14320793, 14.89055448,  0.98382772,  0.14231508,
       -0.10876317]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.628637122080989
{'scaleFactor': 20, 'currentState': array([26.91481935, 21.02042379, 12.90872499,  0.63700909,  0.75639821,
        0.14859733]), 'targetState': array([25., 25., 15.])}
episode index:3424
target thresh 36.09422899771837
model initialize at round 3424
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.06800681, 14.84890537,  0.98628157,  0.06775138,
       -0.15052712]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6287284631108634
{'scaleFactor': 20, 'currentState': array([27.29813669, 20.2305757 , 12.95842466,  0.76275192,  0.61764611,
        0.19163191]), 'targetState': array([25., 25., 15.])}
episode index:3425
target thresh 36.100619255300394
model initialize at round 3425
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.50002024e+01,  1.48462733e+01,  9.88157843e-01,
        2.02021045e-04, -1.53440659e-01]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6288170027736761
{'scaleFactor': 20, 'currentState': array([28.68506514, 20.72844959, 11.75407938,  0.59994588,  0.78296486,
        0.16441099]), 'targetState': array([25., 25., 15.])}
episode index:3426
target thresh 36.10700887388861
model initialize at round 3426
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10536988, 14.89383378,  0.9887776 ,  0.10523977,
       -0.10603513]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6289082380075912
{'scaleFactor': 20, 'currentState': array([26.59539492, 21.08278583, 12.41751556,  0.52638891,  0.84664963,
        0.07809693]), 'targetState': array([25., 25., 15.])}
episode index:3427
target thresh 36.113397853546914
model initialize at round 3427
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87423265,  0.98046269,  0.15224576,
       -0.12455576]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6290021941954245
{'scaleFactor': 20, 'currentState': array([25.22791129, 20.17847684, 13.34404831,  0.59323342,  0.80108778,
        0.07957689]), 'targetState': array([25., 25., 15.])}
episode index:3428
target thresh 36.1197861943392
model initialize at round 3428
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13810631, 14.87041836,  0.98219083,  0.13701692,
       -0.12855949]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6290960955823317
{'scaleFactor': 20, 'currentState': array([ 2.51655473e+01,  2.00103839e+01,  1.26421395e+01,  6.00062624e-01,
        7.99911978e-01, -8.10393236e-03]), 'targetState': array([25., 25., 15.])}
episode index:3429
target thresh 36.12617389632934
model initialize at round 3429
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13280254, 14.90659081,  0.98681683,  0.13237554,
       -0.09310885]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6291871696505004
{'scaleFactor': 20, 'currentState': array([27.12020612, 20.74409378, 13.4110813 ,  0.63350835,  0.75665966,
        0.16165806]), 'targetState': array([25., 25., 15.])}
episode index:3430
target thresh 36.13256095958122
model initialize at round 3430
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.06602083, 14.84627329,  0.98601927,  0.06575536,
       -0.15310858]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.6290037866223306
{'scaleFactor': 20, 'currentState': array([16.52931517, 18.59675271,  3.00493143,  0.88569106, -0.45655874,
       -0.0842939 ]), 'targetState': array([25., 25., 15.])}
episode index:3431
target thresh 36.13894738415871
model initialize at round 3431
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.629097605463612
{'scaleFactor': 20, 'currentState': array([ 2.49624659e+01,  2.01569069e+01,  1.22668766e+01,  5.81834864e-01,
        8.13287230e-01, -5.66330227e-03]), 'targetState': array([25., 25., 15.])}
episode index:3432
target thresh 36.14533317012567
model initialize at round 3432
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14486145, 14.87921268,  0.9823312 ,  0.14373932,
       -0.11985167]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.629188599504957
{'scaleFactor': 20, 'currentState': array([ 2.65307124e+01,  2.13184910e+01,  1.20749879e+01,  6.11540270e-01,
        7.91004186e-01, -1.81900282e-02]), 'targetState': array([25., 25., 15.])}
episode index:3433
target thresh 36.15171831754596
model initialize at round 3433
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.07869955, 14.84627329,  0.98512314,  0.07831186,
       -0.15296943]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.6290053762668949
{'scaleFactor': 20, 'currentState': array([ 3.08122732e+01,  2.32182659e+01,  9.16806026e+00,  9.73599921e-01,
       -7.70136290e-03,  2.28131283e-01]), 'targetState': array([25., 25., 15.])}
episode index:3434
target thresh 36.15810282648345
model initialize at round 3434
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13900533, 14.84627329,  0.97878169,  0.13743017,
       -0.15198473]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6290963441775599
{'scaleFactor': 20, 'currentState': array([ 2.61653003e+01,  2.16047165e+01,  1.18984433e+01,  5.14696938e-01,
        8.57303641e-01, -1.08410854e-02]), 'targetState': array([25., 25., 15.])}
episode index:3435
target thresh 36.16448669700196
model initialize at round 3435
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14155517, 14.84627329,  0.97843965,  0.13990221,
       -0.15193162]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.629187259138335
{'scaleFactor': 20, 'currentState': array([26.04738122, 21.40438204, 11.01492497,  0.51152374,  0.83930763,
       -0.18413628]), 'targetState': array([25., 25., 15.])}
episode index:3436
target thresh 36.17086992916533
model initialize at round 3436
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.1242326 , 14.84627329,  0.98064723,  0.12305894,
       -0.15227442]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6292781211954378
{'scaleFactor': 20, 'currentState': array([2.70436199e+01, 2.05397009e+01, 1.22460525e+01, 6.58880986e-01,
       7.52049492e-01, 1.72455156e-02]), 'targetState': array([25., 25., 15.])}
episode index:3437
target thresh 36.177252523037396
model initialize at round 3437
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14408263, 14.84627329,  0.97809485,  0.14234998,
       -0.15187808]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6293689303950322
{'scaleFactor': 20, 'currentState': array([26.59448686, 21.05622287, 11.61891286,  0.59560898,  0.80030675,
       -0.06898585]), 'targetState': array([25., 25., 15.])}
episode index:3438
target thresh 36.183634478681995
model initialize at round 3438
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13351736, 14.84627329,  0.97949791,  0.13210099,
       -0.15209595]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6294596867832281
{'scaleFactor': 20, 'currentState': array([26.69590603, 21.14683822, 12.60611734,  0.60076511,  0.79044017,
        0.11952248]), 'targetState': array([25., 25., 15.])}
episode index:3439
target thresh 36.19001579616293
model initialize at round 3439
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84818632,  0.97700468,  0.1517088 ,
       -0.14982089]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6295531549120411
{'scaleFactor': 20, 'currentState': array([24.80362538, 20.07552953, 11.62583868,  0.55617424,  0.80654879,
       -0.20037279]), 'targetState': array([25., 25., 15.])}
episode index:3440
target thresh 36.19639647554402
model initialize at round 3440
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6296465687147114
{'scaleFactor': 20, 'currentState': array([2.49869606e+01, 2.01559701e+01, 1.23606696e+01, 5.84086357e-01,
       8.11532773e-01, 1.60526072e-02]), 'targetState': array([25., 25., 15.])}
episode index:3441
target thresh 36.20277651688909
model initialize at round 3441
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85238717,  0.97760366,  0.15180181,
       -0.14576449]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6297399282385886
{'scaleFactor': 20, 'currentState': array([24.95229542, 20.14134709, 12.16189571,  0.57794781,  0.81189281,
       -0.08250085]), 'targetState': array([25., 25., 15.])}
episode index:3442
target thresh 36.209155920261914
model initialize at round 3442
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6298332335309678
{'scaleFactor': 20, 'currentState': array([25.06561144, 20.17878525, 12.70438985,  0.58665113,  0.80740594,
        0.06273839]), 'targetState': array([25., 25., 15.])}
episode index:3443
target thresh 36.215534685726304
model initialize at round 3443
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12040455, 14.84627329,  0.98109809,  0.1193219 ,
       -0.15234442]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6299237233439381
{'scaleFactor': 20, 'currentState': array([26.58749765, 21.18319115, 12.8750413 ,  0.53009004,  0.82670896,
        0.18856524]), 'targetState': array([25., 25., 15.])}
episode index:3444
target thresh 36.22191281334604
model initialize at round 3444
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14259273, 14.89178754,  0.98404359,  0.14173481,
       -0.10756139]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6300141606229096
{'scaleFactor': 20, 'currentState': array([26.9138933 , 21.12686133, 13.42711319,  0.60357922,  0.77320597,
        0.19453703]), 'targetState': array([25., 25., 15.])}
episode index:3445
target thresh 36.2282903031849
model initialize at round 3445
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13211979, 14.88268213,  0.98444416,  0.13137834,
       -0.11665949]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.630104545413617
{'scaleFactor': 20, 'currentState': array([26.76826735, 21.03247386, 13.10957052,  0.5338784 ,  0.82346841,
        0.19202509]), 'targetState': array([25., 25., 15.])}
episode index:3446
target thresh 36.23466715530665
model initialize at round 3446
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.95584268,  0.98719945,  0.15329184,
       -0.0440324 ]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.630197636653677
{'scaleFactor': 20, 'currentState': array([25.38254639, 20.16428093, 15.0171722 ,  0.58173753,  0.77524129,
        0.2461349 ]), 'targetState': array([25., 25., 15.])}
episode index:3447
target thresh 36.241043369775085
model initialize at round 3447
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.51537267e+01,  1.49865720e+01,  9.88069118e-01,
        1.53426882e-01, -1.34018398e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.630290673896498
{'scaleFactor': 20, 'currentState': array([25.3773123 , 20.15235178, 15.45975302,  0.57449942,  0.76860779,
        0.28141158]), 'targetState': array([25., 25., 15.])}
episode index:3448
target thresh 36.24741894665395
model initialize at round 3448
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.51537267e+01, 1.50091484e+01, 9.88116669e-01,
       1.53434265e-01, 9.13096345e-03]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6303836571890475
{'scaleFactor': 20, 'currentState': array([25.3914448 , 20.16450992, 15.21479355,  0.58300606,  0.77580569,
        0.24130782]), 'targetState': array([25., 25., 15.])}
episode index:3449
target thresh 36.25379388600701
model initialize at round 3449
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.51537267e+01,  1.49922078e+01,  9.88127977e-01,
        1.53436021e-01, -7.77746999e-03]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6304765865782391
{'scaleFactor': 20, 'currentState': array([25.38668119, 20.1608488 , 15.3426211 ,  0.58030158,  0.77398382,
        0.25337545]), 'targetState': array([25., 25., 15.])}
episode index:3450
target thresh 36.260168187898
model initialize at round 3450
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.95604866,  0.98720836,  0.15329322,
       -0.0438274 ]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6305694621109317
{'scaleFactor': 20, 'currentState': array([25.33706241, 20.17245144, 13.97287094,  0.59769659,  0.79633461,
        0.09278995]), 'targetState': array([25., 25., 15.])}
episode index:3451
target thresh 36.266541852390674
model initialize at round 3451
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89098489,  0.98235936,  0.15254027,
       -0.10817375]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6306622838339297
{'scaleFactor': 20, 'currentState': array([25.20956374, 20.17793171, 13.31321237,  0.59347334,  0.80251763,
        0.06127685]), 'targetState': array([25., 25., 15.])}
episode index:3452
target thresh 36.272914879548765
model initialize at round 3452
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6307522976959532
{'scaleFactor': 20, 'currentState': array([26.59954788, 21.0616851 , 11.60948891,  0.6382307 ,  0.76437408,
       -0.09161788]), 'targetState': array([25., 25., 15.])}
episode index:3453
target thresh 36.279287269436
model initialize at round 3453
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09839085, 14.84627329,  0.98342678,  0.09773757,
       -0.15270602]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6308422594364583
{'scaleFactor': 20, 'currentState': array([26.58935982, 20.60284703, 11.2730595 ,  0.55270312,  0.83013296,
       -0.07347473]), 'targetState': array([25., 25., 15.])}
episode index:3454
target thresh 36.28565902211612
model initialize at round 3454
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6309321691007027
{'scaleFactor': 20, 'currentState': array([26.27047012, 21.48502825, 11.86153492,  0.50832616,  0.8593806 ,
        0.05540306]), 'targetState': array([25., 25., 15.])}
episode index:3455
target thresh 36.29203013765282
model initialize at round 3455
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10999206, 14.86725996,  0.9851755 ,  0.10945605,
       -0.13209317]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6310193025436445
{'scaleFactor': 20, 'currentState': array([28.73164639, 21.35819257, 12.68875666,  0.56261678,  0.79641904,
        0.22176358]), 'targetState': array([25., 25., 15.])}
episode index:3456
target thresh 36.29840061610983
model initialize at round 3456
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6311091089789517
{'scaleFactor': 20, 'currentState': array([26.33263974, 21.51327876, 12.50686662,  0.48935639,  0.86525847,
        0.1088949 ]), 'targetState': array([25., 25., 15.])}
episode index:3457
target thresh 36.30477045755084
model initialize at round 3457
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6311988634730008
{'scaleFactor': 20, 'currentState': array([26.40335557, 21.30833619, 11.6108944 ,  0.60565481,  0.79439063,
       -0.04610625]), 'targetState': array([25., 25., 15.])}
episode index:3458
target thresh 36.31113966203955
model initialize at round 3458
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09145854, 14.84627329,  0.98406598,  0.09091035,
       -0.15280528]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6312858442432911
{'scaleFactor': 20, 'currentState': array([28.25448243, 21.22762375, 10.28751592,  0.60114922,  0.77505679,
       -0.19469617]), 'targetState': array([25., 25., 15.])}
episode index:3459
target thresh 36.317508229639664
model initialize at round 3459
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14517584, 14.84627329,  0.97794393,  0.14340791,
       -0.15185465]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6313782443027295
{'scaleFactor': 20, 'currentState': array([24.94942026, 20.04621591, 11.96239529,  0.57550772,  0.80254701,
       -0.15719148]), 'targetState': array([25., 25., 15.])}
episode index:3460
target thresh 36.32387616041485
model initialize at round 3460
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.1112933 , 14.84627329,  0.98211671,  0.11040708,
       -0.1525026 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6314678432351474
{'scaleFactor': 20, 'currentState': array([26.39862724, 21.12818915, 11.63397897,  0.54420287,  0.83747265,
       -0.04982768]), 'targetState': array([25., 25., 15.])}
episode index:3461
target thresh 36.3302434544288
model initialize at round 3461
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12007136, 14.84627329,  0.98113669,  0.11899638,
       -0.15235042]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6315573904061946
{'scaleFactor': 20, 'currentState': array([26.89823941, 20.10584179, 10.98785565,  0.61689984,  0.75429923,
       -0.22464921]), 'targetState': array([25., 25., 15.])}
episode index:3462
target thresh 36.33661011174518
model initialize at round 3462
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6316496320058175
{'scaleFactor': 20, 'currentState': array([24.68478948, 20.0053592 , 11.26750501,  0.52569901,  0.78730763,
       -0.32216029]), 'targetState': array([25., 25., 15.])}
episode index:3463
target thresh 36.342976132427665
model initialize at round 3463
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6317418203481657
{'scaleFactor': 20, 'currentState': array([2.49963318e+01, 2.01658058e+01, 1.24133391e+01, 5.83935117e-01,
       8.11484384e-01, 2.26467112e-02]), 'targetState': array([25., 25., 15.])}
episode index:3464
target thresh 36.349341516539916
model initialize at round 3464
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6318339554793495
{'scaleFactor': 20, 'currentState': array([25.01400194, 20.16191091, 12.41991619,  0.58375743,  0.81128021,
       -0.03242985]), 'targetState': array([25., 25., 15.])}
episode index:3465
target thresh 36.35570626414558
model initialize at round 3465
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.631926037445426
{'scaleFactor': 20, 'currentState': array([25.06685901, 20.17735717, 12.70417044,  0.58679256,  0.80735436,
        0.062076  ]), 'targetState': array([25., 25., 15.])}
episode index:3466
target thresh 36.3620703753083
model initialize at round 3466
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85156671,  0.97748791,  0.15178384,
       -0.14655732]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6320180662923988
{'scaleFactor': 20, 'currentState': array([25.09709213, 20.17778225, 12.8167182 ,  0.58801126,  0.8058706 ,
        0.06939258]), 'targetState': array([25., 25., 15.])}
episode index:3467
target thresh 36.36843385009173
model initialize at round 3467
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87010682,  0.9799559 ,  0.15216707,
       -0.12857534]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.632107299880377
{'scaleFactor': 20, 'currentState': array([26.16619012, 21.57001409, 11.55770693,  0.50840971,  0.85633497,
       -0.09060904]), 'targetState': array([25., 25., 15.])}
episode index:3468
target thresh 36.3747966885595
model initialize at round 3468
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84843084,  0.97703997,  0.15171428,
       -0.14958498]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6321964820220664
{'scaleFactor': 20, 'currentState': array([26.60709997, 21.22384408, 12.5172327 ,  0.54690155,  0.83117459,
        0.10023713]), 'targetState': array([25., 25., 15.])}
episode index:3469
target thresh 36.38115889077523
model initialize at round 3469
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.632285612761945
{'scaleFactor': 20, 'currentState': array([2.68598803e+01, 2.09280044e+01, 1.21098195e+01, 6.75337596e-01,
       7.37361898e-01, 1.47160564e-02]), 'targetState': array([25., 25., 15.])}
episode index:3470
target thresh 36.38752045680255
model initialize at round 3470
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11920525, 14.84627329,  0.98123656,  0.11815005,
       -0.15236593]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6323746921444396
{'scaleFactor': 20, 'currentState': array([26.30759033, 21.32337511, 11.99972234,  0.49622919,  0.86597471,
        0.06200312]), 'targetState': array([25., 25., 15.])}
episode index:3471
target thresh 36.393881386705075
model initialize at round 3471
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84757279,  0.97691588,  0.15169501,
       -0.15041269]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6324664592405674
{'scaleFactor': 20, 'currentState': array([ 2.50131114e+01,  2.01054203e+01,  1.22684618e+01,  6.12025650e-01,
        7.90826570e-01, -4.23547072e-03]), 'targetState': array([25., 25., 15.])}
episode index:3472
target thresh 36.40024168054641
model initialize at round 3472
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10931251, 14.91413171,  0.99028594,  0.10934408,
       -0.08589309]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6325554352527069
{'scaleFactor': 20, 'currentState': array([27.47386198, 20.00815794, 12.80294985,  0.70257665,  0.69752471,
        0.14087342]), 'targetState': array([25., 25., 15.])}
episode index:3473
target thresh 36.40660133839017
model initialize at round 3473
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11886945, 14.85742783,  0.98287212,  0.1180136 ,
       -0.14154567]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.6323733525137164
{'scaleFactor': 20, 'currentState': array([32.00268111, 17.3926149 ,  8.63855607,  0.56544377,  0.51438893,
        0.64473046]), 'targetState': array([25., 25., 15.])}
episode index:3474
target thresh 36.41296036029993
model initialize at round 3474
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.88944706,  0.9821961 ,  0.15251492,
       -0.10968148]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6324650407719571
{'scaleFactor': 20, 'currentState': array([25.22460359, 20.17620615, 13.35034032,  0.59251981,  0.80007925,
        0.09377348]), 'targetState': array([25., 25., 15.])}
episode index:3475
target thresh 36.41931874633929
model initialize at round 3475
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6325539404004464
{'scaleFactor': 20, 'currentState': array([25.92154144, 21.52439302, 11.03946004,  0.46582199,  0.86105236,
       -0.20395761]), 'targetState': array([25., 25., 15.])}
episode index:3476
target thresh 36.42567649657186
model initialize at round 3476
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12542865, 14.84627329,  0.98050361,  0.1242255 ,
       -0.15225211]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6326427888931127
{'scaleFactor': 20, 'currentState': array([2.67619316e+01, 2.09234409e+01, 1.19362240e+01, 6.61910878e-01,
       7.49554461e-01, 6.48846503e-03]), 'targetState': array([25., 25., 15.])}
episode index:3477
target thresh 36.43203361106118
model initialize at round 3477
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.05112562, 14.84627329,  0.98687373,  0.05096417,
       -0.15324126]), 'targetState': array([25., 25., 15.])}
done in step count: 48
reward sum = 0.617290140942288
running average episode reward sum: 0.6326383746757605
{'scaleFactor': 20, 'currentState': array([26.46620731, 29.63365636, 14.21275976, -0.11367822, -0.99266923,
        0.04104963]), 'targetState': array([25., 25., 15.])}
episode index:3478
target thresh 36.43839008987083
model initialize at round 3478
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11505354, 14.84627329,  0.98170565,  0.11408961,
       -0.15243877]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6327271478217004
{'scaleFactor': 20, 'currentState': array([26.23373387, 21.43573035, 12.08958749,  0.48434027,  0.86969177,
        0.0951353 ]), 'targetState': array([25., 25., 15.])}
episode index:3479
target thresh 36.44474593306438
model initialize at round 3479
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85641112,  0.97816266,  0.15188861,
       -0.141872  ]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6328186026786196
{'scaleFactor': 20, 'currentState': array([24.93842365, 20.06180716, 11.92814708,  0.57303354,  0.8007704 ,
       -0.17435401]), 'targetState': array([25., 25., 15.])}
episode index:3480
target thresh 36.4511011407054
model initialize at round 3480
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6329100049903752
{'scaleFactor': 20, 'currentState': array([24.89269139, 20.11497416, 11.93723364,  0.57792277,  0.81212321,
       -0.08038134]), 'targetState': array([25., 25., 15.])}
episode index:3481
target thresh 36.45745571285743
model initialize at round 3481
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12785146, 14.84627329,  0.98020864,  0.12658697,
       -0.15220631]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6329986236418429
{'scaleFactor': 20, 'currentState': array([2.72041648e+01, 2.01246214e+01, 1.15994085e+01, 7.78663958e-01,
       6.27118610e-01, 2.01169061e-02]), 'targetState': array([25., 25., 15.])}
episode index:3482
target thresh 36.463809649584014
model initialize at round 3482
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.07430348, 14.860127  ,  0.98744314,  0.07411158,
       -0.13951175]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6330844883344255
{'scaleFactor': 20, 'currentState': array([29.00767683, 20.57701189, 12.11333565,  0.63553864,  0.74858392,
        0.18897818]), 'targetState': array([25., 25., 15.])}
episode index:3483
target thresh 36.47016295094869
model initialize at round 3483
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.8834945 ,  0.98154341,  0.15241357,
       -0.11551031]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6331757356253457
{'scaleFactor': 20, 'currentState': array([25.27567444, 20.05185815, 13.01472206,  0.65694705,  0.7522094 ,
        0.05100582]), 'targetState': array([25., 25., 15.])}
episode index:3484
target thresh 36.476515617015004
model initialize at round 3484
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10322853, 14.85334259,  0.98398434,  0.10260127,
       -0.14576626]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6332615002199745
{'scaleFactor': 20, 'currentState': array([29.10891828, 20.751897  , 11.77212383,  0.76195377,  0.63893481,
        0.10577697]), 'targetState': array([25., 25., 15.])}
episode index:3485
target thresh 36.48286764784645
model initialize at round 3485
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10235962, 14.88708911,  0.98835755,  0.1021898 ,
       -0.11272357]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6333472156094431
{'scaleFactor': 20, 'currentState': array([29.32697334, 20.32978751, 12.28941516,  0.73622712,  0.64640892,
        0.20031259]), 'targetState': array([25., 25., 15.])}
episode index:3486
target thresh 36.4892190435066
model initialize at round 3486
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.51124779e+01, 1.50039783e+01, 9.93599828e-01,
       1.12886847e-01, 3.99278163e-03]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6334355818078347
{'scaleFactor': 20, 'currentState': array([26.68525274, 21.36620176, 16.13331498,  0.46721266,  0.81160184,
        0.35073463]), 'targetState': array([25., 25., 15.])}
episode index:3487
target thresh 36.495569804058924
model initialize at round 3487
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.88870742,  0.98211679,  0.15250261,
       -0.11040638]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6335238973375344
{'scaleFactor': 20, 'currentState': array([26.55861083, 20.93200255, 11.31667894,  0.58362834,  0.78311635,
       -0.21472478]), 'targetState': array([25., 25., 15.])}
episode index:3488
target thresh 36.50191992956695
model initialize at round 3488
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.1271777 , 14.84627329,  0.98029121,  0.12593049,
       -0.15221913]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6336121622421098
{'scaleFactor': 20, 'currentState': array([25.98538969, 21.54143497, 11.40253451,  0.45932596,  0.88573307,
       -0.06705658]), 'targetState': array([25., 25., 15.])}
episode index:3489
target thresh 36.50826942009419
model initialize at round 3489
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11991067, 14.84627329,  0.98115527,  0.11883938,
       -0.1523533 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6337003765650779
{'scaleFactor': 20, 'currentState': array([26.23396498, 21.14611341, 11.09410627,  0.5125907 ,  0.84303117,
       -0.16293932]), 'targetState': array([25., 25., 15.])}
episode index:3490
target thresh 36.5146182757041
model initialize at round 3490
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6337912644692129
{'scaleFactor': 20, 'currentState': array([24.95262919, 20.14502426, 12.16996744,  0.57840473,  0.81225686,
       -0.07541062]), 'targetState': array([25., 25., 15.])}
episode index:3491
target thresh 36.520966496460204
model initialize at round 3491
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6338821003184198
{'scaleFactor': 20, 'currentState': array([25.12641357, 20.18469973, 12.99319499,  0.58791111,  0.80257439,
        0.10116757]), 'targetState': array([25., 25., 15.])}
episode index:3492
target thresh 36.52731408242597
model initialize at round 3492
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.94608887,  0.98673031,  0.15321899,
       -0.05373307]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6339728841574069
{'scaleFactor': 20, 'currentState': array([25.24178109, 20.15047833, 13.2927967 ,  0.59403721,  0.8034493 ,
       -0.03986241]), 'targetState': array([25., 25., 15.])}
episode index:3493
target thresh 36.53366103366488
model initialize at round 3493
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6340636160308307
{'scaleFactor': 20, 'currentState': array([25.06203453, 20.17729817, 12.67580301,  0.58660277,  0.80797727,
        0.05540695]), 'targetState': array([25., 25., 15.])}
episode index:3494
target thresh 36.54000735024039
model initialize at round 3494
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85167074,  0.97750262,  0.15178612,
       -0.14645681]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6341542959832969
{'scaleFactor': 20, 'currentState': array([24.80171629, 20.04523212, 11.57155955,  0.55042756,  0.79134284,
       -0.26609401]), 'targetState': array([25., 25., 15.])}
episode index:3495
target thresh 36.546353032215976
model initialize at round 3495
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14747926, 14.84627329,  0.97762245,  0.14563539,
       -0.15180473]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6342422038361051
{'scaleFactor': 20, 'currentState': array([26.95707027, 21.09325865, 13.75128348,  0.63574443,  0.71667558,
        0.28671438]), 'targetState': array([25., 25., 15.])}
episode index:3496
target thresh 36.55269807965511
model initialize at round 3496
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10887581, 14.86784634,  0.9853705 ,  0.10836668,
       -0.13153567]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.6340608363199952
{'scaleFactor': 20, 'currentState': array([19.02217013,  4.27034994,  3.18954548,  0.74114277, -0.59872003,
        0.30371322]), 'targetState': array([25., 25., 15.])}
episode index:3497
target thresh 36.55904249262121
model initialize at round 3497
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.04137674, 14.87275447,  0.99098977,  0.0414181 ,
       -0.12737274]), 'targetState': array([25., 25., 15.])}
done in step count: 45
reward sum = 0.6361854860638709
running average episode reward sum: 0.6340614437098592
{'scaleFactor': 20, 'currentState': array([ 2.01965893e+01,  2.03768635e+01,  1.03174377e+01,  4.90013788e-01,
       -8.71684393e-01, -7.26683039e-03]), 'targetState': array([25., 25., 15.])}
episode index:3498
target thresh 36.56538627117772
model initialize at round 3498
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.04550979, 14.85438867,  0.98833418,  0.04543321,
       -0.14536632]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.6338802315224599
{'scaleFactor': 20, 'currentState': array([ 7.46642626, 25.55676009,  5.61626429,  0.5094857 , -0.84795237,
        0.14629114]), 'targetState': array([25., 25., 15.])}
episode index:3499
target thresh 36.57172941538811
model initialize at round 3499
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89907938,  0.98318223,  0.15266805,
       -0.10022562]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6339708343277107
{'scaleFactor': 20, 'currentState': array([25.19500174, 20.17268748, 13.26020202,  0.5941936 ,  0.79732839,
        0.10583672]), 'targetState': array([25., 25., 15.])}
episode index:3500
target thresh 36.57807192531579
model initialize at round 3500
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12294142, 14.89174541,  0.98658559,  0.12251741,
       -0.10788123]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6340586690363862
{'scaleFactor': 20, 'currentState': array([2.64706152e+01, 2.14123704e+01, 1.25367934e+01, 5.59748300e-01,
       8.28616688e-01, 8.73068647e-03]), 'targetState': array([25., 25., 15.])}
episode index:3501
target thresh 36.5844138010242
model initialize at round 3501
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.05391635, 14.84627329,  0.98673003,  0.05373826,
       -0.15321895]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.634146453582464
{'scaleFactor': 20, 'currentState': array([26.77356883, 20.11872576, 11.08495419,  0.5936165 ,  0.7986622 ,
       -0.09878331]), 'targetState': array([25., 25., 15.])}
episode index:3502
target thresh 36.59075504257673
model initialize at round 3502
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86825533,  0.97972342,  0.15213097,
       -0.13037711]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.634231500369311
{'scaleFactor': 20, 'currentState': array([29.47039602, 20.6299676 , 13.86143687,  0.76485244,  0.53801993,
        0.35430961]), 'targetState': array([25., 25., 15.])}
episode index:3503
target thresh 36.59709565003681
model initialize at round 3503
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.04585397, 14.87563323,  0.99115553,  0.04590749,
       -0.12451193]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.6340504982287946
{'scaleFactor': 20, 'currentState': array([33.54289692, 17.68114961, 13.15949728,  0.60020151,  0.62592755,
        0.49796872]), 'targetState': array([25., 25., 15.])}
episode index:3504
target thresh 36.60343562346785
model initialize at round 3504
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86882968,  0.97979587,  0.15214222,
       -0.12981832]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6341355238635102
{'scaleFactor': 20, 'currentState': array([29.20473758, 20.96629605, 13.84746926,  0.70897017,  0.59898293,
        0.37226434]), 'targetState': array([25., 25., 15.])}
episode index:3505
target thresh 36.60977496293324
model initialize at round 3505
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12248506, 14.9178619 ,  0.98908588,  0.12237197,
       -0.08206226]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.634223186335141
{'scaleFactor': 20, 'currentState': array([27.46817324, 20.1592409 , 13.8441033 ,  0.630211  ,  0.73961819,
        0.23621818]), 'targetState': array([25., 25., 15.])}
episode index:3506
target thresh 36.61611366849639
model initialize at round 3506
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86525262,  0.97933975,  0.15207139,
       -0.13329643]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6343107988139165
{'scaleFactor': 20, 'currentState': array([26.53518047, 21.54014266, 13.81968328,  0.4887779 ,  0.8239464 ,
        0.28672025]), 'targetState': array([25., 25., 15.])}
episode index:3507
target thresh 36.622451740220676
model initialize at round 3507
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.93009776,  0.98576136,  0.15306853,
       -0.06960295]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6343983613425901
{'scaleFactor': 20, 'currentState': array([27.05443621, 21.06475486, 14.14838648,  0.64033228,  0.71989314,
        0.26782166]), 'targetState': array([25., 25., 15.])}
episode index:3508
target thresh 36.62878917816948
model initialize at round 3508
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09215571, 14.87978337,  0.9884963 ,  0.09201573,
       -0.12003404]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6344831909198384
{'scaleFactor': 20, 'currentState': array([28.74981818, 21.36365262, 13.73913565,  0.55779508,  0.74942237,
        0.35669421]), 'targetState': array([25., 25., 15.])}
episode index:3509
target thresh 36.635125982406166
model initialize at round 3509
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.93431183,  0.98604069,  0.15311191,
       -0.06542546]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6345706544407732
{'scaleFactor': 20, 'currentState': array([27.07513492, 21.06147789, 14.76140673,  0.60730711,  0.73029689,
        0.31280109]), 'targetState': array([25., 25., 15.])}
episode index:3510
target thresh 36.64146215299411
model initialize at round 3510
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08077517, 14.92768756,  0.99405722,  0.0811062 ,
       -0.07260879]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6346580681391384
{'scaleFactor': 20, 'currentState': array([27.36535294, 20.18154515, 13.28048969,  0.66345895,  0.73864143,
        0.11929398]), 'targetState': array([25., 25., 15.])}
episode index:3511
target thresh 36.647797689996686
model initialize at round 3511
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6347481398879313
{'scaleFactor': 20, 'currentState': array([24.92661794, 20.01033826, 11.79130602,  0.57742138,  0.79703346,
       -0.17698083]), 'targetState': array([25., 25., 15.])}
episode index:3512
target thresh 36.65413259347723
model initialize at round 3512
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14588775, 14.84627329,  0.97784508,  0.14409659,
       -0.1518393 ]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6348381603576189
{'scaleFactor': 20, 'currentState': array([2.51491032e+01, 2.00241185e+01, 1.25878141e+01, 6.05098337e-01,
       7.95763003e-01, 2.48444208e-02]), 'targetState': array([25., 25., 15.])}
episode index:3513
target thresh 36.66046686349911
model initialize at round 3513
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13801319, 14.88868848,  0.98433769,  0.13722382,
       -0.11067487]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6349227440763295
{'scaleFactor': 20, 'currentState': array([29.12173552, 21.13245301, 13.13344372,  0.63275765,  0.74974723,
        0.19364101]), 'targetState': array([25., 25., 15.])}
episode index:3514
target thresh 36.66680050012565
model initialize at round 3514
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13523844, 14.84979386,  0.97978927,  0.13384361,
       -0.14865693]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6350099581318984
{'scaleFactor': 20, 'currentState': array([25.97594871, 21.51540247, 11.25726165,  0.45424514,  0.87954233,
       -0.1416568 ]), 'targetState': array([25., 25., 15.])}
episode index:3515
target thresh 36.67313350342019
model initialize at round 3515
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6350998273275095
{'scaleFactor': 20, 'currentState': array([25.16167471, 20.06553888, 12.63993499,  0.64968294,  0.75857265,
        0.04979571]), 'targetState': array([25., 25., 15.])}
episode index:3516
target thresh 36.679465873446084
model initialize at round 3516
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84798314,  0.97697531,  0.15170424,
       -0.15001689]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6351869414367143
{'scaleFactor': 20, 'currentState': array([26.81577535, 21.14457324, 13.13602815,  0.58131077,  0.78144893,
        0.22674956]), 'targetState': array([25., 25., 15.])}
episode index:3517
target thresh 36.68579761026661
model initialize at round 3517
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10959136, 14.84627329,  0.98229844,  0.10873881,
       -0.15253081]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.635274006021127
{'scaleFactor': 20, 'currentState': array([27.11101175, 20.48525705, 12.61280685,  0.65923984,  0.73459769,
        0.16052746]), 'targetState': array([25., 25., 15.])}
episode index:3518
target thresh 36.692128713945124
model initialize at round 3518
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6353637235669863
{'scaleFactor': 20, 'currentState': array([24.87071821, 20.1041326 , 11.82845483,  0.56392274,  0.80690633,
       -0.17576494]), 'targetState': array([25., 25., 15.])}
episode index:3519
target thresh 36.698459184544916
model initialize at round 3519
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6354533901369673
{'scaleFactor': 20, 'currentState': array([24.89827734, 20.08300461, 11.84655853,  0.57283933,  0.801838  ,
       -0.17003213]), 'targetState': array([25., 25., 15.])}
episode index:3520
target thresh 36.70478902212931
model initialize at round 3520
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6355430057745031
{'scaleFactor': 20, 'currentState': array([24.90558182, 20.13027219, 12.00380504,  0.57454847,  0.81344915,
       -0.09052367]), 'targetState': array([25., 25., 15.])}
episode index:3521
target thresh 36.7111182267616
model initialize at round 3521
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13120594, 14.84627329,  0.97979139,  0.12985298,
       -0.15214152]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6356271972401852
{'scaleFactor': 20, 'currentState': array([29.07740486, 21.05884148, 13.59180632,  0.68747921,  0.62836137,
        0.36405264]), 'targetState': array([25., 25., 15.])}
episode index:3522
target thresh 36.71744679850506
model initialize at round 3522
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13657531, 14.8740825 ,  0.9828473 ,  0.13558856,
       -0.12500775]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.635714013292459
{'scaleFactor': 20, 'currentState': array([26.73274593, 21.20908253, 13.64670154,  0.53586869,  0.80226174,
        0.26309855]), 'targetState': array([25., 25., 15.])}
episode index:3523
target thresh 36.723774737422985
model initialize at round 3523
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6358034786830968
{'scaleFactor': 20, 'currentState': array([25.07169172, 20.17627514, 12.68467397,  0.58709979,  0.80812354,
        0.04743604]), 'targetState': array([25., 25., 15.])}
episode index:3524
target thresh 36.73010204357867
model initialize at round 3524
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.88756432,  0.98199322,  0.15248342,
       -0.11152634]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6358928933132294
{'scaleFactor': 20, 'currentState': array([25.2793252 , 20.17353024, 13.94131772,  0.58987416,  0.78160289,
        0.20284329]), 'targetState': array([25., 25., 15.])}
episode index:3525
target thresh 36.736428717035366
model initialize at round 3525
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.93197869,  0.98588815,  0.15308822,
       -0.06773879]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6359822572260447
{'scaleFactor': 20, 'currentState': array([25.30918856, 20.1743741 , 14.08511627,  0.58951538,  0.7885368 ,
        0.17516087]), 'targetState': array([25., 25., 15.])}
episode index:3526
target thresh 36.742754757856346
model initialize at round 3526
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6360715704646821
{'scaleFactor': 20, 'currentState': array([25.12273866, 20.1867807 , 13.00143192,  0.58740514,  0.80217953,
        0.10706633]), 'targetState': array([25., 25., 15.])}
episode index:3527
target thresh 36.74908016610489
model initialize at round 3527
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.8882063 ,  0.98206277,  0.15249422,
       -0.1108974 ]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6361608330722319
{'scaleFactor': 20, 'currentState': array([25.25196128, 20.15975176, 13.50703007,  0.61350951,  0.77745292,
        0.13846674]), 'targetState': array([25., 25., 15.])}
episode index:3528
target thresh 36.75540494184422
model initialize at round 3528
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13327721, 14.91184123,  0.98722252,  0.13290329,
       -0.08791144]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6362473503055356
{'scaleFactor': 20, 'currentState': array([26.73798638, 21.14209974, 12.91666479,  0.54136549,  0.83882633,
        0.0573916 ]), 'targetState': array([25., 25., 15.])}
episode index:3529
target thresh 36.76172908513758
model initialize at round 3529
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6363365125433811
{'scaleFactor': 20, 'currentState': array([25.08526843, 20.16482472, 12.59378307,  0.58517327,  0.80714585,
       -0.0780245 ]), 'targetState': array([25., 25., 15.])}
episode index:3530
target thresh 36.768052596048264
model initialize at round 3530
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6364256242786845
{'scaleFactor': 20, 'currentState': array([25.02444924, 20.14403006, 12.38031715,  0.60196847,  0.79786528,
       -0.03232586]), 'targetState': array([25., 25., 15.])}
episode index:3531
target thresh 36.77437547463946
model initialize at round 3531
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.88068085,  0.98122347,  0.15236389,
       -0.11826137]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6365146855543419
{'scaleFactor': 20, 'currentState': array([25.180757  , 20.17826722, 13.13205758,  0.59194432,  0.80372111,
        0.06028506]), 'targetState': array([25., 25., 15.])}
episode index:3532
target thresh 36.78069772097441
model initialize at round 3532
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6366010046779893
{'scaleFactor': 20, 'currentState': array([ 2.72306618e+01,  2.04254773e+01,  1.20614517e+01,  7.82294810e-01,
        6.22829985e-01, -9.88131432e-03]), 'targetState': array([25., 25., 15.])}
episode index:3533
target thresh 36.787019335116334
model initialize at round 3533
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08806168, 14.84627329,  0.98436257,  0.08756023,
       -0.15285133]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6366872749509725
{'scaleFactor': 20, 'currentState': array([27.28284001, 20.06950383, 12.34230758,  0.65975489,  0.74886519,
        0.06264511]), 'targetState': array([25., 25., 15.])}
episode index:3534
target thresh 36.793340317128454
model initialize at round 3534
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15302391, 14.84627329,  0.97682921,  0.15098811,
       -0.15168155]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.636773496414749
{'scaleFactor': 20, 'currentState': array([26.79149984, 21.20005141, 13.38344243,  0.57160696,  0.78447559,
        0.2405484 ]), 'targetState': array([25., 25., 15.])}
episode index:3535
target thresh 36.79966066707399
model initialize at round 3535
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14137438, 14.90949597,  0.98592781,  0.14079286,
       -0.09013176]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.636862358562228
{'scaleFactor': 20, 'currentState': array([25.35753407, 20.0646058 , 13.84386238,  0.6029105 ,  0.78711266,
        0.13020212]), 'targetState': array([25., 25., 15.])}
episode index:3536
target thresh 36.80598038501611
model initialize at round 3536
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6369511704625214
{'scaleFactor': 20, 'currentState': array([25.24817482, 20.18265024, 13.86585209,  0.58234624,  0.78492933,
        0.21156276]), 'targetState': array([25., 25., 15.])}
episode index:3537
target thresh 36.81229947101804
model initialize at round 3537
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.92659585,  0.98551621,  0.15303047,
       -0.0730717 ]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6370399321582358
{'scaleFactor': 20, 'currentState': array([25.16809294, 20.15373153, 12.95695932,  0.59004113,  0.80545053,
       -0.05568575]), 'targetState': array([25., 25., 15.])}
episode index:3538
target thresh 36.81861792514296
model initialize at round 3538
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6371286436919295
{'scaleFactor': 20, 'currentState': array([25.19812056, 20.18829052, 13.50139232,  0.5847422 ,  0.79168471,
        0.1769516 ]), 'targetState': array([25., 25., 15.])}
episode index:3539
target thresh 36.82493574745407
model initialize at round 3539
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.9201748 ,  0.98503612,  0.15295592,
       -0.07942496]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6372173051061126
{'scaleFactor': 20, 'currentState': array([ 2.51332819e+01,  2.01382873e+01,  1.27803687e+01,  6.02428094e-01,
        7.97984444e-01, -1.73556811e-02]), 'targetState': array([25., 25., 15.])}
episode index:3540
target thresh 36.831252938014536
model initialize at round 3540
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13672231, 14.85513804,  0.98035277,  0.13538999,
       -0.14345033]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6373032307893362
{'scaleFactor': 20, 'currentState': array([26.57837406, 21.43788592, 14.16303324,  0.49621518,  0.80198838,
        0.33254343]), 'targetState': array([25., 25., 15.])}
episode index:3541
target thresh 36.83756949688753
model initialize at round 3541
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12651169, 14.85305141,  0.98135356,  0.12540676,
       -0.14566517]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6373891079543874
{'scaleFactor': 20, 'currentState': array([26.50000262, 21.44606019, 13.87801046,  0.4740014 ,  0.82556137,
        0.30622066]), 'targetState': array([25., 25., 15.])}
episode index:3542
target thresh 36.84388542413621
model initialize at round 3542
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.637477620780226
{'scaleFactor': 20, 'currentState': array([25.04286424, 20.15557988, 12.43513505,  0.58380294,  0.8100045 ,
       -0.05537898]), 'targetState': array([25., 25., 15.])}
episode index:3543
target thresh 36.850200719823754
model initialize at round 3543
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6375660836552598
{'scaleFactor': 20, 'currentState': array([25.2081253 , 20.17689898, 13.35489732,  0.60495778,  0.78898519,
        0.10737067]), 'targetState': array([25., 25., 15.])}
episode index:3544
target thresh 36.8565153840133
model initialize at round 3544
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6376544966217604
{'scaleFactor': 20, 'currentState': array([24.82357697, 20.0663413 , 11.64342553,  0.54468208,  0.79214438,
       -0.27537012]), 'targetState': array([25., 25., 15.])}
episode index:3545
target thresh 36.862829416767994
model initialize at round 3545
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6377428597219518
{'scaleFactor': 20, 'currentState': array([24.80973386, 20.04919135, 11.57417157,  0.53424554,  0.78209272,
       -0.32080006]), 'targetState': array([25., 25., 15.])}
episode index:3546
target thresh 36.86914281815099
model initialize at round 3546
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6378311729980098
{'scaleFactor': 20, 'currentState': array([24.97728669, 20.14159908, 12.20539664,  0.57845582,  0.81094821,
       -0.08804467]), 'targetState': array([25., 25., 15.])}
episode index:3547
target thresh 36.87545558822541
model initialize at round 3547
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6379194364920635
{'scaleFactor': 20, 'currentState': array([25.15419908, 20.1889356 , 13.16743142,  0.58750179,  0.79927824,
        0.12647507]), 'targetState': array([25., 25., 15.])}
episode index:3548
target thresh 36.88176772705438
model initialize at round 3548
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.8752755 ,  0.98058832,  0.15226527,
       -0.12353877]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6380076502461937
{'scaleFactor': 20, 'currentState': array([ 2.51837273e+01,  2.00562284e+01,  1.26550902e+01,  6.47010879e-01,
        7.62267278e-01, -1.80421763e-02]), 'targetState': array([25., 25., 15.])}
episode index:3549
target thresh 36.888079234701046
model initialize at round 3549
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.0750211 , 14.84627329,  0.98539904,  0.07467245,
       -0.15301227]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6380904834004644
{'scaleFactor': 20, 'currentState': array([29.0407153 , 20.28829679, 10.89213305,  0.73152364,  0.67765262,
       -0.07523352]), 'targetState': array([25., 25., 15.])}
episode index:3550
target thresh 36.89439011122848
model initialize at round 3550
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10481384, 14.84627329,  0.98279411,  0.10405093,
       -0.15260778]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.638175921211222
{'scaleFactor': 20, 'currentState': array([26.59882308, 21.08957883, 12.80353536,  0.51657929,  0.83512768,
        0.18896454]), 'targetState': array([25., 25., 15.])}
episode index:3551
target thresh 36.900700356699836
model initialize at round 3551
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6382639882519565
{'scaleFactor': 20, 'currentState': array([25.2296305 , 20.18249802, 13.8001934 ,  0.58119272,  0.78480798,
        0.21515447]), 'targetState': array([25., 25., 15.])}
episode index:3552
target thresh 36.90700997117817
model initialize at round 3552
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85196308,  0.97754391,  0.15179253,
       -0.14617434]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.63834932913604
{'scaleFactor': 20, 'currentState': array([26.14235064, 21.6138116 , 11.79985375,  0.46512742,  0.87773934,
       -0.11502229]), 'targetState': array([25., 25., 15.])}
episode index:3553
target thresh 36.91331895472663
model initialize at round 3553
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6384372978250564
{'scaleFactor': 20, 'currentState': array([ 2.52671118e+01,  2.00311756e+01,  1.28694463e+01,  6.33353681e-01,
        7.73858934e-01, -2.33787613e-03]), 'targetState': array([25., 25., 15.])}
episode index:3554
target thresh 36.91962730740826
model initialize at round 3554
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12054786, 14.84627329,  0.98108145,  0.11946189,
       -0.15234184]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6385225419464561
{'scaleFactor': 20, 'currentState': array([2.64636174e+01, 2.13369818e+01, 1.24802567e+01, 5.04417314e-01,
       8.63391536e-01, 1.08733155e-02]), 'targetState': array([25., 25., 15.])}
episode index:3555
target thresh 36.92593502928617
model initialize at round 3555
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6386104124492552
{'scaleFactor': 20, 'currentState': array([25.04559181, 20.05775197, 12.17966328,  0.58404547,  0.79746998,
       -0.15143489]), 'targetState': array([25., 25., 15.])}
episode index:3556
target thresh 36.93224212042343
model initialize at round 3556
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6386982335449681
{'scaleFactor': 20, 'currentState': array([25.02216784, 20.14840444, 12.34125907,  0.58192777,  0.81031789,
       -0.06888385]), 'targetState': array([25., 25., 15.])}
episode index:3557
target thresh 36.9385485808831
model initialize at round 3557
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6387860052752534
{'scaleFactor': 20, 'currentState': array([ 2.51472174e+01,  2.01772401e+01,  1.28752852e+01,  5.90832356e-01,
        8.06703529e-01, -1.21055167e-02]), 'targetState': array([25., 25., 15.])}
episode index:3558
target thresh 36.944854410728276
model initialize at round 3558
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6388737276817229
{'scaleFactor': 20, 'currentState': array([25.13833839, 20.1871767 , 13.05163473,  0.58802959,  0.80172786,
        0.10702167]), 'targetState': array([25., 25., 15.])}
episode index:3559
target thresh 36.951159610021975
model initialize at round 3559
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6389614008059417
{'scaleFactor': 20, 'currentState': array([25.19320701, 20.1673435 , 13.09657368,  0.61272827,  0.78776422,
        0.06317918]), 'targetState': array([25., 25., 15.])}
episode index:3560
target thresh 36.95746417882728
model initialize at round 3560
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.1234456 , 14.87772914,  0.98494592,  0.1228154 ,
       -0.12164665]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.639046354119223
{'scaleFactor': 20, 'currentState': array([27.02491921, 20.79784765, 13.73619134,  0.56402367,  0.78333768,
        0.26126497]), 'targetState': array([25., 25., 15.])}
episode index:3561
target thresh 36.96376811720723
model initialize at round 3561
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14314434, 14.87232413,  0.9817432 ,  0.14195049,
       -0.12661103]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6391312597327214
{'scaleFactor': 20, 'currentState': array([27.58971348, 20.21292099, 14.09453901,  0.77187712,  0.59264637,
        0.23016514]), 'targetState': array([25., 25., 15.])}
episode index:3562
target thresh 36.97007142522485
model initialize at round 3562
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11288438, 14.84627329,  0.98194438,  0.11196584,
       -0.15247584]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6392161176865997
{'scaleFactor': 20, 'currentState': array([26.59848207, 21.26799958, 14.11917129,  0.47849906,  0.81206885,
        0.33404016]), 'targetState': array([25., 25., 15.])}
episode index:3563
target thresh 36.97637410294319
model initialize at round 3563
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86565693,  0.97939189,  0.15207949,
       -0.13290355]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6393035963432252
{'scaleFactor': 20, 'currentState': array([25.36005594, 20.04201376, 13.56004175,  0.65256021,  0.74336508,
        0.14687929]), 'targetState': array([25., 25., 15.])}
episode index:3564
target thresh 36.98267615042528
model initialize at round 3564
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14566476, 14.85837473,  0.97958558,  0.14413242,
       -0.14013543]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.639388358349693
{'scaleFactor': 20, 'currentState': array([27.24877798, 20.46690488, 13.75480417,  0.63934172,  0.7109673 ,
        0.29286118]), 'targetState': array([25., 25., 15.])}
episode index:3565
target thresh 36.98897756773412
model initialize at round 3565
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14298172, 14.84627329,  0.97824574,  0.1412841 ,
       -0.15190151]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6394730728171779
{'scaleFactor': 20, 'currentState': array([26.26955179, 21.63404638, 12.51623938,  0.47711361,  0.87585808,
        0.07235482]), 'targetState': array([25., 25., 15.])}
episode index:3566
target thresh 36.99527835493272
model initialize at round 3566
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6395604058637389
{'scaleFactor': 20, 'currentState': array([24.91919543, 20.10272086, 11.93574741,  0.56345119,  0.80264102,
       -0.19567869]), 'targetState': array([25., 25., 15.])}
episode index:3567
target thresh 37.00157851208412
model initialize at round 3567
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6396476899567984
{'scaleFactor': 20, 'currentState': array([24.90565349, 20.11298285, 11.93799588,  0.5678166 ,  0.80786719,
       -0.15790792]), 'targetState': array([25., 25., 15.])}
episode index:3568
target thresh 37.00787803925132
model initialize at round 3568
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6397349251375054
{'scaleFactor': 20, 'currentState': array([24.97887328, 20.14182175, 12.20692358,  0.57980293,  0.81207505,
       -0.06605051]), 'targetState': array([25., 25., 15.])}
episode index:3569
target thresh 37.01417693649728
model initialize at round 3569
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.88802516,  0.98204318,  0.15249118,
       -0.11107488]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6398194476092879
{'scaleFactor': 20, 'currentState': array([26.83474514, 21.29635746, 13.7244534 ,  0.61422452,  0.74337078,
        0.26481715]), 'targetState': array([25., 25., 15.])}
episode index:3570
target thresh 37.020475203885006
model initialize at round 3570
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10886582, 14.89482186,  0.98851133,  0.10870212,
       -0.10501998]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6399039227428055
{'scaleFactor': 20, 'currentState': array([27.048883  , 20.66598777, 13.30010026,  0.57009383,  0.80443171,
        0.16698097]), 'targetState': array([25., 25., 15.])}
episode index:3571
target thresh 37.02677284147748
model initialize at round 3571
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87801255,  0.9809133 ,  0.15231573,
       -0.12086779]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6399910129239806
{'scaleFactor': 20, 'currentState': array([25.24478347, 20.16769956, 13.57771702,  0.60443344,  0.77990662,
        0.16249885]), 'targetState': array([25., 25., 15.])}
episode index:3572
target thresh 37.03306984933771
model initialize at round 3572
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08999044, 14.95203408,  0.99473677,  0.09042101,
       -0.04819542]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6400753927550684
{'scaleFactor': 20, 'currentState': array([27.02729318, 20.89178484, 14.42421611,  0.59287366,  0.76878891,
        0.23971741]), 'targetState': array([25., 25., 15.])}
episode index:3573
target thresh 37.03936622752862
model initialize at round 3573
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.07697901, 14.84627329,  0.9852538 ,  0.07660996,
       -0.15298972]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6401597253674484
{'scaleFactor': 20, 'currentState': array([26.85571207, 20.17997163, 11.21266129,  0.62754248,  0.75699943,
       -0.18205026]), 'targetState': array([25., 25., 15.])}
episode index:3574
target thresh 37.04566197611319
model initialize at round 3574
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6402466709127722
{'scaleFactor': 20, 'currentState': array([25.13849069, 20.17773132, 13.01042945,  0.5912212 ,  0.79996215,
        0.10255759]), 'targetState': array([25., 25., 15.])}
episode index:3575
target thresh 37.05195709515438
model initialize at round 3575
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.96370327,  0.98751   ,  0.15334006,
       -0.03620544]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6403335678308335
{'scaleFactor': 20, 'currentState': array([25.373103  , 20.13035712, 14.83399345,  0.58097984,  0.76666176,
        0.27329869]), 'targetState': array([25., 25., 15.])}
episode index:3576
target thresh 37.05825158471513
model initialize at round 3576
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.94050909,  0.98642033,  0.15317086,
       -0.0592758 ]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6404204161624156
{'scaleFactor': 20, 'currentState': array([25.35038187, 20.15124655, 14.98882852,  0.57185933,  0.76707743,
        0.2908077 ]), 'targetState': array([25., 25., 15.])}
episode index:3577
target thresh 37.06454544485841
model initialize at round 3577
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.88838604,  0.98208217,  0.15249723,
       -0.11072129]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6405072159482563
{'scaleFactor': 20, 'currentState': array([25.39947339, 20.07139272, 14.47356112,  0.59614816,  0.76013622,
        0.25845753]), 'targetState': array([25., 25., 15.])}
episode index:3578
target thresh 37.070838675647146
model initialize at round 3578
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89151482,  0.9824151 ,  0.15254893,
       -0.10765402]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6405939672290476
{'scaleFactor': 20, 'currentState': array([25.19261765, 20.16659008, 13.0553957 ,  0.59213281,  0.80501965,
       -0.03636063]), 'targetState': array([25., 25., 15.])}
episode index:3579
target thresh 37.07713127714426
model initialize at round 3579
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6406806700454362
{'scaleFactor': 20, 'currentState': array([24.84189747, 20.06638982, 11.67722313,  0.54226331,  0.78748046,
       -0.29295909]), 'targetState': array([25., 25., 15.])}
episode index:3580
target thresh 37.08342324941268
model initialize at round 3580
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6407673244380233
{'scaleFactor': 20, 'currentState': array([24.80559198, 20.06298492, 11.59928898,  0.54818842,  0.79827403,
       -0.24949555]), 'targetState': array([25., 25., 15.])}
episode index:3581
target thresh 37.08971459251534
model initialize at round 3581
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14856807, 14.84627329,  0.97746884,  0.14668754,
       -0.15178088]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6408512755337695
{'scaleFactor': 20, 'currentState': array([26.59246118, 21.39700748, 12.81788462,  0.53201366,  0.84397535,
        0.06831591]), 'targetState': array([25., 25., 15.])}
episode index:3582
target thresh 37.09600530651515
model initialize at round 3582
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6409378339413515
{'scaleFactor': 20, 'currentState': array([ 2.51462097e+01,  2.01521755e+01,  1.28127234e+01,  6.18616702e-01,
        7.85684304e-01, -3.68115701e-03]), 'targetState': array([25., 25., 15.])}
episode index:3583
target thresh 37.10229539147502
model initialize at round 3583
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09632508, 14.84627329,  0.98362201,  0.09570451,
       -0.15273634]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6410216906141918
{'scaleFactor': 20, 'currentState': array([ 2.65996825e+01,  2.10157005e+01,  1.21365442e+01,  5.61517515e-01,
        8.27302014e-01, -1.64151753e-02]), 'targetState': array([25., 25., 15.])}
episode index:3584
target thresh 37.10858484745783
model initialize at round 3584
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09620095, 14.84627329,  0.98363361,  0.09558231,
       -0.15273814]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6411055005050666
{'scaleFactor': 20, 'currentState': array([26.19419284, 21.05061364, 10.97274235,  0.4712882 ,  0.84149415,
       -0.26414964]), 'targetState': array([25., 25., 15.])}
episode index:3585
target thresh 37.114873674526486
model initialize at round 3585
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6411919156052884
{'scaleFactor': 20, 'currentState': array([24.96721934, 20.13033517, 12.14960484,  0.58369071,  0.80533107,
       -0.10366791]), 'targetState': array([25., 25., 15.])}
episode index:3586
target thresh 37.12116187274388
model initialize at round 3586
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87956708,  0.9810948 ,  0.15234391,
       -0.11934961]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6412756313102774
{'scaleFactor': 20, 'currentState': array([26.41273837, 21.57386722, 12.58136889,  0.51479478,  0.85436771,
        0.07100803]), 'targetState': array([25., 25., 15.])}
episode index:3587
target thresh 37.12744944217289
model initialize at round 3587
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13387656, 14.84627329,  0.97945186,  0.13245015,
       -0.1520888 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6413593003509939
{'scaleFactor': 20, 'currentState': array([26.36217511, 21.63857749, 13.06295161,  0.47873284,  0.87031518,
        0.11561294]), 'targetState': array([25., 25., 15.])}
episode index:3588
target thresh 37.133736382876414
model initialize at round 3588
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6414455725018853
{'scaleFactor': 20, 'currentState': array([25.18801375, 20.19020977, 13.34026175,  0.58805539,  0.79682286,
        0.13879547]), 'targetState': array([25., 25., 15.])}
episode index:3589
target thresh 37.14002269491728
model initialize at round 3589
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.88155363,  0.9813235 ,  0.15237942,
       -0.11740829]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.641531796590297
{'scaleFactor': 20, 'currentState': array([25.26905523, 20.17920132, 13.91212796,  0.58441618,  0.78581639,
        0.2023619 ]), 'targetState': array([25., 25., 15.])}
episode index:3590
target thresh 37.146308378358384
model initialize at round 3590
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87965177,  0.98110462,  0.15234544,
       -0.11926687]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6416179726563817
{'scaleFactor': 20, 'currentState': array([25.30778395, 20.16088488, 14.51729878,  0.57349137,  0.77118823,
        0.27636275]), 'targetState': array([25., 25., 15.])}
episode index:3591
target thresh 37.15259343326256
model initialize at round 3591
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.94605342,  0.98672843,  0.1532187 ,
       -0.0537683 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6417014532178361
{'scaleFactor': 20, 'currentState': array([26.87629052, 21.27272241, 14.55930557,  0.60564407,  0.71942524,
        0.34003322]), 'targetState': array([25., 25., 15.])}
episode index:3592
target thresh 37.15887785969267
model initialize at round 3592
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11662521, 14.87165111,  0.98500155,  0.11603637,
       -0.12770086]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6417848873108456
{'scaleFactor': 20, 'currentState': array([27.3047419 , 20.38179596, 13.00628137,  0.68129343,  0.73027434,
        0.05038509]), 'targetState': array([25., 25., 15.])}
episode index:3593
target thresh 37.165161657711565
model initialize at round 3593
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11279976, 14.84627329,  0.98195361,  0.11188297,
       -0.15247727]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6418656553855802
{'scaleFactor': 20, 'currentState': array([29.41765222, 20.58280832, 12.93225019,  0.79408903,  0.59749368,
        0.11146259]), 'targetState': array([25., 25., 15.])}
episode index:3594
target thresh 37.171444827382075
model initialize at round 3594
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.02255155, 14.84627329,  0.98790762,  0.02250388,
       -0.1534018 ]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.6416871113924271
{'scaleFactor': 20, 'currentState': array([29.32256844, 66.04013184,  2.55137551, -0.81341659, -0.56864771,
       -0.12244689]), 'targetState': array([25., 25., 15.])}
episode index:3595
target thresh 37.17772736876703
model initialize at round 3595
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87729277,  0.9808285 ,  0.15230256,
       -0.12157045]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6417704798679578
{'scaleFactor': 20, 'currentState': array([27.20837912, 20.72526403, 13.7824675 ,  0.62983348,  0.75111161,
        0.19784121]), 'targetState': array([25., 25., 15.])}
episode index:3596
target thresh 37.184009281929264
model initialize at round 3596
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14068771, 14.84627329,  0.97855667,  0.13906152,
       -0.15194979]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6418564458312694
{'scaleFactor': 20, 'currentState': array([25.21227835, 20.06979509, 13.11753326,  0.59805704,  0.79272925,
        0.11793265]), 'targetState': array([25., 25., 15.])}
episode index:3597
target thresh 37.19029056693158
model initialize at round 3597
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89734796,  0.98301138,  0.15264152,
       -0.1019274 ]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6419423640091652
{'scaleFactor': 20, 'currentState': array([25.39629729, 20.0108297 , 13.58916524,  0.62412714,  0.77389567,
        0.10747465]), 'targetState': array([25., 25., 15.])}
episode index:3598
target thresh 37.196571223836806
model initialize at round 3598
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6420255920684571
{'scaleFactor': 20, 'currentState': array([26.57979851, 21.53357532, 14.01303893,  0.52177215,  0.7950186 ,
        0.30935294]), 'targetState': array([25., 25., 15.])}
episode index:3599
target thresh 37.202851252707745
model initialize at round 3599
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.1501239 , 14.87901789,  0.98155865,  0.14884385,
       -0.11995054]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6421087738899384
{'scaleFactor': 20, 'currentState': array([26.66597944, 21.4651728 , 13.72670519,  0.56433704,  0.80844618,
        0.16714807]), 'targetState': array([25., 25., 15.])}
episode index:3600
target thresh 37.209130653607204
model initialize at round 3600
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6421919095121297
{'scaleFactor': 20, 'currentState': array([26.71741936, 21.38743711, 13.80082211,  0.65393484,  0.69227984,
        0.30515218]), 'targetState': array([25., 25., 15.])}
episode index:3601
target thresh 37.21540942659796
model initialize at round 3601
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.03562304, 14.86606891,  0.99034344,  0.0356354 ,
       -0.13397755]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.6420136219192613
{'scaleFactor': 20, 'currentState': array([32.76347407, 10.44887005, 11.38551311,  0.97531393,  0.05498392,
        0.21386794]), 'targetState': array([25., 25., 15.])}
episode index:3602
target thresh 37.22168757174281
model initialize at round 3602
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.06173874, 14.84627329,  0.98628693,  0.06150718,
       -0.15315014]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6420941247574482
{'scaleFactor': 20, 'currentState': array([29.4395808 , 20.01668821, 12.65577617,  0.67965826,  0.71935754,
        0.14349001]), 'targetState': array([25., 25., 15.])}
episode index:3603
target thresh 37.22796508910454
model initialize at round 3603
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6421798339486643
{'scaleFactor': 20, 'currentState': array([24.9862709 , 20.14566327, 12.2490977 ,  0.58050651,  0.81196419,
       -0.06104381]), 'targetState': array([25., 25., 15.])}
episode index:3604
target thresh 37.23424197874592
model initialize at round 3604
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6422654955897049
{'scaleFactor': 20, 'currentState': array([25.11182207, 20.18350652, 12.89300289,  0.58847914,  0.80534554,
        0.07149033]), 'targetState': array([25., 25., 15.])}
episode index:3605
target thresh 37.240518240729706
model initialize at round 3605
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6423484724765078
{'scaleFactor': 20, 'currentState': array([26.53860891, 21.49759295, 14.32122386,  0.47364704,  0.80633388,
        0.35423744]), 'targetState': array([25., 25., 15.])}
episode index:3606
target thresh 37.24679387511869
model initialize at round 3606
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86965646,  0.97989964,  0.15215833,
       -0.12901373]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6424314033545018
{'scaleFactor': 20, 'currentState': array([27.18393663, 20.77298021, 14.11872571,  0.59236912,  0.75304235,
        0.28640188]), 'targetState': array([25., 25., 15.])}
episode index:3607
target thresh 37.2530688819756
model initialize at round 3607
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.91293319,  0.98444736,  0.1528645 ,
       -0.08657848]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6425142882619426
{'scaleFactor': 20, 'currentState': array([26.54801529, 21.53398577, 14.51583127,  0.46766893,  0.82303393,
        0.32233667]), 'targetState': array([25., 25., 15.])}
episode index:3608
target thresh 37.259343261363206
model initialize at round 3608
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6425971272370434
{'scaleFactor': 20, 'currentState': array([26.59588076, 21.38223229, 13.89785953,  0.48923417,  0.81491982,
        0.31073399]), 'targetState': array([25., 25., 15.])}
episode index:3609
target thresh 37.26561701334424
model initialize at round 3609
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13666689, 14.88643572,  0.98427114,  0.13587604,
       -0.11290712]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6426799203179752
{'scaleFactor': 20, 'currentState': array([26.77755062, 21.05929203, 12.9238159 ,  0.54876866,  0.8181594 ,
        0.17166289]), 'targetState': array([25., 25., 15.])}
episode index:3610
target thresh 37.27189013798146
model initialize at round 3610
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6427626675428666
{'scaleFactor': 20, 'currentState': array([27.39684681, 20.29630411, 12.65317999,  0.73768107,  0.66162856,
        0.13444068]), 'targetState': array([25., 25., 15.])}
episode index:3611
target thresh 37.278162635337566
model initialize at round 3611
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6428480018126222
{'scaleFactor': 20, 'currentState': array([24.97096809, 20.14254836, 12.19459962,  0.57973356,  0.81255903,
       -0.06047166]), 'targetState': array([25., 25., 15.])}
episode index:3612
target thresh 37.284434505475296
model initialize at round 3612
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6429332888450295
{'scaleFactor': 20, 'currentState': array([2.52196881e+01, 2.00950069e+01, 1.29616965e+01, 6.40010536e-01,
       7.68063023e-01, 2.15802169e-02]), 'targetState': array([25., 25., 15.])}
episode index:3613
target thresh 37.29070574845736
model initialize at round 3613
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6430185286793004
{'scaleFactor': 20, 'currentState': array([25.06412363, 20.16043378, 12.50751639,  0.58523884,  0.80925094,
       -0.05107263]), 'targetState': array([25., 25., 15.])}
episode index:3614
target thresh 37.2969763643465
model initialize at round 3614
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6431010906767338
{'scaleFactor': 20, 'currentState': array([26.57014626, 21.38481611, 13.45611697,  0.50117596,  0.8239309 ,
        0.26450052]), 'targetState': array([25., 25., 15.])}
episode index:3615
target thresh 37.3032463532054
model initialize at round 3615
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87959459,  0.98109799,  0.15234441,
       -0.11932274]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6431836070093455
{'scaleFactor': 20, 'currentState': array([ 2.68778891e+01,  2.11304958e+01,  1.26148070e+01,  6.70069487e-01,
        7.42156956e-01, -1.44891166e-02]), 'targetState': array([25., 25., 15.])}
episode index:3616
target thresh 37.30951571509675
model initialize at round 3616
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.07374568, 14.84627329,  0.98549167,  0.07340986,
       -0.15302666]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6432634747839925
{'scaleFactor': 20, 'currentState': array([28.66209659, 20.68228445, 10.65053037,  0.60215723,  0.78285992,
       -0.15664294]), 'targetState': array([25., 25., 15.])}
episode index:3617
target thresh 37.31578445008328
model initialize at round 3617
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13022641, 14.84627329,  0.97991429,  0.12889971,
       -0.1521606 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6433459006199839
{'scaleFactor': 20, 'currentState': array([26.4361924 , 21.04675264, 11.49963219,  0.53917234,  0.83794451,
       -0.08451141]), 'targetState': array([25., 25., 15.])}
episode index:3618
target thresh 37.32205255822765
model initialize at round 3618
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6434309086744961
{'scaleFactor': 20, 'currentState': array([25.20132762, 20.06693225, 12.71840722,  0.61071597,  0.79101505,
       -0.03634818]), 'targetState': array([25., 25., 15.])}
episode index:3619
target thresh 37.32832003959253
model initialize at round 3619
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6435158697632325
{'scaleFactor': 20, 'currentState': array([25.21277636, 20.18637564, 13.63033172,  0.58323832,  0.78859895,
        0.19479415]), 'targetState': array([25., 25., 15.])}
episode index:3620
target thresh 37.33458689424061
model initialize at round 3620
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14794871, 14.90005844,  0.98412405,  0.14707059,
       -0.09934838]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6436007839251041
{'scaleFactor': 20, 'currentState': array([25.26457265, 20.09981951, 13.47342772,  0.59675005,  0.78989029,
        0.14128944]), 'targetState': array([25., 25., 15.])}
episode index:3621
target thresh 37.34085312223456
model initialize at round 3621
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87850638,  0.9809712 ,  0.15232472,
       -0.1203856 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6436830256052465
{'scaleFactor': 20, 'currentState': array([26.80014192, 21.25871083, 13.31817419,  0.61889716,  0.75430564,
        0.21906461]), 'targetState': array([25., 25., 15.])}
episode index:3622
target thresh 37.34711872363705
model initialize at round 3622
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85140572,  0.97746513,  0.1517803 ,
       -0.14671286]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6437652218856207
{'scaleFactor': 20, 'currentState': array([26.96711857, 20.90884995, 13.24489673,  0.590193  ,  0.77709024,
        0.21863894]), 'targetState': array([25., 25., 15.])}
episode index:3623
target thresh 37.353383698510726
model initialize at round 3623
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11227603, 14.84627329,  0.98201055,  0.11136994,
       -0.15248611]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6438473728038092
{'scaleFactor': 20, 'currentState': array([26.91805645, 20.89774152, 13.28811924,  0.61995372,  0.74416076,
        0.24876122]), 'targetState': array([25., 25., 15.])}
episode index:3624
target thresh 37.35964804691824
model initialize at round 3624
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08134475, 14.98201471,  0.99647802,  0.08187702,
       -0.01810298]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6439294783973531
{'scaleFactor': 20, 'currentState': array([27.31565847, 20.4191045 , 15.30588544,  0.56673089,  0.76816314,
        0.29789511]), 'targetState': array([25., 25., 15.])}
episode index:3625
target thresh 37.365911768922224
model initialize at round 3625
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.96189421,  0.98744388,  0.15332979,
       -0.03800741]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.644014161401077
{'scaleFactor': 20, 'currentState': array([25.37025078, 20.14880203, 15.36074214,  0.57172849,  0.76603172,
        0.29380597]), 'targetState': array([25., 25., 15.])}
episode index:3626
target thresh 37.372174864585325
model initialize at round 3626
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.98033995,  0.98796766,  0.15341113,
       -0.01961969]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.644098797708907
{'scaleFactor': 20, 'currentState': array([25.38672658, 20.16717531, 14.99060511,  0.58433089,  0.77760201,
        0.23214764]), 'targetState': array([25., 25., 15.])}
episode index:3627
target thresh 37.37843733397018
model initialize at round 3627
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.94444527,  0.98664214,  0.1532053 ,
       -0.0553663 ]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6441833873594558
{'scaleFactor': 20, 'currentState': array([25.31685528, 20.17092086, 14.21601414,  0.58555338,  0.78308199,
        0.20954674]), 'targetState': array([25., 25., 15.])}
episode index:3628
target thresh 37.3846991771394
model initialize at round 3628
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87126112,  0.98009926,  0.15218933,
       -0.1274514 ]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6442679303912939
{'scaleFactor': 20, 'currentState': array([25.19838208, 20.13077194, 13.00107563,  0.62330349,  0.78027106,
        0.05167048]), 'targetState': array([25., 25., 15.])}
episode index:3629
target thresh 37.39096039415563
model initialize at round 3629
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10321784, 14.87497119,  0.98685393,  0.10288983,
       -0.12463149]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6443498070356493
{'scaleFactor': 20, 'currentState': array([26.66357264, 21.13021418, 13.43292338,  0.50785695,  0.82591951,
        0.24482298]), 'targetState': array([25., 25., 15.])}
episode index:3630
target thresh 37.39722098508144
model initialize at round 3630
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6444342576671184
{'scaleFactor': 20, 'currentState': array([25.00629996, 20.15206718, 12.32664249,  0.58142563,  0.81075833,
       -0.06793501]), 'targetState': array([25., 25., 15.])}
episode index:3631
target thresh 37.40348094997946
model initialize at round 3631
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6445186617949359
{'scaleFactor': 20, 'currentState': array([25.16143359, 20.10057775, 12.65756768,  0.60933081,  0.79144298,
       -0.04831115]), 'targetState': array([25., 25., 15.])}
episode index:3632
target thresh 37.40974028891232
model initialize at round 3632
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14418899, 14.84627329,  0.97808021,  0.14245293,
       -0.15187581]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6446004018135447
{'scaleFactor': 20, 'currentState': array([27.11272953, 20.51241341, 12.3780954 ,  0.63433669,  0.77213531,
        0.03773632]), 'targetState': array([25., 25., 15.])}
episode index:3633
target thresh 37.41599900194256
model initialize at round 3633
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6446820968459023
{'scaleFactor': 20, 'currentState': array([26.65387506, 21.39661035, 12.74358386,  0.63057841,  0.77324968,
        0.06675172]), 'targetState': array([25., 25., 15.])}
episode index:3634
target thresh 37.422257089132785
model initialize at round 3634
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.1257338 , 14.84627329,  0.98046675,  0.12452304,
       -0.15224639]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6447637469291361
{'scaleFactor': 20, 'currentState': array([26.98422301, 20.78488414, 12.9304218 ,  0.59939785,  0.77999827,
        0.17979131]), 'targetState': array([25., 25., 15.])}
episode index:3635
target thresh 37.428514550545586
model initialize at round 3635
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15204557, 14.87568131,  0.98088433,  0.15064557,
       -0.123174  ]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6448479675845186
{'scaleFactor': 20, 'currentState': array([25.26088901, 20.16617778, 13.79745063,  0.58626079,  0.7867476 ,
        0.19320069]), 'targetState': array([25., 25., 15.])}
episode index:3636
target thresh 37.434771386243526
model initialize at round 3636
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.95388724,  0.98711283,  0.15327839,
       -0.04597828]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6449321419266455
{'scaleFactor': 20, 'currentState': array([25.36887428, 20.13291539, 15.3582329 ,  0.57429478,  0.75769634,
        0.30997058]), 'targetState': array([25., 25., 15.])}
episode index:3637
target thresh 37.4410275962892
model initialize at round 3637
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13625427, 14.9554124 ,  0.98967678,  0.13620979,
       -0.04457305]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6450136559473916
{'scaleFactor': 20, 'currentState': array([27.29963929, 20.64544514, 14.65585186,  0.61616675,  0.73762924,
        0.27611889]), 'targetState': array([25., 25., 15.])}
episode index:3638
target thresh 37.44728318074513
model initialize at round 3638
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14398214, 14.84627329,  0.97810867,  0.14225271,
       -0.15188023]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6450951251679065
{'scaleFactor': 20, 'currentState': array([26.81456104, 21.02596316, 12.72520668,  0.60424187,  0.78169716,
        0.1544063 ]), 'targetState': array([25., 25., 15.])}
episode index:3639
target thresh 37.453538139673896
model initialize at round 3639
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13766385, 14.88128757,  0.98355718,  0.13676795,
       -0.11793986]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6451765496251133
{'scaleFactor': 20, 'currentState': array([26.42409339, 21.49705785, 12.42066637,  0.52936601,  0.84788866,
        0.02926527]), 'targetState': array([25., 25., 15.])}
episode index:3640
target thresh 37.459792473138044
model initialize at round 3640
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15117198, 14.84627329,  0.97709719,  0.14920174,
       -0.15172317]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6452605412483693
{'scaleFactor': 20, 'currentState': array([25.20696246, 20.16473618, 13.30831901,  0.59136595,  0.7967841 ,
        0.12418297]), 'targetState': array([25., 25., 15.])}
episode index:3641
target thresh 37.466046181200106
model initialize at round 3641
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89375949,  0.98264833,  0.15258514,
       -0.10545158]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.645341875572409
{'scaleFactor': 20, 'currentState': array([26.97347048, 20.96249582, 13.12308707,  0.61102103,  0.77266538,
        0.17216708]), 'targetState': array([25., 25., 15.])}
episode index:3642
target thresh 37.47229926392265
model initialize at round 3642
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.1222287 , 14.84627329,  0.98088493,  0.12110332,
       -0.15231132]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.645423165244061
{'scaleFactor': 20, 'currentState': array([26.58365256, 21.35491699, 14.46190716,  0.46808721,  0.80894486,
        0.35567202]), 'targetState': array([25., 25., 15.])}
episode index:3643
target thresh 37.47855172136818
model initialize at round 3643
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89581103,  0.98285736,  0.1526176 ,
       -0.10343727]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6455070200422651
{'scaleFactor': 20, 'currentState': array([25.31110413, 20.17159502, 14.26267424,  0.58194097,  0.7799584 ,
        0.23023813]), 'targetState': array([25., 25., 15.])}
episode index:3644
target thresh 37.484803553599214
model initialize at round 3644
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86873927,  0.97978449,  0.15214045,
       -0.12990629]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6455908288296062
{'scaleFactor': 20, 'currentState': array([25.26664591, 20.17946754, 13.92309881,  0.58343672,  0.78490402,
        0.2086319 ]), 'targetState': array([25., 25., 15.])}
episode index:3645
target thresh 37.49105476067829
model initialize at round 3645
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89611935,  0.98288844,  0.15262243,
       -0.10313444]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6456745916439426
{'scaleFactor': 20, 'currentState': array([25.32814445, 20.17693505, 14.16401916,  0.58851816,  0.78631518,
        0.18802875]), 'targetState': array([25., 25., 15.])}
episode index:3646
target thresh 37.49730534266791
model initialize at round 3646
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87504581,  0.98056074,  0.15226098,
       -0.1237628 ]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6457583085230915
{'scaleFactor': 20, 'currentState': array([ 2.50914395e+01,  2.01629655e+01,  1.26700004e+01,  5.87791815e-01,
        8.08750480e-01, -2.05777688e-02]), 'targetState': array([25., 25., 15.])}
episode index:3647
target thresh 37.503555299630584
model initialize at round 3647
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6458419795048287
{'scaleFactor': 20, 'currentState': array([24.8186033 , 20.05578167, 11.60913323,  0.53873409,  0.78631965,
       -0.30243508]), 'targetState': array([25., 25., 15.])}
episode index:3648
target thresh 37.50980463162883
model initialize at round 3648
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6459229984606785
{'scaleFactor': 20, 'currentState': array([26.4034601 , 21.17214118, 11.23520763,  0.56222233,  0.79329599,
       -0.23363973]), 'targetState': array([25., 25., 15.])}
episode index:3649
target thresh 37.5160533387251
model initialize at round 3649
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10680516, 14.84627329,  0.9825901 ,  0.10600575,
       -0.1525761 ]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6460013936249104
{'scaleFactor': 20, 'currentState': array([ 2.87493325e+01,  2.12388295e+01,  1.13025425e+01,  6.42788158e-01,
        7.65935167e-01, -1.29114104e-02]), 'targetState': array([25., 25., 15.])}
episode index:3650
target thresh 37.5223014209819
model initialize at round 3650
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12158598, 14.84627329,  0.98096038,  0.12047579,
       -0.15232304]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6460823245358323
{'scaleFactor': 20, 'currentState': array([26.96579334, 20.81482012, 12.71838389,  0.62088675,  0.78069947,
        0.07076708]), 'targetState': array([25., 25., 15.])}
episode index:3651
target thresh 37.52854887846172
model initialize at round 3651
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.0963017 , 14.84627329,  0.9836242 ,  0.0956815 ,
       -0.15273668]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6461632111253354
{'scaleFactor': 20, 'currentState': array([26.93365402, 20.93089939, 13.76278169,  0.57369282,  0.78530513,
        0.23274966]), 'targetState': array([25., 25., 15.])}
episode index:3652
target thresh 37.534795711227034
model initialize at round 3652
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86647883,  0.97949742,  0.15209587,
       -0.13210468]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6462414761504603
{'scaleFactor': 20, 'currentState': array([29.35904196, 20.65072052, 13.74071482,  0.78393925,  0.52240526,
        0.3354579 ]), 'targetState': array([25., 25., 15.])}
episode index:3653
target thresh 37.5410419193403
model initialize at round 3653
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.04326404, 14.84627329,  0.98723778,  0.04314333,
       -0.15329779]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.6460646175089304
{'scaleFactor': 20, 'currentState': array([33.71142136, 17.8812475 , 12.43835689,  0.8711561 ,  0.42718175,
        0.24208016]), 'targetState': array([25., 25., 15.])}
episode index:3654
target thresh 37.54728750286398
model initialize at round 3654
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.88181566,  0.98135339,  0.15238407,
       -0.11715213]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6461480444398172
{'scaleFactor': 20, 'currentState': array([ 2.51414964e+01,  2.01551876e+01,  1.28167213e+01,  5.98203124e-01,
        8.01204244e-01, -1.49927571e-02]), 'targetState': array([25., 25., 15.])}
episode index:3655
target thresh 37.55353246186054
model initialize at round 3655
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10780187, 14.84627329,  0.9824866 ,  0.10698373,
       -0.15256003]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6462288245560538
{'scaleFactor': 20, 'currentState': array([27.07113212, 20.45195429, 12.45565343,  0.64075544,  0.76472798,
        0.06799691]), 'targetState': array([25., 25., 15.])}
episode index:3656
target thresh 37.55977679639243
model initialize at round 3656
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08620352, 14.84627329,  0.98452018,  0.08572637,
       -0.1528758 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6463095604939386
{'scaleFactor': 20, 'currentState': array([27.04166232, 20.1393896 , 11.29605965,  0.70398896,  0.67086763,
       -0.23310121]), 'targetState': array([25., 25., 15.])}
episode index:3657
target thresh 37.56602050652208
model initialize at round 3657
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.06242886, 14.84627329,  0.98624499,  0.06219207,
       -0.15314363]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6463876785331439
{'scaleFactor': 20, 'currentState': array([28.89224684, 20.60405326, 11.51518483,  0.62337292,  0.78039075,
       -0.04895395]), 'targetState': array([25., 25., 15.])}
episode index:3658
target thresh 37.57226359231194
model initialize at round 3658
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6464709259699757
{'scaleFactor': 20, 'currentState': array([25.22755271, 20.18291909, 13.78217015,  0.58104505,  0.78476648,
        0.21570404]), 'targetState': array([25., 25., 15.])}
episode index:3659
target thresh 37.57850605382443
model initialize at round 3659
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87035375,  0.97998667,  0.15217184,
       -0.12833495]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6465541279164047
{'scaleFactor': 20, 'currentState': array([25.35856828, 20.0610788 , 13.67953605,  0.6108649 ,  0.7866369 ,
        0.08970204]), 'targetState': array([25., 25., 15.])}
episode index:3660
target thresh 37.58474789112197
model initialize at round 3660
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87464788,  0.98051283,  0.15225355,
       -0.12415087]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.646637284409708
{'scaleFactor': 20, 'currentState': array([25.36759334, 20.07224895, 13.77479068,  0.62037903,  0.77501233,
        0.12035674]), 'targetState': array([25., 25., 15.])}
episode index:3661
target thresh 37.59098910426702
model initialize at round 3661
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6467203954871221
{'scaleFactor': 20, 'currentState': array([24.79759632, 20.05212331, 11.56038275,  0.54348052,  0.7943012 ,
       -0.27150419]), 'targetState': array([25., 25., 15.])}
episode index:3662
target thresh 37.597229693321935
model initialize at round 3662
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6468034611858426
{'scaleFactor': 20, 'currentState': array([25.20901033, 20.17692449, 13.49819501,  0.59726199,  0.78229189,
        0.17691102]), 'targetState': array([25., 25., 15.])}
episode index:3663
target thresh 37.60346965834914
model initialize at round 3663
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.90087739,  0.98335666,  0.15269513,
       -0.09845745]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6468864815430244
{'scaleFactor': 20, 'currentState': array([25.30316203, 20.16906177, 14.10831668,  0.585162  ,  0.78281184,
        0.211639  ]), 'targetState': array([25., 25., 15.])}
episode index:3664
target thresh 37.609708999411055
model initialize at round 3664
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.94540184,  0.98669377,  0.15321332,
       -0.05441583]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6469694565957822
{'scaleFactor': 20, 'currentState': array([25.3780119 , 20.08823313, 14.02496667,  0.62587329,  0.75640528,
        0.1900886 ]), 'targetState': array([25., 25., 15.])}
episode index:3665
target thresh 37.615947716570055
model initialize at round 3665
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.1285808 , 14.86049501,  0.98212804,  0.12755839,
       -0.13839571]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6470497923003117
{'scaleFactor': 20, 'currentState': array([27.1107942 , 20.64823484, 13.78031207,  0.59031633,  0.76273887,
        0.26411371]), 'targetState': array([25., 25., 15.])}
episode index:3666
target thresh 37.62218580988853
model initialize at round 3666
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10225989, 14.84946236,  0.98352092,  0.10159064,
       -0.14955244]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6471275167496181
{'scaleFactor': 20, 'currentState': array([29.47391578, 20.33915402, 13.74123152,  0.75449383,  0.59350705,
        0.28015788]), 'targetState': array([25., 25., 15.])}
episode index:3667
target thresh 37.62842327942888
model initialize at round 3667
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.05327124, 14.84627329,  0.98676392,  0.05309711,
       -0.15322421]), 'targetState': array([25., 25., 15.])}
done in step count: 46
reward sum = 0.6298236312032323
running average episode reward sum: 0.6471227992235695
{'scaleFactor': 20, 'currentState': array([27.377782  , 28.36356045, 10.07275535,  0.60431418, -0.65622948,
        0.4518487 ]), 'targetState': array([25., 25., 15.])}
episode index:3668
target thresh 37.63466012525345
model initialize at round 3668
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86114174,  0.97880123,  0.15198777,
       -0.13728752]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.647205619406365
{'scaleFactor': 20, 'currentState': array([25.18291055, 20.18708225, 13.3105697 ,  0.58783088,  0.79714979,
        0.13786609]), 'targetState': array([25., 25., 15.])}
episode index:3669
target thresh 37.640896347424615
model initialize at round 3669
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14386602, 14.84627329,  0.97812462,  0.1421403 ,
       -0.15188271]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6472883944555459
{'scaleFactor': 20, 'currentState': array([25.29688708, 20.08927509, 13.89776329,  0.58847725,  0.7773874 ,
        0.22217864]), 'targetState': array([25., 25., 15.])}
episode index:3670
target thresh 37.64713194600474
model initialize at round 3670
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85840734,  0.97843458,  0.15193084,
       -0.13993854]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.647371124407996
{'scaleFactor': 20, 'currentState': array([25.20024279, 20.18442284, 13.41225268,  0.58946645,  0.79332644,
        0.15219218]), 'targetState': array([25., 25., 15.])}
episode index:3671
target thresh 37.6533669210562
model initialize at round 3671
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12878496, 14.93044788,  0.98924694,  0.12868699,
       -0.06949921]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6474512194583754
{'scaleFactor': 20, 'currentState': array([26.78424534, 21.26719881, 14.86422861,  0.51317758,  0.77687318,
        0.36485179]), 'targetState': array([25., 25., 15.])}
episode index:3672
target thresh 37.65960127264132
model initialize at round 3672
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11407114, 14.98101474,  0.99324693,  0.11444527,
       -0.01904752]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6475312708958767
{'scaleFactor': 20, 'currentState': array([27.25141186, 20.71336541, 15.11584334,  0.59962275,  0.75987144,
        0.25109352]), 'targetState': array([25., 25., 15.])}
episode index:3673
target thresh 37.66583500082245
model initialize at round 3673
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.1273063 , 14.88209237,  0.98498486,  0.12666139,
       -0.11731033]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6476112787561121
{'scaleFactor': 20, 'currentState': array([27.06694439, 20.82912714, 13.84323864,  0.61279658,  0.74220791,
        0.27130751]), 'targetState': array([25., 25., 15.])}
episode index:3674
target thresh 37.67206810566193
model initialize at round 3674
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6476912430746549
{'scaleFactor': 20, 'currentState': array([26.51046069, 21.53846006, 13.09136397,  0.54318165,  0.82208446,
        0.17067755]), 'targetState': array([25., 25., 15.])}
episode index:3675
target thresh 37.67830058722209
model initialize at round 3675
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.06175593, 14.84627329,  0.98628589,  0.06152424,
       -0.15314998]), 'targetState': array([25., 25., 15.])}
done in step count: 45
reward sum = 0.6361854860638709
running average episode reward sum: 0.6476881131081123
{'scaleFactor': 20, 'currentState': array([ 2.24116953e+01,  2.13270652e+01,  1.02166390e+01,  8.99302820e-01,
       -1.95987676e-02,  4.36887087e-01]), 'targetState': array([25., 25., 15.])}
episode index:3676
target thresh 37.68453244556525
model initialize at round 3676
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13831439, 14.92882143,  0.98787969,  0.13801815,
       -0.07102613]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6477654525790938
{'scaleFactor': 20, 'currentState': array([29.00976014, 21.39731429, 13.91061306,  0.59933122,  0.75262579,
        0.27268389]), 'targetState': array([25., 25., 15.])}
episode index:3677
target thresh 37.69076368075375
model initialize at round 3677
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.93629193,  0.98616603,  0.15313137,
       -0.06346135]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6478478953733626
{'scaleFactor': 20, 'currentState': array([25.3489939 , 20.17234293, 14.43431841,  0.58641983,  0.78241264,
        0.20962404]), 'targetState': array([25., 25., 15.])}
episode index:3678
target thresh 37.69699429284989
model initialize at round 3678
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.883857  ,  0.9815841 ,  0.15241989,
       -0.11515567]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6479277084350716
{'scaleFactor': 20, 'currentState': array([26.62577405, 21.41362609, 13.01215453,  0.58615266,  0.80528973,
        0.08907029]), 'targetState': array([25., 25., 15.])}
episode index:3679
target thresh 37.70322428191595
model initialize at round 3679
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.0702107 , 14.84627329,  0.98574024,  0.0699086 ,
       -0.15306525]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6480049197501456
{'scaleFactor': 20, 'currentState': array([28.48169746, 21.29259812, 12.2533362 ,  0.52742086,  0.82556943,
        0.20065479]), 'targetState': array([25., 25., 15.])}
episode index:3680
target thresh 37.70945364801427
model initialize at round 3680
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11094331, 14.84627329,  0.9821543 ,  0.11006409,
       -0.15250843]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6480846467888989
{'scaleFactor': 20, 'currentState': array([27.29098939, 20.31894545, 13.60015367,  0.65673896,  0.70014197,
        0.28016988]), 'targetState': array([25., 25., 15.])}
episode index:3681
target thresh 37.7156823912071
model initialize at round 3681
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10580758, 14.8494223 ,  0.98315701,  0.10507623,
       -0.14953689]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6481617735409679
{'scaleFactor': 20, 'currentState': array([29.57578919, 20.23029506, 12.96884731,  0.8419012 ,  0.4960236 ,
        0.21251577]), 'targetState': array([25., 25., 15.])}
episode index:3682
target thresh 37.72191051155678
model initialize at round 3682
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 14.98214299, 14.84627329,  0.98800094, -0.01782095,
       -0.15341629]), 'targetState': array([25., 25., 15.])}
done in step count: 46
reward sum = 0.6298236312032323
running average episode reward sum: 0.64815679440919
{'scaleFactor': 20, 'currentState': array([25.77487773, 29.22914343, 13.72862498,  0.60791813, -0.76999683,
        0.19375355]), 'targetState': array([25., 25., 15.])}
episode index:3683
target thresh 37.72813800912556
model initialize at round 3683
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12575495, 14.8753364 ,  0.98437787,  0.12504079,
       -0.12395564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6482364152981672
{'scaleFactor': 20, 'currentState': array([27.35352453, 20.21549536, 13.52976883,  0.61934208,  0.74434022,
        0.2497459 ]), 'targetState': array([25., 25., 15.])}
episode index:3684
target thresh 37.734364883975715
model initialize at round 3684
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6483185736793347
{'scaleFactor': 20, 'currentState': array([25.3213643 , 20.09595129, 13.73127064,  0.60394845,  0.77480777,
        0.18686676]), 'targetState': array([25., 25., 15.])}
episode index:3685
target thresh 37.74059113616952
model initialize at round 3685
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14250487, 14.90348422,  0.98522196,  0.1418171 ,
       -0.09604997]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6483981074763291
{'scaleFactor': 20, 'currentState': array([26.68959289, 21.3338935 , 14.2978962 ,  0.49231115,  0.81276453,
        0.31151814]), 'targetState': array([25., 25., 15.])}
episode index:3686
target thresh 37.74681676576923
model initialize at round 3686
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85759677,  0.9783246 ,  0.15191376,
       -0.14072382]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6484801774363029
{'scaleFactor': 20, 'currentState': array([25.2482407 , 20.10010743, 13.33384295,  0.59906409,  0.78800985,
        0.1419954 ]), 'targetState': array([25., 25., 15.])}
episode index:3687
target thresh 37.753041772837115
model initialize at round 3687
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86697545,  0.97956089,  0.15210573,
       -0.13162186]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6485622028897909
{'scaleFactor': 20, 'currentState': array([25.1944492 , 20.18067688, 13.15277822,  0.59311893,  0.80456777,
        0.02967536]), 'targetState': array([25., 25., 15.])}
episode index:3688
target thresh 37.75926615743541
model initialize at round 3688
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6486416059655598
{'scaleFactor': 20, 'currentState': array([26.43963291, 21.5962279 , 12.79477662,  0.49689152,  0.86233004,
        0.09739463]), 'targetState': array([25., 25., 15.])}
episode index:3689
target thresh 37.76548991962637
model initialize at round 3689
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13677088, 14.90823723,  0.98644207,  0.13627934,
       -0.09143298]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6487209660044311
{'scaleFactor': 20, 'currentState': array([26.39039985, 21.63582239, 13.54275115,  0.46824789,  0.85091112,
        0.2381054 ]), 'targetState': array([25., 25., 15.])}
episode index:3690
target thresh 37.77171305947223
model initialize at round 3690
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.92579027,  0.98545815,  0.15302145,
       -0.07386927]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6488028595519509
{'scaleFactor': 20, 'currentState': array([25.34011233, 20.13259831, 15.36020504,  0.56151331,  0.75764481,
        0.33268175]), 'targetState': array([25., 25., 15.])}
episode index:3691
target thresh 37.777935577035215
model initialize at round 3691
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.9557285 ,  0.9871945 ,  0.15329107,
       -0.04414604]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.648884708736769
{'scaleFactor': 20, 'currentState': array([25.30426522, 20.17550617, 13.92424928,  0.59242334,  0.7924281 ,
        0.14523184]), 'targetState': array([25., 25., 15.])}
episode index:3692
target thresh 37.78415747237756
model initialize at round 3692
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12875563, 14.84668272,  0.98015757,  0.12747556,
       -0.15179302]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6489639384797053
{'scaleFactor': 20, 'currentState': array([26.62753971, 21.32151964, 13.82995716,  0.49457694,  0.81907905,
        0.29069428]), 'targetState': array([25., 25., 15.])}
episode index:3693
target thresh 37.79037874556148
model initialize at round 3693
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.1357044 , 14.86529483,  0.98185437,  0.13458784,
       -0.13359683]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6490431253261919
{'scaleFactor': 20, 'currentState': array([26.40643853, 21.62595918, 14.16622639,  0.45221176,  0.83178373,
        0.32193221]), 'targetState': array([25., 25., 15.])}
episode index:3694
target thresh 37.7965993966492
model initialize at round 3694
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86267724,  0.97900417,  0.15201928,
       -0.13579753]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6491248430324366
{'scaleFactor': 20, 'currentState': array([25.34266388, 20.08841771, 13.83564152,  0.62018262,  0.75951509,
        0.19624055]), 'targetState': array([25., 25., 15.])}
episode index:3695
target thresh 37.80281942570289
model initialize at round 3695
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11724426, 14.84627329,  0.98146012,  0.11623289,
       -0.15240064]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6492039434941163
{'scaleFactor': 20, 'currentState': array([26.15620162, 21.42692148, 11.52941349,  0.46704763,  0.86801342,
       -0.16858   ]), 'targetState': array([25., 25., 15.])}
episode index:3696
target thresh 37.80903883278478
model initialize at round 3696
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6492855734931442
{'scaleFactor': 20, 'currentState': array([24.79510038, 20.05093321, 11.55643347,  0.5411092 ,  0.79188711,
       -0.28304706]), 'targetState': array([25., 25., 15.])}
episode index:3697
target thresh 37.815257617957066
model initialize at round 3697
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6493645877105341
{'scaleFactor': 20, 'currentState': array([26.9065662 , 21.02219762, 12.53602129,  0.63785179,  0.76934795,
        0.0353387 ]), 'targetState': array([25., 25., 15.])}
episode index:3698
target thresh 37.82147578128192
model initialize at round 3698
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13887305, 14.84627329,  0.97879927,  0.13730186,
       -0.15198746]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6494435592059896
{'scaleFactor': 20, 'currentState': array([27.45147294, 20.22619023, 12.93821516,  0.72883334,  0.67814305,
        0.09446676]), 'targetState': array([25., 25., 15.])}
episode index:3699
target thresh 37.82769332282153
model initialize at round 3699
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6495224880141504
{'scaleFactor': 20, 'currentState': array([ 2.64392812e+01,  2.14728743e+01,  1.22549325e+01,  5.33828572e-01,
        8.45522691e-01, -1.08827453e-02]), 'targetState': array([25., 25., 15.])}
episode index:3700
target thresh 37.83391024263808
model initialize at round 3700
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6496013741696183
{'scaleFactor': 20, 'currentState': array([26.00239308, 21.67942781, 11.5377313 ,  0.45026776,  0.88424447,
       -0.12397849]), 'targetState': array([25., 25., 15.])}
episode index:3701
target thresh 37.840126540793726
model initialize at round 3701
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6496827865617659
{'scaleFactor': 20, 'currentState': array([25.16217639, 20.18725963, 13.10019707,  0.59014636,  0.80255061,
        0.08740589]), 'targetState': array([25., 25., 15.])}
episode index:3702
target thresh 37.84634221735064
model initialize at round 3702
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6497641549828673
{'scaleFactor': 20, 'currentState': array([25.33417816, 20.04890123, 13.46665437,  0.68489498,  0.71722038,
        0.12850602]), 'targetState': array([25., 25., 15.])}
episode index:3703
target thresh 37.85255727237098
model initialize at round 3703
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.05370747, 14.84627329,  0.98674105,  0.05353067,
       -0.15322066]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6498403702077389
{'scaleFactor': 20, 'currentState': array([28.9016822 , 20.58804222, 11.51121539,  0.60555696,  0.79450206,
       -0.04546691]), 'targetState': array([25., 25., 15.])}
episode index:3704
target thresh 37.85877170591688
model initialize at round 3704
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6499190853978045
{'scaleFactor': 20, 'currentState': array([25.85627005, 21.60026597, 10.93736461,  0.44881789,  0.86669095,
       -0.21773676]), 'targetState': array([25., 25., 15.])}
episode index:3705
target thresh 37.86498551805051
model initialize at round 3705
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6500003241901688
{'scaleFactor': 20, 'currentState': array([24.79019913, 20.04912251, 11.54342227,  0.5436829 ,  0.7955694 ,
       -0.26735412]), 'targetState': array([25., 25., 15.])}
episode index:3706
target thresh 37.87119870883397
model initialize at round 3706
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6500789537626562
{'scaleFactor': 20, 'currentState': array([26.19355906, 21.20853327, 10.8472558 ,  0.4968782 ,  0.78898863,
       -0.36139868]), 'targetState': array([25., 25., 15.])}
episode index:3707
target thresh 37.87741127832944
model initialize at round 3707
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.650160105622456
{'scaleFactor': 20, 'currentState': array([25.26784584, 20.05351769, 13.26528888,  0.60377426,  0.78745247,
        0.12399698]), 'targetState': array([25., 25., 15.])}
episode index:3708
target thresh 37.88362322659903
model initialize at round 3708
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6502412137228274
{'scaleFactor': 20, 'currentState': array([25.22534668, 20.18554502, 13.70721279,  0.58460436,  0.78931747,
        0.18765842]), 'targetState': array([25., 25., 15.])}
episode index:3709
target thresh 37.88983455370484
model initialize at round 3709
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6503222780991555
{'scaleFactor': 20, 'currentState': array([24.78845953, 20.03107985, 11.51205493,  0.53300667,  0.7844546 ,
       -0.31707233]), 'targetState': array([25., 25., 15.])}
episode index:3710
target thresh 37.89604525970899
model initialize at round 3710
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 47
reward sum = 0.6235253948912
running average episode reward sum: 0.6503150571659279
{'scaleFactor': 20, 'currentState': array([21.5931353 , 20.66974598, 13.01087674,  0.32690339,  0.75714155,
        0.56557125]), 'targetState': array([25., 25., 15.])}
episode index:3711
target thresh 37.9022553446736
model initialize at round 3711
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11830435, 14.85093132,  0.98202042,  0.1173508 ,
       -0.14786715]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6503934960377584
{'scaleFactor': 20, 'currentState': array([26.83423064, 20.96189165, 14.06051451,  0.51880484,  0.79425146,
        0.31623749]), 'targetState': array([25., 25., 15.])}
episode index:3712
target thresh 37.908464808660746
model initialize at round 3712
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6504744539030594
{'scaleFactor': 20, 'currentState': array([25.3164032 , 20.04731127, 13.63780073,  0.63804981,  0.74428842,
        0.19729974]), 'targetState': array([25., 25., 15.])}
episode index:3713
target thresh 37.91467365173256
model initialize at round 3713
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13760574, 14.88319873,  0.9837835 ,  0.13674168,
       -0.11606784]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.65055536817231
{'scaleFactor': 20, 'currentState': array([ 2.52041335e+01,  2.00147131e+01,  1.28000187e+01,  6.02228050e-01,
        7.98156609e-01, -1.63524746e-02]), 'targetState': array([25., 25., 15.])}
episode index:3714
target thresh 37.920881873951096
model initialize at round 3714
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6506362388807159
{'scaleFactor': 20, 'currentState': array([25.19488772, 20.1686898 , 13.23857385,  0.5916365 ,  0.79767   ,
        0.11699927]), 'targetState': array([25., 25., 15.])}
episode index:3715
target thresh 37.92708947537846
model initialize at round 3715
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.88833605,  0.98207678,  0.15249639,
       -0.11077027]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6507170660634445
{'scaleFactor': 20, 'currentState': array([25.27651284, 20.17674185, 14.02183921,  0.58259879,  0.78316771,
        0.21731772]), 'targetState': array([25., 25., 15.])}
episode index:3716
target thresh 37.93329645607672
model initialize at round 3716
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.51537267e+01,  1.49877615e+01,  9.88084143e-01,
        1.53429215e-01, -1.22148092e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6507952912674632
{'scaleFactor': 20, 'currentState': array([26.77788927, 21.47845986, 15.91237269,  0.55910777,  0.75565037,
        0.34116129]), 'targetState': array([25., 25., 15.])}
episode index:3717
target thresh 37.939502816107925
model initialize at round 3717
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11963047, 14.91481596,  0.98917549,  0.11953083,
       -0.0851131 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6508734743922973
{'scaleFactor': 20, 'currentState': array([27.15178865, 20.63158149, 14.2414509 ,  0.58537042,  0.75279856,
        0.30105781]), 'targetState': array([25., 25., 15.])}
episode index:3718
target thresh 37.94570855553418
model initialize at round 3718
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08747473, 14.85904226,  0.98624907,  0.08714331,
       -0.14042368]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6509516154718908
{'scaleFactor': 20, 'currentState': array([27.02315349, 20.48237907, 12.73555371,  0.59470972,  0.78537313,
        0.17178301]), 'targetState': array([25., 25., 15.])}
episode index:3719
target thresh 37.95191367441751
model initialize at round 3719
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12401923, 14.85238864,  0.98156056,  0.12296201,
       -0.14635302]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6510297145401513
{'scaleFactor': 20, 'currentState': array([27.46400133, 20.31709719, 14.21069984,  0.71475172,  0.63071579,
        0.30220452]), 'targetState': array([25., 25., 15.])}
episode index:3720
target thresh 37.95811817281999
model initialize at round 3720
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11586322, 14.91506421,  0.98963471,  0.11582047,
       -0.08490445]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6511052414504892
{'scaleFactor': 20, 'currentState': array([29.14803805, 21.2289004 , 14.00508614,  0.6553892 ,  0.70877408,
        0.26096801]), 'targetState': array([25., 25., 15.])}
episode index:3721
target thresh 37.964322050803624
model initialize at round 3721
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11274455, 14.86364705,  0.98440311,  0.11210716,
       -0.13558208]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6511832572774505
{'scaleFactor': 20, 'currentState': array([27.20657757, 20.53541574, 13.40750993,  0.62201413,  0.75180151,
        0.21884449]), 'targetState': array([25., 25., 15.])}
episode index:3722
target thresh 37.97052530843049
model initialize at round 3722
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11975921, 14.87689713,  0.98528361,  0.11918868,
       -0.1225164 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6512612311942175
{'scaleFactor': 20, 'currentState': array([27.18366209, 20.60035981, 13.62506876,  0.59720532,  0.78944006,
        0.14188095]), 'targetState': array([25., 25., 15.])}
episode index:3723
target thresh 37.976727945762626
model initialize at round 3723
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10889742, 14.84627329,  0.98237176,  0.10805833,
       -0.1525422 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6513391632345523
{'scaleFactor': 20, 'currentState': array([26.03225324, 21.34058116, 11.19137926,  0.46881591,  0.87823346,
       -0.09443318]), 'targetState': array([25., 25., 15.])}
episode index:3724
target thresh 37.98292996286202
model initialize at round 3724
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6514196064256035
{'scaleFactor': 20, 'currentState': array([25.2176492 , 20.17134102, 13.5125916 ,  0.60412059,  0.77844859,
        0.17045853]), 'targetState': array([25., 25., 15.])}
episode index:3725
target thresh 37.98913135979072
model initialize at round 3725
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86411856,  0.97919272,  0.15204856,
       -0.13439809]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6515000064372714
{'scaleFactor': 20, 'currentState': array([25.34482342, 20.07999412, 13.89208509,  0.64609064,  0.73107867,
        0.21929627]), 'targetState': array([25., 25., 15.])}
episode index:3726
target thresh 37.99533213661073
model initialize at round 3726
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10772533, 14.91401678,  0.99044686,  0.10777395,
       -0.08602203]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6515778116808891
{'scaleFactor': 20, 'currentState': array([26.63420489, 21.32350188, 14.77302995,  0.46762121,  0.8086038 ,
        0.35705784]), 'targetState': array([25., 25., 15.])}
episode index:3727
target thresh 38.00153229338407
model initialize at round 3727
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.90075751,  0.98334513,  0.15269334,
       -0.09857538]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6516581261224715
{'scaleFactor': 20, 'currentState': array([25.27289608, 20.11396054, 13.52019191,  0.59836642,  0.78714742,
        0.14952114]), 'targetState': array([25., 25., 15.])}
episode index:3728
target thresh 38.00773183017273
model initialize at round 3728
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89265574,  0.98253424,  0.15256743,
       -0.10653476]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6517358472335679
{'scaleFactor': 20, 'currentState': array([26.63401225, 21.463009  , 13.89155993,  0.50159375,  0.83950907,
        0.20887373]), 'targetState': array([25., 25., 15.])}
episode index:3729
target thresh 38.01393074703869
model initialize at round 3729
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6518160762423257
{'scaleFactor': 20, 'currentState': array([25.19032707, 20.19027705, 13.33679037,  0.58843978,  0.79716392,
        0.13516033]), 'targetState': array([25., 25., 15.])}
episode index:3730
target thresh 38.02012904404398
model initialize at round 3730
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.90419016,  0.98367007,  0.1527438 ,
       -0.09519725]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6518962622443782
{'scaleFactor': 20, 'currentState': array([25.28144436, 20.17970827, 13.85224058,  0.58921106,  0.79037156,
        0.16775912]), 'targetState': array([25., 25., 15.])}
episode index:3731
target thresh 38.02632672125055
model initialize at round 3731
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6519764052742967
{'scaleFactor': 20, 'currentState': array([25.09438941, 20.14734996, 12.56768247,  0.59078306,  0.80411004,
       -0.0661998 ]), 'targetState': array([25., 25., 15.])}
episode index:3732
target thresh 38.03252377872038
model initialize at round 3732
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6520565053666154
{'scaleFactor': 20, 'currentState': array([2.51582972e+01, 2.01610559e+01, 1.28984470e+01, 5.93607463e-01,
       8.04751915e-01, 2.12950698e-03]), 'targetState': array([25., 25., 15.])}
episode index:3733
target thresh 38.038720216515465
model initialize at round 3733
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6521365625558317
{'scaleFactor': 20, 'currentState': array([25.20232446, 20.15449908, 13.23861817,  0.61915928,  0.77366013,
        0.13450574]), 'targetState': array([25., 25., 15.])}
episode index:3734
target thresh 38.04491603469773
model initialize at round 3734
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09310687, 14.89588889,  0.99019409,  0.09312513,
       -0.10413152]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.652214030718307
{'scaleFactor': 20, 'currentState': array([27.21806633, 20.48828022, 13.80029425,  0.60119589,  0.77508184,
        0.19445219]), 'targetState': array([25., 25., 15.])}
episode index:3735
target thresh 38.05111123332917
model initialize at round 3735
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12043115, 14.8850568 ,  0.98615381,  0.11996327,
       -0.11449664]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6522914574096031
{'scaleFactor': 20, 'currentState': array([26.9303719 , 20.98972102, 13.81263817,  0.55943608,  0.78197511,
        0.27485668]), 'targetState': array([25., 25., 15.])}
episode index:3736
target thresh 38.05730581247172
model initialize at round 3736
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.90998077,  0.98419299,  0.152825  ,
       -0.08949121]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6523713874584366
{'scaleFactor': 20, 'currentState': array([25.40581538, 20.10132769, 14.44746549,  0.62761736,  0.7438959 ,
        0.22959819]), 'targetState': array([25., 25., 15.])}
episode index:3737
target thresh 38.06349977218733
model initialize at round 3737
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.112629  , 14.85679226,  0.98348449,  0.11188775,
       -0.14226524]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6524487306264254
{'scaleFactor': 20, 'currentState': array([27.21536696, 20.52059371, 13.70745796,  0.61552881,  0.73791013,
        0.2767904 ]), 'targetState': array([25., 25., 15.])}
episode index:3738
target thresh 38.06969311253793
model initialize at round 3738
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11844632, 14.87098781,  0.98470974,  0.11781338,
       -0.12832279]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6525260324233696
{'scaleFactor': 20, 'currentState': array([27.263283  , 20.26107066, 12.47360243,  0.70734075,  0.70117144,
        0.08959735]), 'targetState': array([25., 25., 15.])}
episode index:3739
target thresh 38.07588583358545
model initialize at round 3739
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10966471, 14.88677722,  0.9875609 ,  0.10939453,
       -0.11294383]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6526032928824546
{'scaleFactor': 20, 'currentState': array([27.28490322, 20.08385223, 12.71022543,  0.63774496,  0.75563624,
        0.14931591]), 'targetState': array([25., 25., 15.])}
episode index:3740
target thresh 38.082077935391844
model initialize at round 3740
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85093654,  0.9773986 ,  0.15176997,
       -0.14716608]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.652683054111275
{'scaleFactor': 20, 'currentState': array([25.33258343, 20.06327045, 13.60857286,  0.64329194,  0.74561234,
        0.17388995]), 'targetState': array([25., 25., 15.])}
episode index:3741
target thresh 38.08826941801902
model initialize at round 3741
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11400467, 14.85320304,  0.98282871,  0.11317885,
       -0.14573361]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.652508633198899
{'scaleFactor': 20, 'currentState': array([25.22912459, 31.69203146, 13.24511243,  0.83999408, -0.53085381,
        0.11226831]), 'targetState': array([25., 25., 15.])}
episode index:3742
target thresh 38.09446028152889
model initialize at round 3742
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14550798, 14.8927323 ,  0.98373442,  0.14458708,
       -0.10658882]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6525858363824956
{'scaleFactor': 20, 'currentState': array([27.06714414, 21.00597317, 14.53084386,  0.66098964,  0.6970928 ,
        0.27776667]), 'targetState': array([25., 25., 15.])}
episode index:3743
target thresh 38.10065052598336
model initialize at round 3743
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.06689523, 14.84627329,  0.98596243,  0.06662241,
       -0.15309976]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6526604836879242
{'scaleFactor': 20, 'currentState': array([28.633131  , 21.20880093, 13.44566396,  0.50137663,  0.79935499,
        0.33113906]), 'targetState': array([25., 25., 15.])}
episode index:3744
target thresh 38.106840151444324
model initialize at round 3744
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14074275, 14.91663549,  0.98662257,  0.1402626 ,
       -0.08308011]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6527401444532679
{'scaleFactor': 20, 'currentState': array([25.40114449, 20.0478517 , 14.47751242,  0.59174767,  0.77056576,
        0.2367765 ]), 'targetState': array([25., 25., 15.])}
episode index:3745
target thresh 38.1130291579737
model initialize at round 3745
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.1448651 , 14.91279592,  0.98572606,  0.1442397 ,
       -0.08682761]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6528172240061103
{'scaleFactor': 20, 'currentState': array([27.28640058, 20.62638177, 13.68510191,  0.70434879,  0.66873268,
        0.23809533]), 'targetState': array([25., 25., 15.])}
episode index:3746
target thresh 38.119217545633354
model initialize at round 3746
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08454786, 14.88082939,  0.98928304,  0.08448663,
       -0.11908431]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6528942624169441
{'scaleFactor': 20, 'currentState': array([26.60556397, 20.69777425, 11.51326314,  0.53321879,  0.82876924,
       -0.1697624 ]), 'targetState': array([25., 25., 15.])}
episode index:3747
target thresh 38.12540531448519
model initialize at round 3747
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6529737970454083
{'scaleFactor': 20, 'currentState': array([25.08326401, 20.16637458, 12.61190549,  0.58633042,  0.80846691,
       -0.05096953]), 'targetState': array([25., 25., 15.])}
episode index:3748
target thresh 38.13159246459108
model initialize at round 3748
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.1498579 , 14.84627329,  0.9772855 ,  0.14793328,
       -0.15175241]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6530532892440891
{'scaleFactor': 20, 'currentState': array([25.20104445, 20.15245649, 13.15867036,  0.5953387 ,  0.80145896,
        0.05688023]), 'targetState': array([25., 25., 15.])}
episode index:3749
target thresh 38.1377789960129
model initialize at round 3749
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6531327390469307
{'scaleFactor': 20, 'currentState': array([25.14804752, 20.17935125, 12.97804882,  0.59594207,  0.80197289,
        0.04114042]), 'targetState': array([25., 25., 15.])}
episode index:3750
target thresh 38.1439649088125
model initialize at round 3750
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14542618, 14.84627329,  0.97790922,  0.1436501 ,
       -0.15184926]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6532096111904535
{'scaleFactor': 20, 'currentState': array([27.31619737, 20.47212358, 13.6703973 ,  0.66869905,  0.70053066,
        0.24919547]), 'targetState': array([25., 25., 15.])}
episode index:3751
target thresh 38.150150203051744
model initialize at round 3751
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12538971, 14.91322357,  0.98834456,  0.12518004,
       -0.08663133]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6532864423573539
{'scaleFactor': 20, 'currentState': array([26.53299514, 21.51657012, 14.39756034,  0.46456043,  0.82829339,
        0.313231  ]), 'targetState': array([25., 25., 15.])}
episode index:3752
target thresh 38.15633487879251
model initialize at round 3752
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.92439045,  0.98535578,  0.15300556,
       -0.07525486]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6533657665266965
{'scaleFactor': 20, 'currentState': array([25.2963524 , 20.1734778 , 14.11561631,  0.58410334,  0.78322202,
        0.2130412 ]), 'targetState': array([25., 25., 15.])}
episode index:3753
target thresh 38.16251893609661
model initialize at round 3753
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.93055228,  0.98579231,  0.15307334,
       -0.06915256]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.653445048434894
{'scaleFactor': 20, 'currentState': array([25.39447467, 20.07759386, 14.00274178,  0.62746784,  0.75987133,
        0.1699402 ]), 'targetState': array([25., 25., 15.])}
episode index:3754
target thresh 38.1687023750259
model initialize at round 3754
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13375797, 14.95851432,  0.99014246,  0.13377722,
       -0.04149165]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6535217555190395
{'scaleFactor': 20, 'currentState': array([26.56451615, 21.59669409, 14.98720114,  0.47943563,  0.81613308,
        0.32259613]), 'targetState': array([25., 25., 15.])}
episode index:3755
target thresh 38.17488519564222
model initialize at round 3755
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86272903,  0.97901098,  0.15202034,
       -0.13574726]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6536009536804828
{'scaleFactor': 20, 'currentState': array([25.22529479, 20.02635018, 12.79569129,  0.60854803,  0.79233199,
       -0.0433511 ]), 'targetState': array([25., 25., 15.])}
episode index:3756
target thresh 38.181067398007386
model initialize at round 3756
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6536775784331366
{'scaleFactor': 20, 'currentState': array([26.81745434, 20.73894526, 11.52636915,  0.62082709,  0.76597563,
       -0.16689835]), 'targetState': array([25., 25., 15.])}
episode index:3757
target thresh 38.18724898218322
model initialize at round 3757
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.653754162406252
{'scaleFactor': 20, 'currentState': array([26.71922706, 21.22753055, 12.21098812,  0.62297212,  0.77643398,
       -0.0951631 ]), 'targetState': array([25., 25., 15.])}
episode index:3758
target thresh 38.19342994823155
model initialize at round 3758
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10966612, 14.84627329,  0.98229051,  0.10881211,
       -0.15252958]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.6535802453638454
{'scaleFactor': 20, 'currentState': array([-2.21882343,  4.96488348, 10.15280872,  0.30371677, -0.94737464,
       -0.10118012]), 'targetState': array([25., 25., 15.])}
episode index:3759
target thresh 38.19961029621418
model initialize at round 3759
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12944409, 14.93730204,  0.98961076,  0.1293932 ,
       -0.0626733 ]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.653654310550692
{'scaleFactor': 20, 'currentState': array([29.11050273, 21.31377653, 14.70049872,  0.62206518,  0.71241641,
        0.3248042 ]), 'targetState': array([25., 25., 15.])}
episode index:3760
target thresh 38.20579002619291
model initialize at round 3760
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.94836388,  0.98684801,  0.15323727,
       -0.05147172]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6537308396224416
{'scaleFactor': 20, 'currentState': array([26.77877496, 21.38661081, 14.51314277,  0.56917665,  0.77345328,
        0.27894077]), 'targetState': array([25., 25., 15.])}
episode index:3761
target thresh 38.21196913822953
model initialize at round 3761
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.90956767,  0.98415674,  0.15281937,
       -0.08989857]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6538073280088793
{'scaleFactor': 20, 'currentState': array([27.42989965, 20.51612448, 14.3626356 ,  0.7360405 ,  0.61559281,
        0.28158459]), 'targetState': array([25., 25., 15.])}
episode index:3762
target thresh 38.21814763238586
model initialize at round 3762
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.03864458, 14.84627329,  0.98742357,  0.03854401,
       -0.15332664]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.6536335817085845
{'scaleFactor': 20, 'currentState': array([14.73130615, 32.65866579, 12.46125341,  0.72463165, -0.67835391,
        0.1214288 ]), 'targetState': array([25., 25., 15.])}
episode index:3763
target thresh 38.22432550872365
model initialize at round 3763
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08174694, 14.84627329,  0.98488476,  0.08132456,
       -0.15293242]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6537075540162888
{'scaleFactor': 20, 'currentState': array([28.60257943, 21.34315337, 13.16631339,  0.51638518,  0.79480868,
        0.31878755]), 'targetState': array([25., 25., 15.])}
episode index:3764
target thresh 38.230502767304706
model initialize at round 3764
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.9439219 ,  0.98661351,  0.15320086,
       -0.05588627]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6537865135105474
{'scaleFactor': 20, 'currentState': array([25.36170073, 20.149069  , 14.12321834,  0.604068  ,  0.78470736,
        0.13905468]), 'targetState': array([25., 25., 15.])}
episode index:3765
target thresh 38.23667940819079
model initialize at round 3765
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6538654310719891
{'scaleFactor': 20, 'currentState': array([25.23885253, 20.17951996, 13.90084742,  0.57928834,  0.78182315,
        0.23060265]), 'targetState': array([25., 25., 15.])}
episode index:3766
target thresh 38.24285543144366
model initialize at round 3766
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.92591984,  0.98546753,  0.15302291,
       -0.07374101]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6539443067340088
{'scaleFactor': 20, 'currentState': array([25.28738106, 20.1786968 , 13.78015334,  0.59416711,  0.79648778,
        0.11212791]), 'targetState': array([25., 25., 15.])}
episode index:3767
target thresh 38.249030837125076
model initialize at round 3767
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6540231405299659
{'scaleFactor': 20, 'currentState': array([2.51647859e+01, 2.01540760e+01, 1.28684284e+01, 5.96112656e-01,
       8.02856599e-01, 8.42510949e-03]), 'targetState': array([25., 25., 15.])}
episode index:3768
target thresh 38.25520562529681
model initialize at round 3768
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6541019324931843
{'scaleFactor': 20, 'currentState': array([24.97572489, 20.08299325, 12.01554846,  0.55586347,  0.77714159,
       -0.29507075]), 'targetState': array([25., 25., 15.])}
episode index:3769
target thresh 38.2613797960206
model initialize at round 3769
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12912086, 14.84627329,  0.98005195,  0.12782338,
       -0.15218198]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6541781601369264
{'scaleFactor': 20, 'currentState': array([26.40580805, 21.55986464, 13.27421685,  0.50791585,  0.82848191,
        0.23587964]), 'targetState': array([25., 25., 15.])}
episode index:3770
target thresh 38.26755334935819
model initialize at round 3770
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14951184, 14.88970417,  0.982842  ,  0.14843082,
       -0.10949836]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6542568692034242
{'scaleFactor': 20, 'currentState': array([25.36891931, 20.06558681, 14.10129405,  0.59684164,  0.77288202,
        0.21548422]), 'targetState': array([25., 25., 15.])}
episode index:3771
target thresh 38.2737262853713
model initialize at round 3771
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.90264336,  0.98352503,  0.15272128,
       -0.09671989]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6543330153540597
{'scaleFactor': 20, 'currentState': array([27.20410848, 20.86584938, 13.69812694,  0.71264156,  0.67620458,
        0.18678696]), 'targetState': array([25., 25., 15.])}
episode index:3772
target thresh 38.279898604121676
model initialize at round 3772
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.05252616, 14.84627329,  0.98680256,  0.05235652,
       -0.15323021]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.6541595902240959
{'scaleFactor': 20, 'currentState': array([ 4.65816467, 40.93671254, 11.20692966,  0.73397208, -0.40226146,
        0.54723916]), 'targetState': array([25., 25., 15.])}
episode index:3773
target thresh 38.28607030567106
model initialize at round 3773
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.88318039,  0.98150806,  0.15240808,
       -0.11581756]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6542357217978045
{'scaleFactor': 20, 'currentState': array([26.91376609, 21.16402349, 13.95075359,  0.58165879,  0.77300116,
        0.25326323]), 'targetState': array([25., 25., 15.])}
episode index:3774
target thresh 38.29224139008113
model initialize at round 3774
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10887638, 14.84627329,  0.98237398,  0.1080377 ,
       -0.15254254]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6543118130369047
{'scaleFactor': 20, 'currentState': array([27.1160387 , 20.57887681, 12.96343143,  0.65630816,  0.74769771,
        0.10103333]), 'targetState': array([25., 25., 15.])}
episode index:3775
target thresh 38.298411857413605
model initialize at round 3775
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.05108007, 14.8821693 ,  0.99169066,  0.0511673 ,
       -0.11803192]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6543853706467749
{'scaleFactor': 20, 'currentState': array([29.23677783, 20.66613361, 13.30868816,  0.68384635,  0.70995334,
        0.16828674]), 'targetState': array([25., 25., 15.])}
episode index:3776
target thresh 38.304581707730215
model initialize at round 3776
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09923663, 14.84627329,  0.98334569,  0.09856961,
       -0.15269343]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6544613819728947
{'scaleFactor': 20, 'currentState': array([26.56062762, 21.13202548, 12.12574377,  0.53522547,  0.84279235,
       -0.05687492]), 'targetState': array([25., 25., 15.])}
episode index:3777
target thresh 38.31075094109262
model initialize at round 3777
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13326878, 14.84627329,  0.9795297 ,  0.13185933,
       -0.15210089]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6545348610533431
{'scaleFactor': 20, 'currentState': array([29.51664744, 20.41223149, 12.9410053 ,  0.80788268,  0.5655046 ,
        0.16592201]), 'targetState': array([25., 25., 15.])}
episode index:3778
target thresh 38.31691955756256
model initialize at round 3778
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.05941974, 14.84627329,  0.98642447,  0.05920514,
       -0.1531715 ]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.6543616578617439
{'scaleFactor': 20, 'currentState': array([33.81457828, 22.17264918, 12.03826776,  0.58522082,  0.77943972,
        0.22358512]), 'targetState': array([25., 25., 15.])}
episode index:3779
target thresh 38.323087557201674
model initialize at round 3779
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6544401309813308
{'scaleFactor': 20, 'currentState': array([25.18130121, 20.18937871, 13.30427698,  0.58860582,  0.79833601,
        0.12729021]), 'targetState': array([25., 25., 15.])}
episode index:3780
target thresh 38.329254940071664
model initialize at round 3780
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6545185625917299
{'scaleFactor': 20, 'currentState': array([25.2232812 , 20.18595724, 13.65913362,  0.58394467,  0.78878551,
        0.19190113]), 'targetState': array([25., 25., 15.])}
episode index:3781
target thresh 38.33542170623422
model initialize at round 3781
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.92128095,  0.98512164,  0.1529692 ,
       -0.07833115]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6545969527258675
{'scaleFactor': 20, 'currentState': array([25.29004209, 20.17562255, 13.98656154,  0.58673246,  0.78662037,
        0.19228472]), 'targetState': array([25., 25., 15.])}
episode index:3782
target thresh 38.34158785575098
model initialize at round 3782
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87175859,  0.98016066,  0.15219886,
       -0.12696685]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6546753014166352
{'scaleFactor': 20, 'currentState': array([25.30101925, 20.16855862, 14.33876523,  0.5774083 ,  0.77586708,
        0.25422419]), 'targetState': array([25., 25., 15.])}
episode index:3783
target thresh 38.34775338868363
model initialize at round 3783
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89104179,  0.98236535,  0.1525412 ,
       -0.10811795]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6547536086968898
{'scaleFactor': 20, 'currentState': array([25.28280488, 20.17752886, 13.98541246,  0.58481492,  0.78522004,
        0.20352147]), 'targetState': array([25., 25., 15.])}
episode index:3784
target thresh 38.35391830509379
model initialize at round 3784
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.8568517 ,  0.97822298,  0.15189798,
       -0.14144541]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6548318745994535
{'scaleFactor': 20, 'currentState': array([25.33479379, 20.09966021, 13.94217109,  0.61651485,  0.7563648 ,
        0.21868181]), 'targetState': array([25., 25., 15.])}
episode index:3785
target thresh 38.360082605043154
model initialize at round 3785
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.93957507,  0.98636549,  0.15316234,
       -0.0602031 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6549075872974992
{'scaleFactor': 20, 'currentState': array([27.38253054, 20.67953328, 15.23261251,  0.63071852,  0.72105066,
        0.28684508]), 'targetState': array([25., 25., 15.])}
episode index:3786
target thresh 38.36624628859333
model initialize at round 3786
at step 0:
{'scaleFactor': 20, 'currentState': array([1.70000000e+01, 1.51525889e+01, 1.50114301e+01, 9.88265131e-01,
       1.52321509e-01, 1.14100546e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6549832600099638
{'scaleFactor': 20, 'currentState': array([27.27408306, 20.85086225, 15.63959304,  0.61889797,  0.7523194 ,
        0.22578933]), 'targetState': array([25., 25., 15.])}
episode index:3787
target thresh 38.37240935580597
model initialize at round 3787
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.96864174,  0.98767418,  0.15336556,
       -0.03128459]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6550614033019094
{'scaleFactor': 20, 'currentState': array([25.37403405, 20.16426386, 14.87646364,  0.58210853,  0.77605016,
        0.24268459]), 'targetState': array([25., 25., 15.])}
episode index:3788
target thresh 38.37857180674271
model initialize at round 3788
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.92505317,  0.98540448,  0.15301312,
       -0.07459893]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6551395053464062
{'scaleFactor': 20, 'currentState': array([25.32626309, 20.17390612, 14.25688945,  0.58628671,  0.78377506,
        0.20485251]), 'targetState': array([25., 25., 15.])}
episode index:3789
target thresh 38.38473364146516
model initialize at round 3789
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85843157,  0.97843786,  0.15193134,
       -0.13991506]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6552175661761038
{'scaleFactor': 20, 'currentState': array([25.28006592, 20.17613052, 14.10033735,  0.58297823,  0.78377824,
        0.21407486]), 'targetState': array([25., 25., 15.])}
episode index:3790
target thresh 38.39089486003496
model initialize at round 3790
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.88849853,  0.9820943 ,  0.15249911,
       -0.11061107]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6552955858236174
{'scaleFactor': 20, 'currentState': array([2.52413939e+01, 2.01779289e+01, 1.33582671e+01, 5.95269395e-01,
       8.03336355e-01, 1.74656577e-02]), 'targetState': array([25., 25., 15.])}
episode index:3791
target thresh 38.3970554625137
model initialize at round 3791
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6553735643215278
{'scaleFactor': 20, 'currentState': array([25.22139053, 20.18735463, 13.61202836,  0.58564666,  0.79088645,
        0.17752921]), 'targetState': array([25., 25., 15.])}
episode index:3792
target thresh 38.40321544896299
model initialize at round 3792
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6554515017023818
{'scaleFactor': 20, 'currentState': array([25.21604797, 20.18144975, 13.46597556,  0.59681456,  0.78773626,
        0.15259085]), 'targetState': array([25., 25., 15.])}
episode index:3793
target thresh 38.409374819444444
model initialize at round 3793
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86527597,  0.97934277,  0.15207186,
       -0.13327375]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6555293979986911
{'scaleFactor': 20, 'currentState': array([25.22859566, 20.18487843, 13.50826608,  0.58905955,  0.7949742 ,
        0.14499956]), 'targetState': array([25., 25., 15.])}
episode index:3794
target thresh 38.41553357401962
model initialize at round 3794
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.94651675,  0.98675283,  0.15322249,
       -0.05330783]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6556072532429339
{'scaleFactor': 20, 'currentState': array([25.3624441 , 20.17819105, 14.28587489,  0.597282  ,  0.79467819,
        0.10835489]), 'targetState': array([25., 25., 15.])}
episode index:3795
target thresh 38.42169171275016
model initialize at round 3795
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6556850674675538
{'scaleFactor': 20, 'currentState': array([25.23561725, 20.18002331, 13.87946002,  0.57940135,  0.78219792,
        0.22904254]), 'targetState': array([25., 25., 15.])}
episode index:3796
target thresh 38.4278492356976
model initialize at round 3796
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.91332708,  0.98448067,  0.15286967,
       -0.08618971]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6557628407049604
{'scaleFactor': 20, 'currentState': array([25.44060468, 20.03763847, 14.2965648 ,  0.63527926,  0.74558818,
        0.20129214]), 'targetState': array([25., 25., 15.])}
episode index:3797
target thresh 38.43400614292355
model initialize at round 3797
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12849205, 14.86717522,  0.98301948,  0.12758605,
       -0.13188823]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.65583806906428
{'scaleFactor': 20, 'currentState': array([27.29440928, 20.47854521, 13.67101483,  0.63036753,  0.74293186,
        0.22514226]), 'targetState': array([25., 25., 15.])}
episode index:3798
target thresh 38.440162434489544
model initialize at round 3798
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14036954, 14.86340747,  0.98098635,  0.13909152,
       -0.13534889]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6559132578193041
{'scaleFactor': 20, 'currentState': array([26.42843275, 21.62683419, 13.75831213,  0.48207816,  0.8441634 ,
        0.23449689]), 'targetState': array([25., 25., 15.])}
episode index:3799
target thresh 38.44631811045717
model initialize at round 3799
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6559884070012992
{'scaleFactor': 20, 'currentState': array([26.44692489, 21.58272182, 12.80637903,  0.51087567,  0.8513962 ,
        0.11887208]), 'targetState': array([25., 25., 15.])}
episode index:3800
target thresh 38.45247317088797
model initialize at round 3800
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6560660185884865
{'scaleFactor': 20, 'currentState': array([25.25110551, 20.09987294, 13.26514889,  0.60636234,  0.78339495,
        0.13644436]), 'targetState': array([25., 25., 15.])}
episode index:3801
target thresh 38.45862761584351
model initialize at round 3801
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.656141088060031
{'scaleFactor': 20, 'currentState': array([27.21478533, 20.65768026, 13.64417029,  0.63722536,  0.73014523,
        0.24664101]), 'targetState': array([25., 25., 15.])}
episode index:3802
target thresh 38.46478144538531
model initialize at round 3802
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87615277,  0.98069323,  0.15228156,
       -0.12268297]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6562161180524951
{'scaleFactor': 20, 'currentState': array([26.73662662, 21.15672022, 13.90829749,  0.505437  ,  0.80979049,
        0.29794765]), 'targetState': array([25., 25., 15.])}
episode index:3803
target thresh 38.47093465957495
model initialize at round 3803
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86624517,  0.97946748,  0.15209122,
       -0.13233182]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6562911085970136
{'scaleFactor': 20, 'currentState': array([26.64082463, 21.42734957, 14.89300417,  0.49529907,  0.77379191,
        0.39487328]), 'targetState': array([25., 25., 15.])}
episode index:3804
target thresh 38.47708725847391
model initialize at round 3804
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89809704,  0.98308564,  0.15265305,
       -0.10119125]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6563635854010372
{'scaleFactor': 20, 'currentState': array([29.23761124, 21.10227054, 13.595626  ,  0.66210561,  0.71905166,
        0.21114181]), 'targetState': array([25., 25., 15.])}
episode index:3805
target thresh 38.48323924214375
model initialize at round 3805
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09487421, 14.84627329,  0.98375672,  0.0942759 ,
       -0.15275725]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6564360241195097
{'scaleFactor': 20, 'currentState': array([29.35263272, 20.38025198, 13.46757865,  0.64717334,  0.7228895 ,
        0.2420691 ]), 'targetState': array([25., 25., 15.])}
episode index:3806
target thresh 38.48939061064598
model initialize at round 3806
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6565133958100221
{'scaleFactor': 20, 'currentState': array([25.19094418, 20.18949117, 13.28726746,  0.59096613,  0.80071024,
        0.09809253]), 'targetState': array([25., 25., 15.])}
episode index:3807
target thresh 38.49554136404213
model initialize at round 3807
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6565907268641424
{'scaleFactor': 20, 'currentState': array([25.16043604, 20.18710006, 13.06613339,  0.59042733,  0.80309261,
        0.0802361 ]), 'targetState': array([25., 25., 15.])}
episode index:3808
target thresh 38.501691502393676
model initialize at round 3808
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86007402,  0.97865887,  0.15196566,
       -0.13832303]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6566680173138761
{'scaleFactor': 20, 'currentState': array([25.19018892, 20.18498319, 13.20037092,  0.59238891,  0.80324002,
        0.06229649]), 'targetState': array([25., 25., 15.])}
episode index:3809
target thresh 38.50784102576215
model initialize at round 3809
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6567452671911954
{'scaleFactor': 20, 'currentState': array([25.30967   , 20.10115594, 13.66373382,  0.62755575,  0.75559237,
        0.18776032]), 'targetState': array([25., 25., 15.])}
episode index:3810
target thresh 38.51398993420902
model initialize at round 3810
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09279234, 14.84627329,  0.98394653,  0.09222495,
       -0.15278673]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.656819981146118
{'scaleFactor': 20, 'currentState': array([27.02843052, 20.65294156, 13.5653025 ,  0.57073884,  0.79085392,
        0.22092363]), 'targetState': array([25., 25., 15.])}
episode index:3811
target thresh 38.5201382277958
model initialize at round 3811
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13989284, 14.88840616,  0.98405304,  0.1390525 ,
       -0.11092349]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.656897150629002
{'scaleFactor': 20, 'currentState': array([25.39151627, 20.03614143, 14.22338905,  0.60460573,  0.76562024,
        0.21972153]), 'targetState': array([25., 25., 15.])}
episode index:3812
target thresh 38.52628590658396
model initialize at round 3812
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13797202, 14.89916204,  0.98542613,  0.13733458,
       -0.10037208]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6569717855618034
{'scaleFactor': 20, 'currentState': array([27.58726   , 20.18814545, 14.03168191,  0.72198455,  0.65268883,
        0.22964233]), 'targetState': array([25., 25., 15.])}
episode index:3813
target thresh 38.532432970634964
model initialize at round 3813
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08565553, 14.9345751 ,  0.99412559,  0.08601248,
       -0.06569755]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6570439128723292
{'scaleFactor': 20, 'currentState': array([29.64056559, 20.52954003, 14.067492  ,  0.83109919,  0.52946862,
        0.17010914]), 'targetState': array([25., 25., 15.])}
episode index:3814
target thresh 38.538579420010336
model initialize at round 3814
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.49913963e+01,  1.49040701e+01,  9.95300875e-01,
       -8.64972280e-03, -9.64435055e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.6568716864207244
{'scaleFactor': 20, 'currentState': array([ 2.98060803e+01,  1.55576899e+01,  1.22105397e+01,  9.88216530e-01,
        1.81262799e-02, -1.51985290e-01]), 'targetState': array([25., 25., 15.])}
episode index:3815
target thresh 38.544725254771464
model initialize at round 3815
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.656948761463565
{'scaleFactor': 20, 'currentState': array([25.18107416, 20.18931944, 13.23517569,  0.5893765 ,  0.79942132,
        0.11645126]), 'targetState': array([25., 25., 15.])}
episode index:3816
target thresh 38.550870474979845
model initialize at round 3816
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11693051, 14.85900188,  0.98331009,  0.11614036,
       -0.14004533]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6570233046618718
{'scaleFactor': 20, 'currentState': array([2.67736327e+01, 2.10826405e+01, 1.29944805e+01, 5.36602356e-01,
       8.43537799e-01, 2.24029904e-02]), 'targetState': array([25., 25., 15.])}
episode index:3817
target thresh 38.55701508069696
model initialize at round 3817
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6571002996187179
{'scaleFactor': 20, 'currentState': array([25.03418176, 20.14154336, 12.34781065,  0.58511325,  0.80448759,
       -0.10218713]), 'targetState': array([25., 25., 15.])}
episode index:3818
target thresh 38.5631590719842
model initialize at round 3818
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11016051, 14.84627329,  0.98223797,  0.10929681,
       -0.15252142]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6571747640988912
{'scaleFactor': 20, 'currentState': array([27.12476624, 20.2364007 , 11.94979696,  0.62149786,  0.78022353,
       -0.07065162]), 'targetState': array([25., 25., 15.])}
episode index:3819
target thresh 38.56930244890303
model initialize at round 3819
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6572516790951742
{'scaleFactor': 20, 'currentState': array([25.2132348 , 20.18909656, 13.53270012,  0.58912106,  0.79601971,
        0.13888483]), 'targetState': array([25., 25., 15.])}
episode index:3820
target thresh 38.57544521151489
model initialize at round 3820
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6573285538323648
{'scaleFactor': 20, 'currentState': array([25.21242568, 20.18897235, 13.48607796,  0.58724973,  0.79363312,
        0.15901017]), 'targetState': array([25., 25., 15.])}
episode index:3821
target thresh 38.5815873598812
model initialize at round 3821
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86093989,  0.9787744 ,  0.1519836 ,
       -0.13748331]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6574029001420373
{'scaleFactor': 20, 'currentState': array([26.82553957, 21.2713625 , 14.31761762,  0.53106457,  0.80740013,
        0.25705144]), 'targetState': array([25., 25., 15.])}
episode index:3822
target thresh 38.58772889406339
model initialize at round 3822
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15021545, 14.84627329,  0.97723442,  0.14827849,
       -0.15174447]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6574772075574856
{'scaleFactor': 20, 'currentState': array([26.36494769, 21.53617021, 12.44641245,  0.49280381,  0.86729348,
        0.07033087]), 'targetState': array([25., 25., 15.])}
episode index:3823
target thresh 38.59386981412285
model initialize at round 3823
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.657553963007889
{'scaleFactor': 20, 'currentState': array([25.33785778, 20.01720593, 13.02395168,  0.67836382,  0.73291635,
       -0.05153785]), 'targetState': array([25., 25., 15.])}
episode index:3824
target thresh 38.600010120121034
model initialize at round 3824
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13645755, 14.84627329,  0.97911758,  0.13495756,
       -0.15203689]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.657628192076227
{'scaleFactor': 20, 'currentState': array([26.96219125, 20.49963264, 11.7813922 ,  0.63352098,  0.77226538,
       -0.04751165]), 'targetState': array([25., 25., 15.])}
episode index:3825
target thresh 38.606149812119305
model initialize at round 3825
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13627912, 14.84627329,  0.97914089,  0.1347843 ,
       -0.15204051]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6577048679407916
{'scaleFactor': 20, 'currentState': array([25.28568645, 20.03083915, 13.33759078,  0.60349495,  0.78779309,
        0.12319045]), 'targetState': array([25., 25., 15.])}
episode index:3826
target thresh 38.61228889017907
model initialize at round 3826
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85254395,  0.97762571,  0.15180524,
       -0.14561296]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.657781503734353
{'scaleFactor': 20, 'currentState': array([25.28005184, 20.18347824, 13.87041889,  0.58971288,  0.79175775,
        0.15924314]), 'targetState': array([25., 25., 15.])}
episode index:3827
target thresh 38.61842735436173
model initialize at round 3827
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6578580994883148
{'scaleFactor': 20, 'currentState': array([25.19987959, 20.18939612, 13.33692896,  0.58934449,  0.79753224,
        0.12890076]), 'targetState': array([25., 25., 15.])}
episode index:3828
target thresh 38.624565204728654
model initialize at round 3828
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6579346552340478
{'scaleFactor': 20, 'currentState': array([25.20665648, 20.18842078, 13.51476899,  0.58558678,  0.7920555 ,
        0.17244188]), 'targetState': array([25., 25., 15.])}
episode index:3829
target thresh 38.63070244134125
model initialize at round 3829
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87055976,  0.9800123 ,  0.15217582,
       -0.12813437]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6580111710028902
{'scaleFactor': 20, 'currentState': array([25.21418412, 20.18611455, 13.43857155,  0.58896825,  0.79594824,
        0.13993856]), 'targetState': array([25., 25., 15.])}
episode index:3830
target thresh 38.636839064260855
model initialize at round 3830
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6580876468261471
{'scaleFactor': 20, 'currentState': array([25.15959511, 20.15749968, 12.78355477,  0.59061891,  0.79722228,
       -0.12492374]), 'targetState': array([25., 25., 15.])}
episode index:3831
target thresh 38.64297507354885
model initialize at round 3831
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11186659, 14.84627329,  0.98205489,  0.11096882,
       -0.152493  ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6581616010282804
{'scaleFactor': 20, 'currentState': array([26.37252702, 21.19632612, 11.52147883,  0.54233084,  0.83202765,
       -0.11665014]), 'targetState': array([25., 25., 15.])}
episode index:3832
target thresh 38.64911046926659
model initialize at round 3832
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09066327, 14.84627329,  0.9841364 ,  0.09012628,
       -0.15281621]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.658235516642257
{'scaleFactor': 20, 'currentState': array([26.65700025, 20.96098505, 12.23570004,  0.53636461,  0.84325514,
        0.03512521]), 'targetState': array([25., 25., 15.])}
episode index:3833
target thresh 38.65524525147544
model initialize at round 3833
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85688374,  0.97822736,  0.15189866,
       -0.14141438]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6583118741105037
{'scaleFactor': 20, 'currentState': array([25.29078783, 20.1813207 , 13.9838347 ,  0.58965802,  0.79096647,
        0.16332626]), 'targetState': array([25., 25., 15.])}
episode index:3834
target thresh 38.66137942023674
model initialize at round 3834
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6583881917573849
{'scaleFactor': 20, 'currentState': array([25.24416769, 20.17986105, 13.90570714,  0.58004537,  0.78224331,
        0.22725046]), 'targetState': array([25., 25., 15.])}
episode index:3835
target thresh 38.66751297561184
model initialize at round 3835
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.91901554,  0.98494524,  0.15294181,
       -0.08057097]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6584644696140437
{'scaleFactor': 20, 'currentState': array([25.29922069, 20.17723675, 13.9482859 ,  0.58958165,  0.78954914,
        0.17031043]), 'targetState': array([25., 25., 15.])}
episode index:3836
target thresh 38.67364591766207
model initialize at round 3836
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6585407077115902
{'scaleFactor': 20, 'currentState': array([25.21525918, 20.12707915, 13.1550333 ,  0.60325537,  0.78909411,
        0.11581644]), 'targetState': array([25., 25., 15.])}
episode index:3837
target thresh 38.67977824644875
model initialize at round 3837
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12284579, 14.84627329,  0.98081213,  0.12170569,
       -0.15230002]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6586144282539793
{'scaleFactor': 20, 'currentState': array([26.45937654, 21.50753222, 14.30940409,  0.45489416,  0.82059251,
        0.34597577]), 'targetState': array([25., 25., 15.])}
episode index:3838
target thresh 38.685909962033215
model initialize at round 3838
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84879511,  0.97709246,  0.15172243,
       -0.14923349]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6586905875719387
{'scaleFactor': 20, 'currentState': array([25.0959904 , 20.15251588, 12.55970425,  0.58451201,  0.80643166,
       -0.08951921]), 'targetState': array([25., 25., 15.])}
episode index:3839
target thresh 38.69204106447679
model initialize at round 3839
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15364189, 14.84627329,  0.9767391 ,  0.15158388,
       -0.15166756]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6587642306869983
{'scaleFactor': 20, 'currentState': array([27.32888652, 20.55655983, 13.90283624,  0.68894276,  0.67234593,
        0.27075601]), 'targetState': array([25., 25., 15.])}
episode index:3840
target thresh 38.69817155384075
model initialize at round 3840
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.07798701, 14.84627329,  0.9851776 ,  0.07760713,
       -0.15297789]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6588378354562547
{'scaleFactor': 20, 'currentState': array([27.24108174, 20.25612014, 13.37561128,  0.60634451,  0.77236411,
        0.18920893]), 'targetState': array([25., 25., 15.])}
episode index:3841
target thresh 38.70430143018645
model initialize at round 3841
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85547494,  0.9780339 ,  0.15186862,
       -0.14277819]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.658913877157047
{'scaleFactor': 20, 'currentState': array([25.19830667, 20.16203649, 13.13045316,  0.60163365,  0.79610339,
        0.06524074]), 'targetState': array([25., 25., 15.])}
episode index:3842
target thresh 38.71043069357515
model initialize at round 3842
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13008727, 14.86154123,  0.98208026,  0.1290466 ,
       -0.13735114]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6589874046803995
{'scaleFactor': 20, 'currentState': array([26.69151973, 21.34577309, 14.15999545,  0.5418821 ,  0.77992503,
        0.31317843]), 'targetState': array([25., 25., 15.])}
episode index:3843
target thresh 38.71655934406816
model initialize at round 3843
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09618602, 14.90824201,  0.99110506,  0.09629339,
       -0.09186042]), 'targetState': array([25., 25., 15.])}
done in step count: 44
reward sum = 0.6426116020847181
running average episode reward sum: 0.6589831445860719
{'scaleFactor': 20, 'currentState': array([20.56074726, 25.77939817, 16.19343874,  0.89726384, -0.37405205,
       -0.23452647]), 'targetState': array([25., 25., 15.])}
episode index:3844
target thresh 38.72268738172677
model initialize at round 3844
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.91786775,  0.98485399,  0.15292764,
       -0.08170533]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6590590891648271
{'scaleFactor': 20, 'currentState': array([25.35894931, 20.09898995, 13.86459818,  0.63393818,  0.75456358,
        0.16957651]), 'targetState': array([25., 25., 15.])}
episode index:3845
target thresh 38.72881480661224
model initialize at round 3845
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14504298, 14.91628887,  0.98599268,  0.14445587,
       -0.08337228]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.659132521577785
{'scaleFactor': 20, 'currentState': array([26.92824735, 21.24246231, 14.87409548,  0.56916085,  0.76620194,
        0.29831278]), 'targetState': array([25., 25., 15.])}
episode index:3846
target thresh 38.73494161878587
model initialize at round 3846
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09047995, 14.95169313,  0.99467593,  0.09090731,
       -0.04853503]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.659205915814287
{'scaleFactor': 20, 'currentState': array([27.16555342, 20.59044044, 13.91200755,  0.57822683,  0.7947235 ,
        0.18457601]), 'targetState': array([25., 25., 15.])}
episode index:3847
target thresh 38.741067818308906
model initialize at round 3847
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12855219, 14.88978665,  0.9856859 ,  0.127992  ,
       -0.10973307]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6592792719040964
{'scaleFactor': 20, 'currentState': array([26.48444009, 21.60539445, 13.91114886,  0.47950614,  0.8604584 ,
        0.17229396]), 'targetState': array([25., 25., 15.])}
episode index:3848
target thresh 38.74719340524263
model initialize at round 3848
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6593525898769456
{'scaleFactor': 20, 'currentState': array([26.68158372, 21.41888804, 14.00397663,  0.55950101,  0.77454375,
        0.29502644]), 'targetState': array([25., 25., 15.])}
episode index:3849
target thresh 38.753318379648285
model initialize at round 3849
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11344934, 14.84627329,  0.98188262,  0.11251913,
       -0.15246625]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6594258697625363
{'scaleFactor': 20, 'currentState': array([27.08663645, 20.60804714, 13.82970972,  0.61476036,  0.72661177,
        0.30676544]), 'targetState': array([25., 25., 15.])}
episode index:3850
target thresh 38.7594427415871
model initialize at round 3850
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.06241059, 14.89921552,  0.99290722,  0.06259386,
       -0.10108044]), 'targetState': array([25., 25., 15.])}
done in step count: 45
reward sum = 0.6361854860638709
running average episode reward sum: 0.6594198348667433
{'scaleFactor': 20, 'currentState': array([20.54737535, 25.45495685, 15.96500671,  0.85743316, -0.23032792,
       -0.46017108]), 'targetState': array([25., 25., 15.])}
episode index:3851
target thresh 38.76556649112036
model initialize at round 3851
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6594955280689845
{'scaleFactor': 20, 'currentState': array([25.06625371, 20.13570559, 12.39984028,  0.57041193,  0.79458472,
       -0.20800326]), 'targetState': array([25., 25., 15.])}
episode index:3852
target thresh 38.7716896283093
model initialize at round 3852
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6595711819806978
{'scaleFactor': 20, 'currentState': array([24.91681814, 20.11032038, 11.95602759,  0.56663263,  0.80585629,
       -0.17182287]), 'targetState': array([25., 25., 15.])}
episode index:3853
target thresh 38.777812153215116
model initialize at round 3853
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6596467966324673
{'scaleFactor': 20, 'currentState': array([25.06806152, 20.1498289 , 12.46499088,  0.58030543,  0.8047287 ,
       -0.12512921]), 'targetState': array([25., 25., 15.])}
episode index:3854
target thresh 38.78393406589906
model initialize at round 3854
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6597223720548454
{'scaleFactor': 20, 'currentState': array([25.21513246, 20.18912072, 13.42405886,  0.59247279,  0.80030831,
        0.09210102]), 'targetState': array([25., 25., 15.])}
episode index:3855
target thresh 38.79005536642235
model initialize at round 3855
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.65979544201785
{'scaleFactor': 20, 'currentState': array([26.34221672, 21.50551198, 12.07994543,  0.48925376,  0.86857815,
       -0.07875764]), 'targetState': array([25., 25., 15.])}
episode index:3856
target thresh 38.79617605484618
model initialize at round 3856
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6598709397124009
{'scaleFactor': 20, 'currentState': array([25.12982353, 20.17242073, 12.77966539,  0.5893591 ,  0.80716672,
       -0.03373019]), 'targetState': array([25., 25., 15.])}
episode index:3857
target thresh 38.80229613123177
model initialize at round 3857
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6599463982686963
{'scaleFactor': 20, 'currentState': array([25.25646157, 20.06479342, 12.97266783,  0.66036187,  0.74739871,
        0.07292026]), 'targetState': array([25., 25., 15.])}
episode index:3858
target thresh 38.808415595640334
model initialize at round 3858
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.07801695, 14.88265189,  0.99002117,  0.07801862,
       -0.11735062]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.660016913674148
{'scaleFactor': 20, 'currentState': array([28.9975938 , 21.06536149, 13.46321185,  0.59995115,  0.78117237,
        0.17270887]), 'targetState': array([25., 25., 15.])}
episode index:3859
target thresh 38.814534448133045
model initialize at round 3859
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10644133, 14.84627329,  0.98262766,  0.10564868,
       -0.15258193]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6600898316108648
{'scaleFactor': 20, 'currentState': array([26.92231998, 20.68712283, 12.30705978,  0.58463852,  0.80951117,
       -0.05375375]), 'targetState': array([25., 25., 15.])}
episode index:3860
target thresh 38.820652688771105
model initialize at round 3860
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.660165174842745
{'scaleFactor': 20, 'currentState': array([25.02501874, 20.14166043, 12.31910937,  0.57730647,  0.80582865,
       -0.13174758]), 'targetState': array([25., 25., 15.])}
episode index:3861
target thresh 38.82677031761569
model initialize at round 3861
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6602380166279749
{'scaleFactor': 20, 'currentState': array([27.36907073, 20.46218196, 12.96628171,  0.72961943,  0.67501672,
        0.10958064]), 'targetState': array([25., 25., 15.])}
episode index:3862
target thresh 38.83288733472797
model initialize at round 3862
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.08866628, 14.84627329,  0.98431059,  0.08815673,
       -0.15284326]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6603083835270893
{'scaleFactor': 20, 'currentState': array([29.52249766, 20.43337624, 13.51028287,  0.73740442,  0.63093786,
        0.24114755]), 'targetState': array([25., 25., 15.])}
episode index:3863
target thresh 38.83900374016912
model initialize at round 3863
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09882668, 14.89419753,  0.98947528,  0.0987743 ,
       -0.10574639]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.660381150547243
{'scaleFactor': 20, 'currentState': array([26.70441531, 21.20978205, 14.44069321,  0.51714052,  0.78638067,
        0.33789219]), 'targetState': array([25., 25., 15.])}
episode index:3864
target thresh 38.845119534000325
model initialize at round 3864
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.0751925 , 14.90282985,  0.99238661,  0.07537377,
       -0.0974044 ]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6604514440006349
{'scaleFactor': 20, 'currentState': array([29.13681887, 21.09351929, 13.41916773,  0.71229033,  0.69295268,
        0.1116202 ]), 'targetState': array([25., 25., 15.])}
episode index:3865
target thresh 38.851234716282725
model initialize at round 3865
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.0482791 , 14.84627329,  0.98701251,  0.04813341,
       -0.15326281]), 'targetState': array([25., 25., 15.])}
done in step count: 44
reward sum = 0.6426116020847181
running average episode reward sum: 0.6604468294528036
{'scaleFactor': 20, 'currentState': array([21.23185654, 23.04295672, 15.11295875,  0.97691609,  0.03711959,
       -0.21037369]), 'targetState': array([25., 25., 15.])}
episode index:3866
target thresh 38.85734928707745
model initialize at round 3866
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.94919758,  0.98688989,  0.15324377,
       -0.05064282]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6605219634637804
{'scaleFactor': 20, 'currentState': array([25.38939892, 20.07489123, 14.07103304,  0.61402007,  0.77029701,
        0.17211004]), 'targetState': array([25., 25., 15.])}
episode index:3867
target thresh 38.86346324644568
model initialize at round 3867
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.93237467,  0.98591441,  0.1530923 ,
       -0.06734625]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6605946000165046
{'scaleFactor': 20, 'currentState': array([26.77654674, 21.40266349, 15.36640232,  0.54986129,  0.77474726,
        0.31212056]), 'targetState': array([25., 25., 15.])}
episode index:3868
target thresh 38.86957659444854
model initialize at round 3868
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09340836, 14.92316058,  0.9926193 ,  0.09365549,
       -0.07704271]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6606671990212564
{'scaleFactor': 20, 'currentState': array([27.24773299, 20.47249717, 13.99015813,  0.61919699,  0.74247253,
        0.2555966 ]), 'targetState': array([25., 25., 15.])}
episode index:3869
target thresh 38.875689331147164
model initialize at round 3869
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11891699, 14.85952901,  0.98315485,  0.11809476,
       -0.13949974]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6607397605071426
{'scaleFactor': 20, 'currentState': array([26.90092933, 20.86100431, 13.56713228,  0.54077912,  0.8031452 ,
        0.25003148]), 'targetState': array([25., 25., 15.])}
episode index:3870
target thresh 38.881801456602695
model initialize at round 3870
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.90310658,  0.9835687 ,  0.15272806,
       -0.09626397]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6608147412070632
{'scaleFactor': 20, 'currentState': array([25.31730298, 20.13251416, 14.0431449 ,  0.59056618,  0.77995871,
        0.2071135 ]), 'targetState': array([25., 25., 15.])}
episode index:3871
target thresh 38.88791297087623
model initialize at round 3871
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12983064, 14.84627329,  0.9799637 ,  0.12851446,
       -0.15216828]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6608872271079397
{'scaleFactor': 20, 'currentState': array([26.94459753, 20.82242439, 14.27919513,  0.52479935,  0.77959909,
        0.3417761 ]), 'targetState': array([25., 25., 15.])}
episode index:3872
target thresh 38.89402387402888
model initialize at round 3872
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.9514045 ,  0.98699747,  0.15326048,
       -0.04844812]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6609621310126111
{'scaleFactor': 20, 'currentState': array([25.48051099, 20.05158444, 14.63053156,  0.6244494 ,  0.7610245 ,
        0.17579719]), 'targetState': array([25., 25., 15.])}
episode index:3873
target thresh 38.90013416612178
model initialize at round 3873
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89214669,  0.98248123,  0.1525592 ,
       -0.1070342 ]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6610369962472232
{'scaleFactor': 20, 'currentState': array([25.26778395, 20.17400453, 13.73091324,  0.59316964,  0.79122318,
        0.14871335]), 'targetState': array([25., 25., 15.])}
episode index:3874
target thresh 38.906243847216025
model initialize at round 3874
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11531396, 14.84627329,  0.9816767 ,  0.11434447,
       -0.15243427]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6611093686738435
{'scaleFactor': 20, 'currentState': array([26.58134884, 21.3269066 , 14.19414366,  0.48640616,  0.81171381,
        0.32331058]), 'targetState': array([25., 25., 15.])}
episode index:3875
target thresh 38.91235291737271
model initialize at round 3875
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11953283, 14.84627329,  0.98119887,  0.11847018,
       -0.15236007]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6611817037565905
{'scaleFactor': 20, 'currentState': array([27.49778056, 20.185468  , 13.59744182,  0.71076521,  0.66395311,
        0.23233398]), 'targetState': array([25., 25., 15.])}
episode index:3876
target thresh 38.918461376652914
model initialize at round 3876
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.05652167, 14.84627329,  0.98658904,  0.05632693,
       -0.15319706]), 'targetState': array([25., 25., 15.])}
done in step count: 45
reward sum = 0.6361854860638709
running average episode reward sum: 0.6611752564474099
{'scaleFactor': 20, 'currentState': array([20.95211746, 22.10131026, 12.93748188,  0.95374554, -0.15542468,
       -0.25731812]), 'targetState': array([25., 25., 15.])}
episode index:3877
target thresh 38.924569225117736
model initialize at round 3877
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10787377, 14.84826156,  0.98277307,  0.1070863 ,
       -0.15063076]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6612475372346595
{'scaleFactor': 20, 'currentState': array([27.12987571, 20.46016517, 13.01308643,  0.63618114,  0.74945082,
        0.1832949 ]), 'targetState': array([25., 25., 15.])}
episode index:3878
target thresh 38.93067646282825
model initialize at round 3878
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.0754553 , 14.9129347 ,  0.99329633,  0.07570654,
       -0.08735519]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6613173536333892
{'scaleFactor': 20, 'currentState': array([29.29429442, 20.44845303, 14.10538466,  0.58901488,  0.75440634,
        0.28971116]), 'targetState': array([25., 25., 15.])}
episode index:3879
target thresh 38.93678308984553
model initialize at round 3879
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86282984,  0.97902422,  0.1520224 ,
       -0.1356494 ]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6613920115447981
{'scaleFactor': 20, 'currentState': array([25.24416342, 20.18060201, 13.86201051,  0.58153763,  0.78415119,
        0.2166123 ]), 'targetState': array([25., 25., 15.])}
episode index:3880
target thresh 38.94288910623064
model initialize at round 3880
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89186533,  0.98245183,  0.15255463,
       -0.1073102 ]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6614666309826635
{'scaleFactor': 20, 'currentState': array([25.3738493 , 20.01405216, 13.51177961,  0.63433998,  0.76176403,
        0.1316372 ]), 'targetState': array([25., 25., 15.])}
episode index:3881
target thresh 38.948994512044635
model initialize at round 3881
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09702465, 14.84627329,  0.98355635,  0.09639314,
       -0.15272614]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.661536336989084
{'scaleFactor': 20, 'currentState': array([29.46184311, 20.23808272, 13.30909946,  0.6819552 ,  0.69606582,
        0.22456507]), 'targetState': array([25., 25., 15.])}
episode index:3882
target thresh 38.955099307348576
model initialize at round 3882
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6616108808244976
{'scaleFactor': 20, 'currentState': array([25.17632553, 20.18165044, 13.14656581,  0.59772167,  0.79560267,
        0.09871772]), 'targetState': array([25., 25., 15.])}
episode index:3883
target thresh 38.96120349220351
model initialize at round 3883
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87759452,  0.98086411,  0.15230809,
       -0.1212759 ]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.661685386274826
{'scaleFactor': 20, 'currentState': array([25.27834298, 20.18061355, 13.90600041,  0.5861846 ,  0.78738105,
        0.19083682]), 'targetState': array([25., 25., 15.])}
episode index:3884
target thresh 38.96730706667048
model initialize at round 3884
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.91608275,  0.98470958,  0.15290521,
       -0.0834688 ]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6617598533697102
{'scaleFactor': 20, 'currentState': array([25.36796476, 20.11692646, 14.46180038,  0.61008792,  0.75066385,
        0.2535676 ]), 'targetState': array([25., 25., 15.])}
episode index:3885
target thresh 38.97341003081052
model initialize at round 3885
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09068811, 14.93106163,  0.99344487,  0.09100367,
       -0.06917825]), 'targetState': array([25., 25., 15.])}
done in step count: 42
reward sum = 0.6556592205741436
running average episode reward sum: 0.6617582834693512
{'scaleFactor': 20, 'currentState': array([20.55574477, 25.52044579, 14.97048804,  0.83364695, -0.50990887,
       -0.21219264]), 'targetState': array([25., 25., 15.])}
episode index:3886
target thresh 38.979512384684654
model initialize at round 3886
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89634393,  0.98291102,  0.15262593,
       -0.10291383]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6618326934941597
{'scaleFactor': 20, 'currentState': array([25.31147553, 20.15791421, 14.13226949,  0.60156951,  0.76789448,
        0.22011858]), 'targetState': array([25., 25., 15.])}
episode index:3887
target thresh 38.985614128353916
model initialize at round 3887
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15273518, 14.84627329,  0.97687119,  0.15070969,
       -0.15168807]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6619070652422065
{'scaleFactor': 20, 'currentState': array([25.24505487, 20.00447624, 12.98806215,  0.60844781,  0.78791124,
        0.09480052]), 'targetState': array([25., 25., 15.])}
episode index:3888
target thresh 38.99171526187932
model initialize at round 3888
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15354712, 14.84627329,  0.97675294,  0.15149252,
       -0.15166971]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6619813987430185
{'scaleFactor': 20, 'currentState': array([25.17704746, 20.15572737, 13.03987744,  0.61447503,  0.78597218,
        0.06832401]), 'targetState': array([25., 25., 15.])}
episode index:3889
target thresh 38.997815785321876
model initialize at round 3889
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13225421, 14.84627329,  0.97965889,  0.13087274,
       -0.15212095]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6620532493215938
{'scaleFactor': 20, 'currentState': array([26.58452189, 21.27717559, 12.83606303,  0.53049634,  0.82717739,
        0.1853408 ]), 'targetState': array([25., 25., 15.])}
episode index:3890
target thresh 39.003915698742595
model initialize at round 3890
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.1512778 , 14.89520478,  0.98315792,  0.15023229,
       -0.10407096]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6621250629684916
{'scaleFactor': 20, 'currentState': array([26.74624046, 21.37949117, 14.49346713,  0.51259796,  0.80129696,
        0.30849071]), 'targetState': array([25., 25., 15.])}
episode index:3891
target thresh 39.01001500220246
model initialize at round 3891
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.91148713,  0.98432381,  0.15284531,
       -0.08800538]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6621992831604062
{'scaleFactor': 20, 'currentState': array([25.29649437, 20.18021346, 13.89786301,  0.59224994,  0.79317279,
        0.14183416]), 'targetState': array([25., 25., 15.])}
episode index:3892
target thresh 39.01611369576249
model initialize at round 3892
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6622734652222453
{'scaleFactor': 20, 'currentState': array([25.21120044, 20.18664186, 13.61560319,  0.58342682,  0.78895928,
        0.19275997]), 'targetState': array([25., 25., 15.])}
episode index:3893
target thresh 39.02221177948364
model initialize at round 3893
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86805512,  0.97969809,  0.15212703,
       -0.13057186]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.662347609183385
{'scaleFactor': 20, 'currentState': array([25.26757457, 20.08435991, 13.24618696,  0.60536706,  0.789306  ,
        0.10259996]), 'targetState': array([25., 25., 15.])}
episode index:3894
target thresh 39.02830925342692
model initialize at round 3894
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.94504893,  0.98667483,  0.15321038,
       -0.0547665 ]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.662421715073171
{'scaleFactor': 20, 'currentState': array([25.36004869, 20.15074121, 15.14562867,  0.57912755,  0.77539976,
        0.25172703]), 'targetState': array([25., 25., 15.])}
episode index:3895
target thresh 39.03440611765328
model initialize at round 3895
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89380666,  0.98265318,  0.1525859 ,
       -0.10540528]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6624933419813661
{'scaleFactor': 20, 'currentState': array([26.79225869, 21.31008396, 14.08031513,  0.53339812,  0.7940672 ,
        0.29145107]), 'targetState': array([25., 25., 15.])}
episode index:3896
target thresh 39.040502372223706
model initialize at round 3896
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.51216591e+01,  1.49861465e+01,  9.92438012e-01,
        1.21958711e-01, -1.38876032e-02]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6625649321295363
{'scaleFactor': 20, 'currentState': array([27.65020659, 20.13417703, 14.31579457,  0.6804874 ,  0.71572715,
        0.15707181]), 'targetState': array([25., 25., 15.])}
episode index:3897
target thresh 39.04659801719915
model initialize at round 3897
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13335197, 14.87595811,  0.98349643,  0.13247595,
       -0.12322703]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6626364855459733
{'scaleFactor': 20, 'currentState': array([27.53828277, 20.12794444, 13.72708653,  0.6729727 ,  0.70576418,
        0.22136998]), 'targetState': array([25., 25., 15.])}
episode index:3898
target thresh 39.052693052640585
model initialize at round 3898
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15038834, 14.91929053,  0.98546221,  0.14969902,
       -0.08033953]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6627104413203653
{'scaleFactor': 20, 'currentState': array([25.36706623, 20.115696  , 14.43898303,  0.58877234,  0.77298693,
        0.23630137]), 'targetState': array([25., 25., 15.])}
episode index:3899
target thresh 39.05878747860895
model initialize at round 3899
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14035202, 14.88812267,  0.9839597 ,  0.13949569,
       -0.11119473]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6627819207326936
{'scaleFactor': 20, 'currentState': array([26.78852903, 21.16059851, 14.02957604,  0.52056422,  0.79677444,
        0.30686053]), 'targetState': array([25., 25., 15.])}
episode index:3900
target thresh 39.06488129516518
model initialize at round 3900
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87735453,  0.9808358 ,  0.1523037 ,
       -0.12151017]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6628558013092554
{'scaleFactor': 20, 'currentState': array([2.52654840e+01, 2.01833838e+01, 1.35215287e+01, 5.96582311e-01,
       8.02203376e-01, 2.36492981e-02]), 'targetState': array([25., 25., 15.])}
episode index:3901
target thresh 39.07097450237023
model initialize at round 3901
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6629296440177614
{'scaleFactor': 20, 'currentState': array([25.18266956, 20.18862325, 13.24792169,  0.58897864,  0.79872514,
        0.12305408]), 'targetState': array([25., 25., 15.])}
episode index:3902
target thresh 39.077067100285014
model initialize at round 3902
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6630034488873188
{'scaleFactor': 20, 'currentState': array([25.11369918, 20.18294355, 12.88757091,  0.58864976,  0.80553379,
        0.06787326]), 'targetState': array([25., 25., 15.])}
episode index:3903
target thresh 39.08315908897046
model initialize at round 3903
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6630772159470045
{'scaleFactor': 20, 'currentState': array([25.24138473, 20.18245833, 13.83412113,  0.58169411,  0.78466376,
        0.21432394]), 'targetState': array([25., 25., 15.])}
episode index:3904
target thresh 39.08925046848752
model initialize at round 3904
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86878293,  0.97978999,  0.1521413 ,
       -0.12986381]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6631509452258657
{'scaleFactor': 20, 'currentState': array([25.27541405, 20.17558286, 14.07994882,  0.58031192,  0.78072745,
        0.23173848]), 'targetState': array([25., 25., 15.])}
episode index:3905
target thresh 39.09534123889708
model initialize at round 3905
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86702582,  0.97956731,  0.15210673,
       -0.13157289]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6632246367529201
{'scaleFactor': 20, 'currentState': array([25.24969013, 20.18452865, 13.74669328,  0.58706103,  0.79060109,
        0.17409555]), 'targetState': array([25., 25., 15.])}
episode index:3906
target thresh 39.10143140026005
model initialize at round 3906
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85367861,  0.97778465,  0.15182991,
       -0.14451596]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6632982905571554
{'scaleFactor': 20, 'currentState': array([25.22297705, 20.18489302, 13.68819383,  0.58320296,  0.78776949,
        0.19822597]), 'targetState': array([25., 25., 15.])}
episode index:3907
target thresh 39.10752095263732
model initialize at round 3907
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.92491981,  0.98539471,  0.1530116 ,
       -0.07473093]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.663369473223185
{'scaleFactor': 20, 'currentState': array([26.7581972 , 21.49941544, 14.15791368,  0.59297765,  0.7847518 ,
        0.18039435]), 'targetState': array([25., 25., 15.])}
episode index:3908
target thresh 39.11360989608982
model initialize at round 3908
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.04555564, 14.84627329,  0.98713789,  0.04542393,
       -0.15328228]), 'targetState': array([25., 25., 15.])}
done in step count: 41
reward sum = 0.6622820409839835
running average episode reward sum: 0.6633691950363751
{'scaleFactor': 20, 'currentState': array([20.6124462 , 20.09781902, 13.73164979,  0.9553855 , -0.15393431,
       -0.25207692]), 'targetState': array([25., 25., 15.])}
episode index:3909
target thresh 39.1196982306784
model initialize at round 3909
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.92308769,  0.98525881,  0.1529905 ,
       -0.07654397]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6634403231576961
{'scaleFactor': 20, 'currentState': array([27.47348023, 20.61013108, 14.37048923,  0.79643045,  0.57930466,
        0.17350694]), 'targetState': array([25., 25., 15.])}
episode index:3910
target thresh 39.12578595646398
model initialize at round 3910
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.03293827, 14.87999777,  0.99219246,  0.03301121,
       -0.12026799]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6635090076436969
{'scaleFactor': 20, 'currentState': array([28.66760156, 21.23083726, 14.3691623 ,  0.51744113,  0.80450042,
        0.29160548]), 'targetState': array([25., 25., 15.])}
episode index:3911
target thresh 39.13187307350741
model initialize at round 3911
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13741531, 14.84627329,  0.978992  ,  0.13588736,
       -0.15201739]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6635800636615286
{'scaleFactor': 20, 'currentState': array([27.28785272, 20.49161826, 13.66887482,  0.61772455,  0.7456908 ,
        0.24972307]), 'targetState': array([25., 25., 15.])}
episode index:3912
target thresh 39.13795958186955
model initialize at round 3912
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86615242,  0.97945558,  0.15208938,
       -0.13242198]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6636535136963454
{'scaleFactor': 20, 'currentState': array([25.30514656, 20.16812548, 14.3958649 ,  0.57755933,  0.77579345,
        0.25410579]), 'targetState': array([25., 25., 15.])}
episode index:3913
target thresh 39.144045481611315
model initialize at round 3913
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6637244964852326
{'scaleFactor': 20, 'currentState': array([26.81047057, 21.33099073, 14.21622606,  0.60241443,  0.74195013,
        0.29429043]), 'targetState': array([25., 25., 15.])}
episode index:3914
target thresh 39.150130772793524
model initialize at round 3914
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15310881, 14.87145061,  0.98021375,  0.15159532,
       -0.12727867]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6637978721055174
{'scaleFactor': 20, 'currentState': array([25.28226398, 20.17093608, 14.08978224,  0.58362559,  0.78353783,
        0.21318922]), 'targetState': array([25., 25., 15.])}
episode index:3915
target thresh 39.15621545547704
model initialize at round 3915
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13418479, 14.86774543,  0.98236872,  0.13315045,
       -0.1312351 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6638687817779626
{'scaleFactor': 20, 'currentState': array([26.42070892, 21.59481457, 14.80697626,  0.44529837,  0.82523544,
        0.34741306]), 'targetState': array([25., 25., 15.])}
episode index:3916
target thresh 39.16229952972271
model initialize at round 3916
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.90375694,  0.98362968,  0.15273753,
       -0.09562377]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6639420830973708
{'scaleFactor': 20, 'currentState': array([25.26629815, 20.17284179, 13.60890282,  0.60202546,  0.790019  ,
        0.11591083]), 'targetState': array([25., 25., 15.])}
episode index:3917
target thresh 39.16838299559138
model initialize at round 3917
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6640153469990561
{'scaleFactor': 20, 'currentState': array([25.27248507, 20.17242523, 13.94276738,  0.59084568,  0.77720818,
        0.21644589]), 'targetState': array([25., 25., 15.])}
episode index:3918
target thresh 39.17446585314387
model initialize at round 3918
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15006638, 14.95070907,  0.98750992,  0.14968893,
       -0.04916695]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6640885735116616
{'scaleFactor': 20, 'currentState': array([25.44355178, 20.00698702, 14.68108425,  0.59502907,  0.7631255 ,
        0.25215053]), 'targetState': array([25., 25., 15.])}
episode index:3919
target thresh 39.180548102441016
model initialize at round 3919
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13793089, 14.96699528,  0.98989397,  0.13791611,
       -0.03300118]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6641593366687762
{'scaleFactor': 20, 'currentState': array([26.88148446, 21.20172347, 15.35923547,  0.52162865,  0.82545814,
        0.21569054]), 'targetState': array([25., 25., 15.])}
episode index:3920
target thresh 39.186629743543655
model initialize at round 3920
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.138484  , 14.86405559,  0.98132482,  0.13727049,
       -0.13475316]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.664230063731447
{'scaleFactor': 20, 'currentState': array([27.409015  , 20.40203546, 13.41255395,  0.71979792,  0.68005989,
        0.13931799]), 'targetState': array([25., 25., 15.])}
episode index:3921
target thresh 39.192710776512584
model initialize at round 3921
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.07386761, 14.84627329,  0.98548288,  0.07353057,
       -0.15302529]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.6640607036947995
{'scaleFactor': 20, 'currentState': array([32.91534749, 19.39957713, 14.32319016,  0.77677337,  0.61418189,
       -0.13929729]), 'targetState': array([25., 25., 15.])}
episode index:3922
target thresh 39.198791201408625
model initialize at round 3922
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.11533866, 14.84632294,  0.98168131,  0.11436951,
       -0.15238576]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6641290199436428
{'scaleFactor': 20, 'currentState': array([29.48963739, 20.57065839, 13.0766352 ,  0.81006506,  0.57689407,
        0.10482284]), 'targetState': array([25., 25., 15.])}
episode index:3923
target thresh 39.204871018292565
model initialize at round 3923
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.50011263e+01,  1.48462733e+01,  9.88157239e-01,
        1.12424382e-03, -1.53440565e-01]), 'targetState': array([25., 25., 15.])}
done in step count: 49
reward sum = 0.0
running average episode reward sum: 0.6639597719772963
{'scaleFactor': 20, 'currentState': array([20.25171856, 13.58095151, 16.00673438,  0.70869032, -0.66304246,
       -0.24110729]), 'targetState': array([25., 25., 15.])}
episode index:3924
target thresh 39.210950227225226
model initialize at round 3924
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10006267, 14.90876612,  0.99077501,  0.100141  ,
       -0.0913053 ]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6640280791303995
{'scaleFactor': 20, 'currentState': array([29.58006693, 20.2924745 , 14.09073826,  0.71086214,  0.68072392,
        0.17688969]), 'targetState': array([25., 25., 15.])}
episode index:3925
target thresh 39.21702882826739
model initialize at round 3925
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12638602, 14.85329406,  0.98140324,  0.12528853,
       -0.145432  ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6640987495507434
{'scaleFactor': 20, 'currentState': array([27.56961208, 20.00474669, 13.80026922,  0.67475864,  0.70556756,
        0.2165068 ]), 'targetState': array([25., 25., 15.])}
episode index:3926
target thresh 39.22310682147984
model initialize at round 3926
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12245023, 14.87159729,  0.98431657,  0.12174726,
       -0.12766557]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.664169383979022
{'scaleFactor': 20, 'currentState': array([26.83676233, 21.09490386, 15.00032287,  0.51077046,  0.80022982,
        0.3142384 ]), 'targetState': array([25., 25., 15.])}
episode index:3927
target thresh 39.22918420692335
model initialize at round 3927
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.12383876, 14.87967533,  0.98512873,  0.12322942,
       -0.11973262]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6642375855991667
{'scaleFactor': 20, 'currentState': array([29.30310084, 21.15373313, 15.22802561,  0.70266669,  0.68621045,
        0.18808174]), 'targetState': array([25., 25., 15.])}
episode index:3928
target thresh 39.2352609846587
model initialize at round 3928
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89881413,  0.98315624,  0.15266401,
       -0.10048639]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6643105691736897
{'scaleFactor': 20, 'currentState': array([25.33298457, 20.17457449, 14.38352538,  0.58555512,  0.78295345,
        0.21002166]), 'targetState': array([25., 25., 15.])}
episode index:3929
target thresh 39.24133715474668
model initialize at round 3929
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14350795, 14.85419051,  0.97930804,  0.14195807,
       -0.14423475]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6643835156064445
{'scaleFactor': 20, 'currentState': array([25.34762885, 20.064816  , 14.51530921,  0.57893641,  0.76362229,
        0.28585596]), 'targetState': array([25., 25., 15.])}
episode index:3930
target thresh 39.24741271724801
model initialize at round 3930
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86334167,  0.97909132,  0.15203281,
       -0.13515251]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6644564249257764
{'scaleFactor': 20, 'currentState': array([25.27770106, 20.18632157, 13.74164517,  0.59400049,  0.79723801,
        0.10758706]), 'targetState': array([25., 25., 15.])}
episode index:3931
target thresh 39.25348767222347
model initialize at round 3931
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86837592,  0.97973866,  0.15213333,
       -0.13025979]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6645292971600019
{'scaleFactor': 20, 'currentState': array([25.28769651, 20.15781837, 14.4932829 ,  0.57013135,  0.76872846,
        0.28983926]), 'targetState': array([25., 25., 15.])}
episode index:3932
target thresh 39.25956201973382
model initialize at round 3932
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13743306, 14.92773719,  0.98792273,  0.13714469,
       -0.07211118]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6645997143611818
{'scaleFactor': 20, 'currentState': array([26.50238609, 21.52040724, 16.01726105,  0.46967717,  0.82205342,
        0.32191853]), 'targetState': array([25., 25., 15.])}
episode index:3933
target thresh 39.26563575983978
model initialize at round 3933
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.91403913,  0.98454052,  0.15287896,
       -0.08548682]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.664672513124664
{'scaleFactor': 20, 'currentState': array([25.34438428, 20.08137543, 15.45240713,  0.58326573,  0.72306078,
        0.37011375]), 'targetState': array([25., 25., 15.])}
episode index:3934
target thresh 39.271708892602085
model initialize at round 3934
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13984284, 14.91535033,  0.98664049,  0.13936829,
       -0.08436241]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.664745274887504
{'scaleFactor': 20, 'currentState': array([25.39691598, 20.03930597, 14.47902836,  0.59263628,  0.77130058,
        0.23211561]), 'targetState': array([25., 25., 15.])}
episode index:3935
target thresh 39.27778141808149
model initialize at round 3935
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85522403,  0.97799926,  0.15186324,
       -0.143021  ]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6648179996779037
{'scaleFactor': 20, 'currentState': array([25.28319477, 20.18222875, 13.98192543,  0.58940464,  0.79101689,
        0.16399525]), 'targetState': array([25., 25., 15.])}
episode index:3936
target thresh 39.283853336338716
model initialize at round 3936
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6648906875240358
{'scaleFactor': 20, 'currentState': array([25.28107539, 20.16156379, 14.42050303,  0.57423716,  0.77379417,
        0.26738412]), 'targetState': array([25., 25., 15.])}
episode index:3937
target thresh 39.28992464743447
model initialize at round 3937
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85345236,  0.97775305,  0.15182501,
       -0.14473475]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.664963338454045
{'scaleFactor': 20, 'currentState': array([25.33631208, 20.0996623 , 13.56250798,  0.60930196,  0.79190934,
        0.04038227]), 'targetState': array([25., 25., 15.])}
episode index:3938
target thresh 39.29599535142947
model initialize at round 3938
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6650335382029525
{'scaleFactor': 20, 'currentState': array([27.5845363 , 20.29533006, 13.94476713,  0.72647799,  0.67128345,
        0.14699745]), 'targetState': array([25., 25., 15.])}
episode index:3939
target thresh 39.30206544838442
model initialize at round 3939
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.07029783, 14.84715738,  0.98586672,  0.07000434,
       -0.1522045 ]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6651037023174697
{'scaleFactor': 20, 'currentState': array([27.37115889, 20.19057899, 14.33979776,  0.60795226,  0.75429083,
        0.24786972]), 'targetState': array([25., 25., 15.])}
episode index:3940
target thresh 39.30813493836002
model initialize at round 3940
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6651762438925986
{'scaleFactor': 20, 'currentState': array([25.16893444, 20.18737172, 13.11654113,  0.59029587,  0.80204378,
        0.0909756 ]), 'targetState': array([25., 25., 15.])}
episode index:3941
target thresh 39.31420382141698
model initialize at round 3941
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10100157, 14.87080244,  0.98655635,  0.10065025,
       -0.12874815]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6652439478763668
{'scaleFactor': 20, 'currentState': array([29.23743691, 20.95676737, 14.32003483,  0.64718948,  0.7336504 ,
        0.20713008]), 'targetState': array([25., 25., 15.])}
episode index:3942
target thresh 39.32027209761596
model initialize at round 3942
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14026435, 14.87481641,  0.98244215,  0.13919354,
       -0.12422791]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6653140052442401
{'scaleFactor': 20, 'currentState': array([26.89155413, 21.17600477, 13.33559518,  0.57733679,  0.81228661,
        0.08290166]), 'targetState': array([25., 25., 15.])}
episode index:3943
target thresh 39.32633976701767
model initialize at round 3943
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.1508962 , 14.84627329,  0.97713684,  0.14893559,
       -0.15172932]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6653864383184429
{'scaleFactor': 20, 'currentState': array([25.28549828, 20.16153337, 13.79887528,  0.59194236,  0.78988481,
        0.16026923]), 'targetState': array([25., 25., 15.])}
episode index:3944
target thresh 39.33240682968279
model initialize at round 3944
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87473174,  0.98052294,  0.15225512,
       -0.1240691 ]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6654588346711886
{'scaleFactor': 20, 'currentState': array([25.27485148, 20.18621764, 13.76108749,  0.59245951,  0.79494248,
        0.13060694]), 'targetState': array([25., 25., 15.])}
episode index:3945
target thresh 39.33847328567196
model initialize at round 3945
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84909445,  0.9771355 ,  0.15172911,
       -0.14894461]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6655311943303951
{'scaleFactor': 20, 'currentState': array([25.30815788, 20.15703289, 14.6322177 ,  0.57384471,  0.77204897,
        0.27320807]), 'targetState': array([25., 25., 15.])}
episode index:3946
target thresh 39.34453913504588
model initialize at round 3946
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84732803,  0.97688037,  0.1516895 ,
       -0.15064873]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6656035173239522
{'scaleFactor': 20, 'currentState': array([25.30518667, 20.16941138, 14.36906505,  0.58166031,  0.78084659,
        0.2279252 ]), 'targetState': array([25., 25., 15.])}
episode index:3947
target thresh 39.350604377865174
model initialize at round 3947
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6656758036797212
{'scaleFactor': 20, 'currentState': array([25.29869772, 20.14372195, 14.81885026,  0.5687228 ,  0.76739063,
        0.29608444]), 'targetState': array([25., 25., 15.])}
episode index:3948
target thresh 39.356669014190516
model initialize at round 3948
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89385696,  0.98265835,  0.1525867 ,
       -0.10535591]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6657480534255356
{'scaleFactor': 20, 'currentState': array([25.39340175, 20.02428611, 15.32570539,  0.61880667,  0.70950526,
        0.33716553]), 'targetState': array([25., 25., 15.])}
episode index:3949
target thresh 39.362733044082546
model initialize at round 3949
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10189539, 14.89306613,  0.98905219,  0.10179783,
       -0.10683149]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6658154755254043
{'scaleFactor': 20, 'currentState': array([29.55780043, 20.7500925 , 14.89010806,  0.77847696,  0.62248582,
        0.0805297 ]), 'targetState': array([25., 25., 15.])}
episode index:3950
target thresh 39.36879646760191
model initialize at round 3950
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.06546187, 14.86877335,  0.98920614,  0.06540937,
       -0.13112142]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6658828634961412
{'scaleFactor': 20, 'currentState': array([28.90032562, 21.28149034, 13.76168093,  0.55835229,  0.8174333 ,
        0.14158223]), 'targetState': array([25., 25., 15.])}
episode index:3951
target thresh 39.37485928480925
model initialize at round 3951
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6659525996514815
{'scaleFactor': 20, 'currentState': array([26.99338632, 21.1164788 , 13.64164249,  0.65147861,  0.74173481,
        0.15938975]), 'targetState': array([25., 25., 15.])}
episode index:3952
target thresh 39.380921495765165
model initialize at round 3952
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.1137848 , 14.84627329,  0.98184582,  0.1128476 ,
       -0.15246053]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.666022300524173
{'scaleFactor': 20, 'currentState': array([26.84236781, 21.21536227, 14.41966793,  0.56311899,  0.77926386,
        0.27503607]), 'targetState': array([25., 25., 15.])}
episode index:3953
target thresh 39.386983100530294
model initialize at round 3953
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10218781, 14.93272189,  0.99245006,  0.10244071,
       -0.06744461]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6660895850581595
{'scaleFactor': 20, 'currentState': array([ 2.92576184e+01,  2.13179431e+01,  1.54600149e+01,  6.87877712e-01,
        7.25826337e-01, -6.18005599e-04]), 'targetState': array([25., 25., 15.])}
episode index:3954
target thresh 39.39304409916525
model initialize at round 3954
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.8744846 ,  0.98049314,  0.15225049,
       -0.12431009]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6661616205739224
{'scaleFactor': 20, 'currentState': array([25.36865192, 20.14230777, 14.71535368,  0.58468726,  0.77260039,
        0.24744584]), 'targetState': array([25., 25., 15.])}
episode index:3955
target thresh 39.39910449173066
model initialize at round 3955
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89747565,  0.98302408,  0.15264349,
       -0.10180193]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6662336196713253
{'scaleFactor': 20, 'currentState': array([25.31675228, 20.18273343, 13.9425372 ,  0.59581713,  0.79664367,
        0.10178806]), 'targetState': array([25., 25., 15.])}
episode index:3956
target thresh 39.40516427828712
model initialize at round 3956
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6663055823779791
{'scaleFactor': 20, 'currentState': array([25.20103022, 20.17877522, 13.08123913,  0.59282292,  0.80430216,
       -0.04073112]), 'targetState': array([25., 25., 15.])}
episode index:3957
target thresh 39.41122345889519
model initialize at round 3957
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6663775087214663
{'scaleFactor': 20, 'currentState': array([25.26115438, 20.18644477, 13.74963471,  0.58762535,  0.79010723,
        0.17443338]), 'targetState': array([25., 25., 15.])}
episode index:3958
target thresh 39.41728203361553
model initialize at round 3958
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6664493987293416
{'scaleFactor': 20, 'currentState': array([25.34185928, 20.12626659, 13.96605707,  0.60928245,  0.7747806 ,
        0.16878955]), 'targetState': array([25., 25., 15.])}
episode index:3959
target thresh 39.42334000250868
model initialize at round 3959
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6665212524291323
{'scaleFactor': 20, 'currentState': array([2.52963356e+01, 2.01853893e+01, 1.36979411e+01, 5.98316833e-01,
       8.01191379e-01, 1.04567027e-02]), 'targetState': array([25., 25., 15.])}
episode index:3960
target thresh 39.429397365635225
model initialize at round 3960
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6665930698483372
{'scaleFactor': 20, 'currentState': array([25.2974346 , 20.18013322, 14.13214664,  0.58639726,  0.78619553,
        0.19502525]), 'targetState': array([25., 25., 15.])}
episode index:3961
target thresh 39.435454123055734
model initialize at round 3961
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85452805,  0.97790287,  0.15184827,
       -0.14369439]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6666648510144281
{'scaleFactor': 20, 'currentState': array([25.36491768, 20.1516516 , 14.25614587,  0.60014739,  0.78302576,
        0.16338227]), 'targetState': array([25., 25., 15.])}
episode index:3962
target thresh 39.44151027483079
model initialize at round 3962
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89107345,  0.98236869,  0.15254172,
       -0.1080869 ]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6667365959548484
{'scaleFactor': 20, 'currentState': array([25.29291445, 20.10685409, 15.5795585 ,  0.56476547,  0.76697688,
        0.30460865]), 'targetState': array([25., 25., 15.])}
episode index:3963
target thresh 39.44756582102096
model initialize at round 3963
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.91096103,  0.98427837,  0.15283826,
       -0.08852438]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6668083046970142
{'scaleFactor': 20, 'currentState': array([25.33608465, 20.17409818, 14.38863025,  0.58951422,  0.78757733,
        0.1794295 ]), 'targetState': array([25., 25., 15.])}
episode index:3964
target thresh 39.45362076168678
model initialize at round 3964
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86538032,  0.97935624,  0.15207395,
       -0.13317234]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6668799772683138
{'scaleFactor': 20, 'currentState': array([25.30932477, 20.13572579, 15.00199877,  0.56190526,  0.7596087 ,
        0.3275013 ]), 'targetState': array([25., 25., 15.])}
episode index:3965
target thresh 39.4596750968888
model initialize at round 3965
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.88369061,  0.98156544,  0.15241699,
       -0.11531846]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6669516136961081
{'scaleFactor': 20, 'currentState': array([25.2853295 , 20.09693647, 15.5922947 ,  0.54800369,  0.7486671 ,
        0.37308113]), 'targetState': array([25., 25., 15.])}
episode index:3966
target thresh 39.465728826687574
model initialize at round 3966
at step 0:
{'scaleFactor': 20, 'currentState': array([ 1.70000000e+01,  1.51537267e+01,  1.49966783e+01,  9.88152432e-01,
        1.53439819e-01, -3.31548111e-03]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.66702321400773
{'scaleFactor': 20, 'currentState': array([25.40197881, 20.16729573, 14.73030095,  0.59959468,  0.78821853,
        0.13855603]), 'targetState': array([25., 25., 15.])}
episode index:3967
target thresh 39.47178195114363
model initialize at round 3967
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87443066,  0.98048662,  0.15224948,
       -0.12436268]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6670947782304851
{'scaleFactor': 20, 'currentState': array([25.32552923, 20.17847168, 14.21988628,  0.59261477,  0.7912441 ,
        0.1507996 ]), 'targetState': array([25., 25., 15.])}
episode index:3968
target thresh 39.47783447031753
model initialize at round 3968
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6671663063916516
{'scaleFactor': 20, 'currentState': array([25.28838266, 20.18440675, 13.97725022,  0.59160989,  0.79295702,
        0.14566022]), 'targetState': array([25., 25., 15.])}
episode index:3969
target thresh 39.48388638426975
model initialize at round 3969
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6672354030775481
{'scaleFactor': 20, 'currentState': array([26.57378322, 21.55062557, 14.65018884,  0.47465698,  0.81163913,
        0.34050356]), 'targetState': array([25., 25., 15.])}
episode index:3970
target thresh 39.48993769306085
model initialize at round 3970
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87192493,  0.98018115,  0.15220204,
       -0.12680481]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6673068598004951
{'scaleFactor': 20, 'currentState': array([25.26185995, 20.18489765, 13.52283301,  0.59559551,  0.80093711,
        0.06136548]), 'targetState': array([25., 25., 15.])}
episode index:3971
target thresh 39.495988396751315
model initialize at round 3971
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6673782805432191
{'scaleFactor': 20, 'currentState': array([25.24361841, 20.17332397, 13.52404308,  0.60829806,  0.78296696,
        0.13013921]), 'targetState': array([25., 25., 15.])}
episode index:3972
target thresh 39.502038495401656
model initialize at round 3972
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87067058,  0.98002607,  0.15217796,
       -0.12802647]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6674496653328886
{'scaleFactor': 20, 'currentState': array([25.35477475, 20.13230023, 14.09894888,  0.59693871,  0.78645367,
        0.15860266]), 'targetState': array([25., 25., 15.])}
episode index:3973
target thresh 39.50808798907239
model initialize at round 3973
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85489078,  0.97795316,  0.15185608,
       -0.14334345]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6675210141966449
{'scaleFactor': 20, 'currentState': array([25.42617202, 20.02826939, 13.7728335 ,  0.62105115,  0.78301541,
        0.03438527]), 'targetState': array([25., 25., 15.])}
episode index:3974
target thresh 39.514136877824015
model initialize at round 3974
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6675923271616017
{'scaleFactor': 20, 'currentState': array([25.44783117, 20.03419124, 13.82987316,  0.66499372,  0.74341548,
        0.07153172]), 'targetState': array([25., 25., 15.])}
episode index:3975
target thresh 39.520185161716995
model initialize at round 3975
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6676636042548458
{'scaleFactor': 20, 'currentState': array([25.22385569, 20.15767212, 13.18634424,  0.60935339,  0.79245881,
        0.02640992]), 'targetState': array([25., 25., 15.])}
episode index:3976
target thresh 39.52623284081183
model initialize at round 3976
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6677324542787698
{'scaleFactor': 20, 'currentState': array([26.56239797, 21.61733916, 14.32421388,  0.50262217,  0.82810294,
        0.24822668]), 'targetState': array([25., 25., 15.])}
episode index:3977
target thresh 39.532279915168985
model initialize at round 3977
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15090623, 14.87586589,  0.98107265,  0.14954543,
       -0.12301472]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6678012696872972
{'scaleFactor': 20, 'currentState': array([26.62638504, 21.48829874, 15.58168229,  0.54778298,  0.78851414,
        0.27960555]), 'targetState': array([25., 25., 15.])}
episode index:3978
target thresh 39.53832638484896
model initialize at round 3978
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09227799, 14.9219153 ,  0.99262776,  0.09252292,
       -0.07829196]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6678700505065266
{'scaleFactor': 20, 'currentState': array([27.15494735, 20.57097245, 14.69160471,  0.55099576,  0.77910117,
        0.29900677]), 'targetState': array([25., 25., 15.])}
episode index:3979
target thresh 39.544372249912165
model initialize at round 3979
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13941046, 14.89169681,  0.98447057,  0.13863181,
       -0.10769829]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6679387967625302
{'scaleFactor': 20, 'currentState': array([27.29308274, 20.71747279, 13.96898703,  0.62075717,  0.77262053,
        0.13310919]), 'targetState': array([25., 25., 15.])}
episode index:3980
target thresh 39.55041751041912
model initialize at round 3980
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.88945284,  0.98219671,  0.15251502,
       -0.10967581]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6680075084813542
{'scaleFactor': 20, 'currentState': array([26.65172182, 21.52390104, 13.37431639,  0.52694921,  0.84852707,
        0.04823215]), 'targetState': array([25., 25., 15.])}
episode index:3981
target thresh 39.55646216643024
model initialize at round 3981
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.668078573911143
{'scaleFactor': 20, 'currentState': array([ 2.52090857e+01,  2.01789222e+01,  1.31195256e+01,  5.93674116e-01,
        8.04425529e-01, -2.12276572e-02]), 'targetState': array([25., 25., 15.])}
episode index:3982
target thresh 39.562506218005986
model initialize at round 3982
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6681496036565582
{'scaleFactor': 20, 'currentState': array([25.3582448 , 20.13106034, 14.35169024,  0.61380394,  0.76800214,
        0.18280436]), 'targetState': array([25., 25., 15.])}
episode index:3983
target thresh 39.568549665206774
model initialize at round 3983
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6682205977444707
{'scaleFactor': 20, 'currentState': array([2.54129961e+01, 2.00058110e+01, 1.33704501e+01, 6.98167680e-01,
       7.15908424e-01, 6.08440561e-03]), 'targetState': array([25., 25., 15.])}
episode index:3984
target thresh 39.574592508093076
model initialize at round 3984
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.06031336, 14.84627329,  0.98637209,  0.06009234,
       -0.15316337]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6682891697775087
{'scaleFactor': 20, 'currentState': array([27.25250148, 20.2968149 , 13.33875512,  0.65467091,  0.74543194,
        0.1254481 ]), 'targetState': array([25., 25., 15.])}
episode index:3985
target thresh 39.58063474672531
model initialize at round 3985
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.07193297, 14.87153102,  0.98912075,  0.07186909,
       -0.12835489]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6683553454368488
{'scaleFactor': 20, 'currentState': array([29.62819958, 20.18793509, 13.29756154,  0.742055  ,  0.66630215,
        0.07345627]), 'targetState': array([25., 25., 15.])}
episode index:3986
target thresh 39.586676381163876
model initialize at round 3986
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.09840296, 14.84627329,  0.98342563,  0.09774949,
       -0.15270584]), 'targetState': array([25., 25., 15.])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6684214879004732
{'scaleFactor': 20, 'currentState': array([29.52527336, 20.44452216, 14.05245827,  0.68486416,  0.71152489,
        0.15714139]), 'targetState': array([25., 25., 15.])}
episode index:3987
target thresh 39.5927174114692
model initialize at round 3987
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.1514583 , 14.86118456,  0.97913828,  0.14979659,
       -0.13729243]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6684923426050869
{'scaleFactor': 20, 'currentState': array([25.29750372, 20.08696483, 15.41290697,  0.56050553,  0.75886118,
        0.33160709]), 'targetState': array([25., 25., 15.])}
episode index:3988
target thresh 39.59875783770171
model initialize at round 3988
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89770618,  0.98304696,  0.15264704,
       -0.10157538]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6685631617846546
{'scaleFactor': 20, 'currentState': array([25.3143351 , 20.14732188, 14.81377558,  0.56688751,  0.76396017,
        0.30822623]), 'targetState': array([25., 25., 15.])}
episode index:3989
target thresh 39.6047976599218
model initialize at round 3989
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.95897318,  0.98733036,  0.15331217,
       -0.04091619]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6686339454658865
{'scaleFactor': 20, 'currentState': array([25.33393961, 20.12475213, 15.87482011,  0.56946728,  0.76937543,
        0.28942783]), 'targetState': array([25., 25., 15.])}
episode index:3990
target thresh 39.61083687818987
model initialize at round 3990
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.94672274,  0.98676361,  0.15322416,
       -0.05310309]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6687046936754666
{'scaleFactor': 20, 'currentState': array([25.34642463, 20.15074702, 14.96909535,  0.57470053,  0.77081227,
        0.2748959 ]), 'targetState': array([25., 25., 15.])}
episode index:3991
target thresh 39.616875492566294
model initialize at round 3991
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.86047889,  0.97871297,  0.15197406,
       -0.13793043]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.668775406440052
{'scaleFactor': 20, 'currentState': array([25.30597325, 20.16784615, 14.43158701,  0.57756529,  0.77565098,
        0.2545268 ]), 'targetState': array([25., 25., 15.])}
episode index:3992
target thresh 39.62291350311148
model initialize at round 3992
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.87779511,  0.98088773,  0.15231176,
       -0.12108008]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6688460837862729
{'scaleFactor': 20, 'currentState': array([25.38291543, 20.07555786, 14.96535941,  0.61475119,  0.73423261,
        0.28806847]), 'targetState': array([25., 25., 15.])}
episode index:3993
target thresh 39.628950909885795
model initialize at round 3993
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.10928739, 14.84627329,  0.98233061,  0.10844075,
       -0.15253581]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6689143446940382
{'scaleFactor': 20, 'currentState': array([27.1222503 , 20.73005122, 14.15905137,  0.58349106,  0.78262285,
        0.21688626]), 'targetState': array([25., 25., 15.])}
episode index:3994
target thresh 39.63498771294963
model initialize at round 3994
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.85717121,  0.97826662,  0.15190475,
       -0.141136  ]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6689849518793213
{'scaleFactor': 20, 'currentState': array([25.3641983 , 20.09491657, 14.19923042,  0.59568332,  0.77484057,
        0.21162104]), 'targetState': array([25., 25., 15.])}
episode index:3995
target thresh 39.64102391236334
model initialize at round 3995
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.89449885,  0.98272412,  0.15259691,
       -0.10472578]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6690555237256729
{'scaleFactor': 20, 'currentState': array([ 2.54532957e+01,  2.00403400e+01,  1.40196681e+01,  6.41250623e-01,
        7.67318301e-01, -4.50152223e-03]), 'targetState': array([25., 25., 15.])}
episode index:3996
target thresh 39.647059508187276
model initialize at round 3996
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14280559, 14.84627329,  0.97826978,  0.14111353,
       -0.15190525]), 'targetState': array([25., 25., 15.])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.669126060259617
{'scaleFactor': 20, 'currentState': array([25.32892295, 20.08207886, 13.64059264,  0.60479561,  0.79234941,
        0.08002931]), 'targetState': array([25., 25., 15.])}
episode index:3997
target thresh 39.653094500481814
model initialize at round 3997
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.13527313, 14.84627329,  0.97927173,  0.13380723,
       -0.15206083]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.669194182843194
{'scaleFactor': 20, 'currentState': array([26.76669297, 21.44596402, 14.42307275,  0.56563532,  0.81479356,
        0.12715402]), 'targetState': array([25., 25., 15.])}
episode index:3998
target thresh 39.6591288893073
model initialize at round 3998
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.15372671, 14.84627329,  0.97672671,  0.15166564,
       -0.15166564]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6692622713569619
{'scaleFactor': 20, 'currentState': array([27.2664212 , 20.7785628 , 13.76951833,  0.66848924,  0.7423678 ,
        0.04485737]), 'targetState': array([25., 25., 15.])}
episode index:3999
target thresh 39.665162674724066
model initialize at round 3999
at step 0:
{'scaleFactor': 20, 'currentState': array([17.        , 15.14709908, 14.84627329,  0.97767584,  0.1452679 ,
       -0.15181302]), 'targetState': array([25., 25., 15.])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.6693303258264729
{'scaleFactor': 20, 'currentState': array([26.31938444, 21.62660325, 12.50686084,  0.48396792,  0.87461436,
        0.02871891]), 'targetState': array([25., 25., 15.])}

Process finished with exit code 0
