/home/yangyutu/anaconda3/bin/python /home/yangyutu/Dropbox/pythonScripts/DeepReinforcementLearning-PyTorch/Env/CustomEnv/TwoArmRobot/TD3Solver/TD3_TwoArmRobot.py
episode index:0
target Thresh 0.19999999999999996
current state at start:  [-0.98465263  1.86208971]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.98465263,  1.86208971]), 'currentState': array([5.031209  , 1.68384509]), 'targetState': array([ 1.10738439, -0.08869697]), 'effectorPosition': array([ 1.22163139, -0.53103721])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.0
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([-0.98465263,  1.86208971]), 'currentState': array([5.03643479, 5.84026465]), 'targetState': array([ 1.10738439, -0.08869697]), 'effectorPosition': array([ 0.19980933, -1.94089768])}
episode index:1
target Thresh 0.2035964023988004
current state at start:  [-3.80904119  1.6834153 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.80904119,  1.6834153 ]), 'currentState': array([1.97414412, 1.9448675 ]), 'targetState': array([-1.25713821, -0.27367696]), 'effectorPosition': array([-1.10522603,  0.21830996])}
done in step count: 134
reward sum = 0.26008546137772603
running average episode reward sum: 0.13004273068886302
{'reset': False, 'endBeforeDone': False, 'stepCount': 135, 'initial state': array([-3.80904119,  1.6834153 ]), 'currentState': array([4.05139323, 4.80323499]), 'targetState': array([-1.25713821, -0.27367696]), 'effectorPosition': array([-1.45572334, -0.24962322])}
episode index:2
target Thresh 0.20718561918081524
current state at start:  [-1.41383875 -2.18395188]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.41383875, -2.18395188]), 'currentState': array([4.36934656, 3.88388016]), 'targetState': array([-0.67207245, -0.52746686]), 'effectorPosition': array([-0.72507671, -0.02038099])}
done in step count: 120
reward sum = 0.2993803913123313
running average episode reward sum: 0.18648861756335244
{'reset': False, 'endBeforeDone': False, 'stepCount': 121, 'initial state': array([-1.41383875, -2.18395188]), 'currentState': array([4.78715408, 4.07977999]), 'targetState': array([-0.67207245, -0.52746686]), 'effectorPosition': array([-0.77370297, -0.4678482 ])}
episode index:3
target Thresh 0.2107676647029164
current state at start:  [-1.34322146  3.13345721]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.34322146,  3.13345721]), 'currentState': array([4.69843544, 2.81663969]), 'targetState': array([-0.00610476,  0.06198092]), 'effectorPosition': array([ 0.31850291, -0.05678388])}
done in step count: 14
reward sum = 0.8687458127689782
running average episode reward sum: 0.3570529163647589
{'reset': False, 'endBeforeDone': False, 'stepCount': 15, 'initial state': array([-1.34322146,  3.13345721]), 'currentState': array([5.72107163, 3.23262433]), 'targetState': array([-0.00610476,  0.06198092]), 'effectorPosition': array([-0.04494728, -0.07912513])}
episode index:4
target Thresh 0.21434255329329077
current state at start:  [ 0.74266461 -2.87037964]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.74266461, -2.87037964]), 'currentState': array([1.05588642, 3.07017707]), 'targetState': array([ 0.2148658 , -0.10728816]), 'effectorPosition': array([-0.06084753,  0.03735767])}
done in step count: 81
reward sum = 0.4430479816261725
running average episode reward sum: 0.3742519294170416
{'reset': False, 'endBeforeDone': False, 'stepCount': 82, 'initial state': array([ 0.74266461, -2.87037964]), 'currentState': array([5.24510599, 2.79987997]), 'targetState': array([ 0.2148658 , -0.10728816]), 'effectorPosition': array([0.31803068, 0.12038372])}
episode index:5
target Thresh 0.2179102992514974
current state at start:  [ 3.2504581 -2.6014481]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.2504581, -2.6014481]), 'currentState': array([2.75773815, 3.73383523]), 'targetState': array([-0.25030115,  0.45170597]), 'effectorPosition': array([0.05113764, 0.58138036])}
done in step count: 114
reward sum = 0.3179890638191435
running average episode reward sum: 0.36487478515072524
{'reset': False, 'endBeforeDone': False, 'stepCount': 115, 'initial state': array([ 3.2504581, -2.6014481]), 'currentState': array([0.50993418, 2.65141278]), 'targetState': array([-0.25030115,  0.45170597]), 'effectorPosition': array([-0.12702825,  0.46836678])}
episode index:6
target Thresh 0.22147091684852493
current state at start:  [-0.80641094  2.71589618]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.80641094,  2.71589618]), 'currentState': array([5.15108249, 2.76841373]), 'targetState': array([0.26693411, 0.30198713]), 'effectorPosition': array([0.35928932, 0.09254731])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.4556069587006216
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.80641094,  2.71589618]), 'currentState': array([5.15108249, 2.76841373]), 'targetState': array([0.26693411, 0.30198713]), 'effectorPosition': array([0.35928932, 0.09254731])}
episode index:7
target Thresh 0.22502442032684855
current state at start:  [ 2.65480148 -1.73463899]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.65480148, -1.73463899]), 'currentState': array([2.78835451, 4.53142726]), 'targetState': array([-0.19332545,  1.29145937]), 'effectorPosition': array([-0.4291049 ,  1.20661412])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.522406088863044
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 2.65480148, -1.73463899]), 'currentState': array([2.47299292, 4.49212405]), 'targetState': array([-0.19332545,  1.29145937]), 'effectorPosition': array([-0.00833379,  1.25018168])}
episode index:8
target Thresh 0.22857082390048666
current state at start:  [-0.18569575  3.04305323]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.18569575,  3.04305323]), 'currentState': array([5.59748956, 2.95157883]), 'targetState': array([-0.05014253, -0.01683083]), 'effectorPosition': array([0.13352661, 0.13478648])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.5754720789893724
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.18569575,  3.04305323]), 'currentState': array([5.59748956, 2.95157883]), 'targetState': array([-0.05014253, -0.01683083]), 'effectorPosition': array([0.13352661, 0.13478648])}
episode index:9
target Thresh 0.23211014175505862
current state at start:  [-0.51867812 -2.04803804]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.51867812, -2.04803804]), 'currentState': array([5.26450719, 4.10562259]), 'targetState': array([-0.06576196, -1.01652268]), 'effectorPosition': array([-0.47401528, -0.79679446])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.5179248710904352
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([-0.51867812, -2.04803804]), 'currentState': array([1.5584802 , 5.17904547]), 'targetState': array([-0.06576196, -1.01652268]), 'effectorPosition': array([0.91086653, 1.43879385])}
episode index:10
target Thresh 0.23564238804784043
current state at start:  [-3.74725126  2.17906405]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.74725126,  2.17906405]), 'currentState': array([2.19211428, 2.03304842]), 'targetState': array([-0.78443547, -0.46790329]), 'effectorPosition': array([-1.05028405, -0.07052288])}
done in step count: 74
reward sum = 0.47534004200570695
running average episode reward sum: 0.5140535229918235
{'reset': False, 'endBeforeDone': False, 'stepCount': 75, 'initial state': array([-3.74725126,  2.17906405]), 'currentState': array([2.49217185, 2.34809135]), 'targetState': array([-0.78443547, -0.46790329]), 'effectorPosition': array([-0.66890818, -0.38711001])}
episode index:11
target Thresh 0.23916757690782187
current state at start:  [ 1.22124507 -2.16082025]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.22124507, -2.16082025]), 'currentState': array([1.2148624 , 3.96311024]), 'targetState': array([0.96396019, 0.05668111]), 'effectorPosition': array([0.79741032, 0.04376177])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.5545490627425048
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.22124507, -2.16082025]), 'currentState': array([1.2148624 , 3.96311024]), 'targetState': array([0.96396019, 0.05668111]), 'effectorPosition': array([0.79741032, 0.04376177])}
episode index:12
target Thresh 0.24268572243576325
current state at start:  [-0.49812842  3.0372041 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.49812842,  3.0372041 ]), 'currentState': array([5.28505689, 2.5372041 ]), 'targetState': array([0.03305459, 0.04347507]), 'effectorPosition': array([0.57359156, 0.15903865])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.5850445232930814
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([-0.49812842,  3.0372041 ]), 'currentState': array([3.10244544, 2.98837692]), 'targetState': array([0.03305459, 0.04347507]), 'effectorPosition': array([-0.01767861, -0.15204157])}
episode index:13
target Thresh 0.24619683870425102
current state at start:  [ 1.84129198 -2.63291604]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.84129198, -2.63291604]), 'currentState': array([2.02624193, 3.80516001]), 'targetState': array([0.35574176, 0.22818531]), 'effectorPosition': array([0.45980743, 0.46149444])}
done in step count: 104
reward sum = 0.35160920655802225
running average episode reward sum: 0.56837057209772
{'reset': False, 'endBeforeDone': False, 'stepCount': 105, 'initial state': array([ 1.84129198, -2.63291604]), 'currentState': array([5.02605024, 2.62997906]), 'targetState': array([0.35574176, 0.22818531]), 'effectorPosition': array([0.50520539, 0.02926104])}
episode index:14
target Thresh 0.24970093975775565
current state at start:  [-3.69482413  1.73290546]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.69482413,  1.73290546]), 'currentState': array([2.35881685, 1.6014856 ]), 'targetState': array([-1.23993995, -0.42680585]), 'effectorPosition': array([-1.39212261, -0.02501495])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.5304792006245387
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([-3.69482413,  1.73290546]), 'currentState': array([1.40389151, 6.06498069]), 'targetState': array([-1.23993995, -0.42680585]), 'effectorPosition': array([0.54179154, 1.91286102])}
episode index:15
target Thresh 0.2531980396126854
current state at start:  [-0.88330298 -2.92337409]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.88330298, -2.92337409]), 'currentState': array([4.89988233, 2.85981121]), 'targetState': array([-0.05661128, -0.15902397]), 'effectorPosition': array([0.28054521, 0.01308362])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.557967938085505
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-0.88330298, -2.92337409]), 'currentState': array([3.68569191, 2.87921081]), 'targetState': array([-0.05661128, -0.15902397]), 'effectorPosition': array([ 0.1049855 , -0.23964186])}
episode index:16
target Thresh 0.25668815225744424
current state at start:  [ 3.55302695 -2.64638203]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.55302695, -2.64638203]), 'currentState': array([3.40352288, 3.7038138 ]), 'targetState': array([-0.22939252,  0.37273695]), 'effectorPosition': array([-0.28671188,  0.47502625])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.5839698240804754
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.55302695, -2.64638203]), 'currentState': array([3.40352288, 3.7038138 ]), 'targetState': array([-0.22939252,  0.37273695]), 'effectorPosition': array([-0.28671188,  0.47502625])}
episode index:17
target Thresh 0.2601712916524881
current state at start:  [ 4.08914413 -2.04599663]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.08914413, -2.04599663]), 'currentState': array([3.9137161 , 4.13454864]), 'targetState': array([-1.0062673 ,  0.14989225]), 'effectorPosition': array([-0.90949402,  0.28352822])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6070826116315601
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.08914413, -2.04599663]), 'currentState': array([3.9137161 , 4.13454864]), 'targetState': array([-1.0062673 ,  0.14989225]), 'effectorPosition': array([-0.90949402,  0.28352822])}
episode index:18
target Thresh 0.2636474717303785
current state at start:  [2.0257462  1.60355642]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.0257462 , 1.60355642]), 'currentState': array([1.85125524, 1.67956766]), 'targetState': array([-1.28850729,  0.41435659]), 'effectorPosition': array([-1.2019981 ,  0.58145217])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6277624741772674
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.0257462 , 1.60355642]), 'currentState': array([1.85125524, 1.67956766]), 'targetState': array([-1.28850729,  0.41435659]), 'effectorPosition': array([-1.2019981 ,  0.58145217])}
episode index:19
target Thresh 0.26711670639584084
current state at start:  [-0.88324351  2.9445481 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.88324351,  2.9445481 ]), 'currentState': array([5.15260193, 3.12807629]), 'targetState': array([0.17356977, 0.02997271]), 'effectorPosition': array([0.01226628, 0.00567695])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6463743504684041
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.88324351,  2.9445481 ]), 'currentState': array([5.15260193, 3.12807629]), 'targetState': array([0.17356977, 0.02997271]), 'effectorPosition': array([0.01226628, 0.00567695])}
episode index:20
target Thresh 0.27057900952581826
current state at start:  [-3.75469388  2.99769275]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.75469388,  2.99769275]), 'currentState': array([2.37075573, 3.41260354]), 'targetState': array([-0.12677317, -0.11275669]), 'effectorPosition': array([0.16033815, 0.21746297])}
done in step count: 30
reward sum = 0.7397003733882802
running average episode reward sum: 0.650818446797922
{'reset': False, 'endBeforeDone': False, 'stepCount': 31, 'initial state': array([-3.75469388,  2.99769275]), 'currentState': array([4.23272846, 3.12798099]), 'targetState': array([-0.12677317, -0.11275669]), 'effectorPosition': array([ 0.01203248, -0.00636347])}
episode index:21
target Thresh 0.27403439496952786
current state at start:  [1.7384549  2.71591589]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.7384549 , 2.71591589]), 'currentState': array([1.59958088, 2.92048845]), 'targetState': array([-0.33548404, -0.04428295]), 'effectorPosition': array([-0.21991687,  0.01802225])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6666903355798346
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.7384549 , 2.71591589]), 'currentState': array([1.59958088, 2.92048845]), 'targetState': array([-0.33548404, -0.04428295]), 'effectorPosition': array([-0.21991687,  0.01802225])}
episode index:22
target Thresh 0.277482876548516
current state at start:  [-1.80755879  2.5811055 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.80755879,  2.5811055 ]), 'currentState': array([4.26961441, 3.0811055 ]), 'targetState': array([ 0.57137456, -0.14316878]), 'effectorPosition': array([ 0.0538373 , -0.02755224])}
done in step count: 43
reward sum = 0.6491026283684022
running average episode reward sum: 0.6659256526575984
{'reset': False, 'endBeforeDone': False, 'stepCount': 44, 'initial state': array([-1.80755879,  2.5811055 ]), 'currentState': array([4.9217008 , 2.59273186]), 'targetState': array([ 0.57137456, -0.14316878]), 'effectorPosition': array([ 0.54084864, -0.03526916])}
episode index:23
target Thresh 0.28092446805671356
current state at start:  [ 4.21013175 -2.88328962]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.21013175, -2.88328962]), 'currentState': array([3.92006384, 2.92235022]), 'targetState': array([-0.35940474,  0.10123283]), 'effectorPosition': array([ 0.13567665, -0.17165915])}
done in step count: 16
reward sum = 0.8514577710948755
running average episode reward sum: 0.673656157592485
{'reset': False, 'endBeforeDone': False, 'stepCount': 17, 'initial state': array([ 4.21013175, -2.88328962]), 'currentState': array([4.21185198, 3.36791991]), 'targetState': array([-0.35940474,  0.10123283]), 'effectorPosition': array([-0.20911044,  0.0853145 ])}
episode index:24
target Thresh 0.2843591832604915
current state at start:  [ 3.27705555 -2.1692366 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.27705555, -2.1692366 ]), 'currentState': array([3.19902327, 3.87549648]), 'targetState': array([-0.45138687,  0.63861728]), 'effectorPosition': array([-0.29545455,  0.65389283])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6867099112887856
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.27705555, -2.1692366 ]), 'currentState': array([3.19902327, 3.87549648]), 'targetState': array([-0.45138687,  0.63861728]), 'effectorPosition': array([-0.29545455,  0.65389283])}
episode index:25
target Thresh 0.2877870358987147
current state at start:  [-0.24374073 -1.8638597 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.24374073, -1.8638597 ]), 'currentState': array([5.66404004, 3.9193256 ]), 'targetState': array([ 0.34265555, -1.2088009 ]), 'effectorPosition': array([-0.17307652, -0.73826307])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.6602979916238323
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([-0.24374073, -1.8638597 ]), 'currentState': array([2.3164571 , 4.96911073]), 'targetState': array([ 0.34265555, -1.2088009 ]), 'effectorPosition': array([-0.14016144,  1.57739564])}
episode index:26
target Thresh 0.29120803968279874
current state at start:  [ 0.18356552 -2.42875049]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.18356552, -2.42875049]), 'currentState': array([6.25205069, 3.63406562]), 'targetState': array([ 0.37745215, -0.524061  ]), 'effectorPosition': array([ 0.10405782, -0.47627653])}
done in step count: 41
reward sum = 0.6622820409839835
running average episode reward sum: 0.6603714749334674
{'reset': False, 'endBeforeDone': False, 'stepCount': 42, 'initial state': array([ 0.18356552, -2.42875049]), 'currentState': array([4.09459055, 2.72070767]), 'targetState': array([ 0.37745215, -0.524061  ]), 'effectorPosition': array([ 0.28249505, -0.30780042])}
episode index:27
target Thresh 0.2946222082967629
current state at start:  [-0.10430876 -2.19934038]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.10430876, -2.19934038]), 'currentState': array([5.70274147, 3.58384493]), 'targetState': array([ 0.29913454, -0.70519682]), 'effectorPosition': array([-0.1542474 , -0.41064299])}
done in step count: 115
reward sum = 0.31480917318095203
running average episode reward sum: 0.6480299641565919
{'reset': False, 'endBeforeDone': False, 'stepCount': 116, 'initial state': array([-0.10430876, -2.19934038]), 'currentState': array([3.85228713, 2.53996205]), 'targetState': array([ 0.29913454, -0.70519682]), 'effectorPosition': array([ 0.23614942, -0.54351249])}
episode index:28
target Thresh 0.2980295553972867
current state at start:  [ 0.38408145 -2.86395689]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.38408145, -2.86395689]), 'currentState': array([6.16726675, 3.40572606]), 'targetState': array([ 0.07432224, -0.18663411]), 'effectorPosition': array([ 0.00425269, -0.26333192])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6601668619442955
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.38408145, -2.86395689]), 'currentState': array([6.16726675, 3.40572606]), 'targetState': array([ 0.07432224, -0.18663411]), 'effectorPosition': array([ 0.00425269, -0.26333192])}
episode index:29
target Thresh 0.3014300946137627
current state at start:  [ 1.76737792 -2.99651408]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.76737792, -2.99651408]), 'currentState': array([1.42186905, 3.22774319]), 'targetState': array([0.00495091, 0.11184322]), 'effectorPosition': array([ 0.08564185, -0.00909937])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.671494633212819
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.76737792, -2.99651408]), 'currentState': array([1.42186905, 3.22774319]), 'targetState': array([0.00495091, 0.11184322]), 'effectorPosition': array([ 0.08564185, -0.00909937])}
episode index:30
target Thresh 0.30482383954835224
current state at start:  [-1.90827004  2.65404767]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.90827004,  2.65404767]), 'currentState': array([3.94837933, 2.60491421]), 'targetState': array([ 0.53095257, -0.22084276]), 'effectorPosition': array([ 0.27191979, -0.45523211])}
done in step count: 22
reward sum = 0.8016305895390459
running average episode reward sum: 0.6756925672878585
{'reset': False, 'endBeforeDone': False, 'stepCount': 23, 'initial state': array([-1.90827004,  2.65404767]), 'currentState': array([4.70778645, 2.78551929]), 'targetState': array([ 0.53095257, -0.22084276]), 'effectorPosition': array([ 0.34830421, -0.0643309 ])}
episode index:31
target Thresh 0.30821080377604004
current state at start:  [0.08469324 1.83925571]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.08469324, 1.83925571]), 'currentState': array([5.86787855, 1.90793832]), 'targetState': array([0.76940647, 1.11597478]), 'effectorPosition': array([0.99307779, 0.59347606])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.654577174560113
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([0.08469324, 1.83925571]), 'currentState': array([4.20275312, 3.76551356]), 'targetState': array([0.76940647, 1.11597478]), 'effectorPosition': array([-0.60189585,  0.12055436])}
episode index:32
target Thresh 0.31159100084468694
current state at start:  [0.57709703 2.58953218]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.57709703, 2.58953218]), 'currentState': array([0.30312279, 3.08953218]), 'targetState': array([-0.19991917,  0.41321257]), 'effectorPosition': array([-0.01424007,  0.05006896])}
done in step count: 16
reward sum = 0.8514577710948755
running average episode reward sum: 0.6605432532429846
{'reset': False, 'endBeforeDone': False, 'stepCount': 17, 'initial state': array([0.57709703, 2.58953218]), 'currentState': array([3.77616388, 3.66689897]), 'targetState': array([-0.19991917,  0.41321257]), 'effectorPosition': array([-0.40587417,  0.32392193])}
episode index:33
target Thresh 0.3149644442750861
current state at start:  [-0.77820278 -3.07119582]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.77820278, -3.07119582]), 'currentState': array([5.00498253, 3.34889016]), 'targetState': array([-0.09905674,  0.05293803]), 'effectorPosition': array([-0.19089342, -0.07986424])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6705272752064262
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.77820278, -3.07119582]), 'currentState': array([5.00498253, 3.34889016]), 'targetState': array([-0.09905674,  0.05293803]), 'effectorPosition': array([-0.19089342, -0.07986424])}
episode index:34
target Thresh 0.31833114756101555
current state at start:  [ 1.43431781 -2.72373409]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.43431781, -2.72373409]), 'currentState': array([1.34141574, 3.28028952]), 'targetState': array([ 0.29222461, -0.0942651 ]), 'effectorPosition': array([ 0.1368149 , -0.02208363])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6799407816290998
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.43431781, -2.72373409]), 'currentState': array([1.34141574, 3.28028952]), 'targetState': array([ 0.29222461, -0.0942651 ]), 'effectorPosition': array([ 0.1368149 , -0.02208363])}
episode index:35
target Thresh 0.321691124169293
current state at start:  [-2.70613739  2.64200664]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.70613739,  2.64200664]), 'currentState': array([3.29948614, 2.48183078]), 'targetState': array([-0.00501121, -0.60328393]), 'effectorPosition': array([-0.11087542, -0.63830261])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6888313154727359
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.70613739,  2.64200664]), 'currentState': array([3.29948614, 2.48183078]), 'targetState': array([-0.00501121, -0.60328393]), 'effectorPosition': array([-0.11087542, -0.63830261])}
episode index:36
target Thresh 0.32504438753982967
current state at start:  [ 3.43606043 -1.93231138]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.43606043, -1.93231138]), 'currentState': array([3.00674564, 4.31231757]), 'targetState': array([-1.02804339,  0.81894678]), 'effectorPosition': array([-0.48115105,  0.99474894])}
done in step count: 179
reward sum = 0.16546259566473476
running average episode reward sum: 0.6746862149373846
{'reset': False, 'endBeforeDone': False, 'stepCount': 180, 'initial state': array([ 3.43606043, -1.93231138]), 'currentState': array([3.19372247, 4.59732928]), 'targetState': array([-1.02804339,  0.81894678]), 'effectorPosition': array([-0.93575319,  0.94591436])}
episode index:37
target Thresh 0.32839095108568306
current state at start:  [ 3.69773726 -2.04906128]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.69773726, -2.04906128]), 'currentState': array([3.19773726, 4.32131738]), 'targetState': array([-1.00897387,  0.45007119]), 'effectorPosition': array([-0.66972409,  0.8883192 ])}
done in step count: 102
reward sum = 0.3587482976818919
running average episode reward sum: 0.6663720592201348
{'reset': False, 'endBeforeDone': False, 'stepCount': 103, 'initial state': array([ 3.69773726, -2.04906128]), 'currentState': array([3.6739955 , 4.17081511]), 'targetState': array([-1.00897387,  0.45007119]), 'effectorPosition': array([-0.85241897,  0.49235287])}
episode index:38
target Thresh 0.33173082819311195
current state at start:  [-0.8842008  -1.70809123]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.8842008 , -1.70809123]), 'currentState': array([5.45164461, 4.55213064]), 'targetState': array([-0.1844292 , -1.40115869]), 'effectorPosition': array([-0.16327371, -1.28615521])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6749266218042339
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.8842008 , -1.70809123]), 'currentState': array([5.45164461, 4.55213064]), 'targetState': array([-0.1844292 , -1.40115869]), 'effectorPosition': array([-0.16327371, -1.28615521])}
episode index:39
target Thresh 0.33506403222162917
current state at start:  [ 1.86778102 -2.86340958]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.86778102, -2.86340958]), 'currentState': array([1.84617709, 3.66756381]), 'targetState': array([0.23332389, 0.21377207]), 'effectorPosition': array([0.44638396, 0.26658547])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6830534562591281
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.86778102, -2.86340958]), 'currentState': array([1.84617709, 3.66756381]), 'targetState': array([0.23332389, 0.21377207]), 'effectorPosition': array([0.44638396, 0.26658547])}
episode index:40
target Thresh 0.3383905765040556
current state at start:  [ 2.15638532 -2.34491092]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.15638532, -2.34491092]), 'currentState': array([2.01827616, 3.80463343]), 'targetState': array([0.39394805, 0.73572689]), 'effectorPosition': array([0.46323518, 0.45734528])}
done in step count: 88
reward sum = 0.41294967113388814
running average episode reward sum: 0.6764655590609514
{'reset': False, 'endBeforeDone': False, 'stepCount': 89, 'initial state': array([ 2.15638532, -2.34491092]), 'currentState': array([1.95786016, 4.19735073]), 'targetState': array([0.39394805, 0.73572689]), 'effectorPosition': array([0.61435135, 0.79839598])}
episode index:41
target Thresh 0.3417104743465722
current state at start:  [ 2.68655435 -2.13439064]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.68655435, -2.13439064]), 'currentState': array([2.69371163, 4.02877082]), 'targetState': array([-0.11601411,  0.85384571]), 'effectorPosition': array([0.00368405, 0.85835998])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6841687600356907
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.68655435, -2.13439064]), 'currentState': array([2.69371163, 4.02877082]), 'targetState': array([-0.11601411,  0.85384571]), 'effectorPosition': array([0.00368405, 0.85835998])}
episode index:42
target Thresh 0.3450237390287756
current state at start:  [ 0.65608327 -2.27762489]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.65608327, -2.27762489]), 'currentState': array([0.78025374, 4.20749872]), 'targetState': array([ 0.82581177, -0.4679379 ]), 'effectorPosition': array([ 0.9826318 , -0.25886665])}
done in step count: 29
reward sum = 0.7471720943315961
running average episode reward sum: 0.6856339538565257
{'reset': False, 'endBeforeDone': False, 'stepCount': 30, 'initial state': array([ 0.65608327, -2.27762489]), 'currentState': array([4.54117854, 2.34321606]), 'targetState': array([ 0.82581177, -0.4679379 ]), 'effectorPosition': array([ 0.65427697, -0.41973913])}
episode index:43
target Thresh 0.3483303838037284
current state at start:  [0.96025734 2.62868115]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.96025734, 2.62868115]), 'currentState': array([0.64328363, 2.98554968]), 'targetState': array([-0.29393586,  0.44420063]), 'effectorPosition': array([-0.08349765,  0.13163656])}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.690605502064532
{'reset': False, 'endBeforeDone': False, 'stepCount': 11, 'initial state': array([0.96025734, 2.62868115]), 'currentState': array([3.70657853, 3.77592893]), 'targetState': array([-0.29393586,  0.44420063]), 'effectorPosition': array([-0.48160671,  0.39638936])}
episode index:44
target Thresh 0.35163042189801375
current state at start:  [0.53266029 2.18422427]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.53266029, 2.18422427]), 'currentState': array([0.1922202 , 2.68422427]), 'targetState': array([-0.08019343,  1.05853607]), 'effectorPosition': array([0.01652883, 0.45309095])}
done in step count: 37
reward sum = 0.6894490858690777
running average episode reward sum: 0.6905798039268553
{'reset': False, 'endBeforeDone': False, 'stepCount': 38, 'initial state': array([0.53266029, 2.18422427]), 'currentState': array([2.82839019, 4.16136524]), 'targetState': array([-0.08019343,  1.05853607]), 'effectorPosition': array([-0.19075862,  0.95733573])}
episode index:45
target Thresh 0.3549238665117893
current state at start:  [ 0.28910293 -1.83107734]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.28910293, -1.83107734]), 'currentState': array([0.13213259, 4.10143966]), 'targetState': array([ 0.90242489, -0.82125071]), 'effectorPosition': array([ 0.53055388, -0.75579227])}
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.6946437434719013
{'reset': False, 'endBeforeDone': False, 'stepCount': 14, 'initial state': array([ 0.28910293, -1.83107734]), 'currentState': array([4.70816883, 1.80963121]), 'targetState': array([ 0.90242489, -0.82125071]), 'effectorPosition': array([ 0.96838384, -0.7675228 ])}
episode index:46
target Thresh 0.35821073081883736
current state at start:  [-3.07829245  1.68559118]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.07829245,  1.68559118]), 'currentState': array([2.79981778, 1.8092769 ]), 'targetState': array([-0.77822349, -0.88506147]), 'effectorPosition': array([-1.04527199, -0.65951005])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.6798640893554778
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([-3.07829245,  1.68559118]), 'currentState': array([3.08711888, 2.83016736]), 'targetState': array([-0.77822349, -0.88506147]), 'effectorPosition': array([-0.06471421, -0.30334215])}
episode index:47
target Thresh 0.36149102796661947
current state at start:  [ 1.61994211 -1.80246026]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.61994211, -1.80246026]), 'currentState': array([1.75819215, 4.0986678 ]), 'targetState': array([0.92059596, 0.86817567]), 'effectorPosition': array([0.72419052, 0.56896485])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.665700254160572
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([ 1.61994211, -1.80246026]), 'currentState': array([5.98413753, 3.01936179]), 'targetState': array([0.92059596, 0.86817567]), 'effectorPosition': array([0.04305064, 0.11431726])}
episode index:48
target Thresh 0.3647647710763289
current state at start:  [ 2.84540353 -2.95103541]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.84540353, -2.95103541]), 'currentState': array([2.50474072, 3.29743715]), 'targetState': array([-0.0519236 ,  0.05090116]), 'effectorPosition': array([0.08255747, 0.13199491])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6725226979532134
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.84540353, -2.95103541]), 'currentState': array([2.50474072, 3.29743715]), 'targetState': array([-0.0519236 ,  0.05090116]), 'effectorPosition': array([0.08255747, 0.13199491])}
episode index:49
target Thresh 0.36803197324294223
current state at start:  [ 2.73437436 -2.75419474]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.73437436, -2.75419474]), 'currentState': array([2.56449822, 3.60077536]), 'targetState': array([-0.01483292,  0.45459239]), 'effectorPosition': array([0.15500503, 0.42795254])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6790722439941491
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.73437436, -2.75419474]), 'currentState': array([2.56449822, 3.60077536]), 'targetState': array([-0.01483292,  0.45459239]), 'effectorPosition': array([0.15500503, 0.42795254])}
episode index:50
target Thresh 0.3712926475352729
current state at start:  [ 0.37298088 -2.36931852]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.37298088, -2.36931852]), 'currentState': array([0.45058295, 3.89806635]), 'targetState': array([ 0.65717807, -0.58531577]), 'effectorPosition': array([ 0.54442166, -0.49908251])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6853649450923031
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.37298088, -2.36931852]), 'currentState': array([0.45058295, 3.89806635]), 'targetState': array([ 0.65717807, -0.58531577]), 'effectorPosition': array([ 0.54442166, -0.49908251])}
episode index:51
target Thresh 0.37454680699602183
current state at start:  [-0.81260269  2.65113329]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.81260269,  2.65113329]), 'currentState': array([5.25806573, 3.13983446]), 'targetState': array([0.25090356, 0.07611845]), 'effectorPosition': array([0.00150367, 0.00091118])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.6910329269174511
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-0.81260269,  2.65113329]), 'currentState': array([5.46711709, 3.08532193]), 'targetState': array([0.25090356, 0.07611845]), 'effectorPosition': array([0.04205357, 0.03737722])}
episode index:52
target Thresh 0.3777944646418312
current state at start:  [ 1.39297587 -2.24406349]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.39297587, -2.24406349]), 'currentState': array([1.33450057, 3.78451009]), 'targetState': array([0.66101388, 0.0652673 ]), 'effectorPosition': array([0.62961166, 0.0537496 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.696862494334103
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.39297587, -2.24406349]), 'currentState': array([1.33450057, 3.78451009]), 'targetState': array([0.66101388, 0.0652673 ]), 'effectorPosition': array([0.62961166, 0.0537496 ])}
episode index:53
target Thresh 0.3810356334633367
current state at start:  [-1.31056224 -1.74171898]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.31056224, -1.74171898]), 'currentState': array([5.28533634, 4.05390269]), 'targetState': array([-0.54869841, -1.12672511]), 'effectorPosition': array([-0.45423269, -0.75487217])}
done in step count: 34
reward sum = 0.7105532272722921
running average episode reward sum: 0.6971160264255509
{'reset': False, 'endBeforeDone': False, 'stepCount': 35, 'initial state': array([-1.31056224, -1.74171898]), 'currentState': array([3.18055946, 1.90684269]), 'targetState': array([-0.54869841, -1.12672511]), 'effectorPosition': array([-0.63295611, -0.96945975])}
episode index:54
target Thresh 0.3842703264252172
current state at start:  [0.30043608 1.79428066]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.30043608, 1.79428066]), 'currentState': array([0.11883339, 1.85492624]), 'targetState': array([0.32180322, 1.32917597]), 'effectorPosition': array([0.60080161, 1.03845689])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.68444118958145
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([0.30043608, 1.79428066]), 'currentState': array([0.36115138, 3.95887003]), 'targetState': array([0.32180322, 1.32917597]), 'effectorPosition': array([ 0.55311347, -0.57065477])}
episode index:55
target Thresh 0.3874985564662492
current state at start:  [0.2151836  2.26716625]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.2151836 , 2.26716625]), 'currentState': array([6.21385624, 2.76716625]), 'targetState': array([0.19659394, 0.93247179]), 'effectorPosition': array([0.09445202, 0.36006068])}
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.6882072085935441
{'reset': False, 'endBeforeDone': False, 'stepCount': 12, 'initial state': array([0.2151836 , 2.26716625]), 'currentState': array([2.52086214, 4.26149883]), 'targetState': array([0.19659394, 0.93247179]), 'effectorPosition': array([0.06452368, 1.06033151])}
episode index:56
target Thresh 0.390720336499357
current state at start:  [-1.54445026  2.09438952]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.54445026,  2.09438952]), 'currentState': array([4.55398783, 2.20386775]), 'targetState': array([ 0.92117706, -0.64786687]), 'effectorPosition': array([ 0.73170389, -0.53043555])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6936772575655872
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.54445026,  2.09438952]), 'currentState': array([4.55398783, 2.20386775]), 'targetState': array([ 0.92117706, -0.64786687]), 'effectorPosition': array([ 0.73170389, -0.53043555])}
episode index:57
target Thresh 0.3939356794116651
current state at start:  [ 0.19843118 -2.31101373]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.19843118, -2.31101373]), 'currentState': array([0.18267198, 3.87329608]), 'targetState': array([ 0.49105955, -0.51013144]), 'effectorPosition': array([ 0.37307634, -0.61052382])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.698958684159284
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.19843118, -2.31101373]), 'currentState': array([0.18267198, 3.87329608]), 'targetState': array([ 0.49105955, -0.51013144]), 'effectorPosition': array([ 0.37307634, -0.61052382])}
episode index:58
target Thresh 0.39714459806454916
current state at start:  [ 4.13343955 -2.64002007]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.13343955, -2.64002007]), 'currentState': array([4.07868161, 3.94154108]), 'targetState': array([-0.6423913 , -0.02217215]), 'effectorPosition': array([-0.75761277,  0.18037596])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.7040610793430249
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.13343955, -2.64002007]), 'currentState': array([4.07868161, 3.94154108]), 'targetState': array([-0.6423913 , -0.02217215]), 'effectorPosition': array([-0.75761277,  0.18037596])}
episode index:59
target Thresh 0.40034710529368867
current state at start:  [1.04528854 2.84122607]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.04528854, 2.84122607]), 'currentState': array([1.45087783, 3.34122607]), 'targetState': array([-0.21320667,  0.12871868]), 'effectorPosition': array([ 0.19926181, -0.00400606])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.7080180638439911
{'reset': False, 'endBeforeDone': False, 'stepCount': 7, 'initial state': array([1.04528854, 2.84122607]), 'currentState': array([2.09441161, 3.08629699]), 'targetState': array([-0.21320667,  0.12871868]), 'effectorPosition': array([-0.04862682, -0.0263109 ])}
episode index:60
target Thresh 0.4035432139091164
current state at start:  [ 1.48381385 -2.08490096]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.48381385, -2.08490096]), 'currentState': array([1.32441545, 3.69828435]), 'targetState': array([0.96229509, 0.54400999]), 'effectorPosition': array([0.54925036, 0.01756275])}
done in step count: 110
reward sum = 0.33103308832101386
running average episode reward sum: 0.7018379822780407
{'reset': False, 'endBeforeDone': False, 'stepCount': 111, 'initial state': array([ 1.48381385, -2.08490096]), 'currentState': array([5.63035285, 2.22840961]), 'targetState': array([0.96229509, 0.54400999]), 'effectorPosition': array([0.78958564, 0.39254973])}
episode index:61
target Thresh 0.4067329366952712
current state at start:  [-1.28232153 -2.99086439]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.28232153, -2.99086439]), 'currentState': array([5.19530941, 2.9509374 ]), 'targetState': array([-0.13541079,  0.12166899]), 'effectorPosition': array([0.17624553, 0.07195114])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.706167998692911
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-1.28232153, -2.99086439]), 'currentState': array([4.75480291, 3.06651077]), 'targetState': array([-0.13541079,  0.12166899]), 'effectorPosition': array([0.07506335, 0.00036579])}
episode index:62
target Thresh 0.4099162864110484
current state at start:  [ 0.77389246 -2.83222843]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.77389246, -2.83222843]), 'currentState': array([1.22008493, 3.18414065]), 'targetState': array([ 0.10008241, -0.02818507]), 'effectorPosition': array([ 0.04025692, -0.0137637 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.7108319987136584
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.77389246, -2.83222843]), 'currentState': array([1.22008493, 3.18414065]), 'targetState': array([ 0.10008241, -0.02818507]), 'effectorPosition': array([ 0.04025692, -0.0137637 ])}
episode index:63
target Thresh 0.4130932757898511
current state at start:  [-1.84512747  2.92986568]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.84512747,  2.92986568]), 'currentState': array([4.58238828, 2.60677745]), 'targetState': array([ 0.2830855 , -0.26909252]), 'effectorPosition': array([ 0.48727942, -0.20453143])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.7153502487337575
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.84512747,  2.92986568]), 'currentState': array([4.58238828, 2.60677745]), 'targetState': array([ 0.2830855 , -0.26909252]), 'effectorPosition': array([ 0.48727942, -0.20453143])}
episode index:64
target Thresh 0.4162639175396412
current state at start:  [-0.31988739  2.35148012]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.31988739,  2.35148012]), 'currentState': array([5.61546199, 2.67681417]), 'targetState': array([0.30719216, 0.37582874]), 'effectorPosition': array([0.36083761, 0.28627691])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.7197294756763151
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.31988739,  2.35148012]), 'currentState': array([5.61546199, 2.67681417]), 'targetState': array([0.30719216, 0.37582874]), 'effectorPosition': array([0.36083761, 0.28627691])}
episode index:65
target Thresh 0.41942822434298965
current state at start:  [-2.95120539  2.66152602]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.95120539,  2.66152602]), 'currentState': array([2.98289876, 2.84777797]), 'targetState': array([-0.0572866, -0.5201155]), 'effectorPosition': array([-0.0880814 , -0.27919435])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.7239759987721285
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.95120539,  2.66152602]), 'currentState': array([2.98289876, 2.84777797]), 'targetState': array([-0.0572866, -0.5201155]), 'effectorPosition': array([-0.0880814 , -0.27919435])}
episode index:66
target Thresh 0.42258620885712816
current state at start:  [ 3.97306684 -2.04559195]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.97306684, -2.04559195]), 'currentState': array([3.47306684, 4.16050209]), 'targetState': array([-0.97643693,  0.40829431]), 'effectorPosition': array([-0.72693125,  0.65036998])}
done in step count: 22
reward sum = 0.8016305895390459
running average episode reward sum: 0.7251350225149183
{'reset': False, 'endBeforeDone': False, 'stepCount': 23, 'initial state': array([ 3.97306684, -2.04559195]), 'currentState': array([1.88396374, 2.07266104]), 'targetState': array([-0.97643693,  0.40829431]), 'effectorPosition': array([-0.99391855,  0.22361491])}
episode index:67
target Thresh 0.4257378837139987
current state at start:  [-0.67812016  3.02312214]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.67812016,  3.02312214]), 'currentState': array([5.36997299, 2.56537709]), 'targetState': array([ 0.04180948, -0.11290709]), 'effectorPosition': array([0.52992776, 0.2052202 ])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.7285976840955813
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([-0.67812016,  3.02312214]), 'currentState': array([4.79661962, 3.08040229]), 'targetState': array([ 0.04180948, -0.11290709]), 'effectorPosition': array([0.06109284, 0.00327989])}
episode index:68
target Thresh 0.4288832615203053
current state at start:  [-1.01767489 -3.03606178]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.01767489, -3.03606178]), 'currentState': array([5.51118024, 2.98064436]), 'targetState': array([-0.08086777, -0.15989837]), 'effectorPosition': array([0.12104952, 0.10580877])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.7318207618608628
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([-1.01767489, -3.03606178]), 'currentState': array([4.7631189 , 3.07165287]), 'targetState': array([-0.08086777, -0.15989837]), 'effectorPosition': array([0.06991684, 0.00110198])}
episode index:69
target Thresh 0.432022354857563
current state at start:  [-0.32301927  2.20731439]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.32301927,  2.20731439]), 'currentState': array([5.75786528, 2.70020522]), 'targetState': array([0.46139125, 0.63334596]), 'effectorPosition': array([0.29715106, 0.32153007])}
done in step count: 33
reward sum = 0.7177305325982749
running average episode reward sum: 0.7316194728713972
{'reset': False, 'endBeforeDone': False, 'stepCount': 34, 'initial state': array([-0.32301927,  2.20731439]), 'currentState': array([2.42856956, 3.91937077]), 'targetState': array([0.46139125, 0.63334596]), 'effectorPosition': array([0.24151627, 0.71883317])}
episode index:70
target Thresh 0.4351551762821495
current state at start:  [-4.14869566  2.2906725 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.14869566,  2.2906725 ]), 'currentState': array([2.18554745, 2.6037695 ]), 'targetState': array([-0.92020442, -0.27785234]), 'effectorPosition': array([-0.49990312, -0.18012549])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.7348444945210959
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([-4.14869566,  2.2906725 ]), 'currentState': array([2.43969444, 2.35492232]), 'targetState': array([-0.92020442, -0.27785234]), 'effectorPosition': array([-0.6814828 , -0.35095284])}
episode index:71
target Thresh 0.4382817383253548
current state at start:  [-3.74151925  2.9577839 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.74151925,  2.9577839 ]), 'currentState': array([2.63507671, 2.58727529]), 'targetState': array([-0.06001746, -0.32781963]), 'effectorPosition': array([-0.38629507, -0.38762896])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.7375836730403444
{'reset': False, 'endBeforeDone': False, 'stepCount': 8, 'initial state': array([-3.74151925,  2.9577839 ]), 'currentState': array([2.56298763, 2.82937198]), 'targetState': array([-0.06001746, -0.32781963]), 'effectorPosition': array([-0.20845613, -0.23073463])}
episode index:72
target Thresh 0.4414020534934311
current state at start:  [-2.47249734  2.49780987]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.47249734,  2.49780987]), 'currentState': array([3.55935259, 2.4061725 ]), 'targetState': array([ 0.33121803, -0.55730898]), 'effectorPosition': array([ 0.03596877, -0.71805875])}
done in step count: 22
reward sum = 0.8016305895390459
running average episode reward sum: 0.7384610280608745
{'reset': False, 'endBeforeDone': False, 'stepCount': 23, 'initial state': array([-2.47249734,  2.49780987]), 'currentState': array([4.0469095 , 2.64948299]), 'targetState': array([ 0.33121803, -0.55730898]), 'effectorPosition': array([ 0.29840132, -0.38507218])}
episode index:73
target Thresh 0.4445161342676429
current state at start:  [-2.50298257  2.49520205]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.50298257,  2.49520205]), 'currentState': array([3.73716559, 2.66429226]), 'targetState': array([-0.00341297, -0.82505446]), 'effectorPosition': array([ 0.16518672, -0.44298614])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.7417264195735654
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-2.50298257,  2.49520205]), 'currentState': array([3.31945309, 2.49021638]), 'targetState': array([-0.00341297, -0.82505446]), 'effectorPosition': array([-0.09425398, -0.63294226])}
episode index:74
target Thresh 0.447623993104318
current state at start:  [-1.99563489  3.00035976]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.99563489,  3.00035976]), 'currentState': array([4.06974007, 2.78910321]), 'targetState': array([-0.01975832, -0.26212061]), 'effectorPosition': array([ 0.23951627, -0.25612419])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.7450367339792513
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.99563489,  3.00035976]), 'currentState': array([3.85781763, 2.85780484]), 'targetState': array([-0.01975832, -0.26212061]), 'effectorPosition': array([ 0.15365751, -0.23745704])}
episode index:75
target Thresh 0.450725642434896
current state at start:  [-1.77921752 -2.05718886]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.77921752, -2.05718886]), 'currentState': array([4.47137687, 3.72599645]), 'targetState': array([-0.8230262 , -0.20136262]), 'effectorPosition': array([-0.5753683 , -0.02947873])}
done in step count: 50
reward sum = 0.6050060671375364
running average episode reward sum: 0.7431942252050182
{'reset': False, 'endBeforeDone': False, 'stepCount': 51, 'initial state': array([-1.77921752, -2.05718886]), 'currentState': array([2.08985285, 2.52044928]), 'targetState': array([-0.8230262 , -0.20136262]), 'effectorPosition': array([-0.59797078, -0.12650607])}
episode index:76
target Thresh 0.45382109466597775
current state at start:  [-2.04710064  2.94604646]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.04710064,  2.94604646]), 'currentState': array([3.92924532, 3.0309879 ]), 'targetState': array([-0.00413608,  0.00992054]), 'effectorPosition': array([ 0.07391477, -0.08220433])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.7465293651374205
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.04710064,  2.94604646]), 'currentState': array([3.92924532, 3.0309879 ]), 'targetState': array([-0.00413608,  0.00992054]), 'effectorPosition': array([ 0.07391477, -0.08220433])}
episode index:77
target Thresh 0.4569103621793764
current state at start:  [0.95436917 2.68346506]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.95436917, 2.68346506]), 'currentState': array([1.06497814, 2.80541308]), 'targetState': array([-0.3521721 ,  0.34599025]), 'effectorPosition': array([-0.26145173,  0.20880446])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.7497789886612998
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.95436917, 2.68346506]), 'currentState': array([1.06497814, 2.80541308]), 'targetState': array([-0.3521721 ,  0.34599025]), 'effectorPosition': array([-0.26145173,  0.20880446])}
episode index:78
target Thresh 0.4599934573321667
current state at start:  [-0.22253845 -2.36803981]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.22253845, -2.36803981]), 'currentState': array([6.17784077, 3.4151455 ]), 'targetState': array([ 0.03393226, -0.72942809]), 'effectorPosition': array([ 0.00857009, -0.27256602])}
done in step count: 69
reward sum = 0.4998370298991989
running average episode reward sum: 0.7466151663984884
{'reset': False, 'endBeforeDone': False, 'stepCount': 70, 'initial state': array([-0.22253845, -2.36803981]), 'currentState': array([3.3114962 , 2.55150755]), 'targetState': array([ 0.03393226, -0.72942809]), 'effectorPosition': array([-0.07258619, -0.57701351])}
episode index:79
target Thresh 0.463070392456733
current state at start:  [ 0.9365177  -1.93669827]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.9365177 , -1.93669827]), 'currentState': array([1.30454115, 3.91917192]), 'targetState': array([ 1.33560258, -0.24760387]), 'effectorPosition': array([0.75245283, 0.09266565])}
done in step count: 40
reward sum = 0.6689717585696803
running average episode reward sum: 0.7456446238006282
{'reset': False, 'endBeforeDone': False, 'stepCount': 41, 'initial state': array([ 0.9365177 , -1.93669827]), 'currentState': array([5.51029017, 1.4520983 ]), 'targetState': array([ 1.33560258, -0.24760387]), 'effectorPosition': array([ 1.49396577, -0.07003753])}
episode index:80
target Thresh 0.4661411798608195
current state at start:  [-0.42009268  2.86274442]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.42009268,  2.86274442]), 'currentState': array([5.73401041, 2.71021506]), 'targetState': array([-0.00503304,  0.28784886]), 'effectorPosition': array([0.29639188, 0.30882136])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.7485391346179044
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-0.42009268,  2.86274442]), 'currentState': array([5.59946595, 2.83065268]), 'targetState': array([-0.00503304,  0.28784886]), 'effectorPosition': array([0.23044004, 0.20689268])}
episode index:81
target Thresh 0.4692058318275807
current state at start:  [-0.53710069 -2.32136198]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.53710069, -2.32136198]), 'currentState': array([6.06494523, 3.46182332]), 'targetState': array([-0.21272563, -0.95139627]), 'effectorPosition': array([-0.01852346, -0.31832565])}
done in step count: 77
reward sum = 0.46122196741809546
running average episode reward sum: 0.7450352667252239
{'reset': False, 'endBeforeDone': False, 'stepCount': 78, 'initial state': array([-0.53710069, -2.32136198]), 'currentState': array([3.29655045, 2.2283183 ]), 'targetState': array([-0.21272563, -0.95139627]), 'effectorPosition': array([-0.2620233 , -0.84203865])}
episode index:82
target Thresh 0.4722643606156278
current state at start:  [ 1.73196986 -1.80125181]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.73196986, -1.80125181]), 'currentState': array([1.83475785, 3.9819335 ]), 'targetState': array([0.81479031, 1.09026778]), 'effectorPosition': array([0.63224374, 0.51560633])}
done in step count: 59
reward sum = 0.5526834771623851
running average episode reward sum: 0.7427177752847077
{'reset': False, 'endBeforeDone': False, 'stepCount': 60, 'initial state': array([ 1.73196986, -1.80125181]), 'currentState': array([0.24570133, 1.66206384]), 'targetState': array([0.81479031, 1.09026778]), 'effectorPosition': array([0.63933905, 1.18699783])}
episode index:83
target Thresh 0.4753167784590806
current state at start:  [-3.58405967  2.06443643]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.58405967,  2.06443643]), 'currentState': array([2.60102003, 2.56443643]), 'targetState': array([-0.64457871, -0.46510424]), 'effectorPosition': array([-0.41968854, -0.38448157])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.7457806589122707
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.58405967,  2.06443643]), 'currentState': array([2.60102003, 2.56443643]), 'targetState': array([-0.64457871, -0.46510424]), 'effectorPosition': array([-0.41968854, -0.38448157])}
episode index:84
target Thresh 0.4783630975676143
current state at start:  [-4.07485087  2.56753932]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.07485087,  2.56753932]), 'currentState': array([2.19374652, 3.06753932]), 'targetState': array([-0.46693253, -0.26398084]), 'effectorPosition': array([-0.06168727, -0.04093985])}
done in step count: 14
reward sum = 0.8687458127689782
running average episode reward sum: 0.7472273077811732
{'reset': False, 'endBeforeDone': False, 'stepCount': 15, 'initial state': array([-4.07485087,  2.56753932]), 'currentState': array([1.99835817, 2.65788599]), 'targetState': array([-0.46693253, -0.26398084]), 'effectorPosition': array([-0.4707687 , -0.08844485])}
episode index:85
target Thresh 0.48140333012650927
current state at start:  [-0.63385104  2.88813722]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.63385104,  2.88813722]), 'currentState': array([5.20163776, 2.87147757]), 'targetState': array([ 0.17484412, -0.05752065]), 'effectorPosition': array([0.25257881, 0.09339998])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.7501665251325549
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.63385104,  2.88813722]), 'currentState': array([5.20163776, 2.87147757]), 'targetState': array([ 0.17484412, -0.05752065]), 'effectorPosition': array([0.25257881, 0.09339998])}
episode index:86
target Thresh 0.4844374882967002
current state at start:  [-4.4500986  3.0535075]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.4500986,  3.0535075]), 'currentState': array([1.84160788, 3.00655685]), 'targetState': array([-0.21421938,  0.07796703]), 'effectorPosition': array([-0.13215454, -0.02724251])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.7530381742689624
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.4500986,  3.0535075]), 'currentState': array([1.84160788, 3.00655685]), 'targetState': array([-0.21421938,  0.07796703]), 'effectorPosition': array([-0.13215454, -0.02724251])}
episode index:87
target Thresh 0.48746558421482344
current state at start:  [-2.88606976  2.79116804]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.88606976,  2.79116804]), 'currentState': array([3.30918645, 2.96690964]), 'targetState': array([-0.15317027, -0.38532248]), 'effectorPosition': array([ 0.01398587, -0.1738995 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.7557309222886331
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.88606976,  2.79116804]), 'currentState': array([3.19412172, 2.8388204 ]), 'targetState': array([-0.15317027, -0.38532248]), 'effectorPosition': array([-0.02976844, -0.30014449])}
episode index:88
target Thresh 0.4904876299932668
current state at start:  [ 2.3080109  -2.76350355]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.3080109 , -2.76350355]), 'currentState': array([2.070558  , 3.30969605]), 'targetState': array([0.43134017, 0.44553561]), 'effectorPosition': array([0.14009479, 0.09255116])}
done in step count: 20
reward sum = 0.8179069375972308
running average episode reward sum: 0.7564295292022128
{'reset': False, 'endBeforeDone': False, 'stepCount': 21, 'initial state': array([ 2.3080109 , -2.76350355]), 'currentState': array([2.49262825, 3.64742446]), 'targetState': array([0.43134017, 0.44553561]), 'effectorPosition': array([0.19306391, 0.46171729])}
episode index:89
target Thresh 0.4935036377202173
current state at start:  [ 2.14430869 -2.68552851]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.14430869, -2.68552851]), 'currentState': array([2.02254597, 3.23049162]), 'targetState': array([0.26953475, 0.20236292]), 'effectorPosition': array([0.07815187, 0.04230966])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.7591358677666327
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.14430869, -2.68552851]), 'currentState': array([2.02254597, 3.23049162]), 'targetState': array([0.26953475, 0.20236292]), 'effectorPosition': array([0.07815187, 0.04230966])}
episode index:90
target Thresh 0.4965136194597104
current state at start:  [ 3.16445795 -3.00689939]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.16445795, -3.00689939]), 'currentState': array([3.10203523, 3.43083665]), 'targetState': array([0.03117997, 0.34719847]), 'effectorPosition': array([-0.03022779,  0.28664737])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.7617827263626038
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.16445795, -3.00689939]), 'currentState': array([3.10203523, 3.43083665]), 'targetState': array([0.03117997, 0.34719847]), 'effectorPosition': array([-0.03022779,  0.28664737])}
episode index:91
target Thresh 0.4995175872516764
current state at start:  [-1.74404414 -1.83706122]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.74404414, -1.83706122]), 'currentState': array([4.66034043, 4.0847045 ]), 'targetState': array([-0.97457857, -0.66447967]), 'effectorPosition': array([-0.82976561, -0.37006036])}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.7634320146356586
{'reset': False, 'endBeforeDone': False, 'stepCount': 10, 'initial state': array([-1.74404414, -1.83706122]), 'currentState': array([4.50738368, 4.42055286]), 'targetState': array([-0.97457857, -0.66447967]), 'effectorPosition': array([-1.08266483, -0.50240867])}
episode index:92
target Thresh 0.5025155531119907
current state at start:  [ 3.09400042 -1.97395821]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.09400042, -1.97395821]), 'currentState': array([3.01724577, 4.80922709]), 'targetState': array([-0.80302397,  1.12048866]), 'effectorPosition': array([-0.96477358,  1.12364834])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.7659757564137697
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.09400042, -1.97395821]), 'currentState': array([3.01724577, 4.80922709]), 'targetState': array([-0.80302397,  1.12048866]), 'effectorPosition': array([-0.96477358,  1.12364834])}
episode index:93
target Thresh 0.5055075290325213
current state at start:  [-0.76284664 -2.91388721]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.76284664, -2.91388721]), 'currentState': array([5.33178554, 3.42323595]), 'targetState': array([-0.11413439,  0.04840565]), 'effectorPosition': array([-0.20342894, -0.19343384])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.7683589930476658
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.76284664, -2.91388721]), 'currentState': array([5.19287776, 3.33178965]), 'targetState': array([-0.11413439,  0.04840565]), 'effectorPosition': array([-0.1593107 , -0.10337348])}
episode index:94
target Thresh 0.5084935269811748
current state at start:  [-1.88211344  2.13325828]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.88211344,  2.13325828]), 'currentState': array([4.06802394, 1.9381279 ]), 'targetState': array([ 0.86186993, -0.92893531]), 'effectorPosition': array([ 0.3611801 , -1.07298478])}
done in step count: 20
reward sum = 0.8179069375972308
running average episode reward sum: 0.7688805503587137
{'reset': False, 'endBeforeDone': False, 'stepCount': 21, 'initial state': array([-1.88211344,  2.13325828]), 'currentState': array([4.3611011 , 1.84833929]), 'targetState': array([ 0.86186993, -0.92893531]), 'effectorPosition': array([ 0.65317475, -1.01260841])}
episode index:95
target Thresh 0.5114735589019479
current state at start:  [ 0.31165736 -2.72707228]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.31165736, -2.72707228]), 'currentState': array([0.78840231, 3.86047885]), 'targetState': array([-0.04257058, -0.50435801]), 'effectorPosition': array([ 0.6415142 , -0.28875622])}
done in step count: 86
reward sum = 0.421334222154768
running average episode reward sum: 0.7652602761065893
{'reset': False, 'endBeforeDone': False, 'stepCount': 87, 'initial state': array([ 0.31165736, -2.72707228]), 'currentState': array([2.95820096, 2.67875249]), 'targetState': array([-0.04257058, -0.50435801]), 'effectorPosition': array([-0.18487225, -0.41981692])}
episode index:96
target Thresh 0.5144476367149717
current state at start:  [-2.92404183  2.97892487]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.92404183,  2.97892487]), 'currentState': array([3.28368425, 2.80877796]), 'targetState': array([-0.03823062, -0.01431936]), 'effectorPosition': array([-0.00805455, -0.33118287])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.7674751186209543
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-2.92404183,  2.97892487]), 'currentState': array([2.82432795, 2.91555204]), 'targetState': array([-0.03823062, -0.01431936]), 'effectorPosition': array([-0.09408768, -0.20499923])}
episode index:97
target Thresh 0.5174157723165616
current state at start:  [ 4.44236357 -2.91052768]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.44236357, -2.91052768]), 'currentState': array([4.37114907, 2.91202819]), 'targetState': array([-0.14338517,  0.06364438]), 'effectorPosition': array([ 0.20565331, -0.10087381])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.7697457806758425
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 4.44236357, -2.91052768]), 'currentState': array([4.26341054, 3.08661976]), 'targetState': array([-0.14338517,  0.06364438]), 'effectorPosition': array([ 0.04884396, -0.02520963])}
episode index:98
target Thresh 0.5203779775792643
current state at start:  [0.39989077 1.64424608]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.39989077, 1.64424608]), 'currentState': array([0.66269125, 1.94930915]), 'targetState': array([0.45438416, 1.28015251]), 'effectorPosition': array([-0.07467381,  1.12042219])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.761970570770026
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([0.39989077, 1.64424608]), 'currentState': array([0.36785231, 2.43558875]), 'targetState': array([0.45438416, 1.28015251]), 'effectorPosition': array([-0.01026765,  0.69135617])}
episode index:99
target Thresh 0.5233342643519041
current state at start:  [-2.42289866  2.86586842]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.42289866,  2.86586842]), 'currentState': array([3.65909066, 3.24490089]), 'targetState': array([-0.03631019, -0.14969686]), 'effectorPosition': array([-0.05564991,  0.08698384])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.7643508650623256
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.42289866,  2.86586842]), 'currentState': array([3.65909066, 3.24490089]), 'targetState': array([-0.03631019, -0.14969686]), 'effectorPosition': array([-0.05564991,  0.08698384])}
episode index:100
target Thresh 0.5262846444596327
current state at start:  [ 1.5500839  -2.36289836]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.5500839 , -2.36289836]), 'currentState': array([1.24089458, 3.76998853]), 'targetState': array([0.85422615, 0.19244602]), 'effectorPosition': array([ 0.61803133, -0.00970624])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.7665850149131936
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.5500839 , -2.36289836]), 'currentState': array([1.19141486, 4.0995272 ]), 'targetState': array([0.85422615, 0.19244602]), 'effectorPosition': array([0.91715906, 0.09163917])}
episode index:101
target Thresh 0.5292291297039742
current state at start:  [ 3.59607137 -1.59096913]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.59607137, -1.59096913]), 'currentState': array([3.6760483 , 4.97557296]), 'targetState': array([-1.19058042,  0.23072474]), 'effectorPosition': array([-1.57625564,  0.18902532])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.7682073711190152
{'reset': False, 'endBeforeDone': False, 'stepCount': 8, 'initial state': array([ 3.59607137, -1.59096913]), 'currentState': array([3.83134524, 4.3079055 ]), 'targetState': array([-1.19058042,  0.23072474]), 'effectorPosition': array([-1.05281917,  0.32323961])}
episode index:102
target Thresh 0.532167731862873
current state at start:  [-1.41787039 -2.98679181]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.41787039, -2.98679181]), 'currentState': array([4.89589657, 3.35815842]), 'targetState': array([-0.41496701,  0.07770168]), 'effectorPosition': array([-0.20700652, -0.06217725])}
done in step count: 29
reward sum = 0.7471720943315961
running average episode reward sum: 0.7680031451307878
{'reset': False, 'endBeforeDone': False, 'stepCount': 30, 'initial state': array([-1.41787039, -2.98679181]), 'currentState': array([4.30058799, 3.76311639]), 'targetState': array([-0.41496701,  0.07770168]), 'effectorPosition': array([-0.60844914,  0.06168723])}
episode index:103
target Thresh 0.5351004626907427
current state at start:  [ 2.27258068 -1.59408493]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.27258068, -1.59408493]), 'currentState': array([1.83536505, 4.4798513 ]), 'targetState': array([0.08052262, 1.20913618]), 'effectorPosition': array([0.73799403, 0.99723093])}
done in step count: 78
reward sum = 0.4566097477439145
running average episode reward sum: 0.7650089778482217
{'reset': False, 'endBeforeDone': False, 'stepCount': 79, 'initial state': array([ 2.27258068, -1.59408493]), 'currentState': array([2.30019023, 4.59372798]), 'targetState': array([0.08052262, 1.20913618]), 'effectorPosition': array([0.15281007, 1.31904648])}
episode index:104
target Thresh 0.5380273339185098
current state at start:  [-2.7378106   2.72901193]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.7378106 ,  2.72901193]), 'currentState': array([3.55028169, 3.21142972]), 'targetState': array([ 0.29865231, -0.29751358]), 'effectorPosition': array([-0.02996802,  0.06306466])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.7671517494877624
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.7378106 ,  2.72901193]), 'currentState': array([3.72636699, 2.94588909]), 'targetState': array([ 0.29865231, -0.29751358]), 'effectorPosition': array([ 0.09142527, -0.17268243])}
episode index:105
target Thresh 0.5409483572536633
current state at start:  [-1.73931886 -2.6265284 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.73931886, -2.6265284 ]), 'currentState': array([4.47590087, 4.03986936]), 'targetState': array([-0.64385225,  0.08046963]), 'effectorPosition': array([-0.84881878, -0.18327242])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.7692540914737269
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.73931886, -2.6265284 ]), 'currentState': array([4.46609088, 3.92009131]), 'targetState': array([-0.64385225,  0.08046963]), 'effectorPosition': array([-0.75124622, -0.10812912])}
episode index:106
target Thresh 0.5438635443803004
current state at start:  [ 2.39912844 -2.59400086]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.39912844, -2.59400086]), 'currentState': array([2.10216374, 3.48930458]), 'targetState': array([0.084814  , 0.36725933]), 'effectorPosition': array([0.26343927, 0.22425453])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.7714105952917294
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.39912844, -2.59400086]), 'currentState': array([2.10216374, 3.48930458]), 'targetState': array([0.084814  , 0.36725933]), 'effectorPosition': array([0.26343927, 0.22425453])}
episode index:107
target Thresh 0.5467729069591734
current state at start:  [ 1.9678853  -1.84833171]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.9678853 , -1.84833171]), 'currentState': array([1.85220946, 4.14935667]), 'targetState': array([0.84760318, 0.97618412]), 'effectorPosition': array([0.68289324, 0.68275255])}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.7726418126965171
{'reset': False, 'endBeforeDone': False, 'stepCount': 11, 'initial state': array([ 1.9678853 , -1.84833171]), 'currentState': array([1.96301762, 4.35623841]), 'targetState': array([0.84760318, 0.97618412]), 'effectorPosition': array([0.61710755, 0.96012517])}
episode index:108
target Thresh 0.5496764566277366
current state at start:  [-3.76616802  1.89734317]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.76616802,  1.89734317]), 'currentState': array([2.90523367, 2.07371229]), 'targetState': array([-1.11137776, -0.2956025 ]), 'effectorPosition': array([-0.70878544, -0.73051914])}
done in step count: 16
reward sum = 0.8514577710948755
running average episode reward sum: 0.773364894883658
{'reset': False, 'endBeforeDone': False, 'stepCount': 17, 'initial state': array([-3.76616802,  1.89734317]), 'currentState': array([2.39662127, 2.13476645]), 'targetState': array([-1.11137776, -0.2956025 ]), 'effectorPosition': array([-0.91512187, -0.30571317])}
episode index:109
target Thresh 0.5525742050001927
current state at start:  [-2.57100969  2.73595551]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.57100969,  2.73595551]), 'currentState': array([3.6904969 , 2.83942335]), 'targetState': array([ 0.1622986 , -0.47172763]), 'effectorPosition': array([ 0.1166183 , -0.27751366])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.7754252140210792
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.57100969,  2.73595551]), 'currentState': array([3.6904969 , 2.83942335]), 'targetState': array([ 0.1622986 , -0.47172763]), 'effectorPosition': array([ 0.1166183 , -0.27751366])}
episode index:110
target Thresh 0.5554661636675386
current state at start:  [-2.07459613  1.87402317]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.07459613,  1.87402317]), 'currentState': array([3.7476354 , 2.27592745]), 'targetState': array([ 0.29102058, -0.89787989]), 'effectorPosition': array([ 0.1445784 , -0.82633511])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.7774484102911596
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.07459613,  1.87402317]), 'currentState': array([3.7476354 , 2.27592745]), 'targetState': array([ 0.29102058, -0.89787989]), 'effectorPosition': array([ 0.1445784 , -0.82633511])}
episode index:111
target Thresh 0.5583523441976135
current state at start:  [ 3.47842232 -1.94493116]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.47842232, -1.94493116]), 'currentState': array([3.66230083, 4.38260006]), 'targetState': array([-1.00701456,  0.45560002]), 'effectorPosition': array([-1.05722861,  0.48433562])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.7794354780564171
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.47842232, -1.94493116]), 'currentState': array([3.66230083, 4.38260006]), 'targetState': array([-1.00701456,  0.45560002]), 'effectorPosition': array([-1.05722861,  0.48433562])}
episode index:112
target Thresh 0.5612327581351428
current state at start:  [-1.54760415 -2.08627146]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.54760415, -2.08627146]), 'currentState': array([4.5595121 , 4.18530766]), 'targetState': array([-1.13847428, -0.57330306]), 'effectorPosition': array([-0.92988109, -0.35957656])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.7812112702860063
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.54760415, -2.08627146]), 'currentState': array([4.63721168, 4.26527588]), 'targetState': array([-1.13847428, -0.57330306]), 'effectorPosition': array([-0.94178536, -0.49830903])}
episode index:113
target Thresh 0.5641074170017863
current state at start:  [ 4.1740578  -2.92644911]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.1740578 , -2.92644911]), 'currentState': array([4.14635826, 3.82912178]), 'targetState': array([-0.41143859,  0.21444119]), 'effectorPosition': array([-0.65748577,  0.14859186])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.7830427503712167
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 4.1740578 , -2.92644911]), 'currentState': array([4.14221898, 3.62203768]), 'targetState': array([-0.41143859,  0.21444119]), 'effectorPosition': array([-0.45017053,  0.15416819])}
episode index:114
target Thresh 0.5669763322961832
current state at start:  [0.6200648  1.66317122]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.6200648 , 1.66317122]), 'currentState': array([1.1200648 , 2.16317122]), 'targetState': array([-0.02868114,  1.18068336]), 'effectorPosition': array([-0.55436122,  0.75895846])}
done in step count: 15
reward sum = 0.8600583546412884
running average episode reward sum: 0.7837124512779129
{'reset': False, 'endBeforeDone': False, 'stepCount': 16, 'initial state': array([0.6200648 , 1.66317122]), 'currentState': array([2.32450537, 4.46539507]), 'targetState': array([-0.02868114,  1.18068336]), 'effectorPosition': array([0.18999546, 1.21446339])}
episode index:115
target Thresh 0.5698395154939986
current state at start:  [-1.9885304   1.98752881]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.9885304 ,  1.98752881]), 'currentState': array([4.56003877, 2.01356462]), 'targetState': array([ 0.78453272, -1.03988533]), 'effectorPosition': array([ 0.8063627, -0.7020643])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.7854907922151723
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.9885304 ,  1.98752881]), 'currentState': array([4.3254789 , 1.78083185]), 'targetState': array([ 0.78453272, -1.03988533]), 'effectorPosition': array([ 0.60706972, -1.10203315])}
episode index:116
target Thresh 0.5726969780479694
current state at start:  [ 1.39845719 -2.58937262]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.39845719, -2.58937262]), 'currentState': array([1.43856632, 3.46222784]), 'targetState': array([ 0.44593457, -0.01408574]), 'effectorPosition': array([0.31913755, 0.00896616])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.7873242042475213
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.39845719, -2.58937262]), 'currentState': array([1.43856632, 3.46222784]), 'targetState': array([ 0.44593457, -0.01408574]), 'effectorPosition': array([0.31913755, 0.00896616])}
episode index:117
target Thresh 0.575548731387949
current state at start:  [-0.39003542  2.01203802]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.39003542,  2.01203802]), 'currentState': array([6.17825217, 2.4695467 ]), 'targetState': array([0.75736022, 0.83100619]), 'effectorPosition': array([0.28146473, 0.59638793])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.7887112029394914
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([-0.39003542,  2.01203802]), 'currentState': array([6.07842364, 2.16483583]), 'targetState': array([0.75736022, 0.83100619]), 'effectorPosition': array([0.5995891 , 0.72184957])}
episode index:118
target Thresh 0.5783947869209551
current state at start:  [-1.53036768 -2.89346444]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.53036768, -2.89346444]), 'currentState': array([4.40308925, 2.91283507]), 'targetState': array([-0.19264302, -0.27802819]), 'effectorPosition': array([ 0.20807709, -0.09384109])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.790155613082857
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([-1.53036768, -2.89346444]), 'currentState': array([3.07353684, 3.02123397]), 'targetState': array([-0.19264302, -0.27802819]), 'effectorPosition': array([-0.01538266, -0.1192984 ])}
episode index:119
target Thresh 0.5812351560312132
current state at start:  [ 1.06751631 -1.79446074]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.06751631, -1.79446074]), 'currentState': array([1.31923179, 4.47771016]), 'targetState': array([1.1186695, 0.1470187]), 'effectorPosition': array([1.13301416, 0.50121619])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.7918209829738332
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.06751631, -1.79446074]), 'currentState': array([1.21076254, 4.27627105]), 'targetState': array([1.1186695, 0.1470187]), 'effectorPosition': array([1.05176798, 0.22121526])}
episode index:120
target Thresh 0.5840698500802037
current state at start:  [0.579431  2.0782545]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.579431 , 2.0782545]), 'currentState': array([0.85410685, 2.5782545 ]), 'targetState': array([-0.07206598,  0.73466006]), 'effectorPosition': array([-0.30113159,  0.46729578])}
done in step count: 14
reward sum = 0.8687458127689782
running average episode reward sum: 0.7924567253688344
{'reset': False, 'endBeforeDone': False, 'stepCount': 15, 'initial state': array([0.579431 , 2.0782545]), 'currentState': array([3.20154784, 3.74399292]), 'targetState': array([-0.07206598,  0.73466006]), 'effectorPosition': array([-0.20965735,  0.55505666])}
episode index:121
target Thresh 0.5868988804067068
current state at start:  [ 4.15670736 -2.26195354]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.15670736, -2.26195354]), 'currentState': array([4.2450094 , 3.52123177]), 'targetState': array([-0.58397772, -0.03626107]), 'effectorPosition': array([-0.36292052,  0.1034013 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.7940759325379423
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 4.15670736, -2.26195354]), 'currentState': array([4.18618055, 3.71015756]), 'targetState': array([-0.58397772, -0.03626107]), 'effectorPosition': array([-0.54460213,  0.13438547])}
episode index:122
target Thresh 0.5897222583268475
current state at start:  [-2.60856745  2.34764594]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.60856745,  2.34764594]), 'currentState': array([3.53817478, 2.84764594]), 'targetState': array([-0.01457037, -0.64128116]), 'effectorPosition': array([ 0.07235101, -0.28381269])}
done in step count: 40
reward sum = 0.6689717585696803
running average episode reward sum: 0.7930588254325093
{'reset': False, 'endBeforeDone': False, 'stepCount': 41, 'initial state': array([-2.60856745,  2.34764594]), 'currentState': array([3.66872479, 2.66242577]), 'targetState': array([-0.01457037, -0.64128116]), 'effectorPosition': array([ 0.13459657, -0.45510999])}
episode index:123
target Thresh 0.592539995134141
current state at start:  [0.59191649 2.24956072]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.59191649, 2.24956072]), 'currentState': array([0.8384959 , 2.66578854]), 'targetState': array([-0.1022814 ,  0.83769715]), 'effectorPosition': array([-0.2663631 ,  0.38884616])}
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.7937399721870774
{'reset': False, 'endBeforeDone': False, 'stepCount': 14, 'initial state': array([0.59191649, 2.24956072]), 'currentState': array([2.55812307, 3.99586175]), 'targetState': array([-0.1022814 ,  0.83769715]), 'effectorPosition': array([0.12900113, 0.81842471])}
episode index:124
target Thresh 0.5953521020995383
current state at start:  [-0.56012247 -2.85752729]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.56012247, -2.85752729]), 'currentState': array([5.4560385, 3.4272217]), 'targetState': array([-0.40948838, -0.16278425]), 'effectorPosition': array([-0.17994889, -0.22056562])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.7953900524095808
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.56012247, -2.85752729]), 'currentState': array([5.4560385, 3.4272217]), 'targetState': array([-0.40948838, -0.16278425]), 'effectorPosition': array([-0.17994889, -0.22056562])}
episode index:125
target Thresh 0.5981585904714712
current state at start:  [1.78799912 2.27457539]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.78799912, 2.27457539]), 'currentState': array([1.84050264, 2.43019367]), 'targetState': array([-0.54058838,  0.15220145]), 'effectorPosition': array([-0.69391868,  0.0598198 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.7970139408825206
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.78799912, 2.27457539]), 'currentState': array([1.84050264, 2.43019367]), 'targetState': array([-0.54058838,  0.15220145]), 'effectorPosition': array([-0.69391868,  0.0598198 ])}
episode index:126
target Thresh 0.600959471475897
current state at start:  [-0.4505366  -2.43595765]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.4505366 , -2.43595765]), 'currentState': array([5.48564074, 3.6401241 ]), 'targetState': array([-0.03732905, -0.98304868]), 'effectorPosition': array([-0.25716164, -0.42106596])}
done in step count: 40
reward sum = 0.6689717585696803
running average episode reward sum: 0.796005734722577
{'reset': False, 'endBeforeDone': False, 'stepCount': 41, 'initial state': array([-0.4505366 , -2.43595765]), 'currentState': array([3.72195827, 2.18138181]), 'targetState': array([-0.03732905, -0.98304868]), 'effectorPosition': array([ 0.09245981, -0.91910646])}
episode index:127
target Thresh 0.603754756316343
current state at start:  [ 4.65859938 -3.06699956]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.65859938, -3.06699956]), 'currentState': array([4.50591121, 2.85268113]), 'targetState': array([-0.00567408, -0.00865606]), 'effectorPosition': array([ 0.27036042, -0.09897538])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.7975213149200568
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 4.65859938, -3.06699956]), 'currentState': array([4.26495007, 3.02824932]), 'targetState': array([-0.00567408, -0.00865606]), 'effectorPosition': array([ 0.09919081, -0.0547188 ])}
episode index:128
target Thresh 0.6065444561739528
current state at start:  [-0.69728038  2.18951487]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.69728038,  2.18951487]), 'currentState': array([5.58566057, 1.88573932]), 'targetState': array([1.04598066, 0.36698862]), 'effectorPosition': array([1.13975125, 0.28538139])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.7990909171299789
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.69728038,  2.18951487]), 'currentState': array([5.58566057, 1.88573932]), 'targetState': array([1.04598066, 0.36698862]), 'effectorPosition': array([1.13975125, 0.28538139])}
episode index:129
target Thresh 0.6093285822075294
current state at start:  [ 2.48372358 -2.27790614]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.48372358, -2.27790614]), 'currentState': array([2.29944509, 4.04634619]), 'targetState': array([-0.05311706,  0.94066211]), 'effectorPosition': array([0.33217877, 0.8086399 ])}
done in step count: 44
reward sum = 0.6426116020847181
running average episode reward sum: 0.7978872300911691
{'reset': False, 'endBeforeDone': False, 'stepCount': 45, 'initial state': array([ 2.48372358, -2.27790614]), 'currentState': array([2.54648409, 4.02519681]), 'targetState': array([-0.05311706,  0.94066211]), 'effectorPosition': array([0.13058534, 0.84510897])}
episode index:130
target Thresh 0.6121071455535807
current state at start:  [-3.49474789  2.14464012]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.49474789,  2.14464012]), 'currentState': array([2.99585378, 1.94524083]), 'targetState': array([-0.96710373, -0.65754746]), 'effectorPosition': array([-0.76268183, -0.82873715])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.7993537397851297
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.49474789,  2.14464012]), 'currentState': array([2.98092396, 1.93342241]), 'targetState': array([-0.96710373, -0.65754746]), 'effectorPosition': array([-0.78653321, -0.8196975 ])}
episode index:131
target Thresh 0.6148801573263634
current state at start:  [-1.20207876  2.06585707]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.20207876,  2.06585707]), 'currentState': array([5.08570858, 1.61833449]), 'targetState': array([ 0.8968855, -0.3764487]), 'effectorPosition': array([ 1.27744723, -0.52257827])}
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.7999459161731133
{'reset': False, 'endBeforeDone': False, 'stepCount': 14, 'initial state': array([-1.20207876,  2.06585707]), 'currentState': array([4.69619361, 2.13817521]), 'targetState': array([ 0.8968855, -0.3764487]), 'effectorPosition': array([ 0.83571065, -0.47617302])}
episode index:132
target Thresh 0.6176476286179289
current state at start:  [-0.20748085  3.05997632]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.20748085,  3.05997632]), 'currentState': array([5.86594123, 3.39252369]), 'targetState': array([-0.23152703, -0.15145876]), 'effectorPosition': array([-0.07199261, -0.2396951 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8014500822169244
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.20748085,  3.05997632]), 'currentState': array([5.86594123, 3.39252369]), 'targetState': array([-0.23152703, -0.15145876]), 'effectorPosition': array([-0.07199261, -0.2396951 ])}
episode index:133
target Thresh 0.6204095704981654
current state at start:  [ 2.13307338 -2.40115483]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.13307338, -2.40115483]), 'currentState': array([2.29442735, 4.01321699]), 'targetState': array([0.18267697, 0.80192007]), 'effectorPosition': array([0.33759075, 0.77386313])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8029317980212757
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.13307338, -2.40115483]), 'currentState': array([2.29442735, 4.01321699]), 'targetState': array([0.18267697, 0.80192007]), 'effectorPosition': array([0.33759075, 0.77386313])}
episode index:134
target Thresh 0.6231659940148448
current state at start:  [-2.18676217  2.70594444]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.18676217,  2.70594444]), 'currentState': array([4.00985858, 2.89696502]), 'targetState': array([ 0.44058852, -0.01670637]), 'effectorPosition': array([ 0.16560812, -0.17921718])}
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.8036162902897013
{'reset': False, 'endBeforeDone': False, 'stepCount': 12, 'initial state': array([-2.18676217,  2.70594444]), 'currentState': array([1.8771063 , 3.50733245]), 'targetState': array([ 0.44058852, -0.01670637]), 'effectorPosition': array([0.3210489 , 0.17090561])}
episode index:135
target Thresh 0.6259169101936644
current state at start:  [0.44490695 1.71016605]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.44490695, 1.71016605]), 'currentState': array([0.66849397, 2.21016605]), 'targetState': array([0.13023578, 1.02852386]), 'effectorPosition': array([-0.1808759 ,  0.87971833])}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.8044243855631862
{'reset': False, 'endBeforeDone': False, 'stepCount': 10, 'initial state': array([0.44490695, 1.71016605]), 'currentState': array([2.21411865, 4.43151449]), 'targetState': array([0.13023578, 1.02852386]), 'effectorPosition': array([0.33517475, 1.15467135])}
episode index:136
target Thresh 0.6286623300382923
current state at start:  [-3.3258233   1.81235561]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.3258233 ,  1.81235561]), 'currentState': array([3.36149289, 2.29126456]), 'targetState': array([-0.69531091, -1.02813501]), 'effectorPosition': array([-0.16814385, -0.80762269])}
done in step count: 30
reward sum = 0.7397003733882802
running average episode reward sum: 0.8039519475181138
{'reset': False, 'endBeforeDone': False, 'stepCount': 31, 'initial state': array([-3.3258233 ,  1.81235561]), 'currentState': array([5.10217796, 4.19819936]), 'targetState': array([-0.69531091, -1.02813501]), 'effectorPosition': array([-0.61227899, -0.80090924])}
episode index:137
target Thresh 0.6314022645304123
current state at start:  [-2.00714873 -1.64055609]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.00714873, -1.64055609]), 'currentState': array([4.60791956, 4.5616523 ]), 'targetState': array([-1.08859532, -0.72762354]), 'effectorPosition': array([-1.07189078, -0.7421032 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8053725855795768
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.00714873, -1.64055609]), 'currentState': array([4.60791956, 4.5616523 ]), 'targetState': array([-1.08859532, -0.72762354]), 'effectorPosition': array([-1.07189078, -0.7421032 ])}
episode index:138
target Thresh 0.6341367246297656
current state at start:  [-2.05917274  1.99866232]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.05917274,  1.99866232]), 'currentState': array([3.85800545, 2.49866232]), 'targetState': array([ 0.3159862 , -0.73833853]), 'effectorPosition': array([ 0.24313515, -0.5832672 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8067727828056229
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.05917274,  1.99866232]), 'currentState': array([3.85800545, 2.49866232]), 'targetState': array([ 0.3159862 , -0.73833853]), 'effectorPosition': array([ 0.24313515, -0.5832672 ])}
episode index:139
target Thresh 0.6368657212741959
current state at start:  [1.23780954 2.69362845]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.23780954, 2.69362845]), 'currentState': array([1.38238418, 3.06710904]), 'targetState': array([-0.26044541,  0.54672011]), 'effectorPosition': array([-0.07257853,  0.01666139])}
done in step count: 37
reward sum = 0.6894490858690777
running average episode reward sum: 0.8059347563989333
{'reset': False, 'endBeforeDone': False, 'stepCount': 38, 'initial state': array([1.23780954, 2.69362845]), 'currentState': array([2.94083801, 3.95297465]), 'targetState': array([-0.26044541,  0.54672011]), 'effectorPosition': array([-0.16062791,  0.77279043])}
episode index:140
target Thresh 0.6395892653796942
current state at start:  [-0.39735588 -3.00940661]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.39735588, -3.00940661]), 'currentState': array([5.77801723, 3.4854351 ]), 'targetState': array([-0.22487379,  0.01515126]), 'effectorPosition': array([-0.11192207, -0.32332777])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.8070316447223451
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([-0.39735588, -3.00940661]), 'currentState': array([5.02310213, 3.4316307 ]), 'targetState': array([-0.22487379,  0.01515126]), 'effectorPosition': array([-0.25952459, -0.12720455])}
episode index:141
target Thresh 0.6423073678404398
current state at start:  [ 3.43378644 -2.14510484]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.43378644, -2.14510484]), 'currentState': array([3.16098629, 4.28661378]), 'targetState': array([-0.44125886,  0.97459061]), 'effectorPosition': array([-0.60452377,  0.89916474])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8083905768017653
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.43378644, -2.14510484]), 'currentState': array([3.16098629, 4.28661378]), 'targetState': array([-0.44125886,  0.97459061]), 'effectorPosition': array([-0.60452377,  0.89916474])}
episode index:142
target Thresh 0.6450200395288468
current state at start:  [-4.30481025  2.65810576]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.30481025,  2.65810576]), 'currentState': array([1.96059135, 2.87857497]), 'targetState': array([-0.38581977,  0.10765155]), 'effectorPosition': array([-0.25356082, -0.06698754])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8097305028381165
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.30481025,  2.65810576]), 'currentState': array([1.96059135, 2.87857497]), 'targetState': array([-0.38581977,  0.10765155]), 'effectorPosition': array([-0.25356082, -0.06698754])}
episode index:143
target Thresh 0.6477272912956051
current state at start:  [ 2.30993332 -2.69552466]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.30993332, -2.69552466]), 'currentState': array([2.24559948, 3.33131305]), 'targetState': array([0.18277738, 0.33239095]), 'effectorPosition': array([0.13604251, 0.13182728])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8110518187906296
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.30993332, -2.69552466]), 'currentState': array([2.24559948, 3.33131305]), 'targetState': array([0.18277738, 0.33239095]), 'effectorPosition': array([0.13604251, 0.13182728])}
episode index:144
target Thresh 0.6504291339697257
current state at start:  [-0.57408684 -2.61698765]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.57408684, -2.61698765]), 'currentState': array([5.68559057, 3.2170338 ]), 'targetState': array([-0.17408526, -0.19789445]), 'effectorPosition': array([-0.04005575, -0.06390778])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8123549096955218
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.57408684, -2.61698765]), 'currentState': array([5.68559057, 3.2170338 ]), 'targetState': array([-0.17408526, -0.19789445]), 'effectorPosition': array([-0.04005575, -0.06390778])}
episode index:145
target Thresh 0.6531255783585825
current state at start:  [1.18021444 2.29471177]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.18021444, 2.29471177]), 'currentState': array([1.60238859, 2.44046032]), 'targetState': array([-0.44608415,  0.63065113]), 'effectorPosition': array([-0.65221243,  0.21539381])}
done in step count: 52
reward sum = 0.5929664464014994
running average episode reward sum: 0.8108522489880285
{'reset': False, 'endBeforeDone': False, 'stepCount': 53, 'initial state': array([1.18021444, 2.29471177]), 'currentState': array([1.2130284 , 2.32881428]), 'targetState': array([-0.44608415,  0.63065113]), 'effectorPosition': array([-0.57077924,  0.54703217])}
episode index:146
target Thresh 0.6558166352479571
current state at start:  [0.42379999 2.23191996]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.42379999, 2.23191996]), 'currentState': array([0.77718777, 2.47121633]), 'targetState': array([0.07161972, 0.87607712]), 'effectorPosition': array([-0.28141257,  0.59466892])}
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.8113057780629329
{'reset': False, 'endBeforeDone': False, 'stepCount': 14, 'initial state': array([0.42379999, 2.23191996]), 'currentState': array([2.57386211, 3.89675849]), 'targetState': array([0.07161972, 0.87607712]), 'effectorPosition': array([0.13936189, 0.72405972])}
episode index:147
target Thresh 0.6585023154020804
current state at start:  [-3.0019347   2.63578556]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.0019347 ,  2.63578556]), 'currentState': array([3.55534888, 3.05688496]), 'targetState': array([-0.01696355, -0.25767345]), 'effectorPosition': array([ 0.03073314, -0.07890867])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8125807390219671
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.0019347 ,  2.63578556]), 'currentState': array([3.55534888, 3.05688496]), 'targetState': array([-0.01696355, -0.25767345]), 'effectorPosition': array([ 0.03073314, -0.07890867])}
episode index:148
target Thresh 0.6611826295636767
current state at start:  [-2.388263    2.97094854]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.388263  ,  2.97094854]), 'currentState': array([4.10807087, 3.37907698]), 'targetState': array([-0.00136156,  0.01076869]), 'effectorPosition': array([-0.20953941,  0.11057788])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8138385864110814
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.388263  ,  2.97094854]), 'currentState': array([4.10807087, 3.37907698]), 'targetState': array([-0.00136156,  0.01076869]), 'effectorPosition': array([-0.20953941,  0.11057788])}
episode index:149
target Thresh 0.6638575884540061
current state at start:  [0.44424057 2.95056928]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.44424057, 2.95056928]), 'currentState': array([0.80575183, 3.32317642]), 'targetState': array([0.14426899, 0.1695947 ]), 'effectorPosition': array([ 0.14165368, -0.11320954])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.8150129958350075
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.44424057, 2.95056928]), 'currentState': array([1.30575183, 3.42875336]), 'targetState': array([0.14426899, 0.1695947 ]), 'effectorPosition': array([ 0.28406661, -0.0346746 ])}
episode index:150
target Thresh 0.6665272027729079
current state at start:  [-4.00187138  2.72762813]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.00187138,  2.72762813]), 'currentState': array([2.47843178, 3.22762813]), 'targetState': array([-0.10542531, -0.09120891]), 'effectorPosition': array([0.04998424, 0.06999367])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8162380753327889
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.00187138,  2.72762813]), 'currentState': array([2.47843178, 3.22762813]), 'targetState': array([-0.10542531, -0.09120891]), 'effectorPosition': array([0.04998424, 0.06999367])}
episode index:151
target Thresh 0.6691914831988426
current state at start:  [-0.81244471  3.09835343]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.81244471,  3.09835343]), 'currentState': array([5.59923377, 3.09883568]), 'targetState': array([0.10487913, 0.00505938]), 'effectorPosition': array([0.0277166 , 0.03255258])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8174470353634943
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.81244471,  3.09835343]), 'currentState': array([5.59923377, 3.09883568]), 'targetState': array([0.10487913, 0.00505938]), 'effectorPosition': array([0.0277166 , 0.03255258])}
episode index:152
target Thresh 0.671850440388936
current state at start:  [-0.46972505 -2.09899017]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.46972505, -2.09899017]), 'currentState': array([5.82959181, 4.24999618]), 'targetState': array([-0.2434466 , -1.18218077]), 'effectorPosition': array([ 0.10571461, -1.04720705])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.8185748325179812
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.46972505, -2.09899017]), 'currentState': array([5.64104569, 4.29905618]), 'targetState': array([-0.2434466 , -1.18218077]), 'effectorPosition': array([-0.06931699, -1.09172697])}
episode index:153
target Thresh 0.6745040849790198
current state at start:  [-1.50318089  2.18189047]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.50318089,  2.18189047]), 'currentState': array([4.77145743, 2.68189047]), 'targetState': array([ 0.85219271, -0.09811796]), 'effectorPosition': array([ 0.44903608, -0.07744195])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.8194970479561762
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([-1.50318089,  2.18189047]), 'currentState': array([5.04052383, 2.41389054]), 'targetState': array([ 0.85219271, -0.09811796]), 'effectorPosition': array([ 0.71129768, -0.02541566])}
episode index:154
target Thresh 0.6771524275836762
current state at start:  [-0.13812272  1.93303674]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.13812272,  1.93303674]), 'currentState': array([6.25053131, 2.22499478]), 'targetState': array([0.96653051, 0.88756138]), 'effectorPosition': array([0.41717544, 0.78033191])}
done in step count: 107
reward sum = 0.34116606151404244
running average episode reward sum: 0.8164110415920334
{'reset': False, 'endBeforeDone': False, 'stepCount': 108, 'initial state': array([-0.13812272,  1.93303674]), 'currentState': array([5.93813657, 1.84484891]), 'targetState': array([0.96653051, 0.88756138]), 'effectorPosition': array([1.0119955 , 0.65923829])}
episode index:155
target Thresh 0.6797954787962794
current state at start:  [-0.49051227  2.14268292]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.49051227,  2.14268292]), 'currentState': array([5.47278531, 1.99816406]), 'targetState': array([0.89661354, 0.44493065]), 'effectorPosition': array([1.06294338, 0.20297273])}
done in step count: 14
reward sum = 0.8687458127689782
running average episode reward sum: 0.8167465208944497
{'reset': False, 'endBeforeDone': False, 'stepCount': 15, 'initial state': array([-0.49051227,  2.14268292]), 'currentState': array([5.76202355, 2.06109228]), 'targetState': array([0.89661354, 0.44493065]), 'effectorPosition': array([0.89810225, 0.50163569])}
episode index:156
target Thresh 0.6824332491890372
current state at start:  [-1.72687127  2.06876917]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.72687127,  2.06876917]), 'currentState': array([4.37798803, 2.43205969]), 'targetState': array([ 0.51706095, -0.53873833]), 'effectorPosition': array([ 0.53618561, -0.44178337])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.817913740506587
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.72687127,  2.06876917]), 'currentState': array([4.37798803, 2.43205969]), 'targetState': array([ 0.51706095, -0.53873833]), 'effectorPosition': array([ 0.53618561, -0.44178337])}
episode index:157
target Thresh 0.685065749313035
current state at start:  [-3.65663121  2.80851055]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.65663121,  2.80851055]), 'currentState': array([2.90800699, 2.45063565]), 'targetState': array([-0.15812236, -0.48666702]), 'effectorPosition': array([-0.37064292, -0.56687815])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8190661851869251
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.65663121,  2.80851055]), 'currentState': array([2.90800699, 2.45063565]), 'targetState': array([-0.15812236, -0.48666702]), 'effectorPosition': array([-0.37064292, -0.56687815])}
episode index:158
target Thresh 0.6876929896982773
current state at start:  [ 3.83130229 -2.06162582]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.83130229, -2.06162582]), 'currentState': array([4.08540166, 4.11119137]), 'targetState': array([-1.13454089,  0.06617986]), 'effectorPosition': array([-0.92265562,  0.13208184])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.820204133707762
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.83130229, -2.06162582]), 'currentState': array([4.08540166, 4.11119137]), 'targetState': array([-1.13454089,  0.06617986]), 'effectorPosition': array([-0.92265562,  0.13208184])}
episode index:159
target Thresh 0.6903149808537281
current state at start:  [1.62252333 2.76678265]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.62252333, 2.76678265]), 'currentState': array([1.66174506, 2.7036082 ]), 'targetState': array([-0.35200158,  0.17427938]), 'effectorPosition': array([-0.43093514,  0.05548198])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8213278578720885
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.62252333, 2.76678265]), 'currentState': array([1.66174506, 2.7036082 ]), 'targetState': array([-0.35200158,  0.17427938]), 'effectorPosition': array([-0.43093514,  0.05548198])}
episode index:160
target Thresh 0.6929317332673564
current state at start:  [ 4.06429055 -2.14997415]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.06429055, -2.14997415]), 'currentState': array([4.04705501, 4.01831179]), 'targetState': array([-0.96241703,  0.24250321]), 'effectorPosition': array([-0.82713634,  0.19103056])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8224376227300259
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.06429055, -2.14997415]), 'currentState': array([4.04705501, 4.01831179]), 'targetState': array([-0.96241703,  0.24250321]), 'effectorPosition': array([-0.82713634,  0.19103056])}
episode index:161
target Thresh 0.6955432574061748
current state at start:  [-1.29741468  1.8272142 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.29741468,  1.8272142 ]), 'currentState': array([5.12285121, 2.06367049]), 'targetState': array([ 1.11338251, -0.14144871]), 'effectorPosition': array([ 1.01802623, -0.13153999])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8235336867872479
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.29741468,  1.8272142 ]), 'currentState': array([5.12285121, 2.06367049]), 'targetState': array([ 1.11338251, -0.14144871]), 'effectorPosition': array([ 1.01802623, -0.13153999])}
episode index:162
target Thresh 0.6981495637162838
current state at start:  [0.24794608 2.75029788]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.24794608, 2.75029788]), 'currentState': array([0.33784474, 2.77300612]), 'targetState': array([0.15849445, 0.5452342 ]), 'effectorPosition': array([-0.05605628,  0.36219139])}
done in step count: 48
reward sum = 0.617290140942288
running average episode reward sum: 0.8222683889599782
{'reset': False, 'endBeforeDone': False, 'stepCount': 49, 'initial state': array([0.24794608, 2.75029788]), 'currentState': array([2.24143346, 3.93241156]), 'targetState': array([0.15849445, 0.5452342 ]), 'effectorPosition': array([0.37254304, 0.67430331])}
episode index:163
target Thresh 0.7007506626229114
current state at start:  [-0.63993046  1.76057849]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.63993046,  1.76057849]), 'currentState': array([6.14325485, 1.90137178]), 'targetState': array([1.35875128, 0.34641449]), 'effectorPosition': array([0.80073345, 0.84240796])}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.822824784438781
{'reset': False, 'endBeforeDone': False, 'stepCount': 10, 'initial state': array([-0.63993046,  1.76057849]), 'currentState': array([5.86131576, 1.63767565]), 'targetState': array([1.35875128, 0.34641449]), 'effectorPosition': array([1.25990622, 0.52818308])}
episode index:164
target Thresh 0.7033465645304575
current state at start:  [-3.88756621  1.80158851]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.88756621,  1.80158851]), 'currentState': array([2.38043849, 1.73609881]), 'targetState': array([-1.39621694, -0.04749543]), 'effectorPosition': array([-1.28525427, -0.13791326])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8238985736240005
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.88756621,  1.80158851]), 'currentState': array([2.38043849, 1.73609881]), 'targetState': array([-1.39621694, -0.04749543]), 'effectorPosition': array([-1.28525427, -0.13791326])}
episode index:165
target Thresh 0.705937279822533
current state at start:  [-0.71791858  2.68035844]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.71791858,  2.68035844]), 'currentState': array([5.50427344, 2.41033039]), 'targetState': array([0.46344009, 0.545182  ]), 'effectorPosition': array([0.65109331, 0.2956576 ])}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.8244384451532755
{'reset': False, 'endBeforeDone': False, 'stepCount': 10, 'initial state': array([-0.71791858,  2.68035844]), 'currentState': array([5.5861545, 2.4567523]), 'targetState': array([0.46344009, 0.545182  ]), 'effectorPosition': array([0.57894832, 0.34026277])}
episode index:166
target Thresh 0.7085228188620021
current state at start:  [ 1.23130697 -2.77566951]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.23130697, -2.77566951]), 'currentState': array([1.06558603, 3.33039666]), 'targetState': array([ 0.4253478 , -0.05129677]), 'effectorPosition': array([ 0.17283821, -0.07528704])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.825429831709244
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.23130697, -2.77566951]), 'currentState': array([0.94651919, 3.38442298]), 'targetState': array([ 0.4253478 , -0.05129677]), 'effectorPosition': array([ 0.21224722, -0.11674116])}
episode index:167
target Thresh 0.7111031919910247
current state at start:  [-0.39056564 -2.82175219]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.39056564, -2.82175219]), 'currentState': array([5.67582207, 2.96143311]), 'targetState': array([0.11864193, 0.01367713]), 'effectorPosition': array([0.11555282, 0.13790326])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8264689398538317
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.39056564, -2.82175219]), 'currentState': array([5.67582207, 2.96143311]), 'targetState': array([0.11864193, 0.01367713]), 'effectorPosition': array([0.11555282, 0.13790326])}
episode index:168
target Thresh 0.7136784095310968
current state at start:  [ 0.79432883 -2.63962822]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.79432883, -2.63962822]), 'currentState': array([0.81504718, 3.50674556]), 'targetState': array([ 0.54550017, -0.26517999]), 'effectorPosition': array([ 0.30509425, -0.19692426])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8274957508606139
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.79432883, -2.63962822]), 'currentState': array([0.81504718, 3.50674556]), 'targetState': array([ 0.54550017, -0.26517999]), 'effectorPosition': array([ 0.30509425, -0.19692426])}
episode index:169
target Thresh 0.7162484817830919
current state at start:  [-0.26979826  2.74408373]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.26979826,  2.74408373]), 'currentState': array([5.51338705, 2.97935903]), 'targetState': array([-0.07840937,  0.16396233]), 'effectorPosition': array([0.12184715, 0.10684262])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8285104817379043
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.26979826,  2.74408373]), 'currentState': array([5.51338705, 2.97935903]), 'targetState': array([-0.07840937,  0.16396233]), 'effectorPosition': array([0.12184715, 0.10684262])}
episode index:170
target Thresh 0.7188134190273026
current state at start:  [ 0.68144702 -2.43267716]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.68144702, -2.43267716]), 'currentState': array([0.33903857, 3.79781814]), 'targetState': array([ 0.78108855, -0.56274755]), 'effectorPosition': array([ 0.39879346, -0.50632217])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.8292267365224781
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([ 0.68144702, -2.43267716]), 'currentState': array([4.66926815, 1.88948366]), 'targetState': array([ 0.78108855, -0.56274755]), 'effectorPosition': array([ 0.91916375, -0.72697833])}
episode index:171
target Thresh 0.7213732315234809
current state at start:  [0.63361756 2.50974985]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.63361756, 2.50974985]), 'currentState': array([1.0621597 , 2.68178678]), 'targetState': array([-0.54795293,  0.40254153]), 'effectorPosition': array([-0.33701734,  0.30682566])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8302196043333939
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.63361756, 2.50974985]), 'currentState': array([1.0621597 , 2.68178678]), 'targetState': array([-0.54795293,  0.40254153]), 'effectorPosition': array([-0.33701734,  0.30682566])}
episode index:172
target Thresh 0.7239279295108805
current state at start:  [-0.31886392  2.17765934]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.31886392,  2.17765934]), 'currentState': array([0.01276769, 1.75567043]), 'targetState': array([1.00079198, 0.88900436]), 'effectorPosition': array([0.80356091, 0.99329969])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8312009939037212
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.31886392,  2.17765934]), 'currentState': array([0.01276769, 1.75567043]), 'targetState': array([1.00079198, 0.88900436]), 'effectorPosition': array([0.80356091, 0.99329969])}
episode index:173
target Thresh 0.726477523208297
current state at start:  [-3.41899369  2.37454921]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.41899369,  2.37454921]), 'currentState': array([2.99034853, 2.11848373]), 'targetState': array([-0.58319934, -0.69998057]), 'effectorPosition': array([-0.60244447, -0.77177205])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8321711031341595
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.41899369,  2.37454921]), 'currentState': array([2.99034853, 2.11848373]), 'targetState': array([-0.58319934, -0.69998057]), 'effectorPosition': array([-0.60244447, -0.77177205])}
episode index:174
target Thresh 0.729022022814108
current state at start:  [-3.47950297  2.64322372]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.47950297,  2.64322372]), 'currentState': array([2.87684993, 2.3697343 ]), 'targetState': array([-0.22978979, -0.46788622]), 'effectorPosition': array([-0.45601128, -0.59901768])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.8330729825448215
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.47950297,  2.64322372]), 'currentState': array([2.90134466, 2.68036888]), 'targetState': array([-0.22978979, -0.46788622]), 'effectorPosition': array([-0.20738577, -0.40739915])}
episode index:175
target Thresh 0.7315614385063158
current state at start:  [ 3.61481691 -2.54429212]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.61481691, -2.54429212]), 'currentState': array([3.75190351, 3.64873012]), 'targetState': array([-0.39162082,  0.32690567]), 'effectorPosition': array([-0.38149211,  0.32586357])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.834021431507635
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.61481691, -2.54429212]), 'currentState': array([3.75190351, 3.64873012]), 'targetState': array([-0.39162082,  0.32690567]), 'effectorPosition': array([-0.38149211,  0.32586357])}
episode index:176
target Thresh 0.7340957804425863
current state at start:  [1.84836829 2.49988693]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.84836829, 2.49988693]), 'currentState': array([1.79253805, 2.80085358]), 'targetState': array([-0.63651924,  0.12897046]), 'effectorPosition': array([-0.33864574, -0.01741229])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.8349026663578745
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.84836829, 2.49988693]), 'currentState': array([1.60260832, 2.72535126]), 'targetState': array([-0.63651924,  0.12897046]), 'effectorPosition': array([-0.40683687,  0.07248146])}
episode index:177
target Thresh 0.7366250587602907
current state at start:  [-0.86795691 -2.37448958]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.86795691, -2.37448958]), 'currentState': array([5.41231299, 3.82594749]), 'targetState': array([-0.27400056, -0.937927  ]), 'effectorPosition': array([-0.33849642, -0.57945323])}
done in step count: 23
reward sum = 0.7936142836436554
running average episode reward sum: 0.8346707091516147
{'reset': False, 'endBeforeDone': False, 'stepCount': 24, 'initial state': array([-0.86795691, -2.37448958]), 'currentState': array([3.55031046, 2.15764567]), 'targetState': array([-0.27400056, -0.937927  ]), 'effectorPosition': array([-0.07856352, -0.94146018])}
episode index:178
target Thresh 0.7391492835765456
current state at start:  [ 2.4570226  -1.68037751]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.4570226 , -1.68037751]), 'currentState': array([2.52193625, 4.97394053]), 'targetState': array([-0.34902882,  1.34115234]), 'effectorPosition': array([-0.4635781 ,  1.51731824])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8355943364747901
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.4570226 , -1.68037751]), 'currentState': array([2.52193625, 4.97394053]), 'targetState': array([-0.34902882,  1.34115234]), 'effectorPosition': array([-0.4635781 ,  1.51731824])}
episode index:179
target Thresh 0.7416684649882537
current state at start:  [-0.21625976  2.7388124 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.21625976,  2.7388124 ]), 'currentState': array([5.71768036, 2.75887554]), 'targetState': array([0.30835026, 0.20031677]), 'effectorPosition': array([0.26118977, 0.2765378 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8365077012721523
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.21625976,  2.7388124 ]), 'currentState': array([5.71768036, 2.75887554]), 'targetState': array([0.30835026, 0.20031677]), 'effectorPosition': array([0.26118977, 0.2765378 ])}
episode index:180
target Thresh 0.7441826130721441
current state at start:  [0.45592496 2.09370396]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.45592496, 2.09370396]), 'currentState': array([0.56772584, 2.44915167]), 'targetState': array([0.27230981, 0.83741805]), 'effectorPosition': array([-0.14910714,  0.66210813])}
done in step count: 17
reward sum = 0.8429431933839268
running average episode reward sum: 0.8365432564771897
{'reset': False, 'endBeforeDone': False, 'stepCount': 18, 'initial state': array([0.45592496, 2.09370396]), 'currentState': array([0.27486547, 2.26891248]), 'targetState': array([0.27230981, 0.83741805]), 'effectorPosition': array([0.13589416, 0.83425498])}
episode index:181
target Thresh 0.7466917378848121
current state at start:  [-3.69017409  2.37951663]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.69017409,  2.37951663]), 'currentState': array([2.8712372 , 2.20464053]), 'targetState': array([-0.33766027, -0.60344704]), 'effectorPosition': array([-0.60813884, -0.66758814])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.8371198328119359
{'reset': False, 'endBeforeDone': False, 'stepCount': 7, 'initial state': array([-3.69017409,  2.37951663]), 'currentState': array([3.10137933, 2.33686005]), 'targetState': array([-0.33766027, -0.60344704]), 'effectorPosition': array([-0.33541983, -0.70773273])}
episode index:182
target Thresh 0.7491958494627609
current state at start:  [ 0.72287823 -2.10804612]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.72287823, -2.10804612]), 'currentState': array([0.88081954, 4.02354973]), 'targetState': array([ 0.75963115, -0.58473849]), 'effectorPosition': array([ 0.82732246, -0.21036752])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.8377945660206139
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([ 0.72287823, -2.10804612]), 'currentState': array([0.48385215, 4.02316393]), 'targetState': array([ 0.75963115, -0.58473849]), 'effectorPosition': array([ 0.68127727, -0.51379243])}
episode index:183
target Thresh 0.7516949578224394
current state at start:  [0.10170575 2.05911149]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.10170575, 2.05911149]), 'currentState': array([0.58895503, 2.29123689]), 'targetState': array([0.56330345, 1.29262988]), 'effectorPosition': array([-0.13450733,  0.81392636])}
done in step count: 60
reward sum = 0.5471566423907612
running average episode reward sum: 0.836215012087843
{'reset': False, 'endBeforeDone': False, 'stepCount': 61, 'initial state': array([0.10170575, 2.05911149]), 'currentState': array([0.37347887, 1.76220973]), 'targetState': array([0.56330345, 1.29262988]), 'effectorPosition': array([0.39573887, 1.20950296])}
episode index:184
target Thresh 0.7541890729602854
current state at start:  [-1.23402476 -2.7568919 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.23402476, -2.7568919 ]), 'currentState': array([4.66075579, 3.27798808]), 'targetState': array([-0.18824443,  0.02478295]), 'effectorPosition': array([-0.13627103, -0.00225747])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8371003363468276
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.23402476, -2.7568919 ]), 'currentState': array([4.66075579, 3.27798808]), 'targetState': array([-0.18824443,  0.02478295]), 'effectorPosition': array([-0.13627103, -0.00225747])}
episode index:185
target Thresh 0.7566782048527616
current state at start:  [ 1.06412375 -1.91234519]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.06412375, -1.91234519]), 'currentState': array([1.25308653, 4.27675519]), 'targetState': array([0.79436839, 0.46614164]), 'effectorPosition': array([1.04179746, 0.26587194])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.8378691517428124
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 1.06412375, -1.91234519]), 'currentState': array([1.35667106, 4.22573537]), 'targetState': array([0.79436839, 0.46614164]), 'effectorPosition': array([0.97683294, 0.33234943])}
episode index:186
target Thresh 0.7591623634563998
current state at start:  [-2.146854    1.61153376]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.146854  ,  1.61153376]), 'currentState': array([3.87982147, 1.92871013]), 'targetState': array([ 0.28898992, -1.16177353]), 'effectorPosition': array([ 0.14978935, -1.13000936])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8387361616265406
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.146854  ,  1.61153376]), 'currentState': array([3.87982147, 1.92871013]), 'targetState': array([ 0.28898992, -1.16177353]), 'effectorPosition': array([ 0.14978935, -1.13000936])}
episode index:187
target Thresh 0.7616415587078369
current state at start:  [ 2.18569327 -2.52833336]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.18569327, -2.52833336]), 'currentState': array([1.68569327, 3.26356269]), 'targetState': array([0.23530497, 0.27292979]), 'effectorPosition': array([0.12001393, 0.02132867])}
done in step count: 14
reward sum = 0.8687458127689782
running average episode reward sum: 0.8388957874304899
{'reset': False, 'endBeforeDone': False, 'stepCount': 15, 'initial state': array([ 2.18569327, -2.52833336]), 'currentState': array([1.64720017, 3.59529222]), 'targetState': array([0.23530497, 0.27292979]), 'effectorPosition': array([0.42929303, 0.13432785])}
episode index:188
target Thresh 0.7641158005238582
current state at start:  [1.40719929 2.73173381]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.40719929, 2.73173381]), 'currentState': array([1.51453161, 2.82796331]), 'targetState': array([-0.62058322,  0.45728104]), 'effectorPosition': array([-0.30528162,  0.06605191])}
done in step count: 22
reward sum = 0.8016305895390459
running average episode reward sum: 0.8386986170712759
{'reset': False, 'endBeforeDone': False, 'stepCount': 23, 'initial state': array([1.40719929, 2.73173381]), 'currentState': array([3.63324164, 3.8142543 ]), 'targetState': array([-0.62058322,  0.45728104]), 'effectorPosition': array([-0.48617177,  0.44643579])}
episode index:189
target Thresh 0.7665850988014333
current state at start:  [-0.96660666 -2.00023741]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.96660666, -2.00023741]), 'currentState': array([5.6666037 , 4.23606572]), 'targetState': array([-0.44916388, -1.1203657 ]), 'effectorPosition': array([-0.07210672, -1.0381575 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.8394949401393219
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.96660666, -2.00023741]), 'currentState': array([5.42570612, 4.37496949]), 'targetState': array([-0.44916388, -1.1203657 ]), 'effectorPosition': array([-0.27583269, -1.12330313])}
episode index:190
target Thresh 0.7690494634177594
current state at start:  [-0.92363464 -2.77200741]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.92363464, -2.77200741]), 'currentState': array([5.15234294, 3.6312659 ]), 'targetState': array([-0.40366964, -0.19693931]), 'effectorPosition': array([-0.3754992 , -0.30663849])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8403352807668647
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.92363464, -2.77200741]), 'currentState': array([5.15234294, 3.6312659 ]), 'targetState': array([-0.40366964, -0.19693931]), 'effectorPosition': array([-0.3754992 , -0.30663849])}
episode index:191
target Thresh 0.7715089042302978
current state at start:  [ 2.72063221 -2.51337293]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.72063221, -2.51337293]), 'currentState': array([2.87206137, 4.15724617]), 'targetState': array([0.00504873, 0.82845108]), 'effectorPosition': array([-0.22956922,  0.94507599])}
done in step count: 45
reward sum = 0.6361854860638709
running average episode reward sum: 0.83927200058612
{'reset': False, 'endBeforeDone': False, 'stepCount': 46, 'initial state': array([ 2.72063221, -2.51337293]), 'currentState': array([3.0134643 , 3.88237681]), 'targetState': array([0.00504873, 0.82845108]), 'effectorPosition': array([-0.17367909,  0.70282033])}
episode index:192
target Thresh 0.7739634310768151
current state at start:  [-0.55700764  1.77100154]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.55700764,  1.77100154]), 'currentState': array([6.09762121, 1.59363387]), 'targetState': array([1.14474462, 0.66236351]), 'effectorPosition': array([1.14484167, 0.80228824])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.84010478814785
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.55700764,  1.77100154]), 'currentState': array([6.09762121, 1.59363387]), 'targetState': array([1.14474462, 0.66236351]), 'effectorPosition': array([1.14484167, 0.80228824])}
episode index:193
target Thresh 0.7764130537754221
current state at start:  [-2.29504907  2.45356858]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.29504907,  2.45356858]), 'currentState': array([3.75104917, 2.85162348]), 'targetState': array([ 0.44449024, -0.39445012]), 'effectorPosition': array([ 0.12943732, -0.25834202])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.8407758923326549
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-2.29504907,  2.45356858]), 'currentState': array([3.98163191, 2.49133689]), 'targetState': array([ 0.44449024, -0.39445012]), 'effectorPosition': array([ 0.31461151, -0.55602304])}
episode index:194
target Thresh 0.7788577821246128
current state at start:  [-0.68048081  2.74936523]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.68048081,  2.74936523]), 'currentState': array([5.30795816, 3.04967346]), 'targetState': array([0.01263632, 0.06906992]), 'effectorPosition': array([0.07835453, 0.04799749])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8415924262181285
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.68048081,  2.74936523]), 'currentState': array([5.30795816, 3.04967346]), 'targetState': array([0.01263632, 0.06906992]), 'effectorPosition': array([0.07835453, 0.04799749])}
episode index:195
target Thresh 0.7812976259033035
current state at start:  [-0.95897554  1.92260494]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.95897554,  1.92260494]), 'currentState': array([5.82420976, 2.01523773]), 'targetState': array([0.78669144, 0.24372259]), 'effectorPosition': array([0.91104046, 0.55686447])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.8422990975129339
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-0.95897554,  1.92260494]), 'currentState': array([5.66742166, 2.17939536]), 'targetState': array([0.78669144, 0.24372259]), 'effectorPosition': array([0.82349717, 0.42239225])}
episode index:196
target Thresh 0.7837325948708731
current state at start:  [ 3.2281398 -2.7396627]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.2281398, -2.7396627]), 'currentState': array([3.44888977, 3.94702244]), 'targetState': array([-0.2579531,  0.6594806]), 'effectorPosition': array([-0.51093725,  0.59442443])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.8429985944798732
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 3.2281398, -2.7396627]), 'currentState': array([3.29261574, 3.86545963]), 'targetState': array([-0.2579531,  0.6594806]), 'effectorPosition': array([-0.34753644,  0.61702337])}
episode index:197
target Thresh 0.7861626987672004
current state at start:  [-0.26217692 -2.47118852]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.26217692, -2.47118852]), 'currentState': array([5.52100838, 3.82318209]), 'targetState': array([ 0.0203397 , -0.62454167]), 'effectorPosition': array([-0.27342002, -0.60999744])}
done in step count: 50
reward sum = 0.6050060671375364
running average episode reward sum: 0.8417966120185484
{'reset': False, 'endBeforeDone': False, 'stepCount': 51, 'initial state': array([-0.26217692, -2.47118852]), 'currentState': array([3.57004306, 2.51199738]), 'targetState': array([ 0.0203397 , -0.62454167]), 'effectorPosition': array([ 0.07022784, -0.61525303])}
episode index:198
target Thresh 0.7885879473127044
current state at start:  [ 0.46462481 -2.07467038]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.46462481, -2.07467038]), 'currentState': array([0.32163738, 4.26468828]), 'targetState': array([ 1.23298798, -0.52514769]), 'effectorPosition': array([ 0.8229894 , -0.67594414])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.8424423526616712
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 0.46462481, -2.07467038]), 'currentState': array([0.58744509, 4.37334621]), 'targetState': array([ 1.23298798, -0.52514769]), 'effectorPosition': array([ 1.07821505, -0.41507023])}
episode index:199
target Thresh 0.7910083502083824
current state at start:  [ 3.01978658 -1.91885904]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.01978658, -1.91885904]), 'currentState': array([2.89489989, 4.07125566]), 'targetState': array([-0.27455979,  0.72885647]), 'effectorPosition': array([-0.19402372,  0.87529801])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8432301408983629
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.01978658, -1.91885904]), 'currentState': array([2.89489989, 4.07125566]), 'targetState': array([-0.27455979,  0.72885647]), 'effectorPosition': array([-0.19402372,  0.87529801])}
episode index:200
target Thresh 0.7934239171358493
current state at start:  [ 4.00642202 -2.85046207]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.00642202, -2.85046207]), 'currentState': array([3.95095367, 3.02144257]), 'targetState': array([-0.08459967, -0.01588011]), 'effectorPosition': array([ 0.08178694, -0.08791803])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8440100904461323
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.00642202, -2.85046207]), 'currentState': array([3.95095367, 3.02144257]), 'targetState': array([-0.08459967, -0.01588011]), 'effectorPosition': array([ 0.08178694, -0.08791803])}
episode index:201
target Thresh 0.7958346577573758
current state at start:  [-3.73822423  1.68988051]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.73822423,  1.68988051]), 'currentState': array([2.83230976, 2.06065145]), 'targetState': array([-0.8987267 , -0.55916554]), 'effectorPosition': array([-0.77295956, -0.67936545])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8447823177211514
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.73822423,  1.68988051]), 'currentState': array([2.83230976, 2.06065145]), 'targetState': array([-0.8987267 , -0.55916554]), 'effectorPosition': array([-0.77295956, -0.67936545])}
episode index:202
target Thresh 0.7982405817159279
current state at start:  [-0.72715464 -2.30294884]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.72715464, -2.30294884]), 'currentState': array([5.41767246, 3.86370431]), 'targetState': array([-0.10517218, -0.52621611]), 'effectorPosition': array([-0.34148595, -0.6185176 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.8454976757619339
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.72715464, -2.30294884]), 'currentState': array([5.44220811, 3.7639218 ]), 'targetState': array([-0.10517218, -0.52621611]), 'effectorPosition': array([-0.30945675, -0.52838495])}
episode index:203
target Thresh 0.8006416986352045
current state at start:  [ 4.07789034 -3.07572512]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.07789034, -3.07572512]), 'currentState': array([3.60580367, 3.38622809]), 'targetState': array([0.07258295, 0.36100691]), 'effectorPosition': array([-0.1350618 ,  0.20324108])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.8462060204885912
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 4.07789034, -3.07572512]), 'currentState': array([3.32521287, 3.31104147]), 'targetState': array([0.07258295, 0.36100691]), 'effectorPosition': array([-0.04487319,  0.16318903])}
episode index:204
target Thresh 0.8030380181196766
current state at start:  [0.07995631 2.10557219]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.07995631, 2.10557219]), 'currentState': array([6.25516012, 2.32750979]), 'targetState': array([0.2989117 , 0.69991947]), 'effectorPosition': array([0.33371572, 0.71802699])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8469562350227932
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.07995631, 2.10557219]), 'currentState': array([6.25516012, 2.32750979]), 'targetState': array([0.2989117 , 0.69991947]), 'effectorPosition': array([0.33371572, 0.71802699])}
episode index:205
target Thresh 0.8054295497546251
current state at start:  [-0.30800001  1.93385298]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.30800001,  1.93385298]), 'currentState': array([5.76970844, 1.78368166]), 'targetState': array([1.14502326, 0.43818009]), 'effectorPosition': array([1.16712718, 0.46395281])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8476991659207408
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.30800001,  1.93385298]), 'currentState': array([5.76970844, 1.78368166]), 'targetState': array([1.14502326, 0.43818009]), 'effectorPosition': array([1.16712718, 0.46395281])}
episode index:206
target Thresh 0.8078163031061798
current state at start:  [ 3.69950753 -1.86010296]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.69950753, -1.86010296]), 'currentState': array([4.09160083, 4.30496549]), 'targetState': array([-1.28906802,  0.08790093]), 'effectorPosition': array([-1.09802762,  0.04295668])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8484349187423798
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.69950753, -1.86010296]), 'currentState': array([4.09160083, 4.30496549]), 'targetState': array([-1.28906802,  0.08790093]), 'effectorPosition': array([-1.09802762,  0.04295668])}
episode index:207
target Thresh 0.8101982877213574
current state at start:  [-2.93930227  1.91470945]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.93930227,  1.91470945]), 'currentState': array([3.52041969, 2.24929825]), 'targetState': array([-0.52169068, -1.0294962 ]), 'effectorPosition': array([-0.0580525 , -0.86103136])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.8489279722575607
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([-2.93930227,  1.91470945]), 'currentState': array([3.34661752, 1.98374248]), 'targetState': array([-0.52169068, -1.0294962 ]), 'effectorPosition': array([-0.3996733, -1.0186472])}
episode index:208
target Thresh 0.8125755131280996
current state at start:  [0.7550435  2.58061031]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.7550435 , 2.58061031]), 'currentState': array([0.77373838, 2.29505331]), 'targetState': array([-0.18231677,  0.77200529]), 'effectorPosition': array([-0.28204794,  0.77155087])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8496508049261847
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.7550435 , 2.58061031]), 'currentState': array([0.77373838, 2.29505331]), 'targetState': array([-0.18231677,  0.77200529]), 'effectorPosition': array([-0.28204794,  0.77155087])}
episode index:209
target Thresh 0.814947988835311
current state at start:  [-0.80243923 -2.63636107]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.80243923, -2.63636107]), 'currentState': array([4.98074608, 3.77876344]), 'targetState': array([-0.64805859, -0.5806374 ]), 'effectorPosition': array([-0.52160341, -0.34693745])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.8501791154265362
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([-0.80243923, -2.63636107]), 'currentState': array([4.96212932, 3.90388268]), 'targetState': array([-0.64805859, -0.5806374 ]), 'effectorPosition': array([-0.60075761, -0.43883638])}
episode index:210
target Thresh 0.8173157243328979
current state at start:  [ 1.40529911 -1.85732479]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.40529911, -1.85732479]), 'currentState': array([1.63502024, 4.74260672]), 'targetState': array([1.17188886, 0.74333184]), 'effectorPosition': array([0.93136393, 1.09223967])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.8507484039790172
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 1.40529911, -1.85732479]), 'currentState': array([1.41123166, 4.49077188]), 'targetState': array([1.17188886, 0.74333184]), 'effectorPosition': array([1.08711406, 0.61527887])}
episode index:211
target Thresh 0.8196787290918048
current state at start:  [ 2.19375039 -2.12709224]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.19375039, -2.12709224]), 'currentState': array([2.3741676 , 4.26289747]), 'targetState': array([0.21428697, 0.80229837]), 'effectorPosition': array([0.21833448, 1.04082411])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8514524209413803
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.19375039, -2.12709224]), 'currentState': array([2.3741676 , 4.26289747]), 'targetState': array([0.21428697, 0.80229837]), 'effectorPosition': array([0.21833448, 1.04082411])}
episode index:212
target Thresh 0.8220370125640546
current state at start:  [1.25614939 3.03332001]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.25614939, 3.03332001]), 'currentState': array([1.55917616, 2.89164093]), 'targetState': array([-0.22477516, -0.21619768]), 'effectorPosition': array([-0.24697938,  0.0339478 ])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.8519197337533926
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([1.25614939, 3.03332001]), 'currentState': array([1.94328645, 2.81735616]), 'targetState': array([-0.22477516, -0.21619768]), 'effectorPosition': array([-0.31570101, -0.06741203])}
episode index:213
target Thresh 0.8243905841827839
current state at start:  [-2.00042478  2.26840553]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.00042478,  2.26840553]), 'currentState': array([4.50127514, 2.17443899]), 'targetState': array([ 0.77830482, -0.64137527]), 'effectorPosition': array([ 0.71439554, -0.59527199])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8526116976143581
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.00042478,  2.26840553]), 'currentState': array([4.50127514, 2.17443899]), 'targetState': array([ 0.77830482, -0.64137527]), 'effectorPosition': array([ 0.71439554, -0.59527199])}
episode index:214
target Thresh 0.8267394533622825
current state at start:  [0.66045819 2.46637184]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.66045819, 2.46637184]), 'currentState': array([0.85903208, 2.74928779]), 'targetState': array([-0.21348018,  0.64608026]), 'effectorPosition': array([-0.23987501,  0.30724474])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.853025039250575
{'reset': False, 'endBeforeDone': False, 'stepCount': 7, 'initial state': array([0.66045819, 2.46637184]), 'currentState': array([3.29753132, 3.8355772 ]), 'targetState': array([-0.21348018,  0.64608026]), 'effectorPosition': array([-0.32782535,  0.59592228])}
episode index:215
target Thresh 0.8290836294980302
current state at start:  [ 2.16914845 -2.95136243]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.16914845, -2.95136243]), 'currentState': array([2.16441977, 3.16736192]), 'targetState': array([ 0.01278232, -0.03281321]), 'effectorPosition': array([0.02117256, 0.01468812])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8537054788836742
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.16914845, -2.95136243]), 'currentState': array([2.16441977, 3.16736192]), 'targetState': array([ 0.01278232, -0.03281321]), 'effectorPosition': array([0.02117256, 0.01468812])}
episode index:216
target Thresh 0.8314231219667345
current state at start:  [ 3.86314224 -1.58159861]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.86314224, -1.58159861]), 'currentState': array([3.8520926 , 4.67692962]), 'targetState': array([-1.11350682,  0.17637009]), 'effectorPosition': array([-1.3829649 ,  0.12846876])}
done in step count: 16
reward sum = 0.8514577710948755
running average episode reward sum: 0.853695120783265
{'reset': False, 'endBeforeDone': False, 'stepCount': 17, 'initial state': array([ 3.86314224, -1.58159861]), 'currentState': array([3.84039354, 4.65105267]), 'targetState': array([-1.11350682,  0.17637009]), 'effectorPosition': array([-1.360774  ,  0.16030723])}
episode index:217
target Thresh 0.8337579401263688
current state at start:  [ 0.75131737 -2.52843349]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.75131737, -2.52843349]), 'currentState': array([0.93078445, 3.71470382]), 'targetState': array([ 0.69451271, -0.3707294 ]), 'effectorPosition': array([ 0.53035415, -0.19567432])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8543662440824243
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.75131737, -2.52843349]), 'currentState': array([0.93078445, 3.71470382]), 'targetState': array([ 0.69451271, -0.3707294 ]), 'effectorPosition': array([ 0.53035415, -0.19567432])}
episode index:218
target Thresh 0.8360880933162087
current state at start:  [1.35599661 2.61774921]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.35599661, 2.61774921]), 'currentState': array([1.21861488, 2.82227051]), 'targetState': array([-0.06483343, -0.14343435]), 'effectorPosition': array([-0.27721765,  0.1557354 ])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.8548074486751988
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([1.35599661, 2.61774921]), 'currentState': array([1.14503526, 2.96664625]), 'targetState': array([-0.06483343, -0.14343435]), 'effectorPosition': array([-0.15221221,  0.08578873])}
episode index:219
target Thresh 0.8384135908568697
current state at start:  [-0.25853541  2.70812472]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.25853541,  2.70812472]), 'currentState': array([5.7805462 , 2.62020871]), 'targetState': array([0.14096583, 0.34711036]), 'effectorPosition': array([0.3563806 , 0.37246675])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8554674148175843
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.25853541,  2.70812472]), 'currentState': array([5.7805462 , 2.62020871]), 'targetState': array([0.14096583, 0.34711036]), 'effectorPosition': array([0.3563806 , 0.37246675])}
episode index:220
target Thresh 0.8407344420503455
current state at start:  [ 3.07909943 -2.3802425 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.07909943, -2.3802425 ]), 'currentState': array([3.50879051, 3.92651201]), 'targetState': array([-0.4805692 ,  0.56018968]), 'effectorPosition': array([-0.52678296,  0.55462525])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8561214084156947
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.07909943, -2.3802425 ]), 'currentState': array([3.50879051, 3.92651201]), 'targetState': array([-0.4805692 ,  0.56018968]), 'effectorPosition': array([-0.52678296,  0.55462525])}
episode index:221
target Thresh 0.8430506561800437
current state at start:  [ 4.12526229 -2.52406213]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.12526229, -2.52406213]), 'currentState': array([4.54090497, 3.42083162]), 'targetState': array([-0.22024614, -0.22157937]), 'effectorPosition': array([-0.27819133,  0.00886744])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.856769510179588
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.12526229, -2.52406213]), 'currentState': array([4.54090497, 3.42083162]), 'targetState': array([-0.22024614, -0.22157937]), 'effectorPosition': array([-0.27819133,  0.00886744])}
episode index:222
target Thresh 0.8453622425108243
current state at start:  [ 3.95890591 -1.97754899]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.95890591, -1.97754899]), 'currentState': array([3.75450258, 4.67914816]), 'targetState': array([-1.25778742,  0.47255604]), 'effectorPosition': array([-1.36572468,  0.26139379])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8574117993716077
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.95890591, -1.97754899]), 'currentState': array([3.75450258, 4.67914816]), 'targetState': array([-1.25778742,  0.47255604]), 'effectorPosition': array([-1.36572468,  0.26139379])}
episode index:223
target Thresh 0.8476692102890351
current state at start:  [ 0.66933473 -2.62737715]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.66933473, -2.62737715]), 'currentState': array([1.16933473, 3.63917173]), 'targetState': array([0.03605277, 0.01116326]), 'effectorPosition': array([ 0.4867337 , -0.07489343])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.858003710981556
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.66933473, -2.62737715]), 'currentState': array([1.66933473, 3.36940111]), 'targetState': array([0.03605277, 0.01116326]), 'effectorPosition': array([0.22220583, 0.04792922])}
episode index:224
target Thresh 0.8499715687425506
current state at start:  [-3.67719378  1.8229187 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.67719378,  1.8229187 ]), 'currentState': array([2.90373223, 2.05848164]), 'targetState': array([-1.39287974, -0.08226741]), 'effectorPosition': array([-0.72461005, -0.7333319 ])}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.8582914486857621
{'reset': False, 'endBeforeDone': False, 'stepCount': 9, 'initial state': array([-3.67719378,  1.8229187 ]), 'currentState': array([4.1481955 , 4.61916118]), 'targetState': array([-1.39287974, -0.08226741]), 'effectorPosition': array([-1.32630512, -0.2339425 ])}
episode index:225
target Thresh 0.8522693270808079
current state at start:  [-1.2662029   2.85802359]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.2662029 ,  2.85802359]), 'currentState': array([4.7659829, 3.0501241]), 'targetState': array([ 0.02054108, -0.00033356]), 'effectorPosition': array([0.09143384, 0.00071865])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8589184776738782
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.2662029 ,  2.85802359]), 'currentState': array([4.7659829, 3.0501241]), 'targetState': array([ 0.02054108, -0.00033356]), 'effectorPosition': array([0.09143384, 0.00071865])}
episode index:226
target Thresh 0.8545624944948433
current state at start:  [1.69012562 2.36987704]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.69012562, 2.36987704]), 'currentState': array([1.89060778, 2.62003169]), 'targetState': array([-0.46679406,  0.0027307 ]), 'effectorPosition': array([-0.51477124, -0.03042279])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8595399821775175
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.69012562, 2.36987704]), 'currentState': array([1.89060778, 2.62003169]), 'targetState': array([-0.46679406,  0.0027307 ]), 'effectorPosition': array([-0.51477124, -0.03042279])}
episode index:227
target Thresh 0.8568510801573292
current state at start:  [-0.1340018   2.92823618]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.1340018 ,  2.92823618]), 'currentState': array([5.73197307, 3.08357259]), 'targetState': array([-0.13612188,  0.09445522]), 'effectorPosition': array([0.03180271, 0.04851774])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8601560348872652
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.1340018 ,  2.92823618]), 'currentState': array([5.73197307, 3.08357259]), 'targetState': array([-0.13612188,  0.09445522]), 'effectorPosition': array([0.03180271, 0.04851774])}
episode index:228
target Thresh 0.8591350932226118
current state at start:  [-1.11240957  1.83204045]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.11240957,  1.83204045]), 'currentState': array([4.89876842, 1.61008849]), 'targetState': array([ 1.16672822, -0.53521482]), 'effectorPosition': array([ 1.15994631, -0.75892059])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8607667072240021
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.11240957,  1.83204045]), 'currentState': array([4.89876842, 1.61008849]), 'targetState': array([ 1.16672822, -0.53521482]), 'effectorPosition': array([ 1.15994631, -0.75892059])}
episode index:229
target Thresh 0.8614145428267459
current state at start:  [ 3.98099912 -2.39855408]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.98099912, -2.39855408]), 'currentState': array([4.08078285, 4.08791381]), 'targetState': array([-1.0484025 ,  0.01070197]), 'effectorPosition': array([-0.8999873,  0.1438044])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8613720693665065
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.98099912, -2.39855408]), 'currentState': array([4.08078285, 4.08791381]), 'targetState': array([-1.0484025 ,  0.01070197]), 'effectorPosition': array([-0.8999873,  0.1438044])}
episode index:230
target Thresh 0.8636894380875333
current state at start:  [0.553244   1.87532766]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.553244  , 1.87532766]), 'currentState': array([0.52411194, 2.06115965]), 'targetState': array([0.05976462, 1.01225153]), 'effectorPosition': array([0.01656513, 1.02850996])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8619721902783397
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.553244  , 1.87532766]), 'currentState': array([0.52411194, 2.06115965]), 'targetState': array([0.05976462, 1.01225153]), 'effectorPosition': array([0.01656513, 1.02850996])}
episode index:231
target Thresh 0.865959788104558
current state at start:  [-0.55841549 -2.22249112]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.55841549, -2.22249112]), 'currentState': array([5.84160343, 4.03721397]), 'targetState': array([ 0.1110273 , -0.97957142]), 'effectorPosition': array([ 0.005394  , -0.86596941])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8625671377340365
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.55841549, -2.22249112]), 'currentState': array([5.84160343, 4.03721397]), 'targetState': array([ 0.1110273 , -0.97957142]), 'effectorPosition': array([ 0.005394  , -0.86596941])}
episode index:232
target Thresh 0.8682256019592227
current state at start:  [ 1.46663425 -2.9436535 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.46663425, -2.9436535 ]), 'currentState': array([1.65304016, 3.25685879]), 'targetState': array([-0.08621155,  0.22311014]), 'effectorPosition': array([0.11407718, 0.01606165])}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.8627858077329619
{'reset': False, 'endBeforeDone': False, 'stepCount': 10, 'initial state': array([ 1.46663425, -2.9436535 ]), 'currentState': array([2.44546007, 3.428483  ]), 'targetState': array([-0.08621155,  0.22311014]), 'effectorPosition': array([0.15009469, 0.24334066])}
episode index:233
target Thresh 0.8704868887147867
current state at start:  [-0.53786125 -2.27104097]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.53786125, -2.27104097]), 'currentState': array([5.86543123, 3.8004034 ]), 'targetState': array([ 0.13865244, -0.47979472]), 'effectorPosition': array([-0.05708382, -0.64443758])}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.8630026087575374
{'reset': False, 'endBeforeDone': False, 'stepCount': 10, 'initial state': array([-0.53786125, -2.27104097]), 'currentState': array([4.13647726, 2.74325367]), 'targetState': array([ 0.13865244, -0.47979472]), 'effectorPosition': array([ 0.2826815 , -0.27690804])}
episode index:234
target Thresh 0.8727436574163994
current state at start:  [0.11543248 3.01047674]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.11543248, 3.01047674]), 'currentState': array([6.07262129, 3.26420936]), 'targetState': array([-0.00758195, -0.0056224 ]), 'effectorPosition': array([-0.01822194, -0.12117751])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8635855763798458
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.11543248, 3.01047674]), 'currentState': array([6.07262129, 3.26420936]), 'targetState': array([-0.00758195, -0.0056224 ]), 'effectorPosition': array([-0.01822194, -0.12117751])}
episode index:235
target Thresh 0.8749959170911386
current state at start:  [ 4.28574728 -2.29544085]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.28574728, -2.29544085]), 'currentState': array([3.91559376, 3.57319144]), 'targetState': array([-0.51214633,  0.41986914]), 'effectorPosition': array([-0.35798684,  0.23505153])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8641636035985752
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.28574728, -2.29544085]), 'currentState': array([3.91559376, 3.57319144]), 'targetState': array([-0.51214633,  0.41986914]), 'effectorPosition': array([-0.35798684,  0.23505153])}
episode index:236
target Thresh 0.877243676748046
current state at start:  [1.76312384 2.64183386]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.76312384, 2.64183386]), 'currentState': array([1.90735385, 2.75002226]), 'targetState': array([-0.06863705, -0.22312169]), 'effectorPosition': array([-0.38522483, -0.05459008])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.8644501088488217
{'reset': False, 'endBeforeDone': False, 'stepCount': 8, 'initial state': array([1.76312384, 2.64183386]), 'currentState': array([3.59680726, 2.78207462]), 'targetState': array([-0.06863705, -0.22312169]), 'effectorPosition': array([ 0.09725788, -0.3441045 ])}
episode index:237
target Thresh 0.8794869453781637
current state at start:  [-1.01196758  2.8196474 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.01196758,  2.8196474 ]), 'currentState': array([5.64745119, 2.43232619]), 'targetState': array([0.2472456, 0.5527523]), 'effectorPosition': array([0.58075404, 0.38084789])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.8649360327612216
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.01196758,  2.8196474 ]), 'currentState': array([6.11394893, 2.35556087]), 'targetState': array([0.2472456, 0.5527523]), 'effectorPosition': array([0.40832384, 0.64803892])}
episode index:238
target Thresh 0.8817257319545688
current state at start:  [-0.47803513  2.62307403]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.47803513,  2.62307403]), 'currentState': array([5.79105598, 2.72403245]), 'targetState': array([0.07035379, 0.42350765]), 'effectorPosition': array([0.2673379 , 0.31680956])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8655011539630575
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.47803513,  2.62307403]), 'currentState': array([5.79105598, 2.72403245]), 'targetState': array([0.07035379, 0.42350765]), 'effectorPosition': array([0.2673379 , 0.31680956])}
episode index:239
target Thresh 0.8839600454324108
current state at start:  [ 3.49325366 -1.88722526]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.49325366, -1.88722526]), 'currentState': array([3.85760904, 4.24964504]), 'targetState': array([-0.83714445,  0.77788694]), 'effectorPosition': array([-1.00499984,  0.31171307])}
done in step count: 14
reward sum = 0.8687458127689782
running average episode reward sum: 0.8655146733747489
{'reset': False, 'endBeforeDone': False, 'stepCount': 15, 'initial state': array([ 3.49325366, -1.88722526]), 'currentState': array([3.60107357, 4.11903513]), 'targetState': array([-0.83714445,  0.77788694]), 'effectorPosition': array([-0.7628094 ,  0.54756948])}
episode index:240
target Thresh 0.8861898947489464
current state at start:  [ 1.1466827  -1.91044385]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.1466827 , -1.91044385]), 'currentState': array([1.43256521, 4.52409828]), 'targetState': array([1.2304804 , 0.47412002]), 'effectorPosition': array([1.08495502, 0.66971071])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8660727037756835
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.1466827 , -1.91044385]), 'currentState': array([1.43256521, 4.52409828]), 'targetState': array([1.2304804 , 0.47412002]), 'effectorPosition': array([1.08495502, 0.66971071])}
episode index:241
target Thresh 0.8884152888235759
current state at start:  [-1.24663397  1.59657489]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.24663397,  1.59657489]), 'currentState': array([5.32924054, 1.87665556]), 'targetState': array([ 1.28386221, -0.3225211 ]), 'effectorPosition': array([ 1.18213106, -0.01846282])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.8665848000410733
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.24663397,  1.59657489]), 'currentState': array([5.17300303, 1.52687128]), 'targetState': array([ 1.28386221, -0.3225211 ]), 'effectorPosition': array([ 1.35893227, -0.49104474])}
episode index:242
target Thresh 0.8906362365578786
current state at start:  [ 1.72005702 -2.53776535]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.72005702, -2.53776535]), 'currentState': array([2.06716264, 4.17314676]), 'targetState': array([0.28113072, 0.52744947]), 'effectorPosition': array([0.52284745, 0.83645607])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.8670926815223857
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.72005702, -2.53776535]), 'currentState': array([2.15511759, 3.89443836]), 'targetState': array([0.28113072, 0.52744947]), 'effectorPosition': array([0.42119919, 0.60257689])}
episode index:243
target Thresh 0.8928527468356484
current state at start:  [ 0.46900416 -2.72423708]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.46900416, -2.72423708]), 'currentState': array([0.94452093, 3.34052582]), 'targetState': array([0.03602723, 0.03249454]), 'effectorPosition': array([ 0.17167758, -0.09985426])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.867637383647294
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.46900416, -2.72423708]), 'currentState': array([0.94452093, 3.34052582]), 'targetState': array([0.03602723, 0.03249454]), 'effectorPosition': array([ 0.17167758, -0.09985426])}
episode index:244
target Thresh 0.8950648285229292
current state at start:  [-0.17999799 -1.75293422]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.17999799, -1.75293422]), 'currentState': array([0.02212809, 4.70033041]), 'targetState': array([ 0.23405737, -0.82245343]), 'effectorPosition': array([ 1.00982453, -0.97782302])}
done in step count: 22
reward sum = 0.8016305895390459
running average episode reward sum: 0.8673679681611379
{'reset': False, 'endBeforeDone': False, 'stepCount': 23, 'initial state': array([-0.17999799, -1.75293422]), 'currentState': array([4.14471791, 2.26401437]), 'targetState': array([ 0.23405737, -0.82245343]), 'effectorPosition': array([ 0.45445947, -0.71793803])}
episode index:245
target Thresh 0.8972724904680509
current state at start:  [-3.1720362   2.09209778]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.1720362 ,  2.09209778]), 'currentState': array([3.26691593, 2.39090409]), 'targetState': array([-0.31417732, -0.50892078]), 'effectorPosition': array([-0.18140797, -0.71038895])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8679071227621089
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.1720362 ,  2.09209778]), 'currentState': array([3.26691593, 2.39090409]), 'targetState': array([-0.31417732, -0.50892078]), 'effectorPosition': array([-0.18140797, -0.71038895])}
episode index:246
target Thresh 0.8994757415016643
current state at start:  [ 3.7314     -1.75807348]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.7314    , -1.75807348]), 'currentState': array([3.62111884, 4.55637607]), 'targetState': array([-1.16988834,  0.67921979]), 'effectorPosition': array([-1.20511316,  0.48676556])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8684419117387806
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.7314    , -1.75807348]), 'currentState': array([3.62111884, 4.55637607]), 'targetState': array([-1.16988834,  0.67921979]), 'effectorPosition': array([-1.20511316,  0.48676556])}
episode index:247
target Thresh 0.9016745904367762
current state at start:  [ 1.92763062 -2.7108134 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.92763062, -2.7108134 ]), 'currentState': array([2.22054128, 3.9605887 ]), 'targetState': array([0.09509521, 0.51645467]), 'effectorPosition': array([0.38981352, 0.69435986])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.8689320653204791
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.92763062, -2.7108134 ]), 'currentState': array([2.41833518, 3.7642504 ]), 'targetState': array([0.09509521, 0.51645467]), 'effectorPosition': array([0.2452903 , 0.56140003])}
episode index:248
target Thresh 0.9038690460687857
current state at start:  [ 3.96831752 -2.01130052]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.96831752, -2.01130052]), 'currentState': array([3.78943787, 4.48293187]), 'targetState': array([-1.15757136,  0.45950746]), 'effectorPosition': array([-1.20367412,  0.3102754 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8694584425681879
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.96831752, -2.01130052]), 'currentState': array([3.78943787, 4.48293187]), 'targetState': array([-1.15757136,  0.45950746]), 'effectorPosition': array([-1.20367412,  0.3102754 ])}
episode index:249
target Thresh 0.9060591171755177
current state at start:  [0.149904   2.34624848]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.149904  , 2.34624848]), 'currentState': array([0.11130445, 2.15523027]), 'targetState': array([0.40873748, 0.87040682]), 'effectorPosition': array([0.35285966, 0.87865541])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8699806087979153
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.149904  , 2.34624848]), 'currentState': array([0.11130445, 2.15523027]), 'targetState': array([0.40873748, 0.87040682]), 'effectorPosition': array([0.35285966, 0.87865541])}
episode index:250
target Thresh 0.9082448125172597
current state at start:  [-0.94643351 -2.58453669]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.94643351, -2.58453669]), 'currentState': array([5.49302978, 3.24423529]), 'targetState': array([ 0.00158051, -0.00674338]), 'effectorPosition': array([-0.06909194, -0.07584569])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.870498614340553
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.94643351, -2.58453669]), 'currentState': array([5.49302978, 3.24423529]), 'targetState': array([ 0.00158051, -0.00674338]), 'effectorPosition': array([-0.06909194, -0.07584569])}
episode index:251
target Thresh 0.9104261408367962
current state at start:  [-0.34205719 -2.81392893]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.34205719, -2.81392893]), 'currentState': array([5.48998256, 3.87981627]), 'targetState': array([-0.19384377, -0.75128464]), 'effectorPosition': array([-0.2969224 , -0.65765242])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8710125087280906
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.34205719, -2.81392893]), 'currentState': array([5.48998256, 3.87981627]), 'targetState': array([-0.19384377, -0.75128464]), 'effectorPosition': array([-0.2969224 , -0.65765242])}
episode index:252
target Thresh 0.9126031108594435
current state at start:  [-1.89114022  1.92857024]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.89114022,  1.92857024]), 'currentState': array([4.49354312, 2.29523915]), 'targetState': array([ 0.68982142, -0.65914427]), 'effectorPosition': array([ 0.65778235, -0.49181886])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8715223407094024
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.89114022,  1.92857024]), 'currentState': array([4.49354312, 2.29523915]), 'targetState': array([ 0.68982142, -0.65914427]), 'effectorPosition': array([ 0.65778235, -0.49181886])}
episode index:253
target Thresh 0.9147757312930842
current state at start:  [-3.89837442  2.38309506]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.89837442,  2.38309506]), 'currentState': array([2.50061444, 2.43861546]), 'targetState': array([-0.82562351,  0.01658837]), 'effectorPosition': array([-0.57661069, -0.37640196])}
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.8715808546110037
{'reset': False, 'endBeforeDone': False, 'stepCount': 13, 'initial state': array([-3.89837442,  2.38309506]), 'currentState': array([4.26901269, 3.74753104]), 'targetState': array([-0.82562351,  0.01658837]), 'effectorPosition': array([-0.59083878,  0.08350744])}
episode index:254
target Thresh 0.9169440108282032
current state at start:  [ 0.56286611 -2.00077815]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.56286611, -2.00077815]), 'currentState': array([1.06286611, 4.16844643]), 'targetState': array([ 0.6069042 , -0.35408935]), 'effectorPosition': array([0.98231551, 0.00539953])}
done in step count: 16
reward sum = 0.8514577710948755
running average episode reward sum: 0.8715019405579993
{'reset': False, 'endBeforeDone': False, 'stepCount': 17, 'initial state': array([ 0.56286611, -2.00077815]), 'currentState': array([4.55035559, 2.1882217 ]), 'targetState': array([ 0.6069042 , -0.35408935]), 'effectorPosition': array([ 0.7367634 , -0.54708691])}
episode index:255
target Thresh 0.9191079581379213
current state at start:  [-3.9822626   2.67663199]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.9822626 ,  2.67663199]), 'currentState': array([2.80092271, 2.3246924 ]), 'targetState': array([-0.2050851 , -0.53620388]), 'effectorPosition': array([-0.54096504, -0.58171148])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.8719648236026947
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.9822626 ,  2.67663199]), 'currentState': array([3.29392751, 2.54338857]), 'targetState': array([-0.2050851 , -0.53620388]), 'effectorPosition': array([-0.08618331, -0.58298865])}
episode index:256
target Thresh 0.9212675818780309
current state at start:  [-0.73600803  2.67957638]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.73600803,  2.67957638]), 'currentState': array([5.46612644, 2.3653896 ]), 'targetState': array([0.54444083, 0.27616607]), 'effectorPosition': array([0.70683235, 0.27061149])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8724630149505441
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.73600803,  2.67957638]), 'currentState': array([5.46612644, 2.3653896 ]), 'targetState': array([0.54444083, 0.27616607]), 'effectorPosition': array([0.70683235, 0.27061149])}
episode index:257
target Thresh 0.9234228906870297
current state at start:  [-0.77408852 -2.86725797]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.77408852, -2.86725797]), 'currentState': array([5.23028217, 3.3806202 ]), 'targetState': array([ 0.12334356, -0.47126784]), 'effectorPosition': array([-0.19163552, -0.14191015])}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.8726221398828429
{'reset': False, 'endBeforeDone': False, 'stepCount': 10, 'initial state': array([-0.77408852, -2.86725797]), 'currentState': array([3.96272897, 2.71547213]), 'targetState': array([ 0.12334356, -0.47126784]), 'effectorPosition': array([ 0.24160053, -0.34709781])}
episode index:258
target Thresh 0.9255738931861557
current state at start:  [1.24626421 1.93574639]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.24626421, 1.93574639]), 'currentState': array([1.74626421, 2.10636787]), 'targetState': array([-1.03378199,  0.65229167]), 'effectorPosition': array([-0.93225279,  0.33202329])}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.8728156632594649
{'reset': False, 'endBeforeDone': False, 'stepCount': 9, 'initial state': array([1.24626421, 1.93574639]), 'currentState': array([3.53455665, 4.62119075]), 'targetState': array([-1.03378199,  0.65229167]), 'effectorPosition': array([-1.22098476,  0.57188501])}
episode index:259
target Thresh 0.9277205979794219
current state at start:  [-4.41014106  2.99022184]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.41014106,  2.99022184]), 'currentState': array([2.16127258, 2.87809054]), 'targetState': array([-0.43287025, -0.01413487]), 'effectorPosition': array([-0.23557774, -0.11634291])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.87330483378539
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.41014106,  2.99022184]), 'currentState': array([2.16127258, 2.87809054]), 'targetState': array([-0.43287025, -0.01413487]), 'effectorPosition': array([-0.23557774, -0.11634291])}
episode index:260
target Thresh 0.9298630136536501
current state at start:  [0.73829022 2.68488268]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.73829022, 2.68488268]), 'currentState': array([0.46923688, 3.0670828 ]), 'targetState': array([0.23293473, 0.02625213]), 'effectorPosition': array([-0.03118794,  0.06764956])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.8737519417019212
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.73829022, 2.68488268]), 'currentState': array([0.42968267, 3.23615881]), 'targetState': array([0.23293473, 0.02625213]), 'effectorPosition': array([ 0.0433978 , -0.08398052])}
episode index:261
target Thresh 0.9320011487785065
current state at start:  [0.01021235 2.72276363]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.01021235, 2.72276363]), 'currentState': array([0.17835035, 2.69744883]), 'targetState': array([0.06535728, 0.62086328]), 'effectorPosition': array([0.01925331, 0.4400813 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8742338045198528
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.01021235, 2.72276363]), 'currentState': array([0.17835035, 2.69744883]), 'targetState': array([0.06535728, 0.62086328]), 'effectorPosition': array([0.01925331, 0.4400813 ])}
episode index:262
target Thresh 0.9341350119065337
current state at start:  [ 3.2611359  -2.49849047]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.2611359 , -2.49849047]), 'currentState': array([3.50424717, 4.28469483]), 'targetState': array([-0.27043586,  0.79197958]), 'effectorPosition': array([-0.86996462,  0.64312833])}
done in step count: 38
reward sum = 0.682554595010387
running average episode reward sum: 0.8735049862327444
{'reset': False, 'endBeforeDone': False, 'stepCount': 39, 'initial state': array([ 3.2611359 , -2.49849047]), 'currentState': array([3.37809306, 3.87298461]), 'targetState': array([-0.27043586,  0.79197958]), 'effectorPosition': array([-0.40512705,  0.58939054])}
episode index:263
target Thresh 0.9362646115731874
current state at start:  [0.94737807 2.66373678]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.94737807, 2.66373678]), 'currentState': array([1.26014868, 2.99643117]), 'targetState': array([-0.54509032,  0.07175826]), 'effectorPosition': array([-0.13451364,  0.05423065])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.8739462552242871
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.94737807, 2.66373678]), 'currentState': array([1.72033948, 2.78088943]), 'targetState': array([-0.54509032,  0.07175826]), 'effectorPosition': array([-0.35858074,  0.01105082])}
episode index:264
target Thresh 0.9383899562968692
current state at start:  [ 3.64726387 -1.74540049]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.64726387, -1.74540049]), 'currentState': array([3.8187748 , 4.50770005]), 'targetState': array([-1.06797433,  0.58362685]), 'effectorPosition': array([-1.23444922,  0.26383693])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.8743841938838182
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.64726387, -1.74540049]), 'currentState': array([3.60139908, 4.44736374]), 'targetState': array([-1.06797433,  0.58362685]), 'effectorPosition': array([-1.08969028,  0.5373154 ])}
episode index:265
target Thresh 0.9405110545789606
current state at start:  [ 0.29153444 -2.70140214]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.29153444, -2.70140214]), 'currentState': array([6.23263381, 3.8277295 ]), 'targetState': array([ 0.54387501, -0.77753978]), 'effectorPosition': array([ 0.1939982 , -0.64417863])}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.8745660002768412
{'reset': False, 'endBeforeDone': False, 'stepCount': 9, 'initial state': array([ 0.29153444, -2.70140214]), 'currentState': array([0.18888017, 4.04315666]), 'targetState': array([ 0.54387501, -0.77753978]), 'effectorPosition': array([ 0.5201236 , -0.69907315])}
episode index:266
target Thresh 0.9426279149038579
current state at start:  [0.33355103 2.73638299]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.33355103, 2.73638299]), 'currentState': array([0.07900889, 3.23638299]), 'targetState': array([-0.12788739, -0.02194496]), 'effectorPosition': array([ 0.01194553, -0.09399886])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8750357905379765
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.33355103, 2.73638299]), 'currentState': array([0.07900889, 3.23638299]), 'targetState': array([-0.12788739, -0.02194496]), 'effectorPosition': array([ 0.01194553, -0.09399886])}
episode index:267
target Thresh 0.9447405457390046
current state at start:  [-0.30241384  2.81333811]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.30241384,  2.81333811]), 'currentState': array([5.97206375, 2.66299019]), 'targetState': array([0.26834083, 0.41596995]), 'effectorPosition': array([0.2479495 , 0.40403246])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8755020749016408
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.30241384,  2.81333811]), 'currentState': array([5.97206375, 2.66299019]), 'targetState': array([0.26834083, 0.41596995]), 'effectorPosition': array([0.2479495 , 0.40403246])}
episode index:268
target Thresh 0.9468489555349275
current state at start:  [1.92846289 2.36561133]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.92846289, 2.36561133]), 'currentState': array([2.10547565, 2.86561133]), 'targetState': array([-0.58887492,  0.28696959]), 'effectorPosition': array([-0.25374305, -0.1062918 ])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.8758184092328615
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([1.92846289, 2.36561133]), 'currentState': array([3.90678115, 3.66248927]), 'targetState': array([-0.58887492,  0.28696959]), 'effectorPosition': array([-0.4403715 ,  0.26706984])}
episode index:269
target Thresh 0.9489531527252684
current state at start:  [0.71991275 2.04768044]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.71991275, 2.04768044]), 'currentState': array([1.01523931, 2.4214029 ]), 'targetState': array([-0.40536637,  0.85154414]), 'effectorPosition': array([-0.4293711 ,  0.55881953])}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.8759922102891395
{'reset': False, 'endBeforeDone': False, 'stepCount': 9, 'initial state': array([0.71991275, 2.04768044]), 'currentState': array([3.36954309, 4.06083483]), 'targetState': array([-0.40536637,  0.85154414]), 'effectorPosition': array([-0.56308329,  0.68563211])}
episode index:270
target Thresh 0.9510531457268185
current state at start:  [-0.32792603  2.25347292]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.32792603,  2.25347292]), 'currentState': array([6.17197745, 1.84842312]), 'targetState': array([0.89189737, 0.62930028]), 'effectorPosition': array([0.82817095, 0.87520552])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.876340205823128
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-0.32792603,  2.25347292]), 'currentState': array([6.03670947, 1.6862855 ]), 'targetState': array([0.89189737, 0.62930028]), 'effectorPosition': array([1.10039071, 0.74744568])}
episode index:271
target Thresh 0.9531489429395532
current state at start:  [-1.47951018  2.31937115]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.47951018,  2.31937115]), 'currentState': array([4.99450944, 2.08152206]), 'targetState': array([ 0.8273781 , -0.27575993]), 'effectorPosition': array([ 0.98021357, -0.24811361])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8767948374193665
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.47951018,  2.31937115]), 'currentState': array([4.99450944, 2.08152206]), 'targetState': array([ 0.8273781 , -0.27575993]), 'effectorPosition': array([ 0.98021357, -0.24811361])}
episode index:272
target Thresh 0.9552405527466636
current state at start:  [-2.82474087  2.95130682]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.82474087,  2.95130682]), 'currentState': array([3.95844443, 2.71945003]), 'targetState': array([ 0.42962006, -0.50264971]), 'effectorPosition': array([ 0.23858881, -0.3444547 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8772461383812002
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.82474087,  2.95130682]), 'currentState': array([3.95844443, 2.71945003]), 'targetState': array([ 0.42962006, -0.50264971]), 'effectorPosition': array([ 0.23858881, -0.3444547 ])}
episode index:273
target Thresh 0.9573279835145923
current state at start:  [-0.79422453  2.2670282 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.79422453,  2.2670282 ]), 'currentState': array([5.94396159, 2.1780534 ]), 'targetState': array([0.82624048, 0.57523926]), 'effectorPosition': array([0.67817774, 0.63153845])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8776941451754294
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.79422453,  2.2670282 ]), 'currentState': array([5.94396159, 2.1780534 ]), 'targetState': array([0.82624048, 0.57523926]), 'effectorPosition': array([0.67817774, 0.63153845])}
episode index:274
target Thresh 0.9594112435930646
current state at start:  [ 3.38990654 -2.46066621]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.38990654, -2.46066621]), 'currentState': array([3.59364249, 3.59585274]), 'targetState': array([-0.06060229,  0.58823747]), 'effectorPosition': array([-0.28289871,  0.35042321])}
done in step count: 17
reward sum = 0.8429431933839268
running average episode reward sum: 0.8775677780780058
{'reset': False, 'endBeforeDone': False, 'stepCount': 18, 'initial state': array([ 3.38990654, -2.46066621]), 'currentState': array([3.42075869, 3.61275869]), 'targetState': array([-0.06060229,  0.58823747]), 'effectorPosition': array([-0.2298231 ,  0.40632763])}
episode index:275
target Thresh 0.9614903413151239
current state at start:  [ 0.11252712 -1.98299327]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.11252712, -1.98299327]), 'currentState': array([0.37186305, 4.57313273]), 'targetState': array([ 0.69722014, -0.73444331]), 'effectorPosition': array([ 1.16216692, -0.60971702])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.8777993446407703
{'reset': False, 'endBeforeDone': False, 'stepCount': 7, 'initial state': array([ 0.11252712, -1.98299327]), 'currentState': array([0.46816499, 4.02975186]), 'targetState': array([ 0.69722014, -0.73444331]), 'effectorPosition': array([ 0.67956615, -0.52583939])}
episode index:276
target Thresh 0.9635652849971639
current state at start:  [-0.25128011 -1.6246202 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.25128011, -1.6246202 ]), 'currentState': array([0.08618285, 4.70929784]), 'targetState': array([ 0.79177322, -0.76105741]), 'effectorPosition': array([ 1.07928468, -0.91047367])}
done in step count: 37
reward sum = 0.6894490858690777
running average episode reward sum: 0.8771193798076595
{'reset': False, 'endBeforeDone': False, 'stepCount': 38, 'initial state': array([-0.25128011, -1.6246202 ]), 'currentState': array([4.53127626, 1.81705159]), 'targetState': array([ 0.79177322, -0.76105741]), 'effectorPosition': array([ 0.81775477, -0.91854739])}
episode index:277
target Thresh 0.9656360829389616
current state at start:  [0.8045526  2.73181185]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.8045526 , 2.73181185]), 'currentState': array([0.54394739, 2.45443761]), 'targetState': array([0.094224  , 0.18063596]), 'effectorPosition': array([-0.13409079,  0.66023635])}
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.8771527089152439
{'reset': False, 'endBeforeDone': False, 'stepCount': 13, 'initial state': array([0.8045526 , 2.73181185]), 'currentState': array([3.17592331, 3.14332953]), 'targetState': array([0.094224  , 0.18063596]), 'effectorPosition': array([-6.11239997e-05,  1.73580461e-03])}
episode index:278
target Thresh 0.9677027434237124
current state at start:  [-1.33006889 -1.99082114]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.33006889, -1.99082114]), 'currentState': array([4.45311642, 4.44794937]), 'targetState': array([-1.03840302, -0.6336173 ]), 'effectorPosition': array([-1.12234619, -0.46647853])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8775930217865154
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.33006889, -1.99082114]), 'currentState': array([4.45311642, 4.44794937]), 'targetState': array([-1.03840302, -0.6336173 ]), 'effectorPosition': array([-1.12234619, -0.46647853])}
episode index:279
target Thresh 0.9697652747180603
current state at start:  [-0.13422636 -2.2668181 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.13422636, -2.2668181 ]), 'currentState': array([5.7412523 , 4.14631201]), 'targetState': array([ 0.11134912, -1.06143915]), 'effectorPosition': array([-0.03809878, -0.96223608])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8780301895658493
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.13422636, -2.2668181 ]), 'currentState': array([5.7412523 , 4.14631201]), 'targetState': array([ 0.11134912, -1.06143915]), 'effectorPosition': array([-0.03809878, -0.96223608])}
episode index:280
target Thresh 0.9718236850721331
current state at start:  [ 4.13288456 -2.08334054]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.13288456, -2.08334054]), 'currentState': array([3.63288456, 3.69984477]), 'targetState': array([-0.6701633 ,  0.30508427]), 'effectorPosition': array([-0.3837576 ,  0.39543087])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.8783934273254015
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 4.13288456, -2.08334054]), 'currentState': array([3.90713015, 3.71747112]), 'targetState': array([-0.6701633 ,  0.30508427]), 'effectorPosition': array([-0.49363585,  0.28088283])}
episode index:281
target Thresh 0.9738779827195758
current state at start:  [-3.03096101  1.86499742]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.03096101,  1.86499742]), 'currentState': array([3.60992202, 1.99456396]), 'targetState': array([-0.75711415, -0.84344989]), 'effectorPosition': array([-0.11393374, -1.0791773 ])}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.8785507013222189
{'reset': False, 'endBeforeDone': False, 'stepCount': 9, 'initial state': array([-3.03096101,  1.86499742]), 'currentState': array([4.98911717, 4.19343724]), 'targetState': array([-0.75711415, -0.84344989]), 'effectorPosition': array([-0.69759724, -0.72209262])}
episode index:282
target Thresh 0.9759281758775809
current state at start:  [-1.74391403  1.98498084]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.74391403,  1.98498084]), 'currentState': array([4.63607317, 2.21676216]), 'targetState': array([ 0.8079613 , -0.90655178]), 'effectorPosition': array([ 0.76584803, -0.45775199])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.87890953276631
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.74391403,  1.98498084]), 'currentState': array([4.4548042 , 2.09904886]), 'targetState': array([ 0.8079613 , -0.90655178]), 'effectorPosition': array([ 0.70884681, -0.69963313])}
episode index:283
target Thresh 0.9779742727469241
current state at start:  [-0.94671311 -2.12487482]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.94671311, -2.12487482]), 'currentState': array([5.21156268, 4.55863403]), 'targetState': array([-0.53848876, -1.11925195]), 'effectorPosition': array([-0.46223352, -1.21656914])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8793359076509357
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.94671311, -2.12487482]), 'currentState': array([5.21156268, 4.55863403]), 'targetState': array([-0.53848876, -1.11925195]), 'effectorPosition': array([-0.46223352, -1.21656914])}
episode index:284
target Thresh 0.9800162815119957
current state at start:  [ 3.01893368 -2.45446887]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.01893368, -2.45446887]), 'currentState': array([3.28250351, 3.32871644]), 'targetState': array([-0.41165001,  0.22613938]), 'effectorPosition': array([-0.04341111,  0.18173809])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.8796894658697043
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 3.01893368, -2.45446887]), 'currentState': array([3.60057152, 3.47498654]), 'targetState': array([-0.41165001,  0.22613938]), 'effectorPosition': array([-0.19434751,  0.26898843])}
episode index:285
target Thresh 0.9820542103408332
current state at start:  [1.85444552 1.91510328]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.85444552, 1.91510328]), 'currentState': array([2.26272467, 1.71898549]), 'targetState': array([-1.23541163,  0.24958616]), 'effectorPosition': array([-1.30539855,  0.02529558])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8801101320729571
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.85444552, 1.91510328]), 'currentState': array([2.26272467, 1.71898549]), 'targetState': array([-1.23541163,  0.24958616]), 'effectorPosition': array([-1.30539855,  0.02529558])}
episode index:286
target Thresh 0.9840880673851549
current state at start:  [ 2.95642057 -2.35146369]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.95642057, -2.35146369]), 'currentState': array([3.34508273, 3.82072183]), 'targetState': array([-0.37129611,  0.57232116]), 'effectorPosition': array([-0.34423704,  0.57031647])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8805278668044102
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.95642057, -2.35146369]), 'currentState': array([3.34508273, 3.82072183]), 'targetState': array([-0.37129611,  0.57232116]), 'effectorPosition': array([-0.34423704,  0.57031647])}
episode index:287
target Thresh 0.9861178607803915
current state at start:  [ 0.95579182 -2.23070916]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.95579182, -2.23070916]), 'currentState': array([1.45579182, 4.20440129]), 'targetState': array([0.82834311, 0.10586294]), 'effectorPosition': array([0.92688741, 0.40992643])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.880907978378006
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.95579182, -2.23070916]), 'currentState': array([1.52672909, 3.9168909 ]), 'targetState': array([0.82834311, 0.10586294]), 'effectorPosition': array([0.71183942, 0.25467628])}
episode index:288
target Thresh 0.9881435986457197
current state at start:  [ 1.93189611 -2.55669164]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.93189611, -2.55669164]), 'currentState': array([2.2243494 , 4.22649367]), 'targetState': array([0.43782179, 0.75828692]), 'effectorPosition': array([0.3779672 , 0.96080192])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8813200614978053
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.93189611, -2.55669164]), 'currentState': array([2.2243494 , 4.22649367]), 'targetState': array([0.43782179, 0.75828692]), 'effectorPosition': array([0.3779672 , 0.96080192])}
episode index:289
target Thresh 0.9901652890840928
current state at start:  [ 3.22710082 -1.97011327]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.22710082, -1.97011327]), 'currentState': array([3.43638144, 3.97523017]), 'targetState': array([-0.31357359,  0.63112016]), 'effectorPosition': array([-0.52878098,  0.61320188])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8817293026650542
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.22710082, -1.97011327]), 'currentState': array([3.43638144, 3.97523017]), 'targetState': array([-0.31357359,  0.63112016]), 'effectorPosition': array([-0.52878098,  0.61320188])}
episode index:290
target Thresh 0.9921829401822764
current state at start:  [-3.47342799  2.66466424]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.47342799,  2.66466424]), 'currentState': array([3.09006604, 3.1295543 ]), 'targetState': array([-0.18181245, -0.11112957]), 'effectorPosition': array([-0.00069237, -0.01201835])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8821357311782329
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.47342799,  2.66466424]), 'currentState': array([3.09006604, 3.1295543 ]), 'targetState': array([-0.18181245, -0.11112957]), 'effectorPosition': array([-0.00069237, -0.01201835])}
episode index:291
target Thresh 0.9941965600108766
current state at start:  [1.13878435 2.68296847]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.13878435, 2.68296847]), 'currentState': array([1.41228002, 2.79623795]), 'targetState': array([-0.32773999,  0.02370119]), 'effectorPosition': array([-0.32496578,  0.11174244])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8825393759344718
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.13878435, 2.68296847]), 'currentState': array([1.41228002, 2.79623795]), 'targetState': array([-0.32773999,  0.02370119]), 'effectorPosition': array([-0.32496578,  0.11174244])}
episode index:292
target Thresh 0.9962061566243756
current state at start:  [0.52371685 2.69834844]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.52371685, 2.69834844]), 'currentState': array([0.28289282, 3.06313131]), 'targetState': array([-0.19147567, -0.03354305]), 'effectorPosition': array([-0.01892459,  0.07612414])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8829402654364019
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.52371685, 2.69834844]), 'currentState': array([0.28289282, 3.06313131]), 'targetState': array([-0.19147567, -0.03354305]), 'effectorPosition': array([-0.01892459,  0.07612414])}
episode index:293
target Thresh 0.9982117380611633
current state at start:  [ 2.55438463 -2.66710258]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.55438463, -2.66710258]), 'currentState': array([3.01492277, 3.73907902]), 'targetState': array([-0.31441181,  0.55784183]), 'effectorPosition': array([-0.10078988,  0.57994549])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8833384277988632
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.55438463, -2.66710258]), 'currentState': array([3.01492277, 3.73907902]), 'targetState': array([-0.31441181,  0.55784183]), 'effectorPosition': array([-0.10078988,  0.57994549])}
episode index:294
target Thresh 1.000213312343567
current state at start:  [-0.32280974 -2.67979104]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.32280974, -2.67979104]), 'currentState': array([5.74611227, 3.79283151]), 'targetState': array([ 0.26338939, -0.65162097]), 'effectorPosition': array([-0.13428029, -0.62554129])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.8836999924503924
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.32280974, -2.67979104]), 'currentState': array([6.00935619, 3.87574934]), 'targetState': array([ 0.26338939, -0.65162097]), 'effectorPosition': array([ 0.06683546, -0.71466146])}
episode index:295
target Thresh 1.0022108874778872
current state at start:  [-1.74715396 -2.01578239]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.74715396, -2.01578239]), 'currentState': array([4.98204742, 4.51007268]), 'targetState': array([-0.85152888, -0.56846979]), 'effectorPosition': array([-0.73133114, -1.0311532 ])}
done in step count: 24
reward sum = 0.7856781408072188
running average episode reward sum: 0.8833688375461924
{'reset': False, 'endBeforeDone': False, 'stepCount': 25, 'initial state': array([-1.74715396, -2.01578239]), 'currentState': array([4.78363474, 4.12271572]), 'targetState': array([-0.85152888, -0.56846979]), 'effectorPosition': array([-0.79741395, -0.50194821])}
episode index:296
target Thresh 1.0042044714544271
current state at start:  [0.36494452 2.15289528]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.36494452, 2.15289528]), 'currentState': array([0.83141369, 1.82014034]), 'targetState': array([-0.00702818,  1.28212819]), 'effectorPosition': array([-0.2084828 ,  1.20954466])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8837615350628719
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.36494452, 2.15289528]), 'currentState': array([0.83141369, 1.82014034]), 'targetState': array([-0.00702818,  1.28212819]), 'effectorPosition': array([-0.2084828 ,  1.20954466])}
episode index:297
target Thresh 1.0061940722475249
current state at start:  [ 0.92186316 -2.36214889]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.92186316, -2.36214889]), 'currentState': array([1.17318722, 4.0837551 ]), 'targetState': array([ 1.01561776, -0.27713196]), 'effectorPosition': array([0.90525116, 0.06663065])}
done in step count: 27
reward sum = 0.7623427143471035
running average episode reward sum: 0.883354089355772
{'reset': False, 'endBeforeDone': False, 'stepCount': 28, 'initial state': array([ 0.92186316, -2.36214889]), 'currentState': array([5.11167167, 2.15627577]), 'targetState': array([ 1.01561776, -0.27713196]), 'effectorPosition': array([ 0.94181886, -0.08819953])}
episode index:298
target Thresh 1.0081796978155868
current state at start:  [-0.65562572  2.25135861]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.65562572,  2.25135861]), 'currentState': array([6.12755958, 2.24147337]), 'targetState': array([0.41771327, 0.50562083]), 'effectorPosition': array([0.49533522, 0.71526915])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.883744209458261
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.65562572,  2.25135861]), 'currentState': array([6.12755958, 2.24147337]), 'targetState': array([0.41771327, 0.50562083]), 'effectorPosition': array([0.49533522, 0.71526915])}
episode index:299
target Thresh 1.0101613561011171
current state at start:  [-1.31562238 -2.85604537]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.31562238, -2.85604537]), 'currentState': array([5.46756293, 3.23819697]), 'targetState': array([ 0.12480171, -0.33458862]), 'effectorPosition': array([-0.0670375, -0.0695062])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.8839366625914035
{'reset': False, 'endBeforeDone': False, 'stepCount': 7, 'initial state': array([-1.31562238, -2.85604537]), 'currentState': array([6.06440857, 3.66631985]), 'targetState': array([ 0.12480171, -0.33458862]), 'effectorPosition': array([ 0.02260257, -0.51823531])}
episode index:300
target Thresh 1.0121390550307525
current state at start:  [0.39328127 2.83818668]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.39328127, 2.83818668]), 'currentState': array([6.23334788, 3.33818668]), 'targetState': array([ 0.03063617, -0.06527318]), 'effectorPosition': array([ 0.00950781, -0.19604717])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8843222550744886
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.39328127, 2.83818668]), 'currentState': array([6.23334788, 3.33818668]), 'targetState': array([ 0.03063617, -0.06527318]), 'effectorPosition': array([ 0.00950781, -0.19604717])}
episode index:301
target Thresh 1.0141128025152906
current state at start:  [-0.10205953 -2.0619285 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.10205953, -2.0619285 ]), 'currentState': array([5.89184167, 4.72125681]), 'targetState': array([-0.07058703, -1.39265436]), 'effectorPosition': array([ 0.55117886, -1.30917428])}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.8844494816948641
{'reset': False, 'endBeforeDone': False, 'stepCount': 9, 'initial state': array([-0.10205953, -2.0619285 ]), 'currentState': array([3.96383791, 1.71268783]), 'targetState': array([-0.07058703, -1.39265436]), 'effectorPosition': array([ 0.14097918, -1.30280204])}
episode index:302
target Thresh 1.0160826064497241
current state at start:  [-1.35043869  2.1576968 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.35043869,  2.1576968 ]), 'currentState': array([5.26879644, 1.74406295]), 'targetState': array([1.38155309, 0.23952964]), 'effectorPosition': array([ 1.27353069, -0.18253122])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.8847978332404257
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.35043869,  2.1576968 ]), 'currentState': array([5.60481691, 1.55195715]), 'targetState': array([1.38155309, 0.23952964]), 'effectorPosition': array([1.42067704, 0.13911463])}
episode index:303
target Thresh 1.018048474713272
current state at start:  [1.77525503 2.04040081]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.77525503, 2.04040081]), 'currentState': array([1.65106303, 2.24892274]), 'targetState': array([-0.60991122,  0.38499089]), 'effectorPosition': array([-0.80612263,  0.30902453])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8851767877363453
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.77525503, 2.04040081]), 'currentState': array([1.65106303, 2.24892274]), 'targetState': array([-0.60991122,  0.38499089]), 'effectorPosition': array([-0.80612263,  0.30902453])}
episode index:304
target Thresh 1.0200104151694092
current state at start:  [ 2.62636273 -2.19220978]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.62636273, -2.19220978]), 'currentState': array([2.98040499, 3.65988663]), 'targetState': array([-0.43664014,  0.47545039]), 'effectorPosition': array([-0.0501251 ,  0.51005516])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.8855204703995049
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 2.62636273, -2.19220978]), 'currentState': array([3.34460538, 3.81578428]), 'targetState': array([-0.43664014,  0.47545039]), 'effectorPosition': array([-0.34016023,  0.56733352])}
episode index:305
target Thresh 1.0219684356659005
current state at start:  [-4.00934392  2.03316805]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.00934392,  2.03316805]), 'currentState': array([2.65429551, 1.90274787]), 'targetState': array([-1.10964117, -0.33561948]), 'effectorPosition': array([-1.03832321, -0.51971876])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8858945865093105
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.00934392,  2.03316805]), 'currentState': array([2.65429551, 1.90274787]), 'targetState': array([-1.10964117, -0.33561948]), 'effectorPosition': array([-1.03832321, -0.51971876])}
episode index:306
target Thresh 1.0239225440348303
current state at start:  [ 1.35978456 -2.2195407 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.35978456, -2.2195407 ]), 'currentState': array([1.27861973, 4.1905878 ]), 'targetState': array([1.0648223 , 0.15021595]), 'effectorPosition': array([0.97464919, 0.23059509])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8862662653806157
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.35978456, -2.2195407 ]), 'currentState': array([1.27861973, 4.1905878 ]), 'targetState': array([1.0648223 , 0.15021595]), 'effectorPosition': array([0.97464919, 0.23059509])}
episode index:307
target Thresh 1.0258727480926348
current state at start:  [-1.48873633  2.18549545]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.48873633,  2.18549545]), 'currentState': array([4.96388108, 2.16173556]), 'targetState': array([ 0.95566465, -0.30930825]), 'effectorPosition': array([ 0.91449977, -0.22227845])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8866355307527565
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.48873633,  2.18549545]), 'currentState': array([4.96388108, 2.16173556]), 'targetState': array([ 0.95566465, -0.30930825]), 'effectorPosition': array([ 0.91449977, -0.22227845])}
episode index:308
target Thresh 1.027819055640133
current state at start:  [-1.45280923  2.064024  ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.45280923,  2.064024  ]), 'currentState': array([4.50742884, 2.51061746]), 'targetState': array([ 0.52061705, -0.28117902]), 'effectorPosition': array([ 0.53839583, -0.30858507])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8870024060577638
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.45280923,  2.064024  ]), 'currentState': array([4.50742884, 2.51061746]), 'targetState': array([ 0.52061705, -0.28117902]), 'effectorPosition': array([ 0.53839583, -0.30858507])}
episode index:309
target Thresh 1.0297614744625574
current state at start:  [0.65569813 2.49545426]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.65569813, 2.49545426]), 'currentState': array([1.03700699, 2.74772254]), 'targetState': array([-0.69272254,  0.41089864]), 'effectorPosition': array([-0.29141931,  0.26117667])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.8873346563608032
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.65569813, 2.49545426]), 'currentState': array([1.48751558, 2.48693327]), 'targetState': array([-0.69272254,  0.41089864]), 'effectorPosition': array([-0.58958082,  0.25667823])}
episode index:310
target Thresh 1.031700012329586
current state at start:  [-0.84540191 -2.96600331]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.84540191, -2.96600331]), 'currentState': array([4.95047111, 3.67626613]), 'targetState': array([-0.50425492,  0.05808652]), 'effectorPosition': array([-0.46227158, -0.2558024 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.8876647700059455
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.84540191, -2.96600331]), 'currentState': array([4.62644899, 3.56888157]), 'targetState': array([-0.50425492,  0.05808652]), 'effectorPosition': array([-0.42059274, -0.05400547])}
episode index:311
target Thresh 1.0336346769953728
current state at start:  [-0.7379453  2.6589988]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.7379453,  2.6589988]), 'currentState': array([5.43872479, 2.29344688]), 'targetState': array([0.80765769, 0.19138767]), 'effectorPosition': array([0.78564366, 0.2449774 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8880248188200289
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.7379453,  2.6589988]), 'currentState': array([5.43872479, 2.29344688]), 'targetState': array([0.80765769, 0.19138767]), 'effectorPosition': array([0.78564366, 0.2449774 ])}
episode index:312
target Thresh 1.035565476198579
current state at start:  [ 0.35501412 -2.07806512]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.35501412, -2.07806512]), 'currentState': array([0.8518833 , 4.06481684]), 'targetState': array([ 0.8987703 , -0.33713366]), 'effectorPosition': array([ 0.86145978, -0.22667896])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8883825670027126
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.35501412, -2.07806512]), 'currentState': array([0.8518833 , 4.06481684]), 'targetState': array([ 0.8987703 , -0.33713366]), 'effectorPosition': array([ 0.86145978, -0.22667896])}
episode index:313
target Thresh 1.0374924176624045
current state at start:  [-3.92160043  2.1053416 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.92160043,  2.1053416 ]), 'currentState': array([2.86158487, 1.76600288]), 'targetState': array([-1.11013043, -0.72321208]), 'effectorPosition': array([-1.04575291, -0.72004341])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8887380365345511
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.92160043,  2.1053416 ]), 'currentState': array([2.86158487, 1.76600288]), 'targetState': array([-1.11013043, -0.72321208]), 'effectorPosition': array([-1.04575291, -0.72004341])}
episode index:314
target Thresh 1.0394155090946167
current state at start:  [ 3.92409431 -2.39578427]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.92409431, -2.39578427]), 'currentState': array([4.42409431, 3.5243402 ]), 'targetState': array([-0.56473192, -0.10869126]), 'effectorPosition': array([-0.37863019,  0.03681252])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.889091249116981
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.92409431, -2.39578427]), 'currentState': array([4.42409431, 3.5243402 ]), 'targetState': array([-0.56473192, -0.10869126]), 'effectorPosition': array([-0.37863019,  0.03681252])}
episode index:315
target Thresh 1.0413347581875851
current state at start:  [0.85402185 2.83104825]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.85402185, 2.83104825]), 'currentState': array([0.8951375 , 2.81716123]), 'targetState': array([0.11838786, 0.22477727]), 'effectorPosition': array([-0.21610821,  0.24006872])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.8893482356704083
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([0.85402185, 2.83104825]), 'currentState': array([1.4643717, 3.1597568]), 'targetState': array([0.11838786, 0.22477727]), 'effectorPosition': array([ 0.01807791, -0.00176533])}
episode index:316
target Thresh 1.0432501726183077
current state at start:  [ 4.17202886 -2.39636379]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.17202886, -2.39636379]), 'currentState': array([4.59202557, 3.38682151]), 'targetState': array([-0.40520214, -0.21237674]), 'effectorPosition': array([-0.24461423, -0.00055063])}
done in step count: 126
reward sum = 0.2818606955404635
running average episode reward sum: 0.887431871190503
{'reset': False, 'endBeforeDone': False, 'stepCount': 127, 'initial state': array([ 4.17202886, -2.39636379]), 'currentState': array([4.59336424, 3.77557009]), 'targetState': array([-0.40520214, -0.21237674]), 'effectorPosition': array([-0.61123758, -0.12260889])}
episode index:317
target Thresh 1.0451617600484453
current state at start:  [ 1.89947033 -2.61779101]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.89947033, -2.61779101]), 'currentState': array([2.06669154, 3.61778202]), 'targetState': array([ 0.06651951, -0.08727626]), 'effectorPosition': array([0.35024311, 0.31596434])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.8877232804005958
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 1.89947033, -2.61779101]), 'currentState': array([2.37159118, 3.23679172]), 'targetState': array([ 0.06651951, -0.08727626]), 'effectorPosition': array([0.06292077, 0.07139326])}
episode index:318
target Thresh 1.0470695281243498
current state at start:  [-1.73090005  2.09724436]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.73090005,  2.09724436]), 'currentState': array([4.64850809, 2.59724436]), 'targetState': array([ 0.6436337 , -0.16684074]), 'effectorPosition': array([ 0.50757767, -0.17729913])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8880752450388385
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.73090005,  2.09724436]), 'currentState': array([4.64850809, 2.59724436]), 'targetState': array([ 0.6436337 , -0.16684074]), 'effectorPosition': array([ 0.50757767, -0.17729913])}
episode index:319
target Thresh 1.0489734844770964
current state at start:  [ 3.42980668 -2.52392193]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.42980668, -2.52392193]), 'currentState': array([3.85558042, 3.56168277]), 'targetState': array([-0.2640318 ,  0.36788952]), 'effectorPosition': array([-0.33278831,  0.25129179])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8884250098980921
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.42980668, -2.52392193]), 'currentState': array([3.85558042, 3.56168277]), 'targetState': array([-0.2640318 ,  0.36788952]), 'effectorPosition': array([-0.33278831,  0.25129179])}
episode index:320
target Thresh 1.0508736367225127
current state at start:  [-3.53649994  2.70032979]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.53649994,  2.70032979]), 'currentState': array([3.08358935, 3.20032979]), 'targetState': array([-0.00707906, -0.0003242 ]), 'effectorPosition': array([0.00168145, 0.05870462])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8887725955370388
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.53649994,  2.70032979]), 'currentState': array([3.08358935, 3.20032979]), 'targetState': array([-0.00707906, -0.0003242 ]), 'effectorPosition': array([0.00168145, 0.05870462])}
episode index:321
target Thresh 1.0527699924612102
current state at start:  [-1.63423842 -1.96751421]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.63423842, -1.96751421]), 'currentState': array([4.87537584, 4.24900089]), 'targetState': array([-0.52014538, -0.23406244]), 'effectorPosition': array([-0.79295164, -0.69084353])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.8890562210167374
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.63423842, -1.96751421]), 'currentState': array([4.87277461, 3.91228041]), 'targetState': array([-0.52014538, -0.23406244]), 'effectorPosition': array([-0.64256229, -0.39019258])}
episode index:322
target Thresh 1.054662559278615
current state at start:  [ 2.11260134 -2.74545762]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.11260134, -2.74545762]), 'currentState': array([2.03942179, 3.70852712]), 'targetState': array([0.37139351, 0.35152272]), 'effectorPosition': array([0.40848772, 0.38214556])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8893997002086361
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.11260134, -2.74545762]), 'currentState': array([2.03942179, 3.70852712]), 'targetState': array([0.37139351, 0.35152272]), 'effectorPosition': array([0.40848772, 0.38214556])}
episode index:323
target Thresh 1.0565513447449963
current state at start:  [1.59126377 1.64392386]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.59126377, 1.64392386]), 'currentState': array([1.60199644, 2.14392386]), 'targetState': array([-0.52159943,  0.41781931]), 'effectorPosition': array([-0.85407937,  0.43130438])}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.8894459421061676
{'reset': False, 'endBeforeDone': False, 'stepCount': 11, 'initial state': array([1.59126377, 1.64392386]), 'currentState': array([3.48333269, 3.81805105]), 'targetState': array([-0.52159943,  0.41781931]), 'effectorPosition': array([-0.41727272,  0.51603675])}
episode index:324
target Thresh 1.0584363564154986
current state at start:  [0.27705024 2.46530353]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.27705024, 2.46530353]), 'currentState': array([6.06023555, 2.96530353]), 'targetState': array([0.18123232, 0.42175589]), 'effectorPosition': array([0.05389236, 0.16760986])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.8897553392073794
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.27705024, 2.46530353]), 'currentState': array([5.81933092, 2.68566331]), 'targetState': array([0.18123232, 0.42175589]), 'effectorPosition': array([0.28834249, 0.34807205])}
episode index:325
target Thresh 1.060317601830171
current state at start:  [1.56858224 2.42697959]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.56858224, 2.42697959]), 'currentState': array([1.96882243, 2.1251957 ]), 'targetState': array([-1.01681025,  0.02613348]), 'effectorPosition': array([-0.96730796,  0.1070039 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8900935130134917
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.56858224, 2.42697959]), 'currentState': array([1.96882243, 2.1251957 ]), 'targetState': array([-1.01681025,  0.02613348]), 'effectorPosition': array([-0.96730796,  0.1070039 ])}
episode index:326
target Thresh 1.062195088513998
current state at start:  [0.75083005 2.53086386]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.75083005, 2.53086386]), 'currentState': array([1.1843757 , 2.20158244]), 'targetState': array([-0.68661171,  0.80353811]), 'effectorPosition': array([-0.59341565,  0.68432325])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8904296184782822
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.75083005, 2.53086386]), 'currentState': array([1.1843757 , 2.20158244]), 'targetState': array([-0.68661171,  0.80353811]), 'effectorPosition': array([-0.59341565,  0.68432325])}
episode index:327
target Thresh 1.0640688239769287
current state at start:  [-3.7828083   2.13480376]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.7828083 ,  2.13480376]), 'currentState': array([2.97310088, 2.63480376]), 'targetState': array([-0.39419815, -0.35987863]), 'effectorPosition': array([-0.20530728, -0.45742074])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.890763674519507
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.7828083 ,  2.13480376]), 'currentState': array([2.97310088, 2.63480376]), 'targetState': array([-0.39419815, -0.35987863]), 'effectorPosition': array([-0.20530728, -0.45742074])}
episode index:328
target Thresh 1.0659388157139071
current state at start:  [-0.13915695  2.19496308]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.13915695,  2.19496308]), 'currentState': array([5.88909452, 2.69496308]), 'targetState': array([0.041114  , 0.48484649]), 'effectorPosition': array([0.25641981, 0.36115491])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8910956998249188
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.13915695,  2.19496308]), 'currentState': array([5.88909452, 2.69496308]), 'targetState': array([0.041114  , 0.48484649]), 'effectorPosition': array([0.25641981, 0.36115491])}
episode index:329
target Thresh 1.0678050712049034
current state at start:  [ 3.94912603 -2.3771635 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.94912603, -2.3771635 ]), 'currentState': array([3.60010862, 3.74065492]), 'targetState': array([-0.31524821,  0.55696881]), 'effectorPosition': array([-0.40572705,  0.42855114])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8914257128557523
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.94912603, -2.3771635 ]), 'currentState': array([3.60010862, 3.74065492]), 'targetState': array([-0.31524821,  0.55696881]), 'effectorPosition': array([-0.40572705,  0.42855114])}
episode index:330
target Thresh 1.0696675979149415
current state at start:  [ 3.39066832 -2.223624  ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.39066832, -2.223624  ]), 'currentState': array([3.81859769, 3.65463203]), 'targetState': array([-0.26125033,  0.35416828]), 'effectorPosition': array([-0.4078338 ,  0.30192407])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8917537318501458
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.39066832, -2.223624  ]), 'currentState': array([3.81859769, 3.65463203]), 'targetState': array([-0.26125033,  0.35416828]), 'effectorPosition': array([-0.4078338 ,  0.30192407])}
episode index:331
target Thresh 1.0715264032941305
current state at start:  [-0.91861217  2.63121396]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.91861217,  2.63121396]), 'currentState': array([4.980628  , 3.00553536]), 'targetState': array([-0.00646285, -0.00853407]), 'effectorPosition': array([0.1332367, 0.0270376])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8920797748265009
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.91861217,  2.63121396]), 'currentState': array([4.980628  , 3.00553536]), 'targetState': array([-0.00646285, -0.00853407]), 'effectorPosition': array([0.1332367, 0.0270376])}
episode index:332
target Thresh 1.0733814947776947
current state at start:  [-1.45095561  2.90320669]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.45095561,  2.90320669]), 'currentState': array([4.6047876, 3.1980602]), 'targetState': array([ 0.0546604 , -0.11880542]), 'effectorPosition': array([-0.05628231,  0.0044764 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8924038595867816
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.45095561,  2.90320669]), 'currentState': array([4.6047876, 3.1980602]), 'targetState': array([ 0.0546604 , -0.11880542]), 'effectorPosition': array([-0.05628231,  0.0044764 ])}
episode index:333
target Thresh 1.075232879786003
current state at start:  [0.92571366 2.98637974]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.92571366, 2.98637974]), 'currentState': array([1.42571366, 2.84899938]), 'targetState': array([-0.58468023,  0.19073074]), 'effectorPosition': array([-0.27926139,  0.08375483])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.8925507945862254
{'reset': False, 'endBeforeDone': False, 'stepCount': 7, 'initial state': array([0.92571366, 2.98637974]), 'currentState': array([4.13487905, 3.67227192]), 'targetState': array([-0.58468023,  0.19073074]), 'effectorPosition': array([-0.49912584,  0.16107897])}
episode index:334
target Thresh 1.077080565724597
current state at start:  [-4.1699492   2.43222919]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.1699492 ,  2.43222919]), 'currentState': array([2.58456127, 2.93222919]), 'targetState': array([-0.24156004,  0.29299967]), 'effectorPosition': array([-0.12841259, -0.16487386])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.8928121354979083
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-4.1699492 ,  2.43222919]), 'currentState': array([3.51587768, 3.33117391]), 'targetState': array([-0.24156004,  0.29299967]), 'effectorPosition': array([-0.08557419,  0.1688508 ])}
episode index:335
target Thresh 1.0789245599842237
current state at start:  [-0.45693012  2.89130347]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.45693012,  2.89130347]), 'currentState': array([5.54194503, 3.31836813]), 'targetState': array([ 0.06217882, -0.09192712]), 'effectorPosition': array([-0.10724335, -0.14023958])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8931311469994027
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.45693012,  2.89130347]), 'currentState': array([5.54194503, 3.31836813]), 'targetState': array([ 0.06217882, -0.09192712]), 'effectorPosition': array([-0.10724335, -0.14023958])}
episode index:336
target Thresh 1.0807648699408618
current state at start:  [ 1.55776022 -2.45545586]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.55776022, -2.45545586]), 'currentState': array([2.05776022, 3.32772945]), 'targetState': array([ 0.18710402, -0.18445607]), 'effectorPosition': array([0.15546852, 0.10186524])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.8933892148124608
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 1.55776022, -2.45545586]), 'currentState': array([3.05776022, 3.09475781]), 'targetState': array([ 0.18710402, -0.18445607]), 'effectorPosition': array([-0.00501295, -0.04656148])}
episode index:337
target Thresh 1.0826015029557543
current state at start:  [0.57247526 2.00699081]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.57247526, 2.00699081]), 'currentState': array([0.97311405, 1.78405658]), 'targetState': array([-0.02144776,  1.13285657]), 'effectorPosition': array([-0.36428728,  1.20166549])}
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.893394981201355
{'reset': False, 'endBeforeDone': False, 'stepCount': 12, 'initial state': array([0.57247526, 2.00699081]), 'currentState': array([2.37104199, 4.55406968]), 'targetState': array([-0.02144776,  1.13285657]), 'effectorPosition': array([0.08341664, 1.29526992])}
episode index:338
target Thresh 1.0844344663754355
current state at start:  [ 1.23733464 -2.09842428]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.23733464, -2.09842428]), 'currentState': array([1.15507756, 3.7993208 ]), 'targetState': array([ 1.24784742, -0.24218189]), 'effectorPosition': array([ 0.64350152, -0.05603209])}
done in step count: 74
reward sum = 0.47534004200570695
running average episode reward sum: 0.8921617807907484
{'reset': False, 'endBeforeDone': False, 'stepCount': 75, 'initial state': array([ 1.23733464, -2.09842428]), 'currentState': array([0.91263346, 4.3382048 ]), 'targetState': array([ 1.24784742, -0.24218189]), 'effectorPosition': array([ 1.1244698 , -0.06738765])}
episode index:339
target Thresh 1.086263767531761
current state at start:  [-2.230707    2.54157929]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.230707  ,  2.54157929]), 'currentState': array([3.8850589 , 2.63188421]), 'targetState': array([ 0.29660063, -0.27982553]), 'effectorPosition': array([ 0.23667595, -0.44520881])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8924789520237167
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.230707  ,  2.54157929]), 'currentState': array([3.8850589 , 2.63188421]), 'targetState': array([ 0.29660063, -0.27982553]), 'effectorPosition': array([ 0.23667595, -0.44520881])}
episode index:340
target Thresh 1.0880894137419388
current state at start:  [-3.80970551  2.13463837]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.80970551,  2.13463837]), 'currentState': array([2.75096607, 1.67464942]), 'targetState': array([-1.01197998, -0.89698658]), 'effectorPosition': array([-1.20752962, -0.57839364])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.8927649375016531
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.80970551,  2.13463837]), 'currentState': array([3.12512075, 1.51012499]), 'targetState': array([-1.01197998, -0.89698658]), 'effectorPosition': array([-1.07693109, -0.98055478])}
episode index:341
target Thresh 1.0899114123085554
current state at start:  [-0.06143128 -2.02478126]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.06143128, -2.02478126]), 'currentState': array([0.22348649, 3.82791111]), 'targetState': array([ 0.7023834 , -0.44957008]), 'effectorPosition': array([ 0.36123093, -0.56775326])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.8930203031814729
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-0.06143128, -2.02478126]), 'currentState': array([0.43844597, 3.86385915]), 'targetState': array([ 0.7023834 , -0.44957008]), 'effectorPosition': array([ 0.50672625, -0.49255445])}
episode index:342
target Thresh 1.0917297705196078
current state at start:  [-2.41726581  1.57095204]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.41726581,  1.57095204]), 'currentState': array([3.87626599, 1.90436916]), 'targetState': array([-0.58021002, -1.24549561]), 'effectorPosition': array([ 0.13430733, -1.15200674])}
done in step count: 67
reward sum = 0.5099857462495653
running average episode reward sum: 0.8919035843565986
{'reset': False, 'endBeforeDone': False, 'stepCount': 68, 'initial state': array([-2.41726581,  1.57095204]), 'currentState': array([3.40905825, 1.90276311]), 'targetState': array([-0.58021002, -1.24549561]), 'effectorPosition': array([-0.4002699 , -1.08994398])}
episode index:343
target Thresh 1.0935444956485316
current state at start:  [-1.38973255  2.73647438]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.38973255,  2.73647438]), 'currentState': array([4.39345276, 3.09362479]), 'targetState': array([-0.00180911, -0.00114009]), 'effectorPosition': array([ 0.04517069, -0.01612711])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8922178181230037
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.38973255,  2.73647438]), 'currentState': array([4.39345276, 3.09362479]), 'targetState': array([-0.00180911, -0.00114009]), 'effectorPosition': array([ 0.04517069, -0.01612711])}
episode index:344
target Thresh 1.0953555949542289
current state at start:  [-1.10253806 -2.18056985]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.10253806, -2.18056985]), 'currentState': array([4.87195342, 3.72941757]), 'targetState': array([-0.52130156, -0.28603491]), 'effectorPosition': array([-0.52083807, -0.2538307 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8925302302443864
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.10253806, -2.18056985]), 'currentState': array([4.87195342, 3.72941757]), 'targetState': array([-0.52130156, -0.28603491]), 'effectorPosition': array([-0.52083807, -0.2538307 ])}
episode index:345
target Thresh 1.0971630756811
current state at start:  [1.62249747 2.83548677]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.62249747, 2.83548677]), 'currentState': array([1.55899469, 3.21370581]), 'targetState': array([0.2205602 , 0.08116533]), 'effectorPosition': array([0.07207632, 0.00174855])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8928408365153563
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.62249747, 2.83548677]), 'currentState': array([1.55899469, 3.21370581]), 'targetState': array([0.2205602 , 0.08116533]), 'effectorPosition': array([0.07207632, 0.00174855])}
episode index:346
target Thresh 1.09896694505907
current state at start:  [2.01115798 2.16512351]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.01115798, 2.16512351]), 'currentState': array([2.36102139, 2.43299018]), 'targetState': array([-0.47677346, -0.01819966]), 'effectorPosition': array([-0.62897967, -0.2929853 ])}
done in step count: 18
reward sum = 0.8345137614500875
running average episode reward sum: 0.8926727469618541
{'reset': False, 'endBeforeDone': False, 'stepCount': 19, 'initial state': array([2.01115798, 2.16512351]), 'currentState': array([4.29455048, 3.76977792]), 'targetState': array([-0.47677346, -0.01819966]), 'effectorPosition': array([-0.61458489,  0.06399039])}
episode index:347
target Thresh 1.100767210303619
current state at start:  [-0.06276533  2.02823506]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.06276533,  2.02823506]), 'currentState': array([0.43723467, 1.86806878]), 'targetState': array([0.10715379, 1.23634713]), 'effectorPosition': array([0.23570462, 1.16559708])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8929811586085153
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.06276533,  2.02823506]), 'currentState': array([0.43723467, 1.86806878]), 'targetState': array([0.10715379, 1.23634713]), 'effectorPosition': array([0.23570462, 1.16559708])}
episode index:348
target Thresh 1.1025638786158103
current state at start:  [ 3.17507878 -1.67354345]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.17507878, -1.67354345]), 'currentState': array([3.53715754, 4.41150657]), 'targetState': array([-0.4575023 ,  0.58170739]), 'effectorPosition': array([-1.01732011,  0.61019145])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.8932307827958835
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 3.17507878, -1.67354345]), 'currentState': array([3.56671137, 4.03254956]), 'targetState': array([-0.4575023 ,  0.58170739]), 'effectorPosition': array([-0.65901465,  0.55530477])}
episode index:349
target Thresh 1.1043569571823193
current state at start:  [-0.75888455 -2.51500401]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.75888455, -2.51500401]), 'currentState': array([5.46467166, 3.61105024]), 'targetState': array([-0.11197241, -0.395828  ]), 'effectorPosition': array([-0.25638877, -0.38812006])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.893535837702181
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.75888455, -2.51500401]), 'currentState': array([5.46467166, 3.61105024]), 'targetState': array([-0.11197241, -0.395828  ]), 'effectorPosition': array([-0.25638877, -0.38812006])}
episode index:350
target Thresh 1.1061464531754628
current state at start:  [ 3.16157662 -2.12423529]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.16157662, -2.12423529]), 'currentState': array([3.37413702, 3.8071671 ]), 'targetState': array([-0.06019896,  0.4443971 ]), 'effectorPosition': array([-0.35000074,  0.55170201])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.8938106643753941
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.16157662, -2.12423529]), 'currentState': array([3.53718368, 3.41400387]), 'targetState': array([-0.06019896,  0.4443971 ]), 'effectorPosition': array([-0.13770829,  0.23406523])}
episode index:351
target Thresh 1.1079323737532274
current state at start:  [-0.06288096 -2.36817513]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.06288096, -2.36817513]), 'currentState': array([5.72719039, 4.36162688]), 'targetState': array([ 0.27285368, -1.14684799]), 'effectorPosition': array([ 0.06186653, -1.14409149])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8941123386243277
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.06288096, -2.36817513]), 'currentState': array([5.72719039, 4.36162688]), 'targetState': array([ 0.27285368, -1.14684799]), 'effectorPosition': array([ 0.06186653, -1.14409149])}
episode index:352
target Thresh 1.1097147260592974
current state at start:  [1.64308936 1.90684891]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.64308936, 1.90684891]), 'currentState': array([2.0025996 , 1.67136198]), 'targetState': array([-0.93261218,  0.49282338]), 'effectorPosition': array([-1.28011631,  0.40063669])}
done in step count: 41
reward sum = 0.6622820409839835
running average episode reward sum: 0.8934555955715222
{'reset': False, 'endBeforeDone': False, 'stepCount': 42, 'initial state': array([1.64308936, 1.90684891]), 'currentState': array([3.58740711, 4.46419754]), 'targetState': array([-0.93261218,  0.49282338]), 'effectorPosition': array([-1.09859894,  0.54934317])}
episode index:353
target Thresh 1.1114935172230846
current state at start:  [-1.6094796   2.19079121]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.6094796 ,  2.19079121]), 'currentState': array([4.64743245, 2.62952619]), 'targetState': array([ 0.50497178, -0.34277857]), 'effectorPosition': array([ 0.4806205 , -0.15980065])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.893756568465388
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.6094796 ,  2.19079121]), 'currentState': array([4.64743245, 2.62952619]), 'targetState': array([ 0.50497178, -0.34277857]), 'effectorPosition': array([ 0.4806205 , -0.15980065])}
episode index:354
target Thresh 1.1132687543597561
current state at start:  [-0.58238076 -2.50931363]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.58238076, -2.50931363]), 'currentState': array([5.94242104, 3.38965247]), 'targetState': array([ 0.17525589, -0.1753903 ]), 'effectorPosition': array([-0.0532065 , -0.24163579])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8940558457373164
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.58238076, -2.50931363]), 'currentState': array([5.94242104, 3.38965247]), 'targetState': array([ 0.17525589, -0.1753903 ]), 'effectorPosition': array([-0.0532065 , -0.24163579])}
episode index:355
target Thresh 1.1150404445702629
current state at start:  [-2.81259874  2.82749824]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.81259874,  2.82749824]), 'currentState': array([3.33961325, 3.12317984]), 'targetState': array([-0.16476814,  0.15011784]), 'effectorPosition': array([ 0.00345593, -0.01808532])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8943534416762566
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.81259874,  2.82749824]), 'currentState': array([3.33961325, 3.12317984]), 'targetState': array([-0.16476814,  0.15011784]), 'effectorPosition': array([ 0.00345593, -0.01808532])}
episode index:356
target Thresh 1.1168085949413677
current state at start:  [ 0.01546904 -2.12219847]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.01546904, -2.12219847]), 'currentState': array([0.42003945, 3.66098683]), 'targetState': array([ 0.19012822, -0.29123537]), 'effectorPosition': array([ 0.32282754, -0.39942746])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.894649370411057
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.01546904, -2.12219847]), 'currentState': array([0.42003945, 3.66098683]), 'targetState': array([ 0.19012822, -0.29123537]), 'effectorPosition': array([ 0.32282754, -0.39942746])}
episode index:357
target Thresh 1.1185732125456749
current state at start:  [0.19826203 2.43616692]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.19826203, 2.43616692]), 'currentState': array([0.69826203, 1.94873972]), 'targetState': array([-0.02734451,  1.12026885]), 'effectorPosition': array([-0.11420231,  1.11755906])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8949436459127021
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.19826203, 2.43616692]), 'currentState': array([0.69826203, 1.94873972]), 'targetState': array([-0.02734451,  1.12026885]), 'effectorPosition': array([-0.11420231,  1.11755906])}
episode index:358
target Thresh 1.120334304441657
current state at start:  [ 1.0299464  -2.62519171]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.0299464 , -2.62519171]), 'currentState': array([1.5299464 , 3.20353611]), 'targetState': array([0.00209574, 0.0081447 ]), 'effectorPosition': array([ 0.06193053, -0.00061178])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8952362819965107
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.0299464 , -2.62519171]), 'currentState': array([1.5299464 , 3.20353611]), 'targetState': array([0.00209574, 0.0081447 ]), 'effectorPosition': array([ 0.06193053, -0.00061178])}
episode index:359
target Thresh 1.122091877673684
current state at start:  [ 3.59390359 -2.61202552]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.59390359, -2.61202552]), 'currentState': array([4.05204981, 3.32592542]), 'targetState': array([-0.24606513,  0.20650414]), 'effectorPosition': array([-0.15515156,  0.09904777])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8955272923242982
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.59390359, -2.61202552]), 'currentState': array([4.05204981, 3.32592542]), 'targetState': array([-0.24606513,  0.20650414]), 'effectorPosition': array([-0.15515156,  0.09904777])}
episode index:360
target Thresh 1.123845939272051
current state at start:  [-1.67474683  2.88701581]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.67474683,  2.88701581]), 'currentState': array([4.2896481 , 3.22677224]), 'targetState': array([-0.04346432,  0.02935401]), 'effectorPosition': array([-0.07907458,  0.03159725])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8958166904065024
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.67474683,  2.88701581]), 'currentState': array([4.2896481 , 3.22677224]), 'targetState': array([-0.04346432,  0.02935401]), 'effectorPosition': array([-0.07907458,  0.03159725])}
episode index:361
target Thresh 1.125596496253007
current state at start:  [ 1.22489217 -1.7824541 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.22489217, -1.7824541 ]), 'currentState': array([1.72489217, 4.0594821 ]), 'targetState': array([0.70548082, 0.29747786]), 'effectorPosition': array([0.72466524, 0.50976893])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8961044896042745
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.22489217, -1.7824541 ]), 'currentState': array([1.72489217, 4.0594821 ]), 'targetState': array([0.70548082, 0.29747786]), 'effectorPosition': array([0.72466524, 0.50976893])}
episode index:362
target Thresh 1.1273435556187823
current state at start:  [ 0.19119879 -1.95802944]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.19119879, -1.95802944]), 'currentState': array([0.46364292, 4.26341641]), 'targetState': array([ 0.4690731 , -0.74479011]), 'effectorPosition': array([ 0.90909911, -0.55268299])}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.8961524586342452
{'reset': False, 'endBeforeDone': False, 'stepCount': 10, 'initial state': array([ 0.19119879, -1.95802944]), 'currentState': array([4.05314066, 2.09864847]), 'targetState': array([ 0.4690731 , -0.74479011]), 'effectorPosition': array([ 0.37885708, -0.92147128])}
episode index:363
target Thresh 1.1290871243576162
current state at start:  [-1.27622926  2.38502031]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.27622926,  2.38502031]), 'currentState': array([4.55422083, 2.60992292]), 'targetState': array([ 0.34591883, -0.12156244]), 'effectorPosition': array([ 0.47890265, -0.21616827])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8964377540775577
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.27622926,  2.38502031]), 'currentState': array([4.55422083, 2.60992292]), 'targetState': array([ 0.34591883, -0.12156244]), 'effectorPosition': array([ 0.47890265, -0.21616827])}
episode index:364
target Thresh 1.1308272094437863
current state at start:  [ 3.70510405 -2.62032642]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.70510405, -2.62032642]), 'currentState': array([3.59682498, 3.63761905]), 'targetState': array([-0.28944538,  0.53241283]), 'effectorPosition': array([-0.31750014,  0.37447605])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8967214862581672
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.70510405, -2.62032642]), 'currentState': array([3.59682498, 3.63761905]), 'targetState': array([-0.28944538,  0.53241283]), 'effectorPosition': array([-0.31750014,  0.37447605])}
episode index:365
target Thresh 1.1325638178376356
current state at start:  [ 1.12958537 -2.58868809]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.12958537, -2.58868809]), 'currentState': array([1.04782734, 3.9831868 ]), 'targetState': array([ 0.86443896, -0.16603465]), 'effectorPosition': array([ 0.8127157 , -0.08332688])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8970036679897022
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.12958537, -2.58868809]), 'currentState': array([1.04782734, 3.9831868 ]), 'targetState': array([ 0.86443896, -0.16603465]), 'effectorPosition': array([ 0.8127157 , -0.08332688])}
episode index:366
target Thresh 1.1342969564855996
current state at start:  [-1.67945595  1.86962617]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.67945595,  1.86962617]), 'currentState': array([4.40989246, 2.25815988]), 'targetState': array([ 0.77633373, -0.50684941]), 'effectorPosition': array([ 0.62894406, -0.57915984])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8972843119461335
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.67945595,  1.86962617]), 'currentState': array([4.40989246, 2.25815988]), 'targetState': array([ 0.77633373, -0.50684941]), 'effectorPosition': array([ 0.62894406, -0.57915984])}
episode index:367
target Thresh 1.136026632320235
current state at start:  [-2.824121   2.6501098]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.824121 ,  2.6501098]), 'currentState': array([3.22316611, 2.94679893]), 'targetState': array([-0.03690373, -0.08305753]), 'effectorPosition': array([-0.0030773 , -0.19446155])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8975634306636712
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.824121 ,  2.6501098]), 'currentState': array([3.22316611, 2.94679893]), 'targetState': array([-0.03690373, -0.08305753]), 'effectorPosition': array([-0.0030773 , -0.19446155])}
episode index:368
target Thresh 1.137752852260248
current state at start:  [-0.82045667 -2.31408869]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.82045667, -2.31408869]), 'currentState': array([5.70762726, 4.39097606]), 'targetState': array([ 0.03163928, -0.87001677]), 'effectorPosition': array([ 0.05744824, -1.16828285])}
done in step count: 47
reward sum = 0.6235253948912
running average episode reward sum: 0.8968207801602227
{'reset': False, 'endBeforeDone': False, 'stepCount': 48, 'initial state': array([-0.82045667, -2.31408869]), 'currentState': array([3.60453193, 2.14466942]), 'targetState': array([ 0.03163928, -0.87001677]), 'effectorPosition': array([-0.03395753, -0.95554663])}
episode index:369
target Thresh 1.1394756232105203
current state at start:  [ 2.65619923 -1.81585308]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.65619923, -1.81585308]), 'currentState': array([2.15619923, 4.56542025]), 'targetState': array([0.3373735 , 1.27004722]), 'effectorPosition': array([0.35288226, 1.25801179])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8970996429165465
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.65619923, -1.81585308]), 'currentState': array([2.15619923, 4.56542025]), 'targetState': array([0.3373735 , 1.27004722]), 'effectorPosition': array([0.35288226, 1.25801179])}
episode index:370
target Thresh 1.141194952062138
current state at start:  [2.18999713 1.67581969]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.18999713, 1.67581969]), 'currentState': array([1.80870175, 1.8287022 ]), 'targetState': array([-0.78498157,  0.71639526]), 'effectorPosition': array([-1.11525059,  0.49608832])}
done in step count: 42
reward sum = 0.6556592205741436
running average episode reward sum: 0.8964488601069982
{'reset': False, 'endBeforeDone': False, 'stepCount': 43, 'initial state': array([2.18999713, 1.67581969]), 'currentState': array([1.54364409, 1.9595812 ]), 'targetState': array([-0.78498157,  0.71639526]), 'effectorPosition': array([-0.90817154,  0.64582966])}
episode index:371
target Thresh 1.1429108456924189
current state at start:  [-3.00245823  2.16224298]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.00245823,  2.16224298]), 'currentState': array([3.35719114, 2.66224298]), 'targetState': array([ 0.12471434, -0.5288693 ]), 'effectorPosition': array([-0.01142971, -0.47463595])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8967272233862805
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.00245823,  2.16224298]), 'currentState': array([3.35719114, 2.66224298]), 'targetState': array([ 0.12471434, -0.5288693 ]), 'effectorPosition': array([-0.01142971, -0.47463595])}
episode index:372
target Thresh 1.14462331096494
current state at start:  [1.74614499 2.73475568]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.74614499, 2.73475568]), 'currentState': array([1.94251165, 3.04540332]), 'targetState': array([-0.01635795, -0.50534531]), 'effectorPosition': array([-0.09116102, -0.03057655])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.8968472044211725
{'reset': False, 'endBeforeDone': False, 'stepCount': 7, 'initial state': array([1.74614499, 2.73475568]), 'currentState': array([3.27188719, 2.77330621]), 'targetState': array([-0.01635795, -0.50534531]), 'effectorPosition': array([-0.01971032, -0.3656778 ])}
episode index:373
target Thresh 1.146332354729564
current state at start:  [ 0.55967589 -2.87019732]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.55967589, -2.87019732]), 'currentState': array([0.76479389, 3.20391638]), 'targetState': array([ 0.0664778 , -0.14048918]), 'effectorPosition': array([ 0.04452513, -0.04359476])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8971230140350196
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.55967589, -2.87019732]), 'currentState': array([0.76479389, 3.20391638]), 'targetState': array([ 0.0664778 , -0.14048918]), 'effectorPosition': array([ 0.04452513, -0.04359476])}
episode index:374
target Thresh 1.1480379838224692
current state at start:  [-0.25190007 -2.91032329]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.25190007, -2.91032329]), 'currentState': array([5.53128524, 3.73405877]), 'targetState': array([ 0.09360956, -0.64075526]), 'effectorPosition': array([-0.25692492, -0.52426843])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.8973442859975929
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-0.25190007, -2.91032329]), 'currentState': array([5.72282806, 3.92195446]), 'targetState': array([ 0.09360956, -0.64075526]), 'effectorPosition': array([-0.12883116, -0.74972292])}
episode index:375
target Thresh 1.1497402050661736
current state at start:  [-0.77032332  2.01208643]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.77032332,  2.01208643]), 'currentState': array([5.70637096, 1.68932608]), 'targetState': array([1.12785059, 0.1050128 ]), 'effectorPosition': array([1.28061458, 0.35145625])}
done in step count: 45
reward sum = 0.6361854860638709
running average episode reward sum: 0.8966497147211734
{'reset': False, 'endBeforeDone': False, 'stepCount': 46, 'initial state': array([-0.77032332,  2.01208643]), 'currentState': array([1.24143112, 4.09118207]), 'targetState': array([1.12785059, 0.1050128 ]), 'effectorPosition': array([0.90466005, 0.13249969])}
episode index:376
target Thresh 1.1514390252695645
current state at start:  [ 2.54129004 -2.70759616]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.54129004, -2.70759616]), 'currentState': array([2.59849718, 3.07558915]), 'targetState': array([0.22125719, 0.15711595]), 'effectorPosition': array([-0.03594923, -0.05534017])}
done in step count: 24
reward sum = 0.7856781408072188
running average episode reward sum: 0.8963553604137093
{'reset': False, 'endBeforeDone': False, 'stepCount': 25, 'initial state': array([ 2.54129004, -2.70759616]), 'currentState': array([3.12623549, 3.19883781]), 'targetState': array([0.22125719, 0.15711595]), 'effectorPosition': array([-0.00075925,  0.0572323 ])}
episode index:377
target Thresh 1.153134451227925
current state at start:  [ 1.59156956 -1.72109093]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.59156956, -1.72109093]), 'currentState': array([1.61550023, 4.85101129]), 'targetState': array([0.99761704, 0.927686  ]), 'effectorPosition': array([0.93855375, 1.181302  ])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.8965769070792815
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 1.59156956, -1.72109093]), 'currentState': array([1.58862125, 4.75916086]), 'targetState': array([0.99761704, 0.927686  ]), 'effectorPosition': array([0.98009038, 1.06439303])}
episode index:378
target Thresh 1.1548264897229612
current state at start:  [ 3.98403414 -1.9760603 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.98403414, -1.9760603 ]), 'currentState': array([3.51160301, 3.92700724]), 'targetState': array([-0.59547184,  0.56746383]), 'effectorPosition': array([-0.52879384,  0.55334143])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8968497912294681
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.98403414, -1.9760603 ]), 'currentState': array([3.51160301, 3.92700724]), 'targetState': array([-0.59547184,  0.56746383]), 'effectorPosition': array([-0.52879384,  0.55334143])}
episode index:379
target Thresh 1.1565151475228297
current state at start:  [ 2.59885482 -2.07016877]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.59885482, -2.07016877]), 'currentState': array([3.04985408, 3.77525776]), 'targetState': array([-0.40396814,  0.59031023]), 'effectorPosition': array([-0.13907838,  0.60739739])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.8970949233578116
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 2.59885482, -2.07016877]), 'currentState': array([3.44838876, 3.76827875]), 'targetState': array([-0.40396814,  0.59031023]), 'effectorPosition': array([-0.3582671 ,  0.50169096])}
episode index:380
target Thresh 1.1582004313821632
current state at start:  [ 2.51216635 -2.34856109]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.51216635, -2.34856109]), 'currentState': array([2.82837644, 3.43462422]), 'targetState': array([-0.04747008,  0.17841892]), 'effectorPosition': array([0.04844878, 0.28793668])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8973650154224893
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.51216635, -2.34856109]), 'currentState': array([2.82837644, 3.43462422]), 'targetState': array([-0.04747008,  0.17841892]), 'effectorPosition': array([0.04844878, 0.28793668])}
episode index:381
target Thresh 1.1598823480421
current state at start:  [-1.25954305  1.76836664]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.25954305,  1.76836664]), 'currentState': array([5.51857595, 1.73246849]), 'targetState': array([ 1.2235098 , -0.01745509]), 'effectorPosition': array([1.28871704, 0.13141845])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8976336933925875
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.25954305,  1.76836664]), 'currentState': array([5.51857595, 1.73246849]), 'targetState': array([ 1.2235098 , -0.01745509]), 'effectorPosition': array([1.28871704, 0.13141845])}
episode index:382
target Thresh 1.161560904230309
current state at start:  [ 3.62430109 -2.70961045]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.62430109, -2.70961045]), 'currentState': array([4.02622695, 3.07357486]), 'targetState': array([ 0.03254262, -0.10844007]), 'effectorPosition': array([ 0.05111865, -0.04484998])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.897900968344565
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.62430109, -2.70961045]), 'currentState': array([4.02622695, 3.07357486]), 'targetState': array([ 0.03254262, -0.10844007]), 'effectorPosition': array([ 0.05111865, -0.04484998])}
episode index:383
target Thresh 1.163236106661017
current state at start:  [-1.61407351  2.34120616]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.61407351,  2.34120616]), 'currentState': array([4.82966864, 2.36954185]), 'targetState': array([0.62218959, 0.15979972]), 'effectorPosition': array([ 0.72598872, -0.1999433 ])}
done in step count: 16
reward sum = 0.8514577710948755
running average episode reward sum: 0.897780022518394
{'reset': False, 'endBeforeDone': False, 'stepCount': 17, 'initial state': array([-1.61407351,  2.34120616]), 'currentState': array([5.39976262, 2.35260434]), 'targetState': array([0.62218959, 0.15979972]), 'effectorPosition': array([0.73594931, 0.22192654])}
episode index:384
target Thresh 1.164907962035036
current state at start:  [-1.00242252  2.48966844]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.00242252,  2.48966844]), 'currentState': array([5.3090474 , 2.91542025]), 'targetState': array([0.16673121, 0.34317985]), 'effectorPosition': array([0.19981289, 0.10493369])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8980455289534112
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.00242252,  2.48966844]), 'currentState': array([5.3090474 , 2.91542025]), 'targetState': array([0.16673121, 0.34317985]), 'effectorPosition': array([0.19981289, 0.10493369])}
episode index:385
target Thresh 1.1665764770397895
current state at start:  [ 1.60262928 -1.76868637]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.60262928, -1.76868637]), 'currentState': array([2.04920939, 5.01449894]), 'targetState': array([0.79763349, 1.07016192]), 'effectorPosition': array([0.25017462, 1.59137777])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.8982837529716666
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.60262928, -1.76868637]), 'currentState': array([1.57954598, 4.91565071]), 'targetState': array([0.79763349, 1.07016192]), 'effectorPosition': array([0.96886011, 1.21038839])}
episode index:386
target Thresh 1.16824165834934
current state at start:  [ 2.96692042 -1.98481258]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.96692042, -1.98481258]), 'currentState': array([3.31888808, 4.50118337]), 'targetState': array([-0.5902407 ,  0.94260395]), 'effectorPosition': array([-0.95042061,  0.82305706])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.8985207458580448
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 2.96692042, -1.98481258]), 'currentState': array([2.90454195, 4.41675228]), 'targetState': array([-0.5902407 ,  0.94260395]), 'effectorPosition': array([-0.46418458,  1.09628222])}
episode index:387
target Thresh 1.1699035126244148
current state at start:  [-3.53060267  1.7633774 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.53060267,  1.7633774 ]), 'currentState': array([3.07770357, 1.84738979]), 'targetState': array([-0.92877357, -0.68467123]), 'effectorPosition': array([-0.78685569, -0.91361795])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.8987310016676889
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-3.53060267,  1.7633774 ]), 'currentState': array([2.91714098, 1.74967419]), 'targetState': array([-0.92877357, -0.68467123]), 'effectorPosition': array([-1.02047433, -0.77638987])}
episode index:388
target Thresh 1.1715620465124332
current state at start:  [-0.28032702 -2.26573862]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.28032702, -2.26573862]), 'currentState': array([5.56809474, 4.51744668]), 'targetState': array([ 0.51394489, -1.08019733]), 'effectorPosition': array([-0.03449005, -1.2694056 ])}
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.8986764773009313
{'reset': False, 'endBeforeDone': False, 'stepCount': 14, 'initial state': array([-0.28032702, -2.26573862]), 'currentState': array([4.19965876, 2.04960285]), 'targetState': array([ 0.51394489, -1.08019733]), 'effectorPosition': array([ 0.50886644, -0.90532562])}
episode index:389
target Thresh 1.1732172666475333
current state at start:  [-0.20244022 -1.69104277]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.20244022, -1.69104277]), 'currentState': array([5.64219044, 4.50451874]), 'targetState': array([ 0.55094838, -0.84255711]), 'effectorPosition': array([ 0.05097032, -1.25882847])}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.8986911070386437
{'reset': False, 'endBeforeDone': False, 'stepCount': 11, 'initial state': array([-0.20244022, -1.69104277]), 'currentState': array([6.08725158, 4.27409626]), 'targetState': array([ 0.55094838, -0.84255711]), 'effectorPosition': array([ 0.38831175, -1.00021279])}
episode index:390
target Thresh 1.1748691796505977
current state at start:  [-1.15592482 -2.72543255]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.15592482, -2.72543255]), 'currentState': array([5.25868147, 3.55626166]), 'targetState': array([-0.09103301, -0.39919328]), 'effectorPosition': array([-0.30021973, -0.28172446])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.898950209066678
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.15592482, -2.72543255]), 'currentState': array([5.25868147, 3.55626166]), 'targetState': array([-0.09103301, -0.39919328]), 'effectorPosition': array([-0.30021973, -0.28172446])}
episode index:391
target Thresh 1.1765177921292804
current state at start:  [1.2928914  2.21826243]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.2928914 , 2.21826243]), 'currentState': array([1.7928914 , 1.91079765]), 'targetState': array([-1.07047088,  0.19125078]), 'effectorPosition': array([-1.06641339,  0.44247688])}
done in step count: 137
reward sum = 0.2523606630893462
running average episode reward sum: 0.8973007459391847
{'reset': False, 'endBeforeDone': False, 'stepCount': 138, 'initial state': array([1.2928914 , 2.21826243]), 'currentState': array([2.19038703, 1.7763987 ]), 'targetState': array([-1.07047088,  0.19125078]), 'effectorPosition': array([-1.25911712,  0.07943742])}
episode index:392
target Thresh 1.1781631106780335
current state at start:  [ 1.69745701 -1.97487743]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.69745701, -1.97487743]), 'currentState': array([1.98727395, 3.80830788]), 'targetState': array([0.3204734 , 0.42957531]), 'effectorPosition': array([0.4789165 , 0.44600955])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8975620671963369
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.69745701, -1.97487743]), 'currentState': array([1.98727395, 3.80830788]), 'targetState': array([0.3204734 , 0.42957531]), 'effectorPosition': array([0.4789165 , 0.44600955])}
episode index:393
target Thresh 1.1798051418781337
current state at start:  [-0.70518411 -2.46461422]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.70518411, -2.46461422]), 'currentState': array([5.09144249, 3.83178867]), 'targetState': array([-0.27601757, -0.55174332]), 'effectorPosition': array([-0.5067986 , -0.44823288])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.8977966812389859
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.70518411, -2.46461422]), 'currentState': array([5.18273353, 3.88228003]), 'targetState': array([-0.27601757, -0.55174332]), 'effectorPosition': array([-0.48278635, -0.53935847])}
episode index:394
target Thresh 1.1814438922977075
current state at start:  [ 1.07545041 -2.26714114]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.07545041, -2.26714114]), 'currentState': array([1.48812174, 3.54753282]), 'targetState': array([ 0.27443783, -0.02454066]), 'effectorPosition': array([0.40024512, 0.04838129])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8980554238181276
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.07545041, -2.26714114]), 'currentState': array([1.48812174, 3.54753282]), 'targetState': array([ 0.27443783, -0.02454066]), 'effectorPosition': array([0.40024512, 0.04838129])}
episode index:395
target Thresh 1.1830793684917595
current state at start:  [-2.10803881  1.86666087]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.10803881,  1.86666087]), 'currentState': array([3.67514649, 2.0434993 ]), 'targetState': array([-3.53737008e-04, -9.33092833e-01]), 'effectorPosition': array([-0.01616998, -1.04362326])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8983128596165667
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.10803881,  1.86666087]), 'currentState': array([3.67514649, 2.0434993 ]), 'targetState': array([-3.53737008e-04, -9.33092833e-01]), 'effectorPosition': array([-0.01616998, -1.04362326])}
episode index:396
target Thresh 1.184711577002196
current state at start:  [0.82592739 1.76747955]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.82592739, 1.76747955]), 'currentState': array([1.03879671, 1.46770547]), 'targetState': array([-0.30710994,  1.16934381]), 'effectorPosition': array([-0.29776042,  1.45504482])}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.8983744007621873
{'reset': False, 'endBeforeDone': False, 'stepCount': 9, 'initial state': array([0.82592739, 1.76747955]), 'currentState': array([2.64152266, 4.65098475]), 'targetState': array([-0.30710994,  1.16934381]), 'effectorPosition': array([-0.34511434,  1.32595807])}
episode index:397
target Thresh 1.1863405243578535
current state at start:  [ 0.99677567 -1.71020088]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.99677567, -1.71020088]), 'currentState': array([1.49677567, 4.26246553]), 'targetState': array([1.12533473, 0.36534467]), 'effectorPosition': array([0.93980577, 0.49696269])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8986297414637898
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.99677567, -1.71020088]), 'currentState': array([1.49677567, 4.26246553]), 'targetState': array([1.12533473, 0.36534467]), 'effectorPosition': array([0.93980577, 0.49696269])}
episode index:398
target Thresh 1.1879662170745238
current state at start:  [ 3.9741541  -2.12931398]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.9741541 , -2.12931398]), 'currentState': array([3.60134261, 3.65387132]), 'targetState': array([-0.42794338,  0.62656592]), 'effectorPosition': array([-0.33253849,  0.38230676])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.8988587396054847
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.9741541 , -2.12931398]), 'currentState': array([3.68962145, 3.82113723]), 'targetState': array([-0.42794338,  0.62656592]), 'effectorPosition': array([-0.51702938,  0.42066924])}
episode index:399
target Thresh 1.1895886616549793
current state at start:  [-2.73746361  1.77853434]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.73746361,  1.77853434]), 'currentState': array([3.88594954, 2.20631774]), 'targetState': array([ 0.23092259, -0.97115778]), 'effectorPosition': array([ 0.24630668, -0.86725925])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8991115927564709
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.73746361,  1.77853434]), 'currentState': array([3.88594954, 2.20631774]), 'targetState': array([ 0.23092259, -0.97115778]), 'effectorPosition': array([ 0.24630668, -0.86725925])}
episode index:400
target Thresh 1.1912078645890012
current state at start:  [0.22309466 2.30723203]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.22309466, 2.30723203]), 'currentState': array([0.72309466, 1.92466188]), 'targetState': array([-0.18121914,  1.1487469 ]), 'effectorPosition': array([-0.13075943,  1.13571524])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8993631847944847
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.22309466, 2.30723203]), 'currentState': array([0.72309466, 1.92466188]), 'targetState': array([-0.18121914,  1.1487469 ]), 'effectorPosition': array([-0.13075943,  1.13571524])}
episode index:401
target Thresh 1.1928238323534028
current state at start:  [-3.18352491  2.13962895]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.18352491,  2.13962895]), 'currentState': array([2.90324209, 2.63962895]), 'targetState': array([-0.21792086, -0.24856497]), 'effectorPosition': array([-0.23347212, -0.43841981])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8996135251308168
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.18352491,  2.13962895]), 'currentState': array([2.90324209, 2.63962895]), 'targetState': array([-0.21792086, -0.24856497]), 'effectorPosition': array([-0.23347212, -0.43841981])}
episode index:402
target Thresh 1.1944365714120577
current state at start:  [-0.09548979  1.70317212]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.09548979,  1.70317212]), 'currentState': array([5.81358478, 1.9517111 ]), 'targetState': array([1.20589336, 0.42316552]), 'effectorPosition': array([0.98031867, 0.54353991])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.8998378091875643
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.09548979,  1.70317212]), 'currentState': array([5.96520408, 1.68306635]), 'targetState': array([1.20589336, 0.42316552]), 'effectorPosition': array([1.15413193, 0.66626634])}
episode index:403
target Thresh 1.1960460882159243
current state at start:  [ 4.17505138 -2.34430949]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.17505138, -2.34430949]), 'currentState': array([4.10572078, 4.3606621 ]), 'targetState': array([-1.35533374,  0.08537134]), 'effectorPosition': array([-1.14496736, -0.00328208])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9000857354024465
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.17505138, -2.34430949]), 'currentState': array([4.10572078, 4.3606621 ]), 'targetState': array([-1.35533374,  0.08537134]), 'effectorPosition': array([-1.14496736, -0.00328208])}
episode index:404
target Thresh 1.1976523892030717
current state at start:  [-2.11318938  2.40287601]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.11318938,  2.40287601]), 'currentState': array([3.88938865, 2.59567112]), 'targetState': array([ 0.14032798, -0.42394341]), 'effectorPosition': array([ 0.24650303, -0.47951838])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9003324372903417
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.11318938,  2.40287601]), 'currentState': array([3.88938865, 2.59567112]), 'targetState': array([ 0.14032798, -0.42394341]), 'effectorPosition': array([ 0.24650303, -0.47951838])}
episode index:405
target Thresh 1.1992554807987061
current state at start:  [ 4.06458464 -1.98910095]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.06458464, -1.98910095]), 'currentState': array([4.56458464, 3.952515  ]), 'targetState': array([-0.53923334, -0.44116893]), 'effectorPosition': array([-0.76284383, -0.20102012])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9005532933561291
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 4.06458464, -1.98910095]), 'currentState': array([5.06458464, 4.0658763 ]), 'targetState': array([-0.53923334, -0.44116893]), 'effectorPosition': array([-0.61204096, -0.64853125])}
episode index:406
target Thresh 1.200855369415196
current state at start:  [-3.5610667   2.26587363]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.5610667 ,  2.26587363]), 'currentState': array([2.99189364, 1.94020267]), 'targetState': array([-0.79819436, -0.41262557]), 'effectorPosition': array([-0.77087201, -0.82682076])}
done in step count: 20
reward sum = 0.8179069375972308
running average episode reward sum: 0.9003502310569671
{'reset': False, 'endBeforeDone': False, 'stepCount': 21, 'initial state': array([-3.5610667 ,  2.26587363]), 'currentState': array([2.75786856, 1.96870011]), 'targetState': array([-0.79819436, -0.41262557]), 'effectorPosition': array([-0.91309764, -0.62552314])}
episode index:407
target Thresh 1.202452061452098
current state at start:  [-3.55896851  2.47375479]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.55896851,  2.47375479]), 'currentState': array([3.20013804, 2.38504015]), 'targetState': array([-0.25908971, -0.86927168]), 'effectorPosition': array([-0.23216219, -0.70120411])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9005944706867295
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.55896851,  2.47375479]), 'currentState': array([3.20013804, 2.38504015]), 'targetState': array([-0.25908971, -0.86927168]), 'effectorPosition': array([-0.23216219, -0.70120411])}
episode index:408
target Thresh 1.2040455632961824
current state at start:  [1.67933387 2.76097242]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.67933387, 2.76097242]), 'currentState': array([1.55714679, 3.26097242]), 'targetState': array([0.02302458, 0.01123462]), 'effectorPosition': array([0.11918246, 0.00549108])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9008375159906739
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.67933387, 2.76097242]), 'currentState': array([1.55714679, 3.26097242]), 'targetState': array([0.02302458, 0.01123462]), 'effectorPosition': array([0.11918246, 0.00549108])}
episode index:409
target Thresh 1.205635881321459
current state at start:  [-1.78612084  2.28734448]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.78612084,  2.28734448]), 'currentState': array([4.28432263, 2.40353277]), 'targetState': array([ 0.53784519, -0.46025008]), 'effectorPosition': array([ 0.50411993, -0.51605461])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9010793757077699
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.78612084,  2.28734448]), 'currentState': array([4.28432263, 2.40353277]), 'targetState': array([ 0.53784519, -0.46025008]), 'effectorPosition': array([ 0.50411993, -0.51605461])}
episode index:410
target Thresh 1.2072230218892013
current state at start:  [0.00601674 1.84995126]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.00601674, 1.84995126]), 'currentState': array([5.78920205, 2.1788544 ]), 'targetState': array([0.42555105, 0.49102258]), 'effectorPosition': array([0.76662368, 0.51936382])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9012957275916925
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.00601674, 1.84995126]), 'currentState': array([5.62365511, 2.38212188]), 'targetState': array([0.42555105, 0.49102258]), 'effectorPosition': array([0.6390671 , 0.37575555])}
episode index:411
target Thresh 1.2088069913479744
current state at start:  [-2.46614979  2.55005461]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.46614979,  2.55005461]), 'currentState': array([3.31703552, 2.34917547]), 'targetState': array([-0.32486438, -0.46083078]), 'effectorPosition': array([-0.16901658, -0.75311419])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9015110292237516
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.46614979,  2.55005461]), 'currentState': array([2.91127213, 2.30673618]), 'targetState': array([-0.32486438, -0.46083078]), 'effectorPosition': array([-0.4892439 , -0.64658508])}
episode index:412
target Thresh 1.210387796033658
current state at start:  [ 0.79157413 -2.16518837]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.79157413, -2.16518837]), 'currentState': array([0.53977592, 3.9604959 ]), 'targetState': array([ 0.74294723, -0.63134611]), 'effectorPosition': array([ 0.64729379, -0.4636436 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9017495013079555
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.79157413, -2.16518837]), 'currentState': array([0.53977592, 3.9604959 ]), 'targetState': array([ 0.74294723, -0.63134611]), 'effectorPosition': array([ 0.64729379, -0.4636436 ])}
episode index:413
target Thresh 1.2119654422694728
current state at start:  [ 1.55625264 -2.61344061]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.55625264, -2.61344061]), 'currentState': array([1.83399759, 3.20710587]), 'targetState': array([ 0.00180677, -0.00022753]), 'effectorPosition': array([0.06265371, 0.01910392])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9019868213531054
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.55625264, -2.61344061]), 'currentState': array([1.83399759, 3.20710587]), 'targetState': array([ 0.00180677, -0.00022753]), 'effectorPosition': array([0.06265371, 0.01910392])}
episode index:414
target Thresh 1.213539936366006
current state at start:  [-1.80490976 -2.31807142]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.80490976, -2.31807142]), 'currentState': array([3.97827554, 4.08975705]), 'targetState': array([-0.92097263,  0.1355216 ]), 'effectorPosition': array([-0.88234935,  0.23475345])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9022229976871943
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.80490976, -2.31807142]), 'currentState': array([3.97827554, 4.08975705]), 'targetState': array([-0.92097263,  0.1355216 ]), 'effectorPosition': array([-0.88234935,  0.23475345])}
episode index:415
target Thresh 1.2151112846212357
current state at start:  [-2.43434884  2.60641238]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.43434884,  2.60641238]), 'currentState': array([4.19051452, 2.18150135]), 'targetState': array([ 0.0858256 , -0.73519913]), 'effectorPosition': array([ 0.4975512 , -0.77817248])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9024340000966001
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.43434884,  2.60641238]), 'currentState': array([3.76349913, 2.31836116]), 'targetState': array([ 0.0858256 , -0.73519913]), 'effectorPosition': array([ 0.16703323, -0.78255351])}
episode index:416
target Thresh 1.2166794933205578
current state at start:  [ 2.05179253 -2.08058878]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.05179253, -2.08058878]), 'currentState': array([2.52692344, 3.86753158]), 'targetState': array([0.0611251 , 0.76167944]), 'effectorPosition': array([0.17685166, 0.68772856])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.90266797131939
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.05179253, -2.08058878]), 'currentState': array([2.52692344, 3.86753158]), 'targetState': array([0.0611251 , 0.76167944]), 'effectorPosition': array([0.17685166, 0.68772856])}
episode index:417
target Thresh 1.2182445687368086
current state at start:  [ 0.28419676 -3.01616113]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.28419676, -3.01616113]), 'currentState': array([0.0671181 , 3.74115877]), 'targetState': array([-0.1233804 , -0.25579531]), 'effectorPosition': array([ 0.21187202, -0.55131587])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.902876899617669
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.28419676, -3.01616113]), 'currentState': array([6.23919517, 3.43502037]), 'targetState': array([-0.1233804 , -0.25579531]), 'effectorPosition': array([ 0.02998118, -0.29083494])}
episode index:418
target Thresh 1.2198065171302923
current state at start:  [1.71968505 1.96799524]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.71968505, 1.96799524]), 'currentState': array([2.18054229, 1.75399957]), 'targetState': array([-1.16208789,  0.28334593]), 'effectorPosition': array([-1.2744065 ,  0.10736756])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9031086969932832
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.71968505, 1.96799524]), 'currentState': array([2.18054229, 1.75399957]), 'targetState': array([-1.16208789,  0.28334593]), 'effectorPosition': array([-1.2744065 ,  0.10736756])}
episode index:419
target Thresh 1.221365344748804
current state at start:  [-3.78627865  2.30322626]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.78627865,  2.30322626]), 'currentState': array([2.65227303, 1.87980971]), 'targetState': array([-0.97096042, -0.22216157]), 'effectorPosition': array([-1.06198372, -0.51376336])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9032920096194896
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-3.78627865,  2.30322626]), 'currentState': array([2.45063275, 1.92121473]), 'targetState': array([-0.97096042, -0.22216157]), 'effectorPosition': array([-1.10463219, -0.30529674])}
episode index:420
target Thresh 1.2229210578276564
current state at start:  [1.44285756 2.03727754]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.44285756, 2.03727754]), 'currentState': array([1.07732939, 2.05664509]), 'targetState': array([-0.43080804,  1.04165093]), 'effectorPosition': array([-0.52628894,  0.88831403])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9035217198104172
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.44285756, 2.03727754]), 'currentState': array([1.07732939, 2.05664509]), 'targetState': array([-0.43080804,  1.04165093]), 'effectorPosition': array([-0.52628894,  0.88831403])}
episode index:421
target Thresh 1.2244736625897041
current state at start:  [-1.54393181 -2.20443012]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.54393181, -2.20443012]), 'currentState': array([5.2392535 , 4.32338836]), 'targetState': array([-0.30108811, -0.88249754]), 'effectorPosition': array([-0.48768627, -1.00181551])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9037503413274541
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.54393181, -2.20443012]), 'currentState': array([5.2392535 , 4.32338836]), 'targetState': array([-0.30108811, -0.88249754]), 'effectorPosition': array([-0.48768627, -1.00181551])}
episode index:422
target Thresh 1.2260231652453684
current state at start:  [ 1.25857369 -2.06396034]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.25857369, -2.06396034]), 'currentState': array([0.98792646, 4.05540802]), 'targetState': array([ 0.8723006 , -0.20732663]), 'effectorPosition': array([ 0.87535958, -0.11084909])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9039778818916918
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.25857369, -2.06396034]), 'currentState': array([0.98792646, 4.05540802]), 'targetState': array([ 0.8723006 , -0.20732663]), 'effectorPosition': array([ 0.87535958, -0.11084909])}
episode index:423
target Thresh 1.2275695719926614
current state at start:  [0.59681973 2.16496623]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.59681973, 2.16496623]), 'currentState': array([0.38755132, 2.66496623]), 'targetState': array([-0.21986894,  0.4811462 ]), 'effectorPosition': array([-0.07019819,  0.46687982])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9042043491513813
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.59681973, 2.16496623]), 'currentState': array([0.38755132, 2.66496623]), 'targetState': array([-0.21986894,  0.4811462 ]), 'effectorPosition': array([-0.07019819,  0.46687982])}
episode index:424
target Thresh 1.2291128890172125
current state at start:  [0.45927006 1.95427731]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.45927006, 1.95427731]), 'currentState': array([0.16178194, 2.45427731]), 'targetState': array([-0.0777697 ,  0.76036742]), 'effectorPosition': array([0.12188535, 0.66275163])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9044297506827897
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.45927006, 1.95427731]), 'currentState': array([0.16178194, 2.45427731]), 'targetState': array([-0.0777697 ,  0.76036742]), 'effectorPosition': array([0.12188535, 0.66275163])}
episode index:425
target Thresh 1.2306531224922919
current state at start:  [-1.25107241  2.08000641]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.25107241,  2.08000641]), 'currentState': array([4.96656558, 2.08754853]), 'targetState': array([ 1.06076739, -0.37885247]), 'effectorPosition': array([ 0.96871234, -0.27106893])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9046540939910461
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.25107241,  2.08000641]), 'currentState': array([4.96656558, 2.08754853]), 'targetState': array([ 1.06076739, -0.37885247]), 'effectorPosition': array([ 0.96871234, -0.27106893])}
episode index:426
target Thresh 1.2321902785788355
current state at start:  [-0.96998904  1.58572076]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.96998904,  1.58572076]), 'currentState': array([5.51265913, 1.90045769]), 'targetState': array([0.78138929, 0.15180422]), 'effectorPosition': array([1.14426603, 0.20787008])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9048539673072263
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.96998904,  1.58572076]), 'currentState': array([5.30820094, 2.07973702]), 'targetState': array([0.78138929, 0.15180422]), 'effectorPosition': array([1.01053641, 0.06565995])}
episode index:427
target Thresh 1.2337243634254698
current state at start:  [ 2.43405045 -2.04855838]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.43405045, -2.04855838]), 'currentState': array([2.3531374 , 4.60955757]), 'targetState': array([0.13424867, 1.01004567]), 'effectorPosition': array([0.07293915, 1.33767684])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9050297757948264
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 2.43405045, -2.04855838]), 'currentState': array([2.26078272, 4.4269222 ]), 'targetState': array([0.13424867, 1.01004567]), 'effectorPosition': array([0.28276489, 1.16483187])}
episode index:428
target Thresh 1.2352553831685358
current state at start:  [-3.08834429  2.86097637]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.08834429,  2.86097637]), 'currentState': array([2.76381897, 3.36097637]), 'targetState': array([-0.17068154,  0.31320413]), 'effectorPosition': array([0.05799439, 0.21112352])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9052278415855144
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.08834429,  2.86097637]), 'currentState': array([2.90521648, 3.48139228]), 'targetState': array([-0.17068154,  0.31320413]), 'effectorPosition': array([0.02246357, 0.33742029])}
episode index:429
target Thresh 1.2367833439321148
current state at start:  [ 2.90759801 -1.91670455]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.90759801, -1.91670455]), 'currentState': array([3.12852172, 4.14301813]), 'targetState': array([-0.15074171,  0.49948345]), 'effectorPosition': array([-0.44984981,  0.84819256])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9053566047678737
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([ 2.90759801, -1.91670455]), 'currentState': array([3.34836351, 3.7668548 ]), 'targetState': array([-0.15074171,  0.49948345]), 'effectorPosition': array([-0.30532481,  0.53400125])}
episode index:430
target Thresh 1.2383082518280522
current state at start:  [ 3.88941318 -1.98901056]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.88941318, -1.98901056]), 'currentState': array([3.38941318, 4.63623445]), 'targetState': array([-1.18982812,  0.65437847]), 'effectorPosition': array([-1.14027343,  0.74000988])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9055761950120318
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.88941318, -1.98901056]), 'currentState': array([3.38941318, 4.63623445]), 'targetState': array([-1.18982812,  0.65437847]), 'effectorPosition': array([-1.14027343,  0.74000988])}
episode index:431
target Thresh 1.239830112955981
current state at start:  [-3.55835513  1.82733448]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.55835513,  1.82733448]), 'currentState': array([3.11899271, 2.32733448]), 'targetState': array([-0.85800673, -0.56170585]), 'effectorPosition': array([-0.32994552, -0.71994434])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9057716204865409
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.55835513,  1.82733448]), 'currentState': array([2.74236706, 1.95585661]), 'targetState': array([-0.85800673, -0.56170585]), 'effectorPosition': array([-0.93552713, -0.61119472])}
episode index:432
target Thresh 1.2413489334033483
current state at start:  [ 3.69399994 -1.90199792]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.69399994, -1.90199792]), 'currentState': array([4.12021937, 4.05250336]), 'targetState': array([-0.57323548,  0.03934421]), 'effectorPosition': array([-0.87153384,  0.11989904])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9059661433029693
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.69399994, -1.90199792]), 'currentState': array([4.23744655, 3.91270442]), 'targetState': array([-0.57323548,  0.03934421]), 'effectorPosition': array([-0.74914572,  0.06714247])}
episode index:433
target Thresh 1.2428647192454376
current state at start:  [ 0.96683575 -2.73543768]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.96683575, -2.73543768]), 'currentState': array([1.46683575, 3.14259968]), 'targetState': array([0.10902326, 0.34721714]), 'effectorPosition': array([ 0.00100164, -0.000104  ])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9061369586409809
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 0.96683575, -2.73543768]), 'currentState': array([2.17679616, 3.43297907]), 'targetState': array([0.10902326, 0.34721714]), 'effectorPosition': array([0.21211534, 0.19827775])}
episode index:434
target Thresh 1.2443774765453943
current state at start:  [-1.79789004  1.9355638 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.79789004,  1.9355638 ]), 'currentState': array([4.95122424, 2.4355638 ]), 'targetState': array([ 1.1985395 , -0.29080683]), 'effectorPosition': array([ 0.68695351, -0.07877842])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9063069886211165
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.79789004,  1.9355638 ]), 'currentState': array([4.99918756, 1.94378837]), 'targetState': array([ 1.1985395 , -0.29080683]), 'effectorPosition': array([ 1.07300361, -0.34620298])}
episode index:435
target Thresh 1.2458872113542498
current state at start:  [1.16412419 1.979253  ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.16412419, 1.979253  ]), 'currentState': array([0.92019856, 2.38424818]), 'targetState': array([-0.40371646,  0.56487429]), 'effectorPosition': array([-0.38110638,  0.63358671])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9065218808490497
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.16412419, 1.979253  ]), 'currentState': array([0.92019856, 2.38424818]), 'targetState': array([-0.40371646,  0.56487429]), 'effectorPosition': array([-0.38110638,  0.63358671])}
episode index:436
target Thresh 1.2473939297109453
current state at start:  [-4.49298589  2.76675736]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.49298589,  2.76675736]), 'currentState': array([1.78877871, 3.22181686]), 'targetState': array([-0.0712932 ,  0.05564574]), 'effectorPosition': array([0.07754623, 0.02047082])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9067357895885256
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.49298589,  2.76675736]), 'currentState': array([1.78877871, 3.22181686]), 'targetState': array([-0.0712932 ,  0.05564574]), 'effectorPosition': array([0.07754623, 0.02047082])}
episode index:437
target Thresh 1.248897637642356
current state at start:  [-1.59077839 -2.18738028]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.59077839, -2.18738028]), 'currentState': array([4.87831774, 4.59580502]), 'targetState': array([-0.91618641, -0.9429377 ]), 'effectorPosition': array([-0.83361439, -1.03559016])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9069487215757664
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.59077839, -2.18738028]), 'currentState': array([4.87831774, 4.59580502]), 'targetState': array([-0.91618641, -0.9429377 ]), 'effectorPosition': array([-0.83361439, -1.03559016])}
episode index:438
target Thresh 1.250398341163316
current state at start:  [ 1.68296619 -1.67132453]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.68296619, -1.67132453]), 'currentState': array([1.18296619, 4.50464904]), 'targetState': array([1.06098286, 0.52311589]), 'effectorPosition': array([1.20600942, 0.36475106])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9071606834856166
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.68296619, -1.67132453]), 'currentState': array([1.18296619, 4.50464904]), 'targetState': array([1.06098286, 0.52311589]), 'effectorPosition': array([1.20600942, 0.36475106])}
episode index:439
target Thresh 1.2518960462766409
current state at start:  [-0.75712068  2.59538072]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.75712068,  2.59538072]), 'currentState': array([5.06679892, 3.09538072]), 'targetState': array([ 0.00485457, -0.00042588]), 'effectorPosition': array([0.04369499, 0.01503031])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9073716819322402
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.75712068,  2.59538072]), 'currentState': array([5.06679892, 3.09538072]), 'targetState': array([ 0.00485457, -0.00042588]), 'effectorPosition': array([0.04369499, 0.01503031])}
episode index:440
target Thresh 1.2533907589731537
current state at start:  [1.09480923 2.74764235]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.09480923, 2.74764235]), 'currentState': array([1.21831213, 2.62836446]), 'targetState': array([-0.01199995,  0.46690754]), 'effectorPosition': array([-0.41632682,  0.29042023])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9075143742634596
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([1.09480923, 2.74764235]), 'currentState': array([0.68003961, 2.59536957]), 'targetState': array([-0.01199995,  0.46690754]), 'effectorPosition': array([-0.21351211,  0.49540631])}
episode index:441
target Thresh 1.2548824852317066
current state at start:  [-4.17337986  2.46077314]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.17337986,  2.46077314]), 'currentState': array([2.60877321, 1.96077314]), 'targetState': array([-1.1339689 , -0.00259759]), 'effectorPosition': array([-1.00373569, -0.48185136])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.907700993326212
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-4.17337986,  2.46077314]), 'currentState': array([2.14173646, 1.92108013]), 'targetState': array([-1.1339689 , -0.00259759]), 'effectorPosition': array([-1.14526925,  0.04505077])}
episode index:442
target Thresh 1.2563712310192072
current state at start:  [-3.33400205  3.06623128]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.33400205,  3.06623128]), 'currentState': array([3.24918362, 3.0375936 ]), 'targetState': array([ 0.12444102, -0.06234488]), 'effectorPosition': array([ 0.00577588, -0.10379161])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9079093432284102
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.33400205,  3.06623128]), 'currentState': array([3.24918362, 3.0375936 ]), 'targetState': array([ 0.12444102, -0.06234488]), 'effectorPosition': array([ 0.00577588, -0.10379161])}
episode index:443
target Thresh 1.2578570022906401
current state at start:  [-1.95628043  2.78286523]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.95628043,  2.78286523]), 'currentState': array([4.08141854, 3.28286523]), 'targetState': array([-0.13368816,  0.19749498]), 'effectorPosition': array([-0.11956934,  0.07501961])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9081167546175354
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.95628043,  2.78286523]), 'currentState': array([4.08141854, 3.28286523]), 'targetState': array([-0.13368816,  0.19749498]), 'effectorPosition': array([-0.11956934,  0.07501961])}
episode index:444
target Thresh 1.259339804989093
current state at start:  [-1.69155535 -2.60366887]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.69155535, -2.60366887]), 'currentState': array([5.03127811, 3.90515843]), 'targetState': array([-0.27353321, -0.61860887]), 'effectorPosition': array([-0.56960033, -0.48042245])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.9081705716811072
{'reset': False, 'endBeforeDone': False, 'stepCount': 8, 'initial state': array([-1.69155535, -2.60366887]), 'currentState': array([5.16203042, 3.95275122]), 'targetState': array([-0.27353321, -0.61860887]), 'effectorPosition': array([-0.51769205, -0.59554787])}
episode index:445
target Thresh 1.260819645045778
current state at start:  [0.14238293 1.85191018]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.14238293, 1.85191018]), 'currentState': array([0.64238293, 1.49089417]), 'targetState': array([0.43510576, 1.31036366]), 'effectorPosition': array([0.267384  , 1.44503983])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9083764672602975
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.14238293, 1.85191018]), 'currentState': array([0.64238293, 1.49089417]), 'targetState': array([0.43510576, 1.31036366]), 'effectorPosition': array([0.267384  , 1.44503983])}
episode index:446
target Thresh 1.262296528380058
current state at start:  [-0.38088915  2.40939103]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.38088915,  2.40939103]), 'currentState': array([0.11911085, 2.01005493]), 'targetState': array([0.6779374 , 1.00833036]), 'effectorPosition': array([0.46311069, 0.96694951])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9085814416064714
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.38088915,  2.40939103]), 'currentState': array([0.11911085, 2.01005493]), 'targetState': array([0.6779374 , 1.00833036]), 'effectorPosition': array([0.46311069, 0.96694951])}
episode index:447
target Thresh 1.2637704608994675
current state at start:  [-0.13702068  2.74543578]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.13702068,  2.74543578]), 'currentState': array([5.65009225, 3.24543578]), 'targetState': array([-0.00991581,  0.01996026]), 'effectorPosition': array([-0.05698463, -0.08675518])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9087855008885998
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.13702068,  2.74543578]), 'currentState': array([5.65009225, 3.24543578]), 'targetState': array([-0.00991581,  0.01996026]), 'effectorPosition': array([-0.05698463, -0.08675518])}
episode index:448
target Thresh 1.2652414484997392
current state at start:  [ 1.81455343 -2.51714979]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.81455343, -2.51714979]), 'currentState': array([1.81836468, 3.56641513]), 'targetState': array([0.3977046, 0.2553404]), 'effectorPosition': array([0.37781102, 0.1871764 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9089886512206964
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.81455343, -2.51714979]), 'currentState': array([1.81836468, 3.56641513]), 'targetState': array([0.3977046, 0.2553404]), 'effectorPosition': array([0.37781102, 0.1871764 ])}
episode index:449
target Thresh 1.266709497064825
current state at start:  [ 3.98608329 -2.00504968]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.98608329, -2.00504968]), 'currentState': array([4.27562105, 4.2701529 ]), 'targetState': array([-0.88014621, -0.12387736]), 'effectorPosition': array([-1.0609315, -0.1360197])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9091908986624282
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.98608329, -2.00504968]), 'currentState': array([4.27562105, 4.2701529 ]), 'targetState': array([-0.88014621, -0.12387736]), 'effectorPosition': array([-1.0609315, -0.1360197])}
episode index:450
target Thresh 1.2681746124669215
current state at start:  [ 4.02362233 -2.43535815]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.02362233, -2.43535815]), 'currentState': array([4.36404764, 4.34782716]), 'targetState': array([-1.0296487 , -0.17416728]), 'effectorPosition': array([-1.09780554, -0.28590751])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9093922492197177
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.02362233, -2.43535815]), 'currentState': array([4.36404764, 4.34782716]), 'targetState': array([-1.0296487 , -0.17416728]), 'effectorPosition': array([-1.09780554, -0.28590751])}
episode index:451
target Thresh 1.2696368005664922
current state at start:  [0.23983725 2.24825645]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.23983725, 2.24825645]), 'currentState': array([0.68808334, 1.91090504]), 'targetState': array([-0.34794276,  1.23721194]), 'effectorPosition': array([-0.0839022 ,  1.15142575])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9095705849515325
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.23983725, 2.24825645]), 'currentState': array([1.06675257, 1.51257697]), 'targetState': array([-0.34794276,  1.23721194]), 'effectorPosition': array([-0.36308047,  1.40873898])}
episode index:452
target Thresh 1.2710960672122913
current state at start:  [-2.41552316  2.07891881]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.41552316,  2.07891881]), 'currentState': array([3.36766215, 2.37287458]), 'targetState': array([-0.18327383, -0.49165459]), 'effectorPosition': array([-0.11821099, -0.74055467])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.909748133329123
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.41552316,  2.07891881]), 'currentState': array([3.18071227, 2.38217404]), 'targetState': array([-0.18327383, -0.49165459]), 'effectorPosition': array([-0.24762639, -0.69871907])}
episode index:453
target Thresh 1.2725524182413872
current state at start:  [0.56889083 1.96629154]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.56889083, 1.96629154]), 'currentState': array([0.82128074, 2.08586742]), 'targetState': array([-0.50351095,  0.63173594]), 'effectorPosition': array([-0.2913593 ,  0.96432169])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9099248995552703
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.56889083, 1.96629154]), 'currentState': array([1.20133751, 2.30303616]), 'targetState': array([-0.50351095,  0.63173594]), 'effectorPosition': array([-0.57380271,  0.5776473 ])}
episode index:454
target Thresh 1.2740058594791863
current state at start:  [ 1.69553601 -2.74986662]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.69553601, -2.74986662]), 'currentState': array([2.10000836, 3.07405092]), 'targetState': array([-0.05091695, -0.04133906]), 'effectorPosition': array([-0.05940916, -0.03210458])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.910122866808995
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.69553601, -2.74986662]), 'currentState': array([2.10000836, 3.07405092]), 'targetState': array([-0.05091695, -0.04133906]), 'effectorPosition': array([-0.05940916, -0.03210458])}
episode index:455
target Thresh 1.2754563967394552
current state at start:  [1.62464799 2.53057212]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.62464799, 2.53057212]), 'currentState': array([1.40253031, 3.03057212]), 'targetState': array([0.04253906, 0.01832126]), 'effectorPosition': array([-0.1081968 ,  0.02462428])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9103199657852911
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.62464799, 2.53057212]), 'currentState': array([1.40253031, 3.03057212]), 'targetState': array([0.04253906, 0.01832126]), 'effectorPosition': array([-0.1081968 ,  0.02462428])}
episode index:456
target Thresh 1.276904035824345
current state at start:  [ 3.09177658 -2.70361094]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.09177658, -2.70361094]), 'currentState': array([3.51073357, 3.85224407]), 'targetState': array([-0.42787262,  0.57492616]), 'effectorPosition': array([-0.46112615,  0.52104556])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9105162021840103
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.09177658, -2.70361094]), 'currentState': array([3.51073357, 3.85224407]), 'targetState': array([-0.42787262,  0.57492616]), 'effectorPosition': array([-0.46112615,  0.52104556])}
episode index:457
target Thresh 1.2783487825244142
current state at start:  [-2.73693269  1.82984702]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.73693269,  1.82984702]), 'currentState': array([4.04625262, 2.18292929]), 'targetState': array([ 0.17953066, -1.29392906]), 'effectorPosition': array([ 0.38058922, -0.84019223])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9106681318735649
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-2.73693269,  1.82984702]), 'currentState': array([3.98899989, 1.81369293]), 'targetState': array([ 0.17953066, -1.29392906]), 'effectorPosition': array([ 0.22483857, -1.21178265])}
episode index:458
target Thresh 1.279790642618651
current state at start:  [-0.60879291  2.1158596 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.60879291,  2.1158596 ]), 'currentState': array([5.18299848, 2.22820324]), 'targetState': array([0.76802519, 0.13099752]), 'effectorPosition': array([0.88188256, 0.012272  ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9108627546799406
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.60879291,  2.1158596 ]), 'currentState': array([5.18299848, 2.22820324]), 'targetState': array([0.76802519, 0.13099752]), 'effectorPosition': array([0.88188256, 0.012272  ])}
episode index:459
target Thresh 1.2812296218744983
current state at start:  [ 1.25306023 -2.34599097]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.25306023, -2.34599097]), 'currentState': array([1.54616539, 3.43719434]), 'targetState': array([ 0.21808675, -0.54902877]), 'effectorPosition': array([0.29229534, 0.03618516])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.9109088472739124
{'reset': False, 'endBeforeDone': False, 'stepCount': 8, 'initial state': array([ 1.25306023, -2.34599097]), 'currentState': array([3.96489265, 2.5341249 ]), 'targetState': array([ 0.21808675, -0.54902877]), 'effectorPosition': array([ 0.29699378, -0.51923273])}
episode index:460
target Thresh 1.2826657260478744
current state at start:  [-0.25529393  2.36725028]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.25529393,  2.36725028]), 'currentState': array([5.52789138, 2.86725028]), 'targetState': array([0.19100815, 0.11434706]), 'effectorPosition': array([0.21293947, 0.17160899])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9111021035704983
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.25529393,  2.36725028]), 'currentState': array([5.52789138, 2.86725028]), 'targetState': array([0.19100815, 0.11434706]), 'effectorPosition': array([0.21293947, 0.17160899])}
episode index:461
target Thresh 1.2840989608831985
current state at start:  [-2.9201703  2.0018551]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.9201703,  2.0018551]), 'currentState': array([3.12330018, 2.5018551 ]), 'targetState': array([-0.12857355, -0.40303248]), 'effectorPosition': array([-0.20863418, -0.59326794])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9112945232597396
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.9201703,  2.0018551]), 'currentState': array([3.12330018, 2.5018551 ]), 'targetState': array([-0.12857355, -0.40303248]), 'effectorPosition': array([-0.20863418, -0.59326794])}
episode index:462
target Thresh 1.2855293321134116
current state at start:  [2.01416345 2.24194175]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.01416345, 2.24194175]), 'currentState': array([2.49323763, 2.74194175]), 'targetState': array([-0.4784087 , -0.21833813]), 'effectorPosition': array([-0.29777847, -0.26255326])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9114861117624183
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.01416345, 2.24194175]), 'currentState': array([2.49323763, 2.74194175]), 'targetState': array([-0.4784087 , -0.21833813]), 'effectorPosition': array([-0.29777847, -0.26255326])}
episode index:463
target Thresh 1.2869568454600002
current state at start:  [ 1.36312295 -2.23436898]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.36312295, -2.23436898]), 'currentState': array([1.76330764, 4.05645402]), 'targetState': array([0.70603557, 0.30983141]), 'effectorPosition': array([0.70320291, 0.53451359])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9116768744525856
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.36312295, -2.23436898]), 'currentState': array([1.76330764, 4.05645402]), 'targetState': array([0.70603557, 0.30983141]), 'effectorPosition': array([0.70320291, 0.53451359])}
episode index:464
target Thresh 1.2883815066330202
current state at start:  [-0.21266149 -2.31217192]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.21266149, -2.31217192]), 'currentState': array([5.73108669, 3.6133829 ]), 'targetState': array([-0.29058069, -0.2620295 ]), 'effectorPosition': array([-0.14535129, -0.44425312])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9118668166580639
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.21266149, -2.31217192]), 'currentState': array([5.73108669, 3.6133829 ]), 'targetState': array([-0.29058069, -0.2620295 ]), 'effectorPosition': array([-0.14535129, -0.44425312])}
episode index:465
target Thresh 1.2898033213311182
current state at start:  [ 3.40022772 -2.40552508]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.40022772, -2.40552508]), 'currentState': array([3.7754794 , 4.27688242]), 'targetState': array([-0.85000122,  0.7300558 ]), 'effectorPosition': array([-1.0028131,  0.3881062])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9120344844334758
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.40022772, -2.40552508]), 'currentState': array([3.35144901, 4.18303763]), 'targetState': array([-0.85000122,  0.7300558 ]), 'effectorPosition': array([-0.6639737 ,  0.74107475])}
episode index:466
target Thresh 1.2912222952415542
current state at start:  [-3.99753402  2.69016404]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.99753402,  2.69016404]), 'currentState': array([2.38699476, 3.19016404]), 'targetState': array([-0.17586641,  0.04420364]), 'effectorPosition': array([0.0323989 , 0.03618049])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9122228474218409
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.99753402,  2.69016404]), 'currentState': array([2.38699476, 3.19016404]), 'targetState': array([-0.17586641,  0.04420364]), 'effectorPosition': array([0.0323989 , 0.03618049])}
episode index:467
target Thresh 1.2926384340402262
current state at start:  [-1.85037292  2.12235444]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.85037292,  2.12235444]), 'currentState': array([4.26060935, 2.37779328]), 'targetState': array([ 0.48721882, -0.84882342]), 'effectorPosition': array([ 0.50100362, -0.55187747])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9123678840726489
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.85037292,  2.12235444]), 'currentState': array([4.11240789, 2.30317726]), 'targetState': array([ 0.48721882, -0.84882342]), 'effectorPosition': array([ 0.42662107, -0.69333294])}
episode index:468
target Thresh 1.294051743391691
current state at start:  [-0.90012975 -2.15292969]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.90012975, -2.15292969]), 'currentState': array([5.35256599, 4.63025562]), 'targetState': array([-0.22822248, -1.12252438]), 'effectorPosition': array([-0.25095527, -1.33151769])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9125547329339013
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.90012975, -2.15292969]), 'currentState': array([5.35256599, 4.63025562]), 'targetState': array([-0.22822248, -1.12252438]), 'effectorPosition': array([-0.25095527, -1.33151769])}
episode index:469
target Thresh 1.2954622289491882
current state at start:  [0.54210883 2.10364543]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.54210883, 2.10364543]), 'currentState': array([1.01254829, 2.46628795]), 'targetState': array([-0.65888278,  0.4841931 ]), 'effectorPosition': array([-0.41396929,  0.51729722])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9127407866936164
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.54210883, 2.10364543]), 'currentState': array([1.01254829, 2.46628795]), 'targetState': array([-0.65888278,  0.4841931 ]), 'effectorPosition': array([-0.41396929,  0.51729722])}
episode index:470
target Thresh 1.296869896354662
current state at start:  [-2.85854591  2.84193716]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.85854591,  2.84193716]), 'currentState': array([3.9246394 , 2.38817106]), 'targetState': array([ 0.28795439, -0.70418809]), 'effectorPosition': array([ 0.29079368, -0.67582131])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9129260504161353
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.85854591,  2.84193716]), 'currentState': array([3.9246394 , 2.38817106]), 'targetState': array([ 0.28795439, -0.70418809]), 'effectorPosition': array([ 0.29079368, -0.67582131])}
episode index:471
target Thresh 1.2982747512387838
current state at start:  [-4.50098835  2.91690022]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.50098835,  2.91690022]), 'currentState': array([2.28219696, 2.45923245]), 'targetState': array([-0.46752546,  0.05692119]), 'effectorPosition': array([-0.62385897, -0.2421302 ])}
done in step count: 17
reward sum = 0.8429431933839268
running average episode reward sum: 0.9127777816512365
{'reset': False, 'endBeforeDone': False, 'stepCount': 18, 'initial state': array([-4.50098835,  2.91690022]), 'currentState': array([2.18331345, 2.75062626]), 'targetState': array([-0.46752546,  0.05692119]), 'effectorPosition': array([-0.35518609, -0.15735442])}
episode index:472
target Thresh 1.2996767992209746
current state at start:  [-0.36481525 -2.89703509]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.36481525, -2.89703509]), 'currentState': array([6.18259048, 2.88615022]), 'targetState': array([0.00941534, 0.34835345]), 'effectorPosition': array([0.05765916, 0.24813751])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9129621838041937
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.36481525, -2.89703509]), 'currentState': array([6.18259048, 2.88615022]), 'targetState': array([0.00941534, 0.34835345]), 'effectorPosition': array([0.05765916, 0.24813751])}
episode index:473
target Thresh 1.3010760459094286
current state at start:  [ 1.53582817 -2.12910174]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.53582817, -2.12910174]), 'currentState': array([1.33569314, 3.65408357]), 'targetState': array([ 0.65788243, -0.16347057]), 'effectorPosition': array([0.5067875 , 0.01071624])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.913145807888995
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.53582817, -2.12910174]), 'currentState': array([1.33569314, 3.65408357]), 'targetState': array([ 0.65788243, -0.16347057]), 'effectorPosition': array([0.5067875 , 0.01071624])}
episode index:474
target Thresh 1.3024724969011343
current state at start:  [ 3.88132933 -2.9090678 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.88132933, -2.9090678 ]), 'currentState': array([4.38132933, 2.97427432]), 'targetState': array([-0.01465721, -0.01212234]), 'effectorPosition': array([ 0.15295614, -0.0673394 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.913328658819755
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.88132933, -2.9090678 ]), 'currentState': array([4.38132933, 2.97427432]), 'targetState': array([-0.01465721, -0.01212234]), 'effectorPosition': array([ 0.15295614, -0.0673394 ])}
episode index:475
target Thresh 1.3038661577818977
current state at start:  [0.73728437 2.69799584]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.73728437, 2.69799584]), 'currentState': array([1.23728437, 2.96996373]), 'targetState': array([-0.46501037,  0.14894955]), 'effectorPosition': array([-0.15656725,  0.06979218])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.913489733065932
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.73728437, 2.69799584]), 'currentState': array([1.73728437, 2.57214245]), 'targetState': array([-0.46501037,  0.14894955]), 'effectorPosition': array([-0.55786494,  0.06626941])}
episode index:476
target Thresh 1.305257034126364
current state at start:  [ 0.42817235 -2.17540146]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.42817235, -2.17540146]), 'currentState': array([0.11428118, 4.60778385]), 'targetState': array([ 1.04979043, -0.89484084]), 'effectorPosition': array([ 1.00315291, -0.8859206 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9136710963089804
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.42817235, -2.17540146]), 'currentState': array([0.11428118, 4.60778385]), 'targetState': array([ 1.04979043, -0.89484084]), 'effectorPosition': array([ 1.00315291, -0.8859206 ])}
episode index:477
target Thresh 1.3066451314980405
current state at start:  [-0.33536063  2.23860317]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.33536063,  2.23860317]), 'currentState': array([5.6826395 , 2.71723601]), 'targetState': array([0.28395659, 0.27662496]), 'effectorPosition': array([0.30584504, 0.28957069])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9138517007100075
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.33536063,  2.23860317]), 'currentState': array([5.6826395 , 2.71723601]), 'targetState': array([0.28395659, 0.27662496]), 'effectorPosition': array([0.30584504, 0.28957069])}
episode index:478
target Thresh 1.3080304554493187
current state at start:  [-0.25376363  2.7323203 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.25376363,  2.7323203 ]), 'currentState': array([5.87918814, 3.15786811]), 'targetState': array([-0.46160422,  0.29053059]), 'effectorPosition': array([-0.00627577, -0.01501663])}
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.9137943586870558
{'reset': False, 'endBeforeDone': False, 'stepCount': 13, 'initial state': array([-0.25376363,  2.7323203 ]), 'currentState': array([4.00211611, 3.52208825]), 'targetState': array([-0.46160422,  0.29053059]), 'effectorPosition': array([-0.32820837,  0.18793051])}
episode index:479
target Thresh 1.309413011521496
current state at start:  [-1.07136197 -2.11636595]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.07136197, -2.11636595]), 'currentState': array([4.80363356, 4.33850264]), 'targetState': array([-0.63200734, -0.98201924]), 'effectorPosition': array([-0.86920399, -0.71694654])}
done in step count: 28
reward sum = 0.7547192872036326
running average episode reward sum: 0.913462952288132
{'reset': False, 'endBeforeDone': False, 'stepCount': 29, 'initial state': array([-1.07136197, -2.11636595]), 'currentState': array([4.94219591, 4.69632598]), 'targetState': array([-0.63200734, -0.98201924]), 'effectorPosition': array([-0.74945407, -1.1858305 ])}
episode index:480
target Thresh 1.3107928052447981
current state at start:  [-1.18337863 -1.85633213]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.18337863, -1.85633213]), 'currentState': array([5.12555394, 4.69196182]), 'targetState': array([-0.38744048, -1.04431112]), 'effectorPosition': array([-0.52235473, -1.29857386])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.913540971202086
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([-1.18337863, -1.85633213]), 'currentState': array([5.14752545, 4.63752539]), 'targetState': array([-0.38744048, -1.04431112]), 'effectorPosition': array([-0.5142665 , -1.25934213])}
episode index:481
target Thresh 1.312169842138403
current state at start:  [-0.81822358  2.91548152]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.81822358,  2.91548152]), 'currentState': array([5.66518443, 2.41548152]), 'targetState': array([0.58182425, 0.33329083]), 'effectorPosition': array([0.59029048, 0.39500998])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9137203467805048
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.81822358,  2.91548152]), 'currentState': array([5.66518443, 2.41548152]), 'targetState': array([0.58182425, 0.33329083]), 'effectorPosition': array([0.59029048, 0.39500998])}
episode index:482
target Thresh 1.313544127710459
current state at start:  [ 3.29569001 -1.76418882]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.29569001, -1.76418882]), 'currentState': array([3.56339331, 4.41801147]), 'targetState': array([-1.28663121,  0.5130168 ]), 'effectorPosition': array([-1.03943182,  0.5824887 ])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9138173978430711
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([ 3.29569001, -1.76418882]), 'currentState': array([3.65968704, 4.40997909]), 'targetState': array([-1.28663121,  0.5130168 ]), 'effectorPosition': array([-1.08278058,  0.48160462])}
episode index:483
target Thresh 1.3149156674581104
current state at start:  [-2.38579596  2.51404977]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.38579596,  2.51404977]), 'currentState': array([3.39738935, 2.48707873]), 'targetState': array([-0.26891985, -0.52324548]), 'effectorPosition': array([-0.04590226, -0.64125278])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9139543453681888
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-2.38579596,  2.51404977]), 'currentState': array([2.9725634 , 2.50246912]), 'targetState': array([-0.26891985, -0.52324548]), 'effectorPosition': array([-0.29491337, -0.55478677])}
episode index:484
target Thresh 1.3162844668675184
current state at start:  [-1.418247   -2.10975391]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.418247  , -2.10975391]), 'currentState': array([4.52677144, 3.88890284]), 'targetState': array([-0.66405293, -0.27909404]), 'effectorPosition': array([-0.71717304, -0.13646768])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9141317590890791
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.418247  , -2.10975391]), 'currentState': array([4.52677144, 3.88890284]), 'targetState': array([-0.66405293, -0.27909404]), 'effectorPosition': array([-0.71717304, -0.13646768])}
episode index:485
target Thresh 1.3176505314138822
current state at start:  [ 2.81494622 -1.57523573]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.81494622, -1.57523573]), 'currentState': array([3.22231181, 4.51509529]), 'targetState': array([-1.07332367,  0.75728509]), 'effectorPosition': array([-0.8804333 ,  0.91258135])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9143084427123526
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.81494622, -1.57523573]), 'currentState': array([3.22231181, 4.51509529]), 'targetState': array([-1.07332367,  0.75728509]), 'effectorPosition': array([-0.8804333 ,  0.91258135])}
episode index:486
target Thresh 1.3190138665614617
current state at start:  [ 0.75721527 -2.7864167 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.75721527, -2.7864167 ]), 'currentState': array([1.05164529, 3.54241581]), 'targetState': array([ 0.19044175, -0.28330153]), 'effectorPosition': array([ 0.37809126, -0.12476672])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9144844007355305
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.75721527, -2.7864167 ]), 'currentState': array([1.05164529, 3.54241581]), 'targetState': array([ 0.19044175, -0.28330153]), 'effectorPosition': array([ 0.37809126, -0.12476672])}
episode index:487
target Thresh 1.3203744777635995
current state at start:  [ 3.00809728 -2.50082454]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.00809728, -2.50082454]), 'currentState': array([3.41107791, 3.51053277]), 'targetState': array([ 0.23241221, -0.00038243]), 'effectorPosition': array([-0.16087294,  0.32969639])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9146188589307446
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 3.00809728, -2.50082454]), 'currentState': array([3.85403223, 2.94326097]), 'targetState': array([ 0.23241221, -0.00038243]), 'effectorPosition': array([ 0.11396235, -0.16192365])}
episode index:488
target Thresh 1.3217323704627424
current state at start:  [-3.51028953  2.29108456]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.51028953,  2.29108456]), 'currentState': array([2.39574366, 1.93504202]), 'targetState': array([-1.04917393, -0.40342457]), 'effectorPosition': array([-1.10692096, -0.2494731 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9147934624912134
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.51028953,  2.29108456]), 'currentState': array([2.39574366, 1.93504202]), 'targetState': array([-1.04917393, -0.40342457]), 'effectorPosition': array([-1.10692096, -0.2494731 ])}
episode index:489
target Thresh 1.3230875500904626
current state at start:  [-1.00983614 -2.9322089 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.00983614, -2.9322089 ]), 'currentState': array([4.77334917, 3.60826427]), 'targetState': array([-0.3752628 , -0.04154725]), 'effectorPosition': array([-0.44256619, -0.13414065])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9149673533840885
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.00983614, -2.9322089 ]), 'currentState': array([4.77334917, 3.60826427]), 'targetState': array([-0.3752628 , -0.04154725]), 'effectorPosition': array([-0.44256619, -0.13414065])}
episode index:490
target Thresh 1.3244400220674808
current state at start:  [ 0.30635369 -3.02772457]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.30635369, -3.02772457]), 'currentState': array([0.59330217, 3.00805126]), 'targetState': array([-0.12480444,  0.24314511]), 'effectorPosition': array([-0.06705972,  0.11536815])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9151405359637543
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.30635369, -3.02772457]), 'currentState': array([0.59330217, 3.00805126]), 'targetState': array([-0.12480444,  0.24314511]), 'effectorPosition': array([-0.06705972,  0.11536815])}
episode index:491
target Thresh 1.3257897918036865
current state at start:  [-1.07964449 -1.61877592]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.07964449, -1.61877592]), 'currentState': array([4.84807126, 4.39491252]), 'targetState': array([-0.39318449, -0.7597914 ]), 'effectorPosition': array([-0.84825455, -0.8100148 ])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.9152134008294783
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([-1.07964449, -1.61877592]), 'currentState': array([5.2854786 , 4.30012753]), 'targetState': array([-0.39318449, -0.7597914 ]), 'effectorPosition': array([-0.44486438, -1.00036544])}
episode index:492
target Thresh 1.3271368646981603
current state at start:  [1.87803368 2.45151286]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.87803368, 2.45151286]), 'currentState': array([2.34056674, 2.00611828]), 'targetState': array([-1.18306738,  0.46521433]), 'effectorPosition': array([-1.05357719, -0.21580178])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9153650977851995
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.87803368, 2.45151286]), 'currentState': array([1.84056674, 1.70428012]), 'targetState': array([-1.18306738,  0.46521433]), 'effectorPosition': array([-1.18629903,  0.57141851])}
episode index:493
target Thresh 1.3284812461391957
current state at start:  [-4.55217749  2.85357263]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.55217749,  2.85357263]), 'currentState': array([1.65800354, 3.22120484]), 'targetState': array([0.04064083, 0.02857381]), 'effectorPosition': array([0.07895003, 0.01008198])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.915536423498185
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.55217749,  2.85357263]), 'currentState': array([1.65800354, 3.22120484]), 'targetState': array([0.04064083, 0.02857381]), 'effectorPosition': array([0.07895003, 0.01008198])}
episode index:494
target Thresh 1.3298229415043206
current state at start:  [ 1.27346686 -1.60757702]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.27346686, -1.60757702]), 'currentState': array([1.49684751, 4.17560829]), 'targetState': array([0.81980043, 0.26942486]), 'effectorPosition': array([0.89311132, 0.42380179])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9157070569860674
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.27346686, -1.60757702]), 'currentState': array([1.49684751, 4.17560829]), 'targetState': array([0.81980043, 0.26942486]), 'effectorPosition': array([0.89311132, 0.42380179])}
episode index:495
target Thresh 1.3311619561603178
current state at start:  [-1.23406557  1.65688725]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.23406557,  1.65688725]), 'currentState': array([5.54602092, 1.63094234]), 'targetState': array([1.29481546, 0.07511786]), 'effectorPosition': array([1.36684941, 0.1072529 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9158770024356923
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.23406557,  1.65688725]), 'currentState': array([5.54602092, 1.63094234]), 'targetState': array([1.29481546, 0.07511786]), 'effectorPosition': array([1.36684941, 0.1072529 ])}
episode index:496
target Thresh 1.3324982954632478
current state at start:  [-3.589329    2.31555156]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.589329  ,  2.31555156]), 'currentState': array([2.19390762, 1.9808989 ]), 'targetState': array([-1.22059937,  0.09938844]), 'effectorPosition': array([-1.0956255 , -0.04688237])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9160462640002079
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.589329  ,  2.31555156]), 'currentState': array([2.19390762, 1.9808989 ]), 'targetState': array([-1.22059937,  0.09938844]), 'effectorPosition': array([-1.0956255 , -0.04688237])}
episode index:497
target Thresh 1.3338319647584695
current state at start:  [-2.45877894  2.50287314]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.45877894,  2.50287314]), 'currentState': array([3.41731936, 3.00287314]), 'targetState': array([0.07259854, 0.0441644 ]), 'effectorPosition': array([ 0.02840158, -0.1356673 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9162148457994044
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.45877894,  2.50287314]), 'currentState': array([3.41731936, 3.00287314]), 'targetState': array([0.07259854, 0.0441644 ]), 'effectorPosition': array([ 0.02840158, -0.1356673 ])}
episode index:498
target Thresh 1.3351629693806624
current state at start:  [1.85506934 1.83528189]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.85506934, 1.83528189]), 'currentState': array([2.35506934, 1.76262501]), 'targetState': array([-1.21211305, -0.09788199]), 'effectorPosition': array([-1.26656657, -0.12041769])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9163827519200468
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.85506934, 1.83528189]), 'currentState': array([2.35506934, 1.76262501]), 'targetState': array([-1.21211305, -0.09788199]), 'effectorPosition': array([-1.26656657, -0.12041769])}
episode index:499
target Thresh 1.3364913146538462
current state at start:  [ 1.44788774 -2.45564992]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.44788774, -2.45564992]), 'currentState': array([1.28501155, 4.07426562]), 'targetState': array([ 0.77185283, -0.01411544]), 'effectorPosition': array([0.8846167 , 0.16147754])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9165499864162067
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.44788774, -2.45564992]), 'currentState': array([1.28501155, 4.07426562]), 'targetState': array([ 0.77185283, -0.01411544]), 'effectorPosition': array([0.8846167 , 0.16147754])}
episode index:500
target Thresh 1.3378170058914036
current state at start:  [-0.41659199  2.2075886 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.41659199,  2.2075886 ]), 'currentState': array([5.39339296, 2.66496336]), 'targetState': array([0.11536399, 0.36245506]), 'effectorPosition': array([0.42661848, 0.20224706])}
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.9165076476294652
{'reset': False, 'endBeforeDone': False, 'stepCount': 12, 'initial state': array([-0.41659199,  2.2075886 ]), 'currentState': array([5.48884061, 2.82264435]), 'targetState': array([0.11536399, 0.36245506]), 'effectorPosition': array([0.25904284, 0.18375355])}
episode index:501
target Thresh 1.3391400483961022
current state at start:  [ 1.55569375 -1.75107415]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.55569375, -1.75107415]), 'currentState': array([1.16956488, 4.07569261]), 'targetState': array([0.82952762, 0.25026142]), 'effectorPosition': array([0.89855851, 0.05922735])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9166739670564982
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.55569375, -1.75107415]), 'currentState': array([1.16956488, 4.07569261]), 'targetState': array([0.82952762, 0.25026142]), 'effectorPosition': array([0.89855851, 0.05922735])}
episode index:502
target Thresh 1.340460447460113
current state at start:  [2.05597294 1.87678793]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.05597294, 1.87678793]), 'currentState': array([1.55597294, 2.3505505 ]), 'targetState': array([-0.59490882,  0.70031535]), 'effectorPosition': array([-0.70660744,  0.30740306])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9168197444579763
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([2.05597294, 1.87678793]), 'currentState': array([1.45892263, 2.14563765]), 'targetState': array([-0.59490882,  0.70031535]), 'effectorPosition': array([-0.7830906 ,  0.54714336])}
episode index:503
target Thresh 1.3417782083650343
current state at start:  [-1.59519627 -2.07350849]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.59519627, -2.07350849]), 'currentState': array([5.03856582, 4.56864812]), 'targetState': array([-0.61141189, -0.70809728]), 'effectorPosition': array([-0.66298086, -1.12869995])}
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.9167417708042878
{'reset': False, 'endBeforeDone': False, 'stepCount': 14, 'initial state': array([-1.59519627, -2.07350849]), 'currentState': array([5.10028355, 4.31458198]), 'targetState': array([-0.61141189, -0.70809728]), 'effectorPosition': array([-0.62171063, -0.9157952 ])}
episode index:504
target Thresh 1.3430933363819113
current state at start:  [-1.54278102  2.7094244 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.54278102,  2.7094244 ]), 'currentState': array([4.91227241, 3.2094244 ]), 'targetState': array([-0.13199948,  0.44504519]), 'effectorPosition': array([-0.06597361, -0.01571192])}
done in step count: 32
reward sum = 0.7249803359578534
running average episode reward sum: 0.9163620451907305
{'reset': False, 'endBeforeDone': False, 'stepCount': 33, 'initial state': array([-1.54278102,  2.7094244 ]), 'currentState': array([0.01075611, 2.82406239]), 'targetState': array([-0.13199948,  0.44504519]), 'effectorPosition': array([0.04662947, 0.31274087])}
episode index:505
target Thresh 1.3444058367712581
current state at start:  [0.58852022 2.679724  ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.58852022, 2.679724  ]), 'currentState': array([0.86451553, 2.64845052]), 'targetState': array([-0.01669609,  0.43752892]), 'effectorPosition': array([-0.28282106,  0.39788538])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.9164116857128852
{'reset': False, 'endBeforeDone': False, 'stepCount': 7, 'initial state': array([0.58852022, 2.679724  ]), 'currentState': array([2.74902331, 3.38393169]), 'targetState': array([-0.01669609,  0.43752892]), 'effectorPosition': array([0.06480746, 0.23289771])}
episode index:506
target Thresh 1.3457157147830778
current state at start:  [ 4.20255614 -3.02838184]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.20255614, -3.02838184]), 'currentState': array([4.54815168, 3.63599037]), 'targetState': array([-0.33424797, -0.17427752]), 'effectorPosition': array([-0.48769473, -0.04055299])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9165765541828795
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.20255614, -3.02838184]), 'currentState': array([4.54815168, 3.63599037]), 'targetState': array([-0.33424797, -0.17427752]), 'effectorPosition': array([-0.48769473, -0.04055299])}
episode index:507
target Thresh 1.3470229756568841
current state at start:  [ 2.9560113  -2.29742485]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.9560113 , -2.29742485]), 'currentState': array([2.65848047, 4.47331745]), 'targetState': array([0.38973359, 1.29093767]), 'effectorPosition': array([-0.22452867,  1.21490146])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9166823070289762
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 2.9560113 , -2.29742485]), 'currentState': array([2.02938087, 4.5029206 ]), 'targetState': array([0.38973359, 1.29093767]), 'effectorPosition': array([0.52645137, 1.14322749])}
episode index:508
target Thresh 1.3483276246217226
current state at start:  [0.72095989 1.59699933]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.72095989, 1.59699933]), 'currentState': array([0.22095989, 1.57959683]), 'targetState': array([0.73625064, 0.97425734]), 'effectorPosition': array([0.7479433 , 1.19288727])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9168459960132022
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.72095989, 1.59699933]), 'currentState': array([0.22095989, 1.57959683]), 'targetState': array([0.73625064, 0.97425734]), 'effectorPosition': array([0.7479433 , 1.19288727])}
episode index:509
target Thresh 1.3496296668961907
current state at start:  [-1.61319111  2.77699194]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.61319111,  2.77699194]), 'currentState': array([4.17434861, 2.77614637]), 'targetState': array([ 0.202875  , -0.28910246]), 'effectorPosition': array([ 0.27303527, -0.23983954])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.917009043079843
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.61319111,  2.77699194]), 'currentState': array([4.17434861, 2.77614637]), 'targetState': array([ 0.202875  , -0.28910246]), 'effectorPosition': array([ 0.27303527, -0.23983954])}
episode index:510
target Thresh 1.350929107688459
current state at start:  [-2.10352816  2.12943223]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.10352816,  2.12943223]), 'currentState': array([3.98845194, 2.41742923]), 'targetState': array([ 0.31995009, -0.17722122]), 'effectorPosition': array([ 0.33014286, -0.62681564])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9171518825258707
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.10352816,  2.12943223]), 'currentState': array([3.80849013, 2.81470662]), 'targetState': array([ 0.31995009, -0.17722122]), 'effectorPosition': array([ 0.15700634, -0.2850533 ])}
episode index:511
target Thresh 1.3522259521962927
current state at start:  [0.75900557 2.77444261]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.75900557, 2.77444261]), 'currentState': array([1.06556602, 2.97418066]), 'targetState': array([-0.48630309,  0.05175806]), 'effectorPosition': array([-0.13904592,  0.09288493])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9172748280678124
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([0.75900557, 2.77444261]), 'currentState': array([1.60913028, 2.59931863]), 'targetState': array([-0.48630309,  0.05175806]), 'effectorPosition': array([-0.52120411,  0.12357856])}
episode index:512
target Thresh 1.3535202056070719
current state at start:  [1.75869982 2.04290052]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.75869982, 2.04290052]), 'currentState': array([2.07050478, 1.9095876 ]), 'targetState': array([-1.09005421, -0.22305959]), 'effectorPosition': array([-1.14774891,  0.1340814 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9174165925355164
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.75869982, 2.04290052]), 'currentState': array([2.40591573, 1.8734695 ]), 'targetState': array([-1.09005421, -0.22305959]), 'effectorPosition': array([-1.16097587, -0.23662031])}
episode index:513
target Thresh 1.3548118730978111
current state at start:  [-1.32303604 -2.52666877]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.32303604, -2.52666877]), 'currentState': array([4.46014927, 4.25651653]), 'targetState': array([-0.78290997, -0.78590304]), 'effectorPosition': array([-1.0091645 , -0.31795493])}
done in step count: 20
reward sum = 0.8179069375972308
running average episode reward sum: 0.9172229939850528
{'reset': False, 'endBeforeDone': False, 'stepCount': 21, 'initial state': array([-1.32303604, -2.52666877]), 'currentState': array([2.90941698, 1.85437129]), 'targetState': array([-0.78290997, -0.78590304]), 'effectorPosition': array([-0.92179143, -0.76858398])}
episode index:514
target Thresh 1.3561009598351825
current state at start:  [-0.97869337 -2.60077842]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.97869337, -2.60077842]), 'currentState': array([4.80449193, 4.09449207]), 'targetState': array([-0.88194761, -0.03859457]), 'effectorPosition': array([-0.77295293, -0.49386164])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9173643085598392
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.97869337, -2.60077842]), 'currentState': array([4.33211278, 4.02704673]), 'targetState': array([-0.88194761, -0.03859457]), 'effectorPosition': array([-0.85514006, -0.05347375])}
episode index:515
target Thresh 1.3573874709755347
current state at start:  [-3.66650153  2.80886609]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.66650153,  2.80886609]), 'currentState': array([2.48302465, 2.46934897]), 'targetState': array([-0.74275076,  0.02541014]), 'effectorPosition': array([-0.55318169, -0.35935667])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9175050754037155
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.66650153,  2.80886609]), 'currentState': array([1.98302465, 2.3713471 ]), 'targetState': array([-0.74275076,  0.02541014]), 'effectorPosition': array([-0.75106986, -0.02036314])}
episode index:516
target Thresh 1.3586714116649141
current state at start:  [-2.74355022  2.79861955]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.74355022,  2.79861955]), 'currentState': array([3.87375661, 2.32297594]), 'targetState': array([ 0.65238494, -1.00703825]), 'effectorPosition': array([ 0.25253571, -0.7548257 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9176452976950042
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.74355022,  2.79861955]), 'currentState': array([4.20403504, 2.04766906]), 'targetState': array([ 0.65238494, -1.00703825]), 'effectorPosition': array([ 0.51276451, -0.9050229 ])}
episode index:517
target Thresh 1.3599527870390848
current state at start:  [0.22465131 2.18379545]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.22465131, 2.18379545]), 'currentState': array([0.18087748, 1.77160651]), 'targetState': array([0.3388834 , 0.95920312]), 'effectorPosition': array([0.61119901, 1.10793013])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.917784978587485
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.22465131, 2.18379545]), 'currentState': array([0.22333646, 1.9749233 ]), 'targetState': array([0.3388834 , 0.95920312]), 'effectorPosition': array([0.38807066, 1.03100376])}
episode index:518
target Thresh 1.3612316022235507
current state at start:  [-0.48726976 -2.28991699]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.48726976, -2.28991699]), 'currentState': array([6.17296106, 3.57345078]), 'targetState': array([ 0.37859461, -0.35863043]), 'effectorPosition': array([ 0.04521127, -0.42611827])}
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.9177073987115918
{'reset': False, 'endBeforeDone': False, 'stepCount': 14, 'initial state': array([-0.48726976, -2.28991699]), 'currentState': array([4.48511413, 2.59179791]), 'targetState': array([ 0.37859461, -0.35863043]), 'effectorPosition': array([ 0.47586984, -0.26131267])}
episode index:519
target Thresh 1.3625078623335736
current state at start:  [-1.4626835  -2.54511765]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.4626835 , -2.54511765]), 'currentState': array([5.28004346, 3.33399895]), 'targetState': array([-0.03700036,  0.44781489]), 'effectorPosition': array([-0.15130962, -0.11837023])}
done in step count: 24
reward sum = 0.7856781408072188
running average episode reward sum: 0.9174534962925449
{'reset': False, 'endBeforeDone': False, 'stepCount': 25, 'initial state': array([-1.4626835 , -2.54511765]), 'currentState': array([3.52498935, 3.4375085 ]), 'targetState': array([-0.03700036,  0.44781489]), 'effectorPosition': array([-0.14939457,  0.25418561])}
episode index:520
target Thresh 1.3637815724741957
current state at start:  [-0.19090792  2.13801042]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.19090792,  2.13801042]), 'currentState': array([5.59227739, 2.5731912 ]), 'targetState': array([0.23632761, 0.1259412 ]), 'effectorPosition': array([0.4641934 , 0.31464176])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.91759274102135
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.19090792,  2.13801042]), 'currentState': array([5.09227739, 2.77876348]), 'targetState': array([0.23632761, 0.1259412 ]), 'effectorPosition': array([0.35375843, 0.07114847])}
episode index:521
target Thresh 1.3650527377402595
current state at start:  [ 1.47190569 -1.7444693 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.47190569, -1.7444693 ]), 'currentState': array([1.5820283 , 4.29436617]), 'targetState': array([0.87234869, 0.75135617]), 'effectorPosition': array([0.90716357, 0.60427283])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9177506093335697
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.47190569, -1.7444693 ]), 'currentState': array([1.5820283 , 4.29436617]), 'targetState': array([0.87234869, 0.75135617]), 'effectorPosition': array([0.90716357, 0.60427283])}
episode index:522
target Thresh 1.3663213632164277
current state at start:  [ 4.18696491 -2.55204667]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.18696491, -2.55204667]), 'currentState': array([4.45923017, 3.23113863]), 'targetState': array([-0.08016442, -0.08680962]), 'effectorPosition': array([-0.08757949,  0.01851917])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9179078739428745
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.18696491, -2.55204667]), 'currentState': array([4.45923017, 3.23113863]), 'targetState': array([-0.08016442, -0.08680962]), 'effectorPosition': array([-0.08757949,  0.01851917])}
episode index:523
target Thresh 1.367587453977204
current state at start:  [0.22797332 1.73233212]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.22797332, 1.73233212]), 'currentState': array([6.20548926, 1.72727741]), 'targetState': array([0.21607935, 0.80050022]), 'effectorPosition': array([0.91827962, 0.91928017])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.9179528592013824
{'reset': False, 'endBeforeDone': False, 'stepCount': 7, 'initial state': array([0.22797332, 1.73233212]), 'currentState': array([6.24622452, 2.18398421]), 'targetState': array([0.21607935, 0.80050022]), 'effectorPosition': array([0.45445287, 0.80157196])}
episode index:524
target Thresh 1.3688510150869528
current state at start:  [ 2.82562859 -2.87437093]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.82562859, -2.87437093]), 'currentState': array([3.08765249, 3.00599379]), 'targetState': array([ 0.2407482 , -0.07565869]), 'effectorPosition': array([-0.01645439, -0.13449219])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.9180157871836654
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([ 2.82562859, -2.87437093]), 'currentState': array([3.52975954, 3.09292469]), 'targetState': array([ 0.2407482 , -0.07565869]), 'effectorPosition': array([ 0.01731722, -0.04547766])}
episode index:525
target Thresh 1.3701120515999206
current state at start:  [-2.11399214 -1.85504779]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.11399214, -1.85504779]), 'currentState': array([4.66919317, 4.15258262]), 'targetState': array([-0.76951975, -0.50850902]), 'effectorPosition': array([-0.86681913, -0.43194948])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9181716507061299
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.11399214, -1.85504779]), 'currentState': array([4.66919317, 4.15258262]), 'targetState': array([-0.76951975, -0.50850902]), 'effectorPosition': array([-0.86681913, -0.43194948])}
episode index:526
target Thresh 1.3713705685602546
current state at start:  [-1.72848586 -2.19445044]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.72848586, -2.19445044]), 'currentState': array([4.05469945, 4.42564509]), 'targetState': array([-1.20462134, -0.29716432]), 'effectorPosition': array([-1.19749196,  0.01875823])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9183079473841069
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.72848586, -2.19445044]), 'currentState': array([4.3021659 , 4.48425835]), 'targetState': array([-1.20462134, -0.29716432]), 'effectorPosition': array([-1.20189174, -0.32115772])}
episode index:527
target Thresh 1.3726265710020247
current state at start:  [0.06038516 2.58049019]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.06038516, 2.58049019]), 'currentState': array([5.84357047, 3.05376257]), 'targetState': array([ 0.32652806, -0.0435664 ]), 'effectorPosition': array([0.04081972, 0.0777362 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9184437277867886
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.06038516, 2.58049019]), 'currentState': array([5.35971344, 2.94485469]), 'targetState': array([ 0.32652806, -0.0435664 ]), 'effectorPosition': array([0.16756072, 0.10249169])}
episode index:528
target Thresh 1.3738800639492426
current state at start:  [-0.52841124  1.88054104]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.52841124,  1.88054104]), 'currentState': array([5.25477407, 2.24076403]), 'targetState': array([0.55297971, 0.07575492]), 'effectorPosition': array([0.86699735, 0.07996401])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9185602802862465
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-0.52841124,  1.88054104]), 'currentState': array([5.05127986, 2.42157081]), 'targetState': array([0.55297971, 0.07575492]), 'effectorPosition': array([ 0.70441178, -0.01487942])}
episode index:529
target Thresh 1.3751310524158815
current state at start:  [ 2.71992094 -1.91446368]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.71992094, -1.91446368]), 'currentState': array([2.24467537, 4.78027331]), 'targetState': array([0.00914385, 1.26184705]), 'effectorPosition': array([0.1132566, 1.456996 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9187139401347629
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.71992094, -1.91446368]), 'currentState': array([2.24467537, 4.78027331]), 'targetState': array([0.00914385, 1.26184705]), 'effectorPosition': array([0.1132566, 1.456996 ])}
episode index:530
target Thresh 1.3763795414058966
current state at start:  [-2.12039049  2.59818905]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.12039049,  2.59818905]), 'currentState': array([4.60986905, 3.09818905]), 'targetState': array([0.80842731, 0.16687041]), 'effectorPosition': array([ 0.04306578, -0.00537739])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9188295447672775
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-2.12039049,  2.59818905]), 'currentState': array([5.60986905, 2.24194514]), 'targetState': array([0.80842731, 0.16687041]), 'effectorPosition': array([0.78392545, 0.37641573])}
episode index:531
target Thresh 1.3776255359132459
current state at start:  [-2.00001236 -1.77361734]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.00001236, -1.77361734]), 'currentState': array([4.25283544, 4.67793549]), 'targetState': array([-1.27498916, -0.46501532]), 'effectorPosition': array([-1.32398798, -0.42209297])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.918982120810948
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.00001236, -1.77361734]), 'currentState': array([4.25283544, 4.67793549]), 'targetState': array([-1.27498916, -0.46501532]), 'effectorPosition': array([-1.32398798, -0.42209297])}
episode index:532
target Thresh 1.3788690409219093
current state at start:  [-3.23699205  2.31389423]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.23699205,  2.31389423]), 'currentState': array([3.45560376, 1.81389423]), 'targetState': array([-1.00887496, -0.94941844]), 'effectorPosition': array([-0.42236771, -1.15766331])}
done in step count: 33
reward sum = 0.7177305325982749
running average episode reward sum: 0.9186045380938511
{'reset': False, 'endBeforeDone': False, 'stepCount': 34, 'initial state': array([-3.23699205,  2.31389423]), 'currentState': array([3.24453585, 1.2575473 ]), 'targetState': array([-1.00887496, -0.94941844]), 'effectorPosition': array([-1.20346503, -1.08072859])}
episode index:533
target Thresh 1.380110061405908
current state at start:  [ 1.26983398 -2.39975569]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.26983398, -2.39975569]), 'currentState': array([1.46948191, 3.56055957]), 'targetState': array([ 0.56649968, -0.17338138]), 'effectorPosition': array([0.41347855, 0.04490084])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.9186297456028645
{'reset': False, 'endBeforeDone': False, 'stepCount': 8, 'initial state': array([ 1.26983398, -2.39975569]), 'currentState': array([1.14213102, 3.85811047]), 'targetState': array([ 0.56649968, -0.17338138]), 'effectorPosition': array([ 0.69955099, -0.04933441])}
episode index:534
target Thresh 1.3813486023293258
current state at start:  [-1.51491643  2.65908508]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.51491643,  2.65908508]), 'currentState': array([4.26826888, 3.1037895 ]), 'targetState': array([0.00327521, 0.02893214]), 'effectorPosition': array([ 0.03382073, -0.01688391])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9187818395363171
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.51491643,  2.65908508]), 'currentState': array([4.26826888, 3.1037895 ]), 'targetState': array([0.00327521, 0.02893214]), 'effectorPosition': array([ 0.03382073, -0.01688391])}
episode index:535
target Thresh 1.3825846686463281
current state at start:  [-3.78212644  2.8845136 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.78212644,  2.8845136 ]), 'currentState': array([2.60595442, 3.3845136 ]), 'targetState': array([ 0.20653277, -0.03661669]), 'effectorPosition': array([0.09752027, 0.221835  ])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9188779536416598
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-3.78212644,  2.8845136 ]), 'currentState': array([3.26260934, 3.05160751]), 'targetState': array([ 0.20653277, -0.03661669]), 'effectorPosition': array([ 0.00683215, -0.08969496])}
episode index:536
target Thresh 1.3838182653011817
current state at start:  [-1.37062384 -2.85794808]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.37062384, -2.85794808]), 'currentState': array([5.10031418, 3.39704498]), 'targetState': array([-0.11242007, -0.07698528]), 'effectorPosition': array([-0.22163254, -0.12562174])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.919029018904897
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.37062384, -2.85794808]), 'currentState': array([5.10031418, 3.39704498]), 'targetState': array([-0.11242007, -0.07698528]), 'effectorPosition': array([-0.22163254, -0.12562174])}
episode index:537
target Thresh 1.385049397228275
current state at start:  [-1.87290202  2.36554253]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.87290202,  2.36554253]), 'currentState': array([4.90970783, 2.36327806]), 'targetState': array([ 0.95682989, -0.48945982]), 'effectorPosition': array([ 0.74489748, -0.14467917])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.919160935226635
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.87290202,  2.36554253]), 'currentState': array([4.76461583, 2.26551232]), 'targetState': array([ 0.95682989, -0.48945982]), 'effectorPosition': array([ 0.78597244, -0.3192378 ])}
episode index:538
target Thresh 1.3862780693521373
current state at start:  [ 4.33440052 -3.11340268]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.33440052, -3.11340268]), 'currentState': array([4.06668716, 3.66978263]), 'targetState': array([-0.32533454,  0.03396312]), 'effectorPosition': array([-0.48451754,  0.19442579])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.919310914938645
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.33440052, -3.11340268]), 'currentState': array([4.06668716, 3.66978263]), 'targetState': array([-0.32533454,  0.03396312]), 'effectorPosition': array([-0.48451754,  0.19442579])}
episode index:539
target Thresh 1.3875042865874585
current state at start:  [0.72286457 2.53047119]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.72286457, 2.53047119]), 'currentState': array([1.21685073, 2.99086009]), 'targetState': array([-0.66936266,  0.22320923]), 'effectorPosition': array([-0.13692423,  0.06268233])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9194418206517216
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.72286457, 2.53047119]), 'currentState': array([1.71685073, 2.49086009]), 'targetState': array([-0.66936266,  0.22320923]), 'effectorPosition': array([-0.62906143,  0.11402287])}
episode index:540
target Thresh 1.3887280538391096
current state at start:  [ 2.66882271 -2.42482731]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.66882271, -2.42482731]), 'currentState': array([3.15913294, 3.9871746 ]), 'targetState': array([-0.42343421,  1.00582457]), 'effectorPosition': array([-0.34977804,  0.74233654])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9195722424250087
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 2.66882271, -2.42482731]), 'currentState': array([3.17845789, 4.16437462]), 'targetState': array([-0.42343421,  1.00582457]), 'effectorPosition': array([-0.51014073,  0.83532607])}
episode index:541
target Thresh 1.389949376002161
current state at start:  [1.62509184 2.26207757]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.62509184, 2.26207757]), 'currentState': array([2.12509184, 1.76207757]), 'targetState': array([-1.15577257,  0.01018927]), 'effectorPosition': array([-1.26104118,  0.17187578])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9197206331216414
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.62509184, 2.26207757]), 'currentState': array([2.12509184, 1.76207757]), 'targetState': array([-1.15577257,  0.01018927]), 'effectorPosition': array([-1.26104118,  0.17187578])}
episode index:542
target Thresh 1.391168257961903
current state at start:  [ 0.14135265 -2.63179046]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.14135265, -2.63179046]), 'currentState': array([0.54940616, 3.32329374]), 'targetState': array([ 0.50157261, -0.16774577]), 'effectorPosition': array([ 0.10839921, -0.14551345])}
done in step count: 17
reward sum = 0.8429431933839268
running average episode reward sum: 0.9195792382049974
{'reset': False, 'endBeforeDone': False, 'stepCount': 18, 'initial state': array([ 0.14135265, -2.63179046]), 'currentState': array([4.90261928, 2.741273  ]), 'targetState': array([ 0.50157261, -0.16774577]), 'effectorPosition': array([ 0.39763234, -0.00394843])}
episode index:543
target Thresh 1.3923847045938649
current state at start:  [-3.57173939  1.70541077]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.57173939,  1.70541077]), 'currentState': array([2.29863244, 1.87416705]), 'targetState': array([-1.05234675, -0.19477344]), 'effectorPosition': array([-1.17903945, -0.11130398])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9197270704877089
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.57173939,  1.70541077]), 'currentState': array([2.29863244, 1.87416705]), 'targetState': array([-1.05234675, -0.19477344]), 'effectorPosition': array([-1.17903945, -0.11130398])}
episode index:544
target Thresh 1.3935987207638352
current state at start:  [-2.42264663  2.29215638]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.42264663,  2.29215638]), 'currentState': array([3.5133885 , 2.25341627]), 'targetState': array([ 0.00186033, -0.66056187]), 'effectorPosition': array([-0.06206451, -0.85702502])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9198743602666305
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.42264663,  2.29215638]), 'currentState': array([3.5133885 , 2.25341627]), 'targetState': array([ 0.00186033, -0.66056187]), 'effectorPosition': array([-0.06206451, -0.85702502])}
episode index:545
target Thresh 1.39481031132788
current state at start:  [-1.27491537 -2.98033751]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.27491537, -2.98033751]), 'currentState': array([5.50622645, 2.8028478 ]), 'targetState': array([0.11683893, 0.63650501]), 'effectorPosition': array([0.27350352, 0.19710614])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9199846636361055
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.27491537, -2.98033751]), 'currentState': array([6.09803948, 2.58978301]), 'targetState': array([0.11683893, 0.63650501]), 'effectorPosition': array([0.24239139, 0.48794663])}
episode index:546
target Thresh 1.3960194811323632
current state at start:  [-2.39143281  2.33709512]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.39143281,  2.33709512]), 'currentState': array([3.69054338, 2.81570266]), 'targetState': array([ 0.14112772, -0.14188778]), 'effectorPosition': array([ 0.12215244, -0.30057686])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9201309439585259
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.39143281,  2.33709512]), 'currentState': array([3.69054338, 2.81570266]), 'targetState': array([ 0.14112772, -0.14188778]), 'effectorPosition': array([ 0.12215244, -0.30057686])}
episode index:547
target Thresh 1.3972262350139655
current state at start:  [ 0.81853444 -2.75824476]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.81853444, -2.75824476]), 'currentState': array([1.31853444, 3.63454137]), 'targetState': array([0.61462603, 0.1668579 ]), 'effectorPosition': array([ 0.48796461, -0.00282414])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9202766904111563
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.81853444, -2.75824476]), 'currentState': array([1.31853444, 3.63454137]), 'targetState': array([0.61462603, 0.1668579 ]), 'effectorPosition': array([ 0.48796461, -0.00282414])}
episode index:548
target Thresh 1.3984305777997044
current state at start:  [ 1.70905124 -2.43466352]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.70905124, -2.43466352]), 'currentState': array([2.20905124, 3.41387661]), 'targetState': array([ 0.03579117, -0.1176309 ]), 'effectorPosition': array([0.19403955, 0.18981648])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9204036909750705
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.70905124, -2.43466352]), 'currentState': array([2.26941374, 2.91387661]), 'targetState': array([ 0.03579117, -0.1176309 ]), 'effectorPosition': array([-0.18946987, -0.12542756])}
episode index:549
target Thresh 1.3996325143069521
current state at start:  [-0.15099247  2.77258771]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.15099247,  2.77258771]), 'currentState': array([5.75070425, 3.08853322]), 'targetState': array([ 0.2796425 , -0.13166115]), 'effectorPosition': array([0.02813665, 0.04497746])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9205122297187521
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-0.15099247,  2.77258771]), 'currentState': array([5.22557138, 3.00679549]), 'targetState': array([ 0.2796425 , -0.13166115]), 'effectorPosition': array([0.12153178, 0.05807586])}
episode index:550
target Thresh 1.4008320493434567
current state at start:  [-0.25871859 -1.97133886]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.25871859, -1.97133886]), 'currentState': array([6.19029963, 4.0473475 ]), 'targetState': array([ 0.37600115, -0.72604493]), 'effectorPosition': array([ 0.30827173, -0.81901465])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9206564906448523
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.25871859, -1.97133886]), 'currentState': array([6.19029963, 4.0473475 ]), 'targetState': array([ 0.37600115, -0.72604493]), 'effectorPosition': array([ 0.30827173, -0.81901465])}
episode index:551
target Thresh 1.40202918770736
current state at start:  [0.52891902 1.89548456]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.52891902, 1.89548456]), 'currentState': array([0.12801109, 2.26143664]), 'targetState': array([0.19240832, 0.53409251]), 'effectorPosition': array([0.26159264, 0.81086837])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9207821129444088
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.52891902, 1.89548456]), 'currentState': array([6.03046115, 2.44005571]), 'targetState': array([0.19240832, 0.53409251]), 'effectorPosition': array([0.39002309, 0.56584422])}
episode index:552
target Thresh 1.4032239341872166
current state at start:  [-3.0656878  2.0153746]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.0656878,  2.0153746]), 'currentState': array([2.74166392, 1.62101072]), 'targetState': array([-0.87605888, -0.43557443]), 'effectorPosition': array([-1.2637182 , -0.55011792])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9208893785629542
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-3.0656878,  2.0153746]), 'currentState': array([2.5446795 , 1.86924955]), 'targetState': array([-0.87605888, -0.43557443]), 'effectorPosition': array([-1.12112322, -0.39369838])}
episode index:553
target Thresh 1.4044162935620141
current state at start:  [ 3.12270327 -2.87079106]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.12270327, -2.87079106]), 'currentState': array([3.53245921, 2.91239425]), 'targetState': array([-0.36380859, -0.08615217]), 'effectorPosition': array([ 0.06238089, -0.22002493])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9209785656052593
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 3.12270327, -2.87079106]), 'currentState': array([2.31761907, 2.67336703]), 'targetState': array([-0.36380859, -0.08615217]), 'effectorPosition': array([-0.40430343, -0.22759127])}
episode index:554
target Thresh 1.405606270601192
current state at start:  [ 2.62025639 -2.49889052]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.62025639, -2.49889052]), 'currentState': array([3.08248666, 3.58752831]), 'targetState': array([-0.55048657,  0.91083071]), 'effectorPosition': array([-0.07214401,  0.43632582])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9211029285501147
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 2.62025639, -2.49889052]), 'currentState': array([3.28236884, 4.08061792]), 'targetState': array([-0.55048657,  0.91083071]), 'effectorPosition': array([-0.51860392,  0.74155255])}
episode index:555
target Thresh 1.4067938700646598
current state at start:  [-3.32387603  2.44630579]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.32387603,  2.44630579]), 'currentState': array([3.40524551, 2.08053668]), 'targetState': array([-0.19347343, -1.09660384]), 'effectorPosition': array([-0.26687721, -0.97615332])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9212448297577583
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.32387603,  2.44630579]), 'currentState': array([3.40524551, 2.08053668]), 'targetState': array([-0.19347343, -1.09660384]), 'effectorPosition': array([-0.26687721, -0.97615332])}
episode index:556
target Thresh 1.4079790967028167
current state at start:  [-1.38488303  1.81203916]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.38488303,  1.81203916]), 'currentState': array([4.39830227, 2.19278481]), 'targetState': array([ 0.47712936, -1.18491753]), 'effectorPosition': array([ 0.64402357, -0.64801917])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9213328982860208
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-1.38488303,  1.81203916]), 'currentState': array([3.97767662, 1.86637631]), 'targetState': array([ 0.47712936, -1.18491753]), 'effectorPosition': array([ 0.23474713, -1.16717794])}
episode index:557
target Thresh 1.4091619552565713
current state at start:  [ 3.36234829 -3.11248495]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.36234829, -3.11248495]), 'currentState': array([3.81897232, 3.16262514]), 'targetState': array([ 0.42949455, -0.07556557]), 'effectorPosition': array([-0.01335355,  0.01624906])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.921455957608089
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.36234829, -3.11248495]), 'currentState': array([4.2323359 , 2.83134354]), 'targetState': array([ 0.42949455, -0.07556557]), 'effectorPosition': array([ 0.24873968, -0.18333979])}
episode index:558
target Thresh 1.410342450457359
current state at start:  [ 0.22531618 -2.12408834]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.22531618, -2.12408834]), 'currentState': array([0.36836848, 4.25590225]), 'targetState': array([ 0.83825644, -0.57699071]), 'effectorPosition': array([ 0.84491183, -0.63602626])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9215964657340137
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.22531618, -2.12408834]), 'currentState': array([0.36836848, 4.25590225]), 'targetState': array([ 0.83825644, -0.57699071]), 'effectorPosition': array([ 0.84491183, -0.63602626])}
episode index:559
target Thresh 1.4115205870271623
current state at start:  [ 2.24595564 -2.57272807]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.24595564, -2.57272807]), 'currentState': array([2.05781387, 3.33494225]), 'targetState': array([1.91860459e-01, 6.53528680e-05]), 'effectorPosition': array([0.16108618, 0.10639074])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9217364720452029
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.24595564, -2.57272807]), 'currentState': array([2.05781387, 3.33494225]), 'targetState': array([1.91860459e-01, 6.53528680e-05]), 'effectorPosition': array([0.16108618, 0.10639074])}
episode index:560
target Thresh 1.412696369678529
current state at start:  [1.78748554 1.77495745]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.78748554, 1.77495745]), 'currentState': array([1.28748554, 2.27495745]), 'targetState': array([-0.51428485,  0.60795732]), 'effectorPosition': array([-0.6332059 ,  0.55159848])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.921875979225158
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.78748554, 1.77495745]), 'currentState': array([1.28748554, 2.27495745]), 'targetState': array([-0.51428485,  0.60795732]), 'effectorPosition': array([-0.6332059 ,  0.55159848])}
episode index:561
target Thresh 1.4138698031145913
current state at start:  [-0.32510318 -2.27987677]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.32510318, -2.27987677]), 'currentState': array([5.50451522, 3.84704201]), 'targetState': array([-0.39374871, -0.61906585]), 'effectorPosition': array([-0.28547235, -0.62917803])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9220149899382805
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.32510318, -2.27987677]), 'currentState': array([5.50451522, 3.84704201]), 'targetState': array([-0.39374871, -0.61906585]), 'effectorPosition': array([-0.28547235, -0.62917803])}
episode index:562
target Thresh 1.4150408920290847
current state at start:  [ 4.25902215 -2.53915361]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.25902215, -2.53915361]), 'currentState': array([4.75229559, 3.33945766]), 'targetState': array([-0.03888252, -0.20636111]), 'effectorPosition': array([-0.19564151, -0.02733858])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9221535068300419
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.25902215, -2.53915361]), 'currentState': array([4.75229559, 3.33945766]), 'targetState': array([-0.03888252, -0.20636111]), 'effectorPosition': array([-0.19564151, -0.02733858])}
episode index:563
target Thresh 1.416209641106366
current state at start:  [1.18890779 1.66093747]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.18890779, 1.66093747]), 'currentState': array([1.48875113, 2.16093747]), 'targetState': array([-0.65521642,  0.5560709 ]), 'effectorPosition': array([-0.79171926,  0.51012157])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9222915325271518
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.18890779, 1.66093747]), 'currentState': array([1.48875113, 2.16093747]), 'targetState': array([-0.65521642,  0.5560709 ]), 'effectorPosition': array([-0.79171926,  0.51012157])}
episode index:564
target Thresh 1.4173760550214336
current state at start:  [ 2.46243087 -1.76494443]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.46243087, -1.76494443]), 'currentState': array([2.06100599, 4.7559839 ]), 'targetState': array([0.36542534, 1.17680716]), 'effectorPosition': array([0.39006662, 1.39104646])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9224290696377232
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.46243087, -1.76494443]), 'currentState': array([2.06100599, 4.7559839 ]), 'targetState': array([0.36542534, 1.17680716]), 'effectorPosition': array([0.39006662, 1.39104646])}
episode index:565
target Thresh 1.4185401384399445
current state at start:  [-1.44801826 -2.02576573]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.44801826, -2.02576573]), 'currentState': array([5.33516704, 3.93531709]), 'targetState': array([-0.24286522, -0.46120555]), 'effectorPosition': array([-0.40482638, -0.65857882])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9225484529069146
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.44801826, -2.02576573]), 'currentState': array([5.46114441, 3.72651138]), 'targetState': array([-0.24286522, -0.46120555]), 'effectorPosition': array([-0.29129043, -0.49763035])}
episode index:566
target Thresh 1.4197018960182342
current state at start:  [-1.25391679 -1.72086315]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.25391679, -1.72086315]), 'currentState': array([5.52926852, 4.36566629]), 'targetState': array([-0.28184439, -0.93449505]), 'effectorPosition': array([-0.16248381, -1.13752552])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9226850517554033
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.25391679, -1.72086315]), 'currentState': array([5.52926852, 4.36566629]), 'targetState': array([-0.28184439, -0.93449505]), 'effectorPosition': array([-0.16248381, -1.13752552])}
episode index:567
target Thresh 1.4208613324033337
current state at start:  [ 3.37985126 -2.5912593 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.37985126, -2.5912593 ]), 'currentState': array([3.87985126, 3.25210983]), 'targetState': array([-0.56040801,  0.05477585]), 'effectorPosition': array([-0.07873926,  0.07747095])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9228035639882283
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.37985126, -2.5912593 ]), 'currentState': array([4.10617585, 3.52892054]), 'targetState': array([-0.56040801,  0.05477585]), 'effectorPosition': array([-0.35261785,  0.15432861])}
episode index:568
target Thresh 1.4220184522329906
current state at start:  [ 1.85843184 -2.52638618]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.85843184, -2.52638618]), 'currentState': array([1.70037528, 3.46156373]), 'targetState': array([0.41310165, 0.21266988]), 'effectorPosition': array([0.30534368, 0.09097366])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9229392343502876
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.85843184, -2.52638618]), 'currentState': array([1.70037528, 3.46156373]), 'targetState': array([0.41310165, 0.21266988]), 'effectorPosition': array([0.30534368, 0.09097366])}
episode index:569
target Thresh 1.4231732601356861
current state at start:  [-0.02420254  1.98094861]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.02420254,  1.98094861]), 'currentState': array([5.92188307, 2.27991311]), 'targetState': array([0.92861744, 0.39463556]), 'effectorPosition': array([0.59459325, 0.58662716])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9230568848163397
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.02420254,  1.98094861]), 'currentState': array([5.62661632, 2.05324083]), 'targetState': array([0.92861744, 0.39463556]), 'effectorPosition': array([0.96533711, 0.37447582])}
episode index:570
target Thresh 1.4243257607306528
current state at start:  [-2.60312753  2.63051688]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.60312753,  2.63051688]), 'currentState': array([3.33501364, 2.97046503]), 'targetState': array([-0.26811777, -0.11085098]), 'effectorPosition': array([ 0.01839911, -0.16992569])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9231396205697261
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-2.60312753,  2.63051688]), 'currentState': array([2.61727759, 2.75948043]), 'targetState': array([-0.26811777, -0.11085098]), 'effectorPosition': array([-0.24910455, -0.28668577])}
episode index:571
target Thresh 1.4254759586278951
current state at start:  [ 3.44163638 -2.17686436]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.44163638, -2.17686436]), 'currentState': array([3.0041545 , 4.31269264]), 'targetState': array([-0.26811277,  1.30685997]), 'effectorPosition': array([-0.47889411,  0.9961843 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9232565093449538
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.44163638, -2.17686436]), 'currentState': array([2.54619353, 4.55387538]), 'targetState': array([-0.26811277,  1.30685997]), 'effectorPosition': array([-0.1434283 ,  1.28985546])}
episode index:572
target Thresh 1.4266238584282058
current state at start:  [1.06103474 2.58330736]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.06103474, 2.58330736]), 'currentState': array([0.60467559, 2.91335607]), 'targetState': array([0.00748786, 0.25648378]), 'effectorPosition': array([-0.10729302,  0.20088406])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9233904421384181
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.06103474, 2.58330736]), 'currentState': array([0.60467559, 2.91335607]), 'targetState': array([0.00748786, 0.25648378]), 'effectorPosition': array([-0.10729302,  0.20088406])}
episode index:573
target Thresh 1.4277694647231858
current state at start:  [-2.14461938  2.84736583]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.14461938,  2.84736583]), 'currentState': array([4.00673091, 3.15520326]), 'targetState': array([0.08891516, 0.16241497]), 'effectorPosition': array([-0.01041994,  0.00875618])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9235239082670968
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.14461938,  2.84736583]), 'currentState': array([4.00673091, 3.15520326]), 'targetState': array([0.08891516, 0.16241497]), 'effectorPosition': array([-0.01041994,  0.00875618])}
episode index:574
target Thresh 1.4289127820952614
current state at start:  [-0.79077531 -2.74095882]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.79077531, -2.74095882]), 'currentState': array([5.72486084, 3.04222649]), 'targetState': array([-0.01179281, -0.00862984]), 'effectorPosition': array([0.0567379 , 0.08152498])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9236569101657628
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.79077531, -2.74095882]), 'currentState': array([5.72486084, 3.04222649]), 'targetState': array([-0.01179281, -0.00862984]), 'effectorPosition': array([0.0567379 , 0.08152498])}
episode index:575
target Thresh 1.430053815117704
current state at start:  [ 3.97896345 -2.80546773]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.97896345, -2.80546773]), 'currentState': array([3.80106242, 3.97771758]), 'targetState': array([-0.63208136,  0.63931968]), 'effectorPosition': array([-0.71518644,  0.3844758 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9237720891411695
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.97896345, -2.80546773]), 'currentState': array([3.41268529, 4.24619478]), 'targetState': array([-0.63208136,  0.63931968]), 'effectorPosition': array([-0.76961271,  0.71324365])}
episode index:576
target Thresh 1.4311925683546474
current state at start:  [-0.41202707 -2.34942783]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.41202707, -2.34942783]), 'currentState': array([6.12338307, 3.59695232]), 'targetState': array([ 0.03099591, -0.12347897]), 'effectorPosition': array([ 0.03061884, -0.45039612])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9238868688826927
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.41202707, -2.34942783]), 'currentState': array([6.03951454, 3.30424374]), 'targetState': array([ 0.03099591, -0.12347897]), 'effectorPosition': array([-0.02626082, -0.1603355 ])}
episode index:577
target Thresh 1.4323290463611056
current state at start:  [ 2.64087076 -1.80871001]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.64087076, -1.80871001]), 'currentState': array([2.83149498, 4.82491076]), 'targetState': array([-0.37305846,  1.212247  ]), 'effectorPosition': array([-0.75601081,  1.28569694])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9239841234347986
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 2.64087076, -1.80871001]), 'currentState': array([2.87955889, 4.44717872]), 'targetState': array([-0.37305846,  1.212247  ]), 'effectorPosition': array([-0.46271159,  1.12324246])}
episode index:578
target Thresh 1.4334632536829925
current state at start:  [-2.74157253  2.07363176]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.74157253,  2.07363176]), 'currentState': array([3.18996734, 2.46772322]), 'targetState': array([ 0.05975426, -0.36033329]), 'effectorPosition': array([-0.18815663, -0.63385424])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9240981404927697
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.74157253,  2.07363176]), 'currentState': array([3.10695278, 2.94986883]), 'targetState': array([ 0.05975426, -0.36033329]), 'effectorPosition': array([-0.02491115, -0.18980253])}
episode index:579
target Thresh 1.4345951948571387
current state at start:  [ 3.56949277 -2.39671644]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.56949277, -2.39671644]), 'currentState': array([3.99528507, 3.45675389]), 'targetState': array([-0.05883345, -0.06830242]), 'effectorPosition': array([-0.26599769,  0.16659053])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9242117643884719
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.56949277, -2.39671644]), 'currentState': array([4.42489536, 3.16241256]), 'targetState': array([-0.05883345, -0.06830242]), 'effectorPosition': array([-0.02002542,  0.00569522])}
episode index:580
target Thresh 1.4357248744113105
current state at start:  [-4.14577985  2.78273706]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.14577985,  2.78273706]), 'currentState': array([1.87420484, 3.28273706]), 'targetState': array([0.38134133, 0.46135801]), 'effectorPosition': array([0.13127953, 0.05152063])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9243249971520029
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-4.14577985,  2.78273706]), 'currentState': array([1.79207923, 3.78273706]), 'targetState': array([0.38134133, 0.46135801]), 'effectorPosition': array([0.53994257, 0.32502065])}
episode index:581
target Thresh 1.4368522968642274
current state at start:  [-1.11784416 -2.61486615]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.11784416, -2.61486615]), 'currentState': array([5.66534115, 3.38296496]), 'targetState': array([0.07918592, 0.24316339]), 'effectorPosition': array([-0.11483833, -0.21163752])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.924437840799508
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.11784416, -2.61486615]), 'currentState': array([6.16534115, 3.1086933 ]), 'targetState': array([0.07918592, 0.24316339]), 'effectorPosition': array([0.00440471, 0.03260166])}
episode index:582
target Thresh 1.437977466725581
current state at start:  [-2.46409752  1.64872841]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.46409752,  1.64872841]), 'currentState': array([3.40311633, 2.14872841]), 'targetState': array([-0.35732184, -0.68512518]), 'effectorPosition': array([-0.2217174 , -0.92642071])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9245502973332996
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.46409752,  1.64872841]), 'currentState': array([3.15927533, 2.4982406 ]), 'targetState': array([-0.35732184, -0.68512518]), 'effectorPosition': array([-0.18927237, -0.60332174])}
episode index:583
target Thresh 1.439100388496052
current state at start:  [ 2.80040574 -1.9541778 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.80040574, -1.9541778 ]), 'currentState': array([3.30040574, 4.46569348]), 'targetState': array([-0.93039801,  0.87490335]), 'effectorPosition': array([-0.89964635,  0.83799449])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9246794920296467
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.80040574, -1.9541778 ]), 'currentState': array([3.30040574, 4.46569348]), 'targetState': array([-0.93039801,  0.87490335]), 'effectorPosition': array([-0.89964635,  0.83799449])}
episode index:584
target Thresh 1.4402210666673294
current state at start:  [ 4.33490653 -2.72703201]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.33490653, -2.72703201]), 'currentState': array([4.47646255, 3.33208713]), 'targetState': array([-0.12900278,  0.30947557]), 'effectorPosition': array([-0.18832753,  0.02666993])}
done in step count: 51
reward sum = 0.598956006466161
running average episode reward sum: 0.9241226997466323
{'reset': False, 'endBeforeDone': False, 'stepCount': 52, 'initial state': array([ 4.33490653, -2.72703201]), 'currentState': array([4.02283947, 3.31003652]), 'targetState': array([-0.12900278,  0.30947557]), 'effectorPosition': array([-0.13835035,  0.09573659])}
episode index:585
target Thresh 1.441339505722127
current state at start:  [-2.30309159  1.7169053 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.30309159,  1.7169053 ]), 'currentState': array([3.94846941, 1.8751058 ]), 'targetState': array([ 0.30468603, -1.2517675 ]), 'effectorPosition': array([ 0.20446834, -1.16572887])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9242521831941636
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.30309159,  1.7169053 ]), 'currentState': array([3.94846941, 1.8751058 ]), 'targetState': array([ 0.30468603, -1.2517675 ]), 'effectorPosition': array([ 0.20446834, -1.16572887])}
episode index:586
target Thresh 1.4424557101342024
current state at start:  [0.49312116 2.616713  ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.49312116, 2.616713  ]), 'currentState': array([0.52161951, 2.68971281]), 'targetState': array([-0.25092366,  0.51405737]), 'effectorPosition': array([-0.13055584,  0.42860178])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.924381225471516
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.49312116, 2.616713  ]), 'currentState': array([0.52161951, 2.68971281]), 'targetState': array([-0.25092366,  0.51405737]), 'effectorPosition': array([-0.13055584,  0.42860178])}
episode index:587
target Thresh 1.4435696843683754
current state at start:  [0.31482154 2.47823278]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.31482154, 2.47823278]), 'currentState': array([6.09800685, 2.97823278]), 'targetState': array([-0.34085117,  0.08045353]), 'effectorPosition': array([0.0430305 , 0.15740244])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9244593169247957
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([0.31482154, 2.47823278]), 'currentState': array([5.07020489, 3.42691108]), 'targetState': array([-0.34085117,  0.08045353]), 'effectorPosition': array([-0.24947723, -0.13644398])}
episode index:588
target Thresh 1.4446814328805435
current state at start:  [ 1.19533293 -1.69063899]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.19533293, -1.69063899]), 'currentState': array([1.69533293, 4.09254631]), 'targetState': array([0.56367039, 0.61607065]), 'effectorPosition': array([0.75560834, 0.51695438])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9245875693578605
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.19533293, -1.69063899]), 'currentState': array([1.69533293, 4.09254631]), 'targetState': array([0.56367039, 0.61607065]), 'effectorPosition': array([0.75560834, 0.51695438])}
episode index:589
target Thresh 1.4457909601177028
current state at start:  [-0.15860219  2.38927259]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.15860219,  2.38927259]), 'currentState': array([5.80925344, 2.85151639]), 'targetState': array([ 0.24957575, -0.02844709]), 'effectorPosition': array([0.1677118 , 0.23543284])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9246984378843727
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.15860219,  2.38927259]), 'currentState': array([5.46219354, 3.12850817]), 'targetState': array([ 0.24957575, -0.02844709]), 'effectorPosition': array([0.00963357, 0.00885412])}
episode index:590
target Thresh 1.4468982705179636
current state at start:  [-2.34532587  1.61145677]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.34532587,  1.61145677]), 'currentState': array([4.28949153, 2.11145677]), 'targetState': array([ 0.33618444, -0.77616527]), 'effectorPosition': array([ 0.58266958, -0.79441265])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9248258516950589
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.34532587,  1.61145677]), 'currentState': array([4.28949153, 2.11145677]), 'targetState': array([ 0.33618444, -0.77616527]), 'effectorPosition': array([ 0.58266958, -0.79441265])}
episode index:591
target Thresh 1.448003368510569
current state at start:  [ 3.63488278 -2.21072497]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.63488278, -2.21072497]), 'currentState': array([3.34976259, 3.9301843 ]), 'targetState': array([-0.28918135,  0.82379999]), 'effectorPosition': array([-0.43538627,  0.63304716])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9249528350536822
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.63488278, -2.21072497]), 'currentState': array([3.34976259, 3.9301843 ]), 'targetState': array([-0.28918135,  0.82379999]), 'effectorPosition': array([-0.43538627,  0.63304716])}
episode index:592
target Thresh 1.4491062585159127
current state at start:  [ 2.97737127 -2.46411312]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.97737127, -2.46411312]), 'currentState': array([2.61001905, 4.30710584]), 'targetState': array([0.42813383, 1.04932573]), 'effectorPosition': array([-0.05631024,  1.0992139 ])}
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.9248877963296728
{'reset': False, 'endBeforeDone': False, 'stepCount': 13, 'initial state': array([ 2.97737127, -2.46411312]), 'currentState': array([2.19997192, 4.53295624]), 'targetState': array([0.42813383, 1.04932573]), 'effectorPosition': array([0.3120805, 1.2432469])}
episode index:593
target Thresh 1.4502069449455557
current state at start:  [-3.84895948  2.5876865 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.84895948,  2.5876865 ]), 'currentState': array([2.93422583, 3.0876865 ]), 'targetState': array([ 0.12510821, -0.97668962]), 'effectorPosition': array([-0.0125145 , -0.05242668])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.9249317395175017
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([-3.84895948,  2.5876865 ]), 'currentState': array([3.95564841, 1.94710186]), 'targetState': array([ 0.12510821, -0.97668962]), 'effectorPosition': array([ 0.24194795, -1.09840209])}
episode index:594
target Thresh 1.4513054322022456
current state at start:  [0.32450162 2.90760771]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.32450162, 2.90760771]), 'currentState': array([0.01337801, 3.21009997]), 'targetState': array([ 0.00319632, -0.03321716]), 'effectorPosition': array([ 0.00326125, -0.06841623])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9250579046611698
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.32450162, 2.90760771]), 'currentState': array([0.01337801, 3.21009997]), 'targetState': array([ 0.00319632, -0.03321716]), 'effectorPosition': array([ 0.00326125, -0.06841623])}
episode index:595
target Thresh 1.4524017246799326
current state at start:  [-2.20276651  2.32314523]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.20276651,  2.32314523]), 'currentState': array([4.21371484, 2.62667067]), 'targetState': array([0.32524075, 0.03694902]), 'effectorPosition': array([ 0.37047744, -0.34940546])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9251668679083827
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.20276651,  2.32314523]), 'currentState': array([4.48335118, 2.72294176]), 'targetState': array([0.32524075, 0.03694902]), 'effectorPosition': array([ 0.37630424, -0.17640487])}
episode index:596
target Thresh 1.4534958267637883
current state at start:  [-0.81177974 -1.89570506]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.81177974, -1.89570506]), 'currentState': array([5.26060558, 3.88748025]), 'targetState': array([-0.68119744, -0.50828345]), 'effectorPosition': array([-0.44079832, -0.58028023])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9252754661195913
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.81177974, -1.89570506]), 'currentState': array([4.94403163, 4.09529476]), 'targetState': array([-0.68119744, -0.50828345]), 'effectorPosition': array([-0.69705214, -0.59731298])}
episode index:597
target Thresh 1.4545877428302223
current state at start:  [ 3.94832739 -2.5986175 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.94832739, -2.5986175 ]), 'currentState': array([3.68657341, 3.25642377]), 'targetState': array([0.15988326, 0.84621912]), 'effectorPosition': array([-0.06502971,  0.09456659])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.9253184670958129
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([ 3.94832739, -2.5986175 ]), 'currentState': array([2.74456216, 4.0726858 ]), 'targetState': array([0.15988326, 0.84621912]), 'effectorPosition': array([-0.06146716,  0.89571597])}
episode index:598
target Thresh 1.4556774772469003
current state at start:  [ 2.75228914 -2.3303707 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.75228914, -2.3303707 ]), 'currentState': array([2.4135408 , 4.39148524]), 'targetState': array([0.65403795, 0.96468334]), 'effectorPosition': array([0.12043093, 1.16389338])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.9253454482014976
{'reset': False, 'endBeforeDone': False, 'stepCount': 7, 'initial state': array([ 2.75228914, -2.3303707 ]), 'currentState': array([1.78574252, 4.61512455]), 'targetState': array([0.65403795, 0.96468334]), 'effectorPosition': array([0.77978863, 1.09439819])}
episode index:599
target Thresh 1.4567650343727618
current state at start:  [-0.80186691  2.92983967]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.80186691,  2.92983967]), 'currentState': array([5.98131839, 2.42983967]), 'targetState': array([0.88189107, 0.19391434]), 'effectorPosition': array([0.42599131, 0.55144835])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9254367057878283
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-0.80186691,  2.92983967]), 'currentState': array([5.47379489, 2.29809103]), 'targetState': array([0.88189107, 0.19391434]), 'effectorPosition': array([0.77194335, 0.2727653 ])}
episode index:600
target Thresh 1.457850418558036
current state at start:  [0.46057022 2.70450561]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.46057022, 2.70450561]), 'currentState': array([0.96057022, 2.29059149]), 'targetState': array([0.33087479, 1.01131741]), 'effectorPosition': array([-0.42095054,  0.71016851])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9255276596883478
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([0.46057022, 2.70450561]), 'currentState': array([0.22690067, 1.8010312 ]), 'targetState': array([0.33087479, 1.01131741]), 'effectorPosition': array([0.5329887 , 1.12227921])}
episode index:601
target Thresh 1.458933634144262
current state at start:  [-1.14314037  2.89770353]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.14314037,  2.89770353]), 'currentState': array([4.80240367, 3.20292604]), 'targetState': array([-0.0100357,  0.0217638]), 'effectorPosition': array([-0.06087776, -0.00738269])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9256513678948456
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.14314037,  2.89770353]), 'currentState': array([4.80240367, 3.20292604]), 'targetState': array([-0.0100357,  0.0217638]), 'effectorPosition': array([-0.06087776, -0.00738269])}
episode index:602
target Thresh 1.4600146854643032
current state at start:  [-0.40758445 -2.38852259]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.40758445, -2.38852259]), 'currentState': array([5.7571686 , 4.25666116]), 'targetState': array([ 0.19199196, -0.83887312]), 'effectorPosition': array([ 0.03334606, -1.0576654 ])}
done in step count: 54
reward sum = 0.5811664141181095
running average episode reward sum: 0.9250800827310367
{'reset': False, 'endBeforeDone': False, 'stepCount': 55, 'initial state': array([-0.40758445, -2.38852259]), 'currentState': array([5.79945484, 4.22464823]), 'targetState': array([ 0.19199196, -0.83887312]), 'effectorPosition': array([ 0.05954961, -1.02917019])}
episode index:603
target Thresh 1.4610935768423658
current state at start:  [ 0.42051395 -2.55546855]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.42051395, -2.55546855]), 'currentState': array([0.92051395, 3.23352123]), 'targetState': array([ 0.39161834, -0.10869547]), 'effectorPosition': array([ 0.07562045, -0.05221553])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9251875660377734
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.42051395, -2.55546855]), 'currentState': array([0.71842334, 3.44191083]), 'targetState': array([ 0.39161834, -0.10869547]), 'effectorPosition': array([ 0.22840652, -0.19325019])}
episode index:604
target Thresh 1.4621703125940178
current state at start:  [ 2.51968993 -2.494267  ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.51968993, -2.494267  ]), 'currentState': array([2.05005331, 4.28891831]), 'targetState': array([0.84639972, 0.88638631]), 'effectorPosition': array([0.53732435, 0.94309517])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9252946940277936
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 2.51968993, -2.494267  ]), 'currentState': array([1.55005331, 4.77629989]), 'targetState': array([0.84639972, 0.88638631]), 'effectorPosition': array([1.01980994, 1.04293936])}
episode index:605
target Thresh 1.4632448970262026
current state at start:  [ 0.72834839 -1.75213232]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.72834839, -1.75213232]), 'currentState': array([0.22834839, 4.59024738]), 'targetState': array([ 1.09306063, -0.54269783]), 'effectorPosition': array([ 1.08004883, -0.76799627])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9254179701102561
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.72834839, -1.75213232]), 'currentState': array([0.22834839, 4.59024738]), 'targetState': array([ 1.09306063, -0.54269783]), 'effectorPosition': array([ 1.08004883, -0.76799627])}
episode index:606
target Thresh 1.46431733443726
current state at start:  [-1.40999194 -1.66965757]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.40999194, -1.66965757]), 'currentState': array([5.28398512, 4.66409021]), 'targetState': array([-0.23421529, -1.2686182 ]), 'effectorPosition': array([-0.32520091, -1.34077752])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9255408400112276
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.40999194, -1.66965757]), 'currentState': array([5.28398512, 4.66409021]), 'targetState': array([-0.23421529, -1.2686182 ]), 'effectorPosition': array([-0.32520091, -1.34077752])}
episode index:607
target Thresh 1.465387629116941
current state at start:  [0.45912648 2.85849385]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.45912648, 2.85849385]), 'currentState': array([6.27402167, 3.35849385]), 'targetState': array([-0.16788447, -0.15824922]), 'effectorPosition': array([ 0.02145797, -0.21541014])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9256633057348933
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.45912648, 2.85849385]), 'currentState': array([6.27402167, 3.35849385]), 'targetState': array([-0.16788447, -0.15824922]), 'effectorPosition': array([ 0.02145797, -0.21541014])}
episode index:608
target Thresh 1.4664557853464255
current state at start:  [0.64629855 2.46138068]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.64629855, 2.46138068]), 'currentState': array([0.26629903, 2.55116483]), 'targetState': array([-0.00830618,  0.63721952]), 'effectorPosition': array([0.01682291, 0.5816458 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9257853692722745
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.64629855, 2.46138068]), 'currentState': array([0.26629903, 2.55116483]), 'targetState': array([-0.00830618,  0.63721952]), 'effectorPosition': array([0.01682291, 0.5816458 ])}
episode index:609
target Thresh 1.4675218073983403
current state at start:  [ 2.76391221 -2.22045062]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.76391221, -2.22045062]), 'currentState': array([2.69337138, 3.6650207 ]), 'targetState': array([0.2407197 , 0.40106848]), 'effectorPosition': array([0.09595394, 0.5084991 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9259070326013363
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.76391221, -2.22045062]), 'currentState': array([2.69337138, 3.6650207 ]), 'targetState': array([0.2407197 , 0.40106848]), 'effectorPosition': array([0.09595394, 0.5084991 ])}
episode index:610
target Thresh 1.4685856995367743
current state at start:  [ 3.01501334 -2.18715256]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.01501334, -2.18715256]), 'currentState': array([3.26067258, 3.81917755]), 'targetState': array([0.17316766, 0.21190122]), 'effectorPosition': array([-0.29382302,  0.59622976])}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9258718035381734
{'reset': False, 'endBeforeDone': False, 'stepCount': 11, 'initial state': array([ 3.01501334, -2.18715256]), 'currentState': array([4.87153601, 3.05290249]), 'targetState': array([0.17316766, 0.21190122]), 'effectorPosition': array([0.08807749, 0.01015612])}
episode index:611
target Thresh 1.4696474660172982
current state at start:  [ 3.77465033 -2.0066701 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.77465033, -2.0066701 ]), 'currentState': array([3.29112448, 4.13249925]), 'targetState': array([-0.58367919,  1.08590499]), 'effectorPosition': array([-0.57164484,  0.75984129])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9259604117023267
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 3.77465033, -2.0066701 ]), 'currentState': array([2.98456105, 4.49763117]), 'targetState': array([-0.58367919,  1.08590499]), 'effectorPosition': array([-0.62441268,  1.0880658 ])}
episode index:612
target Thresh 1.470707111086979
current state at start:  [-0.28896575  2.53626322]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.28896575,  2.53626322]), 'currentState': array([5.68023817, 3.03626322]), 'targetState': array([-0.13079554,  0.02580397]), 'effectorPosition': array([0.06418381, 0.08345342])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9260811940649657
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.28896575,  2.53626322]), 'currentState': array([5.68023817, 3.03626322]), 'targetState': array([-0.13079554,  0.02580397]), 'effectorPosition': array([0.06418381, 0.08345342])}
episode index:613
target Thresh 1.4717646389843981
current state at start:  [ 3.78661851 -2.55316005]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.78661851, -2.55316005]), 'currentState': array([3.62538982, 3.5344328 ]), 'targetState': array([0.21244935, 0.62945268]), 'effectorPosition': array([-0.24549579,  0.30344808])}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9260458534801836
{'reset': False, 'endBeforeDone': False, 'stepCount': 11, 'initial state': array([ 3.78661851, -2.55316005]), 'currentState': array([2.71426135, 3.74563469]), 'targetState': array([0.21244935, 0.62945268]), 'effectorPosition': array([0.07435223, 0.59023605])}
episode index:614
target Thresh 1.4728200539396692
current state at start:  [0.63183017 2.06673664]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.63183017, 2.06673664]), 'currentState': array([0.22267268, 2.54225087]), 'targetState': array([0.47874274, 0.32889961]), 'effectorPosition': array([0.04541573, 0.58866223])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.926133746401354
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([0.63183017, 2.06673664]), 'currentState': array([5.79591556, 2.43208593]), 'targetState': array([0.47874274, 0.32889961]), 'effectorPosition': array([0.51825417, 0.46265103])}
episode index:615
target Thresh 1.4738733601744531
current state at start:  [0.07791748 2.59301623]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.07791748, 2.59301623]), 'currentState': array([5.95618895, 3.09301623]), 'targetState': array([ 0.24132436, -0.05743595]), 'effectorPosition': array([0.01671371, 0.04560545])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9262536591507026
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.07791748, 2.59301623]), 'currentState': array([5.95618895, 3.09301623]), 'targetState': array([ 0.24132436, -0.05743595]), 'effectorPosition': array([0.01671371, 0.04560545])}
episode index:616
target Thresh 1.4749245619019762
current state at start:  [ 2.17143959 -2.04378157]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.17143959, -2.04378157]), 'currentState': array([2.5719272 , 3.73940374]), 'targetState': array([0.09050701, 0.36060653]), 'effectorPosition': array([0.15752248, 0.56749228])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9263731832039429
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.17143959, -2.04378157]), 'currentState': array([2.5719272 , 3.73940374]), 'targetState': array([0.09050701, 0.36060653]), 'effectorPosition': array([0.15752248, 0.56749228])}
episode index:617
target Thresh 1.4759736633270466
current state at start:  [-0.54861137  2.10182395]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.54861137,  2.10182395]), 'currentState': array([5.37085105, 2.52759685]), 'targetState': array([0.20288606, 0.37146871]), 'effectorPosition': array([0.56744956, 0.20807731])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.926476139218176
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.54861137,  2.10182395]), 'currentState': array([5.40783719, 2.82669841]), 'targetState': array([0.20288606, 0.37146871]), 'effectorPosition': array([0.26929476, 0.16069242])}
episode index:618
target Thresh 1.4770206686460718
current state at start:  [ 0.38342838 -2.21853717]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.38342838, -2.21853717]), 'currentState': array([0.74715636, 3.6206734 ]), 'targetState': array([-0.00240574, -0.00781652]), 'effectorPosition': array([ 0.39584241, -0.26166908])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9265787625796975
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.38342838, -2.21853717]), 'currentState': array([1.12332417, 3.21872024]), 'targetState': array([-0.00240574, -0.00781652]), 'effectorPosition': array([ 0.0707513 , -0.03065894])}
episode index:619
target Thresh 1.478065582047074
current state at start:  [-3.20499157  2.93951862]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.20499157,  2.93951862]), 'currentState': array([3.08585322, 3.3205386 ]), 'targetState': array([ 0.12267424, -0.07835934]), 'effectorPosition': array([-0.00602729,  0.17860561])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9266810548981174
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.20499157,  2.93951862]), 'currentState': array([3.37294543, 2.85353039]), 'targetState': array([ 0.12267424, -0.07835934]), 'effectorPosition': array([ 0.02503535, -0.28597356])}
episode index:620
target Thresh 1.4791084077097088
current state at start:  [0.13264543 2.2089562 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.13264543, 2.2089562 ]), 'currentState': array([5.91583073, 2.24752802]), 'targetState': array([0.93096995, 0.47096326]), 'effectorPosition': array([0.62881532, 0.59337563])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9267830177726776
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.13264543, 2.2089562 ]), 'currentState': array([5.62787044, 2.11801166]), 'targetState': array([0.93096995, 0.47096326]), 'effectorPosition': array([0.90074521, 0.38475402])}
episode index:621
target Thresh 1.4801491498052797
current state at start:  [-2.6379665   1.94830722]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.6379665 ,  1.94830722]), 'currentState': array([3.94731357, 1.90904155]), 'targetState': array([ 0.00199776, -1.14069632]), 'effectorPosition': array([ 0.21769118, -1.13531759])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9269007299627537
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.6379665 ,  1.94830722]), 'currentState': array([3.94731357, 1.90904155]), 'targetState': array([ 0.00199776, -1.14069632]), 'effectorPosition': array([ 0.21769118, -1.13531759])}
episode index:622
target Thresh 1.4811878124967568
current state at start:  [ 3.23283826 -2.42750124]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.23283826, -2.42750124]), 'currentState': array([3.71340583, 3.42778605]), 'targetState': array([0.1670937 , 0.09604253]), 'effectorPosition': array([-0.18697427,  0.21538279])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9270020129002132
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.23283826, -2.42750124]), 'currentState': array([3.95636006, 3.14365399]), 'targetState': array([0.1670937 , 0.09604253]), 'effectorPosition': array([-0.00150121,  0.0014126 ])}
episode index:623
target Thresh 1.4822243999387923
current state at start:  [-1.69088413 -2.86784289]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.69088413, -2.86784289]), 'currentState': array([4.89960153, 3.49841662]), 'targetState': array([-0.07229594, -0.31933016]), 'effectorPosition': array([-0.33147307, -0.12690047])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9270871058282577
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.69088413, -2.86784289]), 'currentState': array([5.62378986, 3.55732696]), 'targetState': array([-0.07229594, -0.31933016]), 'effectorPosition': array([-0.18009846, -0.37138192])}
episode index:624
target Thresh 1.483258916277737
current state at start:  [ 2.63077266 -2.10874172]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.63077266, -2.10874172]), 'currentState': array([2.69428234, 3.73166947]), 'targetState': array([0.26556946, 0.26999223]), 'effectorPosition': array([0.08821239, 0.57482406])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9271877664589325
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 2.63077266, -2.10874172]), 'currentState': array([2.78422393, 3.39420108]), 'targetState': array([0.26556946, 0.26999223]), 'effectorPosition': array([0.05769714, 0.24524163])}
episode index:625
target Thresh 1.4842913656516579
current state at start:  [ 0.43547723 -1.95662375]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.43547723, -1.95662375]), 'currentState': array([0.93547723, 4.37940574]), 'targetState': array([ 1.18913641, -0.31853773]), 'effectorPosition': array([ 1.16013347, -0.01904247])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9272722907936626
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 0.43547723, -1.95662375]), 'currentState': array([0.69938001, 4.57968201]), 'targetState': array([ 1.18913641, -0.31853773]), 'effectorPosition': array([ 1.30206954, -0.19994828])}
episode index:626
target Thresh 1.4853217521903537
current state at start:  [-0.09739665  1.99598243]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.09739665,  1.99598243]), 'currentState': array([5.8564279 , 2.44353874]), 'targetState': array([0.4986046 , 0.37295805]), 'effectorPosition': array([0.47896596, 0.48826501])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9273882839502916
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.09739665,  1.99598243]), 'currentState': array([5.8564279 , 2.44353874]), 'targetState': array([0.4986046 , 0.37295805]), 'effectorPosition': array([0.47896596, 0.48826501])}
episode index:627
target Thresh 1.486350080015372
current state at start:  [-1.11523101  2.57832592]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.11523101,  2.57832592]), 'currentState': array([4.88541714, 3.02129452]), 'targetState': array([0.0001376 , 0.03407844]), 'effectorPosition': array([0.11946048, 0.01354216])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.927503907701963
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.11523101,  2.57832592]), 'currentState': array([4.88541714, 3.02129452]), 'targetState': array([0.0001376 , 0.03407844]), 'effectorPosition': array([0.11946048, 0.01354216])}
episode index:628
target Thresh 1.4873763532400255
current state at start:  [-1.6884925  -2.56832542]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.6884925 , -2.56832542]), 'currentState': array([4.83191122, 4.11966373]), 'targetState': array([-0.97830954, -0.77994718]), 'effectorPosition': array([-0.77087525, -0.53712606])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9276032655593527
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.6884925 , -2.56832542]), 'currentState': array([4.71769988, 4.52258446]), 'targetState': array([-0.97830954, -0.77994718]), 'effectorPosition': array([-0.9777184 , -0.81653712])}
episode index:629
target Thresh 1.4884005759694086
current state at start:  [ 3.81400253 -1.82008829]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.81400253, -1.82008829]), 'currentState': array([3.40300165, 4.18941952]), 'targetState': array([-0.876976  ,  0.45349364]), 'effectorPosition': array([-0.70743854,  0.7075457 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9277023079949728
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.81400253, -1.82008829]), 'currentState': array([3.81280695, 4.19607878]), 'targetState': array([-0.876976  ,  0.45349364]), 'effectorPosition': array([-0.93735237,  0.36608902])}
episode index:630
target Thresh 1.4894227523004133
current state at start:  [-1.33089459 -2.53872965]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.33089459, -2.53872965]), 'currentState': array([4.59721122, 3.73773976]), 'targetState': array([-0.66244709, -0.14881496]), 'effectorPosition': array([-0.57756204, -0.10682749])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9278168843689902
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.33089459, -2.53872965]), 'currentState': array([4.59721122, 3.73773976]), 'targetState': array([-0.66244709, -0.14881496]), 'effectorPosition': array([-0.57756204, -0.10682749])}
episode index:631
target Thresh 1.4904428863217465
current state at start:  [-2.36940149  2.18732437]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.36940149,  2.18732437]), 'currentState': array([3.41378382, 2.41096996]), 'targetState': array([-0.34800364, -0.45374897]), 'effectorPosition': array([-0.06643642, -0.71138471])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9278996108177734
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-2.36940149,  2.18732437]), 'currentState': array([2.73183784, 2.55797247]), 'targetState': array([-0.34800364, -0.45374897]), 'effectorPosition': array([-0.37135337, -0.43948859])}
episode index:632
target Thresh 1.4914609821139455
current state at start:  [-0.32559469 -2.7347114 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.32559469, -2.7347114 ]), 'currentState': array([0.05809176, 3.04847391]), 'targetState': array([0.60755314, 0.30242732]), 'effectorPosition': array([-0.00107347,  0.09307891])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9279820758875715
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-0.32559469, -2.7347114 ]), 'currentState': array([5.40653378, 2.26092027]), 'targetState': array([0.60755314, 0.30242732]), 'effectorPosition': array([0.8251762 , 0.21405304])}
episode index:633
target Thresh 1.492477043749395
current state at start:  [ 3.7813654  -2.28479291]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.7813654 , -2.28479291]), 'currentState': array([3.95954961, 3.49839239]), 'targetState': array([-0.02711431,  0.12515907]), 'effectorPosition': array([-0.29794599,  0.19284551])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9280798959571496
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.7813654 , -2.28479291]), 'currentState': array([4.11933268, 3.19837295]), 'targetState': array([-0.02711431,  0.12515907]), 'effectorPosition': array([-0.0479597 ,  0.03038098])}
episode index:634
target Thresh 1.4934910752923427
current state at start:  [-3.35978088  2.44381971]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.35978088,  2.44381971]), 'currentState': array([2.50642866, 2.94381971]), 'targetState': array([-0.20783978,  0.16663716]), 'effectorPosition': array([-0.13226882, -0.14660072])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.9281159749397367
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([-3.35978088,  2.44381971]), 'currentState': array([1.98150587, 3.04004457]), 'targetState': array([-0.20783978,  0.16663716]), 'effectorPosition': array([-0.09500001, -0.03575128])}
episode index:635
target Thresh 1.4945030807989164
current state at start:  [ 2.56271905 -1.98858227]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.56271905, -1.98858227]), 'currentState': array([2.74194357, 3.79460303]), 'targetState': array([-0.01689998,  0.41187403]), 'effectorPosition': array([0.04687776, 0.63975446])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9282290001363724
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.56271905, -1.98858227]), 'currentState': array([2.74194357, 3.79460303]), 'targetState': array([-0.01689998,  0.41187403]), 'effectorPosition': array([0.04687776, 0.63975446])}
episode index:636
target Thresh 1.495513064317139
current state at start:  [-1.99923606  2.51228896]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.99923606,  2.51228896]), 'currentState': array([4.24520047, 2.01584665]), 'targetState': array([ 0.49189453, -0.62719697]), 'effectorPosition': array([ 0.5493771 , -0.91497443])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9283259718787015
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.99923606,  2.51228896]), 'currentState': array([4.1415335 , 2.31070564]), 'targetState': array([ 0.49189453, -0.62719697]), 'effectorPosition': array([ 0.44539232, -0.67318928])}
episode index:637
target Thresh 1.4965210298869467
current state at start:  [1.68947763 2.29511844]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.68947763, 2.29511844]), 'currentState': array([1.40645851, 2.72308268]), 'targetState': array([-0.04728857, -0.02882752]), 'effectorPosition': array([-0.38680468,  0.15162831])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9284226396343775
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.68947763, 2.29511844]), 'currentState': array([1.2617418 , 3.11368109]), 'targetState': array([-0.04728857, -0.02882752]), 'effectorPosition': array([-0.02646723,  0.00885947])}
episode index:638
target Thresh 1.4975269815402021
current state at start:  [ 0.19669025 -2.29734152]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.19669025, -2.29734152]), 'currentState': array([0.69669025, 3.48584379]), 'targetState': array([-0.1467097,  0.0188728]), 'effectorPosition': array([ 0.26156202, -0.22119767])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9285190048305679
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.19669025, -2.29734152]), 'currentState': array([1.19669025, 2.98584379]), 'targetState': array([-0.1467097,  0.0188728]), 'effectorPosition': array([-0.1399676 ,  0.06795428])}
episode index:639
target Thresh 1.4985309233007142
current state at start:  [-1.46971889  2.53295763]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.46971889,  2.53295763]), 'currentState': array([5.31346642, 2.03295763]), 'targetState': array([1.32658272, 0.1110461 ]), 'effectorPosition': array([1.05157559, 0.04920746])}
done in step count: 20
reward sum = 0.8179069375972308
running average episode reward sum: 0.9283461734755158
{'reset': False, 'endBeforeDone': False, 'stepCount': 21, 'initial state': array([-1.46971889,  2.53295763]), 'currentState': array([5.76767395, 1.49442882]), 'targetState': array([1.32658272, 0.1110461 ]), 'effectorPosition': array([1.42796201, 0.33691407])}
episode index:640
target Thresh 1.4995328591842505
current state at start:  [ 0.94818444 -1.93320568]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.94818444, -1.93320568]), 'currentState': array([0.48154942, 4.68268805]), 'targetState': array([ 1.16236122, -0.37988004]), 'effectorPosition': array([ 1.32290762, -0.43648859])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9284579579162717
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.94818444, -1.93320568]), 'currentState': array([0.48154942, 4.68268805]), 'targetState': array([ 1.16236122, -0.37988004]), 'effectorPosition': array([ 1.32290762, -0.43648859])}
episode index:641
target Thresh 1.5005327931985564
current state at start:  [0.06845249 2.01741571]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.06845249, 2.01741571]), 'currentState': array([5.88974067, 2.51741571]), 'targetState': array([-0.15006153,  0.38824196]), 'effectorPosition': array([0.39820283, 0.4674887 ])}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.9284346857816416
{'reset': False, 'endBeforeDone': False, 'stepCount': 10, 'initial state': array([0.06845249, 2.01741571]), 'currentState': array([6.234983  , 2.80552047]), 'targetState': array([-0.15006153,  0.38824196]), 'effectorPosition': array([0.07176784, 0.326703  ])}
episode index:642
target Thresh 1.501530729343369
current state at start:  [-0.85808813  2.49489649]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.85808813,  2.49489649]), 'currentState': array([5.1153009 , 2.99489649]), 'targetState': array([ 0.23012113, -0.29653204]), 'effectorPosition': array([0.13867707, 0.04743278])}
done in step count: 14
reward sum = 0.8687458127689782
running average episode reward sum: 0.9283418570522285
{'reset': False, 'endBeforeDone': False, 'stepCount': 15, 'initial state': array([-0.85808813,  2.49489649]), 'currentState': array([4.53091875, 2.83371191]), 'targetState': array([ 0.23012113, -0.29653204]), 'effectorPosition': array([ 0.28957728, -0.1009413 ])}
episode index:643
target Thresh 1.5025266716104346
current state at start:  [ 2.38113249 -1.63835918]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.38113249, -1.63835918]), 'currentState': array([2.74900291, 4.64687562]), 'targetState': array([-0.27320154,  1.29178886]), 'effectorPosition': array([-0.48167378,  1.27947542])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9284531274605324
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.38113249, -1.63835918]), 'currentState': array([2.74900291, 4.64687562]), 'targetState': array([-0.27320154,  1.29178886]), 'effectorPosition': array([-0.48167378,  1.27947542])}
episode index:644
target Thresh 1.5035206239835233
current state at start:  [-0.13310471  2.636134  ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.13310471,  2.636134  ]), 'currentState': array([5.65944941, 2.99393511]), 'targetState': array([0.06915819, 0.23640922]), 'effectorPosition': array([0.09476215, 0.11306326])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9285640528443145
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.13310471,  2.636134  ]), 'currentState': array([5.65944941, 2.99393511]), 'targetState': array([0.06915819, 0.23640922]), 'effectorPosition': array([0.09476215, 0.11306326])}
episode index:645
target Thresh 1.5045125904384458
current state at start:  [1.15094457 2.77774746]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.15094457, 2.77774746]), 'currentState': array([0.67447229, 3.24833355]), 'targetState': array([0.23154588, 0.10218399]), 'effectorPosition': array([ 0.0709768 , -0.07965613])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9286746348058559
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.15094457, 2.77774746]), 'currentState': array([0.67447229, 3.24833355]), 'targetState': array([0.23154588, 0.10218399]), 'effectorPosition': array([ 0.0709768 , -0.07965613])}
episode index:646
target Thresh 1.5055025749430695
current state at start:  [ 3.74138277 -2.01353685]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.74138277, -2.01353685]), 'currentState': array([4.20878588, 3.82902481]), 'targetState': array([-0.23356095, -0.07201696]), 'effectorPosition': array([-0.66537988,  0.10730151])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9287694189869906
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.74138277, -2.01353685]), 'currentState': array([4.48587086, 3.47543355]), 'targetState': array([-0.23356095, -0.07201696]), 'effectorPosition': array([-0.33170282,  0.01979216])}
episode index:647
target Thresh 1.5064905814573337
current state at start:  [-4.34775265  2.74092651]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.34775265,  2.74092651]), 'currentState': array([2.34984796, 3.19956339]), 'targetState': array([ 0.12506597, -0.63026747]), 'effectorPosition': array([0.04004747, 0.04190305])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9288335078465785
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-4.34775265,  2.74092651]), 'currentState': array([3.33010774, 2.58151188]), 'targetState': array([ 0.12506597, -0.63026747]), 'effectorPosition': array([-0.05052357, -0.55047521])}
episode index:648
target Thresh 1.5074766139332656
current state at start:  [0.9438174  2.41331323]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.9438174 , 2.41331323]), 'currentState': array([0.4438174 , 2.90212461]), 'targetState': array([-0.07275796, -0.04581291]), 'effectorPosition': array([-0.07607413,  0.22646006])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9289277551380322
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.9438174 , 2.41331323]), 'currentState': array([6.22700271, 3.38266482]), 'targetState': array([-0.07275796, -0.04581291]), 'effectorPosition': array([ 0.01546561, -0.23999104])}
episode index:649
target Thresh 1.5084606763149964
current state at start:  [-3.96753941  2.68424236]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.96753941,  2.68424236]), 'currentState': array([2.5204667 , 2.24997037]), 'targetState': array([-0.97762903, -0.14614726]), 'effectorPosition': array([-0.75520822, -0.4163645 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9290217124378198
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.96753941,  2.68424236]), 'currentState': array([2.13380931, 1.95880779]), 'targetState': array([-0.97762903, -0.14614726]), 'effectorPosition': array([-1.11458603,  0.03163983])}
episode index:650
target Thresh 1.5094427725387773
current state at start:  [-2.36815169  2.27660666]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.36815169,  2.27660666]), 'currentState': array([3.50945944, 2.04660074]), 'targetState': array([-0.04122519, -0.8975551 ]), 'effectorPosition': array([-0.18600813, -1.02435036])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9291307420654115
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.36815169,  2.27660666]), 'currentState': array([3.50945944, 2.04660074]), 'targetState': array([-0.04122519, -0.8975551 ]), 'effectorPosition': array([-0.18600813, -1.02435036])}
episode index:651
target Thresh 1.5104229065329942
current state at start:  [-1.38556438  2.83306032]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.38556438,  2.83306032]), 'currentState': array([4.58201117, 3.17681029]), 'targetState': array([ 0.00466263, -0.17782777]), 'effectorPosition': array([-0.03499214,  0.00396284])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9292394372462928
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.38556438,  2.83306032]), 'currentState': array([4.58201117, 3.17681029]), 'targetState': array([ 0.00466263, -0.17782777]), 'effectorPosition': array([-0.03499214,  0.00396284])}
episode index:652
target Thresh 1.5114010822181845
current state at start:  [ 3.46051196 -2.52393187]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.46051196, -2.52393187]), 'currentState': array([3.96051196, 3.31917622]), 'targetState': array([-0.5551576 ,  0.02953663]), 'effectorPosition': array([-0.13976923,  0.10916821])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9293324855812908
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.46051196, -2.52393187]), 'currentState': array([4.43259952, 3.58297988]), 'targetState': array([-0.5551576 ,  0.02953663]), 'effectorPosition': array([-0.43704867,  0.02585787])}
episode index:653
target Thresh 1.5123773035070522
current state at start:  [ 0.75418627 -1.94628898]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.75418627, -1.94628898]), 'currentState': array([0.71916523, 4.05474593]), 'targetState': array([ 0.81474612, -0.58914545]), 'effectorPosition': array([ 0.81383928, -0.33935125])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9294405398846833
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.75418627, -1.94628898]), 'currentState': array([0.71916523, 4.05474593]), 'targetState': array([ 0.81474612, -0.58914545]), 'effectorPosition': array([ 0.81383928, -0.33935125])}
episode index:654
target Thresh 1.5133515743044836
current state at start:  [-0.23921509 -2.4720663 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.23921509, -2.4720663 ]), 'currentState': array([0.26078491, 3.33043726]), 'targetState': array([-0.02920199,  0.06959581]), 'effectorPosition': array([ 0.06557971, -0.1767929 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.929532997075699
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.23921509, -2.4720663 ]), 'currentState': array([0.76078491, 2.91926591]), 'targetState': array([-0.02920199,  0.06959581]), 'effectorPosition': array([-0.13420533,  0.17667722])}
episode index:655
target Thresh 1.5143238985075638
current state at start:  [1.93768659 1.75539407]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.93768659, 1.75539407]), 'currentState': array([1.67379061, 2.11745191]), 'targetState': array([-0.68206626,  1.08627855]), 'effectorPosition': array([-0.89910794,  0.38979315])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9296100809216202
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([1.93768659, 1.75539407]), 'currentState': array([1.40699244, 1.76575366]), 'targetState': array([-0.68206626,  1.08627855]), 'effectorPosition': array([-0.83644242,  0.95546571])}
episode index:656
target Thresh 1.5152942800055902
current state at start:  [-3.319877    2.21966323]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.319877  ,  2.21966323]), 'currentState': array([3.46330831, 2.62367716]), 'targetState': array([-0.15112066, -0.92726505]), 'effectorPosition': array([ 0.03212014, -0.51113815])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9296869301135203
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-3.319877  ,  2.21966323]), 'currentState': array([3.71283842, 1.96988815]), 'targetState': array([-0.15112066, -0.92726505]), 'effectorPosition': array([-0.01615156, -1.10570147])}
episode index:657
target Thresh 1.5162627226800902
current state at start:  [-3.88149429  2.36912403]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.88149429,  2.36912403]), 'currentState': array([2.40385808, 2.85156894]), 'targetState': array([-0.00138645, -0.00080113]), 'effectorPosition': array([-0.22325485, -0.18352952])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9297785913139558
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.88149429,  2.36912403]), 'currentState': array([2.42977512, 3.29224601]), 'targetState': array([-0.00138645, -0.00080113]), 'effectorPosition': array([0.08946025, 0.12103885])}
episode index:658
target Thresh 1.517229230404836
current state at start:  [-1.87994584  2.49188338]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.87994584,  2.49188338]), 'currentState': array([4.5340082 , 2.60835577]), 'targetState': array([ 0.45807178, -0.14174011]), 'effectorPosition': array([ 0.47562341, -0.22682586])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9298851488385173
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.87994584,  2.49188338]), 'currentState': array([4.5340082 , 2.60835577]), 'targetState': array([ 0.45807178, -0.14174011]), 'effectorPosition': array([ 0.47562341, -0.22682586])}
episode index:659
target Thresh 1.5181938070458598
current state at start:  [-2.88813947  2.88257024]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.88813947,  2.88257024]), 'currentState': array([3.83803351, 3.05908359]), 'targetState': array([ 0.51809398, -0.207745  ]), 'effectorPosition': array([ 0.05025909, -0.06540572])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9299762319463377
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.88813947,  2.88257024]), 'currentState': array([4.33803351, 2.57616065]), 'targetState': array([ 0.51809398, -0.207745  ]), 'effectorPosition': array([ 0.44176003, -0.34078386])}
episode index:660
target Thresh 1.5191564564614695
current state at start:  [-0.0180553   2.35607102]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.0180553 ,  2.35607102]), 'currentState': array([5.87439003, 2.83340501]), 'targetState': array([-0.39870827, -0.02139773]), 'effectorPosition': array([0.16380865, 0.25960925])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9300520621551934
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-0.0180553 ,  2.35607102]), 'currentState': array([5.11116981, 3.57120055]), 'targetState': array([-0.39870827, -0.02139773]), 'effectorPosition': array([-0.34854788, -0.24547118])}
episode index:661
target Thresh 1.5201171825022637
current state at start:  [-3.33049424  2.00573859]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.33049424,  2.00573859]), 'currentState': array([2.88718025, 1.91553331]), 'targetState': array([-0.83723649, -0.71149623]), 'effectorPosition': array([-0.87760954, -0.74424674])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9301577236927234
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.33049424,  2.00573859]), 'currentState': array([2.88718025, 1.91553331]), 'targetState': array([-0.83723649, -0.71149623]), 'effectorPosition': array([-0.87760954, -0.74424674])}
episode index:662
target Thresh 1.521075989011148
current state at start:  [ 4.39397476 -2.56510964]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.39397476, -2.56510964]), 'currentState': array([4.89397476, 3.22400907]), 'targetState': array([ 0.1643092 , -0.25853429]), 'effectorPosition': array([-0.08035666, -0.0182052 ])}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9301465426531084
{'reset': False, 'endBeforeDone': False, 'stepCount': 9, 'initial state': array([ 4.39397476, -2.56510964]), 'currentState': array([4.35842038, 2.93896459]), 'targetState': array([ 0.1643092 , -0.25853429]), 'effectorPosition': array([ 0.18167654, -0.08894649])}
episode index:663
target Thresh 1.52203287982335
current state at start:  [-3.66937327  2.26799253]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.66937327,  2.26799253]), 'currentState': array([2.38974876, 2.67007729]), 'targetState': array([-0.09524757, -0.07788636]), 'effectorPosition': array([-0.38994162, -0.25726169])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9302366834021247
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.66937327,  2.26799253]), 'currentState': array([2.31739741, 3.07155281]), 'targetState': array([-0.09524757, -0.07788636]), 'effectorPosition': array([-0.05303245, -0.04572891])}
episode index:664
target Thresh 1.522987858766434
current state at start:  [-0.97979909  2.1027059 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.97979909,  2.1027059 ]), 'currentState': array([4.83740348, 2.19407816]), 'targetState': array([ 7.41841316e-01, -4.48533737e-04]), 'effectorPosition': array([ 0.85753821, -0.31180464])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9303265530511441
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.97979909,  2.1027059 ]), 'currentState': array([5.14523775, 2.20342948]), 'targetState': array([ 7.41841316e-01, -4.48533737e-04]), 'effectorPosition': array([ 0.90354112, -0.03275217])}
episode index:665
target Thresh 1.5239409296603168
current state at start:  [-2.47892424  2.49447158]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.47892424,  2.49447158]), 'currentState': array([3.44698069, 2.99447158]), 'targetState': array([-0.10018676,  0.14083337]), 'effectorPosition': array([ 0.03377155, -0.14305621])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9304161528213376
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.47892424,  2.49447158]), 'currentState': array([3.24258158, 3.47464538]), 'targetState': array([-0.10018676,  0.14083337]), 'effectorPosition': array([-0.08763147,  0.31972375])}
episode index:666
target Thresh 1.5248920963172838
current state at start:  [-1.30046702  2.48435084]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.30046702,  2.48435084]), 'currentState': array([4.84557465, 2.21242283]), 'targetState': array([ 0.91399645, -0.36612932]), 'effectorPosition': array([ 0.84734471, -0.29156202])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9305204764303011
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.30046702,  2.48435084]), 'currentState': array([4.84557465, 2.21242283]), 'targetState': array([ 0.91399645, -0.36612932]), 'effectorPosition': array([ 0.84734471, -0.29156202])}
episode index:667
target Thresh 1.5258413625420024
current state at start:  [ 3.21763617 -1.95273133]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.21763617, -1.95273133]), 'currentState': array([3.23500577, 4.71923469]), 'targetState': array([-0.82843613,  1.12741817]), 'effectorPosition': array([-1.09573111,  0.90170097])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9306095176332497
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.21763617, -1.95273133]), 'currentState': array([2.81190464, 4.7320436 ]), 'targetState': array([-0.82843613,  1.12741817]), 'effectorPosition': array([-0.64105296,  1.27607124])}
episode index:668
target Thresh 1.526788732131539
current state at start:  [-1.24733129  1.58044442]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.24733129,  1.58044442]), 'currentState': array([4.64913288, 1.84642118]), 'targetState': array([ 1.0360075, -0.8074011]), 'effectorPosition': array([ 0.91432046, -0.78722397])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9307132403273705
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.24733129,  1.58044442]), 'currentState': array([4.64913288, 1.84642118]), 'targetState': array([ 1.0360075, -0.8074011]), 'effectorPosition': array([ 0.91432046, -0.78722397])}
episode index:669
target Thresh 1.5277342088753731
current state at start:  [-1.43939037 -2.16850554]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.43939037, -2.16850554]), 'currentState': array([5.27030158, 3.62586607]), 'targetState': array([-0.15374788, -0.13360274]), 'effectorPosition': array([-0.33409229, -0.34402824])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9308017280283745
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.43939037, -2.16850554]), 'currentState': array([5.36240877, 3.22670324]), 'targetState': array([-0.15374788, -0.13360274]), 'effectorPosition': array([-0.06548171, -0.0543285 ])}
episode index:670
target Thresh 1.5286777965554132
current state at start:  [0.41190131 2.25661519]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.41190131, 2.25661519]), 'currentState': array([6.19508662, 2.74316435]), 'targetState': array([0.19166648, 0.13327881]), 'effectorPosition': array([0.1121598 , 0.37957393])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9308899519806422
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.41190131, 2.25661519]), 'currentState': array([5.7504816 , 3.15418571]), 'targetState': array([0.19166648, 0.13327881]), 'effectorPosition': array([-0.00632709, -0.01088811])}
episode index:671
target Thresh 1.529619498946011
current state at start:  [-1.36748388 -2.12902258]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.36748388, -2.12902258]), 'currentState': array([5.27546615, 3.66272019]), 'targetState': array([-0.02126237, -0.1060861 ]), 'effectorPosition': array([-0.35014098, -0.37800072])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9309779133616234
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.36748388, -2.12902258]), 'currentState': array([5.51683745, 3.17708071]), 'targetState': array([-0.02126237, -0.1060861 ]), 'effectorPosition': array([-0.02415249, -0.0259986 ])}
episode index:672
target Thresh 1.5305593198139773
current state at start:  [ 2.58087048 -2.34371331]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.58087048, -2.34371331]), 'currentState': array([2.64020025, 3.439472  ]), 'targetState': array([0.09392448, 0.295751  ]), 'effectorPosition': array([0.10244844, 0.27853589])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9310804721827799
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.58087048, -2.34371331]), 'currentState': array([2.64020025, 3.439472  ]), 'targetState': array([0.09392448, 0.295751  ]), 'effectorPosition': array([0.10244844, 0.27853589])}
episode index:673
target Thresh 1.5314972629185972
current state at start:  [ 0.79052982 -2.46617512]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.79052982, -2.46617512]), 'currentState': array([1.24929321, 3.31701019]), 'targetState': array([ 0.0401548 , -0.51815085]), 'effectorPosition': array([ 0.17042648, -0.04058695])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9311242637819153
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([ 0.79052982, -2.46617512]), 'currentState': array([3.12683097, 2.85016922]), 'targetState': array([ 0.0401548 , -0.51815085]), 'effectorPosition': array([-0.04640065, -0.28666224])}
episode index:674
target Thresh 1.5324333320116441
current state at start:  [ 0.6326026  -2.51606217]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.6326026 , -2.51606217]), 'currentState': array([0.17141038, 4.16661212]), 'targetState': array([ 0.83827288, -0.84600636]), 'effectorPosition': array([ 0.61966222, -0.76016725])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9312263019096457
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.6326026 , -2.51606217]), 'currentState': array([0.17141038, 4.16661212]), 'targetState': array([ 0.83827288, -0.84600636]), 'effectorPosition': array([ 0.61966222, -0.76016725])}
episode index:675
target Thresh 1.5333675308373953
current state at start:  [-2.10448225  1.8912869 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.10448225,  1.8912869 ]), 'currentState': array([3.67870306, 2.1939533 ]), 'targetState': array([ 0.16815778, -0.731801  ]), 'effectorPosition': array([ 0.05771911, -0.9107498 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9313280381494244
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.10448225,  1.8912869 ]), 'currentState': array([3.67870306, 2.1939533 ]), 'targetState': array([ 0.16815778, -0.731801  ]), 'effectorPosition': array([ 0.05771911, -0.9107498 ])}
episode index:676
target Thresh 1.5342998631326479
current state at start:  [ 2.19655205 -1.97842354]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.19655205, -1.97842354]), 'currentState': array([1.69655205, 3.93173379]), 'targetState': array([1.15486589, 0.29760797]), 'effectorPosition': array([0.66768464, 0.38302365])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9314147027902672
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 2.19655205, -1.97842354]), 'currentState': array([1.19655205, 4.36001471]), 'targetState': array([1.15486589, 0.29760797]), 'effectorPosition': array([1.11299434, 0.2664381 ])}
episode index:677
target Thresh 1.535230332626732
current state at start:  [ 2.02110216 -2.45812216]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.02110216, -2.45812216]), 'currentState': array([2.36390829, 3.32506315]), 'targetState': array([-0.0960162 , -0.15294555]), 'effectorPosition': array([0.11604871, 0.14177377])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9315011117832019
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 2.02110216, -2.45812216]), 'currentState': array([2.39365867, 2.82506315]), 'targetState': array([-0.0960162 , -0.15294555]), 'effectorPosition': array([-0.24812211, -0.19440324])}
episode index:678
target Thresh 1.536158943041527
current state at start:  [ 0.74222188 -2.37421338]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.74222188, -2.37421338]), 'currentState': array([1.03096773, 3.49821698]), 'targetState': array([ 0.45578162, -0.26064467]), 'effectorPosition': array([ 0.33180782, -0.12546819])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9316019937982488
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.74222188, -2.37421338]), 'currentState': array([1.03096773, 3.49821698]), 'targetState': array([ 0.45578162, -0.26064467]), 'effectorPosition': array([ 0.33180782, -0.12546819])}
episode index:679
target Thresh 1.5370856980914755
current state at start:  [-0.48206463 -2.67159909]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.48206463, -2.67159909]), 'currentState': array([5.30112068, 4.00717816]), 'targetState': array([-0.27335804, -1.09252961]), 'effectorPosition': array([-0.43791728, -0.71542973])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9316878732191337
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.48206463, -2.67159909]), 'currentState': array([5.40858172, 4.45672125]), 'targetState': array([-0.27335804, -1.09252961]), 'effectorPosition': array([-0.26322685, -1.19370375])}
episode index:680
target Thresh 1.5380106014835995
current state at start:  [-2.17144448  2.22748669]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.17144448,  2.22748669]), 'currentState': array([4.0950506 , 2.72748669]), 'targetState': array([ 0.43796711, -0.0078785 ]), 'effectorPosition': array([ 0.2791748 , -0.30184199])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.9316884275138296
{'reset': False, 'endBeforeDone': False, 'stepCount': 8, 'initial state': array([-2.17144448,  2.22748669]), 'currentState': array([4.29812813, 2.78451073]), 'targetState': array([ 0.43796711, -0.0078785 ]), 'effectorPosition': array([ 0.29458519, -0.19843882])}
episode index:681
target Thresh 1.5389336569175132
current state at start:  [-0.45005589 -1.88054685]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.45005589, -1.88054685]), 'currentState': array([6.1870047 , 4.42794216]), 'targetState': array([ 0.76487147, -1.04678839]), 'effectorPosition': array([ 0.62387515, -1.02446411])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9317885911098504
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.45005589, -1.88054685]), 'currentState': array([6.1870047 , 4.42794216]), 'targetState': array([ 0.76487147, -1.04678839]), 'effectorPosition': array([ 0.62387515, -1.02446411])}
episode index:682
target Thresh 1.53985486808544
current state at start:  [-1.42830326 -2.22914098]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.42830326, -2.22914098]), 'currentState': array([4.35745357, 3.95316529]), 'targetState': array([-1.29514614,  0.1824012 ]), 'effectorPosition': array([-0.78846218, -0.04012861])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9318738201126179
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.42830326, -2.22914098]), 'currentState': array([3.91883426, 4.33248367]), 'targetState': array([-1.29514614,  0.1824012 ]), 'effectorPosition': array([-1.09981428,  0.22077925])}
episode index:683
target Thresh 1.5407742386722254
current state at start:  [ 2.24406395 -2.00572637]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.24406395, -2.00572637]), 'currentState': array([1.89933357, 4.51123971]), 'targetState': array([0.42027347, 1.09459954]), 'effectorPosition': array([0.66923827, 1.07355905])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9319734197908157
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.24406395, -2.00572637]), 'currentState': array([1.89933357, 4.51123971]), 'targetState': array([0.42027347, 1.09459954]), 'effectorPosition': array([0.66923827, 1.07355905])}
episode index:684
target Thresh 1.5416917723553532
current state at start:  [ 3.30852762 -2.65743656]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.30852762, -2.65743656]), 'currentState': array([3.80852762, 3.12574875]), 'targetState': array([-0.11083446, -0.05263549]), 'effectorPosition': array([ 0.00970171, -0.01252601])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9320727286670335
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.30852762, -2.65743656]), 'currentState': array([3.80852762, 3.12574875]), 'targetState': array([-0.11083446, -0.05263549]), 'effectorPosition': array([ 0.00970171, -0.01252601])}
episode index:685
target Thresh 1.5426074728049595
current state at start:  [-0.90268419 -2.37153144]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.90268419, -2.37153144]), 'currentState': array([5.88050111, 3.93980446]), 'targetState': array([ 0.33771598, -1.10814765]), 'effectorPosition': array([-0.002781  , -0.77718436])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9321571707535248
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.90268419, -2.37153144]), 'currentState': array([5.86895958, 4.21626904]), 'targetState': array([ 0.33771598, -1.10814765]), 'effectorPosition': array([ 0.12571239, -1.01595407])}
episode index:686
target Thresh 1.543521343683847
current state at start:  [-2.22625482  2.32504363]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.22625482,  2.32504363]), 'currentState': array([3.60193951, 2.28926197]), 'targetState': array([-0.09030051, -0.74113952]), 'effectorPosition': array([ 0.02825455, -0.82628141])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9322559230522823
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.22625482,  2.32504363]), 'currentState': array([3.60193951, 2.28926197]), 'targetState': array([-0.09030051, -0.74113952]), 'effectorPosition': array([ 0.02825455, -0.82628141])}
episode index:687
target Thresh 1.5444333886475008
current state at start:  [ 0.46318397 -2.48626297]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.46318397, -2.48626297]), 'currentState': array([0.24481638, 4.120322  ]), 'targetState': array([ 1.07622322, -0.5950255 ]), 'effectorPosition': array([ 0.62986804, -0.69793374])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9323398533966831
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.46318397, -2.48626297]), 'currentState': array([0.63313587, 4.19978341]), 'targetState': array([ 1.07622322, -0.5950255 ]), 'effectorPosition': array([ 0.92641473, -0.40106929])}
episode index:688
target Thresh 1.5453436113441015
current state at start:  [-1.98966034  1.92038387]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.98966034,  1.92038387]), 'currentState': array([4.06014396, 2.39613685]), 'targetState': array([ 0.33566866, -0.36585294]), 'effectorPosition': array([ 0.37808424, -0.62249072])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9324235401116372
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.98966034,  1.92038387]), 'currentState': array([3.88034257, 2.80795521]), 'targetState': array([ 0.33566866, -0.36585294]), 'effectorPosition': array([ 0.17974718, -0.27924211])}
episode index:689
target Thresh 1.5462520154145416
current state at start:  [-3.60965065  2.42599721]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.60965065,  2.42599721]), 'currentState': array([3.002826  , 2.92489369]), 'targetState': array([ 0.24507066, -1.05402915]), 'effectorPosition': array([-0.0529028 , -0.20970518])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9324784320824898
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-3.60965065,  2.42599721]), 'currentState': array([4.06148996, 2.01942349]), 'targetState': array([ 0.24507066, -1.05402915]), 'effectorPosition': array([ 0.37371085, -0.99643479])}
episode index:690
target Thresh 1.5471586044924384
current state at start:  [0.3697122  2.60996179]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.3697122 , 2.60996179]), 'currentState': array([6.1528975 , 3.02214484]), 'targetState': array([-0.07194948,  0.02793921]), 'effectorPosition': array([0.02254675, 0.11722827])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.932576147810301
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.3697122 , 2.60996179]), 'currentState': array([6.1528975 , 3.02214484]), 'targetState': array([-0.07194948,  0.02793921]), 'effectorPosition': array([0.02254675, 0.11722827])}
episode index:691
target Thresh 1.5480633822041492
current state at start:  [-0.90367856  2.42625024]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.90367856,  2.42625024]), 'currentState': array([4.87950675, 2.85763677]), 'targetState': array([-0.0049041 ,  0.08643874]), 'effectorPosition': array([0.28291344, 0.00711389])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9326591302556618
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.90367856,  2.42625024]), 'currentState': array([4.37950675, 3.15586873]), 'targetState': array([-0.0049041 ,  0.08643874]), 'effectorPosition': array([-0.01352522,  0.0045685 ])}
episode index:692
target Thresh 1.5489663521687862
current state at start:  [-2.45222334  2.70258679]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.45222334,  2.70258679]), 'currentState': array([3.65530325, 3.10757297]), 'targetState': array([ 0.35251159, -0.07032925]), 'effectorPosition': array([ 0.01621054, -0.02990729])}
done in step count: 21
reward sum = 0.8097278682212584
running average episode reward sum: 0.9324817402671561
{'reset': False, 'endBeforeDone': False, 'stepCount': 22, 'initial state': array([-2.45222334,  2.70258679]), 'currentState': array([4.24195172, 2.75389136]), 'targetState': array([ 0.35251159, -0.07032925]), 'effectorPosition': array([ 0.30335068, -0.23752315])}
episode index:693
target Thresh 1.5498675179982304
current state at start:  [0.83020139 1.5750632 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.83020139, 1.5750632 ]), 'currentState': array([0.53101975, 2.0750632 ]), 'targetState': array([-0.07518882,  0.66941478]), 'effectorPosition': array([0.00228246, 1.01669238])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.932564619603947
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.83020139, 1.5750632 ]), 'currentState': array([0.32054093, 2.57181296]), 'targetState': array([-0.07518882,  0.66941478]), 'effectorPosition': array([-0.02003535,  0.5617463 ])}
episode index:694
target Thresh 1.5507668832971468
current state at start:  [-1.10299248 -2.24629232]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.10299248, -2.24629232]), 'currentState': array([4.9771321 , 4.48748356]), 'targetState': array([-0.84115369, -1.06718345]), 'effectorPosition': array([-0.73754524, -1.00498691])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9326616489282579
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.10299248, -2.24629232]), 'currentState': array([4.9771321 , 4.48748356]), 'targetState': array([-0.84115369, -1.06718345]), 'effectorPosition': array([-0.73754524, -1.00498691])}
episode index:695
target Thresh 1.5516644516629972
current state at start:  [-1.62144742  1.87185792]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.62144742,  1.87185792]), 'currentState': array([4.38398465, 1.91403192]), 'targetState': array([ 0.77030829, -0.98809811]), 'effectorPosition': array([ 0.67735697, -0.93172749])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9327583994326712
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.62144742,  1.87185792]), 'currentState': array([4.38398465, 1.91403192]), 'targetState': array([ 0.77030829, -0.98809811]), 'effectorPosition': array([ 0.67735697, -0.93172749])}
episode index:696
target Thresh 1.5525602266860565
current state at start:  [ 2.3167465  -1.70374077]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.3167465 , -1.70374077]), 'currentState': array([1.93947723, 4.51822112]), 'targetState': array([0.49890539, 1.01020813]), 'effectorPosition': array([0.62442592, 1.10643213])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9328548723172728
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.3167465 , -1.70374077]), 'currentState': array([1.93947723, 4.51822112]), 'targetState': array([0.49890539, 1.01020813]), 'effectorPosition': array([0.62442592, 1.10643213])}
episode index:697
target Thresh 1.553454211949426
current state at start:  [-1.78778842  2.28169749]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.78778842,  2.28169749]), 'currentState': array([4.17589694, 2.06412233]), 'targetState': array([ 0.51848348, -0.88409679]), 'effectorPosition': array([ 0.48794447, -0.9026596 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.932951068775271
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.78778842,  2.28169749]), 'currentState': array([4.17589694, 2.06412233]), 'targetState': array([ 0.51848348, -0.88409679]), 'effectorPosition': array([ 0.48794447, -0.9026596 ])}
episode index:698
target Thresh 1.554346411029048
current state at start:  [-0.90504396 -2.18913277]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.90504396, -2.18913277]), 'currentState': array([5.18076685, 3.80001228]), 'targetState': array([-0.91474371, -0.18795753]), 'effectorPosition': array([-0.45160172, -0.46274775])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9330185207512721
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-0.90504396, -2.18913277]), 'currentState': array([4.63012519, 3.90062954]), 'targetState': array([-0.91474371, -0.18795753]), 'effectorPosition': array([-0.70845164, -0.21702052])}
episode index:699
target Thresh 1.5552368274937196
current state at start:  [-0.71868046 -2.14734211]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.71868046, -2.14734211]), 'currentState': array([5.43623444, 3.74356292]), 'targetState': array([-0.59203658, -0.35991046]), 'effectorPosition': array([-0.3078712 , -0.50672703])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9330857800073417
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-0.71868046, -2.14734211]), 'currentState': array([5.0874277 , 3.79090641]), 'targetState': array([-0.59203658, -0.35991046]), 'effectorPosition': array([-0.48806932, -0.41084122])}
episode index:700
target Thresh 1.5561254649051084
current state at start:  [ 1.17878803 -1.82676796]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.17878803, -1.82676796]), 'currentState': array([0.96964427, 4.04953971]), 'targetState': array([ 0.72277794, -0.33282299]), 'effectorPosition': array([ 0.86759778, -0.12862182])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9331528473682442
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 1.17878803, -1.82676796]), 'currentState': array([0.89960248, 4.02005498]), 'targetState': array([ 0.72277794, -0.33282299]), 'effectorPosition': array([ 0.82770892, -0.19551693])}
episode index:701
target Thresh 1.5570123268177647
current state at start:  [-0.03511973  2.76745923]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.03511973,  2.76745923]), 'currentState': array([5.76901783, 3.2000991 ]), 'targetState': array([-0.01001841,  0.01073332]), 'effectorPosition': array([-0.02726787, -0.05175414])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.933248071232392
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.03511973,  2.76745923]), 'currentState': array([5.76901783, 3.2000991 ]), 'targetState': array([-0.01001841,  0.01073332]), 'effectorPosition': array([-0.02726787, -0.05175414])}
episode index:702
target Thresh 1.557897416779138
current state at start:  [-1.69420478  2.34349799]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.69420478,  2.34349799]), 'currentState': array([4.13543162, 1.89994996]), 'targetState': array([ 0.52853471, -1.06057939]), 'effectorPosition': array([ 0.4239771 , -1.08340158])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9333430241893872
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.69420478,  2.34349799]), 'currentState': array([4.13543162, 1.89994996]), 'targetState': array([ 0.52853471, -1.06057939]), 'effectorPosition': array([ 0.4239771 , -1.08340158])}
episode index:703
target Thresh 1.5587807383295886
current state at start:  [ 1.64529756 -2.36581243]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.64529756, -2.36581243]), 'currentState': array([1.79489098, 3.83016724]), 'targetState': array([0.51977048, 0.41746833]), 'effectorPosition': array([0.56891542, 0.36335951])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9334377073936636
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.64529756, -2.36581243]), 'currentState': array([1.79489098, 3.83016724]), 'targetState': array([0.51977048, 0.41746833]), 'effectorPosition': array([0.56891542, 0.36335951])}
episode index:704
target Thresh 1.5596622950024046
current state at start:  [-2.98189927  2.42974289]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.98189927,  2.42974289]), 'currentState': array([2.9260632 , 2.90849869]), 'targetState': array([-0.0021561 ,  0.02227718]), 'effectorPosition': array([-0.07581828, -0.21986092])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9335179375959421
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.98189927,  2.42974289]), 'currentState': array([2.71741972, 3.23093127]), 'targetState': array([-0.0021561 ,  0.02227718]), 'effectorPosition': array([0.03308533, 0.08295446])}
episode index:705
target Thresh 1.5605420903238132
current state at start:  [-0.81721996  2.79665076]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.81721996,  2.79665076]), 'currentState': array([4.96952902, 3.20886307]), 'targetState': array([ 0.00922883, -0.00148601]), 'effectorPosition': array([-0.06443438, -0.01928246])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9336121048231433
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.81721996,  2.79665076]), 'currentState': array([4.96952902, 3.20886307]), 'targetState': array([ 0.00922883, -0.00148601]), 'effectorPosition': array([-0.06443438, -0.01928246])}
episode index:706
target Thresh 1.5614201278129973
current state at start:  [-4.13330181  2.67108163]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.13330181,  2.67108163]), 'currentState': array([1.81527289, 3.12366628]), 'targetState': array([0.11239756, 0.19076012]), 'effectorPosition': array([-0.01743127, -0.00418292])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9337060056649776
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.13330181,  2.67108163]), 'currentState': array([1.81527289, 3.12366628]), 'targetState': array([0.11239756, 0.19076012]), 'effectorPosition': array([-0.01743127, -0.00418292])}
episode index:707
target Thresh 1.5622964109821078
current state at start:  [ 1.76722074 -2.84236486]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.76722074, -2.84236486]), 'currentState': array([2.26722074, 2.94391982]), 'targetState': array([-0.41204629,  0.43266854]), 'effectorPosition': array([-0.16314924, -0.11103965])}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9336905235869593
{'reset': False, 'endBeforeDone': False, 'stepCount': 9, 'initial state': array([ 1.76722074, -2.84236486]), 'currentState': array([3.53854186, 3.68416618]), 'targetState': array([-0.41204629,  0.43266854]), 'effectorPosition': array([-0.33207136,  0.42066996])}
episode index:708
target Thresh 1.5631709433362786
current state at start:  [ 4.06271498 -2.32796539]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.06271498, -2.32796539]), 'currentState': array([4.17375949, 3.50954001]), 'targetState': array([-0.33539652,  0.03667229]), 'effectorPosition': array([-0.3431054 ,  0.12705663])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9337840489415615
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.06271498, -2.32796539]), 'currentState': array([4.17375949, 3.50954001]), 'targetState': array([-0.33539652,  0.03667229]), 'effectorPosition': array([-0.3431054 ,  0.12705663])}
episode index:709
target Thresh 1.5640437283736404
current state at start:  [ 3.22185583 -2.28799774]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.22185583, -2.28799774]), 'currentState': array([3.63205697, 3.49518757]), 'targetState': array([-0.00951238,  0.05510919]), 'effectorPosition': array([-0.21767959,  0.27631085])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9338632263374185
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.22185583, -2.28799774]), 'currentState': array([3.95178966, 2.99518757]), 'targetState': array([-0.00951238,  0.05510919]), 'effectorPosition': array([ 0.09830594, -0.10831497])}
episode index:710
target Thresh 1.5649147695853345
current state at start:  [1.59369598 2.29337277]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.59369598, 2.29337277]), 'currentState': array([1.34650798, 2.70026126]), 'targetState': array([-0.23554338,  0.04426937]), 'effectorPosition': array([-0.39513411,  0.18841842])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9339562457096584
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.59369598, 2.29337277]), 'currentState': array([1.34650798, 2.70026126]), 'targetState': array([-0.23554338,  0.04426937]), 'effectorPosition': array([-0.39513411,  0.18841842])}
episode index:711
target Thresh 1.5657840704555266
current state at start:  [ 3.04591091 -2.2984217 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.04591091, -2.2984217 ]), 'currentState': array([3.24165191, 3.56868883]), 'targetState': array([0.45602185, 0.11750264]), 'effectorPosition': array([-0.13075664,  0.40318461])}
done in step count: 29
reward sum = 0.7471720943315961
running average episode reward sum: 0.9336939084183972
{'reset': False, 'endBeforeDone': False, 'stepCount': 30, 'initial state': array([ 3.04591091, -2.2984217 ]), 'currentState': array([1.87095129, 3.42408249]), 'targetState': array([0.45602185, 0.11750264]), 'effectorPosition': array([0.25456605, 0.12028037])}
episode index:712
target Thresh 1.5666516344614216
current state at start:  [1.31707752 2.25270683]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.31707752, 2.25270683]), 'currentState': array([0.81707752, 2.62407342]), 'targetState': array([-0.05213651,  0.23577755]), 'effectorPosition': array([-0.27111188,  0.43405074])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9337728790938271
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.31707752, 2.25270683]), 'currentState': array([0.32977093, 2.849858  ]), 'targetState': array([-0.05213651,  0.23577755]), 'effectorPosition': array([-0.05316016,  0.2857992 ])}
episode index:713
target Thresh 1.5675174650732768
current state at start:  [ 3.19134858 -2.86280376]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.19134858, -2.86280376]), 'currentState': array([3.52996578, 2.92038155]), 'targetState': array([ 0.32737053, -0.36947705]), 'effectorPosition': array([ 0.06053458, -0.2122986 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9338516285628834
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.19134858, -2.86280376]), 'currentState': array([3.98528623, 2.50239531]), 'targetState': array([ 0.32737053, -0.36947705]), 'effectorPosition': array([ 0.31445553, -0.54402945])}
episode index:714
target Thresh 1.5683815657544156
current state at start:  [-1.4225586  -2.59856466]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.4225586 , -2.59856466]), 'currentState': array([5.28231878, 3.18462064]), 'targetState': array([ 0.1172218 , -0.00971726]), 'effectorPosition': array([-0.03571635, -0.02398884])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9339441437676906
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.4225586 , -2.59856466]), 'currentState': array([5.28231878, 3.18462064]), 'targetState': array([ 0.1172218 , -0.00971726]), 'effectorPosition': array([-0.03571635, -0.02398884])}
episode index:715
target Thresh 1.569243939961242
current state at start:  [ 0.5912421  -2.28099527]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.5912421 , -2.28099527]), 'currentState': array([1.0912421 , 3.50219004]), 'targetState': array([0.58380376, 0.34110374]), 'effectorPosition': array([ 0.34270724, -0.10573229])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.934022434069691
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.5912421 , -2.28099527]), 'currentState': array([1.56170233, 3.76741062]), 'targetState': array([0.58380376, 0.34110374]), 'effectorPosition': array([0.58745963, 0.18418108])}
episode index:716
target Thresh 1.5701045911432536
current state at start:  [-2.76824402  2.07087863]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.76824402,  2.07087863]), 'currentState': array([3.01767154, 2.08584455]), 'targetState': array([-0.60932111, -0.66732698]), 'effectorPosition': array([-0.61110095, -0.80087576])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9341144529900959
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.76824402,  2.07087863]), 'currentState': array([3.01767154, 2.08584455]), 'targetState': array([-0.60932111, -0.66732698]), 'effectorPosition': array([-0.61110095, -0.80087576])}
episode index:717
target Thresh 1.5709635227430567
current state at start:  [ 2.5738628  -2.56222541]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.5738628 , -2.56222541]), 'currentState': array([2.93319924, 3.26281585]), 'targetState': array([-0.18080943,  0.09969689]), 'effectorPosition': array([0.01783852, 0.11982848])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9342062155903883
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.5738628 , -2.56222541]), 'currentState': array([2.93319924, 3.26281585]), 'targetState': array([-0.18080943,  0.09969689]), 'effectorPosition': array([0.01783852, 0.11982848])}
episode index:718
target Thresh 1.571820738196379
current state at start:  [-1.63085114  2.35077891]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.63085114,  2.35077891]), 'currentState': array([4.15233417, 2.85077891]), 'targetState': array([-0.0516526 , -0.49544886]), 'effectorPosition': array([ 0.22062072, -0.18789563])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9342564141778842
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-1.63085114,  2.35077891]), 'currentState': array([3.56006247, 2.64606602]), 'targetState': array([-0.0516526 , -0.49544886]), 'effectorPosition': array([ 0.08332078, -0.48334336])}
episode index:719
target Thresh 1.572676240932083
current state at start:  [-1.57476717  2.03905944]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.57476717,  2.03905944]), 'currentState': array([4.27218551, 2.42474953]), 'targetState': array([ 0.40400523, -1.0277368 ]), 'effectorPosition': array([ 0.48949616, -0.5026195 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9343338358248594
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.57476717,  2.03905944]), 'currentState': array([4.01725001, 2.1415636 ]), 'targetState': array([ 0.40400523, -1.0277368 ]), 'effectorPosition': array([ 0.35178364, -0.89201601])}
episode index:720
target Thresh 1.5735300343721808
current state at start:  [ 1.45706671 -2.68292533]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.45706671, -2.68292533]), 'currentState': array([1.95706671, 3.27264901]), 'targetState': array([-0.06784935, -0.06063826]), 'effectorPosition': array([0.11782224, 0.05717621])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9344249123355045
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.45706671, -2.68292533]), 'currentState': array([1.95706671, 3.27264901]), 'targetState': array([-0.06784935, -0.06063826]), 'effectorPosition': array([0.11782224, 0.05717621])}
episode index:721
target Thresh 1.5743821219318477
current state at start:  [-0.12961305 -1.81853563]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.12961305, -1.81853563]), 'currentState': array([5.79805624, 4.66686665]), 'targetState': array([-0.09244249, -1.08067094]), 'effectorPosition': array([ 0.3785195 , -1.32880012])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.934501886141134
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.12961305, -1.81853563]), 'currentState': array([5.45487344, 4.58719148]), 'targetState': array([-0.09244249, -1.08067094]), 'effectorPosition': array([-0.13933131, -1.31561598])}
episode index:722
target Thresh 1.5752325070194346
current state at start:  [ 0.04110687 -2.80869121]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.04110687, -2.80869121]), 'currentState': array([0.447907  , 3.20344955]), 'targetState': array([0.12178416, 0.04733135]), 'effectorPosition': array([ 0.02849577, -0.05489122])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9345924782764852
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.04110687, -2.80869121]), 'currentState': array([0.447907  , 3.20344955]), 'targetState': array([0.12178416, 0.04733135]), 'effectorPosition': array([ 0.02849577, -0.05489122])}
episode index:723
target Thresh 1.5760811930364835
current state at start:  [ 3.87897398 -3.11890127]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.87897398, -3.11890127]), 'currentState': array([4.0910665 , 3.66428404]), 'targetState': array([-0.63069152,  0.22302349]), 'effectorPosition': array([-0.48363973,  0.18203056])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9346828201573187
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.87897398, -3.11890127]), 'currentState': array([4.0910665 , 3.66428404]), 'targetState': array([-0.63069152,  0.22302349]), 'effectorPosition': array([-0.48363973,  0.18203056])}
episode index:724
target Thresh 1.576928183377739
current state at start:  [0.39433174 1.89167885]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.39433174, 1.89167885]), 'currentState': array([0.08002452, 2.11801991]), 'targetState': array([0.55693241, 0.83756581]), 'effectorPosition': array([0.40988082, 0.88958485])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9347729128191707
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.39433174, 1.89167885]), 'currentState': array([0.08002452, 2.11801991]), 'targetState': array([0.55693241, 0.83756581]), 'effectorPosition': array([0.40988082, 0.88958485])}
episode index:725
target Thresh 1.5777734814311641
current state at start:  [-1.40113751  2.2821626 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.40113751,  2.2821626 ]), 'currentState': array([5.3820478 , 2.06221541]), 'targetState': array([0.92848789, 0.13589397]), 'effectorPosition': array([1.0190696 , 0.13319954])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9348627572918715
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.40113751,  2.2821626 ]), 'currentState': array([5.3820478 , 2.06221541]), 'targetState': array([0.92848789, 0.13589397]), 'effectorPosition': array([1.0190696 , 0.13319954])}
episode index:726
target Thresh 1.5786170905779522
current state at start:  [ 1.42578826 -2.84260163]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.42578826, -2.84260163]), 'currentState': array([1.27107268, 3.94058368]), 'targetState': array([ 0.72604611, -0.09622435]), 'effectorPosition': array([0.77403866, 0.07748455])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9349523545995856
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.42578826, -2.84260163]), 'currentState': array([1.27107268, 3.94058368]), 'targetState': array([ 0.72604611, -0.09622435]), 'effectorPosition': array([0.77403866, 0.07748455])}
episode index:727
target Thresh 1.5794590141925404
current state at start:  [-0.22935562  2.27103442]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.22935562,  2.27103442]), 'currentState': array([5.94290792, 1.91321438]), 'targetState': array([0.87927113, 0.68913528]), 'effectorPosition': array([0.94052145, 0.66624912])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9350417057608499
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.22935562,  2.27103442]), 'currentState': array([5.94290792, 1.91321438]), 'targetState': array([0.87927113, 0.68913528]), 'effectorPosition': array([0.94052145, 0.66624912])}
episode index:728
target Thresh 1.5802992556426247
current state at start:  [-0.06878208  2.40015437]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.06878208,  2.40015437]), 'currentState': array([5.71440323, 2.90015437]), 'targetState': array([0.00401455, 0.01229466]), 'effectorPosition': array([0.15321877, 0.18583281])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9351308117886128
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.06878208,  2.40015437]), 'currentState': array([5.71440323, 2.90015437]), 'targetState': array([0.00401455, 0.01229466]), 'effectorPosition': array([0.15321877, 0.18583281])}
episode index:729
target Thresh 1.581137818289172
current state at start:  [-1.29870917  3.03102183]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.29870917,  3.03102183]), 'currentState': array([4.48447614, 3.53102183]), 'targetState': array([-0.38580887, -0.27660505]), 'effectorPosition': array([-0.38675983,  0.01284447])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9351924134162997
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.29870917,  3.03102183]), 'currentState': array([5.16695558, 3.76429018]), 'targetState': array([-0.38580887, -0.27660505]), 'effectorPosition': array([-0.44159205, -0.42471189])}
episode index:730
target Thresh 1.5819747054864342
current state at start:  [ 0.19689186 -2.66039191]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.19689186, -2.66039191]), 'currentState': array([0.3921425 , 3.30957254]), 'targetState': array([-0.14316983, -0.2380604 ]), 'effectorPosition': array([ 0.07690229, -0.14912073])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9352810694854976
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.19689186, -2.66039191]), 'currentState': array([0.3921425 , 3.30957254]), 'targetState': array([-0.14316983, -0.2380604 ]), 'effectorPosition': array([ 0.07690229, -0.14912073])}
episode index:731
target Thresh 1.5828099205819608
current state at start:  [ 3.99080614 -2.75718951]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.99080614, -2.75718951]), 'currentState': array([3.71386478, 3.84143184]), 'targetState': array([-0.14695834,  0.94767674]), 'effectorPosition': array([-0.54640899,  0.41418071])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9353422975326485
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 3.99080614, -2.75718951]), 'currentState': array([2.911432  , 4.14039741]), 'targetState': array([-0.14695834,  0.94767674]), 'effectorPosition': array([-0.25477586,  0.92329513])}
episode index:732
target Thresh 1.5836434669166133
current state at start:  [-2.26176552  1.98603277]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.26176552,  1.98603277]), 'currentState': array([4.46734643, 2.06212492]), 'targetState': array([ 0.79259396, -0.97640941]), 'effectorPosition': array([ 0.72722698, -0.72632325])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9354168646574335
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.26176552,  1.98603277]), 'currentState': array([4.5153474 , 1.75422503]), 'targetState': array([ 0.79259396, -0.97640941]), 'effectorPosition': array([ 0.80413833, -0.9942625 ])}
episode index:733
target Thresh 1.5844753478245786
current state at start:  [-0.67608756 -2.46523502]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.67608756, -2.46523502]), 'currentState': array([6.06971282, 4.01418105]), 'targetState': array([ 0.29912702, -0.83222191]), 'effectorPosition': array([ 0.18676717, -0.82427303])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9355048525802435
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.67608756, -2.46523502]), 'currentState': array([6.06971282, 4.01418105]), 'targetState': array([ 0.29912702, -0.83222191]), 'effectorPosition': array([ 0.18676717, -0.82427303])}
episode index:734
target Thresh 1.585305566633381
current state at start:  [ 1.61872911 -2.74515459]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.61872911, -2.74515459]), 'currentState': array([2.11872911, 3.03803072]), 'targetState': array([-0.0694524 , -0.36795955]), 'effectorPosition': array([-0.09103385, -0.0492781 ])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9355655262502024
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 1.61872911, -2.74515459]), 'currentState': array([3.11872911, 2.9817417 ]), 'targetState': array([-0.0694524 , -0.36795955]), 'effectorPosition': array([-0.01638455, -0.158838  ])}
episode index:735
target Thresh 1.586134126663897
current state at start:  [-4.39671848  2.6147324 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.39671848,  2.6147324 ]), 'currentState': array([1.63141009, 3.09674929]), 'targetState': array([0.09536716, 0.13894031]), 'effectorPosition': array([-0.04480691, -0.0017121 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9356530730895364
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.39671848,  2.6147324 ]), 'currentState': array([1.63141009, 3.09674929]), 'targetState': array([0.09536716, 0.13894031]), 'effectorPosition': array([-0.04480691, -0.0017121 ])}
episode index:736
target Thresh 1.586961031230368
current state at start:  [-2.60408292  1.60120893]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.60408292,  1.60120893]), 'currentState': array([4.17910239, 2.01096464]), 'targetState': array([ 0.46975062, -0.56806222]), 'effectorPosition': array([ 0.48730132, -0.9541247 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9357268138316129
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.60408292,  1.60120893]), 'currentState': array([4.48435402, 2.32310012]), 'targetState': array([ 0.46975062, -0.56806222]), 'effectorPosition': array([ 0.63962638, -0.47353232])}
episode index:737
target Thresh 1.587786283640413
current state at start:  [-2.07482406  2.4903373 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.07482406,  2.4903373 ]), 'currentState': array([4.67655761, 2.89369207]), 'targetState': array([0.39164029, 0.26006286]), 'effectorPosition': array([ 0.24411663, -0.03934072])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9358003547342801
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.07482406,  2.4903373 ]), 'currentState': array([5.11598123, 2.57944365]), 'targetState': array([0.39164029, 0.26006286]), 'effectorPosition': array([0.55061773, 0.06780003])}
episode index:738
target Thresh 1.5886098871950431
current state at start:  [-1.51271086 -2.06506523]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.51271086, -2.06506523]), 'currentState': array([5.24167673, 3.84322507]), 'targetState': array([-0.17851012, -0.60294571]), 'effectorPosition': array([-0.43787728, -0.52979658])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.935873696608794
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.51271086, -2.06506523]), 'currentState': array([5.53282072, 3.96591325]), 'targetState': array([-0.17851012, -0.60294571]), 'effectorPosition': array([-0.2658262 , -0.75579409])}
episode index:739
target Thresh 1.5894318451886735
current state at start:  [-4.12992726  2.1186267 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.12992726,  2.1186267 ]), 'currentState': array([2.59700166, 1.95371263]), 'targetState': array([-0.99185594, -0.74279076]), 'effectorPosition': array([-1.01631054, -0.4688908 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9359468402620253
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-4.12992726,  2.1186267 ]), 'currentState': array([2.94442191, 1.71874603]), 'targetState': array([-0.99185594, -0.74279076]), 'effectorPosition': array([-1.02982592, -0.8028932 ])}
episode index:740
target Thresh 1.5902521609091371
current state at start:  [-2.17442789  1.98003592]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.17442789,  1.98003592]), 'currentState': array([4.35407805, 2.48003592]), 'targetState': array([ 0.4195619 , -0.29427148]), 'effectorPosition': array([ 0.50134582, -0.4130118 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9360332817731427
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.17442789,  1.98003592]), 'currentState': array([4.35407805, 2.48003592]), 'targetState': array([ 0.4195619 , -0.29427148]), 'effectorPosition': array([ 0.50134582, -0.4130118 ])}
episode index:741
target Thresh 1.591070837637698
current state at start:  [-1.1847443   2.03365889]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.1847443 ,  2.03365889]), 'currentState': array([5.36105072, 2.14870811]), 'targetState': array([0.75409987, 0.1674396 ]), 'effectorPosition': array([0.94158567, 0.14444504])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9361194902882732
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.1847443 ,  2.03365889]), 'currentState': array([5.36105072, 2.14870811]), 'targetState': array([0.75409987, 0.1674396 ]), 'effectorPosition': array([0.94158567, 0.14444504])}
episode index:742
target Thresh 1.5918878786490642
current state at start:  [ 1.99977129 -2.51346623]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.99977129, -2.51346623]), 'currentState': array([2.39194678, 4.14486427]), 'targetState': array([0.31952087, 1.1844346 ]), 'effectorPosition': array([0.23607882, 0.93229496])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9361920077979795
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.99977129, -2.51346623]), 'currentState': array([2.04263618, 4.61592005]), 'targetState': array([0.31952087, 1.1844346 ]), 'effectorPosition': array([0.47584583, 1.25735118])}
episode index:743
target Thresh 1.5927032872114009
current state at start:  [ 0.64672429 -1.85207932]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.64672429, -1.85207932]), 'currentState': array([1.07445983, 3.96006944]), 'targetState': array([0.79964079, 0.22031186]), 'effectorPosition': array([ 0.79280477, -0.06922694])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9362643303681435
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.64672429, -1.85207932]), 'currentState': array([1.42684499, 3.9538927 ]), 'targetState': array([0.79964079, 0.22031186]), 'effectorPosition': array([0.76314551, 0.20481086])}
episode index:744
target Thresh 1.5935170665863434
current state at start:  [-3.64690266  1.98728513]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.64690266,  1.98728513]), 'currentState': array([3.00357427, 2.30594312]), 'targetState': array([-0.22963704, -0.79865425]), 'effectorPosition': array([-0.42822044, -0.68937302])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9363498816025487
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.64690266,  1.98728513]), 'currentState': array([3.00357427, 2.30594312]), 'targetState': array([-0.22963704, -0.79865425]), 'effectorPosition': array([-0.42822044, -0.68937302])}
episode index:745
target Thresh 1.5943292200290102
current state at start:  [ 3.60791798 -2.359563  ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.60791798, -2.359563  ]), 'currentState': array([3.89739912, 3.96708013]), 'targetState': array([-0.85802856,  0.36344313]), 'effectorPosition': array([-0.73821607,  0.31406913])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9364352034770761
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.60791798, -2.359563  ]), 'currentState': array([3.89739912, 3.96708013]), 'targetState': array([-0.85802856,  0.36344313]), 'effectorPosition': array([-0.73821607,  0.31406913])}
episode index:746
target Thresh 1.5951397507880163
current state at start:  [ 3.53375788 -1.851623  ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.53375788, -1.851623  ]), 'currentState': array([3.90100108, 4.26663895]), 'targetState': array([-1.09477937,  0.37283053]), 'effectorPosition': array([-1.03378403,  0.26271865])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9365202969128498
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.53375788, -1.851623  ]), 'currentState': array([3.90100108, 4.26663895]), 'targetState': array([-1.09477937,  0.37283053]), 'effectorPosition': array([-1.03378403,  0.26271865])}
episode index:747
target Thresh 1.595948662105486
current state at start:  [ 1.45111085 -2.98422535]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.45111085, -2.98422535]), 'currentState': array([1.8613838 , 2.79895996]), 'targetState': array([-0.46186655, -0.60984091]), 'effectorPosition': array([-0.33853685, -0.04057023])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.936578558547993
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 1.45111085, -2.98422535]), 'currentState': array([2.53811682, 2.47513044]), 'targetState': array([-0.46186655, -0.60984091]), 'effectorPosition': array([-0.52702798, -0.38757471])}
episode index:748
target Thresh 1.5967559572170649
current state at start:  [-1.33581539  2.93025291]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.33581539,  2.93025291]), 'currentState': array([4.44736992, 3.31294945]), 'targetState': array([-0.31608092, -0.16132059]), 'effectorPosition': array([-0.16840229,  0.03052939])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9366632333696913
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.33581539,  2.93025291]), 'currentState': array([4.44736992, 3.31294945]), 'targetState': array([-0.31608092, -0.16132059]), 'effectorPosition': array([-0.16840229,  0.03052939])}
episode index:749
target Thresh 1.5975616393519352
current state at start:  [-0.48192158  2.33342833]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.48192158,  2.33342833]), 'currentState': array([5.30126373, 2.73491184]), 'targetState': array([-0.16080485, -0.0929141 ]), 'effectorPosition': array([0.37423803, 0.15188235])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9367343490585317
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.48192158,  2.33342833]), 'currentState': array([4.80126373, 3.21354172]), 'targetState': array([-0.16080485, -0.0929141 ]), 'effectorPosition': array([-0.07137365, -0.00895754])}
episode index:750
target Thresh 1.5983657117328263
current state at start:  [-3.25852721  2.2055679 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.25852721,  2.2055679 ]), 'currentState': array([3.35430525, 2.25564368]), 'targetState': array([-0.26995152, -0.94081902]), 'effectorPosition': array([-0.19565403, -0.8346316 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.936818590937282
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.25852721,  2.2055679 ]), 'currentState': array([3.35430525, 2.25564368]), 'targetState': array([-0.26995152, -0.94081902]), 'effectorPosition': array([-0.19565403, -0.8346316 ])}
episode index:751
target Thresh 1.599168177576029
current state at start:  [ 0.43614301 -2.2303541 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.43614301, -2.2303541 ]), 'currentState': array([0.39787864, 4.12146708]), 'targetState': array([ 0.83201606, -0.556657  ]), 'effectorPosition': array([ 0.73003851, -0.59396138])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9369026087684824
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.43614301, -2.2303541 ]), 'currentState': array([0.39787864, 4.12146708]), 'targetState': array([ 0.83201606, -0.556657  ]), 'effectorPosition': array([ 0.73003851, -0.59396138])}
episode index:752
target Thresh 1.5999690400914073
current state at start:  [-0.36847215 -2.40119733]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.36847215, -2.40119733]), 'currentState': array([6.10076907, 3.4457223 ]), 'targetState': array([-0.03726708,  0.06104625]), 'effectorPosition': array([-0.00919382, -0.30281937])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9369731232322693
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.36847215, -2.40119733]), 'currentState': array([6.10554871, 2.97588505]), 'targetState': array([-0.03726708,  0.06104625]), 'effectorPosition': array([0.04262992, 0.15993413])}
episode index:753
target Thresh 1.6007683024824126
current state at start:  [-2.24924249  2.47270388]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.24924249,  2.47270388]), 'currentState': array([4.50013744, 2.97270388]), 'targetState': array([0.77134451, 0.16460215]), 'effectorPosition': array([ 0.16131775, -0.04931801])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9370303206815634
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-2.24924249,  2.47270388]), 'currentState': array([5.50013744, 2.36183939]), 'targetState': array([0.77134451, 0.16460215]), 'effectorPosition': array([0.70077162, 0.29452512])}
episode index:754
target Thresh 1.6015659679460956
current state at start:  [-0.31441156 -2.04144625]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.31441156, -2.04144625]), 'currentState': array([0.18558844, 3.90146946]), 'targetState': array([ 1.00758577, -0.53820821]), 'effectorPosition': array([ 0.3974621 , -0.62624446])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.937100479197217
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.31441156, -2.04144625]), 'currentState': array([0.49080258, 4.11394367]), 'targetState': array([ 1.00758577, -0.53820821]), 'effectorPosition': array([ 0.77451988, -0.52287824])}
episode index:755
target Thresh 1.6023620396731193
current state at start:  [ 2.97500072 -2.27817162]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.97500072, -2.27817162]), 'currentState': array([3.40309552, 4.50501368]), 'targetState': array([-0.55943449,  1.21101495]), 'effectorPosition': array([-1.02010367,  0.74000285])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9371704521083317
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 2.97500072, -2.27817162]), 'currentState': array([2.94914491, 4.44183505]), 'targetState': array([-0.55943449,  1.21101495]), 'effectorPosition': array([-0.53490325,  1.0859779 ])}
episode index:756
target Thresh 1.6031565208477714
current state at start:  [ 3.69952273 -2.19159424]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.69952273, -2.19159424]), 'currentState': array([4.15073695, 3.71971215]), 'targetState': array([-0.08191397,  0.05114169]), 'effectorPosition': array([-0.54905188,  0.15348799])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9372402401504608
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.69952273, -2.19159424]), 'currentState': array([4.41941365, 3.46386285]), 'targetState': array([-0.08191397,  0.05114169]), 'effectorPosition': array([-0.31809272,  0.0421821 ])}
episode index:757
target Thresh 1.6039494146479776
current state at start:  [-2.99719737  2.80581793]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.99719737,  2.80581793]), 'currentState': array([3.17972755, 3.02318087]), 'targetState': array([-0.33449116, -0.0372442 ]), 'effectorPosition': array([-0.00249341, -0.11831635])}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9372211167392174
{'reset': False, 'endBeforeDone': False, 'stepCount': 9, 'initial state': array([-2.99719737,  2.80581793]), 'currentState': array([2.37159412, 2.96346055]), 'targetState': array([-0.33449116, -0.0372442 ]), 'effectorPosition': array([-0.13470905, -0.11619252])}
episode index:758
target Thresh 1.6047407242453144
current state at start:  [-1.66383115 -1.91719464]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.66383115, -1.91719464]), 'currentState': array([4.19721839, 4.74772882]), 'targetState': array([-1.23877515, -0.61936905]), 'effectorPosition': array([-1.37975637, -0.40857964])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9372906541348179
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.66383115, -1.91719464]), 'currentState': array([4.37206404, 4.77518288]), 'targetState': array([-1.23877515, -0.61936905]), 'effectorPosition': array([-1.29552823, -0.66866425])}
episode index:759
target Thresh 1.6055304528050214
current state at start:  [-3.04034585  2.08608613]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.04034585,  2.08608613]), 'currentState': array([2.74283945, 1.71914468]), 'targetState': array([-1.15730639, -0.16443566]), 'effectorPosition': array([-1.16934201, -0.58054252])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9373600085372721
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.04034585,  2.08608613]), 'currentState': array([2.24283945, 1.84392941]), 'targetState': array([-1.15730639, -0.16443566]), 'effectorPosition': array([-1.20818619, -0.02804886])}
episode index:760
target Thresh 1.6063186034860135
current state at start:  [ 2.71095276 -2.89294861]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.71095276, -2.89294861]), 'currentState': array([2.79384192, 3.77321803]), 'targetState': array([-0.11230661,  0.60296695]), 'effectorPosition': array([0.01983585, 0.62086135])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9374423212724399
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.71095276, -2.89294861]), 'currentState': array([2.79384192, 3.77321803]), 'targetState': array([-0.11230661,  0.60296695]), 'effectorPosition': array([0.01983585, 0.62086135])}
episode index:761
target Thresh 1.6071051794408946
current state at start:  [-3.5319745   2.30290472]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.5319745 ,  2.30290472]), 'currentState': array([3.16565352, 1.98420959]), 'targetState': array([-0.35816462, -1.01372741]), 'effectorPosition': array([-0.57605772, -0.92988319])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9375244179636835
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.5319745 ,  2.30290472]), 'currentState': array([3.16565352, 1.98420959]), 'targetState': array([-0.35816462, -1.01372741]), 'effectorPosition': array([-0.57605772, -0.92988319])}
episode index:762
target Thresh 1.6078901838159696
current state at start:  [-0.73649381  2.02840929]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.73649381,  2.02840929]), 'currentState': array([5.04669149, 2.3558539 ]), 'targetState': array([ 0.39121283, -0.45289258]), 'effectorPosition': array([ 0.76436872, -0.04481793])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9375931933005593
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.73649381,  2.02840929]), 'currentState': array([4.54669149, 2.57795225]), 'targetState': array([ 0.39121283, -0.45289258]), 'effectorPosition': array([ 0.5014358 , -0.24068777])}
episode index:763
target Thresh 1.608673619751257
current state at start:  [ 1.63521895 -2.69414801]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.63521895, -2.69414801]), 'currentState': array([1.46410392, 3.92979106]), 'targetState': array([0.77850129, 0.57787856]), 'effectorPosition': array([0.73645344, 0.21768889])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9376617885972864
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.63521895, -2.69414801]), 'currentState': array([1.70403443, 4.18115684]), 'targetState': array([0.77850129, 0.57787856]), 'effectorPosition': array([0.78899606, 0.60356698])}
episode index:764
target Thresh 1.6094554903805018
current state at start:  [ 1.18409799 -2.16941939]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.18409799, -2.16941939]), 'currentState': array([1.16893513, 4.38030266]), 'targetState': array([1.21783274, 0.27412018]), 'effectorPosition': array([1.13366807, 0.2505286 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9377432764553292
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.18409799, -2.16941939]), 'currentState': array([1.16893513, 4.38030266]), 'targetState': array([1.21783274, 0.27412018]), 'effectorPosition': array([1.13366807, 0.2505286 ])}
episode index:765
target Thresh 1.6102357988311873
current state at start:  [ 0.2567658 -2.8214871]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.2567658, -2.8214871]), 'currentState': array([6.14735254, 3.61640389]), 'targetState': array([ 0.45404927, -0.39179342]), 'effectorPosition': array([ 0.04769406, -0.46793932])}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9377236960610376
{'reset': False, 'endBeforeDone': False, 'stepCount': 9, 'initial state': array([ 0.2567658, -2.8214871]), 'currentState': array([4.34247396, 2.55530251]), 'targetState': array([ 0.45404927, -0.39179342]), 'effectorPosition': array([ 0.45547306, -0.35573353])}
episode index:766
target Thresh 1.6110145482245484
current state at start:  [-0.52873365  2.51141884]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.52873365,  2.51141884]), 'currentState': array([5.25445165, 2.84234788]), 'targetState': array([-0.10443823,  0.09502218]), 'effectorPosition': array([0.27546526, 0.11401793])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9377918529110232
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.52873365,  2.51141884]), 'currentState': array([4.75445165, 3.16438257]), 'targetState': array([-0.10443823,  0.09502218]), 'effectorPosition': array([-0.02275686, -0.00121769])}
episode index:767
target Thresh 1.6117917416755838
current state at start:  [ 3.34039489 -2.10389463]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.34039489, -2.10389463]), 'currentState': array([3.71815274, 3.69780185]), 'targetState': array([-0.66116951,  0.18338727]), 'effectorPosition': array([-0.41418925,  0.36044692])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9378598322692119
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.34039489, -2.10389463]), 'currentState': array([4.00669134, 3.79336215]), 'targetState': array([-0.66116951,  0.18338727]), 'effectorPosition': array([-0.594663  ,  0.23738696])}
episode index:768
target Thresh 1.6125673822930684
current state at start:  [-0.57697001  2.0565454 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.57697001,  2.0565454 ]), 'currentState': array([5.2062153 , 2.49880832]), 'targetState': array([ 0.42751776, -0.32567897]), 'effectorPosition': array([0.62240629, 0.10840061])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9379147609658709
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-0.57697001,  2.0565454 ]), 'currentState': array([4.60504487, 2.64074036]), 'targetState': array([ 0.42751776, -0.32567897]), 'effectorPosition': array([ 0.46425014, -0.17356424])}
episode index:769
target Thresh 1.6133414731795654
current state at start:  [ 0.74141528 -2.42996492]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.74141528, -2.42996492]), 'currentState': array([1.18417625, 3.35322039]), 'targetState': array([0.12065261, 0.02670033]), 'effectorPosition': array([ 0.20295953, -0.05853909])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9379953911464347
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.74141528, -2.42996492]), 'currentState': array([1.18417625, 3.35322039]), 'targetState': array([0.12065261, 0.02670033]), 'effectorPosition': array([ 0.20295953, -0.05853909])}
episode index:770
target Thresh 1.6141140174314397
current state at start:  [ 0.56665505 -2.33655052]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.56665505, -2.33655052]), 'currentState': array([0.88894135, 3.56117167]), 'targetState': array([ 0.17560675, -0.46776565]), 'effectorPosition': array([ 0.37095497, -0.18939738])}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.9379636425813728
{'reset': False, 'endBeforeDone': False, 'stepCount': 10, 'initial state': array([ 0.56665505, -2.33655052]), 'currentState': array([3.32121166, 2.60671244]), 'targetState': array([ 0.17560675, -0.46776565]), 'effectorPosition': array([-0.04635617, -0.52649   ])}
episode index:771
target Thresh 1.6148850181388692
current state at start:  [ 1.6477364  -2.45786154]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.6477364 , -2.45786154]), 'currentState': array([2.1419045 , 3.70392709]), 'targetState': array([0.18177874, 0.76739457]), 'effectorPosition': array([0.36531096, 0.41775871])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9380310471894281
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.6477364 , -2.45786154]), 'currentState': array([2.59043726, 4.09988579]), 'targetState': array([0.18177874, 0.76739457]), 'effectorPosition': array([0.06633794, 0.91965454])}
episode index:772
target Thresh 1.6156544783858577
current state at start:  [-3.89155674  2.20584943]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.89155674,  2.20584943]), 'currentState': array([2.66010613, 1.77937724]), 'targetState': array([-1.29988568, -0.08935954]), 'effectorPosition': array([-1.15583815, -0.49989461])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.9380355091586539
{'reset': False, 'endBeforeDone': False, 'stepCount': 7, 'initial state': array([-3.89155674,  2.20584943]), 'currentState': array([2.51787562, 1.71133927]), 'targetState': array([-1.29988568, -0.08935954]), 'effectorPosition': array([-1.27630536, -0.30146837])}
episode index:773
target Thresh 1.6164224012502473
current state at start:  [ 1.68824267 -2.1266877 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.68824267, -2.1266877 ]), 'currentState': array([1.66876512, 3.91866226]), 'targetState': array([0.5406714 , 0.47650225]), 'effectorPosition': array([0.66975597, 0.35423751])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.938115566640361
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.68824267, -2.1266877 ]), 'currentState': array([1.66876512, 3.91866226]), 'targetState': array([0.5406714 , 0.47650225]), 'effectorPosition': array([0.66975597, 0.35423751])}
episode index:774
target Thresh 1.6171887898037305
current state at start:  [-2.85625282  2.44118554]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.85625282,  2.44118554]), 'currentState': array([3.10366968, 2.84951124]), 'targetState': array([ 0.03096956, -0.35653847]), 'effectorPosition': array([-0.05324009, -0.28613329])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9381954175221153
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.85625282,  2.44118554]), 'currentState': array([3.10366968, 2.84951124]), 'targetState': array([ 0.03096956, -0.35653847]), 'effectorPosition': array([-0.05324009, -0.28613329])}
episode index:775
target Thresh 1.6179536471118625
current state at start:  [-4.42509844  2.64558726]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.42509844,  2.64558726]), 'currentState': array([2.33539708, 2.35753071]), 'targetState': array([-0.50518948, -0.80401364]), 'effectorPosition': array([-0.7117089 , -0.27815184])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9382494182727311
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-4.42509844,  2.64558726]), 'currentState': array([3.22896941, 2.12018262]), 'targetState': array([-0.50518948, -0.80401364]), 'effectorPosition': array([-0.40158911, -0.89129026])}
episode index:776
target Thresh 1.6187169762340736
current state at start:  [ 4.1652121  -2.22106246]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.1652121 , -2.22106246]), 'currentState': array([4.63650928, 3.75084817]), 'targetState': array([-0.38279065, -0.33790926]), 'effectorPosition': array([-0.58425004, -0.13602694])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9383160213380173
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 4.1652121 , -2.22106246]), 'currentState': array([4.91321314, 3.85869322]), 'targetState': array([-0.38279065, -0.33790926]), 'effectorPosition': array([-0.59486567, -0.37243257])}
episode index:777
target Thresh 1.6194787802236812
current state at start:  [1.43675942 2.05151942]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.43675942, 2.05151942]), 'currentState': array([0.94234834, 2.44518262]), 'targetState': array([-0.00589355,  0.93401091]), 'effectorPosition': array([-0.38201933,  0.56547439])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9383824531871972
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.43675942, 2.05151942]), 'currentState': array([0.5918207 , 2.15457305]), 'targetState': array([-0.00589355,  0.93401091]), 'effectorPosition': array([-0.09299367,  0.94286476])}
episode index:778
target Thresh 1.6202390621279024
current state at start:  [0.49190083 2.7123485 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.49190083, 2.7123485 ]), 'currentState': array([0.9388904 , 2.26549078]), 'targetState': array([-0.37821703,  0.73293815]), 'effectorPosition': array([-0.40734572,  0.7441559 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9384615514501148
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.49190083, 2.7123485 ]), 'currentState': array([0.9388904 , 2.26549078]), 'targetState': array([-0.37821703,  0.73293815]), 'effectorPosition': array([-0.40734572,  0.7441559 ])}
episode index:779
target Thresh 1.6209978249878656
current state at start:  [ 1.45709759 -2.13178162]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.45709759, -2.13178162]), 'currentState': array([1.88788369, 3.65140369]), 'targetState': array([0.27923795, 0.2321937 ]), 'effectorPosition': array([0.42403418, 0.27298633])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9385404468969736
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.45709759, -2.13178162]), 'currentState': array([1.88788369, 3.65140369]), 'targetState': array([0.27923795, 0.2321937 ]), 'effectorPosition': array([0.42403418, 0.27298633])}
episode index:780
target Thresh 1.6217550718386236
current state at start:  [ 1.08914412 -2.49924827]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.08914412, -2.49924827]), 'currentState': array([0.98226809, 4.19831235]), 'targetState': array([1.01185373, 0.03595808]), 'effectorPosition': array([ 1.00641058, -0.06062728])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9386191403068366
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.08914412, -2.49924827]), 'currentState': array([0.98226809, 4.19831235]), 'targetState': array([1.01185373, 0.03595808]), 'effectorPosition': array([ 1.00641058, -0.06062728])}
episode index:781
target Thresh 1.6225108057091644
current state at start:  [-1.68651173 -2.05878331]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.68651173, -2.05878331]), 'currentState': array([4.49698529, 3.88965784]), 'targetState': array([-0.65306493, -0.30690012]), 'effectorPosition': array([-0.72156972, -0.11543165])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9386976324547819
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.68651173, -2.05878331]), 'currentState': array([4.49698529, 3.88965784]), 'targetState': array([-0.65306493, -0.30690012]), 'effectorPosition': array([-0.72156972, -0.11543165])}
episode index:782
target Thresh 1.623265029622425
current state at start:  [-0.35440151  2.34688644]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.35440151,  2.34688644]), 'currentState': array([5.42878379, 2.84688644]), 'targetState': array([-0.05393571,  0.35842654]), 'effectorPosition': array([0.24736828, 0.15822105])}
done in step count: 50
reward sum = 0.6050060671375364
running average episode reward sum: 0.9382714618732784
{'reset': False, 'endBeforeDone': False, 'stepCount': 51, 'initial state': array([-0.35440151,  2.34688644]), 'currentState': array([6.01601936, 2.78885143]), 'targetState': array([-0.05393571,  0.35842654]), 'effectorPosition': array([0.15059057, 0.31696062])}
episode index:783
target Thresh 1.6240177465953014
current state at start:  [ 1.41168281 -2.50327686]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.41168281, -2.50327686]), 'currentState': array([1.69132283, 3.42787769]), 'targetState': array([ 0.42041048, -0.11658041]), 'effectorPosition': array([0.2754482 , 0.07435836])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9383501972535421
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.41168281, -2.50327686]), 'currentState': array([1.69132283, 3.42787769]), 'targetState': array([ 0.42041048, -0.11658041]), 'effectorPosition': array([0.2754482 , 0.07435836])}
episode index:784
target Thresh 1.6247689596386632
current state at start:  [ 3.21109321 -2.7876437 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.21109321, -2.7876437 ]), 'currentState': array([3.71109321, 3.29360676]), 'targetState': array([0.71263335, 0.08481333]), 'effectorPosition': array([-0.09136427,  0.12131115])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9383908963653209
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 3.21109321, -2.7876437 ]), 'currentState': array([5.21109321, 2.60929879]), 'targetState': array([0.71263335, 0.08481333]), 'effectorPosition': array([0.51187131, 0.12123287])}
episode index:785
target Thresh 1.625518671757363
current state at start:  [-2.1358431   1.76675056]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.1358431 ,  1.76675056]), 'currentState': array([3.82584048, 1.79270167]), 'targetState': array([-0.17169717, -1.22257139]), 'effectorPosition': array([ 0.01224222, -1.24886862])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9384692794488255
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.1358431 ,  1.76675056]), 'currentState': array([3.82584048, 1.79270167]), 'targetState': array([-0.17169717, -1.22257139]), 'effectorPosition': array([ 0.01224222, -1.24886862])}
episode index:786
target Thresh 1.6262668859502507
current state at start:  [-2.92072731  2.08572233]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.92072731,  2.08572233]), 'currentState': array([3.862458  , 2.33920879]), 'targetState': array([ 0.17126818, -1.09053989]), 'effectorPosition': array([ 0.24544435, -0.74146326])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.938534756857404
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.92072731,  2.08572233]), 'currentState': array([4.10295367, 1.83920879]), 'targetState': array([ 0.17126818, -1.09053989]), 'effectorPosition': array([ 0.37000854, -1.15442259])}
episode index:787
target Thresh 1.627013605210184
current state at start:  [-2.78096579  2.80263394]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.78096579,  2.80263394]), 'currentState': array([3.42110331, 3.16853246]), 'targetState': array([0.32969546, 0.07468385]), 'effectorPosition': array([-0.00778017,  0.02579105])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.9385384946652003
{'reset': False, 'endBeforeDone': False, 'stepCount': 7, 'initial state': array([-2.78096579,  2.80263394]), 'currentState': array([4.78432896, 2.93959713]), 'targetState': array([0.32969546, 0.07468385]), 'effectorPosition': array([ 0.20156716, -0.00585874])}
episode index:788
target Thresh 1.6277588325240406
current state at start:  [ 1.99803185 -2.7214046 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.99803185, -2.7214046 ]), 'currentState': array([1.84675742, 4.0617807 ]), 'targetState': array([0.35689354, 0.30417953]), 'effectorPosition': array([0.658165  , 0.59621956])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.938603718372849
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.99803185, -2.7214046 ]), 'currentState': array([1.80161609, 3.72518523]), 'targetState': array([0.35689354, 0.30417953]), 'effectorPosition': array([0.49854679, 0.28718325])}
episode index:789
target Thresh 1.6285025708727312
current state at start:  [-2.58083712  2.62276679]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.58083712,  2.62276679]), 'currentState': array([4.20234819, 2.18786215]), 'targetState': array([ 0.6302299 , -0.89213391]), 'effectorPosition': array([ 0.50606544, -0.76590376])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9386814351850352
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.58083712,  2.62276679]), 'currentState': array([4.20234819, 2.18786215]), 'targetState': array([ 0.6302299 , -0.89213391]), 'effectorPosition': array([ 0.50606544, -0.76590376])}
episode index:790
target Thresh 1.6292448232312098
current state at start:  [-4.0347864   2.70200279]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.0347864 ,  2.70200279]), 'currentState': array([2.74839891, 2.23350939]), 'targetState': array([-1.20459507, -0.70573056]), 'effectorPosition': array([-0.65742198, -0.5807586 ])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9387091400836636
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([-4.0347864 ,  2.70200279]), 'currentState': array([2.9302218 , 1.49822428]), 'targetState': array([-1.20459507, -0.70573056]), 'effectorPosition': array([-1.25788706, -0.75015789])}
episode index:791
target Thresh 1.629985592568487
current state at start:  [ 0.59507595 -2.32968194]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.59507595, -2.32968194]), 'currentState': array([1.09507595, 3.60867456]), 'targetState': array([ 0.05481955, -0.31035836]), 'effectorPosition': array([ 0.44934059, -0.11099965])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9387367750204266
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([ 0.59507595, -2.32968194]), 'currentState': array([2.78054558, 2.9228846 ]), 'targetState': array([ 0.05481955, -0.31035836]), 'effectorPosition': array([-0.09893063, -0.1945651 ])}
episode index:792
target Thresh 1.6307248818476412
current state at start:  [-1.21863441 -2.28186716]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.21863441, -2.28186716]), 'currentState': array([5.51012831, 3.5909081 ]), 'targetState': array([ 0.0379092 , -0.03023745]), 'effectorPosition': array([-0.23227258, -0.38021067])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9388014196925321
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.21863441, -2.28186716]), 'currentState': array([5.7253926 , 3.33884354]), 'targetState': array([ 0.0379092 , -0.03023745]), 'effectorPosition': array([-0.08728029, -0.1765335 ])}
episode index:793
target Thresh 1.6314626940258303
current state at start:  [-1.20854989  2.99287857]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.20854989,  2.99287857]), 'currentState': array([5.49089924, 2.76525314]), 'targetState': array([0.45811143, 0.34819811]), 'effectorPosition': array([0.31080276, 0.20825304])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9388784959901485
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.20854989,  2.99287857]), 'currentState': array([5.49089924, 2.76525314]), 'targetState': array([0.45811143, 0.34819811]), 'effectorPosition': array([0.31080276, 0.20825304])}
episode index:794
target Thresh 1.632199032054304
current state at start:  [-0.03146364  1.7374444 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.03146364,  1.7374444 ]), 'currentState': array([5.75172166, 2.17368681]), 'targetState': array([1.13576595, 0.21567088]), 'effectorPosition': array([0.79070011, 0.49065455])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9389303469385886
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-0.03146364,  1.7374444 ]), 'currentState': array([5.62080227, 1.8929814 ]), 'targetState': array([1.13576595, 0.21567088]), 'effectorPosition': array([1.12220263, 0.32769094])}
episode index:795
target Thresh 1.632933898878416
current state at start:  [1.91335786 2.12574573]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.91335786, 2.12574573]), 'currentState': array([1.41335786, 2.58610601]), 'targetState': array([-0.63536288,  0.73370779]), 'effectorPosition': array([-0.4972604 ,  0.23118019])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9389575651082637
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([1.91335786, 2.12574573]), 'currentState': array([1.07722093, 2.30423276]), 'targetState': array([-0.63536288,  0.73370779]), 'effectorPosition': array([-0.49759343,  0.64307691])}
episode index:796
target Thresh 1.6336672974376336
current state at start:  [ 1.45369424 -2.40108909]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.45369424, -2.40108909]), 'currentState': array([1.03294517, 4.38209621]), 'targetState': array([0.99273759, 0.32367186]), 'effectorPosition': array([1.15853581, 0.09568073])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9389968893678518
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 1.45369424, -2.40108909]), 'currentState': array([1.36822813, 4.42866489]), 'targetState': array([0.99273759, 0.32367186]), 'effectorPosition': array([1.08525742, 0.5122019 ])}
episode index:797
target Thresh 1.6343992306655526
current state at start:  [ 2.1334826  -2.20101156]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.1334826 , -2.20101156]), 'currentState': array([2.5022391, 3.7866088]), 'targetState': array([-0.09402107,  0.54654239]), 'effectorPosition': array([0.19750232, 0.60233937])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9390608030403231
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 2.1334826 , -2.20101156]), 'currentState': array([2.71047244, 3.80803007]), 'targetState': array([-0.09402107,  0.54654239]), 'effectorPosition': array([0.06394224, 0.65104023])}
episode index:798
target Thresh 1.635129701489907
current state at start:  [-0.46069386  1.59503322]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.46069386,  1.59503322]), 'currentState': array([0.03930614, 2.01378333]), 'targetState': array([0.62988137, 1.03513236]), 'effectorPosition': array([0.53541565, 0.92522969])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9391370723731889
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.46069386,  1.59503322]), 'currentState': array([0.03930614, 2.01378333]), 'targetState': array([0.62988137, 1.03513236]), 'effectorPosition': array([0.53541565, 0.92522969])}
episode index:799
target Thresh 1.6358587128325808
current state at start:  [-1.38328781 -2.2429905 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.38328781, -2.2429905 ]), 'currentState': array([5.39989749, 4.09256989]), 'targetState': array([-0.1754178 , -0.88065071]), 'effectorPosition': array([-0.36309629, -0.84046729])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9392131510327224
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.38328781, -2.2429905 ]), 'currentState': array([5.39989749, 4.09256989]), 'targetState': array([-0.1754178 , -0.88065071]), 'effectorPosition': array([-0.36309629, -0.84046729])}
episode index:800
target Thresh 1.6365862676096203
current state at start:  [ 0.62890807 -2.55840067]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.62890807, -2.55840067]), 'currentState': array([1.12890807, 3.33868024]), 'targetState': array([ 0.04901702, -0.16185809]), 'effectorPosition': array([ 0.18528416, -0.06623989])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.939289039733056
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.62890807, -2.55840067]), 'currentState': array([1.12890807, 3.33868024]), 'targetState': array([ 0.04901702, -0.16185809]), 'effectorPosition': array([ 0.18528416, -0.06623989])}
episode index:801
target Thresh 1.6373123687312456
current state at start:  [ 1.73197251 -1.95075915]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.73197251, -1.95075915]), 'currentState': array([1.89168323, 3.84350776]), 'targetState': array([0.25230704, 0.11424436]), 'effectorPosition': array([0.53816284, 0.42797978])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9393522703568303
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.73197251, -1.95075915]), 'currentState': array([1.78658476, 3.4249835 ]), 'targetState': array([0.25230704, 0.11424436]), 'effectorPosition': array([0.26458748, 0.09883214])}
episode index:802
target Thresh 1.6380370191018625
current state at start:  [1.55658994 2.99208238]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.55658994, 2.99208238]), 'currentState': array([2.01888147, 2.49208238]), 'targetState': array([-0.86396088,  0.12547197]), 'effectorPosition': array([-0.63330636, -0.07850411])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9394030147274942
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([1.55658994, 2.99208238]), 'currentState': array([1.8477923 , 2.44426083]), 'targetState': array([-0.86396088,  0.12547197]), 'effectorPosition': array([-0.68153446,  0.04892934])}
episode index:803
target Thresh 1.638760221620073
current state at start:  [-3.18566796  2.69523826]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.18566796,  2.69523826]), 'currentState': array([2.83538596, 3.19523826]), 'targetState': array([0.33842088, 0.38619986]), 'effectorPosition': array([0.01479173, 0.05155935])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9394536328683805
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-3.18566796,  2.69523826]), 'currentState': array([2.5020792 , 3.67638386]), 'targetState': array([0.33842088, 0.38619986]), 'effectorPosition': array([0.19213541, 0.49227417])}
episode index:804
target Thresh 1.6394819791786885
current state at start:  [-0.72968608  2.271509  ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.72968608,  2.271509  ]), 'currentState': array([5.11344553, 2.771509  ]), 'targetState': array([ 0.05183596, -0.29625469]), 'effectorPosition': array([0.35942332, 0.07887134])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9394919500946308
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-0.72968608,  2.271509  ]), 'currentState': array([4.2938562 , 2.95953474]), 'targetState': array([ 0.05183596, -0.29625469]), 'effectorPosition': array([ 0.15870958, -0.08868429])}
episode index:805
target Thresh 1.6402022946647399
current state at start:  [ 1.64787678 -2.06873104]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.64787678, -2.06873104]), 'currentState': array([2.11390255, 4.19725955]), 'targetState': array([0.24719542, 1.10330906]), 'effectorPosition': array([0.48281093, 0.88408067])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9395546151689551
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.64787678, -2.06873104]), 'currentState': array([2.27093806, 4.62007082]), 'targetState': array([0.24719542, 1.10330906]), 'effectorPosition': array([0.17656679, 1.33583308])}
episode index:806
target Thresh 1.6409211709594902
current state at start:  [-1.45649073  2.49029497]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.45649073,  2.49029497]), 'currentState': array([5.15829149, 2.0724547 ]), 'targetState': array([0.96569994, 0.08243267]), 'effectorPosition': array([ 1.01493769, -0.09022752])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9396295165132316
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.45649073,  2.49029497]), 'currentState': array([5.15829149, 2.0724547 ]), 'targetState': array([0.96569994, 0.08243267]), 'effectorPosition': array([ 1.01493769, -0.09022752])}
episode index:807
target Thresh 1.6416386109384458
current state at start:  [ 0.01591481 -2.56601182]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.01591481, -2.56601182]), 'currentState': array([6.1658822 , 3.29111964]), 'targetState': array([ 0.0301047 , -0.26934346]), 'effectorPosition': array([-0.00635298, -0.14925258])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9397042324581409
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.01591481, -2.56601182]), 'currentState': array([6.1658822 , 3.29111964]), 'targetState': array([ 0.0301047 , -0.26934346]), 'effectorPosition': array([-0.00635298, -0.14925258])}
episode index:808
target Thresh 1.642354617471367
current state at start:  [ 0.57192316 -2.0186203 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.57192316, -2.0186203 ]), 'currentState': array([0.94954225, 3.93268908]), 'targetState': array([0.8717732, 0.3110848]), 'effectorPosition': array([ 0.75108234, -0.17246227])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9397664027517649
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.57192316, -2.0186203 ]), 'currentState': array([1.3339087 , 4.19150953]), 'targetState': array([0.8717732, 0.3110848]), 'effectorPosition': array([0.96105082, 0.28477186])}
episode index:809
target Thresh 1.6430691934222814
current state at start:  [ 1.57363312 -2.44065899]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.57363312, -2.44065899]), 'currentState': array([1.1290062 , 4.34252632]), 'targetState': array([1.21401447, 0.57256027]), 'effectorPosition': array([1.1158588 , 0.17856195])}
done in step count: 22
reward sum = 0.8016305895390459
running average episode reward sum: 0.9395958647107616
{'reset': False, 'endBeforeDone': False, 'stepCount': 23, 'initial state': array([ 1.57363312, -2.44065899]), 'currentState': array([1.06183146, 4.95049025]), 'targetState': array([1.21401447, 0.57256027]), 'effectorPosition': array([1.45081376, 0.60568572])}
episode index:810
target Thresh 1.6437823416494937
current state at start:  [-0.77670702 -2.54272841]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.77670702, -2.54272841]), 'currentState': array([5.23071421, 4.2404569 ]), 'targetState': array([-0.57512543, -0.80157452]), 'effectorPosition': array([-0.50349799, -0.91502663])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9396703457653722
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.77670702, -2.54272841]), 'currentState': array([5.23071421, 4.2404569 ]), 'targetState': array([-0.57512543, -0.80157452]), 'effectorPosition': array([-0.50349799, -0.91502663])}
episode index:811
target Thresh 1.6444940650055975
current state at start:  [-3.5091078   2.92982491]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.5091078 ,  2.92982491]), 'currentState': array([2.91247276, 3.37904083]), 'targetState': array([ 0.02294762, -0.08877226]), 'effectorPosition': array([0.02609866, 0.23544869])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9397323280981735
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.5091078 ,  2.92982491]), 'currentState': array([3.33734486, 2.99878906]), 'targetState': array([ 0.02294762, -0.08877226]), 'effectorPosition': array([ 0.01769691, -0.14158055])}
episode index:812
target Thresh 1.6452043663374871
current state at start:  [-3.83166413  2.67188075]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.83166413,  2.67188075]), 'currentState': array([2.00492831, 3.17188075]), 'targetState': array([-0.30496441,  0.32617034]), 'effectorPosition': array([0.02728132, 0.01315403])}
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.9396777228412985
{'reset': False, 'endBeforeDone': False, 'stepCount': 12, 'initial state': array([-3.83166413,  2.67188075]), 'currentState': array([3.43881792, 3.42229865]), 'targetState': array([-0.30496441,  0.32617034]), 'effectorPosition': array([-0.11855822,  0.25342407])}
episode index:813
target Thresh 1.6459132484863692
current state at start:  [-1.77585522  2.47946565]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.77585522,  2.47946565]), 'currentState': array([4.41118037, 2.97526776]), 'targetState': array([0.14443918, 0.13250111]), 'effectorPosition': array([ 0.15401124, -0.06229601])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9397518288328939
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.77585522,  2.47946565]), 'currentState': array([4.41118037, 2.97526776]), 'targetState': array([0.14443918, 0.13250111]), 'effectorPosition': array([ 0.15401124, -0.06229601])}
episode index:814
target Thresh 1.6466207142877731
current state at start:  [-0.83513053  2.04534543]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.83513053,  2.04534543]), 'currentState': array([5.94805477, 2.48202658]), 'targetState': array([0.26992164, 0.98113874]), 'effectorPosition': array([0.39961005, 0.50970129])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9398134830306449
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.83513053,  2.04534543]), 'currentState': array([0.11563043, 2.09137416]), 'targetState': array([0.26992164, 0.98113874]), 'effectorPosition': array([0.39917243, 0.91972733])}
episode index:815
target Thresh 1.6473267665715632
current state at start:  [-0.09261137  2.39866887]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.09261137,  2.39866887]), 'currentState': array([5.69057394, 2.8652968 ]), 'targetState': array([ 0.05719453, -0.12429248]), 'effectorPosition': array([0.18382358, 0.20509482])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9398749861151663
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.09261137,  2.39866887]), 'currentState': array([5.24667121, 3.23192681]), 'targetState': array([ 0.05719453, -0.12429248]), 'effectorPosition': array([-0.0755627 , -0.04944685])}
episode index:816
target Thresh 1.6480314081619492
current state at start:  [-0.67260555 -2.5557247 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.67260555, -2.5557247 ]), 'currentState': array([5.94905698, 3.22746061]), 'targetState': array([-0.0495253, -0.0110392]), 'effectorPosition': array([-0.02464482, -0.08222779])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9399485785434218
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.67260555, -2.5557247 ]), 'currentState': array([5.94905698, 3.22746061]), 'targetState': array([-0.0495253, -0.0110392]), 'effectorPosition': array([-0.02464482, -0.08222779])}
episode index:817
target Thresh 1.6487346418774984
current state at start:  [-1.15043374  1.91233693]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.15043374,  1.91233693]), 'currentState': array([4.64518161, 2.22448949]), 'targetState': array([ 0.36307961, -0.47409543]), 'effectorPosition': array([ 0.76573392, -0.44430494])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9400097661002147
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.15043374,  1.91233693]), 'currentState': array([4.19977031, 2.4993488 ]), 'targetState': array([ 0.36307961, -0.47409543]), 'effectorPosition': array([ 0.42427842, -0.46741885])}
episode index:818
target Thresh 1.649436470531147
current state at start:  [ 2.37360641 -2.46641127]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.37360641, -2.46641127]), 'currentState': array([2.23540431, 3.88026225]), 'targetState': array([0.15750832, 0.56083361]), 'effectorPosition': array([0.36925092, 0.62042228])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9400830142490545
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.37360641, -2.46641127]), 'currentState': array([2.23540431, 3.88026225]), 'targetState': array([0.15750832, 0.56083361]), 'effectorPosition': array([0.36925092, 0.62042228])}
episode index:819
target Thresh 1.6501368969302102
current state at start:  [-2.64678784  2.50740885]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.64678784,  2.50740885]), 'currentState': array([3.35003518, 2.98838874]), 'targetState': array([ 0.02455873, -0.38888499]), 'effectorPosition': array([ 0.02012034, -0.15172586])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9401560837438727
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.64678784,  2.50740885]), 'currentState': array([3.35003518, 2.98838874]), 'targetState': array([ 0.02455873, -0.38888499]), 'effectorPosition': array([ 0.02012034, -0.15172586])}
episode index:820
target Thresh 1.6508359238763946
current state at start:  [ 1.16079488 -1.77729552]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.16079488, -1.77729552]), 'currentState': array([1.18565473, 4.13837523]), 'targetState': array([ 0.46104303, -0.44062626]), 'effectorPosition': array([0.94990208, 0.10803839])}
done in step count: 15
reward sum = 0.8600583546412884
running average episode reward sum: 0.9400585225634799
{'reset': False, 'endBeforeDone': False, 'stepCount': 16, 'initial state': array([ 1.16079488, -1.77729552]), 'currentState': array([0.85988069, 3.76787569]), 'targetState': array([ 0.46104303, -0.44062626]), 'effectorPosition': array([ 0.56799628, -0.23865608])}
episode index:821
target Thresh 1.651533554165809
current state at start:  [-1.99304677  2.05585288]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.99304677,  2.05585288]), 'currentState': array([3.79013853, 2.49030297]), 'targetState': array([ 0.00384388, -0.45049005]), 'effectorPosition': array([ 0.20303327, -0.60677196])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9401192786187554
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.99304677,  2.05585288]), 'currentState': array([3.29013853, 2.69540221]), 'targetState': array([ 0.00384388, -0.45049005]), 'effectorPosition': array([-0.03295742, -0.44126934])}
episode index:822
target Thresh 1.6522297905889753
current state at start:  [0.74195981 2.42015945]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.74195981, 2.42015945]), 'currentState': array([0.73971024, 2.25186788]), 'targetState': array([-0.19918369,  0.80662043]), 'effectorPosition': array([-0.250105  ,  0.82352641])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9401920376969829
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.74195981, 2.42015945]), 'currentState': array([0.73971024, 2.25186788]), 'targetState': array([-0.19918369,  0.80662043]), 'effectorPosition': array([-0.250105  ,  0.82352641])}
episode index:823
target Thresh 1.6529246359308405
current state at start:  [ 2.85793787 -2.09433038]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.85793787, -2.09433038]), 'currentState': array([3.30166902, 4.16497578]), 'targetState': array([-0.72450437,  0.81907912]), 'effectorPosition': array([-0.60949123,  0.76652468])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.940264620175506
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.85793787, -2.09433038]), 'currentState': array([3.30166902, 4.16497578]), 'targetState': array([-0.72450437,  0.81907912]), 'effectorPosition': array([-0.60949123,  0.76652468])}
episode index:824
target Thresh 1.6536180929707864
current state at start:  [ 0.22218522 -2.25479798]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.22218522, -2.25479798]), 'currentState': array([6.20225346, 4.41612711]), 'targetState': array([ 0.77190614, -0.9607527 ]), 'effectorPosition': array([ 0.62841388, -1.01054541])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9403370266965054
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.22218522, -2.25479798]), 'currentState': array([6.20225346, 4.41612711]), 'targetState': array([ 0.77190614, -0.9607527 ]), 'effectorPosition': array([ 0.62841388, -1.01054541])}
episode index:825
target Thresh 1.6543101644826426
current state at start:  [-0.13114415  1.98976683]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.13114415,  1.98976683]), 'currentState': array([5.65522613, 2.11003521]), 'targetState': array([0.87691376, 0.53139395]), 'effectorPosition': array([0.89783212, 0.40857244])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.940409257899052
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.13114415,  1.98976683]), 'currentState': array([5.65522613, 2.11003521]), 'targetState': array([0.87691376, 0.53139395]), 'effectorPosition': array([0.89783212, 0.40857244])}
episode index:826
target Thresh 1.6550008532346956
current state at start:  [2.10086259 1.8134101 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.10086259, 1.8134101 ]), 'currentState': array([2.60086259, 2.29038018]), 'targetState': array([-0.88077414, -0.40260372]), 'effectorPosition': array([-0.67943134, -0.46928622])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9404813144191257
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.10086259, 1.8134101 ]), 'currentState': array([2.60086259, 2.29038018]), 'targetState': array([-0.88077414, -0.40260372]), 'effectorPosition': array([-0.67943134, -0.46928622])}
episode index:827
target Thresh 1.6556901619897018
current state at start:  [-0.04075944  1.59127423]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.04075944,  1.59127423]), 'currentState': array([0.43778605, 1.95799017]), 'targetState': array([0.64204392, 1.05794953]), 'effectorPosition': array([0.17115832, 1.10250708])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.940541119594948
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.04075944,  1.59127423]), 'currentState': array([6.27499462, 1.77877641]), 'targetState': array([0.64204392, 1.05794953]), 'effectorPosition': array([0.80150354, 0.9719178 ])}
episode index:828
target Thresh 1.6563780935048966
current state at start:  [ 3.14255747 -2.58552639]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.14255747, -2.58552639]), 'currentState': array([3.64255747, 3.30405047]), 'targetState': array([ 0.09272101, -0.20525761]), 'effectorPosition': array([-0.08923046,  0.13554509])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9406007804880784
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.14255747, -2.58552639]), 'currentState': array([4.14255747, 2.87396335]), 'targetState': array([ 0.09272101, -0.20525761]), 'effectorPosition': array([ 0.20345572, -0.17264043])}
episode index:829
target Thresh 1.6570646505320075
current state at start:  [1.52403491 2.28424973]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.52403491, 2.28424973]), 'currentState': array([1.23593255, 2.71884945]), 'targetState': array([-0.22363122,  0.74808455]), 'effectorPosition': array([-0.35854441,  0.21797255])}
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.9405247807802601
{'reset': False, 'endBeforeDone': False, 'stepCount': 14, 'initial state': array([1.52403491, 2.28424973]), 'currentState': array([2.92486132, 3.99732499]), 'targetState': array([-0.22363122,  0.74808455]), 'effectorPosition': array([-0.1739136 ,  0.81143243])}
episode index:830
target Thresh 1.6577498358172629
current state at start:  [1.39056691 2.3910638 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.39056691, 2.3910638 ]), 'currentState': array([1.12216833, 2.8910638 ]), 'targetState': array([-0.02152752, -0.01574164]), 'effectorPosition': array([-0.20984288,  0.13565794])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9405963514411744
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.39056691, 2.3910638 ]), 'currentState': array([1.12216833, 2.8910638 ]), 'targetState': array([-0.02152752, -0.01574164]), 'effectorPosition': array([-0.20984288,  0.13565794])}
episode index:831
target Thresh 1.6584336521014056
current state at start:  [-1.01410607 -1.67218017]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.01410607, -1.67218017]), 'currentState': array([5.09044403, 4.4306657 ]), 'targetState': array([-0.57883457, -0.86015335]), 'effectorPosition': array([-0.62625012, -1.02556714])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9406677500572307
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.01410607, -1.67218017]), 'currentState': array([5.09044403, 4.4306657 ]), 'targetState': array([-0.57883457, -0.86015335]), 'effectorPosition': array([-0.62625012, -1.02556714])}
episode index:832
target Thresh 1.6591161021197012
current state at start:  [0.95494968 1.91509065]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.95494968, 1.91509065]), 'currentState': array([1.45494968, 2.40189985]), 'targetState': array([-1.00898428,  0.51618695]), 'effectorPosition': array([-0.63933711,  0.33748592])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.940715087692216
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([0.95494968, 1.91509065]), 'currentState': array([1.66451204, 2.06284784]), 'targetState': array([-1.00898428,  0.51618695]), 'effectorPosition': array([-0.92686677,  0.44277303])}
episode index:833
target Thresh 1.6597971886019507
current state at start:  [-3.2180896   2.55973936]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.2180896 ,  2.55973936]), 'currentState': array([2.99645785, 2.47225031]), 'targetState': array([-0.32039238, -0.40760513]), 'effectorPosition': array([-0.30323762, -0.58274107])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9407861727189639
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.2180896 ,  2.55973936]), 'currentState': array([2.99645785, 2.47225031]), 'targetState': array([-0.32039238, -0.40760513]), 'effectorPosition': array([-0.30323762, -0.58274107])}
episode index:834
target Thresh 1.660476914272501
current state at start:  [1.09936961 1.73655221]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.09936961, 1.73655221]), 'currentState': array([1.59936961, 2.04838705]), 'targetState': array([-1.25739527,  0.56302699]), 'effectorPosition': array([-0.90318012,  0.51476598])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9408451114342706
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.09936961, 1.73655221]), 'currentState': array([2.09936961, 1.54838705]), 'targetState': array([-1.25739527,  0.56302699]), 'effectorPosition': array([-1.37891257,  0.37870162])}
episode index:835
target Thresh 1.6611552818502557
current state at start:  [0.8185219  2.90457405]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.8185219 , 2.90457405]), 'currentState': array([1.27494068, 2.40457405]), 'targetState': array([0.1222319, 0.972963 ]), 'effectorPosition': array([-0.56721674,  0.44420039])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9408920670426028
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([0.8185219 , 2.90457405]), 'currentState': array([0.57670651, 2.07309569]), 'targetState': array([0.1222319, 0.972963 ]), 'effectorPosition': array([-0.04322579,  1.017471  ])}
episode index:836
target Thresh 1.661832294048686
current state at start:  [ 1.8503883  -2.07915178]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.8503883 , -2.07915178]), 'currentState': array([1.50108842, 3.93179286]), 'targetState': array([0.92204587, 0.24167857]), 'effectorPosition': array([0.72940617, 0.24609037])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9409626858394455
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.8503883 , -2.07915178]), 'currentState': array([1.50108842, 3.93179286]), 'targetState': array([0.92204587, 0.24167857]), 'effectorPosition': array([0.72940617, 0.24609037])}
episode index:837
target Thresh 1.6625079535758418
current state at start:  [0.24588799 2.29681806]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.24588799, 2.29681806]), 'currentState': array([0.70217758, 2.55179022]), 'targetState': array([-0.54131962,  0.62332496]), 'effectorPosition': array([-0.23025501,  0.53374288])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9410212029207827
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.24588799, 2.29681806]), 'currentState': array([1.20217758, 2.1353196 ]), 'targetState': array([-0.54131962,  0.62332496]), 'effectorPosition': array([-0.62054469,  0.7381721 ])}
episode index:838
target Thresh 1.6631822631343618
current state at start:  [ 1.74489118 -2.09822927]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.74489118, -2.09822927]), 'currentState': array([2.24489118, 3.68495604]), 'targetState': array([-0.05278932,  0.2331369 ]), 'effectorPosition': array([0.31403245, 0.43524065])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9410795805096733
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.74489118, -2.09822927]), 'currentState': array([2.54717989, 3.18495604]), 'targetState': array([-0.05278932,  0.2331369 ]), 'effectorPosition': array([0.02349805, 0.03644078])}
episode index:839
target Thresh 1.6638552254214851
current state at start:  [-0.67164645  2.50647802]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.67164645,  2.50647802]), 'currentState': array([5.13413611, 2.89132077]), 'targetState': array([-0.00380927, -0.28936619]), 'effectorPosition': array([0.23871897, 0.07295897])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.9410800573774011
{'reset': False, 'endBeforeDone': False, 'stepCount': 7, 'initial state': array([-0.67164645,  2.50647802]), 'currentState': array([5.31574398, 3.43903323]), 'targetState': array([-0.00380927, -0.28936619]), 'effectorPosition': array([-0.21641291, -0.20245002])}
episode index:840
target Thresh 1.664526843129062
current state at start:  [-3.6978492   2.17366582]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.6978492 ,  2.17366582]), 'currentState': array([2.2750368 , 2.66610449]), 'targetState': array([-0.25868065,  0.09349346]), 'effectorPosition': array([-0.42069267, -0.21184655])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.941138226155787
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.6978492 ,  2.17366582]), 'currentState': array([1.99590438, 3.09237378]), 'targetState': array([-0.25868065,  0.09349346]), 'effectorPosition': array([-0.04531944, -0.0191874 ])}
episode index:841
target Thresh 1.6651971189435641
current state at start:  [0.95859918 2.46327021]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.95859918, 2.46327021]), 'currentState': array([0.69672641, 2.90046038]), 'targetState': array([-0.11950648, -0.10642205]), 'effectorPosition': array([-0.13105278,  0.20171453])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9411844990463384
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([0.95859918, 2.46327021]), 'currentState': array([1.05095338, 3.10735222]), 'targetState': array([-0.11950648, -0.10642205]), 'effectorPosition': array([-0.02942021,  0.01751412])}
episode index:842
target Thresh 1.6658660555460956
current state at start:  [-2.75145877  2.01865666]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.75145877,  2.01865666]), 'currentState': array([3.94092571, 1.77830504]), 'targetState': array([ 0.11568198, -1.15959568]), 'effectorPosition': array([ 0.1479629 , -1.25142382])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9412542683238635
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.75145877,  2.01865666]), 'currentState': array([3.94092571, 1.77830504]), 'targetState': array([ 0.11568198, -1.15959568]), 'effectorPosition': array([ 0.1479629 , -1.25142382])}
episode index:843
target Thresh 1.6665336556124037
current state at start:  [-3.04195618  2.11840036]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.04195618,  2.11840036]), 'currentState': array([3.70903651, 1.61840036]), 'targetState': array([-0.42229575, -1.32913275]), 'effectorPosition': array([-0.26627997, -1.35422408])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9413238722713471
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.04195618,  2.11840036]), 'currentState': array([3.70903651, 1.61840036]), 'targetState': array([-0.42229575, -1.32913275]), 'effectorPosition': array([-0.26627997, -1.35422408])}
episode index:844
target Thresh 1.6671999218128897
current state at start:  [-2.29089731  2.54480014]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.29089731,  2.54480014]), 'currentState': array([3.49939573, 2.04480014]), 'targetState': array([-0.32235443, -1.23074639]), 'effectorPosition': array([-0.19751889, -1.02375859])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9413933114757597
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.29089731,  2.54480014]), 'currentState': array([3.49939573, 2.04480014]), 'targetState': array([-0.32235443, -1.23074639]), 'effectorPosition': array([-0.19751889, -1.02375859])}
episode index:845
target Thresh 1.6678648568126193
current state at start:  [0.89847021 2.70425522]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.89847021, 2.70425522]), 'currentState': array([0.39847021, 3.06992662]), 'targetState': array([0.23889891, 0.03621427]), 'effectorPosition': array([-0.02541745,  0.06699087])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9414390640626678
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([0.89847021, 2.70425522]), 'currentState': array([5.82091334, 2.87528923]), 'targetState': array([0.23889891, 0.03621427]), 'effectorPosition': array([0.14891788, 0.21982462])}
episode index:846
target Thresh 1.668528463271333
current state at start:  [-3.08922885  1.98256841]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.08922885,  1.98256841]), 'currentState': array([3.6220886, 2.2944825]), 'targetState': array([-0.11296012, -0.85060725]), 'effectorPosition': array([ 0.04678056, -0.82067572])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9415082033022631
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.08922885,  1.98256841]), 'currentState': array([3.6220886, 2.2944825]), 'targetState': array([-0.11296012, -0.85060725]), 'effectorPosition': array([ 0.04678056, -0.82067572])}
episode index:847
target Thresh 1.6691907438434583
current state at start:  [ 1.90306185 -2.13960996]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.90306185, -2.13960996]), 'currentState': array([2.39372815, 3.64357535]), 'targetState': array([-0.02546639,  0.41282028]), 'effectorPosition': array([0.23678022, 0.43666298])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9415537124964822
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 1.90306185, -2.13960996]), 'currentState': array([2.40880017, 3.51182143]), 'targetState': array([-0.02546639,  0.41282028]), 'effectorPosition': array([0.19168134, 0.31427548])}
episode index:848
target Thresh 1.6698517011781175
current state at start:  [-0.46979188 -2.6236456 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.46979188, -2.6236456 ]), 'currentState': array([5.73500922, 3.15953971]), 'targetState': array([-0.18339845, -0.03681613]), 'effectorPosition': array([-0.00921482, -0.01540049])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9416225538245193
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.46979188, -2.6236456 ]), 'currentState': array([5.73500922, 3.15953971]), 'targetState': array([-0.18339845, -0.03681613]), 'effectorPosition': array([-0.00921482, -0.01540049])}
episode index:849
target Thresh 1.6705113379191414
current state at start:  [0.91115939 1.65512742]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.91115939, 1.65512742]), 'currentState': array([0.42215573, 1.50292139]), 'targetState': array([0.16181114, 1.30729676]), 'effectorPosition': array([0.56529189, 1.34762412])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9416794684670787
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.91115939, 1.65512742]), 'currentState': array([0.83300191, 1.5329017 ]), 'targetState': array([0.16181114, 1.30729676]), 'effectorPosition': array([-0.04128121,  1.44016213])}
episode index:850
target Thresh 1.6711696567050776
current state at start:  [ 2.59945538 -2.65618628]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.59945538, -2.65618628]), 'currentState': array([2.19975978, 3.94668195]), 'targetState': array([0.79578911, 0.30983409]), 'effectorPosition': array([0.40235827, 0.67231993])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9417362493501962
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 2.59945538, -2.65618628]), 'currentState': array([1.69975978, 3.85513832]), 'targetState': array([0.79578911, 0.30983409]), 'effectorPosition': array([0.61770925, 0.3261034 ])}
episode index:851
target Thresh 1.6718266601692022
current state at start:  [ 3.76879358 -2.39339533]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.76879358, -2.39339533]), 'currentState': array([3.26879358, 3.84722151]), 'targetState': array([0.02453993, 1.21540613]), 'effectorPosition': array([-0.319136  ,  0.61297998])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9417812772265457
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 3.76879358, -2.39339533]), 'currentState': array([2.32462001, 4.5043992 ]), 'targetState': array([0.02453993, 1.21540613]), 'effectorPosition': array([0.17026317, 1.24820816])}
episode index:852
target Thresh 1.67248235093953
current state at start:  [ 3.86748928 -1.5771558 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.86748928, -1.5771558 ]), 'currentState': array([4.32237261, 4.76666942]), 'targetState': array([-1.27275815, -0.37314006]), 'effectorPosition': array([-1.32437166, -0.59543874])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9418495289531265
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.86748928, -1.5771558 ]), 'currentState': array([4.32237261, 4.76666942]), 'targetState': array([-1.27275815, -0.37314006]), 'effectorPosition': array([-1.32437166, -0.59543874])}
episode index:853
target Thresh 1.6731367316388246
current state at start:  [-1.99299471 -2.17494225]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.99299471, -2.17494225]), 'currentState': array([3.84056216, 4.18676643]), 'targetState': array([-0.96240629,  0.26819644]), 'effectorPosition': array([-0.93798575,  0.34158382])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9419176208395983
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.99299471, -2.17494225]), 'currentState': array([3.84056216, 4.18676643]), 'targetState': array([-0.96240629,  0.26819644]), 'effectorPosition': array([-0.93798575,  0.34158382])}
episode index:854
target Thresh 1.67378980488461
current state at start:  [ 3.75208683 -2.62737627]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.75208683, -2.62737627]), 'currentState': array([4.22859306, 3.15580903]), 'targetState': array([-0.10993209, -0.12172031]), 'effectorPosition': array([-0.01263143,  0.00652297])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9419855534468033
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.75208683, -2.62737627]), 'currentState': array([4.22859306, 3.15580903]), 'targetState': array([-0.10993209, -0.12172031]), 'effectorPosition': array([-0.01263143,  0.00652297])}
episode index:855
target Thresh 1.6744415732891802
current state at start:  [-1.62813153 -2.18636517]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.62813153, -2.18636517]), 'currentState': array([4.26857074, 3.64586847]), 'targetState': array([-0.54611269,  0.41710022]), 'effectorPosition': array([-0.48981167,  0.09505427])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9420300796694122
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.62813153, -2.18636517]), 'currentState': array([3.66844909, 3.94628268]), 'targetState': array([-0.54611269,  0.41710022]), 'effectorPosition': array([-0.62741806,  0.46869745])}
episode index:856
target Thresh 1.6750920394596094
current state at start:  [0.05641979 2.51715799]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.05641979, 2.51715799]), 'currentState': array([6.00646285, 2.97225065]), 'targetState': array([-0.19349586, -0.04209377]), 'effectorPosition': array([0.05980409, 0.15821416])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9420860539055039
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.05641979, 2.51715799]), 'currentState': array([5.62012489, 3.47225065]), 'targetState': array([-0.19349586, -0.04209377]), 'effectorPosition': array([-0.15714899, -0.2892168 ])}
episode index:857
target Thresh 1.6757412059977632
current state at start:  [ 0.07204778 -2.80751551]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.07204778, -2.80751551]), 'currentState': array([5.99547399, 3.97566979]), 'targetState': array([ 0.02068906, -0.99112966]), 'effectorPosition': array([ 0.10447739, -0.80334392])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9421535526771759
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.07204778, -2.80751551]), 'currentState': array([5.99547399, 3.97566979]), 'targetState': array([ 0.02068906, -0.99112966]), 'effectorPosition': array([ 0.10447739, -0.80334392])}
episode index:858
target Thresh 1.6763890755003086
current state at start:  [-1.32728368  2.14525176]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.32728368,  2.14525176]), 'currentState': array([4.65153659, 2.64525176]), 'targetState': array([0.10327228, 0.03856224]), 'effectorPosition': array([ 0.46799127, -0.14940641])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.942209252848681
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.32728368,  2.14525176]), 'currentState': array([4.31297752, 3.11623964]), 'targetState': array([0.10327228, 0.03856224]), 'effectorPosition': array([ 0.02323  , -0.0101542])}
episode index:859
target Thresh 1.6770356505587245
current state at start:  [ 2.89749181 -1.60286079]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.89749181, -1.60286079]), 'currentState': array([2.91771674, 4.23461571]), 'targetState': array([-0.15718292,  0.52909713]), 'effectorPosition': array([-0.32956611,  0.98578918])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9422648234849034
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 2.89749181, -1.60286079]), 'currentState': array([3.13158847, 3.9079602 ]), 'targetState': array([-0.15718292,  0.52909713]), 'effectorPosition': array([-0.27261339,  0.69628495])}
episode index:860
target Thresh 1.6776809337593122
current state at start:  [ 2.77201331 -2.36278148]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.77201331, -2.36278148]), 'currentState': array([2.30719918, 4.42040383]), 'targetState': array([0.26279148, 1.14611434]), 'effectorPosition': array([0.23123399, 1.17082151])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9423318794390441
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.77201331, -2.36278148]), 'currentState': array([2.30719918, 4.42040383]), 'targetState': array([0.26279148, 1.14611434]), 'effectorPosition': array([0.23123399, 1.17082151])}
episode index:861
target Thresh 1.678324927683205
current state at start:  [ 3.56250817 -2.811109  ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.56250817, -2.811109  ]), 'currentState': array([3.06250817, 3.9720763 ]), 'targetState': array([0.41264792, 1.10802965]), 'effectorPosition': array([-0.26614002,  0.76166392])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9423756939640567
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 3.56250817, -2.811109  ]), 'currentState': array([2.06404955, 4.44849785]), 'targetState': array([0.41264792, 1.10802965]), 'effectorPosition': array([0.50031781, 1.10815351])}
episode index:862
target Thresh 1.6789676349063798
current state at start:  [1.6203985  2.58221177]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.6203985 , 2.58221177]), 'currentState': array([1.14220212, 3.08221177]), 'targetState': array([0.16041291, 0.8988259 ]), 'effectorPosition': array([-0.05324571,  0.02626686])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9424080500544807
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([1.6203985 , 2.58221177]), 'currentState': array([2.45475505, 4.11395239]), 'targetState': array([0.16041291, 0.8988259 ]), 'effectorPosition': array([0.18625958, 0.91575351])}
episode index:863
target Thresh 1.679609057999666
current state at start:  [-0.35182381 -2.25948587]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.35182381, -2.25948587]), 'currentState': array([6.20493544, 3.52369944]), 'targetState': array([-0.05491909, -0.04590734]), 'effectorPosition': array([ 0.04275045, -0.37737269])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9424631333298806
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.35182381, -2.25948587]), 'currentState': array([6.22928033, 3.14165354]), 'targetState': array([-0.05491909, -0.04590734]), 'effectorPosition': array([-3.27868451e-06, -6.07988940e-05])}
episode index:864
target Thresh 1.680249199528757
current state at start:  [-1.35186942 -2.59421701]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.35186942, -2.59421701]), 'currentState': array([5.43131589, 3.34374961]), 'targetState': array([ 0.08187715, -0.4592942 ]), 'effectorPosition': array([-0.13768024, -0.1475554 ])}
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.9424086537008967
{'reset': False, 'endBeforeDone': False, 'stepCount': 12, 'initial state': array([-1.35186942, -2.59421701]), 'currentState': array([5.87284443, 3.68914455]), 'targetState': array([ 0.08187715, -0.4592942 ]), 'effectorPosition': array([-0.07361644, -0.53570281])}
episode index:865
target Thresh 1.68088806205422
current state at start:  [1.46739352 1.9157694 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.46739352, 1.9157694 ]), 'currentState': array([1.37399265, 1.9082218 ]), 'targetState': array([-0.79379764,  0.82556385]), 'effectorPosition': array([-0.79459332,  0.84053778])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9424751564102489
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.46739352, 1.9157694 ]), 'currentState': array([1.37399265, 1.9082218 ]), 'targetState': array([-0.79379764,  0.82556385]), 'effectorPosition': array([-0.79459332,  0.84053778])}
episode index:866
target Thresh 1.6815256481315055
current state at start:  [ 0.40637346 -2.62716684]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.40637346, -2.62716684]), 'currentState': array([0.90637346, 3.15601846]), 'targetState': array([0.51030168, 0.41390705]), 'effectorPosition': array([ 0.01142081, -0.0088128 ])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.9424849775100065
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([ 0.40637346, -2.62716684]), 'currentState': array([6.04084303, 2.2912964 ]), 'targetState': array([0.51030168, 0.41390705]), 'effectorPosition': array([0.51063418, 0.64786699])}
episode index:867
target Thresh 1.682161960310959
current state at start:  [-0.46782758  2.4028667 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.46782758,  2.4028667 ]), 'currentState': array([5.72254834, 1.98703531]), 'targetState': array([0.66088403, 0.49574501]), 'effectorPosition': array([0.9908133 , 0.45786695])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9425397183193268
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.46782758,  2.4028667 ]), 'currentState': array([5.73432362, 2.10477481]), 'targetState': array([0.66088403, 0.49574501]), 'effectorPosition': array([0.86800161, 0.4781728 ])}
episode index:868
target Thresh 1.68279700113783
current state at start:  [1.19408585 2.82932897]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.19408585, 2.82932897]), 'currentState': array([0.91979815, 3.05297866]), 'targetState': array([0.00092002, 0.01037346]), 'effectorPosition': array([-0.06802072,  0.0567493 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9426058406227568
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.19408585, 2.82932897]), 'currentState': array([0.91979815, 3.05297866]), 'targetState': array([0.00092002, 0.01037346]), 'effectorPosition': array([-0.06802072,  0.0567493 ])}
episode index:869
target Thresh 1.6834307731522826
current state at start:  [-0.07894793 -1.78973538]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.07894793, -1.78973538]), 'currentState': array([0.42105207, 4.14873624]), 'targetState': array([ 0.96028453, -0.50030639]), 'effectorPosition': array([ 0.77054158, -0.58112888])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9426718109208916
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.07894793, -1.78973538]), 'currentState': array([0.42105207, 4.14873624]), 'targetState': array([ 0.96028453, -0.50030639]), 'effectorPosition': array([ 0.77054158, -0.58112888])}
episode index:870
target Thresh 1.6840632788894057
current state at start:  [0.89881301 2.58443002]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.89881301, 2.58443002]), 'currentState': array([1.39881301, 2.91256629]), 'targetState': array([-0.77774901,  0.07719455]), 'effectorPosition': array([-0.21921138,  0.06457995])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9427261486810283
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.89881301, 2.58443002]), 'currentState': array([1.89881301, 2.41629381]), 'targetState': array([-0.77774901,  0.07719455]), 'effectorPosition': array([-0.7090797 ,  0.02456719])}
episode index:871
target Thresh 1.684694520879223
current state at start:  [-3.38403423  2.21845216]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.38403423,  2.21845216]), 'currentState': array([3.05162146, 2.71845216]), 'targetState': array([ 0.08543769, -0.22391291]), 'effectorPosition': array([-0.12473409, -0.40104073])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9427803618132748
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.38403423,  2.21845216]), 'currentState': array([3.2417376 , 3.12071258]), 'targetState': array([ 0.08543769, -0.22391291]), 'effectorPosition': array([ 0.0018705 , -0.02079574])}
episode index:872
target Thresh 1.6853245016467036
current state at start:  [1.39956197 2.48745704]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.39956197, 2.48745704]), 'currentState': array([1.89956197, 2.5302794 ]), 'targetState': array([-0.67332716, -0.07038915]), 'effectorPosition': array([-0.60167817, -0.01390667])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9428459054996284
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.39956197, 2.48745704]), 'currentState': array([1.89956197, 2.5302794 ]), 'targetState': array([-0.67332716, -0.07038915]), 'effectorPosition': array([-0.60167817, -0.01390667])}
episode index:873
target Thresh 1.685953223711771
current state at start:  [-3.64078809  1.97714051]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.64078809,  1.97714051]), 'currentState': array([2.17438074, 2.47714051]), 'targetState': array([-0.51956102,  0.16295264]), 'effectorPosition': array([-0.62842734, -0.17484173])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.9428335707655409
{'reset': False, 'endBeforeDone': False, 'stepCount': 8, 'initial state': array([-3.64078809,  1.97714051]), 'currentState': array([1.58269211, 2.78937065]), 'targetState': array([-0.51956102,  0.16295264]), 'effectorPosition': array([-0.34569012,  0.05728342])}
episode index:874
target Thresh 1.6865806895893147
current state at start:  [-1.25517478  2.47702243]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.25517478,  2.47702243]), 'currentState': array([5.18830677, 2.01056217]), 'targetState': array([ 1.10342774, -0.21275837]), 'effectorPosition': array([ 1.06740305, -0.09589333])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9428989038275231
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.25517478,  2.47702243]), 'currentState': array([5.18830677, 2.01056217]), 'targetState': array([ 1.10342774, -0.21275837]), 'effectorPosition': array([ 1.06740305, -0.09589333])}
episode index:875
target Thresh 1.6872069017891986
current state at start:  [0.24564943 1.68616236]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.24564943, 1.68616236]), 'currentState': array([0.61532226, 1.74700633]), 'targetState': array([-0.03581626,  1.2950894 ]), 'effectorPosition': array([0.10515656, 1.27997775])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9429640877272634
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.24564943, 1.68616236]), 'currentState': array([0.61532226, 1.74700633]), 'targetState': array([-0.03581626,  1.2950894 ]), 'effectorPosition': array([0.10515656, 1.27997775])}
episode index:876
target Thresh 1.687831862816273
current state at start:  [-2.52827764  2.43882888]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.52827764,  2.43882888]), 'currentState': array([3.26320506, 2.65839968]), 'targetState': array([-0.64795506, -0.23901799]), 'effectorPosition': array([-0.05727546, -0.4750659 ])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9430064319829905
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-2.52827764,  2.43882888]), 'currentState': array([2.4263815 , 2.51272143]), 'targetState': array([-0.64795506, -0.23901799]), 'effectorPosition': array([-0.53017801, -0.31863344])}
episode index:877
target Thresh 1.6884555751703823
current state at start:  [ 0.50697436 -2.81700294]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.50697436, -2.81700294]), 'currentState': array([0.84663608, 3.20623894]), 'targetState': array([0.8023289, 0.3726534]), 'effectorPosition': array([ 0.04977384, -0.04123411])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.9430155249418938
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([ 0.50697436, -2.81700294]), 'currentState': array([5.569579  , 2.17407557]), 'targetState': array([0.8023289, 0.3726534]), 'effectorPosition': array([0.86610961, 0.33935573])}
episode index:878
target Thresh 1.6890780413463768
current state at start:  [-3.74160194  2.43981063]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.74160194,  2.43981063]), 'currentState': array([2.04158337, 2.76428357]), 'targetState': array([-0.57746756,  0.10558831]), 'effectorPosition': array([-0.36024597, -0.10442254])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9430577143333136
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-3.74160194,  2.43981063]), 'currentState': array([1.63264994, 2.49461518]), 'targetState': array([-0.57746756,  0.10558831]), 'effectorPosition': array([-0.61411682,  0.16444399])}
episode index:879
target Thresh 1.6896992638341222
current state at start:  [-3.98763099  1.7101752 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.98763099,  1.7101752 ]), 'currentState': array([2.74226434, 2.0412256 ]), 'targetState': array([-0.63584583, -0.50094852]), 'effectorPosition': array([-0.85028129, -0.6086738 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9431224214761168
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.98763099,  1.7101752 ]), 'currentState': array([2.74226434, 2.0412256 ]), 'targetState': array([-0.63584583, -0.50094852]), 'effectorPosition': array([-0.85028129, -0.6086738 ])}
episode index:880
target Thresh 1.690319245118509
current state at start:  [-0.16692578 -2.35646968]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.16692578, -2.35646968]), 'currentState': array([5.61625952, 4.28100141]), 'targetState': array([-0.53043863, -1.02490809]), 'effectorPosition': array([-0.10471403, -1.07367204])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9431756309863595
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.16692578, -2.35646968]), 'currentState': array([5.11625952, 4.32732651]), 'targetState': array([-0.53043863, -1.02490809]), 'effectorPosition': array([-0.60684271, -0.9383538 ])}
episode index:881
target Thresh 1.6909379876794635
current state at start:  [-1.4417932   1.92098955]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.4417932 ,  1.92098955]), 'currentState': array([5.11885298, 2.25073025]), 'targetState': array([0.39705441, 0.24155259]), 'effectorPosition': array([ 0.86103996, -0.03356931])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9432063831054226
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-1.4417932 ,  1.92098955]), 'currentState': array([5.0375727 , 2.71724558]), 'targetState': array([0.39705441, 0.24155259]), 'effectorPosition': array([0.4184838, 0.0474953])}
episode index:882
target Thresh 1.6915554939919568
current state at start:  [-0.59641427  2.53880016]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.59641427,  2.53880016]), 'currentState': array([6.15832284, 2.49492615]), 'targetState': array([0.05582231, 1.04294769]), 'effectorPosition': array([0.27536934, 0.57269381])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9432593770090405
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.59641427,  2.53880016]), 'currentState': array([0.30517652, 2.08597401]), 'targetState': array([0.05582231, 1.04294769]), 'effectorPosition': array([0.2224065 , 0.98242374])}
episode index:883
target Thresh 1.6921717665260145
current state at start:  [-1.99494297  1.66281929]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.99494297,  1.66281929]), 'currentState': array([4.74187979, 2.07675704]), 'targetState': array([ 1.04324819, -0.57092329]), 'effectorPosition': array([ 0.88952487, -0.48933576])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9433235632341433
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.99494297,  1.66281929]), 'currentState': array([4.74187979, 2.07675704]), 'targetState': array([ 1.04324819, -0.57092329]), 'effectorPosition': array([ 0.88952487, -0.48933576])}
episode index:884
target Thresh 1.692786807746728
current state at start:  [ 3.52527446 -2.15422366]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.52527446, -2.15422366]), 'currentState': array([4.01702404, 3.64520207]), 'targetState': array([-0.20267171, -0.10899226]), 'effectorPosition': array([-0.45008315,  0.21385122])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.943376304970602
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.52527446, -2.15422366]), 'currentState': array([4.39400179, 3.4362524 ]), 'targetState': array([-0.20267171, -0.10899226]), 'effectorPosition': array([-0.28930999,  0.049977  ])}
episode index:885
target Thresh 1.693400620114263
current state at start:  [ 1.35453808 -2.2420762 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.35453808, -2.2420762 ]), 'currentState': array([1.85453808, 3.54110911]), 'targetState': array([0.2792965 , 0.20496689]), 'effectorPosition': array([0.35137344, 0.1844948 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9434402143329376
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.35453808, -2.2420762 ]), 'currentState': array([1.85453808, 3.54110911]), 'targetState': array([0.2792965 , 0.20496689]), 'effectorPosition': array([0.35137344, 0.1844948 ])}
episode index:886
target Thresh 1.6940132060838695
current state at start:  [ 1.4582862  -1.74317963]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.4582862 , -1.74317963]), 'currentState': array([1.47846772, 4.77822337]), 'targetState': array([1.02457794, 0.81162874]), 'effectorPosition': array([1.09184653, 0.96924963])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9435039795929907
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.4582862 , -1.74317963]), 'currentState': array([1.47846772, 4.77822337]), 'targetState': array([1.02457794, 0.81162874]), 'effectorPosition': array([1.09184653, 0.96924963])}
episode index:887
target Thresh 1.6946245681058925
current state at start:  [-1.29761634  2.80058898]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.29761634,  2.80058898]), 'currentState': array([4.61972639, 2.99552642]), 'targetState': array([0.16800754, 0.04415798]), 'effectorPosition': array([ 0.14393765, -0.02407054])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9435676012375932
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.29761634,  2.80058898]), 'currentState': array([4.61972639, 2.99552642]), 'targetState': array([0.16800754, 0.04415798]), 'effectorPosition': array([ 0.14393765, -0.02407054])}
episode index:888
target Thresh 1.6952347086257806
current state at start:  [-0.39089917 -2.75207028]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.39089917, -2.75207028]), 'currentState': array([5.39228614, 3.8826718 ]), 'targetState': array([-0.03481525, -0.84743175]), 'effectorPosition': array([-0.3600849 , -0.62837721])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9436198311574608
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.39089917, -2.75207028]), 'currentState': array([5.64225474, 4.12725004]), 'targetState': array([-0.03481525, -0.84743175]), 'effectorPosition': array([-0.13962812, -0.93588117])}
episode index:889
target Thresh 1.6958436300840969
current state at start:  [-1.26800179 -2.6290404 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.26800179, -2.6290404 ]), 'currentState': array([5.18959767, 3.67626385]), 'targetState': array([-0.16430702, -0.40017012]), 'effectorPosition': array([-0.38852868, -0.3580126 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9436831796617784
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.26800179, -2.6290404 ]), 'currentState': array([5.18959767, 3.67626385]), 'targetState': array([-0.16430702, -0.40017012]), 'effectorPosition': array([-0.38852868, -0.3580126 ])}
episode index:890
target Thresh 1.696451334916528
current state at start:  [-1.25347581  2.12205619]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.25347581,  2.12205619]), 'currentState': array([4.52970949, 2.51040778]), 'targetState': array([ 0.18945965, -0.61852253]), 'effectorPosition': array([ 0.54528111, -0.29666607])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9437351626251209
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.25347581,  2.12205619]), 'currentState': array([4.0919028 , 2.55840485]), 'targetState': array([ 0.18945965, -0.61852253]), 'effectorPosition': array([ 0.3519333 , -0.45466485])}
episode index:891
target Thresh 1.6970578255538942
current state at start:  [ 1.89005699 -1.73919444]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.89005699, -1.73919444]), 'currentState': array([1.857643  , 4.04399087]), 'targetState': array([0.3574386 , 0.34900111]), 'effectorPosition': array([0.6451589 , 0.58678002])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.943787029034734
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.89005699, -1.73919444]), 'currentState': array([1.73056492, 3.54399087]), 'targetState': array([0.3574386 , 0.34900111]), 'effectorPosition': array([0.37393104, 0.14116198])}
episode index:892
target Thresh 1.6976631044221584
current state at start:  [-1.03766579 -1.85760971]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.03766579, -1.85760971]), 'currentState': array([5.65870306, 3.9255756 ]), 'targetState': array([ 0.17881631, -0.48842889]), 'effectorPosition': array([-0.17604076, -0.74350258])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.9437739028520602
{'reset': False, 'endBeforeDone': False, 'stepCount': 8, 'initial state': array([-1.03766579, -1.85760971]), 'currentState': array([5.99002438, 3.65884034]), 'targetState': array([ 0.17881631, -0.48842889]), 'effectorPosition': array([-0.01766224, -0.51119578])}
episode index:893
target Thresh 1.6982671739424373
current state at start:  [-1.99655359  2.05549483]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.99655359,  2.05549483]), 'currentState': array([4.78663172, 2.1430018 ]), 'targetState': array([ 1.27918575, -0.57585671]), 'effectorPosition': array([ 0.87240282, -0.3948902 ])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9438145360703465
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.99655359,  2.05549483]), 'currentState': array([4.99050306, 1.567856  ]), 'targetState': array([ 1.27918575, -0.57585671]), 'effectorPosition': array([ 1.23692068, -0.68986076])}
episode index:894
target Thresh 1.6988700365310097
current state at start:  [ 2.2569362  -2.33817789]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.2569362 , -2.33817789]), 'currentState': array([2.7569362 , 3.44500741]), 'targetState': array([-0.39199115, -0.02796877]), 'effectorPosition': array([0.06977431, 0.29408836])}
done in step count: 46
reward sum = 0.6298236312032323
running average episode reward sum: 0.9434637082436793
{'reset': False, 'endBeforeDone': False, 'stepCount': 47, 'initial state': array([ 2.2569362 , -2.33817789]), 'currentState': array([4.01210978, 3.53663597]), 'targetState': array([-0.39199115, -0.02796877]), 'effectorPosition': array([-0.34391305,  0.1891138 ])}
episode index:895
target Thresh 1.6994716945993267
current state at start:  [-2.12032758 -1.97127151]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.12032758, -1.97127151]), 'currentState': array([3.67789118, 4.79223038]), 'targetState': array([-1.35132302,  0.36201695]), 'effectorPosition': array([-1.43749507,  0.30515753])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9435268067835859
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.12032758, -1.97127151]), 'currentState': array([3.67789118, 4.79223038]), 'targetState': array([-1.35132302,  0.36201695]), 'effectorPosition': array([-1.43749507,  0.30515753])}
episode index:896
target Thresh 1.7000721505540215
current state at start:  [-0.25191685 -2.06411487]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.25191685, -2.06411487]), 'currentState': array([0.10421062, 3.9726285 ]), 'targetState': array([-0.00384217, -0.23715765]), 'effectorPosition': array([ 0.40095488, -0.70072331])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9435458359956443
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([-0.25191685, -2.06411487]), 'currentState': array([1.96986216, 3.07977195]), 'targetState': array([-0.00384217, -0.23715765]), 'effectorPosition': array([-0.05766908, -0.02224543])}
episode index:897
target Thresh 1.7006714067969184
current state at start:  [-1.5843877  -2.68940704]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.5843877 , -2.68940704]), 'currentState': array([4.59636999, 3.66834294]), 'targetState': array([-0.37467   ,  0.08491252]), 'effectorPosition': array([-0.5150388 , -0.07644827])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9436087025479877
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.5843877 , -2.68940704]), 'currentState': array([4.59636999, 3.66834294]), 'targetState': array([-0.37467   ,  0.08491252]), 'effectorPosition': array([-0.5150388 , -0.07644827])}
episode index:898
target Thresh 1.7012694657250436
current state at start:  [-1.62109778  2.92804536]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.62109778,  2.92804536]), 'currentState': array([5.05792716, 2.5691815 ]), 'targetState': array([ 0.75557528, -0.15698924]), 'effectorPosition': array([0.56363483, 0.03348122])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9436603057709599
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.62109778,  2.92804536]), 'currentState': array([4.82804471, 2.33818988]), 'targetState': array([ 0.75557528, -0.15698924]), 'effectorPosition': array([ 0.75019605, -0.22064118])}
episode index:899
target Thresh 1.7018663297306331
current state at start:  [-1.93781275  1.62266325]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.93781275,  1.62266325]), 'currentState': array([4.67274868, 1.82371921]), 'targetState': array([ 0.60310366, -0.93478868]), 'effectorPosition': array([ 0.93771144, -0.78754519])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9437117943201033
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.93781275,  1.62266325]), 'currentState': array([4.17274868, 1.87617862]), 'targetState': array([ 0.60310366, -0.93478868]), 'effectorPosition': array([ 0.4588594 , -1.09001488])}
episode index:900
target Thresh 1.7024620012011442
current state at start:  [-0.97703764  2.70593756]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.97703764,  2.70593756]), 'currentState': array([4.95142469, 3.13517352]), 'targetState': array([-0.17163027,  0.21023624]), 'effectorPosition': array([0.00624145, 0.0014998 ])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9437521807858967
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-0.97703764,  2.70593756]), 'currentState': array([4.69920116, 3.22826176]), 'targetState': array([-0.17163027,  0.21023624]), 'effectorPosition': array([-0.08660262, -0.00261158])}
episode index:901
target Thresh 1.7030564825192633
current state at start:  [-3.76316722  2.93351463]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.76316722,  2.93351463]), 'currentState': array([3.00097601, 3.32782573]), 'targetState': array([ 0.46389896, -0.39086236]), 'effectorPosition': array([0.00882999, 0.18575431])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.943781611849327
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-3.76316722,  2.93351463]), 'currentState': array([4.36898191, 2.50081488]), 'targetState': array([ 0.46389896, -0.39086236]), 'effectorPosition': array([ 0.49612396, -0.38807081])}
episode index:902
target Thresh 1.7036497760629168
current state at start:  [ 2.59071555 -2.21225181]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.59071555, -2.21225181]), 'currentState': array([3.09071555, 3.5709335 ]), 'targetState': array([-0.55428466,  0.04936436]), 'effectorPosition': array([-0.06947267,  0.42034852])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.9437895946157175
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([ 2.59071555, -2.21225181]), 'currentState': array([4.04387585, 3.60159363]), 'targetState': array([-0.55428466,  0.04936436]), 'effectorPosition': array([-0.41281535,  0.19359586])}
episode index:903
target Thresh 1.7042418842052791
current state at start:  [ 1.03082044 -2.06400453]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.03082044, -2.06400453]), 'currentState': array([1.53082044, 3.71918078]), 'targetState': array([0.52911106, 0.24455355]), 'effectorPosition': array([0.55205176, 0.1402672 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9438517742676914
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.03082044, -2.06400453]), 'currentState': array([1.53082044, 3.71918078]), 'targetState': array([0.52911106, 0.24455355]), 'effectorPosition': array([0.55205176, 0.1402672 ])}
episode index:904
target Thresh 1.7048328093147842
current state at start:  [ 1.55970209 -2.57484035]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.55970209, -2.57484035]), 'currentState': array([1.28221002, 3.97879119]), 'targetState': array([1.06738626, 0.37342056]), 'effectorPosition': array([0.8061009, 0.1053981])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9439027667823127
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.55970209, -2.57484035]), 'currentState': array([1.30332788, 4.20261617]), 'targetState': array([1.06738626, 0.37342056]), 'effectorPosition': array([0.97714175, 0.26312753])}
episode index:905
target Thresh 1.7054225537551326
current state at start:  [-2.31561733  2.44568025]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.31561733,  2.44568025]), 'currentState': array([4.01880488, 1.94568025]), 'targetState': array([ 0.15453728, -1.30630919]), 'effectorPosition': array([ 0.31034619, -1.08229211])}
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.9438491635676067
{'reset': False, 'endBeforeDone': False, 'stepCount': 12, 'initial state': array([-2.31561733,  2.44568025]), 'currentState': array([5.56488111, 4.77719683]), 'targetState': array([ 0.15453728, -1.30630919]), 'effectorPosition': array([ 0.14495675, -1.45207181])}
episode index:906
target Thresh 1.7060111198853036
current state at start:  [-0.29514209 -1.8819717 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.29514209, -1.8819717 ]), 'currentState': array([0.18769278, 4.01547791]), 'targetState': array([ 0.30355053, -0.61513792]), 'effectorPosition': array([ 0.4949425 , -0.68653316])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9439110718767935
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.29514209, -1.8819717 ]), 'currentState': array([0.18769278, 4.01547791]), 'targetState': array([ 0.30355053, -0.61513792]), 'effectorPosition': array([ 0.4949425 , -0.68653316])}
episode index:907
target Thresh 1.706598510059562
current state at start:  [0.31274785 1.94031555]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.31274785, 1.94031555]), 'currentState': array([0.01105271, 2.07412221]), 'targetState': array([0.25951823, 0.9319047 ]), 'effectorPosition': array([0.50794497, 0.8816511 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9439618306082067
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.31274785, 1.94031555]), 'currentState': array([0.31971539, 2.21393507]), 'targetState': array([0.25951823, 0.9319047 ]), 'effectorPosition': array([0.12849977, 0.88547596])}
episode index:908
target Thresh 1.7071847266274696
current state at start:  [ 0.83193989 -2.63031048]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.83193989, -2.63031048]), 'currentState': array([1.05022797, 3.69385597]), 'targetState': array([ 0.4506016 , -0.22939468]), 'effectorPosition': array([ 0.52906294, -0.13196112])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9440234787593529
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.83193989, -2.63031048]), 'currentState': array([1.05022797, 3.69385597]), 'targetState': array([ 0.4506016 , -0.22939468]), 'effectorPosition': array([ 0.52906294, -0.13196112])}
episode index:909
target Thresh 1.7077697719338931
current state at start:  [ 1.31730733 -2.53477139]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.31730733, -2.53477139]), 'currentState': array([0.98384515, 4.24841392]), 'targetState': array([ 0.83905256, -0.03080004]), 'effectorPosition': array([ 1.05059244, -0.03525066])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9440849914200569
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.31730733, -2.53477139]), 'currentState': array([0.98384515, 4.24841392]), 'targetState': array([ 0.83905256, -0.03080004]), 'effectorPosition': array([ 1.05059244, -0.03525066])}
episode index:910
target Thresh 1.7083536483190147
current state at start:  [-2.35854636  2.05836065]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.35854636,  2.05836065]), 'currentState': array([3.42767726, 2.13341355]), 'targetState': array([-0.0349726 , -0.85476259]), 'effectorPosition': array([-0.20893314, -0.94315602])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9441463690365003
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.35854636,  2.05836065]), 'currentState': array([3.42767726, 2.13341355]), 'targetState': array([-0.0349726 , -0.85476259]), 'effectorPosition': array([-0.20893314, -0.94315602])}
episode index:911
target Thresh 1.7089363581183408
current state at start:  [1.54683713 2.31896024]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.54683713, 2.31896024]), 'currentState': array([1.20916936, 2.02968429]), 'targetState': array([-0.812416  ,  1.11929041]), 'effectorPosition': array([-0.64147744,  0.83821472])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9441966471406269
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.54683713, 2.31896024]), 'currentState': array([1.44832364, 1.7510256 ]), 'targetState': array([-0.812416  ,  1.11929041]), 'effectorPosition': array([-0.87616581,  0.9347851 ])}
episode index:912
target Thresh 1.709517903662711
current state at start:  [-1.35360351  2.64231741]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.35360351,  2.64231741]), 'currentState': array([4.4295818 , 3.14231741]), 'targetState': array([-0.10506295, -0.52570632]), 'effectorPosition': array([-0.00069604,  0.00020199])}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.944163044293248
{'reset': False, 'endBeforeDone': False, 'stepCount': 10, 'initial state': array([-1.35360351,  2.64231741]), 'currentState': array([3.41784314, 2.73300901]), 'targetState': array([-0.10506295, -0.52570632]), 'effectorPosition': array([ 0.02917186, -0.40469748])}
episode index:913
target Thresh 1.710098287278309
current state at start:  [ 0.81765946 -2.87250887]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.81765946, -2.87250887]), 'currentState': array([0.31765946, 3.91067643]), 'targetState': array([ 0.72493992, -0.85852667]), 'effectorPosition': array([ 0.48459863, -0.57277203])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.944213194135378
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.81765946, -2.87250887]), 'currentState': array([6.2662105 , 4.41067643]), 'targetState': array([ 0.72493992, -0.85852667]), 'effectorPosition': array([ 0.68653565, -0.96662151])}
episode index:914
target Thresh 1.7106775112866694
current state at start:  [0.68518743 1.79707604]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.68518743, 1.79707604]), 'currentState': array([0.24858973, 2.15340426]), 'targetState': array([0.10704911, 1.02567614]), 'effectorPosition': array([0.23052125, 0.92002877])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9442741633221152
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.68518743, 1.79707604]), 'currentState': array([0.24858973, 2.15340426]), 'targetState': array([0.10704911, 1.02567614]), 'effectorPosition': array([0.23052125, 0.92002877])}
episode index:915
target Thresh 1.711255578004689
current state at start:  [ 1.15056773 -1.75435417]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.15056773, -1.75435417]), 'currentState': array([0.86856456, 5.02883114]), 'targetState': array([1.35798159, 0.18338771]), 'effectorPosition': array([1.57242463, 0.38711172])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9442919819320256
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([ 1.15056773, -1.75435417]), 'currentState': array([0.79765008, 4.91657381]), 'targetState': array([1.35798159, 0.18338771]), 'effectorPosition': array([1.54085149, 0.17695954])}
episode index:916
target Thresh 1.7118324897446358
current state at start:  [ 4.13357058 -2.70661622]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.13357058, -2.70661622]), 'currentState': array([4.24269077, 4.07656909]), 'targetState': array([-0.87074041,  0.00509335]), 'effectorPosition': array([-0.90128867,  0.00199185])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9443527322243571
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.13357058, -2.70661622]), 'currentState': array([4.24269077, 4.07656909]), 'targetState': array([-0.87074041,  0.00509335]), 'effectorPosition': array([-0.90128867,  0.00199185])}
episode index:917
target Thresh 1.7124082488141572
current state at start:  [-1.53564562 -1.93701343]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.53564562, -1.93701343]), 'currentState': array([5.24753969, 4.04194548]), 'targetState': array([-0.09098345, -0.89484806]), 'effectorPosition': array([-0.4808912 , -0.72531135])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9444024569169231
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.53564562, -1.93701343]), 'currentState': array([5.74753969, 4.25849854]), 'targetState': array([-0.09098345, -0.89484806]), 'effectorPosition': array([ 0.02416796, -1.05947401])}
episode index:918
target Thresh 1.7129828575162906
current state at start:  [0.24715639 2.68248371]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.24715639, 2.68248371]), 'currentState': array([6.09764229, 3.18248371]), 'targetState': array([-0.03591241, -0.38389636]), 'effectorPosition': array([-0.00671992, -0.04033223])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9444520733947067
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.24715639, 2.68248371]), 'currentState': array([5.68394797, 3.68248371]), 'targetState': array([-0.03591241, -0.38389636]), 'effectorPosition': array([-0.17253233, -0.50569968])}
episode index:919
target Thresh 1.7135563181494713
current state at start:  [-0.344263   -1.79886053]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.344263  , -1.79886053]), 'currentState': array([6.02155188, 4.11429271]), 'targetState': array([-0.20278422, -0.38909893]), 'effectorPosition': array([ 0.20830259, -0.91130103])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9444908211410168
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-0.344263  , -1.79886053]), 'currentState': array([5.83410491, 3.6062369 ]), 'targetState': array([-0.20278422, -0.38909893]), 'effectorPosition': array([-0.09903217, -0.44970052])}
episode index:920
target Thresh 1.7141286330075427
current state at start:  [1.22587819 2.03653107]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.22587819, 2.03653107]), 'currentState': array([1.50229005, 2.05792839]), 'targetState': array([-0.74036297,  0.95916273]), 'effectorPosition': array([-0.84519572,  0.59114907])}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9444472720138375
{'reset': False, 'endBeforeDone': False, 'stepCount': 11, 'initial state': array([1.22587819, 2.03653107]), 'currentState': array([1.41325341, 1.92269034]), 'targetState': array([-0.74036297,  0.95916273]), 'effectorPosition': array([-0.82428117,  0.79448587])}
episode index:921
target Thresh 1.714699804379765
current state at start:  [ 2.28183664 -2.51823505]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.28183664, -2.51823505]), 'currentState': array([1.78183664, 3.34636126]), 'targetState': array([0.38289888, 0.1612622 ]), 'effectorPosition': array([0.19445281, 0.06302365])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9445075244303083
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.28183664, -2.51823505]), 'currentState': array([1.78183664, 3.34636126]), 'targetState': array([0.38289888, 0.1612622 ]), 'effectorPosition': array([0.19445281, 0.06302365])}
episode index:922
target Thresh 1.7152698345508244
current state at start:  [1.25992991 2.37230741]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.25992991, 2.37230741]), 'currentState': array([0.75992991, 2.87230741]), 'targetState': array([ 0.10428836, -0.14062223]), 'effectorPosition': array([-0.15714498,  0.21767604])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9445568120528107
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.25992991, 2.37230741]), 'currentState': array([0.29701431, 3.3536755 ]), 'targetState': array([ 0.10428836, -0.14062223]), 'effectorPosition': array([ 0.08302966, -0.19472254])}
episode index:923
target Thresh 1.7158387258008423
current state at start:  [ 0.61717363 -2.04773715]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.61717363, -2.04773715]), 'currentState': array([1.06673641, 3.73544816]), 'targetState': array([0.16651414, 0.04967661]), 'effectorPosition': array([ 0.57265946, -0.12034217])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9446059929921475
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.61717363, -2.04773715]), 'currentState': array([1.55412982, 3.343565  ]), 'targetState': array([0.16651414, 0.04967661]), 'effectorPosition': array([0.20091288, 0.01698117])}
episode index:924
target Thresh 1.7164064804053845
current state at start:  [-0.33919132  2.05819537]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.33919132,  2.05819537]), 'currentState': array([6.12415251, 2.55819537]), 'targetState': array([0.12998549, 0.69926781]), 'effectorPosition': array([0.25055311, 0.51771718])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.944665878405129
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.33919132,  2.05819537]), 'currentState': array([6.12415251, 2.55819537]), 'targetState': array([0.12998549, 0.69926781]), 'effectorPosition': array([0.25055311, 0.51771718])}
episode index:925
target Thresh 1.7169731006354703
current state at start:  [-1.9307958   2.62694608]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.9307958 ,  2.62694608]), 'currentState': array([3.85238951, 3.07607491]), 'targetState': array([0.09042535, 0.01284924]), 'effectorPosition': array([ 0.04108971, -0.05101641])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9447256344759658
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.9307958 ,  2.62694608]), 'currentState': array([3.85238951, 3.07607491]), 'targetState': array([0.09042535, 0.01284924]), 'effectorPosition': array([ 0.04108971, -0.05101641])}
episode index:926
target Thresh 1.7175385887575811
current state at start:  [-0.06653844  1.79138574]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.06653844,  1.79138574]), 'currentState': array([0.35056488, 1.92287245]), 'targetState': array([0.5007302 , 1.12025005]), 'effectorPosition': array([0.29294347, 1.10656653])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9447852616232408
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.06653844,  1.79138574]), 'currentState': array([0.35056488, 1.92287245]), 'targetState': array([0.5007302 , 1.12025005]), 'effectorPosition': array([0.29294347, 1.10656653])}
episode index:927
target Thresh 1.7181029470336706
current state at start:  [-2.11901312 -1.70046969]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.11901312, -1.70046969]), 'currentState': array([3.66796998, 4.09174113]), 'targetState': array([-0.45104095,  0.21764873]), 'effectorPosition': array([-0.77050183,  0.49315546])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9448339844016641
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.11901312, -1.70046969]), 'currentState': array([3.82411655, 3.88279532]), 'targetState': array([-0.45104095,  0.21764873]), 'effectorPosition': array([-0.62944307,  0.35845119])}
episode index:928
target Thresh 1.7186661777211723
current state at start:  [ 1.61213238 -2.0683999 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.61213238, -2.0683999 ]), 'currentState': array([1.57291217, 3.97449315]), 'targetState': array([0.59407632, 0.5451791 ]), 'effectorPosition': array([0.73919164, 0.32883219])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9448826022871306
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.61213238, -2.0683999 ]), 'currentState': array([1.68699698, 4.20310599]), 'targetState': array([0.59407632, 0.5451791 ]), 'effectorPosition': array([0.80779347, 0.61021882])}
episode index:929
target Thresh 1.7192282830730097
current state at start:  [-0.35153364  2.31560222]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.35153364,  2.31560222]), 'currentState': array([5.43165167, 2.71550725]), 'targetState': array([ 0.072129  , -0.06214877]), 'effectorPosition': array([0.36983479, 0.20503879])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9449311156180047
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.35153364,  2.31560222]), 'currentState': array([4.93165167, 3.09404991]), 'targetState': array([ 0.072129  , -0.06214877]), 'effectorPosition': array([0.04663277, 0.00923424])}
episode index:930
target Thresh 1.7197892653376048
current state at start:  [-0.70114349 -1.78280954]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.70114349, -1.78280954]), 'currentState': array([5.08204182, 4.03899171]), 'targetState': array([-0.7464951 , -0.46112528]), 'effectorPosition': array([-0.5929315 , -0.63335751])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9449902658697577
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.70114349, -1.78280954]), 'currentState': array([5.08204182, 4.03899171]), 'targetState': array([-0.7464951 , -0.46112528]), 'effectorPosition': array([-0.5929315 , -0.63335751])}
episode index:931
target Thresh 1.720349126758888
current state at start:  [-2.20121512  1.70255292]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.20121512,  1.70255292]), 'currentState': array([4.49744877, 2.19643227]), 'targetState': array([ 0.62178208, -0.52791799]), 'effectorPosition': array([ 0.70355426, -0.57774185])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9450492891896398
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.20121512,  1.70255292]), 'currentState': array([4.49744877, 2.19643227]), 'targetState': array([ 0.62178208, -0.52791799]), 'effectorPosition': array([ 0.70355426, -0.57774185])}
episode index:932
target Thresh 1.7209078695763051
current state at start:  [1.50859302 1.80302593]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.50859302, 1.80302593]), 'currentState': array([1.42580106, 1.81689961]), 'targetState': array([-0.95876704,  0.99864571]), 'effectorPosition': array([-0.85040519,  0.88857076])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9451081859857924
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.50859302, 1.80302593]), 'currentState': array([1.42580106, 1.81689961]), 'targetState': array([-0.95876704,  0.99864571]), 'effectorPosition': array([-0.85040519,  0.88857076])}
episode index:933
target Thresh 1.7214654960248286
current state at start:  [-3.33274157  1.9881345 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.33274157,  1.9881345 ]), 'currentState': array([2.45044374, 2.3749229 ]), 'targetState': array([-0.77813588, -0.17499066]), 'effectorPosition': array([-0.65777671, -0.35620195])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9451669566646085
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.33274157,  1.9881345 ]), 'currentState': array([2.45044374, 2.3749229 ]), 'targetState': array([-0.77813588, -0.17499066]), 'effectorPosition': array([-0.65777671, -0.35620195])}
episode index:934
target Thresh 1.7220220083349647
current state at start:  [ 2.26030465 -1.58629914]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.26030465, -1.58629914]), 'currentState': array([1.76030465, 4.22888197]), 'targetState': array([0.3363666 , 0.57059162]), 'effectorPosition': array([0.76871674, 0.69231533])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9451834583259298
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([ 2.26030465, -1.58629914]), 'currentState': array([2.00686253, 4.01625349]), 'targetState': array([0.3363666 , 0.57059162]), 'effectorPosition': array([0.54399509, 0.6492727 ])}
episode index:935
target Thresh 1.7225774087327634
current state at start:  [ 2.85484326 -2.42820191]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.85484326, -2.42820191]), 'currentState': array([3.35484326, 3.43845484]), 'targetState': array([-0.50899456,  0.25991687]), 'effectorPosition': array([-0.10465869,  0.2766377 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9452313392465217
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 2.85484326, -2.42820191]), 'currentState': array([3.80949176, 3.62448924]), 'targetState': array([-0.50899456,  0.25991687]), 'effectorPosition': array([-0.37736352,  0.29375079])}
episode index:936
target Thresh 1.7231316994398274
current state at start:  [ 4.13732493 -1.99711486]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.13732493, -1.99711486]), 'currentState': array([3.72941089, 4.55062852]), 'targetState': array([-1.18038928,  0.2802427 ]), 'effectorPosition': array([-1.24543678,  0.3560553 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9452897903252341
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.13732493, -1.99711486]), 'currentState': array([3.72941089, 4.55062852]), 'targetState': array([-1.18038928,  0.2802427 ]), 'effectorPosition': array([-1.24543678,  0.3560553 ])}
episode index:937
target Thresh 1.7236848826733198
current state at start:  [-0.04718116 -1.93865993]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.04718116, -1.93865993]), 'currentState': array([6.0336212 , 4.13150971]), 'targetState': array([ 0.17650671, -0.86739269]), 'effectorPosition': array([ 0.23078964, -0.9215301 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9453481167747808
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.04718116, -1.93865993]), 'currentState': array([6.0336212 , 4.13150971]), 'targetState': array([ 0.17650671, -0.86739269]), 'effectorPosition': array([ 0.23078964, -0.9215301 ])}
episode index:938
target Thresh 1.7242369606459744
current state at start:  [-3.70369129  1.68494554]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.70369129,  1.68494554]), 'currentState': array([2.07949402, 2.09826454]), 'targetState': array([-0.60671683,  0.41582029]), 'effectorPosition': array([-0.99656332,  0.01292253])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9453851262350845
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-3.70369129,  1.68494554]), 'currentState': array([1.66608842, 2.35276679]), 'targetState': array([-0.60671683,  0.41582029]), 'effectorPosition': array([-0.73440655,  0.22647132])}
episode index:939
target Thresh 1.724787935566104
current state at start:  [-3.21284339  2.03591719]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.21284339,  2.03591719]), 'currentState': array([3.12171292, 2.49489101]), 'targetState': array([ 0.17618356, -0.03031529]), 'effectorPosition': array([-0.2138624 , -0.59842435])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9454220569518557
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-3.21284339,  2.03591719]), 'currentState': array([3.02457375, 3.27137532]), 'targetState': array([ 0.17618356, -0.03031529]), 'effectorPosition': array([0.00675745, 0.12951544])}
episode index:940
target Thresh 1.725337809637609
current state at start:  [ 0.68316293 -2.32660636]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.68316293, -2.32660636]), 'currentState': array([0.6149111 , 3.51780761]), 'targetState': array([-0.01004525, -0.6735421 ]), 'effectorPosition': array([ 0.26907664, -0.2597574 ])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9454589091761364
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 0.68316293, -2.32660636]), 'currentState': array([6.07159194, 3.94399077]), 'targetState': array([-0.01004525, -0.6735421 ]), 'effectorPosition': array([ 0.14720484, -0.76704754])}
episode index:941
target Thresh 1.7258865850599863
current state at start:  [0.24032424 2.46375705]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.24032424, 2.46375705]), 'currentState': array([6.02350955, 2.84850581]), 'targetState': array([ 0.60991355, -0.08421583]), 'effectorPosition': array([0.11539599, 0.26827322])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9454956831579027
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([0.24032424, 2.46375705]), 'currentState': array([5.06631251, 2.6326275 ]), 'targetState': array([ 0.60991355, -0.08421583]), 'effectorPosition': array([0.50100204, 0.04998499])}
episode index:942
target Thresh 1.7264342640283383
current state at start:  [ 2.0821826  -2.68446656]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.0821826 , -2.68446656]), 'currentState': array([2.42240901, 3.16937129]), 'targetState': array([-0.39215972,  0.18009263]), 'effectorPosition': array([0.01800714, 0.02115055])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9455116962298455
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([ 2.0821826 , -2.68446656]), 'currentState': array([1.60114353, 2.86275565]), 'targetState': array([-0.39215972,  0.18009263]), 'effectorPosition': array([-0.27628297,  0.03025461])}
episode index:943
target Thresh 1.7269808487333818
current state at start:  [-3.38158948  2.32186765]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.38158948,  2.32186765]), 'currentState': array([3.22549938, 2.74540389]), 'targetState': array([ 0.32489765, -0.60011554]), 'effectorPosition': array([-0.04484696, -0.3910394 ])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9455483363821444
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-3.38158948,  2.32186765]), 'currentState': array([3.67520342, 2.62697741]), 'targetState': array([ 0.32489765, -0.60011554]), 'effectorPosition': array([ 0.1388435 , -0.48965106])}
episode index:944
target Thresh 1.727526341361456
current state at start:  [0.9174995  2.84969543]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.9174995 , 2.84969543]), 'currentState': array([0.42322283, 3.00848322]), 'targetState': array([0.02415614, 0.24853924]), 'effectorPosition': array([-0.04644138,  0.12464018])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9456059571902057
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.9174995 , 2.84969543]), 'currentState': array([0.42322283, 3.00848322]), 'targetState': array([0.02415614, 0.24853924]), 'effectorPosition': array([-0.04644138,  0.12464018])}
episode index:945
target Thresh 1.7280707440945324
current state at start:  [1.29460257 1.58101876]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.29460257, 1.58101876]), 'currentState': array([0.79460257, 1.99246802]), 'targetState': array([-0.28861618,  0.88580559]), 'effectorPosition': array([-0.23724409,  1.06072743])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9456634561783767
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.29460257, 1.58101876]), 'currentState': array([0.79460257, 1.99246802]), 'targetState': array([-0.28861618,  0.88580559]), 'effectorPosition': array([-0.23724409,  1.06072743])}
episode index:946
target Thresh 1.7286140591102228
current state at start:  [-0.79933992 -2.03307244]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.79933992, -2.03307244]), 'currentState': array([5.85603422, 3.8461226 ]), 'targetState': array([ 0.58693685, -0.53454061]), 'effectorPosition': array([-0.05162682, -0.68811519])}
done in step count: 19
reward sum = 0.8261686238355866
running average episode reward sum: 0.9455372736732628
{'reset': False, 'endBeforeDone': False, 'stepCount': 20, 'initial state': array([-0.79933992, -2.03307244]), 'currentState': array([4.26228282, 2.34432579]), 'targetState': array([ 0.58693685, -0.53454061]), 'effectorPosition': array([ 0.51309188, -0.5825867 ])}
episode index:947
target Thresh 1.7291562885817875
current state at start:  [0.94826315 2.03442802]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.94826315, 2.03442802]), 'currentState': array([0.53703259, 2.45309895]), 'targetState': array([-0.38154086,  0.49521607]), 'effectorPosition': array([-0.12932112,  0.66247124])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9455737322453375
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([0.94826315, 2.03442802]), 'currentState': array([1.12698692, 2.32538622]), 'targetState': array([-0.38154086,  0.49521607]), 'effectorPosition': array([-0.52271225,  0.5973207 ])}
episode index:948
target Thresh 1.7296974346781455
current state at start:  [ 3.04731364 -1.95867401]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.04731364, -1.95867401]), 'currentState': array([2.72194443, 3.8245113 ]), 'targetState': array([0.33163332, 0.35538033]), 'effectorPosition': array([0.05231172, 0.6676789 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9456205460153634
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.04731364, -1.95867401]), 'currentState': array([2.52786867, 3.43097941]), 'targetState': array([0.33163332, 0.35538033]), 'effectorPosition': array([0.13035316, 0.2572352 ])}
episode index:949
target Thresh 1.730237499563882
current state at start:  [-2.76395202  2.51974283]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.76395202,  2.51974283]), 'currentState': array([4.01923329, 2.01974283]), 'targetState': array([ 0.55677928, -1.25660507]), 'effectorPosition': array([ 0.33136101, -1.01102252])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.945667261230084
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.76395202,  2.51974283]), 'currentState': array([4.47714555, 1.51974283]), 'targetState': array([ 0.55677928, -1.25660507]), 'effectorPosition': array([ 0.72621649, -1.25485946])}
episode index:950
target Thresh 1.7307764853992569
current state at start:  [1.05958733 2.24060465]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.05958733, 2.24060465]), 'currentState': array([0.66414341, 2.57780079]), 'targetState': array([ 0.08776504, -0.06207579]), 'effectorPosition': array([-0.20752394,  0.51620164])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9457138782003994
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.05958733, 2.24060465]), 'currentState': array([0.254839  , 3.03800047]), 'targetState': array([ 0.08776504, -0.06207579]), 'effectorPosition': array([-0.02088009,  0.10141878])}
episode index:951
target Thresh 1.7313143943402145
current state at start:  [ 3.55414118 -2.1832308 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.55414118, -2.1832308 ]), 'currentState': array([4.05414118, 3.59995451]), 'targetState': array([-0.19757119, -0.24142031]), 'effectorPosition': array([-0.41317414,  0.18902391])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9457397029081721
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 3.55414118, -2.1832308 ]), 'currentState': array([5.08119588, 3.64364375]), 'targetState': array([-0.19757119, -0.24142031]), 'effectorPosition': array([-0.4043791 , -0.28858761])}
episode index:952
target Thresh 1.7318512285383911
current state at start:  [-3.98594373  1.75980485]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.98594373,  1.75980485]), 'currentState': array([2.44748021, 2.20009393]), 'targetState': array([-0.76480415, -0.16520262]), 'effectorPosition': array([-0.83339125, -0.35819676])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9457966392115214
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.98594373,  1.75980485]), 'currentState': array([2.44748021, 2.20009393]), 'targetState': array([-0.76480415, -0.16520262]), 'effectorPosition': array([-0.83339125, -0.35819676])}
episode index:953
target Thresh 1.7323869901411244
current state at start:  [-3.06773545  2.91049851]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.06773545,  2.91049851]), 'currentState': array([3.71544986, 2.41049851]), 'targetState': array([-0.37948318, -0.95192413]), 'effectorPosition': array([ 0.14785048, -0.69946525])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9458429739712577
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.06773545,  2.91049851]), 'currentState': array([3.32263028, 1.97610358]), 'targetState': array([-0.37948318, -0.95192413]), 'effectorPosition': array([-0.43033727, -1.01301903])}
episode index:954
target Thresh 1.7329216812914614
current state at start:  [ 1.82234386 -2.89224457]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.82234386, -2.89224457]), 'currentState': array([1.60349411, 3.89094074]), 'targetState': array([0.93335123, 0.58294325]), 'effectorPosition': array([0.67204042, 0.28999224])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9458892116948481
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.82234386, -2.89224457]), 'currentState': array([1.38813702, 4.39094074]), 'targetState': array([0.93335123, 0.58294325]), 'effectorPosition': array([1.05725118, 0.50033792])}
episode index:955
target Thresh 1.7334553041281675
current state at start:  [0.26190969 2.34505542]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.26190969, 2.34505542]), 'currentState': array([6.08480194, 2.81291538]), 'targetState': array([0.18373567, 0.25020217]), 'effectorPosition': array([0.11609719, 0.3059104 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9459458129378451
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.26190969, 2.34505542]), 'currentState': array([6.08480194, 2.81291538]), 'targetState': array([0.18373567, 0.25020217]), 'effectorPosition': array([0.11609719, 0.3059104 ])}
episode index:956
target Thresh 1.7339878607857349
current state at start:  [ 3.23840233 -2.75491258]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.23840233, -2.75491258]), 'currentState': array([3.73316946, 3.02827273]), 'targetState': array([-0.15401024, -0.48450197]), 'effectorPosition': array([ 0.05773614, -0.09743822])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.945961121398725
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([ 3.23840233, -2.75491258]), 'currentState': array([3.25942399, 2.57140724]), 'targetState': array([-0.15401024, -0.48450197]), 'effectorPosition': array([-0.09364525, -0.55464291])}
episode index:957
target Thresh 1.7345193533943906
current state at start:  [-2.76619226  2.08266656]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.76619226,  2.08266656]), 'currentState': array([3.9686076 , 1.94928467]), 'targetState': array([ 0.42285387, -1.30112602]), 'effectorPosition': array([ 0.25694361, -1.09313655])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9460070910006053
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.76619226,  2.08266656]), 'currentState': array([4.25721633, 1.53889576]), 'targetState': array([ 0.42285387, -1.30112602]), 'effectorPosition': array([ 0.44408911, -1.36622662])}
episode index:958
target Thresh 1.7350497840801058
current state at start:  [ 3.30791694 -2.32690558]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.30791694, -2.32690558]), 'currentState': array([3.23519168, 3.52431   ]), 'targetState': array([0.38159082, 0.25420521]), 'effectorPosition': array([-0.10693288,  0.36504627])}
done in step count: 18
reward sum = 0.8345137614500875
running average episode reward sum: 0.9458908310115016
{'reset': False, 'endBeforeDone': False, 'stepCount': 19, 'initial state': array([ 3.30791694, -2.32690558]), 'currentState': array([5.39514536, 2.52136521]), 'targetState': array([0.38159082, 0.25420521]), 'effectorPosition': array([0.56844572, 0.22220913])}
episode index:959
target Thresh 1.735579154964604
current state at start:  [-2.06087416  2.69456036]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.06087416,  2.69456036]), 'currentState': array([3.91044209, 3.00610183]), 'targetState': array([-0.10042935, -0.0754012 ]), 'effectorPosition': array([ 0.0873331 , -0.10345349])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.945947194729198
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.06087416,  2.69456036]), 'currentState': array([3.91044209, 3.00610183]), 'targetState': array([-0.10042935, -0.0754012 ]), 'effectorPosition': array([ 0.0873331 , -0.10345349])}
episode index:960
target Thresh 1.7361074681653696
current state at start:  [ 2.71753609 -2.25292626]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.71753609, -2.25292626]), 'currentState': array([3.21753609, 3.53025904]), 'targetState': array([-0.00965732, -0.00232539]), 'effectorPosition': array([-0.10312122,  0.37220356])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.945993035317409
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 2.71753609, -2.25292626]), 'currentState': array([3.71753609, 3.03025904]), 'targetState': array([-0.00965732, -0.00232539]), 'effectorPosition': array([ 0.05531761, -0.09655225])}
episode index:961
target Thresh 1.7366347257956563
current state at start:  [ 0.38188929 -2.81627921]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.38188929, -2.81627921]), 'currentState': array([0.70770598, 3.00002745]), 'targetState': array([-0.2148942 , -0.19089627]), 'effectorPosition': array([-0.08412206,  0.11371341])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9460183013929626
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 0.38188929, -2.81627921]), 'currentState': array([1.86629469, 2.83779819]), 'targetState': array([-0.2148942 , -0.19089627]), 'effectorPosition': array([-0.29951265, -0.04330846])}
episode index:962
target Thresh 1.7371609299644946
current state at start:  [-3.65000523  2.04608162]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.65000523,  2.04608162]), 'currentState': array([3.13318008, 2.45551263]), 'targetState': array([-0.11784645, -0.85379789]), 'effectorPosition': array([-0.23158608, -0.63158317])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.946074357154756
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.65000523,  2.04608162]), 'currentState': array([3.13318008, 2.45551263]), 'targetState': array([-0.11784645, -0.85379789]), 'effectorPosition': array([-0.23158608, -0.63158317])}
episode index:963
target Thresh 1.7376860827767024
current state at start:  [-1.58336395  2.73982358]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.58336395,  2.73982358]), 'currentState': array([5.19982136, 2.23982358]), 'targetState': array([1.19027039, 0.61490676]), 'effectorPosition': array([0.87094169, 0.03184522])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9461199231743049
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.58336395,  2.73982358]), 'currentState': array([5.69982136, 1.78223693]), 'targetState': array([1.19027039, 0.61490676]), 'effectorPosition': array([1.19802235, 0.38079546])}
episode index:964
target Thresh 1.7382101863328918
current state at start:  [1.3061052  1.88581296]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.3061052 , 1.88581296]), 'currentState': array([1.8061052 , 2.18732404]), 'targetState': array([-0.91849518,  0.25756469]), 'effectorPosition': array([-0.8917456 ,  0.21995112])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9461757574508083
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.3061052 , 1.88581296]), 'currentState': array([1.8061052 , 2.18732404]), 'targetState': array([-0.91849518,  0.25756469]), 'effectorPosition': array([-0.8917456 ,  0.21995112])}
episode index:965
target Thresh 1.7387332427294773
current state at start:  [ 1.11324015 -2.34937725]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.11324015, -2.34937725]), 'currentState': array([0.86438778, 3.49103162]), 'targetState': array([ 0.59876255, -0.85117146]), 'effectorPosition': array([ 0.29966949, -0.17626205])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9462108757143167
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 1.11324015, -2.34937725]), 'currentState': array([0.21856341, 3.95888189]), 'targetState': array([ 0.59876255, -0.85117146]), 'effectorPosition': array([ 0.46641735, -0.64346991])}
episode index:966
target Thresh 1.7392552540586852
current state at start:  [-1.51093211 -1.72829189]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.51093211, -1.72829189]), 'currentState': array([4.33466415, 4.05543141]), 'targetState': array([-1.17672981, -0.49544859]), 'effectorPosition': array([-0.87960564, -0.06980597])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9462561591934127
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.51093211, -1.72829189]), 'currentState': array([4.48893621, 4.35432676]), 'targetState': array([-1.17672981, -0.49544859]), 'effectorPosition': array([-1.05722931, -0.4258476 ])}
episode index:967
target Thresh 1.739776222408562
current state at start:  [-1.44162667  1.97529735]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.44162667,  1.97529735]), 'currentState': array([4.34662354, 2.24032687]), 'targetState': array([ 0.34777566, -0.7028158 ]), 'effectorPosition': array([ 0.59655285, -0.63473522])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9463013491116012
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.44162667,  1.97529735]), 'currentState': array([3.86013783, 2.18520123]), 'targetState': array([ 0.34777566, -0.7028158 ]), 'effectorPosition': array([ 0.21908345, -0.89390029])}
episode index:968
target Thresh 1.7402961498629812
current state at start:  [-3.41197189  1.92523026]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.41197189,  1.92523026]), 'currentState': array([3.12894393, 2.42519343]), 'targetState': array([-0.05461637, -0.48404851]), 'effectorPosition': array([-0.25411105, -0.6535115 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9463464457585449
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.41197189,  1.92523026]), 'currentState': array([3.07859363, 2.85523063]), 'targetState': array([-0.05461637, -0.48404851]), 'effectorPosition': array([-0.0584246 , -0.27934016])}
episode index:969
target Thresh 1.7408150385016539
current state at start:  [-2.02098176 -2.11690578]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.02098176, -2.11690578]), 'currentState': array([4.41114426, 3.71914399]), 'targetState': array([-0.1608669 , -0.06436579]), 'effectorPosition': array([-0.56951333,  0.00710166])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9463914494227114
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.02098176, -2.11690578]), 'currentState': array([4.54000849, 3.42093256]), 'targetState': array([-0.1608669 , -0.06436579]), 'effectorPosition': array([-0.27828364,  0.00910606])}
episode index:970
target Thresh 1.7413328904001348
current state at start:  [ 0.00611387 -2.82791759]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.00611387, -2.82791759]), 'currentState': array([0.10952514, 2.95526771]), 'targetState': array([0.05955188, 0.15609002]), 'effectorPosition': array([-0.00304423,  0.18603062])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9464466590525541
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.00611387, -2.82791759]), 'currentState': array([0.10952514, 2.95526771]), 'targetState': array([0.05955188, 0.15609002]), 'effectorPosition': array([-0.00304423,  0.18603062])}
episode index:971
target Thresh 1.7418497076298323
current state at start:  [-0.15264288  2.67824725]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.15264288,  2.67824725]), 'currentState': array([5.63054243, 3.01297745]), 'targetState': array([-0.05290432, -0.10552401]), 'effectorPosition': array([0.08445339, 0.096885  ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9465017550823355
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.15264288,  2.67824725]), 'currentState': array([5.63054243, 3.01297745]), 'targetState': array([-0.05290432, -0.10552401]), 'effectorPosition': array([0.08445339, 0.096885  ])}
episode index:972
target Thresh 1.7423654922580163
current state at start:  [ 3.71625075 -2.71172522]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.71625075, -2.71172522]), 'currentState': array([4.1019024 , 3.07146009]), 'targetState': array([ 0.56310016, -0.22260457]), 'effectorPosition': array([ 0.05600812, -0.04218592])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9465464603700205
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.71625075, -2.71172522]), 'currentState': array([4.59084255, 2.57146009]), 'targetState': array([ 0.56310016, -0.22260457]), 'effectorPosition': array([ 0.51658383, -0.22244614])}
episode index:973
target Thresh 1.7428802463478257
current state at start:  [-2.61244672  1.87963873]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.61244672,  1.87963873]), 'currentState': array([3.36925439, 1.49080837]), 'targetState': array([-0.26802466, -1.26120341]), 'effectorPosition': array([-0.82705917, -1.21481624])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.9465510225769302
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([-2.61244672,  1.87963873]), 'currentState': array([3.82845734, 1.60431971]), 'targetState': array([-0.26802466, -1.26120341]), 'effectorPosition': array([-0.11356159, -1.38566575])}
episode index:974
target Thresh 1.7433939719582778
current state at start:  [-0.35930442 -2.47919745]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.35930442, -2.47919745]), 'currentState': array([5.46069501, 3.89013734]), 'targetState': array([-0.47837217, -0.66099104]), 'effectorPosition': array([-0.31686894, -0.65896426])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9466058420409539
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.35930442, -2.47919745]), 'currentState': array([5.46069501, 3.89013734]), 'targetState': array([-0.47837217, -0.66099104]), 'effectorPosition': array([-0.31686894, -0.65896426])}
episode index:975
target Thresh 1.7439066711442757
current state at start:  [ 1.50699446 -2.62831676]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.50699446, -2.62831676]), 'currentState': array([1.75364271, 3.15486855]), 'targetState': array([ 0.0663819 , -0.29900417]), 'effectorPosition': array([0.01303818, 0.00250053])}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9465813941438095
{'reset': False, 'endBeforeDone': False, 'stepCount': 9, 'initial state': array([ 1.50699446, -2.62831676]), 'currentState': array([3.06522633, 3.03348532]), 'targetState': array([ 0.0663819 , -0.29900417]), 'effectorPosition': array([-0.01405258, -0.10713703])}
episode index:976
target Thresh 1.7444183459566163
current state at start:  [-2.11043564  2.69782185]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.11043564,  2.69782185]), 'currentState': array([4.56985715, 2.85960693]), 'targetState': array([ 0.71250517, -0.03879551]), 'effectorPosition': array([ 0.26983148, -0.07862197])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9466258348867533
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.11043564,  2.69782185]), 'currentState': array([4.88802573, 2.45562847]), 'targetState': array([ 0.71250517, -0.03879551]), 'effectorPosition': array([ 0.66319811, -0.11203086])}
episode index:977
target Thresh 1.7449289984420002
current state at start:  [-1.79601467 -2.45231462]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.79601467, -2.45231462]), 'currentState': array([4.67307463, 3.61632065]), 'targetState': array([-0.2695889 , -0.19909908]), 'effectorPosition': array([-0.46108971, -0.09253164])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9466804096977076
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.79601467, -2.45231462]), 'currentState': array([4.67307463, 3.61632065]), 'targetState': array([-0.2695889 , -0.19909908]), 'effectorPosition': array([-0.46108971, -0.09253164])}
episode index:978
target Thresh 1.7454386306430378
current state at start:  [-1.59549612  2.05874045]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.59549612,  2.05874045]), 'currentState': array([4.18768919, 1.88288326]), 'targetState': array([ 0.348492  , -1.23395105]), 'effectorPosition': array([ 0.47652969, -1.07648901])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9467348730177304
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.59549612,  2.05874045]), 'currentState': array([4.18768919, 1.88288326]), 'targetState': array([ 0.348492  , -1.23395105]), 'effectorPosition': array([ 0.47652969, -1.07648901])}
episode index:979
target Thresh 1.7459472445982587
current state at start:  [-3.08922653  2.51342242]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.08922653,  2.51342242]), 'currentState': array([2.69395877, 2.82771294]), 'targetState': array([-0.56981355,  0.02809928]), 'effectorPosition': array([-0.17768133, -0.25718401])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9467689190656714
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-3.08922653,  2.51342242]), 'currentState': array([1.81629901, 2.79355143]), 'targetState': array([-0.56981355,  0.02809928]), 'effectorPosition': array([-0.34540291, -0.02473225])}
episode index:980
target Thresh 1.7464548423421191
current state at start:  [1.43341489 2.75506463]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.43341489, 2.75506463]), 'currentState': array([1.42927227, 3.25506463]), 'targetState': array([ 0.18724636, -0.5302048 ]), 'effectorPosition': array([ 0.11300369, -0.00960439])}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9467444295400468
{'reset': False, 'endBeforeDone': False, 'stepCount': 9, 'initial state': array([1.43341489, 2.75506463]), 'currentState': array([3.83418207, 2.51663695]), 'targetState': array([ 0.18724636, -0.5302048 ]), 'effectorPosition': array([ 0.22811854, -0.57094996])}
episode index:981
target Thresh 1.7469614259050106
current state at start:  [ 0.46330768 -2.11700405]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.46330768, -2.11700405]), 'currentState': array([0.96330768, 3.67382868]), 'targetState': array([0.25080661, 0.1449742 ]), 'effectorPosition': array([ 0.49562562, -0.17608575])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9467884779824705
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.46330768, -2.11700405]), 'currentState': array([1.46330768, 3.20341142]), 'targetState': array([0.25080661, 0.1449742 ]), 'effectorPosition': array([ 0.06162778, -0.00472866])}
episode index:982
target Thresh 1.7474669973132686
current state at start:  [ 0.50363619 -1.65506589]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.50363619, -1.65506589]), 'currentState': array([0.63408677, 4.61671194]), 'targetState': array([ 1.24314284, -0.45653556]), 'effectorPosition': array([ 1.31838442, -0.26608316])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9468426097444415
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.50363619, -1.65506589]), 'currentState': array([0.63408677, 4.61671194]), 'targetState': array([ 1.24314284, -0.45653556]), 'effectorPosition': array([ 1.31838442, -0.26608316])}
episode index:983
target Thresh 1.747971558589179
current state at start:  [0.11504564 2.23727147]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.11504564, 2.23727147]), 'currentState': array([5.99241749, 2.68002001]), 'targetState': array([0.02537775, 0.03008293]), 'effectorPosition': array([0.22793252, 0.39666148])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.94688646888088
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.11504564, 2.23727147]), 'currentState': array([5.49241749, 3.06096879]), 'targetState': array([0.02537775, 0.03008293]), 'effectorPosition': array([0.05953746, 0.0543321 ])}
episode index:984
target Thresh 1.748475111750988
current state at start:  [-0.85406348 -2.27102149]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.85406348, -2.27102149]), 'currentState': array([5.8338337 , 4.45405301]), 'targetState': array([ 0.06024073, -1.30850706]), 'effectorPosition': array([ 0.25065056, -1.19424877])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9469403912474984
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.85406348, -2.27102149]), 'currentState': array([5.8338337 , 4.45405301]), 'targetState': array([ 0.06024073, -1.30850706]), 'effectorPosition': array([ 0.25065056, -1.19424877])}
episode index:985
target Thresh 1.7489776588129082
current state at start:  [-3.85281057  2.56706079]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.85281057,  2.56706079]), 'currentState': array([1.99498612, 2.41144271]), 'targetState': array([-0.6734977, -0.0896444]), 'effectorPosition': array([-0.71279139, -0.04218568])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9469942042381196
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.85281057,  2.56706079]), 'currentState': array([1.99498612, 2.41144271]), 'targetState': array([-0.6734977, -0.0896444]), 'effectorPosition': array([-0.71279139, -0.04218568])}
episode index:986
target Thresh 1.7494792017851293
current state at start:  [-0.36983539 -1.98288965]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.36983539, -1.98288965]), 'currentState': array([0.01159303, 4.45541454]), 'targetState': array([ 0.69938716, -1.0561781 ]), 'effectorPosition': array([ 0.75700647, -0.95845197])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9470479081851935
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.36983539, -1.98288965]), 'currentState': array([0.01159303, 4.45541454]), 'targetState': array([ 0.69938716, -1.0561781 ]), 'effectorPosition': array([ 0.75700647, -0.95845197])}
episode index:987
target Thresh 1.7499797426738235
current state at start:  [-0.69977859  2.05952278]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.69977859,  2.05952278]), 'currentState': array([5.08340672, 1.95611306]), 'targetState': array([ 1.0917536 , -0.13567552]), 'effectorPosition': array([ 1.08992051, -0.24569892])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9471015034198238
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.69977859,  2.05952278]), 'currentState': array([5.08340672, 1.95611306]), 'targetState': array([ 1.0917536 , -0.13567552]), 'effectorPosition': array([ 1.08992051, -0.24569892])}
episode index:988
target Thresh 1.750479283481155
current state at start:  [ 4.35369473 -2.60973546]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.35369473, -2.60973546]), 'currentState': array([3.85369473, 3.72948858]), 'targetState': array([-0.5935554 ,  0.68499715]), 'effectorPosition': array([-0.48948924,  0.31013119])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9471448790483175
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 4.35369473, -2.60973546]), 'currentState': array([3.3891299 , 4.14918392]), 'targetState': array([-0.5935554 ,  0.68499715]), 'effectorPosition': array([-0.65906742,  0.70557225])}
episode index:989
target Thresh 1.7509778262052875
current state at start:  [2.10880246 1.60943308]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.10880246, 1.60943308]), 'currentState': array([2.18582123, 1.6826961 ]), 'targetState': array([-1.3115078 ,  0.11770334]), 'effectorPosition': array([-1.32420058,  0.15218425])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9471982680593798
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.10880246, 1.60943308]), 'currentState': array([2.18582123, 1.6826961 ]), 'targetState': array([-1.3115078 ,  0.11770334]), 'effectorPosition': array([-1.32420058,  0.15218425])}
episode index:990
target Thresh 1.751475372840393
current state at start:  [1.36251963 2.10865867]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.36251963, 2.10865867]), 'currentState': array([0.86251963, 2.60865867]), 'targetState': array([-0.07132789,  0.2881973 ]), 'effectorPosition': array([-0.29565061,  0.43583306])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9472314685961514
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([1.36251963, 2.10865867]), 'currentState': array([0.23005929, 2.87304821]), 'targetState': array([-0.07132789,  0.2881973 ]), 'effectorPosition': array([-0.02560666,  0.26651091])}
episode index:991
target Thresh 1.7519719253766584
current state at start:  [-2.91546216  2.00280679]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.91546216,  2.00280679]), 'currentState': array([3.6308308 , 2.50280679]), 'targetState': array([ 0.1268806 , -0.70961634]), 'effectorPosition': array([ 0.10614742, -0.61894446])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9472846626802278
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.91546216,  2.00280679]), 'currentState': array([3.6308308 , 2.50280679]), 'targetState': array([ 0.1268806 , -0.70961634]), 'effectorPosition': array([ 0.10614742, -0.61894446])}
episode index:992
target Thresh 1.7524674858002947
current state at start:  [ 2.18218443 -1.98238619]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.18218443, -1.98238619]), 'currentState': array([2.48736644, 4.80079912]), 'targetState': array([0.01453703, 1.39900504]), 'effectorPosition': array([-0.25741416,  1.45269679])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9473177093441953
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 2.18218443, -1.98238619]), 'currentState': array([2.35182276, 4.83200418]), 'targetState': array([0.01453703, 1.39900504]), 'effectorPosition': array([-0.08290153,  1.49391689])}
episode index:993
target Thresh 1.752962056093544
current state at start:  [ 0.20823961 -2.73878001]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.20823961, -2.73878001]), 'currentState': array([0.53972753, 3.29703848]), 'targetState': array([0.03008536, 0.04142589]), 'effectorPosition': array([ 0.08990606, -0.12661631])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9473707096366056
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.20823961, -2.73878001]), 'currentState': array([0.53972753, 3.29703848]), 'targetState': array([0.03008536, 0.04142589]), 'effectorPosition': array([ 0.08990606, -0.12661631])}
episode index:994
target Thresh 1.7534556382346884
current state at start:  [ 1.72736281 -2.65292595]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.72736281, -2.65292595]), 'currentState': array([1.85042572, 3.3178839 ]), 'targetState': array([0.05013509, 0.03070144]), 'effectorPosition': array([0.16428965, 0.06330173])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9474236033957648
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.72736281, -2.65292595]), 'currentState': array([1.85042572, 3.3178839 ]), 'targetState': array([0.05013509, 0.03070144]), 'effectorPosition': array([0.16428965, 0.06330173])}
episode index:995
target Thresh 1.753948234198057
current state at start:  [-2.21403289 -1.74843861]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.21403289, -1.74843861]), 'currentState': array([4.53446279, 4.48489641]), 'targetState': array([-0.57884818, -0.72563034]), 'effectorPosition': array([-1.09592621, -0.58980924])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9474663507819137
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.21403289, -1.74843861]), 'currentState': array([5.00898538, 4.33359421]), 'targetState': array([-0.57884818, -0.72563034]), 'effectorPosition': array([-0.7043567 , -0.87423095])}
episode index:996
target Thresh 1.7544398459540345
current state at start:  [1.22786984 2.1838528 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.22786984, 2.1838528 ]), 'currentState': array([0.72786984, 2.56812293]), 'targetState': array([-0.03641521,  0.52051333]), 'effectorPosition': array([-0.24151071,  0.5114934 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9475190425063049
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.22786984, 2.1838528 ]), 'currentState': array([0.72786984, 2.56812293]), 'targetState': array([-0.03641521,  0.52051333]), 'effectorPosition': array([-0.24151071,  0.5114934 ])}
episode index:997
target Thresh 1.7549304754690682
current state at start:  [-0.35303461 -1.98152642]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.35303461, -1.98152642]), 'currentState': array([5.73440729, 3.87234061]), 'targetState': array([-0.09345488, -0.68915447]), 'effectorPosition': array([-0.13032651, -0.70261241])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.947571628636058
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.35303461, -1.98152642]), 'currentState': array([5.73440729, 3.87234061]), 'targetState': array([-0.09345488, -0.68915447]), 'effectorPosition': array([-0.13032651, -0.70261241])}
episode index:998
target Thresh 1.7554201247056769
current state at start:  [-2.05779749  2.93899548]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.05779749,  2.93899548]), 'currentState': array([3.9485919 , 3.16452471]), 'targetState': array([-0.02101457,  0.03944198]), 'effectorPosition': array([-0.01674228,  0.0156701 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9476241094882742
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.05779749,  2.93899548]), 'currentState': array([3.9485919 , 3.16452471]), 'targetState': array([-0.02101457,  0.03944198]), 'effectorPosition': array([-0.01674228,  0.0156701 ])}
episode index:999
target Thresh 1.7559087956224586
current state at start:  [ 3.16946542 -2.14207592]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.16946542, -2.14207592]), 'currentState': array([2.72161472, 4.34512772]), 'targetState': array([-0.0709508 ,  1.30562764]), 'effectorPosition': array([-0.20469055,  1.11354409])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.947676485378786
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.16946542, -2.14207592]), 'currentState': array([2.72161472, 4.34512772]), 'targetState': array([-0.0709508 ,  1.30562764]), 'effectorPosition': array([-0.20469055,  1.11354409])}
episode index:1000
target Thresh 1.7563964901740972
current state at start:  [ 2.73134051 -2.46888587]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.73134051, -2.46888587]), 'currentState': array([2.92155129, 3.31429944]), 'targetState': array([ 0.50118766, -0.04619055]), 'effectorPosition': array([0.02299151, 0.17095308])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9476990852934924
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 2.73134051, -2.46888587]), 'currentState': array([4.38349307, 2.80409728]), 'targetState': array([ 0.50118766, -0.04619055]), 'effectorPosition': array([ 0.29515504, -0.16034202])}
episode index:1001
target Thresh 1.7568832103113716
current state at start:  [ 1.72904295 -2.64813812]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.72904295, -2.64813812]), 'currentState': array([1.82911839, 3.86636373]), 'targetState': array([0.34634602, 0.3912983 ]), 'effectorPosition': array([0.57675769, 0.41236894])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9477512818151557
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.72904295, -2.64813812]), 'currentState': array([1.82911839, 3.86636373]), 'targetState': array([0.34634602, 0.3912983 ]), 'effectorPosition': array([0.57675769, 0.41236894])}
episode index:1002
target Thresh 1.7573689579811633
current state at start:  [-3.43238614  2.00585285]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.43238614,  2.00585285]), 'currentState': array([2.90907075, 2.40886074]), 'targetState': array([ 0.01542192, -0.00569733]), 'effectorPosition': array([-0.40388015, -0.59176113])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9477835337774535
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-3.43238614,  2.00585285]), 'currentState': array([2.8478369 , 3.27835533]), 'targetState': array([ 0.01542192, -0.00569733]), 'effectorPosition': array([0.03053872, 0.13320015])}
episode index:1003
target Thresh 1.7578537351264631
current state at start:  [-3.60462797  2.57979239]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.60462797,  2.57979239]), 'currentState': array([2.37034276, 3.07979239]), 'targetState': array([-0.08147174,  0.15614169]), 'effectorPosition': array([-0.0444182, -0.0429544])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9478355422099461
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.60462797,  2.57979239]), 'currentState': array([2.37034276, 3.07979239]), 'targetState': array([-0.08147174,  0.15614169]), 'effectorPosition': array([-0.0444182, -0.0429544])}
episode index:1004
target Thresh 1.7583375436863808
current state at start:  [-1.91147618  2.44598901]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.91147618,  2.44598901]), 'currentState': array([4.45608609, 2.82566884]), 'targetState': array([ 0.34611803, -0.09213791]), 'effectorPosition': array([ 0.28799942, -0.12663654])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9478874471430706
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.91147618,  2.44598901]), 'currentState': array([4.45608609, 2.82566884]), 'targetState': array([ 0.34611803, -0.09213791]), 'effectorPosition': array([ 0.28799942, -0.12663654])}
episode index:1005
target Thresh 1.758820385596151
current state at start:  [ 1.6796448  -2.87512867]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.6796448 , -2.87512867]), 'currentState': array([2.1796448 , 3.02068617]), 'targetState': array([-0.137375  , -0.62611283]), 'effectorPosition': array([-0.10311419, -0.0629924 ])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9479194675733459
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 1.6796448 , -2.87512867]), 'currentState': array([3.17359207, 2.53517141]), 'targetState': array([-0.137375  , -0.62611283]), 'effectorPosition': array([-0.15998147, -0.57534346])}
episode index:1006
target Thresh 1.7593022627871422
current state at start:  [ 2.57822645 -1.68497063]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.57822645, -1.68497063]), 'currentState': array([3.07086519, 4.24183663]), 'targetState': array([-0.82206575,  0.87846825]), 'effectorPosition': array([-0.48226657,  0.92771849])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9479320559968083
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([ 2.57822645, -1.68497063]), 'currentState': array([3.07842696, 4.37585323]), 'targetState': array([-0.82206575,  0.87846825]), 'effectorPosition': array([-0.60886238,  0.98430091])}
episode index:1007
target Thresh 1.7597831771868633
current state at start:  [-1.53891934  2.92615305]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.53891934,  2.92615305]), 'currentState': array([5.11764973, 2.42615305]), 'targetState': array([ 0.84075469, -0.86509004]), 'effectorPosition': array([0.69948736, 0.03327937])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.94797379006824
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.53891934,  2.92615305]), 'currentState': array([4.63110989, 2.01905965]), 'targetState': array([ 0.84075469, -0.86509004]), 'effectorPosition': array([ 0.85222402, -0.63789657])}
episode index:1008
target Thresh 1.760263130718973
current state at start:  [-1.44568008 -1.95458322]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.44568008, -1.95458322]), 'currentState': array([5.32443011, 4.12898849]), 'targetState': array([-0.31477864, -0.85875629]), 'effectorPosition': array([-0.42505061, -0.84711374])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9480253522188166
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.44568008, -1.95458322]), 'currentState': array([5.32443011, 4.12898849]), 'targetState': array([-0.31477864, -0.85875629]), 'effectorPosition': array([-0.42505061, -0.84711374])}
episode index:1009
target Thresh 1.7607421253032858
current state at start:  [ 2.44101043 -2.77728831]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.44101043, -2.77728831]), 'currentState': array([2.30604584, 3.08584161]), 'targetState': array([-0.00776365,  0.1332407 ]), 'effectorPosition': array([-0.04236927, -0.03622457])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9480768122661247
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.44101043, -2.77728831]), 'currentState': array([2.30604584, 3.08584161]), 'targetState': array([-0.00776365,  0.1332407 ]), 'effectorPosition': array([-0.04236927, -0.03622457])}
episode index:1010
target Thresh 1.7612201628557809
current state at start:  [-0.0375747  2.1902515]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.0375747,  2.1902515]), 'currentState': array([5.7456106 , 2.38663247]), 'targetState': array([0.24849164, 0.48903667]), 'effectorPosition': array([0.58426871, 0.44948016])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9481084870314401
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-0.0375747,  2.1902515]), 'currentState': array([5.71208436, 2.67609204]), 'targetState': array([0.24849164, 0.48903667]), 'effectorPosition': array([0.3321582 , 0.32012028])}
episode index:1011
target Thresh 1.761697245288609
current state at start:  [0.4716012  1.88940762]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.4716012 , 1.88940762]), 'currentState': array([6.25478651, 2.37912636]), 'targetState': array([0.31472453, 0.28376193]), 'effectorPosition': array([0.29636625, 0.68256692])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9481498818071007
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.4716012 , 1.88940762]), 'currentState': array([5.75478651, 2.6891679 ]), 'targetState': array([0.31472453, 0.28376193]), 'effectorPosition': array([0.30727702, 0.32680466])}
episode index:1012
target Thresh 1.7621733745101007
current state at start:  [0.23544473 2.07303165]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.23544473, 2.07303165]), 'currentState': array([0.23592962, 2.49149166]), 'targetState': array([-0.53090571,  0.28728391]), 'effectorPosition': array([0.05684737, 0.63617846])}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.9481156936192198
{'reset': False, 'endBeforeDone': False, 'stepCount': 10, 'initial state': array([0.23544473, 2.07303165]), 'currentState': array([4.30311329, 3.68383965]), 'targetState': array([-0.53090571,  0.28728391]), 'effectorPosition': array([-0.53052474,  0.07376303])}
episode index:1013
target Thresh 1.762648552424773
current state at start:  [-1.2621319   2.60416316]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.2621319 ,  2.60416316]), 'currentState': array([4.87743584, 2.11452263]), 'targetState': array([ 0.89576881, -0.48592938]), 'effectorPosition': array([ 0.92345955, -0.33550777])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9481668615742304
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.2621319 ,  2.60416316]), 'currentState': array([4.87743584, 2.11452263]), 'targetState': array([ 0.89576881, -0.48592938]), 'effectorPosition': array([ 0.92345955, -0.33550777])}
episode index:1014
target Thresh 1.7631227809333387
current state at start:  [-1.75689177 -1.90651436]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.75689177, -1.90651436]), 'currentState': array([4.0851918 , 3.87667095]), 'targetState': array([-0.35008225,  0.36171868]), 'effectorPosition': array([-0.69454967,  0.18451087])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9482080764889356
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.75689177, -1.90651436]), 'currentState': array([3.6976483, 3.5877897]), 'targetState': array([-0.35008225,  0.36171868]), 'effectorPosition': array([-0.31093834,  0.31484578])}
episode index:1015
target Thresh 1.7635960619327125
current state at start:  [-1.62135037  1.6753623 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.62135037,  1.6753623 ]), 'currentState': array([4.16183494, 1.68949946]), 'targetState': array([ 0.26630835, -1.31925921]), 'effectorPosition': array([ 0.38503312, -1.2707873 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9482590527916039
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.62135037,  1.6753623 ]), 'currentState': array([4.16183494, 1.68949946]), 'targetState': array([ 0.26630835, -1.31925921]), 'effectorPosition': array([ 0.38503312, -1.2707873 ])}
episode index:1016
target Thresh 1.7640683973160187
current state at start:  [-0.00923772  1.82353591]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.00923772,  1.82353591]), 'currentState': array([5.77394759, 2.32353591]), 'targetState': array([0.07811969, 0.23124305]), 'effectorPosition': array([0.63201372, 0.48298779])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9483000960041983
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.00923772,  1.82353591]), 'currentState': array([5.27394759, 2.82353591]), 'targetState': array([0.07811969, 0.23124305]), 'effectorPosition': array([0.29140343, 0.12407345])}
episode index:1017
target Thresh 1.7645397889725993
current state at start:  [ 3.61202156 -2.33150657]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.61202156, -2.33150657]), 'currentState': array([3.2939541 , 3.53280063]), 'targetState': array([-0.06345936,  0.37953651]), 'effectorPosition': array([-0.13254738,  0.36542159])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9483508817645085
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.61202156, -2.33150657]), 'currentState': array([3.2939541 , 3.53280063]), 'targetState': array([-0.06345936,  0.37953651]), 'effectorPosition': array([-0.13254738,  0.36542159])}
episode index:1018
target Thresh 1.7650102387880222
current state at start:  [ 3.46998357 -2.57014112]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.46998357, -2.57014112]), 'currentState': array([3.71106731, 3.28475698]), 'targetState': array([-0.33737046, -0.06833022]), 'effectorPosition': array([-0.08554529,  0.11464311])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9483628985733755
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([ 3.46998357, -2.57014112]), 'currentState': array([4.41247501, 3.6989024 ]), 'targetState': array([-0.33737046, -0.06833022]), 'effectorPosition': array([-0.55000101,  0.01169428])}
episode index:1019
target Thresh 1.7654797486440867
current state at start:  [0.25916867 2.3201316 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.25916867, 2.3201316 ]), 'currentState': array([6.04235397, 2.8201316 ]), 'targetState': array([0.62969528, 0.06659454]), 'effectorPosition': array([0.12510483, 0.29461698])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9483940133786958
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([0.25916867, 2.3201316 ]), 'currentState': array([5.08170556, 2.45628926]), 'targetState': array([0.62969528, 0.06659454]), 'effectorPosition': array([0.67173275, 0.01791592])}
episode index:1020
target Thresh 1.7659483204188333
current state at start:  [ 1.5312134  -2.62540146]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.5312134 , -2.62540146]), 'currentState': array([1.78533155, 3.2498752 ]), 'targetState': array([ 0.02617535, -0.48207756]), 'effectorPosition': array([0.10434671, 0.02873017])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9484059644037901
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([ 1.5312134 , -2.62540146]), 'currentState': array([3.03100559, 2.8438139 ]), 'targetState': array([ 0.02617535, -0.48207756]), 'effectorPosition': array([-0.07612048, -0.28674825])}
episode index:1021
target Thresh 1.7664159559865493
current state at start:  [ 0.35412448 -2.83193406]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.35412448, -2.83193406]), 'currentState': array([0.76501679, 3.07314227]), 'targetState': array([0.08045387, 0.46788801]), 'effectorPosition': array([-0.04567892,  0.05096137])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.948436976180303
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 0.35412448, -2.83193406]), 'currentState': array([0.32796466, 2.68090972]), 'targetState': array([0.08045387, 0.46788801]), 'effectorPosition': array([-0.04450593,  0.45444584])}
episode index:1022
target Thresh 1.766882657217778
current state at start:  [1.67775544 1.71625923]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.67775544, 1.71625923]), 'currentState': array([1.37264949, 1.71749011]), 'targetState': array([-1.06466419,  0.88198497]), 'effectorPosition': array([-0.80182382,  1.03186342])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9484679273277319
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([1.67775544, 1.71625923]), 'currentState': array([1.43512994, 1.75601743]), 'targetState': array([-1.06466419,  0.88198497]), 'effectorPosition': array([-0.86352181,  0.94127698])}
episode index:1023
target Thresh 1.7673484259793246
current state at start:  [-0.30178799  2.10398072]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.30178799,  2.10398072]), 'currentState': array([0.18074457, 2.54787279]), 'targetState': array([0.03626773, 0.8053372 ]), 'effectorPosition': array([0.06777934, 0.58109833])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9485182516174508
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.30178799,  2.10398072]), 'currentState': array([0.18074457, 2.54787279]), 'targetState': array([0.03626773, 0.8053372 ]), 'effectorPosition': array([0.06777934, 0.58109833])}
episode index:1024
target Thresh 1.767813264134265
current state at start:  [-0.64479728  1.8440261 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.64479728,  1.8440261 ]), 'currentState': array([5.36418431, 2.32742868]), 'targetState': array([0.28534075, 0.13690102]), 'effectorPosition': array([0.76827081, 0.19185114])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9485587216158728
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.64479728,  1.8440261 ]), 'currentState': array([5.18461148, 2.82742868]), 'targetState': array([0.28534075, 0.13690102]), 'effectorPosition': array([0.29746544, 0.09697519])}
episode index:1025
target Thresh 1.7682771735419525
current state at start:  [1.36347148 1.69686495]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.36347148, 1.69686495]), 'currentState': array([1.86347148, 2.16794111]), 'targetState': array([-0.93109599,  0.4361813 ]), 'effectorPosition': array([-0.91806659,  0.18051708])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9485991127254091
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.36347148, 1.69686495]), 'currentState': array([1.61553987, 2.04527622]), 'targetState': array([-0.93109599,  0.4361813 ]), 'effectorPosition': array([-0.91293339,  0.50279311])}
episode index:1026
target Thresh 1.768740156058025
current state at start:  [2.14327652 1.87330833]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.14327652, 1.87330833]), 'currentState': array([1.9703749 , 1.53577036]), 'targetState': array([-1.34586336,  0.22017585]), 'effectorPosition': array([-1.32331351,  0.56469368])}
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.9485299032904271
{'reset': False, 'endBeforeDone': False, 'stepCount': 14, 'initial state': array([2.14327652, 1.87330833]), 'currentState': array([2.3653574 , 1.39417015]), 'targetState': array([-1.34586336,  0.22017585]), 'effectorPosition': array([-1.52863278,  0.12124485])}
episode index:1027
target Thresh 1.7692022135344132
current state at start:  [ 1.33648016 -2.37056324]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.33648016, -2.37056324]), 'currentState': array([1.73915141, 3.41262207]), 'targetState': array([0.19758106, 0.14592045]), 'effectorPosition': array([0.25782159, 0.08084807])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9485799714778878
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.33648016, -2.37056324]), 'currentState': array([1.73915141, 3.41262207]), 'targetState': array([0.19758106, 0.14592045]), 'effectorPosition': array([0.25782159, 0.08084807])}
episode index:1028
target Thresh 1.7696633478193482
current state at start:  [-3.37850367  1.63370351]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.37850367,  1.63370351]), 'currentState': array([2.64820077, 1.98748944]), 'targetState': array([-0.5036216 , -0.42741135]), 'effectorPosition': array([-0.95735507, -0.52344414])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9486202241781037
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.37850367,  1.63370351]), 'currentState': array([2.51870804, 2.3962218 ]), 'targetState': array([-0.5036216 , -0.42741135]), 'effectorPosition': array([-0.61104012, -0.39617816])}
episode index:1029
target Thresh 1.770123560757367
current state at start:  [-3.1752885   2.79689897]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.1752885 ,  2.79689897]), 'currentState': array([3.4618803 , 2.29689897]), 'targetState': array([ 0.44676374, -1.09215739]), 'effectorPosition': array([-0.0835234 , -0.81553854])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9486507870672511
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-3.1752885 ,  2.79689897]), 'currentState': array([4.16460026, 1.6439393 ]), 'targetState': array([ 0.44676374, -1.09215739]), 'effectorPosition': array([ 0.36865389, -1.31070163])}
episode index:1030
target Thresh 1.7705828541893227
current state at start:  [ 2.31749257 -2.69638495]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.31749257, -2.69638495]), 'currentState': array([1.82896518, 3.99055221]), 'targetState': array([0.81856873, 0.7076133 ]), 'effectorPosition': array([0.63910759, 0.51962735])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9486812906685438
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 2.31749257, -2.69638495]), 'currentState': array([1.6223621 , 4.52677656]), 'targetState': array([0.81856873, 0.7076133 ]), 'effectorPosition': array([0.93948627, 0.86502521])}
episode index:1031
target Thresh 1.771041229952389
current state at start:  [ 3.26313815 -2.32737422]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.26313815, -2.32737422]), 'currentState': array([3.71455679, 4.14030838]), 'targetState': array([-1.06624528,  0.40140844]), 'effectorPosition': array([-0.84118127,  0.45787442])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9487310181000665
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.26313815, -2.32737422]), 'currentState': array([3.71455679, 4.14030838]), 'targetState': array([-1.06624528,  0.40140844]), 'effectorPosition': array([-0.84118127,  0.45787442])}
episode index:1032
target Thresh 1.77149868988007
current state at start:  [ 0.96349695 -2.38991624]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.96349695, -2.38991624]), 'currentState': array([1.27357969, 4.39326907]), 'targetState': array([1.01363922, 0.27575354]), 'effectorPosition': array([1.1088616 , 0.37810566])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9487806492538903
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.96349695, -2.38991624]), 'currentState': array([1.27357969, 4.39326907]), 'targetState': array([1.01363922, 0.27575354]), 'effectorPosition': array([1.1088616 , 0.37810566])}
episode index:1033
target Thresh 1.7719552358022057
current state at start:  [-3.41492864  2.09597962]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.41492864,  2.09597962]), 'currentState': array([2.4849847 , 2.59597962]), 'targetState': array([-0.34073929, -0.31739485]), 'effectorPosition': array([-0.43178059, -0.32240794])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9488301844093507
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.41492864,  2.09597962]), 'currentState': array([2.4849847 , 2.59597962]), 'targetState': array([-0.34073929, -0.31739485]), 'effectorPosition': array([-0.43178059, -0.32240794])}
episode index:1034
target Thresh 1.7724108695449807
current state at start:  [ 2.27145481 -2.58293599]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.27145481, -2.58293599]), 'currentState': array([2.65629077, 3.90956344]), 'targetState': array([-0.17568013,  0.79170884]), 'effectorPosition': array([0.07578028, 0.74539503])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9488699620089552
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 2.27145481, -2.58293599]), 'currentState': array([2.7969557 , 4.10159694]), 'targetState': array([-0.17568013,  0.79170884]), 'effectorPosition': array([-0.12463672,  0.91511351])}
episode index:1035
target Thresh 1.7728655929309303
current state at start:  [ 4.1484363  -2.85921041]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.1484363 , -2.85921041]), 'currentState': array([3.81646347, 3.8145709 ]), 'targetState': array([-0.45021404,  0.9305906 ]), 'effectorPosition': array([-0.55968277,  0.35045358])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9489096628178268
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 4.1484363 , -2.85921041]), 'currentState': array([3.3246015 , 4.03098978]), 'targetState': array([-0.45021404,  0.9305906 ]), 'effectorPosition': array([-0.50528825,  0.69636414])}
episode index:1036
target Thresh 1.7733194077789487
current state at start:  [-0.50777054 -2.91236204]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.50777054, -2.91236204]), 'currentState': array([6.08035118, 2.97740091]), 'targetState': array([0.58611974, 0.36530872]), 'effectorPosition': array([0.04610088, 0.15739482])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9489492870581183
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.50777054, -2.91236204]), 'currentState': array([5.73178116, 2.60344646]), 'targetState': array([0.58611974, 0.36530872]), 'effectorPosition': array([0.38890575, 0.36253508])}
episode index:1037
target Thresh 1.7737723159042962
current state at start:  [0.83140544 2.61442224]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.83140544, 2.61442224]), 'currentState': array([0.33140544, 2.99424751]), 'targetState': array([0.16194687, 0.27583945]), 'effectorPosition': array([-0.03752269,  0.14234953])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.948998468862494
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.83140544, 2.61442224]), 'currentState': array([0.33140544, 2.99424751]), 'targetState': array([0.16194687, 0.27583945]), 'effectorPosition': array([-0.03752269,  0.14234953])}
episode index:1038
target Thresh 1.7742243191186056
current state at start:  [ 0.87280249 -2.04752291]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.87280249, -2.04752291]), 'currentState': array([1.17996242, 4.64918944]), 'targetState': array([1.30119555, 0.02307354]), 'effectorPosition': array([1.27964494, 0.48599781])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9490379313563703
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.87280249, -2.04752291]), 'currentState': array([0.7744933 , 4.72399059]), 'targetState': array([1.30119555, 0.02307354]), 'effectorPosition': array([ 1.42237477, -0.00725995])}
episode index:1039
target Thresh 1.7746754192298904
current state at start:  [-3.75862728  2.7393131 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.75862728,  2.7393131 ]), 'currentState': array([2.68257394, 2.2393131 ]), 'targetState': array([-1.02394031, -0.09389435]), 'effectorPosition': array([-0.68851875, -0.53506681])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9490773179608353
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.75862728,  2.7393131 ]), 'currentState': array([2.22365614, 1.88892773]), 'targetState': array([-1.02394031, -0.09389435]), 'effectorPosition': array([-1.17194219, -0.03109582])}
episode index:1040
target Thresh 1.7751256180425516
current state at start:  [-1.91590469 -1.96106326]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.91590469, -1.96106326]), 'currentState': array([3.96163945, 4.54957346]), 'targetState': array([-1.27881307, -0.16017638]), 'effectorPosition': array([-1.29311423,  0.06050899])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9491262350425251
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.91590469, -1.96106326]), 'currentState': array([3.96163945, 4.54957346]), 'targetState': array([-1.27881307, -0.16017638]), 'effectorPosition': array([-1.29311423,  0.06050899])}
episode index:1041
target Thresh 1.7755749173573852
current state at start:  [-1.58360245 -1.60408937]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.58360245, -1.60408937]), 'currentState': array([4.87551653, 4.17909593]), 'targetState': array([-0.42316961, -0.24703628]), 'effectorPosition': array([-0.76986246, -0.62495446])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9491654613044805
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.58360245, -1.60408937]), 'currentState': array([5.18680733, 3.67909593]), 'targetState': array([-0.42316961, -0.24703628]), 'effectorPosition': array([-0.39103121, -0.35932614])}
episode index:1042
target Thresh 1.776023318971589
current state at start:  [-2.10766783  1.78161084]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.10766783,  1.78161084]), 'currentState': array([3.77155587, 1.85814304]), 'targetState': array([-0.10909536, -0.88506762]), 'effectorPosition': array([-0.01408013, -1.19707322])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9492046123482921
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.10766783,  1.78161084]), 'currentState': array([3.5022609 , 2.09582086]), 'targetState': array([-0.10909536, -0.88506762]), 'effectorPosition': array([-0.16130768, -0.98565276])}
episode index:1043
target Thresh 1.7764708246787702
current state at start:  [-1.31763375 -1.91818318]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.31763375, -1.91818318]), 'currentState': array([4.86501783, 3.86500213]), 'targetState': array([-0.65237316, -0.23909874]), 'effectorPosition': array([-0.61617171, -0.34817526])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9492532669341655
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.31763375, -1.91818318]), 'currentState': array([4.86501783, 3.86500213]), 'targetState': array([-0.65237316, -0.23909874]), 'effectorPosition': array([-0.61617171, -0.34817526])}
episode index:1044
target Thresh 1.776917436268952
current state at start:  [-1.00340474 -3.01422438]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.00340474, -3.01422438]), 'currentState': array([5.76670044, 2.78930694]), 'targetState': array([ 0.52334799, -0.25091483]), 'effectorPosition': array([0.22379467, 0.26970902])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9492734063916447
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-1.00340474, -3.01422438]), 'currentState': array([4.65091881, 2.52604426]), 'targetState': array([ 0.52334799, -0.25091483]), 'effectorPosition': array([ 0.56504049, -0.21866734])}
episode index:1045
target Thresh 1.7773631555285814
current state at start:  [1.4878056  2.39836522]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.4878056 , 2.39836522]), 'currentState': array([1.9878056 , 1.89836522]), 'targetState': array([-1.03369209,  0.12055016]), 'effectorPosition': array([-1.14040166,  0.23664269])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9493219021790331
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.4878056 , 2.39836522]), 'currentState': array([1.9878056 , 1.89836522]), 'targetState': array([-1.03369209,  0.12055016]), 'effectorPosition': array([-1.14040166,  0.23664269])}
episode index:1046
target Thresh 1.7778079842405359
current state at start:  [ 0.97879016 -1.80914091]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.97879016, -1.80914091]), 'currentState': array([1.36037078, 3.97404439]), 'targetState': array([ 0.51424847, -0.06629713]), 'effectorPosition': array([0.79155912, 0.16524262])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9493607542304381
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.97879016, -1.80914091]), 'currentState': array([1.1319285 , 3.47404439]), 'targetState': array([ 0.51424847, -0.06629713]), 'effectorPosition': array([ 0.3186995 , -0.08910983])}
episode index:1047
target Thresh 1.7782519241841312
current state at start:  [-0.4481431  -2.30736549]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.4481431 , -2.30736549]), 'currentState': array([0.0518569 , 3.59407227]), 'targetState': array([ 0.83546156, -0.74542859]), 'effectorPosition': array([ 0.12316045, -0.43139301])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9493807334725846
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-0.4481431 , -2.30736549]), 'currentState': array([0.34217242, 4.20966792]), 'targetState': array([ 0.83546156, -0.74542859]), 'effectorPosition': array([ 0.78216815, -0.65160536])}
episode index:1048
target Thresh 1.7786949771351277
current state at start:  [ 0.9786477  -2.87962508]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.9786477 , -2.87962508]), 'currentState': array([1.47217637, 3.05513755]), 'targetState': array([0.12655838, 0.46559126]), 'effectorPosition': array([-0.08556013,  0.01221855])}
done in step count: 40
reward sum = 0.6689717585696803
running average episode reward sum: 0.9491134227243454
{'reset': False, 'endBeforeDone': False, 'stepCount': 41, 'initial state': array([ 0.9786477 , -2.87962508]), 'currentState': array([2.19194022, 3.50124961]), 'targetState': array([0.12655838, 0.46559126]), 'effectorPosition': array([0.24897742, 0.25685602])}
episode index:1049
target Thresh 1.7791371448657376
current state at start:  [ 2.92797488 -2.38448934]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.92797488, -2.38448934]), 'currentState': array([3.42797488, 3.80146257]), 'targetState': array([-0.81910616,  0.62208395]), 'effectorPosition': array([-0.37454455,  0.52874608])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9491429337503222
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 2.92797488, -2.38448934]), 'currentState': array([3.5390228 , 4.26143915]), 'targetState': array([-0.81910616,  0.62208395]), 'effectorPosition': array([-0.86856457,  0.6115181 ])}
episode index:1050
target Thresh 1.7795784291446326
current state at start:  [ 1.7830225  -2.15429515]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.7830225 , -2.15429515]), 'currentState': array([2.23356126, 4.21132945]), 'targetState': array([0.08136844, 1.13626466]), 'effectorPosition': array([0.37165537, 0.94929558])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9491818082186854
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.7830225 , -2.15429515]), 'currentState': array([2.35203266, 4.55447393]), 'targetState': array([0.08136844, 1.13626466]), 'effectorPosition': array([0.10778639, 1.29377858])}
episode index:1051
target Thresh 1.78001883173695
current state at start:  [1.10418256 2.64058644]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.10418256, 2.64058644]), 'currentState': array([0.64041306, 2.20524547]), 'targetState': array([-0.21645791,  0.87544266]), 'effectorPosition': array([-0.15468113,  0.8891602 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9492301144846371
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.10418256, 2.64058644]), 'currentState': array([0.64041306, 2.20524547]), 'targetState': array([-0.21645791,  0.87544266]), 'effectorPosition': array([-0.15468113,  0.8891602 ])}
episode index:1052
target Thresh 1.7804583544043013
current state at start:  [0.15051756 2.02774014]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.15051756, 2.02774014]), 'currentState': array([5.99371994, 2.26823155]), 'targetState': array([0.38634521, 0.68190237]), 'effectorPosition': array([0.56165   , 0.63248829])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.949278329000796
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.15051756, 2.02774014]), 'currentState': array([5.99371994, 2.26823155]), 'targetState': array([0.38634521, 0.68190237]), 'effectorPosition': array([0.56165   , 0.63248829])}
episode index:1053
target Thresh 1.7808969989047774
current state at start:  [-0.66076177 -2.44295207]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.66076177, -2.44295207]), 'currentState': array([5.21753658, 3.41745654]), 'targetState': array([-1.04589172,  0.08625718]), 'effectorPosition': array([-0.22006153, -0.16490124])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9493075715729015
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-0.66076177, -2.44295207]), 'currentState': array([4.28186158, 4.15502081]), 'targetState': array([-1.04589172,  0.08625718]), 'effectorPosition': array([-0.96779813, -0.07387632])}
episode index:1054
target Thresh 1.781334766992957
current state at start:  [-3.1809213   2.61884443]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.1809213 ,  2.61884443]), 'currentState': array([3.24223402, 2.13995723]), 'targetState': array([-0.50044225, -0.67650683]), 'effectorPosition': array([-0.37410895, -0.884416  ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.949355621268093
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.1809213 ,  2.61884443]), 'currentState': array([3.24223402, 2.13995723]), 'targetState': array([-0.50044225, -0.67650683]), 'effectorPosition': array([-0.37410895, -0.884416  ])}
episode index:1055
target Thresh 1.781771660419913
current state at start:  [ 1.70174893 -1.74211175]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.70174893, -1.74211175]), 'currentState': array([1.96312724, 4.04107355]), 'targetState': array([-0.021766  ,  0.11527428]), 'effectorPosition': array([0.57899231, 0.6486408 ])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9493847352631043
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 1.70174893, -1.74211175]), 'currentState': array([1.99420512, 3.04107355]), 'targetState': array([-0.021766  ,  0.11527428]), 'effectorPosition': array([-0.09356237, -0.03662879])}
episode index:1056
target Thresh 1.7822076809332197
current state at start:  [-3.7372693   2.38279146]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.7372693 ,  2.38279146]), 'currentState': array([2.06329213, 2.72643602]), 'targetState': array([-0.2338683 ,  0.02157033]), 'effectorPosition': array([-0.39556445, -0.11585529])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9494326210386359
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.7372693 ,  2.38279146]), 'currentState': array([2.06329213, 2.72643602]), 'targetState': array([-0.2338683 ,  0.02157033]), 'effectorPosition': array([-0.39556445, -0.11585529])}
episode index:1057
target Thresh 1.7826428302769597
current state at start:  [-2.60813387  2.95403957]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.60813387,  2.95403957]), 'currentState': array([3.59366401, 3.35733738]), 'targetState': array([-0.66520399,  0.59631072]), 'effectorPosition': array([-0.11436823,  0.18244296])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9494616072191288
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-2.60813387,  2.95403957]), 'currentState': array([3.57309587, 4.02066663]), 'targetState': array([-0.66520399,  0.59631072]), 'effectorPosition': array([-0.65104576,  0.54809692])}
episode index:1058
target Thresh 1.783077110191731
current state at start:  [-1.31277726  2.67646747]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.31277726,  2.67646747]), 'currentState': array([4.47040804, 3.0268371 ]), 'targetState': array([-0.2398723 , -0.21202583]), 'effectorPosition': array([ 0.10959174, -0.03382371])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.949454070431765
{'reset': False, 'endBeforeDone': False, 'stepCount': 7, 'initial state': array([-1.31277726,  2.67646747]), 'currentState': array([4.73956013, 3.63305752]), 'targetState': array([-0.2398723 , -0.21202583]), 'effectorPosition': array([-0.46852818, -0.13113478])}
episode index:1059
target Thresh 1.783510522414654
current state at start:  [0.58543685 2.66187826]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.58543685, 2.66187826]), 'currentState': array([0.96460575, 3.16187826]), 'targetState': array([-0.63956507,  0.09823222]), 'effectorPosition': array([ 0.01678729, -0.01138766])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9494829816860746
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([0.58543685, 2.66187826]), 'currentState': array([1.95562112, 2.41814548]), 'targetState': array([-0.63956507,  0.09823222]), 'effectorPosition': array([-0.70758477, -0.01634897])}
episode index:1060
target Thresh 1.7839430686793778
current state at start:  [ 3.37599769 -1.86741316]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.37599769, -1.86741316]), 'currentState': array([3.64139637, 3.97554115]), 'targetState': array([-0.03366127,  0.03433692]), 'effectorPosition': array([-0.64284622,  0.49278308])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9495118384422612
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 3.37599769, -1.86741316]), 'currentState': array([4.06093109, 3.18124027]), 'targetState': array([-0.03366127,  0.03433692]), 'effectorPosition': array([-0.03199605,  0.02340897])}
episode index:1061
target Thresh 1.7843747507160883
current state at start:  [0.71830275 2.24026106]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.71830275, 2.24026106]), 'currentState': array([1.07623234, 2.58113919]), 'targetState': array([-0.77583974,  0.5559441 ]), 'effectorPosition': array([-0.39526091,  0.3869632 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9495499628881724
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.71830275, 2.24026106]), 'currentState': array([1.39597618, 2.11617477]), 'targetState': array([-0.77583974,  0.5559441 ]), 'effectorPosition': array([-0.75819429,  0.62262194])}
episode index:1062
target Thresh 1.7848055702515144
current state at start:  [ 0.2979281  -2.71863293]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.2979281 , -2.71863293]), 'currentState': array([0.5218347 , 3.07313828]), 'targetState': array([-0.09175965,  0.22634301]), 'effectorPosition': array([-0.03206554,  0.06046464])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9495974229418994
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.2979281 , -2.71863293]), 'currentState': array([0.5218347 , 3.07313828]), 'targetState': array([-0.09175965,  0.22634301]), 'effectorPosition': array([-0.03206554,  0.06046464])}
episode index:1063
target Thresh 1.7852355290089343
current state at start:  [1.91387454 1.64010188]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.91387454, 1.64010188]), 'currentState': array([1.71675691, 2.09700644]), 'targetState': array([-0.67822573, -0.01779206]), 'effectorPosition': array([-0.92791472,  0.36668069])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9496077599598112
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([1.91387454, 1.64010188]), 'currentState': array([1.69996633, 2.42439049]), 'targetState': array([-0.67822573, -0.01779206]), 'effectorPosition': array([-0.68353589,  0.15963525])}
episode index:1064
target Thresh 1.7856646287081839
current state at start:  [ 1.34476468 -1.80813605]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.34476468, -1.80813605]), 'currentState': array([1.08937967, 3.97504926]), 'targetState': array([0.7387593 , 0.25227362]), 'effectorPosition': array([ 0.80784865, -0.05233141])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9496456869457645
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.34476468, -1.80813605]), 'currentState': array([1.47372359, 3.99503084]), 'targetState': array([0.7387593 , 0.25227362]), 'effectorPosition': array([0.7832028, 0.267957 ])}
episode index:1065
target Thresh 1.7860928710656627
current state at start:  [-0.89143923 -2.19617158]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.89143923, -2.19617158]), 'currentState': array([5.76874706, 3.58701372]), 'targetState': array([ 0.06797541, -0.30718202]), 'effectorPosition': array([-0.12704999, -0.42308348])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9496929236371849
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.89143923, -2.19617158]), 'currentState': array([5.76874706, 3.58701372]), 'targetState': array([ 0.06797541, -0.30718202]), 'effectorPosition': array([-0.12704999, -0.42308348])}
episode index:1066
target Thresh 1.7865202577943404
current state at start:  [ 4.41618224 -2.69435166]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.41618224, -2.69435166]), 'currentState': array([4.90480782, 3.08883365]), 'targetState': array([ 0.39316003, -0.7682605 ]), 'effectorPosition': array([0.05202738, 0.00871886])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9497122357987245
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 4.41618224, -2.69435166]), 'currentState': array([4.28190477, 2.25465098]), 'targetState': array([ 0.39316003, -0.7682605 ]), 'effectorPosition': array([ 0.55076218, -0.65809558])}
episode index:1067
target Thresh 1.7869467906037646
current state at start:  [-2.09836097  2.26017097]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.09836097,  2.26017097]), 'currentState': array([4.68482433, 2.50323706]), 'targetState': array([ 1.00682984, -0.29657981]), 'effectorPosition': array([ 0.59022187, -0.21327151])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9497499584243811
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.09836097,  2.26017097]), 'currentState': array([5.06831323, 2.04923194]), 'targetState': array([ 1.00682984, -0.29657981]), 'effectorPosition': array([ 1.02010891, -0.19645812])}
episode index:1068
target Thresh 1.7873724712000674
current state at start:  [1.72068073 2.61828531]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.72068073, 2.61828531]), 'currentState': array([1.41590525, 3.04467601]), 'targetState': array([-0.03902962, -0.153043  ]), 'effectorPosition': array([-0.09488259,  0.01956474])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9497969650114492
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.72068073, 2.61828531]), 'currentState': array([1.41590525, 3.04467601]), 'targetState': array([-0.03902962, -0.153043  ]), 'effectorPosition': array([-0.09488259,  0.01956474])}
episode index:1069
target Thresh 1.7877973012859714
current state at start:  [-0.60896019 -1.9587805 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.60896019, -1.9587805 ]), 'currentState': array([5.80714305, 3.9008036 ]), 'targetState': array([-0.00358465, -0.75496788]), 'effectorPosition': array([-0.07135936, -0.73766461])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9498438837357375
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.60896019, -1.9587805 ]), 'currentState': array([5.80714305, 3.9008036 ]), 'targetState': array([-0.00358465, -0.75496788]), 'effectorPosition': array([-0.07135936, -0.73766461])}
episode index:1070
target Thresh 1.7882212825607975
current state at start:  [ 0.51075583 -2.38095654]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.51075583, -2.38095654]), 'currentState': array([1.00807612, 3.64439371]), 'targetState': array([ 0.81844155, -0.02155075]), 'effectorPosition': array([ 0.47360563, -0.15239834])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9498813777751999
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.51075583, -2.38095654]), 'currentState': array([0.93591324, 3.95446872]), 'targetState': array([ 0.81844155, -0.02155075]), 'effectorPosition': array([ 0.77013801, -0.17905998])}
episode index:1071
target Thresh 1.7886444167204714
current state at start:  [-2.86123083  2.10469789]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.86123083,  2.10469789]), 'currentState': array([3.0007377 , 2.06364016]), 'targetState': array([-1.04903443, -0.15570795]), 'effectorPosition': array([-0.64533091, -0.79829922])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9499004240645886
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-2.86123083,  2.10469789]), 'currentState': array([2.30881404, 1.81781236]), 'targetState': array([-1.04903443, -0.15570795]), 'effectorPosition': array([-1.22565772, -0.09348701])}
episode index:1072
target Thresh 1.7890667054575307
current state at start:  [ 0.00978589 -1.7146763 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.00978589, -1.7146763 ]), 'currentState': array([0.41527885, 4.20231088]), 'targetState': array([ 0.75584417, -0.73827817]), 'effectorPosition': array([ 0.82034653, -0.59206482])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9499471151884801
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.00978589, -1.7146763 ]), 'currentState': array([0.41527885, 4.20231088]), 'targetState': array([ 0.75584417, -0.73827817]), 'effectorPosition': array([ 0.82034653, -0.59206482])}
episode index:1073
target Thresh 1.7894881504611302
current state at start:  [0.96287777 1.9216132 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.96287777, 1.9216132 ]), 'currentState': array([0.49072432, 2.05590026]), 'targetState': array([-0.01759328,  0.80765582]), 'effectorPosition': array([0.05382535, 1.03174717])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9499937193642822
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.96287777, 1.9216132 ]), 'currentState': array([0.49072432, 2.05590026]), 'targetState': array([-0.01759328,  0.80765582]), 'effectorPosition': array([0.05382535, 1.03174717])}
episode index:1074
target Thresh 1.789908753417051
current state at start:  [-0.54086724 -2.70560786]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.54086724, -2.70560786]), 'currentState': array([6.00209484, 3.07757745]), 'targetState': array([0.13543542, 0.10117608]), 'effectorPosition': array([0.0197138 , 0.06089263])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.950040236834641
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.54086724, -2.70560786]), 'currentState': array([6.00209484, 3.07757745]), 'targetState': array([0.13543542, 0.10117608]), 'effectorPosition': array([0.0197138 , 0.06089263])}
episode index:1075
target Thresh 1.7903285160077054
current state at start:  [-4.1737248   2.16534185]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.1737248 ,  2.16534185]), 'currentState': array([1.63245449, 1.86234254]), 'targetState': array([-0.96525197,  0.48906692]), 'effectorPosition': array([-0.99988822,  0.65219359])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9500866678413002
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.1737248 ,  2.16534185]), 'currentState': array([1.63245449, 1.86234254]), 'targetState': array([-0.96525197,  0.48906692]), 'effectorPosition': array([-0.99988822,  0.65219359])}
episode index:1076
target Thresh 1.7907474399121444
current state at start:  [-1.60177764 -1.95838247]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.60177764, -1.95838247]), 'currentState': array([4.36793161, 3.90194701]), 'targetState': array([-0.88355253, -0.24565797]), 'effectorPosition': array([-0.74169659, -0.02650454])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9501237275740382
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.60177764, -1.95838247]), 'currentState': array([4.32746982, 4.32345971]), 'targetState': array([-0.88355253, -0.24565797]), 'effectorPosition': array([-1.09071054, -0.22793588])}
episode index:1077
target Thresh 1.7911655268060638
current state at start:  [-1.19825712 -1.82493898]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.19825712, -1.82493898]), 'currentState': array([5.50500558, 3.95824633]), 'targetState': array([-0.0411723 , -0.17928935]), 'effectorPosition': array([-0.28706745, -0.74044865])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9501607185503145
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.19825712, -1.82493898]), 'currentState': array([5.72439463, 3.45824633]), 'targetState': array([-0.0411723 , -0.17928935]), 'effectorPosition': array([-0.12293092, -0.29038337])}
episode index:1078
target Thresh 1.7915827783618121
current state at start:  [-2.55343415  2.20752758]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.55343415,  2.20752758]), 'currentState': array([4.21755721, 2.67302415]), 'targetState': array([ 0.49990075, -0.25192818]), 'effectorPosition': array([ 0.34625334, -0.30931741])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9502069088018897
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.55343415,  2.20752758]), 'currentState': array([4.21755721, 2.67302415]), 'targetState': array([ 0.49990075, -0.25192818]), 'effectorPosition': array([ 0.34625334, -0.30931741])}
episode index:1079
target Thresh 1.7919991962483959
current state at start:  [-1.95241885 -2.348926  ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.95241885, -2.348926  ]), 'currentState': array([4.80051067, 4.21776055]), 'targetState': array([-0.47675053, -0.58392758]), 'effectorPosition': array([-0.83049999, -0.60071663])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9502437542567027
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.95241885, -2.348926  ]), 'currentState': array([5.20166808, 4.04470841]), 'targetState': array([-0.47675053, -0.58392758]), 'effectorPosition': array([-0.51413893, -0.70521526])}
episode index:1080
target Thresh 1.7924147821314875
current state at start:  [-1.71675142  2.70475456]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.71675142,  2.70475456]), 'currentState': array([5.01654995, 2.60064818]), 'targetState': array([0.53642529, 0.3178407 ]), 'effectorPosition': array([0.53406986, 0.01799895])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9502805315423117
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.71675142,  2.70475456]), 'currentState': array([5.4181614 , 2.51992146]), 'targetState': array([0.53642529, 0.3178407 ]), 'effectorPosition': array([0.5646198 , 0.23535481])}
episode index:1081
target Thresh 1.7928295376734307
current state at start:  [ 3.51518758 -2.31778961]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.51518758, -2.31778961]), 'currentState': array([4.01518758, 3.46539569]), 'targetState': array([-0.347501  , -0.02587902]), 'effectorPosition': array([-0.27729296,  0.16445097])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9503264829919029
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.51518758, -2.31778961]), 'currentState': array([4.01518758, 3.46539569]), 'targetState': array([-0.347501  , -0.02587902]), 'effectorPosition': array([-0.27729296,  0.16445097])}
episode index:1082
target Thresh 1.7932434645332485
current state at start:  [-3.85941803  2.51135358]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.85941803,  2.51135358]), 'currentState': array([2.85833765, 2.01135358]), 'targetState': array([-1.11647915, -0.50592001]), 'effectorPosition': array([-0.80349647, -0.70817107])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9503539746973583
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-3.85941803,  2.51135358]), 'currentState': array([2.80332357, 1.72558381]), 'targetState': array([-1.11647915, -0.50592001]), 'effectorPosition': array([-1.12578432, -0.65135966])}
episode index:1083
target Thresh 1.7936565643666484
current state at start:  [ 0.32765657 -2.39254194]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.32765657, -2.39254194]), 'currentState': array([0.7545062 , 3.39064337]), 'targetState': array([-0.01078833,  0.01223204]), 'effectorPosition': array([ 0.191304 , -0.1584585])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9503905485214382
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.32765657, -2.39254194]), 'currentState': array([1.08184657, 2.89064337]), 'targetState': array([-0.01078833,  0.01223204]), 'effectorPosition': array([-0.20451439,  0.14429001])}
episode index:1084
target Thresh 1.794068838826031
current state at start:  [-3.86392618  2.84584984]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.86392618,  2.84584984]), 'currentState': array([2.88843578, 2.34584984]), 'targetState': array([-0.38196347, -0.49063294]), 'effectorPosition': array([-0.46960139, -0.61641376])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9504362715181927
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.86392618,  2.84584984]), 'currentState': array([2.88843578, 2.34584984]), 'targetState': array([-0.38196347, -0.49063294]), 'effectorPosition': array([-0.46960139, -0.61641376])}
episode index:1085
target Thresh 1.7944802895604943
current state at start:  [ 3.71969705 -1.92655337]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.71969705, -1.92655337]), 'currentState': array([4.0302871 , 3.85663194]), 'targetState': array([-0.16529738, -0.17293683]), 'effectorPosition': array([-0.66335745,  0.22320826])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9504545613234245
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 3.71969705, -1.92655337]), 'currentState': array([4.36680186, 3.38953823]), 'targetState': array([-0.16529738, -0.17293683]), 'effectorPosition': array([-0.24126268,  0.05436012])}
episode index:1086
target Thresh 1.794890918215842
current state at start:  [ 1.12990195 -1.6911337 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.12990195, -1.6911337 ]), 'currentState': array([1.54323554, 4.09205161]), 'targetState': array([0.41602124, 0.14377126]), 'effectorPosition': array([0.82491134, 0.3961084 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.950490941671793
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.12990195, -1.6911337 ]), 'currentState': array([1.40262696, 3.59205161]), 'targetState': array([0.41602124, 0.14377126]), 'effectorPosition': array([0.44593317, 0.02547265])}
episode index:1087
target Thresh 1.7953007264345886
current state at start:  [-0.55372858  2.39457215]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.55372858,  2.39457215]), 'currentState': array([6.12817064, 1.91857712]), 'targetState': array([0.8791397 , 0.63647755]), 'effectorPosition': array([0.79643475, 0.82708348])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9505364463209918
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.55372858,  2.39457215]), 'currentState': array([6.12817064, 1.91857712]), 'targetState': array([0.8791397 , 0.63647755]), 'effectorPosition': array([0.79643475, 0.82708348])}
episode index:1088
target Thresh 1.7957097158559683
current state at start:  [-1.05410026 -1.68322553]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.05410026, -1.68322553]), 'currentState': array([4.86222985, 4.09995977]), 'targetState': array([-1.04732945, -0.56166491]), 'effectorPosition': array([-0.74561962, -0.54252894])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9505726846622948
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.05410026, -1.68322553]), 'currentState': array([4.51950195, 4.3763576 ]), 'targetState': array([-1.04732945, -0.56166491]), 'effectorPosition': array([-1.05504653, -0.47685505])}
episode index:1089
target Thresh 1.796117888115939
current state at start:  [-3.03596549  2.17252516]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.03596549,  2.17252516]), 'currentState': array([3.03625572, 2.56250125]), 'targetState': array([-0.02933504, -0.01345306]), 'effectorPosition': array([-0.2196766 , -0.52708796])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9506088565112285
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.03596549,  2.17252516]), 'currentState': array([2.89083221, 2.93341305]), 'targetState': array([-0.02933504, -0.01345306]), 'effectorPosition': array([-0.07220145, -0.19485739])}
episode index:1090
target Thresh 1.7965252448471902
current state at start:  [-1.41899225 -2.74036561]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.41899225, -2.74036561]), 'currentState': array([5.06256872, 3.21622812]), 'targetState': array([-0.1262348 , -0.05607925]), 'effectorPosition': array([-0.06908578, -0.02819615])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.950654127953473
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.41899225, -2.74036561]), 'currentState': array([5.06256872, 3.21622812]), 'targetState': array([-0.1262348 , -0.05607925]), 'effectorPosition': array([-0.06908578, -0.02819615])}
episode index:1091
target Thresh 1.7969317876791497
current state at start:  [ 3.6331283 -1.6301094]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.6331283, -1.6301094]), 'currentState': array([3.35170491, 4.46204375]), 'targetState': array([-1.19950257,  0.48699188]), 'effectorPosition': array([-0.93778539,  0.79062107])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9506632322410614
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([ 3.6331283, -1.6301094]), 'currentState': array([3.60135986, 4.41642903]), 'targetState': array([-1.19950257,  0.48699188]), 'effectorPosition': array([-1.05923149,  0.54287406])}
episode index:1092
target Thresh 1.797337518237989
current state at start:  [-0.75988892 -1.7550175 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.75988892, -1.7550175 ]), 'currentState': array([5.19411979, 4.4127423 ]), 'targetState': array([-0.67354279, -1.05703561]), 'effectorPosition': array([-0.52015474, -1.06727398])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9507083710953698
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.75988892, -1.7550175 ]), 'currentState': array([5.19411979, 4.4127423 ]), 'targetState': array([-0.67354279, -1.05703561]), 'effectorPosition': array([-0.52015474, -1.06727398])}
episode index:1093
target Thresh 1.7977424381466311
current state at start:  [ 3.06672588 -2.14743181]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.06672588, -2.14743181]), 'currentState': array([3.18195351, 3.6357535 ]), 'targetState': array([0.2144381, 0.1902821]), 'effectorPosition': array([-0.13867323,  0.46907962])}
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.9506577585571278
{'reset': False, 'endBeforeDone': False, 'stepCount': 12, 'initial state': array([ 3.06672588, -2.14743181]), 'currentState': array([4.61743616, 3.05471806]), 'targetState': array([0.2144381, 0.1902821]), 'effectorPosition': array([ 0.08601697, -0.01198048])}
episode index:1094
target Thresh 1.7981465490247561
current state at start:  [1.20457657 1.60865377]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.20457657, 1.60865377]), 'currentState': array([0.70457657, 1.83270767]), 'targetState': array([-0.48457545,  1.11429202]), 'effectorPosition': array([-0.06100937,  1.21590439])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9506936875447468
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.20457657, 1.60865377]), 'currentState': array([0.9489642 , 1.96941716]), 'targetState': array([-0.48457545,  1.11429202]), 'effectorPosition': array([-0.3926663 ,  1.03417495])}
episode index:1095
target Thresh 1.798549852488808
current state at start:  [0.18677434 2.2721414 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.18677434, 2.2721414 ]), 'currentState': array([5.96995965, 2.69712418]), 'targetState': array([-0.00820889, -0.07176549]), 'effectorPosition': array([0.22492196, 0.37911929])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9507295509685199
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.18677434, 2.2721414 ]), 'currentState': array([5.46995965, 3.14330307]), 'targetState': array([-0.00820889, -0.07176549]), 'effectorPosition': array([-0.00124162, -0.00117639])}
episode index:1096
target Thresh 1.7989523501520015
current state at start:  [-3.51703706  1.77869122]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.51703706,  1.77869122]), 'currentState': array([3.06843639, 2.25616993]), 'targetState': array([-0.47705295, -0.63191606]), 'effectorPosition': array([-0.42264179, -0.74528473])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.950774464778029
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.51703706,  1.77869122]), 'currentState': array([3.06843639, 2.25616993]), 'targetState': array([-0.47705295, -0.63191606]), 'effectorPosition': array([-0.42264179, -0.74528473])}
episode index:1097
target Thresh 1.7993540436243272
current state at start:  [-1.21000283  2.11874834]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.21000283,  2.11874834]), 'currentState': array([4.65826781, 2.60151565]), 'targetState': array([ 0.45915766, -0.21451136]), 'effectorPosition': array([ 0.50574979, -0.16993815])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9508192967773204
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.21000283,  2.11874834]), 'currentState': array([4.65826781, 2.60151565]), 'targetState': array([ 0.45915766, -0.21451136]), 'effectorPosition': array([ 0.50574979, -0.16993815])}
episode index:1098
target Thresh 1.79975493451256
current state at start:  [ 2.25639492 -2.06274201]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.25639492, -2.06274201]), 'currentState': array([2.63297972, 3.78814803]), 'targetState': array([-0.08618615,  0.50135332]), 'effectorPosition': array([0.11708021, 0.62447162])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9508640471897158
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.25639492, -2.06274201]), 'currentState': array([2.63297972, 3.78814803]), 'targetState': array([-0.08618615,  0.50135332]), 'effectorPosition': array([0.11708021, 0.62447162])}
episode index:1099
target Thresh 1.8001550244202638
current state at start:  [-0.25832893  2.97591453]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.25832893,  2.97591453]), 'currentState': array([0.12907593, 2.59667351]), 'targetState': array([-0.16243404,  0.74446958]), 'effectorPosition': array([0.07690524, 0.53267924])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9508817153286344
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-0.25832893,  2.97591453]), 'currentState': array([0.39837412, 2.44192925]), 'targetState': array([-0.16243404,  0.74446958]), 'effectorPosition': array([-0.03326176,  0.68467195])}
episode index:1100
target Thresh 1.800554314947799
current state at start:  [-0.34354914 -3.00456137]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.34354914, -3.00456137]), 'currentState': array([6.06339176, 2.96334917]), 'targetState': array([0.27654996, 0.15891275]), 'effectorPosition': array([0.05411885, 0.16958144])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9509263277579453
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.34354914, -3.00456137]), 'currentState': array([6.06339176, 2.96334917]), 'targetState': array([0.27654996, 0.15891275]), 'effectorPosition': array([0.05411885, 0.16958144])}
episode index:1101
target Thresh 1.800952807692328
current state at start:  [ 1.73714649 -2.29688904]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.73714649, -2.29688904]), 'currentState': array([1.66909634, 3.64792254]), 'targetState': array([ 0.26949057, -0.1160309 ]), 'effectorPosition': array([0.47031585, 0.17245991])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9509617848107965
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.73714649, -2.29688904]), 'currentState': array([1.5694439 , 3.36912384]), 'targetState': array([ 0.26949057, -0.1160309 ]), 'effectorPosition': array([0.22560768, 0.02546865])}
episode index:1102
target Thresh 1.8013505042478224
current state at start:  [-1.12405976  2.06497678]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.12405976,  2.06497678]), 'currentState': array([5.65912555, 2.56497678]), 'targetState': array([0.29267652, 0.63146028]), 'effectorPosition': array([0.44978494, 0.34794918])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9509882020503153
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.12405976,  2.06497678]), 'currentState': array([6.06036757, 2.46854936]), 'targetState': array([0.29267652, 0.63146028]), 'effectorPosition': array([0.35043186, 0.5597688 ])}
episode index:1103
target Thresh 1.8017474062050687
current state at start:  [ 0.90362393 -1.70673591]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.90362393, -1.70673591]), 'currentState': array([1.40362393, 4.84155273]), 'targetState': array([1.00412   , 0.69775828]), 'effectorPosition': array([1.16567259, 0.94805971])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.9509795896837852
{'reset': False, 'endBeforeDone': False, 'stepCount': 7, 'initial state': array([ 0.90362393, -1.70673591]), 'currentState': array([1.50031193, 4.67261293]), 'targetState': array([1.00412   , 0.69775828]), 'effectorPosition': array([1.06435352, 0.88747983])}
episode index:1104
target Thresh 1.8021435151516758
current state at start:  [-3.67793974  1.73727415]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.67793974,  1.73727415]), 'currentState': array([2.97131017, 1.58637506]), 'targetState': array([-1.19534065, -0.66952152]), 'effectorPosition': array([-1.13962433, -0.81859647])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9510239520460623
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.67793974,  1.73727415]), 'currentState': array([2.97131017, 1.58637506]), 'targetState': array([-1.19534065, -0.66952152]), 'effectorPosition': array([-1.13962433, -0.81859647])}
episode index:1105
target Thresh 1.8025388326720795
current state at start:  [-1.44559274 -1.88657742]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.44559274, -1.88657742]), 'currentState': array([5.08849826, 3.94083436]), 'targetState': array([-0.18991753,  0.01195592]), 'effectorPosition': array([-0.5555206 , -0.54488155])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9510591925957494
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.44559274, -1.88657742]), 'currentState': array([5.27425382, 3.47650672]), 'targetState': array([-0.18991753,  0.01195592]), 'effectorPosition': array([-0.24855532, -0.22213316])}
episode index:1106
target Thresh 1.8029333603475506
current state at start:  [ 1.92416218 -2.07234906]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.92416218, -2.07234906]), 'currentState': array([1.73767355, 4.71083625]), 'targetState': array([0.73005977, 1.1714949 ]), 'effectorPosition': array([0.82026123, 1.15068069])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.951103402900541
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.92416218, -2.07234906]), 'currentState': array([1.73767355, 4.71083625]), 'targetState': array([0.73005977, 1.1714949 ]), 'effectorPosition': array([0.82026123, 1.15068069])}
episode index:1107
target Thresh 1.8033270997562005
current state at start:  [ 3.95780001 -2.4721756 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.95780001, -2.4721756 ]), 'currentState': array([4.39530335, 3.45115924]), 'targetState': array([ 0.07346295, -0.57565976]), 'effectorPosition': array([-0.30427983,  0.04982358])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.9511033005963888
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([ 3.95780001, -2.4721756 ]), 'currentState': array([5.79653175, 3.82847678]), 'targetState': array([ 0.07346295, -0.57565976]), 'effectorPosition': array([-0.09611791, -0.66656588])}
episode index:1108
target Thresh 1.803720052472987
current state at start:  [-1.71907966  1.89320915]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.71907966,  1.89320915]), 'currentState': array([4.21208857, 2.35617288]), 'targetState': array([-0.01195788, -0.00734721]), 'effectorPosition': array([ 0.47995109, -0.59620798])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9511294473045977
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.71907966,  1.89320915]), 'currentState': array([3.58624278, 3.04749252]), 'targetState': array([-0.01195788, -0.00734721]), 'effectorPosition': array([ 0.03642276, -0.08672765])}
episode index:1109
target Thresh 1.8041122200697217
current state at start:  [-0.92227673  1.79195782]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.92227673,  1.79195782]), 'currentState': array([4.86090858, 2.09143171]), 'targetState': array([ 0.66353744, -0.50805079]), 'effectorPosition': array([ 0.93232032, -0.36866781])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9511644658205395
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.92227673,  1.79195782]), 'currentState': array([4.36090858, 2.10832208]), 'targetState': array([ 0.66353744, -0.50805079]), 'effectorPosition': array([ 0.63845534, -0.75389011])}
episode index:1110
target Thresh 1.8045036041150757
current state at start:  [ 2.78394245 -2.75773431]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.78394245, -2.75773431]), 'currentState': array([2.3426569, 3.9356203]), 'targetState': array([0.45503636, 0.77428539]), 'effectorPosition': array([0.30251819, 0.71170613])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9512084221969386
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.78394245, -2.75773431]), 'currentState': array([2.3426569, 3.9356203]), 'targetState': array([0.45503636, 0.77428539]), 'effectorPosition': array([0.30251819, 0.71170613])}
episode index:1111
target Thresh 1.8048942061745852
current state at start:  [0.01951221 2.32029111]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.01951221, 2.32029111]), 'currentState': array([5.85295323, 2.71187748]), 'targetState': array([-0.15537994,  0.46381527]), 'effectorPosition': array([0.25639154, 0.34072641])}
done in step count: 61
reward sum = 0.5416850759668536
running average episode reward sum: 0.9508401458064439
{'reset': False, 'endBeforeDone': False, 'stepCount': 62, 'initial state': array([0.01951221, 2.32029111]), 'currentState': array([3.59295823, 3.62851066]), 'targetState': array([-0.15537994,  0.46381527]), 'effectorPosition': array([-0.30867902,  0.37034983])}
episode index:1112
target Thresh 1.8052840278106594
current state at start:  [-3.59163964  2.49456295]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.59163964,  2.49456295]), 'currentState': array([2.4008602 , 2.98260418]), 'targetState': array([ 0.07358686, -0.00951792]), 'effectorPosition': array([-0.11614593, -0.10832478])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9508843145882889
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.59163964,  2.49456295]), 'currentState': array([2.4008602 , 2.98260418]), 'targetState': array([ 0.07358686, -0.00951792]), 'effectorPosition': array([-0.11614593, -0.10832478])}
episode index:1113
target Thresh 1.8056730705825854
current state at start:  [-0.7837684   1.77440155]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.7837684 ,  1.77440155]), 'currentState': array([5.93400027, 2.10128201]), 'targetState': array([0.82058257, 0.51929586]), 'effectorPosition': array([0.7593428 , 0.64147787])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9509284040725006
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.7837684 ,  1.77440155]), 'currentState': array([5.93400027, 2.10128201]), 'targetState': array([0.82058257, 0.51929586]), 'effectorPosition': array([0.7593428 , 0.64147787])}
episode index:1114
target Thresh 1.8060613360465345
current state at start:  [-0.81281694 -1.88654083]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.81281694, -1.88654083]), 'currentState': array([4.99790815, 4.56874162]), 'targetState': array([-0.60195484, -1.04989436]), 'effectorPosition': array([-0.70829742, -1.10091192])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9509724144724355
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.81281694, -1.88654083]), 'currentState': array([4.99790815, 4.56874162]), 'targetState': array([-0.60195484, -1.04989436]), 'effectorPosition': array([-0.70829742, -1.10091192])}
episode index:1115
target Thresh 1.806448825755569
current state at start:  [-0.80755169 -2.43229827]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.80755169, -2.43229827]), 'currentState': array([5.50895458, 4.35088704]), 'targetState': array([-0.34846255, -1.30607491]), 'effectorPosition': array([-0.19188412, -1.12063441])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9510163460006861
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.80755169, -2.43229827]), 'currentState': array([5.50895458, 4.35088704]), 'targetState': array([-0.34846255, -1.30607491]), 'effectorPosition': array([-0.19188412, -1.12063441])}
episode index:1116
target Thresh 1.8068355412596486
current state at start:  [-0.30540555 -2.72628626]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.30540555, -2.72628626]), 'currentState': array([6.06794985, 3.07976878]), 'targetState': array([0.28163512, 0.0167836 ]), 'effectorPosition': array([0.01506218, 0.05995085])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9510512463176057
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.30540555, -2.72628626]), 'currentState': array([5.57360749, 2.93471857]), 'targetState': array([0.28163512, 0.0167836 ]), 'effectorPosition': array([0.14999779, 0.14193356])}
episode index:1117
target Thresh 1.8072214841056358
current state at start:  [ 3.15547466 -2.05152562]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.15547466, -2.05152562]), 'currentState': array([3.65547466, 4.30344369]), 'targetState': array([-1.10940622,  0.11277006]), 'effectorPosition': array([-0.97558706,  0.50293763])}
done in step count: 35
reward sum = 0.7034476949995692
running average episode reward sum: 0.9508297762359259
{'reset': False, 'endBeforeDone': False, 'stepCount': 36, 'initial state': array([ 3.15547466, -2.05152562]), 'currentState': array([4.07368818, 4.5169087 ]), 'targetState': array([-1.10940622,  0.11277006]), 'effectorPosition': array([-1.26793738, -0.06212433])}
episode index:1118
target Thresh 1.8076066558373023
current state at start:  [1.26238168 2.22352735]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.26238168, 2.22352735]), 'currentState': array([0.80248515, 2.66753987]), 'targetState': array([-0.17660944,  0.03258376]), 'effectorPosition': array([-0.25162734,  0.39652571])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.950864780904169
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.26238168, 2.22352735]), 'currentState': array([0.44141854, 3.02865843]), 'targetState': array([-0.17660944,  0.03258376]), 'effectorPosition': array([-0.04238586,  0.10461371])}
episode index:1119
target Thresh 1.8079910579953355
current state at start:  [ 0.5957724  -2.01982774]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.5957724 , -2.01982774]), 'currentState': array([0.56451532, 3.87039743]), 'targetState': array([ 0.55845106, -0.53341631]), 'effectorPosition': array([ 0.57091872, -0.42674344])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9509086516355046
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.5957724 , -2.01982774]), 'currentState': array([0.56451532, 3.87039743]), 'targetState': array([ 0.55845106, -0.53341631]), 'effectorPosition': array([ 0.57091872, -0.42674344])}
episode index:1120
target Thresh 1.808374692117345
current state at start:  [ 0.50560906 -1.86571329]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.50560906, -1.86571329]), 'currentState': array([0.97285067, 4.509485  ]), 'targetState': array([1.28433776, 0.32130915]), 'effectorPosition': array([1.25904273, 0.10854606])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9509524440961331
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.50560906, -1.86571329]), 'currentState': array([0.97285067, 4.509485  ]), 'targetState': array([1.28433776, 0.32130915]), 'effectorPosition': array([1.25904273, 0.10854606])}
episode index:1121
target Thresh 1.8087575597378671
current state at start:  [-1.77813724 -2.12914872]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.77813724, -2.12914872]), 'currentState': array([4.2123188 , 4.27771232]), 'targetState': array([-0.91372464, -0.24607727]), 'effectorPosition': array([-1.07350923, -0.0731002 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9509961584953344
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.77813724, -2.12914872]), 'currentState': array([4.2123188 , 4.27771232]), 'targetState': array([-0.91372464, -0.24607727]), 'effectorPosition': array([-1.07350923, -0.0731002 ])}
episode index:1122
target Thresh 1.8091396623883735
current state at start:  [1.1245668  1.78686432]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.1245668 , 1.78686432]), 'currentState': array([0.67491648, 2.19851763]), 'targetState': array([0.2404398 , 0.43782633]), 'effectorPosition': array([-0.1835013 ,  0.88978836])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9510220746498355
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([1.1245668 , 1.78686432]), 'currentState': array([6.12897716, 2.62645967]), 'targetState': array([0.2404398 , 0.43782633]), 'effectorPosition': array([0.20390282, 0.46687172])}
episode index:1123
target Thresh 1.8095210015972747
current state at start:  [-3.3181177   2.61274326]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.3181177 ,  2.61274326]), 'currentState': array([2.52861921, 3.07669351]), 'targetState': array([-0.14882198,  0.30659826]), 'effectorPosition': array([-0.03903235, -0.05183528])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9510392249392929
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-3.3181177 ,  2.61274326]), 'currentState': array([2.76247948, 3.55035946]), 'targetState': array([-0.14882198,  0.30659826]), 'effectorPosition': array([0.07056715, 0.39974605])}
episode index:1124
target Thresh 1.8099015788899284
current state at start:  [-0.70996009 -2.61143003]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.70996009, -2.61143003]), 'currentState': array([5.85865365, 3.1961458 ]), 'targetState': array([ 0.19980061, -0.11290321]), 'effectorPosition': array([-0.02110337, -0.05029866])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9510827456282358
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.70996009, -2.61143003]), 'currentState': array([5.85865365, 3.1961458 ]), 'targetState': array([ 0.19980061, -0.11290321]), 'effectorPosition': array([-0.02110337, -0.05029866])}
episode index:1125
target Thresh 1.810281395788644
current state at start:  [1.04547156 1.61567376]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.04547156, 1.61567376]), 'currentState': array([1.53842469, 1.93146504]), 'targetState': array([-0.87509988,  0.97652363]), 'effectorPosition': array([-0.91422681,  0.67704456])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.9510742175676433
{'reset': False, 'endBeforeDone': False, 'stepCount': 7, 'initial state': array([1.04547156, 1.61567376]), 'currentState': array([1.39171299, 1.89696953]), 'targetState': array([-0.87509988,  0.97652363]), 'effectorPosition': array([-0.81107413,  0.83744734])}
episode index:1126
target Thresh 1.81066045381269
current state at start:  [-0.91400131  2.28558259]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.91400131,  2.28558259]), 'currentState': array([4.92407788, 2.78558259]), 'targetState': array([ 0.08162996, -0.27967955]), 'effectorPosition': array([0.35393208, 0.01192631])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.9510573507800117
{'reset': False, 'endBeforeDone': False, 'stepCount': 8, 'initial state': array([-0.91400131,  2.28558259]), 'currentState': array([5.68572216, 3.46200184]), 'targetState': array([ 0.08162996, -0.27967955]), 'effectorPosition': array([-0.13510005, -0.28902375])}
episode index:1127
target Thresh 1.8110387544782989
current state at start:  [0.06285548 2.47713094]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.06285548, 2.47713094]), 'currentState': array([5.91358244, 2.95598688]), 'targetState': array([-0.02491281,  0.05307651]), 'effectorPosition': array([0.0826804 , 0.16587547])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9511007396534338
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.06285548, 2.47713094]), 'currentState': array([5.91358244, 2.95598688]), 'targetState': array([-0.02491281,  0.05307651]), 'effectorPosition': array([0.0826804 , 0.16587547])}
episode index:1128
target Thresh 1.8114162992986738
current state at start:  [-1.94305139  2.58565169]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.94305139,  2.58565169]), 'currentState': array([4.83677913, 2.08565169]), 'targetState': array([ 1.0712438, -0.7316393]), 'effectorPosition': array([ 0.92661572, -0.39568342])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.951117744312731
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-1.94305139,  2.58565169]), 'currentState': array([4.73002329, 1.64139813]), 'targetState': array([ 1.0712438, -0.7316393]), 'effectorPosition': array([ 1.01374311, -0.91172286])}
episode index:1129
target Thresh 1.8117930897839942
current state at start:  [1.99171357 2.28001191]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.99171357, 2.28001191]), 'currentState': array([1.50338544, 2.68728336]), 'targetState': array([0.05735332, 0.09377095]), 'effectorPosition': array([-0.43101237,  0.13076557])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9511521533885605
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.99171357, 2.28001191]), 'currentState': array([1.06334772, 2.9927946 ]), 'targetState': array([0.05735332, 0.09377095]), 'effectorPosition': array([-0.12419849,  0.0816993 ])}
episode index:1130
target Thresh 1.8121691274414229
current state at start:  [-1.5255188  -1.88000126]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.5255188 , -1.88000126]), 'currentState': array([5.23154421, 3.90318405]), 'targetState': array([-0.01660191, -0.188936  ]), 'effectorPosition': array([-0.46208281, -0.58223877])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9511865016172178
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.5255188 , -1.88000126]), 'currentState': array([5.49807562, 3.40318405]), 'targetState': array([-0.01660191, -0.188936  ]), 'effectorPosition': array([-0.15875491, -0.20697247])}
episode index:1131
target Thresh 1.812544413775111
current state at start:  [-2.12426588 -1.73214008]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.12426588, -1.73214008]), 'currentState': array([3.7879223 , 4.05104523]), 'targetState': array([-0.62165423, -0.13101872]), 'effectorPosition': array([-0.78328614,  0.39762686])}
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.9511292563611213
{'reset': False, 'endBeforeDone': False, 'stepCount': 13, 'initial state': array([-2.12426588, -1.73214008]), 'currentState': array([4.26834279, 3.98734816]), 'targetState': array([-0.62165423, -0.13101872]), 'effectorPosition': array([-0.82058892,  0.01737318])}
episode index:1132
target Thresh 1.8129189502862042
current state at start:  [1.86299313 1.8646488 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.86299313, 1.8646488 ]), 'currentState': array([1.49358816, 1.69189538]), 'targetState': array([-0.9849583,  0.6495595]), 'effectorPosition': array([-0.92190547,  0.95314414])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9511635641666278
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.86299313, 1.8646488 ]), 'currentState': array([1.51613683, 1.79156474]), 'targetState': array([-0.9849583,  0.6495595]), 'effectorPosition': array([-0.93160332,  0.83316046])}
episode index:1133
target Thresh 1.813292738472849
current state at start:  [-0.67924497  3.09172905]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.67924497,  3.09172905]), 'currentState': array([5.18745306, 3.47169025]), 'targetState': array([-0.82414943,  0.19078474]), 'effectorPosition': array([-0.26354726, -0.19626873])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9511890813058107
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-0.67924497,  3.09172905]), 'currentState': array([4.31735721, 3.79610278]), 'targetState': array([-0.82414943,  0.19078474]), 'effectorPosition': array([-0.64141392,  0.04353961])}
episode index:1134
target Thresh 1.813665779830199
current state at start:  [-1.14929817 -2.56422397]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.14929817, -2.56422397]), 'currentState': array([5.63388714, 4.03322715]), 'targetState': array([-0.00175963, -1.09281847]), 'effectorPosition': array([-0.17427163, -0.84459888])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9512145534808717
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.14929817, -2.56422397]), 'currentState': array([5.60655683, 4.45011167]), 'targetState': array([-0.00175963, -1.09281847]), 'effectorPosition': array([-0.02722397, -1.21683917])}
episode index:1135
target Thresh 1.8140380758504198
current state at start:  [1.31141427 1.83646166]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.31141427, 1.83646166]), 'currentState': array([0.81141427, 1.70260371]), 'targetState': array([-0.50017789,  1.00292952]), 'effectorPosition': array([-0.12098059,  1.31244488])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9512486955992864
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.31141427, 1.83646166]), 'currentState': array([1.10751968, 1.90052603]), 'targetState': array([-0.50017789,  1.00292952]), 'effectorPosition': array([-0.54421409,  1.02774336])}
episode index:1136
target Thresh 1.8144096280226958
current state at start:  [0.21171527 1.90575085]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.21171527, 1.90575085]), 'currentState': array([0.46651514, 1.8459343 ]), 'targetState': array([0.22510666, 1.12243152]), 'effectorPosition': array([0.21763335, 1.18712943])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9512915727359625
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.21171527, 1.90575085]), 'currentState': array([0.46651514, 1.8459343 ]), 'targetState': array([0.22510666, 1.12243152]), 'effectorPosition': array([0.21763335, 1.18712943])}
episode index:1137
target Thresh 1.8147804378332366
current state at start:  [0.22837612 2.98917016]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.22837612, 2.98917016]), 'currentState': array([6.10484109, 3.39514204]), 'targetState': array([-0.34115675, -0.08837112]), 'effectorPosition': array([-0.01303465, -0.2525346 ])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9513168876984089
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([0.22837612, 2.98917016]), 'currentState': array([5.24127752, 3.47764827]), 'targetState': array([-0.34115675, -0.08837112]), 'effectorPosition': array([-0.25648499, -0.2146858 ])}
episode index:1138
target Thresh 1.8151505067652818
current state at start:  [ 2.33404158 -2.32402493]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.33404158, -2.32402493]), 'currentState': array([2.3717865 , 3.45916038]), 'targetState': array([0.09817463, 0.25204748]), 'effectorPosition': array([0.18142561, 0.25901603])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9513596296758466
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.33404158, -2.32402493]), 'currentState': array([2.3717865 , 3.45916038]), 'targetState': array([0.09817463, 0.25204748]), 'effectorPosition': array([0.18142561, 0.25901603])}
episode index:1139
target Thresh 1.8155198362991076
current state at start:  [-2.43569552  2.42783582]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.43569552,  2.42783582]), 'currentState': array([4.2948438 , 2.75945842]), 'targetState': array([1.081817 , 0.0698542]), 'effectorPosition': array([ 0.31161494, -0.21715052])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9513762431585873
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-2.43569552,  2.42783582]), 'currentState': array([5.48247601, 1.91212346]), 'targetState': array([1.081817 , 0.0698542]), 'effectorPosition': array([1.13959212, 0.17847653])}
episode index:1140
target Thresh 1.8158884279120326
current state at start:  [1.09898382 2.40186082]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.09898382, 2.40186082]), 'currentState': array([1.39963359, 2.72302156]), 'targetState': array([-0.61984504,  0.08905861]), 'effectorPosition': array([-0.38581163,  0.15429865])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9514188581952581
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.09898382, 2.40186082]), 'currentState': array([1.39963359, 2.72302156]), 'targetState': array([-0.61984504,  0.08905861]), 'effectorPosition': array([-0.38581163,  0.15429865])}
episode index:1141
target Thresh 1.8162562830784237
current state at start:  [-0.88718724  3.01828472]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.88718724,  3.01828472]), 'currentState': array([5.19857969, 2.6812259 ]), 'targetState': array([ 0.44880875, -0.02219325]), 'effectorPosition': array([0.44144033, 0.11554738])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9514613985996405
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.88718724,  3.01828472]), 'currentState': array([5.19857969, 2.6812259 ]), 'targetState': array([ 0.44880875, -0.02219325]), 'effectorPosition': array([0.44144033, 0.11554738])}
episode index:1142
target Thresh 1.8166234032697022
current state at start:  [0.13699649 2.3416086 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.13699649, 2.3416086 ]), 'currentState': array([6.12258377, 2.7430348 ]), 'targetState': array([-0.20394629,  0.51742726]), 'effectorPosition': array([0.13942994, 0.37056177])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9506289739289496
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([0.13699649, 2.3416086 ]), 'currentState': array([0.12697576, 2.73189557]), 'targetState': array([-0.20394629,  0.51742726]), 'effectorPosition': array([0.03164957, 0.4056048 ])}
episode index:1143
target Thresh 1.8169897899543492
current state at start:  [-1.92035574  1.78588061]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.92035574,  1.78588061]), 'currentState': array([3.87453542, 1.55860845]), 'targetState': array([ 0.37962195, -1.23069838]), 'effectorPosition': array([-0.08325673, -1.42036737])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9506633891615293
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.92035574,  1.78588061]), 'currentState': array([4.36624912, 1.44385599]), 'targetState': array([ 0.37962195, -1.23069838]), 'effectorPosition': array([ 0.55089993, -1.39631968])}
episode index:1144
target Thresh 1.817355444597912
current state at start:  [ 3.81215908 -2.40306051]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.81215908, -2.40306051]), 'currentState': array([4.31215908, 3.42567127]), 'targetState': array([-0.35801989, -0.47826192]), 'effectorPosition': array([-0.27373979,  0.07229058])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9506720639395541
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([ 3.81215908, -2.40306051]), 'currentState': array([5.38260146, 3.87896096]), 'targetState': array([-0.35801989, -0.47826192]), 'effectorPosition': array([-0.36555737, -0.62119785])}
episode index:1145
target Thresh 1.81772036866301
current state at start:  [-0.21770785  1.73320389]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.21770785,  1.73320389]), 'currentState': array([5.64467656, 2.19493818]), 'targetState': array([0.41588413, 0.20313642]), 'effectorPosition': array([0.81735183, 0.40389815])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9507063815102875
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.21770785,  1.73320389]), 'currentState': array([5.45092607, 2.59513438]), 'targetState': array([0.41588413, 0.20313642]), 'effectorPosition': array([0.48230699, 0.24215532])}
episode index:1146
target Thresh 1.8180845636093392
current state at start:  [-0.12116896 -2.37765945]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.12116896, -2.37765945]), 'currentState': array([6.00530392, 3.88679725]), 'targetState': array([ 0.10376407, -0.64132187]), 'effectorPosition': array([ 0.06886139, -0.72481705])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9507493576380031
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.12116896, -2.37765945]), 'currentState': array([6.00530392, 3.88679725]), 'targetState': array([ 0.10376407, -0.64132187]), 'effectorPosition': array([ 0.06886139, -0.72481705])}
episode index:1147
target Thresh 1.8184480308936806
current state at start:  [ 2.28837249 -2.39315511]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.28837249, -2.39315511]), 'currentState': array([2.769606 , 3.3900302]), 'targetState': array([-0.25478343,  0.20776367]), 'effectorPosition': array([0.06077041, 0.2402319 ])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9507749243996424
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 2.28837249, -2.39315511]), 'currentState': array([3.2271913 , 3.36698296]), 'targetState': array([-0.25478343,  0.20776367]), 'effectorPosition': array([-0.04430726,  0.22050615])}
episode index:1148
target Thresh 1.8188107719699032
current state at start:  [-0.32237509 -2.16870446]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.32237509, -2.16870446]), 'currentState': array([0.15860102, 4.294604  ]), 'targetState': array([ 0.92173902, -0.98135684]), 'effectorPosition': array([ 0.73115735, -0.80866251])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9508090628466401
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.32237509, -2.16870446]), 'currentState': array([0.23125605, 4.39092939]), 'targetState': array([ 0.92173902, -0.98135684]), 'effectorPosition': array([ 0.88329801, -0.76673411])}
episode index:1149
target Thresh 1.819172788288972
current state at start:  [-2.85652188  2.9843705 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.85652188,  2.9843705 ]), 'currentState': array([3.91460162, 2.4843705 ]), 'targetState': array([ 0.43446929, -0.80009303]), 'effectorPosition': array([ 0.27749142, -0.58276398])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9508431419224256
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.85652188,  2.9843705 ]), 'currentState': array([4.22426372, 2.00362203]), 'targetState': array([ 0.43446929, -0.80009303]), 'effectorPosition': array([ 0.52950045, -0.93848499])}
episode index:1150
target Thresh 1.8195340812989533
current state at start:  [0.62523069 2.44442591]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.62523069, 2.44442591]), 'currentState': array([0.13348149, 2.90832066]), 'targetState': array([-0.01131586, -0.00719055]), 'effectorPosition': array([-0.00392049,  0.23271042])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9508858498790526
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.62523069, 2.44442591]), 'currentState': array([0.13348149, 2.90832066]), 'targetState': array([-0.01131586, -0.00719055]), 'effectorPosition': array([-0.00392049,  0.23271042])}
episode index:1151
target Thresh 1.819894652445019
current state at start:  [ 2.4849995  -2.04081572]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.4849995 , -2.04081572]), 'currentState': array([1.9849995, 3.942591 ]), 'targetState': array([0.5708701 , 0.70121126]), 'effectorPosition': array([0.53497896, 0.56728928])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9509284836899214
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.4849995 , -2.04081572]), 'currentState': array([1.9849995, 3.942591 ]), 'targetState': array([0.5708701 , 0.70121126]), 'effectorPosition': array([0.53497896, 0.56728928])}
episode index:1152
target Thresh 1.8202545031694541
current state at start:  [0.52414187 2.16124011]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.52414187, 2.16124011]), 'currentState': array([0.03130623, 1.67097375]), 'targetState': array([0.30244185, 1.26425925]), 'effectorPosition': array([0.86840486, 1.02266959])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9509623705210664
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.52414187, 2.16124011]), 'currentState': array([0.51143312, 1.90757661]), 'targetState': array([0.30244185, 1.26425925]), 'effectorPosition': array([0.12194391, 1.15075182])}
episode index:1153
target Thresh 1.8206136349116626
current state at start:  [-2.65392555  1.81028827]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.65392555,  1.81028827]), 'currentState': array([4.09394663, 1.95855105]), 'targetState': array([ 0.53387909, -1.1025158 ]), 'effectorPosition': array([ 0.39374268, -1.04342951])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.951004864134133
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.65392555,  1.81028827]), 'currentState': array([4.09394663, 1.95855105]), 'targetState': array([ 0.53387909, -1.1025158 ]), 'effectorPosition': array([ 0.39374268, -1.04342951])}
episode index:1154
target Thresh 1.8209720491081713
current state at start:  [-1.10063601  2.46437261]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.10063601,  2.46437261]), 'currentState': array([5.34836274, 1.98940889]), 'targetState': array([ 1.37511369, -0.30142716]), 'effectorPosition': array([1.08754873, 0.06520241])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9510386261565277
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.10063601,  2.46437261]), 'currentState': array([5.16024858, 1.66269574]), 'targetState': array([ 1.37511369, -0.30142716]), 'effectorPosition': array([ 1.29086978, -0.38744676])}
episode index:1155
target Thresh 1.8213297471926377
current state at start:  [-0.55035454  1.6168492 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.55035454,  1.6168492 ]), 'currentState': array([6.20748747, 1.93898125]), 'targetState': array([0.83975469, 0.80761902]), 'effectorPosition': array([0.70880172, 0.88190416])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9510809802861501
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.55035454,  1.6168492 ]), 'currentState': array([6.20748747, 1.93898125]), 'targetState': array([0.83975469, 0.80761902]), 'effectorPosition': array([0.70880172, 0.88190416])}
episode index:1156
target Thresh 1.8216867305958548
current state at start:  [-2.78255074  2.03597424]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.78255074,  2.03597424]), 'currentState': array([3.57476446, 2.53597424]), 'targetState': array([ 0.1196549 , -0.19709487]), 'effectorPosition': array([ 0.07752895, -0.59134494])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9511146181597143
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.78255074,  2.03597424]), 'currentState': array([3.48834269, 2.99645636]), 'targetState': array([ 0.1196549 , -0.19709487]), 'effectorPosition': array([ 0.03926255, -0.13959243])}
episode index:1157
target Thresh 1.8220430007457566
current state at start:  [1.81091939 2.11568767]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.81091939, 2.11568767]), 'currentState': array([2.21187212, 1.77637407]), 'targetState': array([-1.3518805 ,  0.00533849]), 'effectorPosition': array([-1.26055156,  0.05238524])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9511568335153623
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.81091939, 2.11568767]), 'currentState': array([2.21187212, 1.77637407]), 'targetState': array([-1.3518805 ,  0.00533849]), 'effectorPosition': array([-1.26055156,  0.05238524])}
episode index:1158
target Thresh 1.8223985590674239
current state at start:  [-3.34712657  2.03743687]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.34712657,  2.03743687]), 'currentState': array([3.14451454, 2.53743687]), 'targetState': array([ 0.15085388, -0.31501606]), 'effectorPosition': array([-0.17535745, -0.5685823 ])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9511818060489987
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-3.34712657,  2.03743687]), 'currentState': array([3.55007316, 2.65026289]), 'targetState': array([ 0.15085388, -0.31501606]), 'effectorPosition': array([ 0.07884451, -0.47996982])}
episode index:1159
target Thresh 1.8227534069830909
current state at start:  [ 2.27968767 -2.46037216]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.27968767, -2.46037216]), 'currentState': array([2.15855336, 3.38214549]), 'targetState': array([ 0.06936186, -0.04554505]), 'effectorPosition': array([0.18229384, 0.15606449])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9512238906989564
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.27968767, -2.46037216]), 'currentState': array([2.15855336, 3.38214549]), 'targetState': array([ 0.06936186, -0.04554505]), 'effectorPosition': array([0.18229384, 0.15606449])}
episode index:1160
target Thresh 1.8231075459121493
current state at start:  [0.28967243 1.80112429]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.28967243, 1.80112429]), 'currentState': array([0.6566657 , 2.07658286]), 'targetState': array([-0.12566888,  1.1823216 ]), 'effectorPosition': array([-0.12574748,  1.00756949])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9512659028516706
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.28967243, 1.80112429]), 'currentState': array([0.6566657 , 2.07658286]), 'targetState': array([-0.12566888,  1.1823216 ]), 'effectorPosition': array([-0.12574748,  1.00756949])}
episode index:1161
target Thresh 1.8234609772711554
current state at start:  [-0.29510312 -2.74728999]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.29510312, -2.74728999]), 'currentState': array([6.21974422, 3.99805072]), 'targetState': array([ 0.66440742, -0.94112039]), 'effectorPosition': array([ 0.29628929, -0.77587207])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9512992368423318
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.29510312, -2.74728999]), 'currentState': array([0.17632303, 4.37133673]), 'targetState': array([ 0.66440742, -0.94112039]), 'effectorPosition': array([ 0.82051011, -0.81105198])}
episode index:1162
target Thresh 1.8238137024738355
current state at start:  [-1.6044501   1.77153944]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.6044501 ,  1.77153944]), 'currentState': array([4.27332834, 2.08141886]), 'targetState': array([ 0.4062047 , -0.55615531]), 'effectorPosition': array([ 0.57235115, -0.83365055])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9513325135088474
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.6044501 ,  1.77153944]), 'currentState': array([4.25572315, 2.3208535 ]), 'targetState': array([ 0.4062047 , -0.55615531]), 'effectorPosition': array([ 0.51631055, -0.6083274 ])}
episode index:1163
target Thresh 1.8241657229310904
current state at start:  [ 3.36780701 -2.2457774 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.36780701, -2.2457774 ]), 'currentState': array([3.52022092, 3.65369788]), 'targetState': array([-0.04765495,  0.24735279]), 'effectorPosition': array([-0.30033069,  0.40788697])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9513657329989601
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.36780701, -2.2457774 ]), 'currentState': array([3.77067227, 3.31666363]), 'targetState': array([-0.04765495,  0.24735279]), 'effectorPosition': array([-0.11484614,  0.13184084])}
episode index:1164
target Thresh 1.8245170400510025
current state at start:  [1.84137893 1.77700994]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.84137893, 1.77700994]), 'currentState': array([1.45840702, 2.12310186]), 'targetState': array([-0.4937456 ,  0.85513366]), 'effectorPosition': array([-0.79263449,  0.5678273 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9513988954599052
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.84137893, 1.77700994]), 'currentState': array([1.07162741, 2.02456033]), 'targetState': array([-0.4937456 ,  0.85513366]), 'effectorPosition': array([-0.52027335,  0.92337001])}
episode index:1165
target Thresh 1.824867655238841
current state at start:  [-2.06116555  2.16904992]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.06116555,  2.16904992]), 'currentState': array([3.84553504, 2.16747254]), 'targetState': array([-0.03946184, -0.92584115]), 'effectorPosition': array([ 0.20142698, -0.9141307 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.951440577367744
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.06116555,  2.16904992]), 'currentState': array([3.84553504, 2.16747254]), 'targetState': array([-0.03946184, -0.92584115]), 'effectorPosition': array([ 0.20142698, -0.9141307 ])}
episode index:1166
target Thresh 1.8252175698970667
current state at start:  [ 3.84781721 -2.54322923]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.84781721, -2.54322923]), 'currentState': array([4.34781721, 4.2120918 ]), 'targetState': array([-1.38713566,  0.18036645]), 'effectorPosition': array([-1.00528909, -0.17326628])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9514736188610021
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.84781721, -2.54322923]), 'currentState': array([3.98514476, 4.5519832 ]), 'targetState': array([-1.38713566,  0.18036645]), 'effectorPosition': array([-1.29604998,  0.02858116])}
episode index:1167
target Thresh 1.8255667854253392
current state at start:  [-0.64321225  2.43147319]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.64321225,  2.43147319]), 'currentState': array([6.13997305, 2.19866201]), 'targetState': array([0.60233177, 0.98917533]), 'effectorPosition': array([0.52386091, 0.74211326])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.9514650628083824
{'reset': False, 'endBeforeDone': False, 'stepCount': 7, 'initial state': array([-0.64321225,  2.43147319]), 'currentState': array([0.27187756, 1.63565136]), 'targetState': array([0.60233177, 0.98917533]), 'effectorPosition': array([0.63286344, 1.21237977])}
episode index:1168
target Thresh 1.8259153032205209
current state at start:  [-3.49083439  2.11490867]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.49083439,  2.11490867]), 'currentState': array([2.53089816, 2.61490867]), 'targetState': array([0.0783012 , 0.08456839]), 'effectorPosition': array([-0.3992749 , -0.33409908])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9514980268265104
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.49083439,  2.11490867]), 'currentState': array([2.24876899, 3.11490867]), 'targetState': array([0.0783012 , 0.08456839]), 'effectorPosition': array([-0.02100353, -0.01645735])}
episode index:1169
target Thresh 1.8262631246766832
current state at start:  [ 3.85368106 -2.26793976]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.85368106, -2.26793976]), 'currentState': array([4.13912565, 3.71155237]), 'targetState': array([-0.25953411, -0.02074288]), 'effectorPosition': array([-0.53907296,  0.15985905])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9515224729574279
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 3.85368106, -2.26793976]), 'currentState': array([4.50215995, 3.60188273]), 'targetState': array([-0.25953411, -0.02074288]), 'effectorPosition': array([-0.456147  , -0.00908583])}
episode index:1170
target Thresh 1.8266102511851126
current state at start:  [0.12827865 3.00641023]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.12827865, 3.00641023]), 'currentState': array([0.62827865, 2.58817672]), 'targetState': array([-0.40256922,  0.67499939]), 'effectorPosition': array([-0.18815866,  0.51296018])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9515553316483267
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.12827865, 3.00641023]), 'currentState': array([1.12827865, 2.43335142]), 'targetState': array([-0.40256922,  0.67499939]), 'effectorPosition': array([-0.4848577,  0.4958818])}
episode index:1171
target Thresh 1.8269566841343154
current state at start:  [ 0.18300915 -1.60071494]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.18300915, -1.60071494]), 'currentState': array([0.68300915, 4.33609797]), 'targetState': array([0.66115101, 0.07336648]), 'effectorPosition': array([ 1.07760864, -0.32219959])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9515881342663742
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.18300915, -1.60071494]), 'currentState': array([1.16964764, 4.00509725]), 'targetState': array([0.66115101, 0.07336648]), 'effectorPosition': array([0.83653399, 0.02560896])}
episode index:1172
target Thresh 1.8273024249100243
current state at start:  [-1.21159599 -2.59345272]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.21159599, -2.59345272]), 'currentState': array([5.14608891, 3.4600938 ]), 'targetState': array([-0.41813494,  0.11338831]), 'effectorPosition': array([-0.26301656, -0.17723038])}
done in step count: 15
reward sum = 0.8600583546412884
running average episode reward sum: 0.95151010376371
{'reset': False, 'endBeforeDone': False, 'stepCount': 16, 'initial state': array([-1.21159599, -2.59345272]), 'currentState': array([4.76597193, 3.59469372]), 'targetState': array([-0.41813494,  0.11338831]), 'effectorPosition': array([-0.43172325, -0.12420628])}
episode index:1173
target Thresh 1.8276474748952023
current state at start:  [-0.54848263  1.90991323]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.54848263,  1.90991323]), 'currentState': array([5.5889667 , 2.27496411]), 'targetState': array([0.77325144, 0.2058468 ]), 'effectorPosition': array([0.75860484, 0.36016542])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9515514069121226
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.54848263,  1.90991323]), 'currentState': array([5.5889667 , 2.27496411]), 'targetState': array([0.77325144, 0.2058468 ]), 'effectorPosition': array([0.75860484, 0.36016542])}
episode index:1174
target Thresh 1.8279918354700502
current state at start:  [ 1.02042843 -2.61091539]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.02042843, -2.61091539]), 'currentState': array([0.59186254, 4.01585994]), 'targetState': array([ 0.72655103, -0.6184128 ]), 'effectorPosition': array([ 0.72542749, -0.43661975])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9515926397573038
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.02042843, -2.61091539]), 'currentState': array([0.59186254, 4.01585994]), 'targetState': array([ 0.72655103, -0.6184128 ]), 'effectorPosition': array([ 0.72542749, -0.43661975])}
episode index:1175
target Thresh 1.8283355080120107
current state at start:  [ 1.6038746  -1.81056698]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.6038746 , -1.81056698]), 'currentState': array([1.97481001, 4.02199389]), 'targetState': array([0.43295651, 0.65150734]), 'effectorPosition': array([0.5661603 , 0.63700772])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9516338024785985
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.6038746 , -1.81056698]), 'currentState': array([1.97481001, 4.02199389]), 'targetState': array([0.43295651, 0.65150734]), 'effectorPosition': array([0.5661603 , 0.63700772])}
episode index:1176
target Thresh 1.8286784938957743
current state at start:  [ 2.53246604 -1.82594697]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.53246604, -1.82594697]), 'currentState': array([2.03246604, 4.08872207]), 'targetState': array([0.46665499, 0.84234111]), 'effectorPosition': array([0.54146348, 0.73402042])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9516748952547425
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.53246604, -1.82594697]), 'currentState': array([2.03246604, 4.08872207]), 'targetState': array([0.46665499, 0.84234111]), 'effectorPosition': array([0.54146348, 0.73402042])}
episode index:1177
target Thresh 1.829020794493285
current state at start:  [-3.89849468  2.74202156]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.89849468,  2.74202156]), 'currentState': array([2.06839796, 3.24202156]), 'targetState': array([0.07801395, 0.10891007]), 'effectorPosition': array([0.08569651, 0.05228382])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9517159182638641
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.89849468,  2.74202156]), 'currentState': array([2.06839796, 3.24202156]), 'targetState': array([0.07801395, 0.10891007]), 'effectorPosition': array([0.08569651, 0.05228382])}
episode index:1178
target Thresh 1.8293624111737457
current state at start:  [-2.01621751  2.8635091 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.01621751,  2.8635091 ]), 'currentState': array([3.95369216, 3.17536245]), 'targetState': array([0.00318355, 0.03830154]), 'effectorPosition': array([-0.02489545,  0.02281463])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9517568716834877
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.01621751,  2.8635091 ]), 'currentState': array([3.95369216, 3.17536245]), 'targetState': array([0.00318355, 0.03830154]), 'effectorPosition': array([-0.02489545,  0.02281463])}
episode index:1179
target Thresh 1.8297033453036238
current state at start:  [-2.14957855  2.38716673]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.14957855,  2.38716673]), 'currentState': array([4.63360676, 2.83692315]), 'targetState': array([ 0.92209332, -0.02914375]), 'effectorPosition': array([ 0.295423 , -0.0695195])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9517808912837559
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-2.14957855,  2.38716673]), 'currentState': array([5.2939291 , 2.25730788]), 'targetState': array([ 0.92209332, -0.02914375]), 'effectorPosition': array([0.8474527 , 0.11890415])}
episode index:1180
target Thresh 1.8300435982466559
current state at start:  [-2.91332399  2.02929692]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.91332399,  2.02929692]), 'currentState': array([3.16394089, 2.50719537]), 'targetState': array([-0.08133734, -0.38109735]), 'effectorPosition': array([-0.18127782, -0.59689213])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.95182172033432
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.91332399,  2.02929692]), 'currentState': array([3.16394089, 2.50719537]), 'targetState': array([-0.08133734, -0.38109735]), 'effectorPosition': array([-0.18127782, -0.59689213])}
episode index:1181
target Thresh 1.8303831713638543
current state at start:  [-1.66697995 -1.82797845]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.66697995, -1.82797845]), 'currentState': array([4.22462149, 3.95520685]), 'targetState': array([-0.80380429,  0.18411046]), 'effectorPosition': array([-0.78876596,  0.06399869])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9518624803001962
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.66697995, -1.82797845]), 'currentState': array([4.22462149, 3.95520685]), 'targetState': array([-0.80380429,  0.18411046]), 'effectorPosition': array([-0.78876596,  0.06399869])}
episode index:1182
target Thresh 1.830722066013512
current state at start:  [-1.67466404 -1.65875046]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.67466404, -1.65875046]), 'currentState': array([4.84352257, 4.1597258 ]), 'targetState': array([-0.46279937, -0.19595108]), 'effectorPosition': array([-0.78170609, -0.58225768])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9518863497166795
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.67466404, -1.65875046]), 'currentState': array([5.27310653, 3.69172165]), 'targetState': array([-0.46279937, -0.19595108]), 'effectorPosition': array([-0.36428078, -0.40297063])}
episode index:1183
target Thresh 1.8310602835512082
current state at start:  [1.21903782 2.45673022]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.21903782, 2.45673022]), 'currentState': array([1.71903782, 2.13347346]), 'targetState': array([-1.25146702,  0.16267296]), 'effectorPosition': array([-0.90546191,  0.33650219])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9519185402996891
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.21903782, 2.45673022]), 'currentState': array([2.18885683, 1.84238422]), 'targetState': array([-1.25146702,  0.16267296]), 'effectorPosition': array([-1.20914076,  0.03815344])}
episode index:1184
target Thresh 1.831397825329813
current state at start:  [-0.61756428  1.72556753]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.61756428,  1.72556753]), 'currentState': array([6.15865044, 2.12844414]), 'targetState': array([0.73722665, 0.63383328]), 'effectorPosition': array([0.57255721, 0.78345043])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9519591153711662
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.61756428,  1.72556753]), 'currentState': array([6.15865044, 2.12844414]), 'targetState': array([0.73722665, 0.63383328]), 'effectorPosition': array([0.57255721, 0.78345043])}
episode index:1185
target Thresh 1.8317346926994948
current state at start:  [ 2.36173363 -2.26724543]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.36173363, -2.26724543]), 'currentState': array([1.90587662, 3.56884925]), 'targetState': array([ 0.53588112, -0.02268767]), 'effectorPosition': array([0.36176843, 0.22115981])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9519911903160472
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 2.36173363, -2.26724543]), 'currentState': array([1.48584412, 3.71181756]), 'targetState': array([ 0.53588112, -0.02268767]), 'effectorPosition': array([0.55129966, 0.11184595])}
episode index:1186
target Thresh 1.8320708870077227
current state at start:  [ 2.59146066 -1.63554845]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.59146066, -1.63554845]), 'currentState': array([2.99485178, 4.67703832]), 'targetState': array([-1.04142098,  0.89846569]), 'effectorPosition': array([-0.80816595,  1.12968191])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9520232112172131
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 2.59146066, -1.63554845]), 'currentState': array([3.33361502, 4.77454292]), 'targetState': array([-1.04142098,  0.89846569]), 'effectorPosition': array([-1.23306856,  0.77702626])}
episode index:1187
target Thresh 1.832406409599275
current state at start:  [-2.09370341  1.97705942]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.09370341,  1.97705942]), 'currentState': array([3.68948189, 2.03845634]), 'targetState': array([-0.21303158, -0.97503809]), 'effectorPosition': array([-0.00385567, -1.04803986])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9520635957195555
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.09370341,  1.97705942]), 'currentState': array([3.68948189, 2.03845634]), 'targetState': array([-0.21303158, -0.97503809]), 'effectorPosition': array([-0.00385567, -1.04803986])}
episode index:1188
target Thresh 1.832741261816242
current state at start:  [-2.87709405  1.92061813]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.87709405,  1.92061813]), 'currentState': array([3.67499573, 2.36414419]), 'targetState': array([ 0.35214829, -0.23469188]), 'effectorPosition': array([ 0.10928672, -0.75009672])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9520955018627687
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.87709405,  1.92061813]), 'currentState': array([3.89709354, 2.78331633]), 'targetState': array([ 0.35214829, -0.23469188]), 'effectorPosition': array([ 0.19421005, -0.29879287])}
episode index:1189
target Thresh 1.8330754449980333
current state at start:  [-0.73464957 -2.04895315]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.73464957, -2.04895315]), 'currentState': array([5.93059415, 3.73423215]), 'targetState': array([ 0.07901635, -0.36703999]), 'effectorPosition': array([-0.03284542, -0.5830803 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9521357577435563
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.73464957, -2.04895315]), 'currentState': array([5.93059415, 3.73423215]), 'targetState': array([ 0.07901635, -0.36703999]), 'effectorPosition': array([-0.03284542, -0.5830803 ])}
episode index:1190
target Thresh 1.8334089604813821
current state at start:  [ 3.52377513 -1.91550022]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.52377513, -1.91550022]), 'currentState': array([3.02377513, 4.09556536]), 'targetState': array([-0.33429369,  1.10490537]), 'effectorPosition': array([-0.32274663,  0.85961649])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9521759460242082
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.52377513, -1.91550022]), 'currentState': array([3.02377513, 4.09556536]), 'targetState': array([-0.33429369,  1.10490537]), 'effectorPosition': array([-0.32274663,  0.85961649])}
episode index:1191
target Thresh 1.8337418096003506
current state at start:  [0.89783911 1.61030467]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.89783911, 1.61030467]), 'currentState': array([0.41880841, 1.23756989]), 'targetState': array([0.12275226, 1.32047465]), 'effectorPosition': array([0.82809663, 1.40301224])}
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.9521207521699228
{'reset': False, 'endBeforeDone': False, 'stepCount': 13, 'initial state': array([0.89783911, 1.61030467]), 'currentState': array([2.09706409, 4.84957656]), 'targetState': array([0.12275226, 1.32047465]), 'effectorPosition': array([0.28555936, 1.48053071])}
episode index:1192
target Thresh 1.834073993686336
current state at start:  [0.37447962 2.26331798]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.37447962, 2.26331798]), 'currentState': array([0.83210164, 1.76331798]), 'targetState': array([-0.15774493,  1.36392663]), 'effectorPosition': array([-0.18119518,  1.25876891])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9521608856551115
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.37447962, 2.26331798]), 'currentState': array([0.83210164, 1.76331798]), 'targetState': array([-0.15774493,  1.36392663]), 'effectorPosition': array([-0.18119518,  1.25876891])}
episode index:1193
target Thresh 1.8344055140680748
current state at start:  [ 3.59415025 -2.14420746]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.59415025, -2.14420746]), 'currentState': array([4.04058332, 3.77534296]), 'targetState': array([-0.66424721,  0.02142711]), 'effectorPosition': array([-0.58435413,  0.21657688])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9522009519150318
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.59415025, -2.14420746]), 'currentState': array([4.04058332, 3.77534296]), 'targetState': array([-0.66424721,  0.02142711]), 'effectorPosition': array([-0.58435413,  0.21657688])}
episode index:1194
target Thresh 1.834736372071649
current state at start:  [-1.2989335   1.92429127]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.2989335 ,  1.92429127]), 'currentState': array([4.50341095, 2.17417486]), 'targetState': array([ 0.29085985, -0.75884816]), 'effectorPosition': array([ 0.71576681, -0.59398866])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9522325829176134
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.2989335 ,  1.92429127]), 'currentState': array([4.0916316 , 2.08225103]), 'targetState': array([ 0.29085985, -0.75884816]), 'effectorPosition': array([ 0.412381  , -0.92252332])}
episode index:1195
target Thresh 1.8350665690204913
current state at start:  [ 4.1611094  -2.69292493]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.1611094 , -2.69292493]), 'currentState': array([4.28111655, 4.0067954 ]), 'targetState': array([-1.00192874, -0.61023122]), 'effectorPosition': array([-0.83846715, -0.00111427])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9522641610255418
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 4.1611094 , -2.69292493]), 'currentState': array([4.72899768, 4.41306909]), 'targetState': array([-1.00192874, -0.61023122]), 'effectorPosition': array([-0.94369472, -0.72090184])}
episode index:1196
target Thresh 1.8353961062353896
current state at start:  [ 2.4338563  -2.69321578]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.4338563 , -2.69321578]), 'currentState': array([2.48739368, 3.08996952]), 'targetState': array([-0.0282504 ,  0.01928171]), 'effectorPosition': array([-0.03245708, -0.04013594])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9523040405902656
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.4338563 , -2.69321578]), 'currentState': array([2.48739368, 3.08996952]), 'targetState': array([-0.0282504 ,  0.01928171]), 'effectorPosition': array([-0.03245708, -0.04013594])}
episode index:1197
target Thresh 1.8357249850344934
current state at start:  [0.4607585  2.38890064]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.4607585 , 2.38890064]), 'currentState': array([0.41356253, 2.80341345]), 'targetState': array([-0.17402316, -0.07464875]), 'effectorPosition': array([-0.08146508,  0.32656211])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9523355063326778
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.4607585 , 2.38890064]), 'currentState': array([0.12318664, 3.215186  ]), 'targetState': array([-0.17402316, -0.07464875]), 'effectorPosition': array([ 0.0117209 , -0.07263716])}
episode index:1198
target Thresh 1.8360532067333184
current state at start:  [-4.39956239  2.54937448]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.39956239,  2.54937448]), 'currentState': array([2.20817262, 2.15416624]), 'targetState': array([-0.86155047, -0.1009941 ]), 'effectorPosition': array([-0.93803382, -0.13569566])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9523752598720167
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.39956239,  2.54937448]), 'currentState': array([2.20817262, 2.15416624]), 'targetState': array([-0.86155047, -0.1009941 ]), 'effectorPosition': array([-0.93803382, -0.13569566])}
episode index:1199
target Thresh 1.8363807726447519
current state at start:  [ 1.86599916 -2.71727611]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.86599916, -2.71727611]), 'currentState': array([1.78943952, 3.10601067]), 'targetState': array([ 0.04897462, -0.03223636]), 'effectorPosition': array([-0.03486484, -0.00709839])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9524149471554566
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.86599916, -2.71727611]), 'currentState': array([1.78943952, 3.10601067]), 'targetState': array([ 0.04897462, -0.03223636]), 'effectorPosition': array([-0.03486484, -0.00709839])}
episode index:1200
target Thresh 1.8367076840790575
current state at start:  [ 3.58438367 -1.67063441]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.58438367, -1.67063441]), 'currentState': array([3.1711162, 4.2314449]), 'targetState': array([-0.55821242,  0.27323261]), 'effectorPosition': array([-0.56332001,  0.87030905])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9524462419538284
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.58438367, -1.67063441]), 'currentState': array([3.60883895, 3.87002916]), 'targetState': array([-0.55821242,  0.27323261]), 'effectorPosition': array([-0.52643386,  0.48003658])}
episode index:1201
target Thresh 1.8370339423438817
current state at start:  [ 0.58476222 -2.49595836]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.58476222, -2.49595836]), 'currentState': array([1.08039866, 3.40334779]), 'targetState': array([-0.00833313,  0.09575594]), 'effectorPosition': array([ 0.24432114, -0.09182934])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9524774846809884
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.58476222, -2.49595836]), 'currentState': array([1.53584085, 3.04753736]), 'targetState': array([-0.00833313,  0.09575594]), 'effectorPosition': array([-0.09370484,  0.00769947])}
episode index:1202
target Thresh 1.8373595487442582
current state at start:  [-0.98922494  2.66936974]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.98922494,  2.66936974]), 'currentState': array([5.09183464, 2.41518871]), 'targetState': array([ 1.13015154, -0.49654297]), 'effectorPosition': array([0.71044454, 0.01154125])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9525004460403558
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-0.98922494,  2.66936974]), 'currentState': array([4.86025248, 1.98375807]), 'targetState': array([ 1.13015154, -0.49654297]), 'effectorPosition': array([ 0.99414175, -0.45720288])}
episode index:1203
target Thresh 1.8376845045826127
current state at start:  [-3.52469213  1.82422038]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.52469213,  1.82422038]), 'currentState': array([2.3503259 , 2.32422038]), 'targetState': array([-0.3656329 ,  0.04687695]), 'effectorPosition': array([-0.74077858, -0.28803975])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9525315918492924
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.52469213,  1.82422038]), 'currentState': array([1.96653866, 2.82422038]), 'targetState': array([-0.3656329 ,  0.04687695]), 'effectorPosition': array([-0.3072034 , -0.07421998])}
episode index:1204
target Thresh 1.8380088111587691
current state at start:  [ 1.51926161 -2.73223321]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.51926161, -2.73223321]), 'currentState': array([2.01926161, 3.16899469]), 'targetState': array([-0.3767979 ,  0.00311159]), 'effectorPosition': array([0.02452648, 0.01221786])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9525626859639402
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.51926161, -2.73223321]), 'currentState': array([2.34392311, 2.8156444 ]), 'targetState': array([-0.3767979 ,  0.00311159]), 'effectorPosition': array([-0.26595336, -0.18594026])}
episode index:1205
target Thresh 1.8383324697699543
current state at start:  [ 1.32625301 -2.82067307]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.32625301, -2.82067307]), 'currentState': array([1.66414817, 3.29162041]), 'targetState': array([ 0.10687805, -0.02579345]), 'effectorPosition': array([0.14776768, 0.02511679])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9526020203868557
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.32625301, -2.82067307]), 'currentState': array([1.66414817, 3.29162041]), 'targetState': array([ 0.10687805, -0.02579345]), 'effectorPosition': array([0.14776768, 0.02511679])}
episode index:1206
target Thresh 1.838655481710803
current state at start:  [0.68430425 1.79164375]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.68430425, 1.79164375]), 'currentState': array([0.18430425, 1.75695066]), 'targetState': array([0.68807602, 0.96926735]), 'effectorPosition': array([0.62102106, 1.11542403])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9526412896325999
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.68430425, 1.79164375]), 'currentState': array([0.18430425, 1.75695066]), 'targetState': array([0.68807602, 0.96926735]), 'effectorPosition': array([0.62102106, 1.11542403])}
episode index:1207
target Thresh 1.8389778482733632
current state at start:  [-0.1253903   2.57272212]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.1253903 ,  2.57272212]), 'currentState': array([5.65779501, 3.07272212]), 'targetState': array([-0.32273408, -0.24424795]), 'effectorPosition': array([0.04220785, 0.0544038 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9526722157173411
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.1253903 ,  2.57272212]), 'currentState': array([5.16856986, 3.57272212]), 'targetState': array([-0.32273408, -0.24424795]), 'effectorPosition': array([-0.33485329, -0.26624165])}
episode index:1208
target Thresh 1.8392995707471018
current state at start:  [-0.36948212  2.79784712]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.36948212,  2.79784712]), 'currentState': array([5.43905236, 3.29784712]), 'targetState': array([ 0.25225031, -0.46469647]), 'effectorPosition': array([-0.10821514, -0.1124958 ])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9526867953569463
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-0.36948212,  2.79784712]), 'currentState': array([6.21862395, 3.82430477]), 'targetState': array([ 0.25225031, -0.46469647]), 'effectorPosition': array([ 0.1829651 , -0.64404563])}
episode index:1209
target Thresh 1.8396206504189094
current state at start:  [-4.34521029  2.60762142]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.34521029,  2.60762142]), 'currentState': array([1.56811198, 3.10762142]), 'targetState': array([-0.15574744, -0.06376079]), 'effectorPosition': array([-0.03396303,  0.00066814])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9527258971789654
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.34521029,  2.60762142]), 'currentState': array([1.56811198, 3.10762142]), 'targetState': array([-0.15574744, -0.06376079]), 'effectorPosition': array([-0.03396303,  0.00066814])}
episode index:1210
target Thresh 1.8399410885731045
current state at start:  [ 1.59483953 -1.5878921 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.59483953, -1.5878921 ]), 'currentState': array([1.09483953, 4.45652442]), 'targetState': array([1.21949388, 0.27648377]), 'effectorPosition': array([1.20214767, 0.22062898])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9527649344232437
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.59483953, -1.5878921 ]), 'currentState': array([1.09483953, 4.45652442]), 'targetState': array([1.21949388, 0.27648377]), 'effectorPosition': array([1.20214767, 0.22062898])}
episode index:1211
target Thresh 1.8402608864914407
current state at start:  [-1.71863388  2.21608138]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.71863388,  2.21608138]), 'currentState': array([4.40773612, 2.67765385]), 'targetState': array([0.23034793, 0.07390594]), 'effectorPosition': array([ 0.39516145, -0.23506079])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9527956564245447
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.71863388,  2.21608138]), 'currentState': array([4.27916342, 2.92744748]), 'targetState': array([0.23034793, 0.07390594]), 'effectorPosition': array([ 0.18329065, -0.10994414])}
episode index:1212
target Thresh 1.8405800454531098
current state at start:  [-2.86542339  2.35994081]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.86542339,  2.35994081]), 'currentState': array([3.81339847, 1.90829097]), 'targetState': array([-0.26451705, -1.10169901]), 'effectorPosition': array([ 0.06376058, -1.1548534 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.952826327771268
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.86542339,  2.35994081]), 'currentState': array([3.37770873, 1.98554674]), 'targetState': array([-0.26451705, -1.10169901]), 'effectorPosition': array([-0.36637789, -1.02948735])}
episode index:1213
target Thresh 1.8408985667347484
current state at start:  [-0.83014777  2.35525549]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.83014777,  2.35525549]), 'currentState': array([5.0655841 , 2.83194175]), 'targetState': array([ 0.07795495, -0.02490303]), 'effectorPosition': array([0.302367  , 0.06077978])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9528651858208799
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.83014777,  2.35525549]), 'currentState': array([5.0655841 , 2.83194175]), 'targetState': array([ 0.07795495, -0.02490303]), 'effectorPosition': array([0.302367  , 0.06077978])}
episode index:1214
target Thresh 1.8412164516104415
current state at start:  [1.21447599 2.11891099]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.21447599, 2.11891099]), 'currentState': array([0.85779911, 2.61669376]), 'targetState': array([0.02058488, 0.03957239]), 'effectorPosition': array([-0.29099476,  0.42961939])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9528957494539491
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.21447599, 2.11891099]), 'currentState': array([0.4572888 , 3.10825655]), 'targetState': array([0.02058488, 0.03957239]), 'effectorPosition': array([-0.01421723,  0.03015068])}
episode index:1215
target Thresh 1.8415337013517294
current state at start:  [-2.76034833  2.43476933]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.76034833,  2.43476933]), 'currentState': array([3.46299299, 2.9063645 ]), 'targetState': array([-0.01771078, -0.48673176]), 'effectorPosition': array([ 0.04749549, -0.22982993])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.952926262817885
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.76034833,  2.43476933]), 'currentState': array([3.83488875, 2.62222198]), 'targetState': array([-0.01771078, -0.48673176]), 'effectorPosition': array([ 0.21576932, -0.46602595])}
episode index:1216
target Thresh 1.8418503172276115
current state at start:  [ 1.7454423  -2.55333119]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.7454423 , -2.55333119]), 'currentState': array([2.1865454 , 3.66022322]), 'targetState': array([0.06997726, 0.55533537]), 'effectorPosition': array([0.32870194, 0.3936463 ])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9529325649930551
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([ 1.7454423 , -2.55333119]), 'currentState': array([2.3076955 , 3.81331254]), 'targetState': array([0.06997726, 0.55533537]), 'effectorPosition': array([0.31488325, 0.57908857])}
episode index:1217
target Thresh 1.8421663005045517
current state at start:  [ 2.29809489 -2.20762949]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.29809489, -2.20762949]), 'currentState': array([2.79809489, 3.92225215]), 'targetState': array([-0.52072167,  0.90842142]), 'effectorPosition': array([-0.03562549,  0.7601524 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9529629980267226
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 2.29809489, -2.20762949]), 'currentState': array([3.25443875, 4.30989608]), 'targetState': array([-0.52072167,  0.90842142]), 'effectorPosition': array([-0.70802587,  0.84573807])}
episode index:1218
target Thresh 1.842481652446483
current state at start:  [ 4.28058677 -2.72063196]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.28058677, -2.72063196]), 'currentState': array([4.03257728, 3.13991925]), 'targetState': array([0.25874517, 0.45288084]), 'effectorPosition': array([ 0.00130051, -0.00105307])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.9529535781344949
{'reset': False, 'endBeforeDone': False, 'stepCount': 7, 'initial state': array([ 4.28058677, -2.72063196]), 'currentState': array([2.12394229, 3.67838179]), 'targetState': array([0.25874517, 0.45288084]), 'effectorPosition': array([0.36123025, 0.38833304])}
episode index:1219
target Thresh 1.8427963743148146
current state at start:  [ 4.12255973 -2.34173359]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.12255973, -2.34173359]), 'currentState': array([4.57437396, 3.66580629]), 'targetState': array([-0.20754575, -0.50097544]), 'effectorPosition': array([-0.51424702, -0.06414342])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9529758292999584
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 4.12255973, -2.34173359]), 'currentState': array([5.35402998, 3.86791933]), 'targetState': array([-0.20754575, -0.50097544]), 'effectorPosition': array([-0.38098981, -0.59967389])}
episode index:1220
target Thresh 1.8431104673684335
current state at start:  [ 1.99669014 -2.68694646]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.99669014, -2.68694646]), 'currentState': array([2.2854376 , 3.69430948]), 'targetState': array([0.0472178, 0.5143154]), 'effectorPosition': array([0.29896828, 0.45652526])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9530061521260845
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.99669014, -2.68694646]), 'currentState': array([2.35750797, 3.68394793]), 'targetState': array([0.0472178, 0.5143154]), 'effectorPosition': array([0.2628905, 0.4667953])}
episode index:1221
target Thresh 1.843423932863713
current state at start:  [-0.93295447  2.16294727]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.93295447,  2.16294727]), 'currentState': array([5.85023084, 2.10766599]), 'targetState': array([0.777686  , 0.63190493]), 'effectorPosition': array([0.80400188, 0.57505118])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.953044608630073
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.93295447,  2.16294727]), 'currentState': array([5.85023084, 2.10766599]), 'targetState': array([0.777686  , 0.63190493]), 'effectorPosition': array([0.80400188, 0.57505118])}
episode index:1222
target Thresh 1.843736772054515
current state at start:  [-0.99739127  1.57139994]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.99739127,  1.57139994]), 'currentState': array([4.89338862, 1.64092408]), 'targetState': array([ 0.98264964, -0.90414125]), 'effectorPosition': array([ 1.14864586, -0.73516809])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9530830022452569
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.99739127,  1.57139994]), 'currentState': array([4.89338862, 1.64092408]), 'targetState': array([ 0.98264964, -0.90414125]), 'effectorPosition': array([ 1.14864586, -0.73516809])}
episode index:1223
target Thresh 1.844048986192197
current state at start:  [ 2.03254064 -2.88090003]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.03254064, -2.88090003]), 'currentState': array([1.99769735, 3.23585791]), 'targetState': array([ 0.58006728, -0.39652735]), 'effectorPosition': array([0.08383997, 0.04301417])}
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.9530358251635684
{'reset': False, 'endBeforeDone': False, 'stepCount': 12, 'initial state': array([ 2.03254064, -2.88090003]), 'currentState': array([4.22830101, 2.37766993]), 'targetState': array([ 0.58006728, -0.39652735]), 'effectorPosition': array([ 0.48295415, -0.56789022])}
episode index:1224
target Thresh 1.8443605765256157
current state at start:  [0.48883966 2.30754288]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.48883966, 2.30754288]), 'currentState': array([0.10794542, 2.6337104 ]), 'targetState': array([0.00112781, 0.15158892]), 'effectorPosition': array([0.07309396, 0.49709607])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9530660000001696
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.48883966, 2.30754288]), 'currentState': array([6.01650084, 2.98127346]), 'targetState': array([0.00112781, 0.15158892]), 'effectorPosition': array([0.0544392, 0.1506108])}
episode index:1225
target Thresh 1.844671544301133
current state at start:  [ 3.93557743 -2.30791764]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.93557743, -2.30791764]), 'currentState': array([3.81956456, 3.47526767]), 'targetState': array([0.10037453, 0.12331505]), 'effectorPosition': array([-0.24838104,  0.22049189])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.953096125611915
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.93557743, -2.30791764]), 'currentState': array([3.93484866, 2.97526767]), 'targetState': array([0.10037453, 0.12331505]), 'effectorPosition': array([ 0.1083031 , -0.12597906])}
episode index:1226
target Thresh 1.8449818907626205
current state at start:  [-4.316583    2.95446388]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.316583  ,  2.95446388]), 'currentState': array([1.67302103, 3.33255426]), 'targetState': array([ 0.2375275 , -0.01095028]), 'effectorPosition': array([0.18695728, 0.03745172])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.953134352078409
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.316583  ,  2.95446388]), 'currentState': array([1.67302103, 3.33255426]), 'targetState': array([ 0.2375275 , -0.01095028]), 'effectorPosition': array([0.18695728, 0.03745172])}
episode index:1227
target Thresh 1.8452916171514644
current state at start:  [ 2.90947377 -2.34160788]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.90947377, -2.34160788]), 'currentState': array([2.56217336, 3.44157743]), 'targetState': array([0.750016  , 0.35719506]), 'effectorPosition': array([0.12443081, 0.27172596])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9531483298047295
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 2.90947377, -2.34160788]), 'currentState': array([1.68676167, 4.1450125 ]), 'targetState': array([0.750016  , 0.35719506]), 'effectorPosition': array([0.78412681, 0.5570478 ])}
episode index:1228
target Thresh 1.8456007247065704
current state at start:  [ 0.36853017 -2.1144894 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.36853017, -2.1144894 ]), 'currentState': array([0.86853017, 3.67771883]), 'targetState': array([-0.03824962,  0.10744524]), 'effectorPosition': array([ 0.48057256, -0.22285014])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9531783148903238
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.36853017, -2.1144894 ]), 'currentState': array([1.36853017, 3.18824432]), 'targetState': array([-0.03824962,  0.10744524]), 'effectorPosition': array([ 0.04590261, -0.00830263])}
episode index:1229
target Thresh 1.8459092146643696
current state at start:  [ 0.86300476 -2.70560068]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.86300476, -2.70560068]), 'currentState': array([1.36300476, 3.16714264]), 'targetState': array([-0.03263896,  0.44807105]), 'effectorPosition': array([ 0.02506499, -0.00495101])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.9531765358130958
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([ 0.86300476, -2.70560068]), 'currentState': array([2.58784448, 3.51786982]), 'targetState': array([-0.03263896,  0.44807105]), 'effectorPosition': array([0.13373389, 0.34933809])}
episode index:1230
target Thresh 1.8462170882588218
current state at start:  [1.69113573 1.81506865]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.69113573, 1.81506865]), 'currentState': array([2.19113573, 2.19482093]), 'targetState': array([-1.02849836, -0.10438919]), 'effectorPosition': array([-0.90197716, -0.1335112 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9532145727458228
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.69113573, 1.81506865]), 'currentState': array([2.19113573, 2.19482093]), 'targetState': array([-1.02849836, -0.10438919]), 'effectorPosition': array([-0.90197716, -0.1335112 ])}
episode index:1231
target Thresh 1.846524346721422
current state at start:  [ 4.33221123 -2.54254991]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.33221123, -2.54254991]), 'currentState': array([4.4648552, 3.2697292]), 'targetState': array([0.01210565, 0.12772548]), 'effectorPosition': array([-0.1258999 ,  0.02336099])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9532525479302824
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.33221123, -2.54254991]), 'currentState': array([4.4648552, 3.2697292]), 'targetState': array([0.01210565, 0.12772548]), 'effectorPosition': array([-0.1258999 ,  0.02336099])}
episode index:1232
target Thresh 1.8468309912812046
current state at start:  [ 2.81009276 -2.96222832]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.81009276, -2.96222832]), 'currentState': array([3.28759901, 3.79939235]), 'targetState': array([-0.45248202,  0.86734867]), 'effectorPosition': array([-0.29538862,  0.57451444])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9532823512166325
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 2.81009276, -2.96222832]), 'currentState': array([3.38609843, 4.07539196]), 'targetState': array([-0.45248202,  0.86734867]), 'effectorPosition': array([-0.58776567,  0.68188222])}
episode index:1233
target Thresh 1.8471370231647481
current state at start:  [-0.5837275   2.32303246]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.5837275 ,  2.32303246]), 'currentState': array([5.26726145, 1.98342868]), 'targetState': array([ 1.288337  , -0.26961121]), 'effectorPosition': array([ 1.09419092, -0.02649501])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9533121061994391
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.5837275 ,  2.32303246]), 'currentState': array([5.18645214, 1.59426786]), 'targetState': array([ 1.288337  , -0.26961121]), 'effectorPosition': array([ 1.33526695, -0.4124602 ])}
episode index:1234
target Thresh 1.8474424435961803
current state at start:  [ 1.89968449 -2.53274177]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.89968449, -2.53274177]), 'currentState': array([2.25306017, 3.25044354]), 'targetState': array([-0.30553991, -0.15693243]), 'effectorPosition': array([0.08058571, 0.07309421])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9533418129960388
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.89968449, -2.53274177]), 'currentState': array([2.45557672, 2.75044354]), 'targetState': array([-0.30553991, -0.15693243]), 'effectorPosition': array([-0.29994912, -0.24715863])}
episode index:1235
target Thresh 1.8477472537971835
current state at start:  [-0.59605775  1.95701262]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.59605775,  1.95701262]), 'currentState': array([5.65244451, 1.84492989]), 'targetState': array([1.14879858, 0.19668571]), 'effectorPosition': array([1.15668779, 0.34734344])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9533795623382749
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.59605775,  1.95701262]), 'currentState': array([5.65244451, 1.84492989]), 'targetState': array([1.14879858, 0.19668571]), 'effectorPosition': array([1.15668779, 0.34734344])}
episode index:1236
target Thresh 1.848051454986999
current state at start:  [-0.45677286  2.52008377]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.45677286,  2.52008377]), 'currentState': array([5.32641245, 2.13284697]), 'targetState': array([1.0026384 , 0.12192685]), 'effectorPosition': array([0.96071242, 0.10576695])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9534172506468132
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.45677286,  2.52008377]), 'currentState': array([5.32641245, 2.13284697]), 'targetState': array([1.0026384 , 0.12192685]), 'effectorPosition': array([0.96071242, 0.10576695])}
episode index:1237
target Thresh 1.8483550483824318
current state at start:  [-4.01463572  2.26281492]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.01463572,  2.26281492]), 'currentState': array([2.71672162, 2.20856064]), 'targetState': array([-0.60430526, -1.03821159]), 'effectorPosition': array([-0.69980316, -0.5652204 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9534468005251275
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-4.01463572,  2.26281492]), 'currentState': array([3.18820419, 1.87810802]), 'targetState': array([-0.60430526, -1.03821159]), 'effectorPosition': array([-0.65233334, -0.98461488])}
episode index:1238
target Thresh 1.8486580351978559
current state at start:  [-3.48508715  2.40264014]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.48508715,  2.40264014]), 'currentState': array([2.97968499, 2.75388954]), 'targetState': array([ 0.26927981, -0.20257696]), 'effectorPosition': array([-0.13419367, -0.36115416])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9534683123891105
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-3.48508715,  2.40264014]), 'currentState': array([3.73318321, 2.7456306 ]), 'targetState': array([ 0.26927981, -0.20257696]), 'effectorPosition': array([ 0.15087099, -0.36329889])}
episode index:1239
target Thresh 1.848960416645219
current state at start:  [ 3.93811596 -1.79546832]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.93811596, -1.79546832]), 'currentState': array([3.58116457, 4.53703595]), 'targetState': array([-1.24330931,  0.46457871]), 'effectorPosition': array([-1.16608926,  0.53974467])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9535058379436354
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.93811596, -1.79546832]), 'currentState': array([3.58116457, 4.53703595]), 'targetState': array([-1.24330931,  0.46457871]), 'effectorPosition': array([-1.16608926,  0.53974467])}
episode index:1240
target Thresh 1.8492621939340472
current state at start:  [-0.25909538 -2.63484914]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.25909538, -2.63484914]), 'currentState': array([0.06493678, 3.156648  ]), 'targetState': array([-0.00045202,  0.10011742]), 'effectorPosition': array([ 0.00109001, -0.01501569])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9535433030218435
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.25909538, -2.63484914]), 'currentState': array([0.06493678, 3.156648  ]), 'targetState': array([-0.00045202,  0.10011742]), 'effectorPosition': array([ 0.00109001, -0.01501569])}
episode index:1241
target Thresh 1.8495633682714503
current state at start:  [ 3.63029951 -1.57803426]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.63029951, -1.57803426]), 'currentState': array([4.13029951, 4.76734329]), 'targetState': array([-1.09154925, -0.29769536]), 'effectorPosition': array([-1.41402231, -0.33225628])}
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.9534892302108083
{'reset': False, 'endBeforeDone': False, 'stepCount': 13, 'initial state': array([ 3.63029951, -1.57803426]), 'currentState': array([4.2427279, 4.6471019]), 'targetState': array([-1.09154925, -0.29769536]), 'effectorPosition': array([-1.31287914, -0.38192529])}
episode index:1242
target Thresh 1.8498639408621258
current state at start:  [1.62731007 2.64589392]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.62731007, 2.64589392]), 'currentState': array([1.20490608, 3.05812865]), 'targetState': array([ 0.10074128, -0.18781231]), 'effectorPosition': array([-0.07660323,  0.03307783])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9535186033160289
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.62731007, 2.64589392]), 'currentState': array([0.9279224 , 3.37578418]), 'targetState': array([ 0.10074128, -0.18781231]), 'effectorPosition': array([ 0.20209755, -0.11726908])}
episode index:1243
target Thresh 1.8501639129083647
current state at start:  [ 4.13290824 -2.05670218]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.13290824, -2.05670218]), 'currentState': array([3.65372602, 4.50379374]), 'targetState': array([-1.25529012,  0.51948316]), 'effectorPosition': array([-1.17059951,  0.4642469 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9535559677828166
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.13290824, -2.05670218]), 'currentState': array([3.65372602, 4.50379374]), 'targetState': array([-1.25529012,  0.51948316]), 'effectorPosition': array([-1.17059951,  0.4642469 ])}
episode index:1244
target Thresh 1.8504632856100554
current state at start:  [ 3.58513107 -1.57759409]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.58513107, -1.57759409]), 'currentState': array([3.20886173, 4.22725128]), 'targetState': array([-0.44066819,  0.12248424]), 'effectorPosition': array([-0.59192489,  0.8467376 ])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9535772882906216
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 3.58513107, -1.57759409]), 'currentState': array([4.06558352, 3.51983814]), 'targetState': array([-0.44066819,  0.12248424]), 'effectorPosition': array([-0.3372969 ,  0.16614097])}
episode index:1245
target Thresh 1.8507620601646892
current state at start:  [-4.16699079  2.56731495]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.16699079,  2.56731495]), 'currentState': array([1.61619452, 2.95762452]), 'targetState': array([-0.4329114 ,  0.62801048]), 'effectorPosition': array([-0.1835095 ,  0.00855514])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9535829212935987
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([-4.16699079,  2.56731495]), 'currentState': array([1.00935791, 2.53639322]), 'targetState': array([-0.4329114 ,  0.62801048]), 'effectorPosition': array([-0.38702929,  0.453245  ])}
episode index:1246
target Thresh 1.8510602377673646
current state at start:  [-0.60437799  1.5976962 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.60437799,  1.5976962 ]), 'currentState': array([5.88702395, 1.9800735 ]), 'targetState': array([0.5415548 , 0.31103626]), 'effectorPosition': array([0.9094336 , 0.61403414])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9536121250455685
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.60437799,  1.5976962 ]), 'currentState': array([5.64574189, 2.30498792]), 'targetState': array([0.5415548 , 0.31103626]), 'effectorPosition': array([0.70702259, 0.40018068])}
episode index:1247
target Thresh 1.8513578196107925
current state at start:  [ 0.09653186 -1.92905406]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.09653186, -1.92905406]), 'currentState': array([0.07314918, 4.17931607]), 'targetState': array([ 0.78251655, -0.78974378]), 'effectorPosition': array([ 0.55344603, -0.82300239])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9536492948171666
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.09653186, -1.92905406]), 'currentState': array([0.07314918, 4.17931607]), 'targetState': array([ 0.78251655, -0.78974378]), 'effectorPosition': array([ 0.55344603, -0.82300239])}
episode index:1248
target Thresh 1.8516548068853007
current state at start:  [-1.6650311   1.59138266]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.6650311 ,  1.59138266]), 'currentState': array([4.11815421, 1.83588779]), 'targetState': array([ 0.44449444, -1.03496705]), 'effectorPosition': array([ 0.38644473, -1.15180961])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9536864050695147
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.6650311 ,  1.59138266]), 'currentState': array([4.11815421, 1.83588779]), 'targetState': array([ 0.44449444, -1.03496705]), 'effectorPosition': array([ 0.38644473, -1.15180961])}
episode index:1249
target Thresh 1.8519512007788386
current state at start:  [-4.0705011   1.98579575]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.0705011 ,  1.98579575]), 'currentState': array([1.71268421, 2.4716479 ]), 'targetState': array([-0.52646694,  0.20050716]), 'effectorPosition': array([-0.64526812,  0.12616303])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9537234559454592
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.0705011 ,  1.98579575]), 'currentState': array([1.71268421, 2.4716479 ]), 'targetState': array([-0.52646694,  0.20050716]), 'effectorPosition': array([-0.64526812,  0.12616303])}
episode index:1250
target Thresh 1.8522470024769822
current state at start:  [-0.03503616 -2.05230504]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.03503616, -2.05230504]), 'currentState': array([6.22304092, 3.73905623]), 'targetState': array([-0.10317958, -0.34999034]), 'effectorPosition': array([ 0.13910797, -0.57194293])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9537524539822734
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.03503616, -2.05230504]), 'currentState': array([5.93930281, 3.4356244 ]), 'targetState': array([-0.10317958, -0.34999034]), 'effectorPosition': array([-0.05730491, -0.2873147 ])}
episode index:1251
target Thresh 1.8525422131629385
current state at start:  [-2.01214471  2.57499515]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.01214471,  2.57499515]), 'currentState': array([3.77226088, 2.16338643]), 'targetState': array([-0.09373193, -0.95041301]), 'effectorPosition': array([ 0.13258044, -0.93026861])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9537893929167923
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.01214471,  2.57499515]), 'currentState': array([3.77226088, 2.16338643]), 'targetState': array([-0.09373193, -0.95041301]), 'effectorPosition': array([ 0.13258044, -0.93026861])}
episode index:1252
target Thresh 1.8528368340175512
current state at start:  [-1.35850147  1.74778366]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.35850147,  1.74778366]), 'currentState': array([4.79577002, 1.96671181]), 'targetState': array([ 0.78518634, -0.32686712]), 'effectorPosition': array([ 0.97060401, -0.53537074])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9538103910070422
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.35850147,  1.74778366]), 'currentState': array([4.72554156, 2.10516467]), 'targetState': array([ 0.78518634, -0.32686712]), 'effectorPosition': array([ 0.86696988, -0.47934135])}
episode index:1253
target Thresh 1.8531308662193036
current state at start:  [ 0.09752566 -2.40966603]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.09752566, -2.40966603]), 'currentState': array([5.98899276, 4.10830646]), 'targetState': array([ 0.27653991, -0.70183461]), 'effectorPosition': array([ 0.17478307, -0.91292741])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9538472248260159
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.09752566, -2.40966603]), 'currentState': array([5.98899276, 4.10830646]), 'targetState': array([ 0.27653991, -0.70183461]), 'effectorPosition': array([ 0.17478307, -0.91292741])}
episode index:1254
target Thresh 1.8534243109443251
current state at start:  [1.81277051 1.90271523]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.81277051, 1.90271523]), 'currentState': array([2.0065076 , 2.23324516]), 'targetState': array([-0.94517893, -0.09840915]), 'effectorPosition': array([-0.87729041,  0.01619879])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9538839999456764
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.81277051, 1.90271523]), 'currentState': array([2.0065076 , 2.23324516]), 'targetState': array([-0.94517893, -0.09840915]), 'effectorPosition': array([-0.87729041,  0.01619879])}
episode index:1255
target Thresh 1.853717169366395
current state at start:  [ 4.15125532 -2.57471707]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.15125532, -2.57471707]), 'currentState': array([4.493013  , 3.30286408]), 'targetState': array([-0.00354988, -0.38010152]), 'effectorPosition': array([-0.15954874,  0.02227897])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9538970692132357
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 4.15125532, -2.57471707]), 'currentState': array([3.90585426, 2.83833708]), 'targetState': array([-0.00354988, -0.38010152]), 'effectorPosition': array([ 0.17371189, -0.2471548 ])}
episode index:1256
target Thresh 1.8540094426569471
current state at start:  [ 2.96575906 -2.69713195]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.96575906, -2.69713195]), 'currentState': array([3.14472701, 3.13829504]), 'targetState': array([0.02609391, 0.04161003]), 'effectorPosition': array([ 4.89875746e-06, -3.29760858e-03])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9539337461669244
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.96575906, -2.69713195]), 'currentState': array([3.14472701, 3.13829504]), 'targetState': array([0.02609391, 0.04161003]), 'effectorPosition': array([ 4.89875746e-06, -3.29760858e-03])}
episode index:1257
target Thresh 1.8543011319850753
current state at start:  [ 2.32656787 -1.66637159]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.32656787, -1.66637159]), 'currentState': array([2.41603592, 4.14775038]), 'targetState': array([-0.10385664,  0.83400788]), 'effectorPosition': array([0.21275906, 0.94048524])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9539624156850747
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 2.32656787, -1.66637159]), 'currentState': array([2.59493109, 4.05659627]), 'targetState': array([-0.10385664,  0.83400788]), 'effectorPosition': array([0.07866087, 0.87990741])}
episode index:1258
target Thresh 1.8545922385175373
current state at start:  [-0.89963628  2.82048678]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.89963628,  2.82048678]), 'currentState': array([4.96822422, 2.51133149]), 'targetState': array([ 0.78687836, -0.57331121]), 'effectorPosition': array([ 0.61879183, -0.03673453])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9539910396599078
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.89963628,  2.82048678]), 'currentState': array([4.46822422, 2.01133149]), 'targetState': array([ 0.78687836, -0.57331121]), 'effectorPosition': array([ 0.73903527, -0.77522879])}
episode index:1259
target Thresh 1.8548827634187592
current state at start:  [-1.6891003  -2.29389151]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.6891003 , -2.29389151]), 'currentState': array([4.88770458, 3.62523355]), 'targetState': array([-0.14258226, -0.45988113]), 'effectorPosition': array([-0.43787325, -0.19403995])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9540117610570031
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.6891003 , -2.29389151]), 'currentState': array([5.29493853, 3.77795967]), 'targetState': array([-0.14258226, -0.45988113]), 'effectorPosition': array([-0.38857173, -0.49039972])}
episode index:1260
target Thresh 1.8551727078508415
current state at start:  [-1.721143    2.00786118]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.721143  ,  2.00786118]), 'currentState': array([4.8693539 , 2.36078627]), 'targetState': array([0.84827137, 0.17003574]), 'effectorPosition': array([ 0.74047851, -0.17606585])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9540403005010499
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.721143  ,  2.00786118]), 'currentState': array([5.17251096, 2.14241455]), 'targetState': array([0.84827137, 0.17003574]), 'effectorPosition': array([ 0.9573836 , -0.03780476])}
episode index:1261
target Thresh 1.8554620729735622
current state at start:  [-2.02320338 -1.71575391]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.02320338, -1.71575391]), 'currentState': array([3.75998193, 4.06743139]), 'targetState': array([-0.51955872,  0.46102379]), 'effectorPosition': array([-0.7882481 ,  0.41992361])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9540609500252171
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-2.02320338, -1.71575391]), 'currentState': array([3.56211882, 3.68600212]), 'targetState': array([-0.51955872,  0.46102379]), 'effectorPosition': array([-0.34340447,  0.41377143])}
episode index:1262
target Thresh 1.855750859944382
current state at start:  [0.85129239 1.63350868]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.85129239, 1.63350868]), 'currentState': array([0.35129239, 1.61584232]), 'targetState': array([0.05384939, 1.02410753]), 'effectorPosition': array([0.55288561, 1.26659227])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9540738067552051
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([0.85129239, 1.63350868]), 'currentState': array([0.72513725, 1.82148975]), 'targetState': array([0.05384939, 1.02410753]), 'effectorPosition': array([-0.07975935,  1.22371848])}
episode index:1263
target Thresh 1.856039069918449
current state at start:  [-0.18526269  2.20045716]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.18526269,  2.20045716]), 'currentState': array([5.60677799, 1.98866714]), 'targetState': array([1.07085874, 0.15632164]), 'effectorPosition': array([1.03549272, 0.34076978])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9541101407688481
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.18526269,  2.20045716]), 'currentState': array([5.60677799, 1.98866714]), 'targetState': array([1.07085874, 0.15632164]), 'effectorPosition': array([1.03549272, 0.34076978])}
episode index:1264
target Thresh 1.856326704048604
current state at start:  [-1.80334955 -2.20417627]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.80334955, -2.20417627]), 'currentState': array([4.92699862, 3.95661356]), 'targetState': array([-0.19384032, -0.75626979]), 'effectorPosition': array([-0.64414269, -0.46192406])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9541385121990704
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.80334955, -2.20417627]), 'currentState': array([5.38456885, 4.09646851]), 'targetState': array([-0.19384032, -0.75626979]), 'effectorPosition': array([-0.37572472, -0.83869587])}
episode index:1265
target Thresh 1.8566137634853837
current state at start:  [1.12720061 2.59002544]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.12720061, 2.59002544]), 'currentState': array([0.65628297, 3.00430532]), 'targetState': array([ 0.21568467, -0.27216557]), 'effectorPosition': array([-0.07605205,  0.11416792])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9541668388087078
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.12720061, 2.59002544]), 'currentState': array([0.18195895, 3.49447207]), 'targetState': array([ 0.21568467, -0.27216557]), 'effectorPosition': array([ 0.12314007, -0.32874546])}
episode index:1266
target Thresh 1.856900249377026
current state at start:  [-0.46852408 -1.62585173]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.46852408, -1.62585173]), 'currentState': array([0.03147592, 4.25262999]), 'targetState': array([ 0.95053317, -0.67305266]), 'effectorPosition': array([ 0.58419512, -0.87820943])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9541951207038865
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.46852408, -1.62585173]), 'currentState': array([0.51495727, 4.14290127]), 'targetState': array([ 0.95053317, -0.67305266]), 'effectorPosition': array([ 0.81581034, -0.50601593])}
episode index:1267
target Thresh 1.8571861628694748
current state at start:  [0.60496122 2.76064781]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.60496122, 2.76064781]), 'currentState': array([0.1421915 , 3.24141461]), 'targetState': array([ 0.23632147, -0.20289743]), 'effectorPosition': array([ 0.01905041, -0.09794505])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9542312444257288
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.60496122, 2.76064781]), 'currentState': array([0.1421915 , 3.24141461]), 'targetState': array([ 0.23632147, -0.20289743]), 'effectorPosition': array([ 0.01905041, -0.09794505])}
episode index:1268
target Thresh 1.857471505106385
current state at start:  [1.35194527 1.78152563]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.35194527, 1.78152563]), 'currentState': array([0.97201328, 2.28152563]), 'targetState': array([-0.24679233,  0.06967133]), 'effectorPosition': array([-0.4301029 ,  0.71430956])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9542439061716502
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([1.35194527, 1.78152563]), 'currentState': array([0.94085961, 2.9757578 ]), 'targetState': array([-0.24679233,  0.06967133]), 'effectorPosition': array([-0.12531009,  0.10833103])}
episode index:1269
target Thresh 1.8577562772291254
current state at start:  [-1.41729755  2.45022057]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.41729755,  2.45022057]), 'currentState': array([5.32177847, 2.9458275 ]), 'targetState': array([0.05710567, 0.75651646]), 'effectorPosition': array([0.1704363, 0.0956725])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9542565479778143
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-1.41729755,  2.45022057]), 'currentState': array([0.28153702, 2.21878879]), 'targetState': array([0.05710567, 0.75651646]), 'effectorPosition': array([0.15929098, 0.87604358])}
episode index:1270
target Thresh 1.8580404803767852
current state at start:  [-2.03137639 -1.63044891]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.03137639, -1.63044891]), 'currentState': array([3.79530591, 4.15273639]), 'targetState': array([-0.42677724,  0.06204217]), 'effectorPosition': array([-0.88775314,  0.38744126])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9542768811422693
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-2.03137639, -1.63044891]), 'currentState': array([4.21419608, 3.75732081]), 'targetState': array([-0.42677724,  0.06204217]), 'effectorPosition': array([-0.5951037 ,  0.11465318])}
episode index:1271
target Thresh 1.858324115686177
current state at start:  [-0.04677772  2.75657372]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.04677772,  2.75657372]), 'currentState': array([0.04804109, 3.25472863]), 'targetState': array([-0.52814774,  0.06970336]), 'effectorPosition': array([ 0.01180718, -0.11245752])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9542818490108681
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([-0.04677772,  2.75657372]), 'currentState': array([1.4288517 , 2.56891125]), 'targetState': array([-0.52814774,  0.06970336]), 'effectorPosition': array([-0.51386654,  0.2346044 ])}
episode index:1272
target Thresh 1.8586071842918428
current state at start:  [0.84115663 2.47497819]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.84115663, 2.47497819]), 'currentState': array([0.34115663, 1.97497819]), 'targetState': array([0.0566172 , 1.40330683]), 'effectorPosition': array([0.26414773, 1.06943566])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9543099072598776
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.84115663, 2.47497819]), 'currentState': array([0.7902674, 1.5904533]), 'targetState': array([0.0566172 , 1.40330683]), 'effectorPosition': array([-0.02057969,  1.40009466])}
episode index:1273
target Thresh 1.8588896873260572
current state at start:  [-0.15185601  2.14492609]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.15185601,  2.14492609]), 'currentState': array([6.06017192, 2.09806257]), 'targetState': array([0.58760441, 0.58924094]), 'effectorPosition': array([0.67565497, 0.73290166])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9543457707549641
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.15185601,  2.14492609]), 'currentState': array([6.06017192, 2.09806257]), 'targetState': array([0.58760441, 0.58924094]), 'effectorPosition': array([0.67565497, 0.73290166])}
episode index:1274
target Thresh 1.859171625918833
current state at start:  [-0.95073531  1.81271322]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.95073531,  1.81271322]), 'currentState': array([5.83245  , 2.0620096]), 'targetState': array([0.90017904, 0.37003738]), 'effectorPosition': array([0.85966012, 0.56355335])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9543815779935877
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.95073531,  1.81271322]), 'currentState': array([5.83245  , 2.0620096]), 'targetState': array([0.90017904, 0.37003738]), 'effectorPosition': array([0.85966012, 0.56355335])}
episode index:1275
target Thresh 1.8594530011979242
current state at start:  [ 1.6951875 -2.6658916]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.6951875, -2.6658916]), 'currentState': array([2.17510919, 3.11729371]), 'targetState': array([-0.1104081 ,  0.06323109]), 'effectorPosition': array([-0.02016119, -0.0135623 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9544173291080127
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.6951875, -2.6658916]), 'currentState': array([2.17510919, 3.11729371]), 'targetState': array([-0.1104081 ,  0.06323109]), 'effectorPosition': array([-0.02016119, -0.0135623 ])}
episode index:1276
target Thresh 1.859733814288833
current state at start:  [ 1.78896099 -1.66428498]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.78896099, -1.66428498]), 'currentState': array([2.24444589, 4.11890033]), 'targetState': array([0.19944112, 0.55523164]), 'effectorPosition': array([0.37294638, 0.86162521])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9544451933765264
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.78896099, -1.66428498]), 'currentState': array([2.20841683, 3.8318131 ]), 'targetState': array([0.19944112, 0.55523164]), 'effectorPosition': array([0.37534607, 0.56294225])}
episode index:1277
target Thresh 1.8600140663148121
current state at start:  [-3.8138937   2.54875083]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.8138937 ,  2.54875083]), 'currentState': array([2.96929161, 2.09505401]), 'targetState': array([-0.70377497, -0.89793021]), 'effectorPosition': array([-0.6404577 , -0.76725021])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9544808387651207
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.8138937 ,  2.54875083]), 'currentState': array([2.96929161, 2.09505401]), 'targetState': array([-0.70377497, -0.89793021]), 'effectorPosition': array([-0.6404577 , -0.76725021])}
episode index:1278
target Thresh 1.86029375839687
current state at start:  [-1.76931368  2.18346769]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.76931368,  2.18346769]), 'currentState': array([5.01387163, 1.88618553]), 'targetState': array([ 1.07498283, -0.48392611]), 'effectorPosition': array([ 1.11262835, -0.3764109 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9545164284142489
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.76931368,  2.18346769]), 'currentState': array([5.01387163, 1.88618553]), 'targetState': array([ 1.07498283, -0.48392611]), 'effectorPosition': array([ 1.11262835, -0.3764109 ])}
episode index:1279
target Thresh 1.8605728916537747
current state at start:  [1.0419615  2.37445449]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.0419615 , 2.37445449]), 'currentState': array([0.59267856, 2.0928024 ]), 'targetState': array([-0.20355437,  0.75749275]), 'effectorPosition': array([-0.06832447,  0.99904538])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9545441499545502
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.0419615 , 2.37445449]), 'currentState': array([0.78041208, 2.32392391]), 'targetState': array([-0.20355437,  0.75749275]), 'effectorPosition': array([-0.28868238,  0.74082036])}
episode index:1280
target Thresh 1.8608514672020604
current state at start:  [-0.00675338 -1.64849916]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.00675338, -1.64849916]), 'currentState': array([0.39046736, 4.13468614]), 'targetState': array([ 0.32741917, -0.40741544]), 'effectorPosition': array([ 0.73858787, -0.60190195])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9545718282137582
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.00675338, -1.64849916]), 'currentState': array([0.71883703, 3.67873749]), 'targetState': array([ 0.32741917, -0.40741544]), 'effectorPosition': array([ 0.44293201, -0.29234395])}
episode index:1281
target Thresh 1.8611294861560292
current state at start:  [-2.10191396  2.03279093]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.10191396,  2.03279093]), 'currentState': array([3.75073087, 2.22091372]), 'targetState': array([-0.12005012, -0.9803314 ]), 'effectorPosition': array([ 0.13172103, -0.87868644])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9545994632931547
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.10191396,  2.03279093]), 'currentState': array([3.40572524, 2.03832152]), 'targetState': array([-0.12005012, -0.9803314 ]), 'effectorPosition': array([-0.29721527, -1.00513989])}
episode index:1282
target Thresh 1.8614069496277579
current state at start:  [ 0.171412   -1.93619261]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.171412  , -1.93619261]), 'currentState': array([0.01121991, 4.21241406]), 'targetState': array([ 0.55614989, -0.82351866]), 'effectorPosition': array([ 0.53041004, -0.87169842])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9546348495259738
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.171412  , -1.93619261]), 'currentState': array([0.01121991, 4.21241406]), 'targetState': array([ 0.55614989, -0.82351866]), 'effectorPosition': array([ 0.53041004, -0.87169842])}
episode index:1283
target Thresh 1.8616838587270998
current state at start:  [0.69634072 2.52682078]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.69634072, 2.52682078]), 'currentState': array([0.43220589, 2.08406311]), 'targetState': array([-0.12122154,  1.31798856]), 'effectorPosition': array([0.09727026, 1.00423458])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9546623924780563
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.69634072, 2.52682078]), 'currentState': array([0.93220589, 1.73769808]), 'targetState': array([-0.12122154,  1.31798856]), 'effectorPosition': array([-0.29473799,  1.25732796])}
episode index:1284
target Thresh 1.8619602145616925
current state at start:  [-1.80058436 -1.87925753]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.80058436, -1.87925753]), 'currentState': array([4.98260095, 4.39494575]), 'targetState': array([-0.29159974, -0.86081632]), 'effectorPosition': array([-0.73194909, -0.91650064])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9546821882815754
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.80058436, -1.87925753]), 'currentState': array([5.43331131, 4.09518312]), 'targetState': array([-0.29159974, -0.86081632]), 'effectorPosition': array([-0.33454847, -0.85472786])}
episode index:1285
target Thresh 1.8622360182369593
current state at start:  [ 0.33556443 -2.23593703]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.33556443, -2.23593703]), 'currentState': array([0.6757254 , 3.62719521]), 'targetState': array([ 0.3266215 , -0.31036333]), 'effectorPosition': array([ 0.38213174, -0.29186913])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9547174276374994
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.33556443, -2.23593703]), 'currentState': array([0.6757254 , 3.62719521]), 'targetState': array([ 0.3266215 , -0.31036333]), 'effectorPosition': array([ 0.38213174, -0.29186913])}
episode index:1286
target Thresh 1.8625112708561153
current state at start:  [-0.77334829  1.67975751]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.77334829,  1.67975751]), 'currentState': array([5.39080206, 2.0830535 ]), 'targetState': array([0.650112  , 0.04425293]), 'effectorPosition': array([0.99859583, 0.15004828])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9547448422236398
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.77334829,  1.67975751]), 'currentState': array([5.14869841, 2.36055857]), 'targetState': array([0.650112  , 0.04425293]), 'effectorPosition': array([0.76053506, 0.03485108])}
episode index:1287
target Thresh 1.8627859735201715
current state at start:  [-3.66835866  2.43916387]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.66835866,  2.43916387]), 'currentState': array([3.08607083, 2.23590872]), 'targetState': array([-0.04903109, -1.27430565]), 'effectorPosition': array([-0.42592724, -0.7643892 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9547722142405468
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.66835866,  2.43916387]), 'currentState': array([3.57365283, 1.94304499]), 'targetState': array([-0.04903109, -1.27430565]), 'effectorPosition': array([-0.18775358, -1.11235182])}
episode index:1288
target Thresh 1.8630601273279388
current state at start:  [-1.10045955 -2.28977009]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.10045955, -2.28977009]), 'currentState': array([5.54680765, 3.49341522]), 'targetState': array([-0.07652738, -0.07975635]), 'effectorPosition': array([-0.18605922, -0.29646174])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9548073017391965
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.10045955, -2.28977009]), 'currentState': array([5.54680765, 3.49341522]), 'targetState': array([-0.07652738, -0.07975635]), 'effectorPosition': array([-0.18605922, -0.29646174])}
episode index:1289
target Thresh 1.8633337333760327
current state at start:  [-3.8698079   1.92878921]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.8698079 ,  1.92878921]), 'currentState': array([2.35007046, 1.95135757]), 'targetState': array([-0.96887514, -0.43081477]), 'effectorPosition': array([-1.10225366, -0.20531352])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.954834582900639
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.8698079 ,  1.92878921]), 'currentState': array([2.40521394, 1.96359267]), 'targetState': array([-0.96887514, -0.43081477]), 'effectorPosition': array([-1.07776775, -0.26994465])}
episode index:1290
target Thresh 1.8636067927588782
current state at start:  [-1.29060005  2.27739758]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.29060005,  2.27739758]), 'currentState': array([5.1614941, 2.305066 ]), 'targetState': array([0.67290022, 0.04543005]), 'effectorPosition': array([0.81196188, 0.0250503 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9548695677318546
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.29060005,  2.27739758]), 'currentState': array([5.1614941, 2.305066 ]), 'targetState': array([0.67290022, 0.04543005]), 'effectorPosition': array([0.81196188, 0.0250503 ])}
episode index:1291
target Thresh 1.8638793065687125
current state at start:  [-2.12178118  1.69542096]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.12178118,  1.69542096]), 'currentState': array([4.46867665, 1.84098112]), 'targetState': array([ 0.37955047, -0.77522454]), 'effectorPosition': array([ 0.75834272, -0.94397948])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9548967584689043
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.12178118,  1.69542096]), 'currentState': array([4.06915223, 2.00772125]), 'targetState': array([ 0.37955047, -0.77522454]), 'effectorPosition': array([ 0.37900461, -1.00500993])}
episode index:1292
target Thresh 1.8641512758955918
current state at start:  [-1.17425374 -2.22777845]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.17425374, -2.22777845]), 'currentState': array([5.5747821 , 3.59062861]), 'targetState': array([0.27782541, 0.07610532]), 'effectorPosition': array([-0.2071507 , -0.39415298])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9549162505350536
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.17425374, -2.22777845]), 'currentState': array([5.86151142, 2.85287838]), 'targetState': array([0.27782541, 0.07610532]), 'effectorPosition': array([0.15429631, 0.2428398 ])}
episode index:1293
target Thresh 1.8644227018273936
current state at start:  [ 3.70091147 -1.87744135]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.70091147, -1.87744135]), 'currentState': array([3.21978767, 4.01610598]), 'targetState': array([-0.22198805,  0.43841303]), 'effectorPosition': array([-0.41746637,  0.73687256])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9549433631698797
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.70091147, -1.87744135]), 'currentState': array([3.22562682, 3.62587338]), 'targetState': array([-0.22198805,  0.43841303]), 'effectorPosition': array([-0.15366209,  0.4542773 ])}
episode index:1294
target Thresh 1.8646935854498219
current state at start:  [-0.37791947 -2.58509673]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.37791947, -2.58509673]), 'currentState': array([6.08176969, 3.22620242]), 'targetState': array([-0.32345772,  0.33806339]), 'effectorPosition': array([-0.01340159, -0.0835161 ])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9549552208044976
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-0.37791947, -2.58509673]), 'currentState': array([0.54727571, 2.73177585]), 'targetState': array([-0.32345772,  0.33806339]), 'effectorPosition': array([-0.13662208,  0.38333633])}
episode index:1295
target Thresh 1.8649639278464114
current state at start:  [ 3.54238159 -2.50820635]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.54238159, -2.50820635]), 'currentState': array([3.18643186, 3.27497895]), 'targetState': array([0.38347869, 0.22849748]), 'effectorPosition': array([-0.01483506,  0.13245929])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.9549375588655334
{'reset': False, 'endBeforeDone': False, 'stepCount': 8, 'initial state': array([ 3.54238159, -2.50820635]), 'currentState': array([1.8062448 , 3.68468611]), 'targetState': array([0.38347869, 0.22849748]), 'effectorPosition': array([0.468963  , 0.26047161])}
episode index:1296
target Thresh 1.8652337300985324
current state at start:  [ 1.07741393 -2.37803029]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.07741393, -2.37803029]), 'currentState': array([0.57741393, 3.81777613]), 'targetState': array([ 0.72528914, -0.54045087]), 'effectorPosition': array([ 0.52597063, -0.40425386])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9549723024593149
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.07741393, -2.37803029]), 'currentState': array([0.57741393, 3.81777613]), 'targetState': array([ 0.72528914, -0.54045087]), 'effectorPosition': array([ 0.52597063, -0.40425386])}
episode index:1297
target Thresh 1.8655029932853942
current state at start:  [-2.03834535  2.25974687]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.03834535,  2.25974687]), 'currentState': array([4.58962854, 2.29885493]), 'targetState': array([ 0.84024554, -0.26281463]), 'effectorPosition': array([ 0.69988014, -0.4234671 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9550069925190534
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.03834535,  2.25974687]), 'currentState': array([4.58962854, 2.29885493]), 'targetState': array([ 0.84024554, -0.26281463]), 'effectorPosition': array([ 0.69988014, -0.4234671 ])}
episode index:1298
target Thresh 1.8657717184840497
current state at start:  [ 2.96774818 -2.34676033]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.96774818, -2.34676033]), 'currentState': array([3.28048707, 3.50103916]), 'targetState': array([-0.60252106,  0.35899288]), 'effectorPosition': array([-0.11199291,  0.33952064])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.955026309691864
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 2.96774818, -2.34676033]), 'currentState': array([3.79038584, 3.86979763]), 'targetState': array([-0.60252106,  0.35899288]), 'effectorPosition': array([-0.60422622,  0.3770546 ])}
episode index:1299
target Thresh 1.8660399067694
current state at start:  [ 1.47027816 -1.94213718]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.47027816, -1.94213718]), 'currentState': array([0.97027816, 3.92144794]), 'targetState': array([ 1.13094432, -0.30071458]), 'effectorPosition': array([ 0.74344742, -0.15891923])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9550532125305625
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.47027816, -1.94213718]), 'currentState': array([0.55586831, 4.28411178]), 'targetState': array([ 1.13094432, -0.30071458]), 'effectorPosition': array([ 0.97668777, -0.46419021])}
episode index:1300
target Thresh 1.866307559214199
current state at start:  [-0.35785593 -2.54198858]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.35785593, -2.54198858]), 'currentState': array([5.93071453, 3.24119672]), 'targetState': array([-0.05765621, -0.13019037]), 'effectorPosition': array([-0.02967658, -0.09503721])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9550877604071725
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.35785593, -2.54198858]), 'currentState': array([5.93071453, 3.24119672]), 'targetState': array([-0.05765621, -0.13019037]), 'effectorPosition': array([-0.02967658, -0.09503721])}
episode index:1301
target Thresh 1.8665746768890565
current state at start:  [ 1.32432711 -1.83256001]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.32432711, -1.83256001]), 'currentState': array([0.92490122, 3.9506253 ]), 'targetState': array([ 0.56974033, -0.13152075]), 'effectorPosition': array([ 0.76432836, -0.18816125])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9551222552148474
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.32432711, -1.83256001]), 'currentState': array([0.92490122, 3.9506253 ]), 'targetState': array([ 0.56974033, -0.13152075]), 'effectorPosition': array([ 0.76432836, -0.18816125])}
episode index:1302
target Thresh 1.8668412608624436
current state at start:  [-3.64846499  1.6692789 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.64846499,  1.6692789 ]), 'currentState': array([2.13472031, 1.62936618]), 'targetState': array([-1.27519217, -0.06968347]), 'effectorPosition': array([-1.34693363,  0.26210119])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9551414246275759
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-3.64846499,  1.6692789 ]), 'currentState': array([2.28586978, 1.64386514]), 'targetState': array([-1.27519217, -0.06968347]), 'effectorPosition': array([-1.36083663,  0.0460006 ])}
episode index:1303
target Thresh 1.8671073122006967
current state at start:  [-3.54481981  1.81713345]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.54481981,  1.81713345]), 'currentState': array([2.23836549, 2.10097569]), 'targetState': array([-0.90681903, -0.35274934]), 'effectorPosition': array([-0.98353411, -0.14589203])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9551758253755608
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.54481981,  1.81713345]), 'currentState': array([2.23836549, 2.10097569]), 'targetState': array([-0.90681903, -0.35274934]), 'effectorPosition': array([-0.98353411, -0.14589203])}
episode index:1304
target Thresh 1.8673728319680216
current state at start:  [1.07051801 2.37146391]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.07051801, 2.37146391]), 'currentState': array([1.57051801, 2.5889676 ]), 'targetState': array([-1.37063075, -0.04480958]), 'effectorPosition': array([-0.5248819 ,  0.14899659])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9551949243599474
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([1.07051801, 2.37146391]), 'currentState': array([2.22657444, 1.68561218]), 'targetState': array([-1.37063075, -0.04480958]), 'effectorPosition': array([-1.3272732 ,  0.09601216])}
episode index:1305
target Thresh 1.8676378212264972
current state at start:  [-1.31920635 -2.6259154 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.31920635, -2.6259154 ]), 'currentState': array([5.31183968, 3.1572699 ]), 'targetState': array([0.3851637, 0.3570079]), 'effectorPosition': array([-0.01287399, -0.00894603])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9552215744944343
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.31920635, -2.6259154 ]), 'currentState': array([5.71658195, 2.68842871]), 'targetState': array([0.3851637, 0.3570079]), 'effectorPosition': array([0.32016483, 0.31521691])}
episode index:1306
target Thresh 1.8679022810360815
current state at start:  [-0.45009582 -1.64701294]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.45009582, -1.64701294]), 'currentState': array([0.02208699, 4.17334483]), 'targetState': array([ 0.68811592, -0.44995983]), 'effectorPosition': array([ 0.50551889, -0.84724189])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9552481838483025
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.45009582, -1.64701294]), 'currentState': array([0.46045138, 3.87838928]), 'targetState': array([ 0.68811592, -0.44995983]), 'effectorPosition': array([ 0.53093067, -0.48668583])}
episode index:1307
target Thresh 1.8681662124546135
current state at start:  [ 1.80602548 -2.02548468]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.80602548, -2.02548468]), 'currentState': array([1.35731182, 3.84345902]), 'targetState': array([0.76797747, 0.26293786]), 'effectorPosition': array([0.68106411, 0.09420535])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.955282397775024
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.80602548, -2.02548468]), 'currentState': array([1.35731182, 3.84345902]), 'targetState': array([0.76797747, 0.26293786]), 'effectorPosition': array([0.68106411, 0.09420535])}
episode index:1308
target Thresh 1.8684296165378198
current state at start:  [0.01887962 1.89376135]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.01887962, 1.89376135]), 'currentState': array([6.14213373, 2.39376135]), 'targetState': array([-0.20373615,  0.13642043]), 'effectorPosition': array([0.35978899, 0.63578381])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9552938695872661
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([0.01887962, 1.89376135]), 'currentState': array([6.03793031, 3.01684384]), 'targetState': array([-0.20373615,  0.13642043]), 'effectorPosition': array([0.03774947, 0.11881528])}
episode index:1309
target Thresh 1.8686924943393166
current state at start:  [0.93906625 2.57729094]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.93906625, 2.57729094]), 'currentState': array([0.43906625, 2.12479146]), 'targetState': array([0.49308676, 1.27919691]), 'effectorPosition': array([0.06744718, 0.97122236])}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9552690228886712
{'reset': False, 'endBeforeDone': False, 'stepCount': 9, 'initial state': array([0.93906625, 2.57729094]), 'currentState': array([0.38807731, 1.76679779]), 'targetState': array([0.49308676, 1.27919691]), 'effectorPosition': array([0.37420723, 1.21262983])}
episode index:1310
target Thresh 1.8689548469106159
current state at start:  [2.04365391 1.57886704]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.04365391, 1.57886704]), 'currentState': array([2.29035438, 1.66932375]), 'targetState': array([-1.33824464, -0.05338346]), 'effectorPosition': array([-1.3426721 ,  0.02225871])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9553031426271238
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.04365391, 1.57886704]), 'currentState': array([2.29035438, 1.66932375]), 'targetState': array([-1.33824464, -0.05338346]), 'effectorPosition': array([-1.3426721 ,  0.02225871])}
episode index:1311
target Thresh 1.8692166753011281
current state at start:  [-1.88872655  2.40946195]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.88872655,  2.40946195]), 'currentState': array([4.72078536, 2.3000756 ]), 'targetState': array([ 0.73900775, -0.43384433]), 'effectorPosition': array([ 0.74843012, -0.32739511])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9553372103537799
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.88872655,  2.40946195]), 'currentState': array([4.72078536, 2.3000756 ]), 'targetState': array([ 0.73900775, -0.43384433]), 'effectorPosition': array([ 0.74843012, -0.32739511])}
episode index:1312
target Thresh 1.869477980558167
current state at start:  [-0.52524712 -1.93810541]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.52524712, -1.93810541]), 'currentState': array([6.23353831, 4.52063295]), 'targetState': array([ 0.80201394, -1.0290759 ]), 'effectorPosition': array([ 0.75970263, -1.02063012])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9553712261874785
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.52524712, -1.93810541]), 'currentState': array([6.23353831, 4.52063295]), 'targetState': array([ 0.80201394, -1.0290759 ]), 'effectorPosition': array([ 0.75970263, -1.02063012])}
episode index:1313
target Thresh 1.8697387637269542
current state at start:  [0.16324674 2.03630414]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.16324674, 2.03630414]), 'currentState': array([0.66324674, 2.52879929]), 'targetState': array([-0.41739443,  0.58846658]), 'effectorPosition': array([-0.21073006,  0.56524654])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9554051902466966
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.16324674, 2.03630414]), 'currentState': array([0.66324674, 2.52879929]), 'targetState': array([-0.41739443,  0.58846658]), 'effectorPosition': array([-0.21073006,  0.56524654])}
episode index:1314
target Thresh 1.8699990258506225
current state at start:  [-3.0686524   1.90732486]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.0686524 ,  1.90732486]), 'currentState': array([2.716358  , 1.92760879]), 'targetState': array([-0.99657044, -0.56327599]), 'effectorPosition': array([-0.97931077, -0.58512557])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9554391026495508
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.0686524 ,  1.90732486]), 'currentState': array([2.716358  , 1.92760879]), 'targetState': array([-0.99657044, -0.56327599]), 'effectorPosition': array([-0.97931077, -0.58512557])}
episode index:1315
target Thresh 1.870258767970221
current state at start:  [-3.44843722  1.9052428 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.44843722,  1.9052428 ]), 'currentState': array([3.31745282, 2.38252839]), 'targetState': array([-0.06442747, -0.85829726]), 'effectorPosition': array([-0.14987398, -0.72565633])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9554729635137988
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.44843722,  1.9052428 ]), 'currentState': array([3.31745282, 2.38252839]), 'targetState': array([-0.06442747, -0.85829726]), 'effectorPosition': array([-0.14987398, -0.72565633])}
episode index:1316
target Thresh 1.8705179911247183
current state at start:  [ 3.09159899 -2.54289113]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.09159899, -2.54289113]), 'currentState': array([3.59159899, 4.14025138]), 'targetState': array([-1.0190491 ,  0.80246346]), 'effectorPosition': array([-0.77861648,  0.55758001])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.955499179942414
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.09159899, -2.54289113]), 'currentState': array([3.45497942, 4.5317959 ]), 'targetState': array([-1.0190491 ,  0.80246346]), 'effectorPosition': array([-1.0836987 ,  0.68291366])}
episode index:1317
target Thresh 1.8707766963510075
current state at start:  [-2.03816216  1.85740106]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.03816216,  1.85740106]), 'currentState': array([3.85709547, 1.6735999 ]), 'targetState': array([ 0.25661293, -1.27780693]), 'effectorPosition': array([-0.02477413, -1.33945551])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9555178452080115
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-2.03816216,  1.85740106]), 'currentState': array([3.94672866, 1.62309448]), 'targetState': array([ 0.25661293, -1.27780693]), 'effectorPosition': array([ 0.06315283, -1.37530473])}
episode index:1318
target Thresh 1.87103488468391
current state at start:  [-0.83843742 -1.63288326]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.83843742, -1.63288326]), 'currentState': array([5.94474789, 4.26909417]), 'targetState': array([ 0.58898941, -0.54756833]), 'effectorPosition': array([ 0.23876478, -1.04170778])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9555439878575885
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.83843742, -1.63288326]), 'currentState': array([0.16156258, 3.9030962 ]), 'targetState': array([ 0.58898941, -0.54756833]), 'effectorPosition': array([ 0.38359923, -0.63659476])}
episode index:1319
target Thresh 1.871292557156179
current state at start:  [ 3.38713229 -2.1182587 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.38713229, -2.1182587 ]), 'currentState': array([3.88713229, 4.46414997]), 'targetState': array([-1.14906103,  0.4868043 ]), 'effectorPosition': array([-1.21177681,  0.20050512])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9555625908970903
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 3.38713229, -2.1182587 ]), 'currentState': array([3.81897614, 4.41904533]), 'targetState': array([-1.14906103,  0.4868043 ]), 'effectorPosition': array([-1.15388438,  0.30040226])}
episode index:1320
target Thresh 1.8715497147985052
current state at start:  [ 4.25739639 -2.63528351]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.25739639, -2.63528351]), 'currentState': array([4.03530027, 4.10011824]), 'targetState': array([-1.14606307,  0.68462534]), 'effectorPosition': array([-0.90426291,  0.18125733])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9555886600939888
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 4.25739639, -2.63528351]), 'currentState': array([3.53530027, 4.3345791 ]), 'targetState': array([-1.14606307,  0.68462534]), 'effectorPosition': array([-0.93939018,  0.61625863])}
episode index:1321
target Thresh 1.871806358639519
current state at start:  [-1.16147634 -1.75357667]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.16147634, -1.75357667]), 'currentState': array([5.56034455, 4.02960864]), 'targetState': array([ 0.22077402, -0.24442644]), 'effectorPosition': array([-0.23646001, -0.82594289])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.955607201198305
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.16147634, -1.75357667]), 'currentState': array([6.15196234, 3.41053309]), 'targetState': array([ 0.22077402, -0.24442644]), 'effectorPosition': array([ 0.00087069, -0.26812925])}
episode index:1322
target Thresh 1.872062489705797
current state at start:  [1.15159213 1.62313239]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.15159213, 1.62313239]), 'currentState': array([1.65159213, 2.12125532]), 'targetState': array([-1.09517059,  0.36575714]), 'effectorPosition': array([-0.88799555,  0.40657959])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9556407558459253
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.15159213, 1.62313239]), 'currentState': array([1.65159213, 2.12125532]), 'targetState': array([-1.09517059,  0.36575714]), 'effectorPosition': array([-0.88799555,  0.40657959])}
episode index:1323
target Thresh 1.8723181090218626
current state at start:  [ 0.05320215 -2.77477896]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.05320215, -2.77477896]), 'currentState': array([0.12431873, 3.01657767]), 'targetState': array([1.00244901, 0.29029558]), 'effectorPosition': array([-0.00771738,  0.12469501])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9556592295952864
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 0.05320215, -2.77477896]), 'currentState': array([5.40750403, 2.12914622]), 'targetState': array([1.00244901, 0.29029558]), 'effectorPosition': array([0.95250609, 0.18209148])}
episode index:1324
target Thresh 1.8725732176101944
current state at start:  [-3.49407561  2.06081406]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.49407561,  2.06081406]), 'currentState': array([2.93139806, 2.52320529]), 'targetState': array([ 0.11828405, -0.4031533 ]), 'effectorPosition': array([-0.30206884, -0.52832341])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9556776754597428
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-3.49407561,  2.06081406]), 'currentState': array([3.55270386, 2.55185834]), 'targetState': array([ 0.11828405, -0.4031533 ]), 'effectorPosition': array([ 0.06741195, -0.57730295])}
episode index:1325
target Thresh 1.8728278164912266
current state at start:  [ 1.70945908 -2.0845297 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.70945908, -2.0845297 ]), 'currentState': array([1.20945908, 3.73472247]), 'targetState': array([0.7725442 , 0.07121264]), 'effectorPosition': array([ 0.58324796, -0.03783126])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9557111010438607
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.70945908, -2.0845297 ]), 'currentState': array([1.20945908, 3.73472247]), 'targetState': array([0.7725442 , 0.07121264]), 'effectorPosition': array([ 0.58324796, -0.03783126])}
episode index:1326
target Thresh 1.8730819066833555
current state at start:  [ 2.88902915 -2.8361413 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.88902915, -2.8361413 ]), 'currentState': array([3.11381452, 2.94704401]), 'targetState': array([-0.05831466, -0.03992517]), 'effectorPosition': array([-0.02422718, -0.19272517])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9557444762503083
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.88902915, -2.8361413 ]), 'currentState': array([3.11381452, 2.94704401]), 'targetState': array([-0.05831466, -0.03992517]), 'effectorPosition': array([-0.02422718, -0.19272517])}
episode index:1327
target Thresh 1.8733354892029417
current state at start:  [ 0.671214   -2.66794476]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.671214  , -2.66794476]), 'currentState': array([1.08600624, 3.12549416]), 'targetState': array([0.05332982, 0.08621851]), 'effectorPosition': array([-0.01418251,  0.00761659])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.955777801192891
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.671214  , -2.66794476]), 'currentState': array([1.08600624, 3.12549416]), 'targetState': array([0.05332982, 0.08621851]), 'effectorPosition': array([-0.01418251,  0.00761659])}
episode index:1328
target Thresh 1.8735885650643158
current state at start:  [-0.99017464  2.85102747]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.99017464,  2.85102747]), 'currentState': array([4.96934898, 2.56042452]), 'targetState': array([ 0.66047496, -0.39344741]), 'effectorPosition': array([ 0.57269982, -0.01926376])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9558035515305938
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.99017464,  2.85102747]), 'currentState': array([4.50379957, 2.2078648 ]), 'targetState': array([ 0.66047496, -0.39344741]), 'effectorPosition': array([ 0.70251864, -0.56283615])}
episode index:1329
target Thresh 1.8738411352797817
current state at start:  [1.47852921 2.47993117]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.47852921, 2.47993117]), 'currentState': array([1.08274948, 2.92508918]), 'targetState': array([-0.12226524, -0.14828933]), 'effectorPosition': array([-0.17878963,  0.1213475 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9558292631459844
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.47852921, 2.47993117]), 'currentState': array([1.03406866, 3.2648226 ]), 'targetState': array([-0.12226524, -0.14828933]), 'effectorPosition': array([ 0.10951182, -0.05633448])}
episode index:1330
target Thresh 1.8740932008596203
current state at start:  [ 0.95193394 -1.63352107]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.95193394, -1.63352107]), 'currentState': array([1.42693721, 4.24397682]), 'targetState': array([0.98706141, 0.40875336]), 'effectorPosition': array([0.96170819, 0.41494248])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9558624492743495
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.95193394, -1.63352107]), 'currentState': array([1.42693721, 4.24397682]), 'targetState': array([0.98706141, 0.40875336]), 'effectorPosition': array([0.96170819, 0.41494248])}
episode index:1331
target Thresh 1.8743447628120946
current state at start:  [ 0.27993483 -2.82751082]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.27993483, -2.82751082]), 'currentState': array([0.77993483, 2.95567449]), 'targetState': array([-0.49092307,  0.10945906]), 'effectorPosition': array([-0.1177399 ,  0.14353895])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9558880780661856
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.27993483, -2.82751082]), 'currentState': array([1.27993483, 2.7598279 ]), 'targetState': array([-0.49092307,  0.10945906]), 'effectorPosition': array([-0.33626471,  0.17580907])}
episode index:1332
target Thresh 1.8745958221434527
current state at start:  [ 2.06485416 -2.3692313 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.06485416, -2.3692313 ]), 'currentState': array([1.69329501, 3.80284735]), 'targetState': array([1.15176910e+00, 6.24869985e-04]), 'effectorPosition': array([0.58375024, 0.28423756])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9559062415485066
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 2.06485416, -2.3692313 ]), 'currentState': array([0.83333303, 4.41311899]), 'targetState': array([1.15176910e+00, 6.24869985e-04]), 'effectorPosition': array([ 1.18144724, -0.12056931])}
episode index:1333
target Thresh 1.874846379857932
current state at start:  [1.2064955  1.68924592]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.2064955 , 1.68924592]), 'currentState': array([0.72589521, 1.26720999]), 'targetState': array([-0.12624622,  1.33450136]), 'effectorPosition': array([0.33803791, 1.57595028])}
done in step count: 16
reward sum = 0.8514577710948755
running average episode reward sum: 0.9558279443442684
{'reset': False, 'endBeforeDone': False, 'stepCount': 17, 'initial state': array([1.2064955 , 1.68924592]), 'currentState': array([2.43129856, 4.72395356]), 'targetState': array([-0.12624622,  1.33450136]), 'effectorPosition': array([-0.1149247 ,  1.41771681])}
episode index:1334
target Thresh 1.875096436957764
current state at start:  [ 1.65868196 -2.65701932]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.65868196, -2.65701932]), 'currentState': array([1.15868196, 4.06816312]), 'targetState': array([1.29349508, 0.067032  ]), 'effectorPosition': array([0.89260899, 0.04571548])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9558535413897035
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.65868196, -2.65701932]), 'currentState': array([0.77859649, 4.46606615]), 'targetState': array([1.29349508, 0.067032  ]), 'effectorPosition': array([ 1.21939366, -0.15937448])}
episode index:1335
target Thresh 1.8753459944431772
current state at start:  [ 2.33083576 -2.01663093]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.33083576, -2.01663093]), 'currentState': array([2.67109278, 3.76655438]), 'targetState': array([-0.13091674,  0.52174333]), 'effectorPosition': array([0.09675267, 0.60718028])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9558865851461482
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.33083576, -2.01663093]), 'currentState': array([2.67109278, 3.76655438]), 'targetState': array([-0.13091674,  0.52174333]), 'effectorPosition': array([0.09675267, 0.60718028])}
episode index:1336
target Thresh 1.8755950533124022
current state at start:  [ 1.14734975 -1.81158158]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.14734975, -1.81158158]), 'currentState': array([1.13716552, 3.97160372]), 'targetState': array([ 0.64825267, -0.01190229]), 'effectorPosition': array([ 0.80625013, -0.01501837])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9559195794728901
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.14734975, -1.81158158]), 'currentState': array([1.13716552, 3.97160372]), 'targetState': array([ 0.64825267, -0.01190229]), 'effectorPosition': array([ 0.80625013, -0.01501837])}
episode index:1337
target Thresh 1.8758436145616741
current state at start:  [-2.07979251  2.55574883]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.07979251,  2.55574883]), 'currentState': array([3.7033928 , 2.17164249]), 'targetState': array([-0.48941558, -1.22659129]), 'effectorPosition': array([ 0.07155915, -0.92962251])}
done in step count: 15
reward sum = 0.8600583546412884
running average episode reward sum: 0.9558479343123284
{'reset': False, 'endBeforeDone': False, 'stepCount': 16, 'initial state': array([-2.07979251,  2.55574883]), 'currentState': array([3.3043088 , 1.68836431]), 'targetState': array([-0.48941558, -1.22659129]), 'effectorPosition': array([-0.71016221, -1.12297595])}
episode index:1338
target Thresh 1.8760916791852391
current state at start:  [-1.82546635 -1.95210992]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.82546635, -1.95210992]), 'currentState': array([4.01950164, 3.83107538]), 'targetState': array([-0.34639831,  0.33942198]), 'effectorPosition': array([-0.63535677,  0.2305893 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9558734399625806
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.82546635, -1.95210992]), 'currentState': array([3.6573443 , 3.67020558]), 'targetState': array([-0.34639831,  0.33942198]), 'effectorPosition': array([-0.36747084,  0.37141658])}
episode index:1339
target Thresh 1.8763392481753556
current state at start:  [ 0.21743264 -1.71331879]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.21743264, -1.71331879]), 'currentState': array([0.60415681, 4.25810592]), 'targetState': array([ 0.86914291, -0.53021317]), 'effectorPosition': array([ 0.97229468, -0.42072158])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9559063702312652
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.21743264, -1.71331879]), 'currentState': array([0.60415681, 4.25810592]), 'targetState': array([ 0.86914291, -0.53021317]), 'effectorPosition': array([ 0.97229468, -0.42072158])}
episode index:1340
target Thresh 1.8765863225222998
current state at start:  [-0.34501591 -2.38568004]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.34501591, -2.38568004]), 'currentState': array([6.19930041, 3.39750527]), 'targetState': array([ 0.08328217, -0.15702044]), 'effectorPosition': array([ 0.01124404, -0.25496704])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9559392513869466
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.34501591, -2.38568004]), 'currentState': array([6.19930041, 3.39750527]), 'targetState': array([ 0.08328217, -0.15702044]), 'effectorPosition': array([ 0.01124404, -0.25496704])}
episode index:1341
target Thresh 1.8768329032143696
current state at start:  [-2.73322988  2.19814921]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.73322988,  2.19814921]), 'currentState': array([4.03313533, 2.00465247]), 'targetState': array([ 0.71286052, -1.05949638]), 'effectorPosition': array([ 0.34182832, -1.02098374])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9559646319745867
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.73322988,  2.19814921]), 'currentState': array([4.50950417, 1.60580084]), 'targetState': array([ 0.71286052, -1.05949638]), 'effectorPosition': array([ 0.78444536, -1.1465822 ])}
episode index:1342
target Thresh 1.877078991237888
current state at start:  [-0.2083379   1.91607674]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.2083379 ,  1.91607674]), 'currentState': array([5.74769793, 2.32227664]), 'targetState': array([0.17651056, 0.17961236]), 'effectorPosition': array([0.64570264, 0.46650382])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9559899747653726
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.2083379 ,  1.91607674]), 'currentState': array([5.4823221 , 2.66315233]), 'targetState': array([0.17651056, 0.17961236]), 'effectorPosition': array([0.40870485, 0.23985872])}
episode index:1343
target Thresh 1.8773245875772073
current state at start:  [ 3.05399529 -1.76028272]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.05399529, -1.76028272]), 'currentState': array([3.55399529, 4.53176787]), 'targetState': array([-1.32529526,  0.15458007]), 'effectorPosition': array([-1.14587224,  0.57244702])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9560152798436722
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.05399529, -1.76028272]), 'currentState': array([3.97566617, 4.69999009]), 'targetState': array([-1.32529526,  0.15458007]), 'effectorPosition': array([-1.40415146, -0.05967851])}
episode index:1344
target Thresh 1.8775696932147137
current state at start:  [-1.40037404 -2.05596596]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.40037404, -2.05596596]), 'currentState': array([5.07361918, 3.72721935]), 'targetState': array([-0.03023813,  0.18923889]), 'effectorPosition': array([-0.45815789, -0.35122589])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.956033186698807
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.40037404, -2.05596596]), 'currentState': array([5.66943625, 2.92973748]), 'targetState': array([-0.03023813,  0.18923889]), 'effectorPosition': array([0.13938154, 0.15902132])}
episode index:1345
target Thresh 1.8778143091308295
current state at start:  [-0.1326987   2.66604098]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.1326987 ,  2.66604098]), 'currentState': array([5.83131104, 3.01396441]), 'targetState': array([0.04511421, 0.14527168]), 'effectorPosition': array([0.0628951 , 0.11095529])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9560658514932359
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.1326987 ,  2.66604098]), 'currentState': array([5.83131104, 3.01396441]), 'targetState': array([0.04511421, 0.14527168]), 'effectorPosition': array([0.0628951 , 0.11095529])}
episode index:1346
target Thresh 1.878058436304019
current state at start:  [ 3.77661089 -1.90615787]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.77661089, -1.90615787]), 'currentState': array([4.26608337, 4.14276837]), 'targetState': array([-0.59931262, -0.40384006]), 'effectorPosition': array([-0.95846887, -0.052079  ])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9560836942167004
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 3.77661089, -1.90615787]), 'currentState': array([4.90955073, 4.08499832]), 'targetState': array([-0.59931262, -0.40384006]), 'effectorPosition': array([-0.71298344, -0.56354765])}
episode index:1347
target Thresh 1.8783020757107909
current state at start:  [-0.39781545  2.84480207]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.39781545,  2.84480207]), 'currentState': array([0.06261356, 3.14045425]), 'targetState': array([-0.550445  ,  0.64043566]), 'effectorPosition': array([-7.05860675e-05,  1.13621081e-03])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9561015104672814
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-0.39781545,  2.84480207]), 'currentState': array([0.97995923, 2.4088216 ]), 'targetState': array([-0.550445  ,  0.64043566]), 'effectorPosition': array([-0.41254784,  0.58579608])}
episode index:1348
target Thresh 1.8785452283257036
current state at start:  [-2.09403033  2.13435121]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.09403033,  2.13435121]), 'currentState': array([4.68062597, 2.60307323]), 'targetState': array([1.21365323, 0.01593623]), 'effectorPosition': array([ 0.50811214, -0.15774707])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9561193003038513
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-2.09403033,  2.13435121]), 'currentState': array([5.41129493, 1.78782927]), 'targetState': array([1.21365323, 0.01593623]), 'effectorPosition': array([1.2524267 , 0.02758823])}
episode index:1349
target Thresh 1.8787878951213675
current state at start:  [ 3.08233948 -2.02253694]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.08233948, -2.02253694]), 'currentState': array([3.37198083, 3.76064837]), 'targetState': array([-0.16104329, -0.00089413]), 'effectorPosition': array([-0.31317699,  0.5225578 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.956144397118441
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.08233948, -2.02253694]), 'currentState': array([3.67652331, 3.26064837]), 'targetState': array([-0.16104329, -0.00089413]), 'effectorPosition': array([-0.066639  ,  0.09857369])}
episode index:1350
target Thresh 1.8790300770684505
current state at start:  [ 0.64165819 -2.6581626 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.64165819, -2.6581626 ]), 'currentState': array([0.98871399, 3.19212762]), 'targetState': array([ 0.02121821, -0.05998527]), 'effectorPosition': array([ 0.04289672, -0.02670412])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9561768587045858
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.64165819, -2.6581626 ]), 'currentState': array([0.98871399, 3.19212762]), 'targetState': array([ 0.02121821, -0.05998527]), 'effectorPosition': array([ 0.04289672, -0.02670412])}
episode index:1351
target Thresh 1.8792717751356802
current state at start:  [0.27318098 2.35626988]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.27318098, 2.35626988]), 'currentState': array([6.05636629, 2.82414208]), 'targetState': array([ 0.04169708, -0.02041673]), 'effectorPosition': array([0.11888094, 0.2929142 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9562018758209285
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.27318098, 2.35626988]), 'currentState': array([5.55636629, 3.18052424]), 'targetState': array([ 0.04169708, -0.02041673]), 'effectorPosition': array([-0.02529709, -0.02958943])}
episode index:1352
target Thresh 1.8795129902898497
current state at start:  [-0.67227853  1.66947865]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.67227853,  1.66947865]), 'currentState': array([5.11090678, 1.61747368]), 'targetState': array([ 1.27366578, -0.28884997]), 'effectorPosition': array([ 1.29057936, -0.49100316])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9562342469400558
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.67227853,  1.66947865]), 'currentState': array([5.11090678, 1.61747368]), 'targetState': array([ 1.27366578, -0.28884997]), 'effectorPosition': array([ 1.29057936, -0.49100316])}
episode index:1353
target Thresh 1.8797537234958197
current state at start:  [1.65876815 2.95999026]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.65876815, 2.95999026]), 'currentState': array([1.97635982, 2.8299547 ]), 'targetState': array([-0.12693306, -0.6112674 ]), 'effectorPosition': array([-0.30074911, -0.07671201])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9562446344977071
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([1.65876815, 2.95999026]), 'currentState': array([2.98848447, 2.72057341]), 'targetState': array([-0.12693306, -0.6112674 ]), 'effectorPosition': array([-0.1486353 , -0.39059164])}
episode index:1354
target Thresh 1.8799939757165232
current state at start:  [-3.33077683  2.67835019]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.33077683,  2.67835019]), 'currentState': array([2.5189025 , 2.85019642]), 'targetState': array([-0.41658488, -0.08031497]), 'effectorPosition': array([-0.20179803, -0.20878263])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9562695462065649
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.33077683,  2.67835019]), 'currentState': array([2.17985462, 2.63304804]), 'targetState': array([-0.41658488, -0.08031497]), 'effectorPosition': array([-0.47175082, -0.17476562])}
episode index:1355
target Thresh 1.8802337479129696
current state at start:  [ 1.22266751 -2.51043503]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.22266751, -2.51043503]), 'currentState': array([1.68605909, 4.03128792]), 'targetState': array([0.35001722, 0.71695589]), 'effectorPosition': array([0.72913176, 0.45724096])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9562944211724893
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.22266751, -2.51043503]), 'currentState': array([2.0601668 , 4.15563012]), 'targetState': array([0.35001722, 0.71695589]), 'effectorPosition': array([0.52765992, 0.81529156])}
episode index:1356
target Thresh 1.880473041044248
current state at start:  [0.39382341 2.17136713]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.39382341, 2.17136713]), 'currentState': array([0.76941674, 2.06632057]), 'targetState': array([-0.19551384,  0.96771253]), 'effectorPosition': array([-0.23527318,  0.99682532])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9563266286734675
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.39382341, 2.17136713]), 'currentState': array([0.76941674, 2.06632057]), 'targetState': array([-0.19551384,  0.96771253]), 'effectorPosition': array([-0.23527318,  0.99682532])}
episode index:1357
target Thresh 1.8807118560675313
current state at start:  [1.57318404 2.29059247]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.57318404, 2.29059247]), 'currentState': array([2.0128679 , 1.94781912]), 'targetState': array([-1.29285981, -0.03324965]), 'effectorPosition': array([-1.11069588,  0.17333967])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.9563226989394664
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([1.57318404, 2.29059247]), 'currentState': array([2.08526259, 1.84043961]), 'targetState': array([-1.29285981, -0.03324965]), 'effectorPosition': array([-1.20008766,  0.16436048])}
episode index:1358
target Thresh 1.8809501939380797
current state at start:  [ 1.96266689 -1.77938464]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.96266689, -1.77938464]), 'currentState': array([2.46266689, 4.18301115]), 'targetState': array([-0.14526694,  0.96703205]), 'effectorPosition': array([0.15676804, 0.98256344])}
done in step count: 25
reward sum = 0.7778213593991467
running average episode reward sum: 0.9561913513754192
{'reset': False, 'endBeforeDone': False, 'stepCount': 26, 'initial state': array([ 1.96266689, -1.77938464]), 'currentState': array([2.76976016, 4.40168118]), 'targetState': array([-0.14526694,  0.96703205]), 'effectorPosition': array([-0.30089687,  1.1392962 ])}
episode index:1359
target Thresh 1.8811880556092453
current state at start:  [-1.32318401 -2.07476091]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.32318401, -2.07476091]), 'currentState': array([5.43144617, 3.92473445]), 'targetState': array([ 0.13341973, -0.83564953]), 'effectorPosition': array([-0.33897255, -0.68388352])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9562162106758785
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.32318401, -2.07476091]), 'currentState': array([5.88742677, 4.14304794]), 'targetState': array([ 0.13341973, -0.83564953]), 'effectorPosition': array([ 0.1005988 , -0.95484322])}
episode index:1360
target Thresh 1.8814254420324747
current state at start:  [-0.4766958   2.39208922]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.4766958 ,  2.39208922]), 'currentState': array([0.0233042 , 2.77384728]), 'targetState': array([-0.12086085,  0.88008967]), 'effectorPosition': array([0.05846417, 0.36097281])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9562410334454039
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.4766958 ,  2.39208922]), 'currentState': array([0.508728  , 2.29106853]), 'targetState': array([-0.12086085,  0.88008967]), 'effectorPosition': array([-0.0687894 ,  0.82224658])}
episode index:1361
target Thresh 1.881662354157314
current state at start:  [ 1.90167861 -1.87499455]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.90167861, -1.87499455]), 'currentState': array([2.26620149, 3.90819076]), 'targetState': array([-0.05114224,  0.13547154]), 'effectorPosition': array([0.3533913, 0.6592156])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9562658197644601
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.90167861, -1.87499455]), 'currentState': array([2.46759707, 3.40819076]), 'targetState': array([-0.05114224,  0.13547154]), 'effectorPosition': array([0.13682089, 0.22789169])}
episode index:1362
target Thresh 1.8818987929314126
current state at start:  [0.97106126 2.96697106]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.97106126, 2.96697106]), 'currentState': array([1.40048569, 2.49145307]), 'targetState': array([-0.59832957,  0.21301048]), 'effectorPosition': array([-0.56196441,  0.3036402 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.956297906470429
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.97106126, 2.96697106]), 'currentState': array([1.40048569, 2.49145307]), 'targetState': array([-0.59832957,  0.21301048]), 'effectorPosition': array([-0.56196441,  0.3036402 ])}
episode index:1363
target Thresh 1.882134759300525
current state at start:  [ 3.231869  -2.9671831]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.231869 , -2.9671831]), 'currentState': array([3.40417664, 2.8867826 ]), 'targetState': array([ 0.33698935, -0.00994425]), 'effectorPosition': array([ 0.03424732, -0.25180298])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.9562940150799814
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([ 3.231869 , -2.9671831]), 'currentState': array([4.3200796 , 2.76527118]), 'targetState': array([ 0.33698935, -0.00994425]), 'effectorPosition': array([ 0.3128283 , -0.20516549])}
episode index:1364
target Thresh 1.882370254208518
current state at start:  [ 2.92067777 -2.47834133]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.92067777, -2.47834133]), 'currentState': array([3.2073385 , 3.30484397]), 'targetState': array([ 0.02811776, -0.09752063]), 'effectorPosition': array([-0.02394499,  0.16130249])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9563187081092268
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 2.92067777, -2.47834133]), 'currentState': array([3.49207406, 2.82885028]), 'targetState': array([ 0.02811776, -0.09752063]), 'effectorPosition': array([ 0.06008044, -0.30561991])}
episode index:1365
target Thresh 1.8826052785973704
current state at start:  [ 1.9533533  -1.79443409]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.9533533 , -1.79443409]), 'currentState': array([1.4533533 , 4.79247908]), 'targetState': array([1.0467667 , 0.87030401]), 'effectorPosition': array([1.11647569, 0.95576725])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9563506856289126
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.9533533 , -1.79443409]), 'currentState': array([1.4533533 , 4.79247908]), 'targetState': array([1.0467667 , 0.87030401]), 'effectorPosition': array([1.11647569, 0.95576725])}
episode index:1366
target Thresh 1.882839833407181
current state at start:  [ 0.9282022  -2.21993489]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.9282022 , -2.21993489]), 'currentState': array([1.33162498, 3.56325042]), 'targetState': array([-0.00366258,  0.0008757 ]), 'effectorPosition': array([ 0.41837291, -0.0118609 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9563753010746852
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.9282022 , -2.21993489]), 'currentState': array([1.76443299, 3.07969308]), 'targetState': array([-0.00366258,  0.0008757 ]), 'effectorPosition': array([-0.06107248, -0.01002429])}
episode index:1367
target Thresh 1.883073919576169
current state at start:  [-0.63007081  2.62649014]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.63007081,  2.62649014]), 'currentState': array([6.10266739, 2.9343737 ]), 'targetState': array([-0.03982113,  0.48136167]), 'effectorPosition': array([0.05798373, 0.19855516])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9563998805329639
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.63007081,  2.62649014]), 'currentState': array([0.23718401, 2.63104527]), 'targetState': array([-0.03982113,  0.48136167]), 'effectorPosition': array([0.00913516, 0.50493785])}
episode index:1368
target Thresh 1.8833075380406792
current state at start:  [ 2.3684412  -2.36053256]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.3684412 , -2.36053256]), 'currentState': array([2.5930184 , 4.39865693]), 'targetState': array([0.09084511, 0.96296356]), 'effectorPosition': array([-0.09392361,  1.17215913])}
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.9563487373563263
{'reset': False, 'endBeforeDone': False, 'stepCount': 13, 'initial state': array([ 2.3684412 , -2.36053256]), 'currentState': array([2.44619304, 4.41379882]), 'targetState': array([0.09084511, 0.96296356]), 'effectorPosition': array([0.07041074, 1.18604226])}
episode index:1369
target Thresh 1.883540689735186
current state at start:  [-4.16888988  2.59751116]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.16888988,  2.59751116]), 'currentState': array([1.67848799, 3.08660381]), 'targetState': array([-0.08418557,  0.68755874]), 'effectorPosition': array([-0.0548052 , -0.00440467])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9563518375553363
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([-4.16888988,  2.59751116]), 'currentState': array([2.72524075, 4.07743264]), 'targetState': array([-0.08418557,  0.68755874]), 'effectorPosition': array([-0.04649698,  0.90086253])}
episode index:1370
target Thresh 1.8837733755922967
current state at start:  [ 3.32613445 -2.80407117]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.32613445, -2.80407117]), 'currentState': array([3.78061555, 3.00389694]), 'targetState': array([-0.00477469, -0.20948492]), 'effectorPosition': array([ 0.07426661, -0.1158216 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9563836742894316
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.32613445, -2.80407117]), 'currentState': array([3.78061555, 3.00389694]), 'targetState': array([-0.00477469, -0.20948492]), 'effectorPosition': array([ 0.07426661, -0.1158216 ])}
episode index:1371
target Thresh 1.8840055965427547
current state at start:  [0.42648965 1.57230996]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.42648965, 1.57230996]), 'currentState': array([0.92648965, 2.05571722]), 'targetState': array([-0.36594228,  0.42077054]), 'effectorPosition': array([-0.38668069,  0.95822821])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9564081759845559
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.42648965, 1.57230996]), 'currentState': array([0.88824421, 2.49639856]), 'targetState': array([-0.36594228,  0.42077054]), 'effectorPosition': array([-0.33983301,  0.53530123])}
episode index:1372
target Thresh 1.8842373535154442
current state at start:  [-2.07099971  2.31395266]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.07099971,  2.31395266]), 'currentState': array([4.71218559, 2.70881293]), 'targetState': array([0.8665234 , 0.16158151]), 'effectorPosition': array([ 0.4193771 , -0.09228184])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9564326419889372
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.07099971,  2.31395266]), 'currentState': array([5.21218559, 2.29412866]), 'targetState': array([0.8665234 , 0.16158151]), 'effectorPosition': array([0.81995271, 0.06248996])}
episode index:1373
target Thresh 1.8844686474373933
current state at start:  [-2.64246692  2.26293532]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.64246692,  2.26293532]), 'currentState': array([4.14071839, 2.76293532]), 'targetState': array([ 0.6342337 , -0.04375485]), 'effectorPosition': array([ 0.27256844, -0.25958198])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9564570723805027
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.64246692,  2.26293532]), 'currentState': array([4.64071839, 2.56135943]), 'targetState': array([ 0.6342337 , -0.04375485]), 'effectorPosition': array([ 0.53509166, -0.20250257])}
episode index:1374
target Thresh 1.8846994792337783
current state at start:  [0.16206055 2.01215213]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.16206055, 2.01215213]), 'currentState': array([0.6515699 , 2.43489292]), 'targetState': array([-0.33192742,  0.91242472]), 'effectorPosition': array([-0.203348  ,  0.66153735])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9564814672369533
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.16206055, 2.01215213]), 'currentState': array([0.98390605, 2.04033815]), 'targetState': array([-0.33192742,  0.91242472]), 'effectorPosition': array([-0.43934823,  0.94974609])}
episode index:1375
target Thresh 1.8849298498279263
current state at start:  [ 3.22783867 -1.76797683]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.22783867, -1.76797683]), 'currentState': array([3.32971709, 4.02791905]), 'targetState': array([0.02941633, 0.04923295]), 'effectorPosition': array([-0.50614151,  0.69231201])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9564986318683217
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 3.22783867, -1.76797683]), 'currentState': array([4.05967148, 3.11121234]), 'targetState': array([0.02941633, 0.04923295]), 'effectorPosition': array([ 0.02385125, -0.01881516])}
episode index:1376
target Thresh 1.8851597601413204
current state at start:  [-1.67231006  2.72334786]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.67231006,  2.72334786]), 'currentState': array([4.20612436, 2.9435167 ]), 'targetState': array([-0.00453066,  0.00118948]), 'effectorPosition': array([ 0.16261765, -0.11252323])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9565302232758248
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.67231006,  2.72334786]), 'currentState': array([4.20612436, 2.9435167 ]), 'targetState': array([-0.00453066,  0.00118948]), 'effectorPosition': array([ 0.16261765, -0.11252323])}
episode index:1377
target Thresh 1.8853892110936017
current state at start:  [-1.0284984  -1.95052092]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.0284984 , -1.95052092]), 'currentState': array([5.69909255, 3.83266439]), 'targetState': array([ 0.47128678, -0.24460048]), 'effectorPosition': array([-0.16007048, -0.65821782])}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.9564990092150177
{'reset': False, 'endBeforeDone': False, 'stepCount': 10, 'initial state': array([-1.0284984 , -1.95052092]), 'currentState': array([0.42131102, 3.60490533]), 'targetState': array([ 0.47128678, -0.24460048]), 'effectorPosition': array([ 0.27897289, -0.36471944])}
episode index:1378
target Thresh 1.8856182036025748
current state at start:  [-1.28046031 -2.71658479]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.28046031, -2.71658479]), 'currentState': array([5.41744002, 3.06843214]), 'targetState': array([0.51409376, 0.20212838]), 'effectorPosition': array([0.0574014, 0.0453338])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9565233028994158
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.28046031, -2.71658479]), 'currentState': array([5.78174444, 2.63854926]), 'targetState': array([0.51409376, 0.20212838]), 'effectorPosition': array([0.34036735, 0.36319586])}
episode index:1379
target Thresh 1.8858467385842097
current state at start:  [ 0.54341066 -1.92053783]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.54341066, -1.92053783]), 'currentState': array([0.63848344, 3.96007601]), 'targetState': array([ 0.13010171, -0.40903009]), 'effectorPosition': array([ 0.68941665, -0.39755008])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9565475613755756
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.54341066, -1.92053783]), 'currentState': array([0.65381311, 3.56039838]), 'targetState': array([ 0.13010171, -0.40903009]), 'effectorPosition': array([ 0.31594503, -0.27023731])}
episode index:1380
target Thresh 1.8860748169526467
current state at start:  [2.22844475 1.79541738]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.22844475, 1.79541738]), 'currentState': array([1.72844475, 2.25323711]), 'targetState': array([-0.4835144 ,  0.63741437]), 'effectorPosition': array([-0.82439262,  0.24289654])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9565717847199815
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([2.22844475, 1.79541738]), 'currentState': array([1.22844475, 2.37242652]), 'targetState': array([-0.4835144 ,  0.63741437]), 'effectorPosition': array([-0.56066939,  0.49866624])}
episode index:1381
target Thresh 1.8863024396201997
current state at start:  [ 3.3216324 -2.7865554]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.3216324, -2.7865554]), 'currentState': array([3.61026569, 3.06436948]), 'targetState': array([0.02449838, 0.10574473]), 'effectorPosition': array([ 0.0321884, -0.0701738])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9566032088989106
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.3216324, -2.7865554]), 'currentState': array([3.61026569, 3.06436948]), 'targetState': array([0.02449838, 0.10574473]), 'effectorPosition': array([ 0.0321884, -0.0701738])}
episode index:1382
target Thresh 1.8865296074973594
current state at start:  [-2.08750863  1.80200674]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.08750863,  1.80200674]), 'currentState': array([3.69567668, 1.52870943]), 'targetState': array([ 0.04830025, -1.34028593]), 'effectorPosition': array([-0.3604635 , -1.39793241])}
done in step count: 21
reward sum = 0.8097278682212584
running average episode reward sum: 0.9564970083633518
{'reset': False, 'endBeforeDone': False, 'stepCount': 22, 'initial state': array([-2.08750863,  1.80200674]), 'currentState': array([5.58579601, 4.73524521]), 'targetState': array([ 0.04830025, -1.34028593]), 'effectorPosition': array([ 0.14198873, -1.42321737])}
episode index:1383
target Thresh 1.886756321492798
current state at start:  [ 1.08082972 -1.66410382]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.08082972, -1.66410382]), 'currentState': array([1.48709081, 4.46145336]), 'targetState': array([0.65373441, 0.90500348]), 'effectorPosition': array([1.02813604, 0.66806851])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9565212157272512
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.08082972, -1.66410382]), 'currentState': array([1.86942492, 4.58173084]), 'targetState': array([0.65373441, 0.90500348]), 'effectorPosition': array([0.69171632, 1.12292258])}
episode index:1384
target Thresh 1.8869825825133715
current state at start:  [ 1.05143203 -1.67375335]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.05143203, -1.67375335]), 'currentState': array([0.5558412 , 4.29309288]), 'targetState': array([ 1.04372803, -0.32699535]), 'effectorPosition': array([ 0.98557807, -0.46303414])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9565526083512749
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.05143203, -1.67375335]), 'currentState': array([0.5558412 , 4.29309288]), 'targetState': array([ 1.04372803, -0.32699535]), 'effectorPosition': array([ 0.98557807, -0.46303414])}
episode index:1385
target Thresh 1.8872083914641242
current state at start:  [-2.45349726  2.20136311]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.45349726,  2.20136311]), 'currentState': array([3.39122371, 2.42667331]), 'targetState': array([-0.26028077, -0.74605749]), 'effectorPosition': array([-0.07531138, -0.69572693])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9565839556756968
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.45349726,  2.20136311]), 'currentState': array([3.39122371, 2.42667331]), 'targetState': array([-0.26028077, -0.74605749]), 'effectorPosition': array([-0.07531138, -0.69572693])}
episode index:1386
target Thresh 1.8874337492482927
current state at start:  [-0.99157341  2.8128719 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.99157341,  2.8128719 ]), 'currentState': array([5.55683096, 2.42734477]), 'targetState': array([ 1.16519322, -0.11350015]), 'effectorPosition': array([0.61777402, 0.32738815])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.95660091028588
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-0.99157341,  2.8128719 ]), 'currentState': array([5.25623532, 2.02078712]), 'targetState': array([ 1.16519322, -0.11350015]), 'effectorPosition': array([ 1.06290911, -0.01759958])}
episode index:1387
target Thresh 1.887658656767308
current state at start:  [-3.47549873  2.43792885]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.47549873,  2.43792885]), 'currentState': array([2.35273967, 2.93792885]), 'targetState': array([0.04258746, 0.2119314 ]), 'effectorPosition': array([-0.15807562, -0.12785878])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9566249730306309
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.47549873,  2.43792885]), 'currentState': array([2.0249813 , 3.43792885]), 'targetState': array([0.04258746, 0.2119314 ]), 'effectorPosition': array([0.24328994, 0.16728538])}
episode index:1388
target Thresh 1.8878831149208004
current state at start:  [1.15975091 2.69615022]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.15975091, 2.69615022]), 'currentState': array([1.65975091, 3.19615022]), 'targetState': array([-0.45090626, -0.28559437]), 'effectorPosition': array([0.05418272, 0.00632636])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9566418736979955
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([1.15975091, 2.69615022]), 'currentState': array([2.48874429, 2.70680892]), 'targetState': array([-0.45090626, -0.28559437]), 'effectorPosition': array([-0.32977327, -0.27807783])}
episode index:1389
target Thresh 1.888107124606603
current state at start:  [0.26530312 3.00357425]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.26530312, 3.00357425]), 'currentState': array([6.10640158, 2.69676941]), 'targetState': array([0.39372438, 0.41594316]), 'effectorPosition': array([0.17147071, 0.40647794])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9566730665946156
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.26530312, 3.00357425]), 'currentState': array([6.10640158, 2.69676941]), 'targetState': array([0.39372438, 0.41594316]), 'effectorPosition': array([0.17147071, 0.40647794])}
episode index:1390
target Thresh 1.888330686720755
current state at start:  [-4.0662335   2.76645737]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.0662335 ,  2.76645737]), 'currentState': array([2.61005353, 2.45317256]), 'targetState': array([-1.09433953,  0.38571308]), 'effectorPosition': array([-0.51834393, -0.43222463])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9566828623770781
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-4.0662335 ,  2.76645737]), 'currentState': array([1.63362671, 2.03053077]), 'targetState': array([-1.09433953,  0.38571308]), 'effectorPosition': array([-0.92933096,  0.49892252])}
episode index:1391
target Thresh 1.888553802157505
current state at start:  [1.97083697 1.81306422]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.97083697, 1.81306422]), 'currentState': array([2.27493865, 2.31306422]), 'targetState': array([-0.56500005, -0.26489492]), 'effectorPosition': array([-0.77144599, -0.23010694])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9567139810104279
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.97083697, 1.81306422]), 'currentState': array([2.27493865, 2.31306422]), 'targetState': array([-0.56500005, -0.26489492]), 'effectorPosition': array([-0.77144599, -0.23010694])}
episode index:1392
target Thresh 1.888776471809315
current state at start:  [-1.34913766 -2.21084606]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.34913766, -2.21084606]), 'currentState': array([4.50217981, 3.82055674]), 'targetState': array([-1.28261048,  0.0985043 ]), 'effectorPosition': array([-0.66044032, -0.08585581])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.956737876214297
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.34913766, -2.21084606]), 'currentState': array([4.17841837, 4.27359826]), 'targetState': array([-1.28261048,  0.0985043 ]), 'effectorPosition': array([-1.07197481, -0.03434946])}
episode index:1393
target Thresh 1.888998696566864
current state at start:  [ 1.23774078 -2.24243141]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.23774078, -2.24243141]), 'currentState': array([0.82311609, 4.45561885]), 'targetState': array([ 1.35906036, -0.22249692]), 'effectorPosition': array([ 1.2164917 , -0.11059905])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9567689107363815
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.23774078, -2.24243141]), 'currentState': array([0.82311609, 4.45561885]), 'targetState': array([ 1.35906036, -0.22249692]), 'effectorPosition': array([ 1.2164917 , -0.11059905])}
episode index:1394
target Thresh 1.889220477319051
current state at start:  [1.003973   2.36120191]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.003973  , 2.36120191]), 'currentState': array([0.503973  , 2.72982114]), 'targetState': array([0.26571174, 0.24243969]), 'effectorPosition': array([-0.12008157,  0.39083747])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9567856355315525
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([1.003973  , 2.36120191]), 'currentState': array([5.98998912, 2.75293936]), 'targetState': array([0.26571174, 0.24243969]), 'effectorPosition': array([0.18091658, 0.34121657])}
episode index:1395
target Thresh 1.8894418149529997
current state at start:  [ 4.28740467 -2.68378575]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.28740467, -2.68378575]), 'currentState': array([4.63255171, 3.14663236]), 'targetState': array([ 0.21184392, -0.0695898 ]), 'effectorPosition': array([-0.00502465,  0.00038927])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9568165913800256
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.28740467, -2.68378575]), 'currentState': array([4.63255171, 3.14663236]), 'targetState': array([ 0.21184392, -0.0695898 ]), 'effectorPosition': array([-0.00502465,  0.00038927])}
episode index:1396
target Thresh 1.8896627103540609
current state at start:  [-3.40024835  2.17527023]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.40024835,  2.17527023]), 'currentState': array([2.38293695, 2.41207148]), 'targetState': array([-0.86799889, -0.10898114]), 'effectorPosition': array([-0.64323598, -0.30864253])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9568403447147571
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.40024835,  2.17527023]), 'currentState': array([1.91428783, 2.27631887]), 'targetState': array([-0.86799889, -0.10898114]), 'effectorPosition': array([-0.83520273,  0.07465232])}
episode index:1397
target Thresh 1.8898831644058163
current state at start:  [-1.10088351  2.76945872]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.10088351,  2.76945872]), 'currentState': array([5.6823018, 3.1614448]), 'targetState': array([-0.08866598,  0.89836006]), 'effectorPosition': array([-0.01106057, -0.0164851 ])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9568569825225435
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.10088351,  2.76945872]), 'currentState': array([0.34858114, 2.43197979]), 'targetState': array([-0.08866598,  0.89836006]), 'effectorPosition': array([0.00432542, 0.69480426])}
episode index:1398
target Thresh 1.8901031779900825
current state at start:  [ 3.57448096 -2.33412817]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.57448096, -2.33412817]), 'currentState': array([4.03673629, 4.21048913]), 'targetState': array([-0.85687577, -0.02591007]), 'effectorPosition': array([-1.00859336,  0.14337203])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9568878209910763
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.57448096, -2.33412817]), 'currentState': array([4.03673629, 4.21048913]), 'targetState': array([-0.85687577, -0.02591007]), 'effectorPosition': array([-1.00859336,  0.14337203])}
episode index:1399
target Thresh 1.8903227519869144
current state at start:  [-1.59361201 -2.18449667]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.59361201, -2.18449667]), 'currentState': array([4.52714268, 3.6949797 ]), 'targetState': array([-0.3299593 ,  0.29309868]), 'effectorPosition': array([-0.54407   , -0.04989285])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9568974004046541
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-1.59361201, -2.18449667]), 'currentState': array([4.30847795, 3.5899078 ]), 'targetState': array([-0.3299593 ,  0.29309868]), 'effectorPosition': array([-0.43740718,  0.07948337])}
episode index:1400
target Thresh 1.8905418872746076
current state at start:  [0.38354958 2.90593011]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.38354958, 2.90593011]), 'currentState': array([6.16931016, 3.40593011]), 'targetState': array([ 0.05336889, -0.12867398]), 'effectorPosition': array([ 0.00482134, -0.26352443])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9569281660003681
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.38354958, 2.90593011]), 'currentState': array([6.16931016, 3.40593011]), 'targetState': array([ 0.05336889, -0.12867398]), 'effectorPosition': array([ 0.00482134, -0.26352443])}
episode index:1401
target Thresh 1.8907605847297042
current state at start:  [1.83881262 2.31432228]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.83881262, 2.31432228]), 'currentState': array([1.57497984, 2.81432228]), 'targetState': array([-0.04891969, -0.23141973]), 'effectorPosition': array([-0.32167871,  0.05173137])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9569446936993693
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([1.83881262, 2.31432228]), 'currentState': array([1.57535721, 3.03484119]), 'targetState': array([-0.04891969, -0.23141973]), 'effectorPosition': array([-0.10657368,  0.00520651])}
episode index:1402
target Thresh 1.890978845226994
current state at start:  [-1.03891645 -1.60970106]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.03891645, -1.60970106]), 'currentState': array([4.79661711, 4.27677055]), 'targetState': array([-0.83354118, -0.68093626]), 'effectorPosition': array([-0.8547665 , -0.65225142])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9569753817295195
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.03891645, -1.60970106]), 'currentState': array([4.79661711, 4.27677055]), 'targetState': array([-0.83354118, -0.68093626]), 'effectorPosition': array([-0.8547665 , -0.65225142])}
episode index:1403
target Thresh 1.8911966696395193
current state at start:  [-3.53459559  2.87760669]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.53459559,  2.87760669]), 'currentState': array([2.89541537, 3.27224988]), 'targetState': array([ 0.14554742, -0.19678208]), 'effectorPosition': array([0.02348388, 0.12843499])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9569989035374044
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.53459559,  2.87760669]), 'currentState': array([3.18792218, 2.88990346]), 'targetState': array([ 0.14554742, -0.19678208]), 'effectorPosition': array([-0.01993927, -0.25023224])}
episode index:1404
target Thresh 1.8914140588385782
current state at start:  [-0.93495039  2.70014791]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.93495039,  2.70014791]), 'currentState': array([5.27946549, 2.68983804]), 'targetState': array([0.48064992, 0.03853213]), 'effectorPosition': array([0.42210201, 0.14988281])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9570295093000112
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.93495039,  2.70014791]), 'currentState': array([5.27946549, 2.68983804]), 'targetState': array([0.48064992, 0.03853213]), 'effectorPosition': array([0.42210201, 0.14988281])}
episode index:1405
target Thresh 1.8916310136937275
current state at start:  [ 2.16380044 -2.15802041]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.16380044, -2.15802041]), 'currentState': array([2.66380044, 3.68720115]), 'targetState': array([-0.39089071,  0.11084792]), 'effectorPosition': array([0.10968909, 0.52758407])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9570389470601108
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 2.16380044, -2.15802041]), 'currentState': array([3.74298277, 3.43334978]), 'targetState': array([-0.39089071,  0.11084792]), 'effectorPosition': array([-0.19758662,  0.21325957])}
episode index:1406
target Thresh 1.8918475350727872
current state at start:  [-3.07520627  2.46600741]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.07520627,  2.46600741]), 'currentState': array([2.82520641, 2.9527972 ]), 'targetState': array([0.02926042, 0.04526487]), 'effectorPosition': array([-0.07527943, -0.17283224])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9570694808575095
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.07520627,  2.46600741]), 'currentState': array([2.82520641, 2.9527972 ]), 'targetState': array([0.02926042, 0.04526487]), 'effectorPosition': array([-0.07527943, -0.17283224])}
episode index:1407
target Thresh 1.8920636238418431
current state at start:  [ 2.41739021 -2.46824669]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.41739021, -2.46824669]), 'currentState': array([2.27735536, 3.3169093 ]), 'targetState': array([ 0.51613837, -0.29234863]), 'effectorPosition': array([0.12271219, 0.12489595])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.9570517222403571
{'reset': False, 'endBeforeDone': False, 'stepCount': 8, 'initial state': array([ 2.41739021, -2.46824669]), 'currentState': array([4.42511414, 2.46724446]), 'targetState': array([ 0.51613837, -0.29234863]), 'effectorPosition': array([ 0.53678153, -0.38682992])}
episode index:1408
target Thresh 1.8922792808652502
current state at start:  [-0.96439374 -2.03421637]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.96439374, -2.03421637]), 'currentState': array([5.77593005, 4.15129098]), 'targetState': array([ 0.44460646, -0.87895556]), 'effectorPosition': array([-0.00232754, -0.96734805])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9570751063977451
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.96439374, -2.03421637]), 'currentState': array([6.1855337 , 4.27184787]), 'targetState': array([ 0.44460646, -0.87895556]), 'effectorPosition': array([ 0.48265084, -0.95613295])}
episode index:1409
target Thresh 1.8924945070056374
current state at start:  [-1.2774676  -2.79635482]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.2774676 , -2.79635482]), 'currentState': array([5.36416439, 3.07304459]), 'targetState': array([0.11062099, 0.1924248 ]), 'effectorPosition': array([0.0558782 , 0.03968155])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9571055495846971
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.2774676 , -2.79635482]), 'currentState': array([5.36416439, 3.07304459]), 'targetState': array([0.11062099, 0.1924248 ]), 'effectorPosition': array([0.0558782 , 0.03968155])}
episode index:1410
target Thresh 1.892709303123909
current state at start:  [-1.0736992   2.09186859]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.0736992 ,  2.09186859]), 'currentState': array([4.78607828, 2.44886557]), 'targetState': array([ 0.49453769, -0.11079641]), 'effectorPosition': array([ 0.65387439, -0.18284901])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9571359496204273
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.0736992 ,  2.09186859]), 'currentState': array([4.78607828, 2.44886557]), 'targetState': array([ 0.49453769, -0.11079641]), 'effectorPosition': array([ 0.65387439, -0.18284901])}
episode index:1411
target Thresh 1.8929236700792504
current state at start:  [ 3.40277189 -1.63512364]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.40277189, -1.63512364]), 'currentState': array([3.62195797, 4.1955657 ]), 'targetState': array([-0.35437408, -0.05881891]), 'effectorPosition': array([-0.85037628,  0.5372323 ])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9571522131121974
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 3.40277189, -1.63512364]), 'currentState': array([4.25493912, 3.70159681]), 'targetState': array([-0.35437408, -0.05881891]), 'effectorPosition': array([-0.54403623,  0.0975642 ])}
episode index:1412
target Thresh 1.8931376087291292
current state at start:  [0.1410077  2.40976475]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.1410077 , 2.40976475]), 'currentState': array([5.93381743, 2.90976475]), 'targetState': array([ 0.00553841, -0.01946987]), 'effectorPosition': array([0.10378254, 0.20671983])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9571825370944251
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.1410077 , 2.40976475]), 'currentState': array([5.93381743, 2.90976475]), 'targetState': array([ 0.00553841, -0.01946987]), 'effectorPosition': array([0.10378254, 0.20671983])}
episode index:1413
target Thresh 1.8933511199293003
current state at start:  [ 3.83423783 -2.27064287]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.83423783, -2.27064287]), 'currentState': array([4.07611524, 3.63764487]), 'targetState': array([-0.31456508, -0.07472667]), 'effectorPosition': array([-0.45444002,  0.18586957])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9572057460498039
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.83423783, -2.27064287]), 'currentState': array([4.28039087, 3.61768164]), 'targetState': array([-0.31456508, -0.07472667]), 'effectorPosition': array([-0.46276278,  0.09089717])}
episode index:1414
target Thresh 1.893564204533809
current state at start:  [-2.36238687  3.0449275 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.36238687,  3.0449275 ]), 'currentState': array([4.26346122, 2.91550076]), 'targetState': array([0.76609628, 0.10471416]), 'effectorPosition': array([ 0.19091288, -0.1202183 ])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9572219257345744
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-2.36238687,  3.0449275 ]), 'currentState': array([5.03155839, 2.25718039]), 'targetState': array([0.76609628, 0.10471416]), 'effectorPosition': array([ 0.84939894, -0.10503782])}
episode index:1415
target Thresh 1.8937768633949938
current state at start:  [-2.1095355  -1.78331577]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.1095355 , -1.78331577]), 'currentState': array([4.6276194 , 4.90191944]), 'targetState': array([-1.03334583, -0.85058605]), 'effectorPosition': array([-1.07918568, -1.10097857])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9572450740921065
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.1095355 , -1.78331577]), 'currentState': array([4.53050375, 4.56632779]), 'targetState': array([-1.03334583, -0.85058605]), 'effectorPosition': array([-1.12758982, -0.66140486])}
episode index:1416
target Thresh 1.8939890973634907
current state at start:  [2.24062817 1.77743599]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.24062817, 1.77743599]), 'currentState': array([1.74062817, 2.17738045]), 'targetState': array([-0.45359613,  0.07391799]), 'effectorPosition': array([-0.88244616,  0.28488623])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.957268189777292
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([2.24062817, 1.77743599]), 'currentState': array([1.27492022, 2.5869526 ]), 'targetState': array([-0.45359613,  0.07391799]), 'effectorPosition': array([-0.46004296,  0.29695178])}
episode index:1417
target Thresh 1.8942009072882358
current state at start:  [-1.16731931 -2.01742814]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.16731931, -2.01742814]), 'currentState': array([5.46947392, 3.77079662]), 'targetState': array([ 0.00126981, -0.03271796]), 'effectorPosition': array([-0.29622116, -0.54337884])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9572912728592544
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.16731931, -2.01742814]), 'currentState': array([5.77443188, 3.27079662]), 'targetState': array([ 0.00126981, -0.03271796]), 'effectorPosition': array([-0.05547928, -0.1165869 ])}
episode index:1418
target Thresh 1.8944122940164687
current state at start:  [-1.88334523  2.29702575]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.88334523,  2.29702575]), 'currentState': array([3.95623396, 2.64140285]), 'targetState': array([-0.03250719, -0.06753228]), 'effectorPosition': array([ 0.26483679, -0.41818462])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9573143234069224
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.88334523,  2.29702575]), 'currentState': array([3.62628098, 2.84740839]), 'targetState': array([-0.03250719, -0.06753228]), 'effectorPosition': array([ 0.0970887 , -0.27657874])}
episode index:1419
target Thresh 1.894623258393737
current state at start:  [-0.46632653 -1.61434967]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.46632653, -1.61434967]), 'currentState': array([5.52797354, 4.47149658]), 'targetState': array([ 0.20743471, -1.16328402]), 'effectorPosition': array([-0.11123327, -1.2290193 ])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9573303696580442
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-0.46632653, -1.61434967]), 'currentState': array([5.5839243 , 4.51297216]), 'targetState': array([ 0.20743471, -1.16328402]), 'effectorPosition': array([-0.0171863 , -1.26629741])}
episode index:1420
target Thresh 1.8948338012638986
current state at start:  [1.41954969 2.74030401]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.41954969, 2.74030401]), 'currentState': array([0.91954969, 2.89007439]), 'targetState': array([-0.07809171,  0.47542919]), 'effectorPosition': array([-0.17886424,  0.17588696])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9573533602494179
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.41954969, 2.74030401]), 'currentState': array([0.52009187, 2.51588734]), 'targetState': array([-0.07809171,  0.47542919]), 'effectorPosition': array([-0.12665456,  0.60237708])}
episode index:1421
target Thresh 1.8950439234691248
current state at start:  [-0.48862073  2.96537495]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.48862073,  2.96537495]), 'currentState': array([5.58000693, 3.26033968]), 'targetState': array([ 0.99394635, -0.43211045]), 'effectorPosition': array([-0.0712352 , -0.09492018])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9573556405938276
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([-0.48862073,  2.96537495]), 'currentState': array([0.63079518, 4.1917637 ]), 'targetState': array([ 0.99394635, -0.43211045]), 'effectorPosition': array([ 0.91750594, -0.40415033])}
episode index:1422
target Thresh 1.8952536258499049
current state at start:  [ 3.87372503 -1.64732626]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.87372503, -1.64732626]), 'currentState': array([4.32940656, 4.68930879]), 'targetState': array([-0.83960459, -0.46342597]), 'effectorPosition': array([-1.29237168, -0.53255908])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9573647364191307
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 3.87372503, -1.64732626]), 'currentState': array([4.79426487, 4.24879361]), 'targetState': array([-0.83960459, -0.46342597]), 'effectorPosition': array([-0.84624103, -0.6241333 ])}
episode index:1423
target Thresh 1.8954629092450488
current state at start:  [ 1.33105537 -2.64591091]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.33105537, -2.64591091]), 'currentState': array([1.73051687, 3.15715386]), 'targetState': array([ 0.03345265, -0.17720107]), 'effectorPosition': array([0.01534327, 0.00259432])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9573946769132183
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.33105537, -2.64591091]), 'currentState': array([1.73051687, 3.15715386]), 'targetState': array([ 0.03345265, -0.17720107]), 'effectorPosition': array([0.01534327, 0.00259432])}
episode index:1424
target Thresh 1.8956717744916904
current state at start:  [-1.60274628  2.29934108]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.60274628,  2.29934108]), 'currentState': array([5.14841566, 2.68913602]), 'targetState': array([0.53735622, 0.45947039]), 'effectorPosition': array([0.43877046, 0.09342812])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9574175578417004
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.60274628,  2.29934108]), 'currentState': array([5.58263228, 2.47540456]), 'targetState': array([0.53735622, 0.45947039]), 'effectorPosition': array([0.56184375, 0.33461231])}
episode index:1425
target Thresh 1.8958802224252909
current state at start:  [1.82023088 2.12570387]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.82023088, 2.12570387]), 'currentState': array([1.40214427, 2.5261682 ]), 'targetState': array([-0.65047111,  0.03000293]), 'effectorPosition': array([-0.53831793,  0.27777121])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9574404066791184
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.82023088, 2.12570387]), 'currentState': array([1.72680099, 2.54265098]), 'targetState': array([-0.65047111,  0.03000293]), 'effectorPosition': array([-0.58396753,  0.08435916])}
episode index:1426
target Thresh 1.896088253879642
current state at start:  [-0.28847544 -2.24086408]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.28847544, -2.24086408]), 'currentState': array([6.27474608, 4.08601633]), 'targetState': array([ 0.36409085, -0.72008333]), 'effectorPosition': array([ 0.40693833, -0.8136224 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9574702312014176
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.28847544, -2.24086408]), 'currentState': array([6.27474608, 4.08601633]), 'targetState': array([ 0.36409085, -0.72008333]), 'effectorPosition': array([ 0.40693833, -0.8136224 ])}
episode index:1427
target Thresh 1.8962958696868704
current state at start:  [-3.36983015  2.43914908]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.36983015,  2.43914908]), 'currentState': array([2.51415216, 2.85930255]), 'targetState': array([-0.18429357, -0.20325167]), 'effectorPosition': array([-0.19557436, -0.20226369])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9575000139526771
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.36983015,  2.43914908]), 'currentState': array([2.51415216, 2.85930255]), 'targetState': array([-0.18429357, -0.20325167]), 'effectorPosition': array([-0.19557436, -0.20226369])}
episode index:1428
target Thresh 1.8965030706774388
current state at start:  [-1.47040943  2.80862963]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.47040943,  2.80862963]), 'currentState': array([4.82271059, 2.38455563]), 'targetState': array([ 0.65360229, -0.25481153]), 'effectorPosition': array([ 0.7126663 , -0.19585345])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9575297550205899
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.47040943,  2.80862963]), 'currentState': array([4.82271059, 2.38455563]), 'targetState': array([ 0.65360229, -0.25481153]), 'effectorPosition': array([ 0.7126663 , -0.19585345])}
episode index:1429
target Thresh 1.8967098576801524
current state at start:  [0.4700134  2.25759792]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.4700134 , 2.25759792]), 'currentState': array([0.19055363, 2.75759792]), 'targetState': array([-0.0491809 ,  0.03635304]), 'effectorPosition': array([0.00055099, 0.38163948])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9575524614856105
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.4700134 , 2.25759792]), 'currentState': array([6.14550065, 3.22895222]), 'targetState': array([-0.0491809 ,  0.03635304]), 'effectorPosition': array([-0.00819753, -0.08694621])}
episode index:1430
target Thresh 1.8969162315221588
current state at start:  [-3.39394954  2.39783351]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.39394954,  2.39783351]), 'currentState': array([2.77716751, 2.86684661]), 'targetState': array([ 0.36815832, -0.03114652]), 'effectorPosition': array([-0.13173836, -0.2401182 ])}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.9575216891487817
{'reset': False, 'endBeforeDone': False, 'stepCount': 10, 'initial state': array([-3.39394954,  2.39783351]), 'currentState': array([1.38896101, 3.63806041]), 'targetState': array([ 0.36815832, -0.03114652]), 'effectorPosition': array([0.49030191, 0.03260327])}
episode index:1431
target Thresh 1.897122193028954
current state at start:  [0.32429871 2.49377337]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.32429871, 2.49377337]), 'currentState': array([6.12964818, 1.99377337]), 'targetState': array([0.60661223, 1.18283867]), 'effectorPosition': array([0.72204471, 0.81098554])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9575443695334543
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.32429871, 2.49377337]), 'currentState': array([0.34646288, 1.75229698]), 'targetState': array([0.60661223, 1.18283867]), 'effectorPosition': array([0.43680449, 1.20340778])}
episode index:1432
target Thresh 1.8973277430243838
current state at start:  [ 2.82939259 -1.91057416]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.82939259, -1.91057416]), 'currentState': array([3.31579385, 3.87261114]), 'targetState': array([-0.54950001,  0.44547453]), 'effectorPosition': array([-0.36735251,  0.61323935])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9575739966307792
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.82939259, -1.91057416]), 'currentState': array([3.31579385, 3.87261114]), 'targetState': array([-0.54950001,  0.44547453]), 'effectorPosition': array([-0.36735251,  0.61323935])}
episode index:1433
target Thresh 1.897532882330649
current state at start:  [1.55644946 2.39815591]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.55644946, 2.39815591]), 'currentState': array([2.05644946, 1.89815591]), 'targetState': array([-1.2798558 ,  0.18564943]), 'effectorPosition': array([-1.1540993 ,  0.15800911])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9576035824071873
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.55644946, 2.39815591]), 'currentState': array([2.05644946, 1.89815591]), 'targetState': array([-1.2798558 ,  0.18564943]), 'effectorPosition': array([-1.1540993 ,  0.15800911])}
episode index:1434
target Thresh 1.897737611768307
current state at start:  [ 0.84467452 -1.64418924]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.84467452, -1.64418924]), 'currentState': array([1.25065731, 4.13899607]), 'targetState': array([0.58706424, 0.04017688]), 'effectorPosition': array([0.94136206, 0.16990175])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9576261583079488
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.84467452, -1.64418924]), 'currentState': array([1.33396794, 3.63899607]), 'targetState': array([0.58706424, 0.04017688]), 'effectorPosition': array([0.49225694, 0.005845  ])}
episode index:1435
target Thresh 1.8979419321562756
current state at start:  [0.80647751 1.6912018 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.80647751, 1.6912018 ]), 'currentState': array([1.30647751, 1.73475021]), 'targetState': array([-0.75669591,  1.17200767]), 'effectorPosition': array([-0.73371586,  1.06546721])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9576556665542525
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.80647751, 1.6912018 ]), 'currentState': array([1.30647751, 1.73475021]), 'targetState': array([-0.75669591,  1.17200767]), 'effectorPosition': array([-0.73371586,  1.06546721])}
episode index:1436
target Thresh 1.8981458443118366
current state at start:  [ 1.47756751 -2.76750439]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.47756751, -2.76750439]), 'currentState': array([1.88885542, 3.02235155]), 'targetState': array([-0.09242036,  0.10770185]), 'effectorPosition': array([-0.11521285, -0.03045655])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9576851337313199
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.47756751, -2.76750439]), 'currentState': array([1.88885542, 3.02235155]), 'targetState': array([-0.09242036,  0.10770185]), 'effectorPosition': array([-0.11521285, -0.03045655])}
episode index:1437
target Thresh 1.8983493490506393
current state at start:  [1.70417767 2.48014936]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.70417767, 2.48014936]), 'currentState': array([1.88270678, 2.54885181]), 'targetState': array([-0.67465996, -0.15799335]), 'effectorPosition': array([-0.58403107, -0.0090766 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9577145599248308
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.70417767, 2.48014936]), 'currentState': array([1.88270678, 2.54885181]), 'targetState': array([-0.67465996, -0.15799335]), 'effectorPosition': array([-0.58403107, -0.0090766 ])}
episode index:1438
target Thresh 1.8985524471867026
current state at start:  [0.16317673 2.36666294]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.16317673, 2.36666294]), 'currentState': array([0.37256863, 2.86666294]), 'targetState': array([-0.51146421, -0.02549547]), 'effectorPosition': array([-0.06384169,  0.26652519])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.95772330519243
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([0.16317673, 2.36666294]), 'currentState': array([1.36422076, 2.74165648]), 'targetState': array([-0.51146421, -0.02549547]), 'effectorPosition': array([-0.36489535,  0.1570977 ])}
episode index:1439
target Thresh 1.8987551395324194
current state at start:  [1.2019081  2.00871713]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.2019081 , 2.00871713]), 'currentState': array([0.80343996, 2.49817995]), 'targetState': array([-0.12831955, -0.08522921]), 'effectorPosition': array([-0.29298803,  0.56040337])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9577457195638241
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.2019081 , 2.00871713]), 'currentState': array([0.45163827, 2.99817995]), 'targetState': array([-0.12831955, -0.08522921]), 'effectorPosition': array([-0.05314007,  0.13307182])}
episode index:1440
target Thresh 1.8989574268985594
current state at start:  [ 1.85700642 -1.57402225]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.85700642, -1.57402225]), 'currentState': array([2.34325777, 4.27111991]), 'targetState': array([-0.21012798,  0.83967186]), 'effectorPosition': array([0.24775506, 1.04136583])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9577681028257506
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.85700642, -1.57402225]), 'currentState': array([2.79169681, 4.28930481]), 'targetState': array([-0.21012798,  0.83967186]), 'effectorPosition': array([-0.24113689,  1.05863296])}
episode index:1441
target Thresh 1.899159310094272
current state at start:  [1.05117081 1.94929943]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.05117081, 1.94929943]), 'currentState': array([0.55117081, 2.44929943]), 'targetState': array([0.36108686, 0.13079266]), 'effectorPosition': array([-0.13814678,  0.66433947])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9577767927683126
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([1.05117081, 1.94929943]), 'currentState': array([5.84537475, 2.75690788]), 'targetState': array([0.36108686, 0.13079266]), 'effectorPosition': array([0.22528743, 0.30888837])}
episode index:1442
target Thresh 1.8993607899270908
current state at start:  [-0.95325428 -1.59277725]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.95325428, -1.59277725]), 'currentState': array([5.80819653, 4.49803931]), 'targetState': array([ 0.07354897, -1.09730281]), 'effectorPosition': array([ 0.25327102, -1.22899541])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9578060534801849
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.95325428, -1.59277725]), 'currentState': array([5.80819653, 4.49803931]), 'targetState': array([ 0.07354897, -1.09730281]), 'effectorPosition': array([ 0.25327102, -1.22899541])}
episode index:1443
target Thresh 1.899561867202935
current state at start:  [-0.06642549 -2.05368916]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.06642549, -2.05368916]), 'currentState': array([0.43357451, 3.76439681]), 'targetState': array([ 0.65827532, -0.14218023]), 'effectorPosition': array([ 0.41544188, -0.45046216])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9578214925013205
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-0.06642549, -2.05368916]), 'currentState': array([0.74810449, 3.81156787]), 'targetState': array([ 0.65827532, -0.14218023]), 'effectorPosition': array([ 0.58085592, -0.30811085])}
episode index:1444
target Thresh 1.899762542726114
current state at start:  [ 0.32453899 -1.8780744 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.32453899, -1.8780744 ]), 'currentState': array([6.16308169, 4.1162584 ]), 'targetState': array([ 0.14686729, -0.98012834]), 'effectorPosition': array([ 0.33624737, -0.87409858])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9578506817798663
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.32453899, -1.8780744 ]), 'currentState': array([6.16308169, 4.1162584 ]), 'targetState': array([ 0.14686729, -0.98012834]), 'effectorPosition': array([ 0.33624737, -0.87409858])}
episode index:1445
target Thresh 1.8999628172993306
current state at start:  [-0.04845974  1.90393418]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.04845974,  1.90393418]), 'currentState': array([5.81979331, 1.68855167]), 'targetState': array([0.99475225, 0.60311189]), 'effectorPosition': array([1.23333722, 0.493875  ])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.9578393605264923
{'reset': False, 'endBeforeDone': False, 'stepCount': 7, 'initial state': array([-0.04845974,  1.90393418]), 'currentState': array([5.91045123, 1.63387513]), 'targetState': array([0.99475225, 0.60311189]), 'effectorPosition': array([1.2360655 , 0.58827555])}
episode index:1446
target Thresh 1.9001626917236827
current state at start:  [0.95699171 2.23969247]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.95699171, 2.23969247]), 'currentState': array([0.50468997, 1.73969247]), 'targetState': array([0.05537111, 1.22880655]), 'effectorPosition': array([0.25153157, 1.26512579])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9578684971121685
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.95699171, 2.23969247]), 'currentState': array([0.50468997, 1.73969247]), 'targetState': array([0.05537111, 1.22880655]), 'effectorPosition': array([0.25153157, 1.26512579])}
episode index:1447
target Thresh 1.9003621667986685
current state at start:  [-0.59759888  1.73317091]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.59759888,  1.73317091]), 'currentState': array([5.26987428, 1.99370574]), 'targetState': array([ 0.73438322, -0.16768175]), 'effectorPosition': array([ 1.08574863, -0.01787104])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9578906873765939
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.59759888,  1.73317091]), 'currentState': array([4.88602263, 2.13842876]), 'targetState': array([ 0.73438322, -0.16768175]), 'effectorPosition': array([ 0.91037675, -0.30974118])}
episode index:1448
target Thresh 1.900561243322189
current state at start:  [0.2198216  2.42380093]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.2198216 , 2.42380093]), 'currentState': array([6.08784417, 2.8273264 ]), 'targetState': array([0.2074704 , 0.10450051]), 'effectorPosition': array([0.10804541, 0.29373336])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9579197483238839
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.2198216 , 2.42380093]), 'currentState': array([6.08784417, 2.8273264 ]), 'targetState': array([0.2074704 , 0.10450051]), 'effectorPosition': array([0.10804541, 0.29373336])}
episode index:1449
target Thresh 1.90075992209055
current state at start:  [-1.50512927 -2.49611446]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.50512927, -2.49611446]), 'currentState': array([5.22791345, 3.28707085]), 'targetState': array([ 0.04854942, -0.0691317 ]), 'effectorPosition': array([-0.12091742, -0.0806572 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9579487691871089
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.50512927, -2.49611446]), 'currentState': array([5.22791345, 3.28707085]), 'targetState': array([ 0.04854942, -0.0691317 ]), 'effectorPosition': array([-0.12091742, -0.0806572 ])}
episode index:1450
target Thresh 1.900958203898467
current state at start:  [1.24269141 1.68823759]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.24269141, 1.68823759]), 'currentState': array([0.82660492, 2.16526467]), 'targetState': array([-0.30044702,  0.39808753]), 'effectorPosition': array([-0.31143522,  0.88480016])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9579708582503845
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.24269141, 1.68823759]), 'currentState': array([0.80427433, 2.60332239]), 'targetState': array([-0.30044702,  0.39808753]), 'effectorPosition': array([-0.2711949 ,  0.45744933])}
episode index:1451
target Thresh 1.9011560895390676
current state at start:  [-1.33776443 -2.2919173 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.33776443, -2.2919173 ]), 'currentState': array([5.44542088, 4.38911414]), 'targetState': array([-0.28820264, -0.96447454]), 'effectorPosition': array([-0.24809178, -1.14153561])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9579998039402947
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.33776443, -2.2919173 ]), 'currentState': array([5.44542088, 4.38911414]), 'targetState': array([-0.28820264, -0.96447454]), 'effectorPosition': array([-0.24809178, -1.14153561])}
episode index:1452
target Thresh 1.9013535798038945
current state at start:  [0.08786578 1.61435442]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.08786578, 1.61435442]), 'currentState': array([0.20703272, 1.98543366]), 'targetState': array([0.38993704, 0.48336156]), 'effectorPosition': array([0.3962516 , 1.01846386])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9580218274750915
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.08786578, 1.61435442]), 'currentState': array([6.21355997, 2.34338381]), 'targetState': array([0.38993704, 0.48336156]), 'effectorPosition': array([0.35109671, 0.69336147])}
episode index:1453
target Thresh 1.9015506754829092
current state at start:  [-1.71158807 -1.61796782]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.71158807, -1.61796782]), 'currentState': array([5.07159724, 4.7843381 ]), 'targetState': array([-0.40275497, -1.07584523]), 'effectorPosition': array([-0.55694954, -1.35409798])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9580370119128665
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.71158807, -1.61796782]), 'currentState': array([5.15572877, 4.26223497]), 'targetState': array([-0.40275497, -1.07584523]), 'effectorPosition': array([-0.57101802, -0.8965099 ])}
episode index:1454
target Thresh 1.9017473773644944
current state at start:  [-0.93422887 -1.75588054]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.93422887, -1.75588054]), 'currentState': array([5.52038366, 4.16132066]), 'targetState': array([-0.29451422, -0.88649698]), 'effectorPosition': array([-0.24427253, -0.94505848])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9580658524545071
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.93422887, -1.75588054]), 'currentState': array([5.52038366, 4.16132066]), 'targetState': array([-0.29451422, -0.88649698]), 'effectorPosition': array([-0.24427253, -0.94505848])}
episode index:1455
target Thresh 1.9019436862354582
current state at start:  [ 2.15529727 -2.45156864]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.15529727, -2.45156864]), 'currentState': array([2.52802666, 3.41866177]), 'targetState': array([-0.09831216,  0.29126214]), 'effectorPosition': array([0.12631715, 0.2456042 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9580946533800192
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.15529727, -2.45156864]), 'currentState': array([2.52802666, 3.41866177]), 'targetState': array([-0.09831216,  0.29126214]), 'effectorPosition': array([0.12631715, 0.2456042 ])}
episode index:1456
target Thresh 1.9021396028810362
current state at start:  [0.88043421 2.14748828]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.88043421, 2.14748828]), 'currentState': array([0.49851334, 1.68184905]), 'targetState': array([-0.18738038,  1.19131406]), 'effectorPosition': array([0.30578261, 1.29801687])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.958116551352991
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.88043421, 2.14748828]), 'currentState': array([0.99851334, 1.81016995]), 'targetState': array([-0.18738038,  1.19131406]), 'effectorPosition': array([-0.40354289,  1.16746084])}
episode index:1457
target Thresh 1.9023351280848952
current state at start:  [ 2.19150597 -1.91019177]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.19150597, -1.91019177]), 'currentState': array([1.96458486, 3.897914  ]), 'targetState': array([0.28301799, 0.57472409]), 'effectorPosition': array([0.5291191 , 0.51507492])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9581384192875911
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 2.19150597, -1.91019177]), 'currentState': array([2.05973692, 3.93694457]), 'targetState': array([0.28301799, 0.57472409]), 'effectorPosition': array([0.48954688, 0.60023066])}
episode index:1458
target Thresh 1.9025302626291363
current state at start:  [-0.72087494 -1.75647634]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.72087494, -1.75647634]), 'currentState': array([6.02861467, 4.02670897]), 'targetState': array([ 0.24894665, -0.48670782]), 'effectorPosition': array([ 0.16006561, -0.8414155 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9581602572455846
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.72087494, -1.75647634]), 'currentState': array([0.03148517, 3.58512509]), 'targetState': array([ 0.24894665, -0.48670782]), 'effectorPosition': array([ 0.11021971, -0.42587414])}
episode index:1459
target Thresh 1.902725007294298
current state at start:  [-0.1031883   1.79966922]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.1031883 ,  1.79966922]), 'currentState': array([5.81144843, 2.17246141]), 'targetState': array([-0.03053482,  0.04290604]), 'effectorPosition': array([0.76121738, 0.53713705])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9581685714529506
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-0.1031883 ,  1.79966922]), 'currentState': array([4.84014315, 2.93069058]), 'targetState': array([-0.03053482,  0.04290604]), 'effectorPosition': array([0.21045907, 0.00469467])}
episode index:1460
target Thresh 1.9029193628593593
current state at start:  [ 1.78377417 -2.78692705]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.78377417, -2.78692705]), 'currentState': array([1.91877586, 3.05440878]), 'targetState': array([ 0.0004958 , -0.00503931]), 'effectorPosition': array([-0.08314975, -0.02612151])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9581972035053443
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.78377417, -2.78692705]), 'currentState': array([1.91877586, 3.05440878]), 'targetState': array([ 0.0004958 , -0.00503931]), 'effectorPosition': array([-0.08314975, -0.02612151])}
episode index:1461
target Thresh 1.9031133301017424
current state at start:  [-3.85737814  2.48831228]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.85737814,  2.48831228]), 'currentState': array([2.03785865, 2.97657118]), 'targetState': array([-0.02945306, -0.00558629]), 'effectorPosition': array([-0.1527959 , -0.06183651])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9582257963894035
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.85737814,  2.48831228]), 'currentState': array([2.03785865, 2.97657118]), 'targetState': array([-0.02945306, -0.00558629]), 'effectorPosition': array([-0.1527959 , -0.06183651])}
episode index:1462
target Thresh 1.9033069097973168
current state at start:  [ 3.69310926 -1.92639494]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.69310926, -1.92639494]), 'currentState': array([3.23837404, 4.25543716]), 'targetState': array([-0.52573473,  1.22386156]), 'effectorPosition': array([-0.64288659,  0.8392064 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9582475149154531
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.69310926, -1.92639494]), 'currentState': array([2.8520986 , 4.62171721]), 'targetState': array([-0.52573473,  1.22386156]), 'effectorPosition': array([-0.58731396,  1.21407048])}
episode index:1463
target Thresh 1.9035001027204013
current state at start:  [0.3799157  2.67622454]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.3799157 , 2.67622454]), 'currentState': array([6.2753336 , 3.16074328]), 'targetState': array([ 0.07223339, -0.04872232]), 'effectorPosition': array([ 3.30075372e-05, -1.91503008e-02])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9582760343724781
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.3799157 , 2.67622454]), 'currentState': array([6.2753336 , 3.16074328]), 'targetState': array([ 0.07223339, -0.04872232]), 'effectorPosition': array([ 3.30075372e-05, -1.91503008e-02])}
episode index:1464
target Thresh 1.9036929096437682
current state at start:  [-3.03861817  2.18137652]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.03861817,  2.18137652]), 'currentState': array([2.7723671 , 1.96612493]), 'targetState': array([-1.11286832, -0.50795325]), 'effectorPosition': array([-0.90650703, -0.63876605])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9583045148950908
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.03861817,  2.18137652]), 'currentState': array([2.7723671 , 1.96612493]), 'targetState': array([-1.11286832, -0.50795325]), 'effectorPosition': array([-0.90650703, -0.63876605])}
episode index:1465
target Thresh 1.9038853313386452
current state at start:  [ 3.07729074 -1.98134894]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.07729074, -1.98134894]), 'currentState': array([2.68570331, 3.8189556 ]), 'targetState': array([0.25913883, 0.37659428]), 'effectorPosition': array([0.07770497, 0.65992847])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9583261352805648
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.07729074, -1.98134894]), 'currentState': array([2.37668538, 3.5877599 ]), 'targetState': array([0.25913883, 0.37659428]), 'effectorPosition': array([0.22818444, 0.3790998 ])}
episode index:1466
target Thresh 1.9040773685747194
current state at start:  [0.37535961 2.67109089]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.37535961, 2.67109089]), 'currentState': array([6.22206744, 3.16798808]), 'targetState': array([0.16208086, 0.14840009]), 'effectorPosition': array([-0.00126435, -0.02636436])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9583545428229775
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.37535961, 2.67109089]), 'currentState': array([6.22206744, 3.16798808]), 'targetState': array([0.16208086, 0.14840009]), 'effectorPosition': array([-0.00126435, -0.02636436])}
episode index:1467
target Thresh 1.9042690221201402
current state at start:  [-2.83880969  2.66141341]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.83880969,  2.66141341]), 'currentState': array([3.88597522, 2.23191611]), 'targetState': array([ 0.10812988, -0.7359824 ]), 'effectorPosition': array([ 0.25086366, -0.84206012])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9583829116630164
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.83880969,  2.66141341]), 'currentState': array([3.88597522, 2.23191611]), 'targetState': array([ 0.10812988, -0.7359824 ]), 'effectorPosition': array([ 0.25086366, -0.84206012])}
episode index:1468
target Thresh 1.9044602927415215
current state at start:  [0.03707368 2.85397571]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.03707368, 2.85397571]), 'currentState': array([5.87131868, 3.17325094]), 'targetState': array([ 0.65119247, -0.05522452]), 'effectorPosition': array([-0.01221217, -0.02920661])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9583844181969422
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([0.03707368, 2.85397571]), 'currentState': array([5.33550351, 2.4899052 ]), 'targetState': array([ 0.65119247, -0.05522452]), 'effectorPosition': array([0.61213623, 0.18752696])}
episode index:1469
target Thresh 1.9046511812039466
current state at start:  [-3.3045338   2.22519935]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.3045338 ,  2.22519935]), 'currentState': array([3.4786515 , 2.18432695]), 'targetState': array([ 0.02548213, -1.32707242]), 'effectorPosition': array([-0.12997317, -0.91191637])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9584059253954477
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.3045338 ,  2.22519935]), 'currentState': array([3.9786515 , 1.79579422]), 'targetState': array([ 0.02548213, -1.32707242]), 'effectorPosition': array([ 0.20370908, -1.22975363])}
episode index:1470
target Thresh 1.9048416882709693
current state at start:  [ 4.25712304 -2.80337057]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.25712304, -2.80337057]), 'currentState': array([4.19687553, 3.97981474]), 'targetState': array([-1.00522287,  0.18182008]), 'effectorPosition': array([-0.81011817,  0.07834018])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9584342014488838
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.25712304, -2.80337057]), 'currentState': array([4.19687553, 3.97981474]), 'targetState': array([-1.00522287,  0.18182008]), 'effectorPosition': array([-0.81011817,  0.07834018])}
episode index:1471
target Thresh 1.9050318147046184
current state at start:  [-1.31686737  2.22239129]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.31686737,  2.22239129]), 'currentState': array([4.5125226 , 1.79823179]), 'targetState': array([ 0.89263413, -1.06162839]), 'effectorPosition': array([ 0.80108162, -0.95252753])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.958462439083769
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.31686737,  2.22239129]), 'currentState': array([4.5125226 , 1.79823179]), 'targetState': array([ 0.89263413, -1.06162839]), 'effectorPosition': array([ 0.80108162, -0.95252753])}
episode index:1472
target Thresh 1.9052215612653993
current state at start:  [-2.32524239  1.7590908 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.32524239,  1.7590908 ]), 'currentState': array([3.5029429 , 2.13522964]), 'targetState': array([-0.66622924, -0.33032747]), 'effectorPosition': array([-0.13632822, -0.95474624])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9584771285344929
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-2.32524239,  1.7590908 ]), 'currentState': array([2.68741633, 2.41087775]), 'targetState': array([-0.66622924, -0.33032747]), 'effectorPosition': array([-0.52222487, -0.48773585])}
episode index:1473
target Thresh 1.9054109287122993
current state at start:  [ 1.97208597 -1.91851081]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.97208597, -1.91851081]), 'currentState': array([2.47208597, 4.73158832]), 'targetState': array([-0.22771994,  1.36629447]), 'effectorPosition': array([-0.17869687,  1.416497  ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9585052987322307
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.97208597, -1.91851081]), 'currentState': array([2.47208597, 4.73158832]), 'targetState': array([-0.22771994,  1.36629447]), 'effectorPosition': array([-0.17869687,  1.416497  ])}
episode index:1474
target Thresh 1.9055999178027878
current state at start:  [ 0.73173197 -2.39794654]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.73173197, -2.39794654]), 'currentState': array([1.23173197, 3.45032019]), 'targetState': array([0.29392153, 0.32899711]), 'effectorPosition': array([ 0.30227269, -0.0564736 ])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9585199392076664
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 0.73173197, -2.39794654]), 'currentState': array([1.73839442, 3.669802  ]), 'targetState': array([0.29392153, 0.32899711]), 'effectorPosition': array([0.47419081, 0.21845191])}
episode index:1475
target Thresh 1.9057885292928216
current state at start:  [-1.31826501  2.82406325]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.31826501,  2.82406325]), 'currentState': array([4.53143178, 3.13794078]), 'targetState': array([-0.31159117, -0.05734045]), 'effectorPosition': array([ 0.00359104, -0.00066379])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9585412671621328
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.31826501,  2.82406325]), 'currentState': array([4.2557507 , 3.34466795]), 'targetState': array([-0.31159117, -0.05734045]), 'effectorPosition': array([-0.19007873,  0.07048492])}
episode index:1476
target Thresh 1.9059767639368472
current state at start:  [ 0.24585888 -1.90032051]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.24585888, -1.90032051]), 'currentState': array([6.02904419, 4.13096919]), 'targetState': array([ 0.27031909, -0.84959433]), 'effectorPosition': array([ 0.22620673, -0.92217599])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9585693367172025
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.24585888, -1.90032051]), 'currentState': array([6.02904419, 4.13096919]), 'targetState': array([ 0.27031909, -0.84959433]), 'effectorPosition': array([ 0.22620673, -0.92217599])}
episode index:1477
target Thresh 1.906164622487803
current state at start:  [ 2.06210519 -2.38515393]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.06210519, -2.38515393]), 'currentState': array([2.50895534, 3.47456052]), 'targetState': array([-0.12878841,  0.42938725]), 'effectorPosition': array([0.14896318, 0.29606933])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9585906023892476
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 2.06210519, -2.38515393]), 'currentState': array([2.77537109, 3.7277983 ]), 'targetState': array([-0.12878841,  0.42938725]), 'effectorPosition': array([0.0422139 , 0.57630421])}
episode index:1478
target Thresh 1.9063521056971235
current state at start:  [0.7559619  1.94364719]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.7559619 , 1.94364719]), 'currentState': array([1.19297362, 2.41479818]), 'targetState': array([-0.36661938,  0.26195277]), 'effectorPosition': array([-0.52439457,  0.4799936 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9586118393044679
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.7559619 , 1.94364719]), 'currentState': array([0.8252149, 2.7077227]), 'targetState': array([-0.36661938,  0.26195277]), 'effectorPosition': array([-0.24599779,  0.35326156])}
episode index:1479
target Thresh 1.9065392143147424
current state at start:  [-3.97307325  2.47834853]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.97307325,  2.47834853]), 'currentState': array([1.81011206, 2.74611071]), 'targetState': array([-0.51552936,  0.02931867]), 'effectorPosition': array([-0.39257014, -0.01633042])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9586398042779108
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.97307325,  2.47834853]), 'currentState': array([1.81011206, 2.74611071]), 'targetState': array([-0.51552936,  0.02931867]), 'effectorPosition': array([-0.39257014, -0.01633042])}
episode index:1480
target Thresh 1.9067259490890935
current state at start:  [ 1.52010684 -2.40163535]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.52010684, -2.40163535]), 'currentState': array([1.85013132, 3.45005787]), 'targetState': array([0.28812128, 0.32649527]), 'effectorPosition': array([0.2788153 , 0.12907646])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.958667731486366
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.52010684, -2.40163535]), 'currentState': array([1.85013132, 3.45005787]), 'targetState': array([0.28812128, 0.32649527]), 'effectorPosition': array([0.2788153 , 0.12907646])}
episode index:1481
target Thresh 1.9069123107671166
current state at start:  [-1.92165915  2.30103276]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.92165915,  2.30103276]), 'currentState': array([4.63847384, 2.65313346]), 'targetState': array([0.2502306 , 0.08183393]), 'effectorPosition': array([ 0.45934851, -0.15127801])}
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.9586249990455915
{'reset': False, 'endBeforeDone': False, 'stepCount': 12, 'initial state': array([-1.92165915,  2.30103276]), 'currentState': array([4.71700188, 2.70534784]), 'targetState': array([0.2502306 , 0.08183393]), 'effectorPosition': array([ 0.42296649, -0.09170512])}
episode index:1482
target Thresh 1.907098300094259
current state at start:  [-0.72615835 -3.08759048]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.72615835, -3.08759048]), 'currentState': array([5.65103133, 3.29228415]), 'targetState': array([-0.22021979,  0.01691501]), 'effectorPosition': array([-0.079562  , -0.12780797])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9586528985742189
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.72615835, -3.08759048]), 'currentState': array([5.65103133, 3.29228415]), 'targetState': array([-0.22021979,  0.01691501]), 'effectorPosition': array([-0.079562  , -0.12780797])}
episode index:1483
target Thresh 1.9072839178144776
current state at start:  [ 3.20503435 -1.80067043]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.20503435, -1.80067043]), 'currentState': array([3.0798949 , 4.00555008]), 'targetState': array([-0.1818075 ,  0.30072467]), 'effectorPosition': array([-0.30301335,  0.7805872 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9586740219579291
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.20503435, -1.80067043]), 'currentState': array([3.3845078 , 3.56834393]), 'targetState': array([-0.1818075 ,  0.30072467]), 'effectorPosition': array([-0.18661214,  0.38019128])}
episode index:1484
target Thresh 1.907469164670244
current state at start:  [-3.46009672  2.30841713]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.46009672,  2.30841713]), 'currentState': array([2.41389885, 2.80841713]), 'targetState': array([-0.07400705, -0.14237081]), 'effectorPosition': array([-0.25859682, -0.2076308 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9587018508993714
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.46009672,  2.30841713]), 'currentState': array([2.41389885, 2.80841713]), 'targetState': array([-0.07400705, -0.14237081]), 'effectorPosition': array([-0.25859682, -0.2076308 ])}
episode index:1485
target Thresh 1.9076540414025456
current state at start:  [-0.63064951 -1.96630092]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.63064951, -1.96630092]), 'currentState': array([5.2001932 , 3.85167633]), 'targetState': array([-0.92420247, -0.29613358]), 'effectorPosition': array([-0.46258433, -0.51903862])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9587162507305294
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-0.63064951, -1.96630092]), 'currentState': array([4.63942482, 4.14076308]), 'targetState': array([-0.92420247, -0.29613358]), 'effectorPosition': array([-0.87224559, -0.39646849])}
episode index:1486
target Thresh 1.9078385487508898
current state at start:  [-1.47638217 -2.08223457]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.47638217, -2.08223457]), 'currentState': array([4.8998734 , 3.74991918]), 'targetState': array([-0.22518928,  0.23134163]), 'effectorPosition': array([-0.52804327, -0.28277058])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.9587046595393193
{'reset': False, 'endBeforeDone': False, 'stepCount': 7, 'initial state': array([-1.47638217, -2.08223457]), 'currentState': array([0.81284751, 2.94762216]), 'targetState': array([-0.22518928,  0.23134163]), 'effectorPosition': array([-0.12709721,  0.14612677])}
episode index:1487
target Thresh 1.908022687453306
current state at start:  [ 2.33234985 -2.58491784]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.33234985, -2.58491784]), 'currentState': array([2.82327176, 4.18303377]), 'targetState': array([-0.09970514,  1.04006269]), 'effectorPosition': array([-0.20001763,  0.97469951])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9587324117842525
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.33234985, -2.58491784]), 'currentState': array([2.82327176, 4.18303377]), 'targetState': array([-0.09970514,  1.04006269]), 'effectorPosition': array([-0.20001763,  0.97469951])}
episode index:1488
target Thresh 1.9082064582463494
current state at start:  [ 0.54808873 -2.52773616]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.54808873, -2.52773616]), 'currentState': array([0.19473913, 3.77846541]), 'targetState': array([ 0.00469556, -0.63437616]), 'effectorPosition': array([ 0.30741276, -0.54550763])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9587467620785546
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 0.54808873, -2.52773616]), 'currentState': array([5.97888432, 3.8674629 ]), 'targetState': array([ 0.00469556, -0.63437616]), 'effectorPosition': array([ 0.0416087 , -0.70881917])}
episode index:1489
target Thresh 1.9083898618651034
current state at start:  [-3.50263604  2.58457873]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.50263604,  2.58457873]), 'currentState': array([2.45868633, 2.89249707]), 'targetState': array([-0.23246955, -0.2389964 ]), 'effectorPosition': array([-0.17951394, -0.1717649 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9587744488154145
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.50263604,  2.58457873]), 'currentState': array([2.45868633, 2.89249707]), 'targetState': array([-0.23246955, -0.2389964 ]), 'effectorPosition': array([-0.17951394, -0.1717649 ])}
episode index:1490
target Thresh 1.9085728990431827
current state at start:  [ 0.49072875 -2.03144933]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.49072875, -2.03144933]), 'currentState': array([0.97168963, 3.78656151]), 'targetState': array([ 0.00146371, -0.05503694]), 'effectorPosition': array([ 0.60975105, -0.17310883])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9587953915056792
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.49072875, -2.03144933]), 'currentState': array([1.46122046, 3.28656151]), 'targetState': array([ 0.00146371, -0.05503694]), 'effectorPosition': array([ 0.14474232, -0.00537116])}
episode index:1491
target Thresh 1.9087555705127364
current state at start:  [-2.33462329  1.93752801]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.33462329,  1.93752801]), 'currentState': array([4.31718113, 1.47885373]), 'targetState': array([ 0.37210248, -1.24650776]), 'effectorPosition': array([ 0.49867032, -1.39102629])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9588230085355012
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.33462329,  1.93752801]), 'currentState': array([4.31718113, 1.47885373]), 'targetState': array([ 0.37210248, -1.24650776]), 'effectorPosition': array([ 0.49867032, -1.39102629])}
episode index:1492
target Thresh 1.9089378770044503
current state at start:  [-0.7987015  -2.47124013]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.7987015 , -2.47124013]), 'currentState': array([5.92941502, 3.32889432]), 'targetState': array([ 0.50027007, -0.2743643 ]), 'effectorPosition': array([-0.04810285, -0.18073624])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9588241960783441
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([-0.7987015 , -2.47124013]), 'currentState': array([0.439176  , 3.62387785]), 'targetState': array([ 0.50027007, -0.2743643 ]), 'effectorPosition': array([ 0.30044535, -0.37129219])}
episode index:1493
target Thresh 1.909119819247551
current state at start:  [0.59043139 1.80342305]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.59043139, 1.80342305]), 'currentState': array([0.16127538, 2.21943194]), 'targetState': array([0.31829553, 0.52073842]), 'effectorPosition': array([0.26279749, 0.85014006])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9588450634169797
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.59043139, 1.80342305]), 'currentState': array([6.2120898 , 2.45824507]), 'targetState': array([0.31829553, 0.52073842]), 'effectorPosition': array([0.2688207 , 0.61384735])}
episode index:1494
target Thresh 1.9093013979698072
current state at start:  [ 2.22160853 -2.93018773]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.22160853, -2.93018773]), 'currentState': array([2.26350064, 2.86811973]), 'targetState': array([ 0.02854032, -0.22098457]), 'effectorPosition': array([-0.23156202, -0.14388028])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.958852724913022
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 2.22160853, -2.93018773]), 'currentState': array([2.62380126, 3.15634114]), 'targetState': array([ 0.02854032, -0.22098457]), 'effectorPosition': array([0.00720518, 0.01286854])}
episode index:1495
target Thresh 1.9094826138975347
current state at start:  [ 0.21036869 -3.11699431]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.21036869, -3.11699431]), 'currentState': array([0.71036869, 2.84420244]), 'targetState': array([-0.46816773,  0.3494457 ]), 'effectorPosition': array([-0.15780801,  0.25077415])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9588735452840694
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.21036869, -3.11699431]), 'currentState': array([1.21036869, 2.59242101]), 'targetState': array([-0.46816773,  0.3494457 ]), 'effectorPosition': array([-0.43658331,  0.32168402])}
episode index:1496
target Thresh 1.9096634677555968
current state at start:  [0.56903598 2.54621102]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.56903598, 2.54621102]), 'currentState': array([0.32718517, 2.04621102]), 'targetState': array([0.07734726, 1.14246359]), 'effectorPosition': array([0.22778572, 1.01621813])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9589010178657099
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.56903598, 2.54621102]), 'currentState': array([0.32718517, 2.04621102]), 'targetState': array([0.07734726, 1.14246359]), 'effectorPosition': array([0.22778572, 1.01621813])}
episode index:1497
target Thresh 1.9098439602674098
current state at start:  [-0.4020052  -1.60626989]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.4020052 , -1.60626989]), 'currentState': array([5.48991799, 4.72450987]), 'targetState': array([-0.09483326, -1.40655925]), 'effectorPosition': array([-0.00257335, -1.42275598])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9589284537683364
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.4020052 , -1.60626989]), 'currentState': array([5.48991799, 4.72450987]), 'targetState': array([-0.09483326, -1.40655925]), 'effectorPosition': array([-0.00257335, -1.42275598])}
episode index:1498
target Thresh 1.9100240921549434
current state at start:  [ 3.83051306 -2.66553852]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.83051306, -2.66553852]), 'currentState': array([4.28347338, 4.02168653]), 'targetState': array([-0.90998996,  0.37654807]), 'effectorPosition': array([-0.85191108, -0.0094833 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9589491819512794
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.83051306, -2.66553852]), 'currentState': array([3.97194019, 4.02862531]), 'targetState': array([-0.90998996,  0.37654807]), 'effectorPosition': array([-0.82067876,  0.25110994])}
episode index:1499
target Thresh 1.9102038641387258
current state at start:  [-0.52518627 -2.15521339]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.52518627, -2.15521339]), 'currentState': array([6.11826227, 3.62797191]), 'targetState': array([-0.13637758, -0.04565262]), 'effectorPosition': array([ 0.03765466, -0.48012494])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9589698824966452
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.52518627, -2.15521339]), 'currentState': array([0.12459928, 3.15394973]), 'targetState': array([-0.13637758, -0.04565262]), 'effectorPosition': array([ 0.00161142, -0.01225148])}
episode index:1500
target Thresh 1.9103832769378448
current state at start:  [ 2.77172581 -1.59004239]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.77172581, -1.59004239]), 'currentState': array([2.28025795, 4.85279661]), 'targetState': array([-0.01585768,  1.3690737 ]), 'effectorPosition': array([0.00865598, 1.50990681])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9589972176848554
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.77172581, -1.59004239]), 'currentState': array([2.28025795, 4.85279661]), 'targetState': array([-0.01585768,  1.3690737 ]), 'effectorPosition': array([0.00865598, 1.50990681])}
episode index:1501
target Thresh 1.9105623312699522
current state at start:  [-4.11676507  2.65811434]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.11676507,  2.65811434]), 'currentState': array([1.82017719, 2.29070747]), 'targetState': array([-0.78524012,  0.32067742]), 'effectorPosition': array([-0.81268743,  0.14458014])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.959024516474679
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.11676507,  2.65811434]), 'currentState': array([1.82017719, 2.29070747]), 'targetState': array([-0.78524012,  0.32067742]), 'effectorPosition': array([-0.81268743,  0.14458014])}
episode index:1502
target Thresh 1.9107410278512655
current state at start:  [-1.60940908 -2.83880891]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.60940908, -2.83880891]), 'currentState': array([4.48906073, 3.81718843]), 'targetState': array([-0.79882414,  0.04169719]), 'effectorPosition': array([-0.65848264, -0.07570723])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9590517789387677
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.60940908, -2.83880891]), 'currentState': array([4.48906073, 3.81718843]), 'targetState': array([-0.79882414,  0.04169719]), 'effectorPosition': array([-0.65848264, -0.07570723])}
episode index:1503
target Thresh 1.9109193673965712
current state at start:  [0.30456722 1.81741668]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.30456722, 1.81741668]), 'currentState': array([0.80456722, 2.05756664]), 'targetState': array([-0.19655809,  1.27080792]), 'effectorPosition': array([-0.26778173,  0.99636609])}
done in step count: 38
reward sum = 0.682554595010387
running average episode reward sum: 0.9588679377260493
{'reset': False, 'endBeforeDone': False, 'stepCount': 39, 'initial state': array([0.30456722, 1.81741668]), 'currentState': array([2.49542431, 4.73040061]), 'targetState': array([-0.19655809,  1.27080792]), 'effectorPosition': array([-0.21074249,  1.41124375])}
episode index:1504
target Thresh 1.9110973506192277
current state at start:  [-0.89712617 -2.6165846 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.89712617, -2.6165846 ]), 'currentState': array([5.62015576, 3.2913723 ]), 'targetState': array([-0.16717669, -0.08575661]), 'effectorPosition': array([-0.08302223, -0.12449635])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9588952679999855
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.89712617, -2.6165846 ]), 'currentState': array([5.62015576, 3.2913723 ]), 'targetState': array([-0.16717669, -0.08575661]), 'effectorPosition': array([-0.08302223, -0.12449635])}
episode index:1505
target Thresh 1.911274978231168
current state at start:  [ 2.83865497 -1.73454632]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.83865497, -1.73454632]), 'currentState': array([2.6070452 , 4.07652976]), 'targetState': array([-0.1563984 ,  0.58038811]), 'effectorPosition': array([0.06040991, 0.89922888])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9589159218724954
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 2.83865497, -1.73454632]), 'currentState': array([2.78866287, 3.87378994]), 'targetState': array([-0.1563984 ,  0.58038811]), 'effectorPosition': array([-0.00942798,  0.71588862])}
episode index:1506
target Thresh 1.911452250942903
current state at start:  [ 2.95952485 -2.58016926]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.95952485, -2.58016926]), 'currentState': array([3.32676349, 3.24988214]), 'targetState': array([-0.06338399, -0.17199644]), 'effectorPosition': array([-0.02565616,  0.10515188])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9589365483344248
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 2.95952485, -2.58016926]), 'currentState': array([3.64868201, 2.89725841]), 'targetState': array([-0.06338399, -0.17199644]), 'effectorPosition': array([ 0.09151631, -0.22589285])}
episode index:1507
target Thresh 1.911629169463524
current state at start:  [-2.97312538  2.2239102 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.97312538,  2.2239102 ]), 'currentState': array([3.71155314, 1.96836399]), 'targetState': array([ 0.03037453, -1.16461276]), 'effectorPosition': array([-0.01843643, -1.10693558])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9589637787400386
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.97312538,  2.2239102 ]), 'currentState': array([3.71155314, 1.96836399]), 'targetState': array([ 0.03037453, -1.16461276]), 'effectorPosition': array([-0.01843643, -1.10693558])}
episode index:1508
target Thresh 1.9118057345007047
current state at start:  [-0.14090027 -2.13114913]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.14090027, -2.13114913]), 'currentState': array([0.15683381, 4.64148687]), 'targetState': array([ 0.77180429, -1.12699605]), 'effectorPosition': array([ 1.07355275, -0.84011848])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9589843461497536
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.14090027, -2.13114913]), 'currentState': array([5.94001912, 4.7700747 ]), 'targetState': array([ 0.77180429, -1.12699605]), 'effectorPosition': array([ 0.66007555, -1.29599681])}
episode index:1509
target Thresh 1.9119819467607058
current state at start:  [ 4.31464353 -2.75814023]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.31464353, -2.75814023]), 'currentState': array([4.06974823, 3.64841853]), 'targetState': array([-0.21080746,  0.6293782 ]), 'effectorPosition': array([-0.46391376,  0.19027541])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9589983300264756
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 4.31464353, -2.75814023]), 'currentState': array([3.30275846, 3.97545047]), 'targetState': array([-0.21080746,  0.6293782 ]), 'effectorPosition': array([-0.4425578 ,  0.67830281])}
episode index:1510
target Thresh 1.9121578069483767
current state at start:  [0.83456427 1.93050601]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.83456427, 1.93050601]), 'currentState': array([0.33456427, 2.43050601]), 'targetState': array([0.40321134, 0.39787746]), 'effectorPosition': array([0.01460454, 0.69604632])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9590122953937644
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([0.83456427, 1.93050601]), 'currentState': array([6.07919491, 2.5086423 ]), 'targetState': array([0.40321134, 0.39787746]), 'effectorPosition': array([0.30952826, 0.54001911])}
episode index:1511
target Thresh 1.9123333157671583
current state at start:  [ 4.01090567 -2.66999233]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.01090567, -2.66999233]), 'currentState': array([4.43003248, 3.16518405]), 'targetState': array([ 0.22937622, -0.20650961]), 'effectorPosition': array([-0.02273264,  0.00630517])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9590327899073929
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 4.01090567, -2.66999233]), 'currentState': array([4.60545715, 2.89484659]), 'targetState': array([ 0.22937622, -0.20650961]), 'effectorPosition': array([ 0.23962223, -0.05618302])}
episode index:1512
target Thresh 1.9125084739190858
current state at start:  [-2.94293771  2.98112229]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.94293771,  2.98112229]), 'currentState': array([3.50509664, 3.48112229]), 'targetState': array([0.42909503, 0.34737027]), 'effectorPosition': array([-0.17177236,  0.29098353])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.9590211886909313
{'reset': False, 'endBeforeDone': False, 'stepCount': 7, 'initial state': array([-2.94293771,  2.98112229]), 'currentState': array([1.96307413, 3.66168715]), 'targetState': array([0.42909503, 0.34737027]), 'effectorPosition': array([0.40866332, 0.31216958])}
episode index:1513
target Thresh 1.9126832821047925
current state at start:  [1.42055066 2.79774181]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.42055066, 2.79774181]), 'currentState': array([0.96526806, 3.08010317]), 'targetState': array([0.06588537, 0.62916927]), 'effectorPosition': array([-0.04944918,  0.03653142])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9590351112875688
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([1.42055066, 2.79774181]), 'currentState': array([0.41858107, 2.33333994]), 'targetState': array([0.06588537, 0.62916927]), 'effectorPosition': array([-0.01136724,  0.78634913])}
episode index:1514
target Thresh 1.9128577410235112
current state at start:  [-4.2864463   2.32991307]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.2864463 ,  2.32991307]), 'currentState': array([1.52710295, 2.45141322]), 'targetState': array([-0.68663208,  0.9385718 ]), 'effectorPosition': array([-0.62607107,  0.25645944])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.959055550158006
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-4.2864463 ,  2.32991307]), 'currentState': array([1.07926634, 2.02629477]), 'targetState': array([-0.68663208,  0.9385718 ]), 'effectorPosition': array([-0.52737564,  0.91763552])}
episode index:1515
target Thresh 1.913031851373078
current state at start:  [-0.93923005 -1.94929533]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.93923005, -1.94929533]), 'currentState': array([5.59252326, 4.02303602]), 'targetState': array([-0.32509726, -0.75686656]), 'effectorPosition': array([-0.21103195, -0.82667374])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9590825583703029
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.93923005, -1.94929533]), 'currentState': array([5.59252326, 4.02303602]), 'targetState': array([-0.32509726, -0.75686656]), 'effectorPosition': array([-0.21103195, -0.82667374])}
episode index:1516
target Thresh 1.9132056138499343
current state at start:  [0.3957573  2.61517548]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.3957573 , 2.61517548]), 'currentState': array([6.18007748, 2.29812103]), 'targetState': array([0.74414592, 0.44130273]), 'effectorPosition': array([0.41022709, 0.70849584])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9591029390173891
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.3957573 , 2.61517548]), 'currentState': array([5.69984589, 2.13630815]), 'targetState': array([0.74414592, 0.44130273]), 'effectorPosition': array([0.85245456, 0.44902692])}
episode index:1517
target Thresh 1.91337902914913
current state at start:  [ 3.94900314 -1.78377265]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.94900314, -1.78377265]), 'currentState': array([3.44900314, 4.13358081]), 'targetState': array([-0.39446931,  0.7000345 ]), 'effectorPosition': array([-0.6850421 ,  0.66080561])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9591232928125027
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.94900314, -1.78377265]), 'currentState': array([3.09622342, 4.11317071]), 'targetState': array([-0.39446931,  0.7000345 ]), 'effectorPosition': array([-0.39810223,  0.84470136])}
episode index:1518
target Thresh 1.913552097964327
current state at start:  [-1.65283381  1.82826255]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.65283381,  1.82826255]), 'currentState': array([5.1303515 , 2.14761363]), 'targetState': array([1.0671952 , 0.04285339]), 'effectorPosition': array([ 0.95058676, -0.07527879])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9591502030871489
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.65283381,  1.82826255]), 'currentState': array([5.1303515 , 2.14761363]), 'targetState': array([1.0671952 , 0.04285339]), 'effectorPosition': array([ 0.95058676, -0.07527879])}
episode index:1519
target Thresh 1.9137248209878004
current state at start:  [ 2.37766526 -2.20393558]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.37766526, -2.20393558]), 'currentState': array([2.79958138, 3.64153545]), 'targetState': array([-0.23015197,  0.28028411]), 'effectorPosition': array([0.04547269, 0.49265836])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9591704990061706
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 2.37766526, -2.20393558]), 'currentState': array([3.14858669, 3.47519594]), 'targetState': array([-0.23015197,  0.28028411]), 'effectorPosition': array([-0.05742025,  0.32705619])}
episode index:1520
target Thresh 1.913897198910443
current state at start:  [ 0.8356892  -2.55151391]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.8356892 , -2.55151391]), 'currentState': array([0.72661778, 4.09444619]), 'targetState': array([ 0.91632804, -0.27720252]), 'effectorPosition': array([ 0.85588683, -0.3297552 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9591973428595524
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.8356892 , -2.55151391]), 'currentState': array([0.72661778, 4.09444619]), 'targetState': array([ 0.91632804, -0.27720252]), 'effectorPosition': array([ 0.85588683, -0.3297552 ])}
episode index:1521
target Thresh 1.9140692324217663
current state at start:  [-0.72328149 -2.93118823]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.72328149, -2.93118823]), 'currentState': array([5.8059062 , 3.04037002]), 'targetState': array([ 0.0230494 , -0.02153664]), 'effectorPosition': array([0.0509653 , 0.08740603])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9592241514384883
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.72328149, -2.93118823]), 'currentState': array([5.8059062 , 3.04037002]), 'targetState': array([ 0.0230494 , -0.02153664]), 'effectorPosition': array([0.0509653 , 0.08740603])}
episode index:1522
target Thresh 1.9142409222099046
current state at start:  [-0.76454807  2.54627327]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.76454807,  2.54627327]), 'currentState': array([5.04766583, 2.96301023]), 'targetState': array([-0.16390346,  0.00413795]), 'effectorPosition': array([0.17297663, 0.04342927])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9592443588242805
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.76454807,  2.54627327]), 'currentState': array([4.64345052, 3.09435754]), 'targetState': array([-0.16390346,  0.00413795]), 'effectorPosition': array([ 0.04702856, -0.00436525])}
episode index:1523
target Thresh 1.9144122689616174
current state at start:  [-2.11563978  2.64595311]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.11563978,  2.64595311]), 'currentState': array([3.68986312, 2.57783406]), 'targetState': array([ 0.10468315, -0.32585684]), 'effectorPosition': array([ 0.14645281, -0.53669949])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9592711013709837
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.11563978,  2.64595311]), 'currentState': array([3.68986312, 2.57783406]), 'targetState': array([ 0.10468315, -0.32585684]), 'effectorPosition': array([ 0.14645281, -0.53669949])}
episode index:1524
target Thresh 1.914583273362292
current state at start:  [-0.42310931  1.98354007]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.42310931,  1.98354007]), 'currentState': array([0.02950741, 2.29159728]), 'targetState': array([0.13200534, 1.18680493]), 'effectorPosition': array([0.31770033, 0.76098177])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9592912514684454
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.42310931,  1.98354007]), 'currentState': array([0.51623017, 1.95131091]), 'targetState': array([0.13200534, 1.18680493]), 'effectorPosition': array([0.08838689, 1.11776168])}
episode index:1525
target Thresh 1.9147539360959462
current state at start:  [-1.57902   -2.1396993]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.57902  , -2.1396993]), 'currentState': array([5.18569809, 4.13241273]), 'targetState': array([-0.04001532, -0.90417108]), 'effectorPosition': array([-0.53848236, -0.78359978])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9593113751568672
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.57902  , -2.1396993]), 'currentState': array([5.68569809, 4.24542166]), 'targetState': array([-0.04001532, -0.90417108]), 'effectorPosition': array([-0.04777269, -1.04754811])}
episode index:1526
target Thresh 1.9149242578452312
current state at start:  [ 1.58002577 -2.44039321]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.58002577, -2.44039321]), 'currentState': array([2.08002577, 4.28652278]), 'targetState': array([0.31989204, 0.86662879]), 'effectorPosition': array([0.50902269, 0.95638714])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9593380212766073
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.58002577, -2.44039321]), 'currentState': array([2.08002577, 4.28652278]), 'targetState': array([0.31989204, 0.86662879]), 'effectorPosition': array([0.50902269, 0.95638714])}
episode index:1527
target Thresh 1.915094239291434
current state at start:  [ 0.87553135 -1.6132676 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.87553135, -1.6132676 ]), 'currentState': array([0.42677397, 4.40216193]), 'targetState': array([ 1.1450039 , -0.64334702]), 'effectorPosition': array([ 1.02658911, -0.57927981])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9593646325192272
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.87553135, -1.6132676 ]), 'currentState': array([0.42677397, 4.40216193]), 'targetState': array([ 1.1450039 , -0.64334702]), 'effectorPosition': array([ 1.02658911, -0.57927981])}
episode index:1528
target Thresh 1.9152638811144809
current state at start:  [ 3.92441876 -1.87379759]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.92441876, -1.87379759]), 'currentState': array([4.42441876, 4.14024774]), 'targetState': array([-0.48580601, -0.60261558]), 'effectorPosition': array([-0.93635961, -0.20090704])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9593846687307909
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.92441876, -1.87379759]), 'currentState': array([4.92441876, 4.12581238]), 'targetState': array([-0.48580601, -0.60261558]), 'effectorPosition': array([-0.72022886, -0.61175497])}
episode index:1529
target Thresh 1.9154331839929393
current state at start:  [-1.18228254 -2.22631812]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.18228254, -2.22631812]), 'currentState': array([4.79047171, 3.55989513]), 'targetState': array([-1.22464362,  0.23103655]), 'effectorPosition': array([-0.39824672, -0.11764324])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9593918022806401
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-1.18228254, -2.22631812]), 'currentState': array([4.0015173 , 4.43292567]), 'targetState': array([-1.22464362,  0.23103655]), 'effectorPosition': array([-1.20090434,  0.07841634])}
episode index:1530
target Thresh 1.9156021486040207
current state at start:  [-3.39621469  2.22977346]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.39621469,  2.22977346]), 'currentState': array([2.50157771, 2.46574038]), 'targetState': array([-0.68996065, -0.25840541]), 'effectorPosition': array([-0.54991002, -0.37047375])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.959418326250411
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.39621469,  2.22977346]), 'currentState': array([2.50157771, 2.46574038]), 'targetState': array([-0.68996065, -0.25840541]), 'effectorPosition': array([-0.54991002, -0.37047375])}
episode index:1531
target Thresh 1.915770775623584
current state at start:  [ 4.19780013 -2.16153257]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.19780013, -2.16153257]), 'currentState': array([3.73757654, 3.76742454]), 'targetState': array([-0.58620582,  0.56838581]), 'effectorPosition': array([-0.48565663,  0.3783985 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9594448155935896
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.19780013, -2.16153257]), 'currentState': array([3.73757654, 3.76742454]), 'targetState': array([-0.58620582,  0.56838581]), 'effectorPosition': array([-0.48565663,  0.3783985 ])}
episode index:1532
target Thresh 1.9159390657261377
current state at start:  [-0.32690764 -2.49757112]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.32690764, -2.49757112]), 'currentState': array([6.28182614, 3.28561419]), 'targetState': array([0.00988865, 0.05949207]), 'effectorPosition': array([ 0.0101581, -0.1435381])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9594712703779382
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.32690764, -2.49757112]), 'currentState': array([6.28182614, 3.28561419]), 'targetState': array([0.00988865, 0.05949207]), 'effectorPosition': array([ 0.0101581, -0.1435381])}
episode index:1533
target Thresh 1.916107019584842
current state at start:  [-1.70581249 -2.22886522]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.70581249, -2.22886522]), 'currentState': array([4.29999205, 3.75740002]), 'targetState': array([-0.8297217 ,  0.14934097]), 'effectorPosition': array([-0.60281708,  0.06322058])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9594976906710426
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.70581249, -2.22886522]), 'currentState': array([4.29999205, 3.75740002]), 'targetState': array([-0.8297217 ,  0.14934097]), 'effectorPosition': array([-0.60281708,  0.06322058])}
episode index:1534
target Thresh 1.916274637871513
current state at start:  [-0.14422175 -1.81145217]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.14422175, -1.81145217]), 'currentState': array([0.29240215, 3.99292396]), 'targetState': array([ 0.20640412, -0.21398771]), 'effectorPosition': array([ 0.54335495, -0.62193299])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9595175618823318
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.14422175, -1.81145217]), 'currentState': array([0.63389316, 3.56837137]), 'targetState': array([ 0.20640412, -0.21398771]), 'effectorPosition': array([ 0.3174419 , -0.28039768])}
episode index:1535
target Thresh 1.9164419212566237
current state at start:  [-1.57885008  1.62757693]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.57885008,  1.62757693]), 'currentState': array([4.20433522, 1.97504999]), 'targetState': array([ 0.04754006, -0.63095705]), 'effectorPosition': array([ 0.50813986, -0.97730677])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.959537407219648
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.57885008,  1.62757693]), 'currentState': array([3.70433522, 2.27267183]), 'targetState': array([ 0.04754006, -0.63095705]), 'effectorPosition': array([ 0.10769736, -0.83492469])}
episode index:1536
target Thresh 1.916608870409308
current state at start:  [-0.1424085  -2.18000613]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.1424085 , -2.18000613]), 'currentState': array([0.21166649, 3.63001027]), 'targetState': array([-0.03543508, -0.00639167]), 'effectorPosition': array([ 0.21289416, -0.43419252])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9595572267334934
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.1424085 , -2.18000613]), 'currentState': array([0.56001877, 3.21577178]), 'targetState': array([-0.03543508, -0.00639167]), 'effectorPosition': array([ 0.04169792, -0.06132948])}
episode index:1537
target Thresh 1.916775485997363
current state at start:  [-1.29079382 -1.82060917]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.29079382, -1.82060917]), 'currentState': array([5.12981391, 4.40160372]), 'targetState': array([-0.697478 , -0.8990748]), 'effectorPosition': array([-0.58891154, -1.02057359])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.959583522424824
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.29079382, -1.82060917]), 'currentState': array([5.12981391, 4.40160372]), 'targetState': array([-0.697478 , -0.8990748]), 'effectorPosition': array([-0.58891154, -1.02057359])}
episode index:1538
target Thresh 1.9169417686872507
current state at start:  [ 0.35792197 -2.30945448]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.35792197, -2.30945448]), 'currentState': array([0.06368439, 4.37300613]), 'targetState': array([ 0.76740178, -0.87658914]), 'effectorPosition': array([ 0.72575375, -0.89859395])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9596097839437163
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.35792197, -2.30945448]), 'currentState': array([0.06368439, 4.37300613]), 'targetState': array([ 0.76740178, -0.87658914]), 'effectorPosition': array([ 0.72575375, -0.89859395])}
episode index:1539
target Thresh 1.9171077191441026
current state at start:  [2.01076528 1.86875536]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.01076528, 1.86875536]), 'currentState': array([1.6905851 , 2.18743299]), 'targetState': array([-0.991944  ,  0.02508464]), 'effectorPosition': array([-0.86037662,  0.32118999])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9596295178502463
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([2.01076528, 1.86875536]), 'currentState': array([2.02860522, 2.23640962]), 'targetState': array([-0.991944  ,  0.02508464]), 'effectorPosition': array([-0.87458329, -0.00456307])}
episode index:1540
target Thresh 1.9172733380317204
current state at start:  [1.24231902 2.73724392]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.24231902, 2.73724392]), 'currentState': array([0.75601604, 2.91197415]), 'targetState': array([0.12565278, 0.37502392]), 'effectorPosition': array([-0.13704775,  0.18360643])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9596492261449574
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.24231902, 2.73724392]), 'currentState': array([0.29226291, 2.6895165 ]), 'targetState': array([0.12565278, 0.37502392]), 'effectorPosition': array([-0.02966268,  0.44725374])}
episode index:1541
target Thresh 1.9174386260125802
current state at start:  [-4.32839147  2.7274211 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.32839147,  2.7274211 ]), 'currentState': array([1.62370228, 3.206501  ]), 'targetState': array([-0.0011129 , -0.12149158]), 'effectorPosition': array([0.06466067, 0.00553289])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.959675393961984
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.32839147,  2.7274211 ]), 'currentState': array([1.62370228, 3.206501  ]), 'targetState': array([-0.0011129 , -0.12149158]), 'effectorPosition': array([0.06466067, 0.00553289])}
episode index:1542
target Thresh 1.9176035837478338
current state at start:  [-3.52003369  1.88182228]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.52003369,  1.88182228]), 'currentState': array([2.28129783, 2.26225175]), 'targetState': array([-0.89201312, -0.00830407]), 'effectorPosition': array([-0.82025237, -0.22774557])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9597015278609069
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.52003369,  1.88182228]), 'currentState': array([2.28129783, 2.26225175]), 'targetState': array([-0.89201312, -0.00830407]), 'effectorPosition': array([-0.82025237, -0.22774557])}
episode index:1543
target Thresh 1.9177682118973127
current state at start:  [-1.97651082  2.74401419]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.97651082,  2.74401419]), 'currentState': array([3.82685811, 3.17239161]), 'targetState': array([-0.49644022, -0.17182833]), 'effectorPosition': array([-0.0198561 ,  0.02354221])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.9596897264499873
{'reset': False, 'endBeforeDone': False, 'stepCount': 7, 'initial state': array([-1.97651082,  2.74401419]), 'currentState': array([4.49643734, 3.77032242]), 'targetState': array([-0.49644022, -0.17182833]), 'effectorPosition': array([-0.61543272, -0.06076303])}
episode index:1544
target Thresh 1.9179325111195293
current state at start:  [-0.81885449  2.18714876]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.81885449,  2.18714876]), 'currentState': array([4.96433081, 2.54848842]), 'targetState': array([-0.0578017 ,  0.02929701]), 'effectorPosition': array([ 0.58386768, -0.02606379])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9597029369830294
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-0.81885449,  2.18714876]), 'currentState': array([4.08637746, 2.99852709]), 'targetState': array([-0.0578017 ,  0.02929701]), 'effectorPosition': array([ 0.10955509, -0.09181803])}
episode index:1545
target Thresh 1.9180964820716813
current state at start:  [ 1.64736721 -1.80137688]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.64736721, -1.80137688]), 'currentState': array([1.55535961, 3.98180842]), 'targetState': array([0.32805111, 0.2776637 ]), 'effectorPosition': array([0.74983394, 0.32116161])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9597225340483703
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.64736721, -1.80137688]), 'currentState': array([1.75728321, 3.51469278]), 'targetState': array([0.32805111, 0.2776637 ]), 'effectorPosition': array([0.34542841, 0.13518724])}
episode index:1546
target Thresh 1.918260125409652
current state at start:  [-1.70565629 -2.33363253]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.70565629, -2.33363253]), 'currentState': array([4.1087513 , 3.44955277]), 'targetState': array([-0.18870137,  0.55350451]), 'effectorPosition': array([-0.27625296,  0.13332876])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9597293708072272
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-1.70565629, -2.33363253]), 'currentState': array([3.36584623, 3.79951264]), 'targetState': array([-0.18870137,  0.55350451]), 'effectorPosition': array([-0.33948598,  0.54974325])}
episode index:1547
target Thresh 1.9184234417880157
current state at start:  [ 3.11838523 -2.70242137]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.11838523, -2.70242137]), 'currentState': array([3.57012895, 3.08076394]), 'targetState': array([ 0.03471427, -0.34080691]), 'effectorPosition': array([ 0.02357892, -0.0560627 ])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9597425301284112
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 3.11838523, -2.70242137]), 'currentState': array([3.53905103, 2.7370931 ]), 'targetState': array([ 0.03471427, -0.34080691]), 'effectorPosition': array([ 0.07792744, -0.39411722])}
episode index:1548
target Thresh 1.9185864318600376
current state at start:  [-2.60516244  1.59382929]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.60516244,  1.59382929]), 'currentState': array([3.17802286, 1.65506947]), 'targetState': array([-1.21765383, -0.42559818]), 'effectorPosition': array([-0.87892602, -1.02914634])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9597620636790062
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.60516244,  1.59382929]), 'currentState': array([2.68910179, 1.61823842]), 'targetState': array([-1.21765383, -0.42559818]), 'effectorPosition': array([-1.29342445, -0.4818761 ])}
episode index:1549
target Thresh 1.9187490962776783
current state at start:  [-4.24540083  2.74729196]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.24540083,  2.74729196]), 'currentState': array([2.27286338, 2.25294266]), 'targetState': array([-0.95770164,  0.23515217]), 'effectorPosition': array([-0.83129951, -0.21913492])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9597815720250197
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-4.24540083,  2.74729196]), 'currentState': array([1.796189  , 2.12402115]), 'targetState': array([-0.95770164,  0.23515217]), 'effectorPosition': array([-0.93537427,  0.27241051])}
episode index:1550
target Thresh 1.918911435691596
current state at start:  [ 3.77518458 -1.84547134]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.77518458, -1.84547134]), 'currentState': array([4.20374826, 3.94577261]), 'targetState': array([-0.32484364, -0.24650597]), 'effectorPosition': array([-0.77824624,  0.08323795])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9598010552152034
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.77518458, -1.84547134]), 'currentState': array([4.6087195 , 3.62404226]), 'targetState': array([-0.32484364, -0.24650597]), 'effectorPosition': array([-0.47327123, -0.06551471])}
episode index:1551
target Thresh 1.9190734507511482
current state at start:  [ 1.63420616 -1.85895694]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.63420616, -1.85895694]), 'currentState': array([1.43391162, 3.92804864]), 'targetState': array([0.28132854, 0.02347865]), 'effectorPosition': array([0.74130268, 0.19430272])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9598205132981833
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.63420616, -1.85895694]), 'currentState': array([1.63661992, 3.48407116]), 'targetState': array([0.28132854, 0.02347865]), 'effectorPosition': array([0.3312755 , 0.08003811])}
episode index:1552
target Thresh 1.9192351421043956
current state at start:  [-2.2014188  -1.68198284]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.2014188 , -1.68198284]), 'currentState': array([3.58176651, 4.45447843]), 'targetState': array([-1.25507412,  0.31784397]), 'effectorPosition': array([-1.08593345,  0.55733922])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.9598148272303159
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([-2.2014188 , -1.68198284]), 'currentState': array([3.76272648, 4.7461684 ]), 'targetState': array([-1.25507412,  0.31784397]), 'effectorPosition': array([-1.42230958,  0.21114319])}
episode index:1553
target Thresh 1.9193965103981037
current state at start:  [ 4.07935947 -1.96898179]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.07935947, -1.96898179]), 'currentState': array([3.68994379, 3.82410385]), 'targetState': array([-0.22424368,  0.09607427]), 'effectorPosition': array([-0.51996033,  0.42149585])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9598342514084173
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 4.07935947, -1.96898179]), 'currentState': array([3.93195   , 3.47602351]), 'targetState': array([-0.22424368,  0.09607427]), 'effectorPosition': array([-0.27222382,  0.19157151])}
episode index:1554
target Thresh 1.9195575562777458
current state at start:  [-4.16411163  2.36997549]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.16411163,  2.36997549]), 'currentState': array([2.4445167 , 2.86997549]), 'targetState': array([-0.00497999, -0.53080795]), 'effectorPosition': array([-0.20034556, -0.18216773])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.959853650603653
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-4.16411163,  2.36997549]), 'currentState': array([2.86726122, 2.72706733]), 'targetState': array([-0.00497999, -0.53080795]), 'effectorPosition': array([-0.1906333 , -0.36475161])}
episode index:1555
target Thresh 1.919718280387506
current state at start:  [ 2.91662742 -2.43132002]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.91662742, -2.43132002]), 'currentState': array([3.41487212, 4.33631917]), 'targetState': array([-1.03064   ,  0.90145998]), 'effectorPosition': array([-0.86028155,  0.72483107])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.959879451599409
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.91662742, -2.43132002]), 'currentState': array([3.41487212, 4.33631917]), 'targetState': array([-1.03064   ,  0.90145998]), 'effectorPosition': array([-0.86028155,  0.72483107])}
episode index:1556
target Thresh 1.9198786833702803
current state at start:  [ 3.45540612 -2.25085086]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.45540612, -2.25085086]), 'currentState': array([3.66204531, 3.53904831]), 'targetState': array([0.16615411, 0.00747828]), 'effectorPosition': array([-0.2601112 ,  0.29705978])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9598987968456522
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.45540612, -2.25085086]), 'currentState': array([3.90354776, 3.09622663]), 'targetState': array([0.16615411, 0.00747828]), 'effectorPosition': array([ 0.03056275, -0.03352076])}
episode index:1557
target Thresh 1.9200387658676816
current state at start:  [-3.35166576  2.551285  ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.35166576,  2.551285  ]), 'currentState': array([2.77347804, 2.94815987]), 'targetState': array([-0.09311828, -0.32700437]), 'effectorPosition': array([-0.08657533, -0.17263961])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9599245357436974
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.35166576,  2.551285  ]), 'currentState': array([2.77347804, 2.94815987]), 'targetState': array([-0.09311828, -0.32700437]), 'effectorPosition': array([-0.08657533, -0.17263961])}
episode index:1558
target Thresh 1.9201985285200398
current state at start:  [-0.33126991 -1.78074   ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.33126991, -1.78074   ]), 'currentState': array([5.5814981 , 4.00828882]), 'targetState': array([-0.52803716, -0.39592288]), 'effectorPosition': array([-0.22266271, -0.80976839])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9599374770293011
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-0.33126991, -1.78074   ]), 'currentState': array([4.90295837, 3.77332821]), 'targetState': array([-0.52803716, -0.39592288]), 'effectorPosition': array([-0.54329836, -0.3013624 ])}
episode index:1559
target Thresh 1.9203579719664055
current state at start:  [-0.09520223  2.24282491]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.09520223,  2.24282491]), 'currentState': array([5.97128747, 2.67148369]), 'targetState': array([-0.14981832,  0.15674938]), 'effectorPosition': array([0.24225214, 0.3978392 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9599567478773593
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.09520223,  2.24282491]), 'currentState': array([5.95510449, 3.03799491]), 'targetState': array([-0.14981832,  0.15674938]), 'effectorPosition': array([0.03839777, 0.09616916])}
episode index:1560
target Thresh 1.9205170968445529
current state at start:  [-3.10143352  2.45986553]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.10143352,  2.45986553]), 'currentState': array([2.86001653, 2.88971828]), 'targetState': array([-0.01681124, -0.00809878]), 'effectorPosition': array([-0.09956108, -0.23063739])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9599824001849331
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.10143352,  2.45986553]), 'currentState': array([2.86001653, 2.88971828]), 'targetState': array([-0.01681124, -0.00809878]), 'effectorPosition': array([-0.09956108, -0.23063739])}
episode index:1561
target Thresh 1.9206759037909817
current state at start:  [-1.27099813  2.49137877]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.27099813,  2.49137877]), 'currentState': array([5.49058529, 2.26083384]), 'targetState': array([0.75703861, 0.52884443]), 'effectorPosition': array([0.80437879, 0.28256419])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.960001617598387
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.27099813,  2.49137877]), 'currentState': array([5.93815987, 2.08955663]), 'targetState': array([0.75703861, 0.52884443]), 'effectorPosition': array([0.76820466, 0.64672541])}
episode index:1562
target Thresh 1.92083439344092
current state at start:  [-0.32559487 -2.63593934]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.32559487, -2.63593934]), 'currentState': array([5.45759044, 3.92776405]), 'targetState': array([-0.93582741, -0.63994158]), 'effectorPosition': array([-0.32110311, -0.69553805])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9600144764482921
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-0.32559487, -2.63593934]), 'currentState': array([4.55986608, 4.28387594]), 'targetState': array([-0.93582741, -0.63994158]), 'effectorPosition': array([-0.98782671, -0.43950075])}
episode index:1563
target Thresh 1.9209925664283263
current state at start:  [1.50051446 2.16345701]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.50051446, 2.16345701]), 'currentState': array([1.01844228, 2.36850564]), 'targetState': array([0.04327345, 0.89735349]), 'effectorPosition': array([-0.44535843,  0.60839077])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9600336487779287
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.50051446, 2.16345701]), 'currentState': array([0.55366711, 1.95777369]), 'targetState': array([0.04327345, 0.89735349]), 'effectorPosition': array([0.04266401, 1.11507746])}
episode index:1564
target Thresh 1.9211504233858931
current state at start:  [1.01037924 2.84059677]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.01037924, 2.84059677]), 'currentState': array([1.51037924, 2.34059677]), 'targetState': array([-1.07473796,  0.49740352]), 'effectorPosition': array([-0.69838334,  0.34680943])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9600527966061856
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.01037924, 2.84059677]), 'currentState': array([1.84742074, 1.85764024]), 'targetState': array([-1.07473796,  0.49740352]), 'effectorPosition': array([-1.11851764,  0.42786127])}
episode index:1565
target Thresh 1.9213079649450484
current state at start:  [ 3.05419909 -1.99943631]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.05419909, -1.99943631]), 'currentState': array([2.58341076, 4.42652039]), 'targetState': array([0.24657402, 1.06086043]), 'effectorPosition': array([-0.10087891,  1.19408611])}
done in step count: 76
reward sum = 0.46588077516979337
running average episode reward sum: 0.9597372333741062
{'reset': False, 'endBeforeDone': False, 'stepCount': 77, 'initial state': array([ 3.05419909, -1.99943631]), 'currentState': array([2.15764732, 4.60624293]), 'targetState': array([0.24657402, 1.06086043]), 'effectorPosition': array([0.33292755, 1.29509288])}
episode index:1566
target Thresh 1.9214651917359584
current state at start:  [ 4.10256422 -1.95221533]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.10256422, -1.95221533]), 'currentState': array([3.60256422, 3.85453417]), 'targetState': array([-0.29869891,  0.48269714]), 'effectorPosition': array([-0.50907501,  0.47745177])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.959762927545533
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.10256422, -1.95221533]), 'currentState': array([3.60256422, 3.85453417]), 'targetState': array([-0.29869891,  0.48269714]), 'effectorPosition': array([-0.50907501,  0.47745177])}
episode index:1567
target Thresh 1.9216221043875306
current state at start:  [-0.59361621 -1.97478699]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.59361621, -1.97478699]), 'currentState': array([5.275205  , 4.38753176]), 'targetState': array([-0.18920768, -1.05580095]), 'effectorPosition': array([-0.43825118, -1.08147536])}
done in step count: 18
reward sum = 0.8345137614500875
running average episode reward sum: 0.9596830492508294
{'reset': False, 'endBeforeDone': False, 'stepCount': 19, 'initial state': array([-0.59361621, -1.97478699]), 'currentState': array([5.29519449, 4.3842612 ]), 'targetState': array([-0.18920768, -1.05580095]), 'effectorPosition': array([-0.41737606, -1.08685542])}
episode index:1568
target Thresh 1.921778703527416
current state at start:  [ 0.74235267 -1.95669228]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.74235267, -1.95669228]), 'currentState': array([0.28112743, 3.97550768]), 'targetState': array([ 0.13225574, -1.21882785]), 'effectorPosition': array([ 0.52060389, -0.62049048])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.959696061966412
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 0.74235267, -1.95669228]), 'currentState': array([5.65372823, 4.64117637]), 'targetState': array([ 0.13225574, -1.21882785]), 'effectorPosition': array([ 0.1636175 , -1.35311657])}
episode index:1569
target Thresh 1.9219349897820113
current state at start:  [2.28173382 1.62719054]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.28173382, 1.62719054]), 'currentState': array([2.78173382, 2.10402573]), 'targetState': array([-0.82946116, -0.77530611]), 'effectorPosition': array([-0.76344318, -0.63286682])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9597217332645226
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.28173382, 1.62719054]), 'currentState': array([2.78173382, 2.10402573]), 'targetState': array([-0.82946116, -0.77530611]), 'effectorPosition': array([-0.76344318, -0.63286682])}
episode index:1570
target Thresh 1.9220909637764614
current state at start:  [ 2.61731309 -3.07511795]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.61731309, -3.07511795]), 'currentState': array([3.11112243, 2.80330748]), 'targetState': array([-0.50785635, -0.32636284]), 'effectorPosition': array([-0.06675913, -0.32998927])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9597284660886699
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 2.61731309, -3.07511795]), 'currentState': array([2.858676  , 2.47903146]), 'targetState': array([-0.50785635, -0.32636284]), 'effectorPosition': array([-0.3748898, -0.5316192])}
episode index:1571
target Thresh 1.9222466261346627
current state at start:  [ 3.55864582 -1.82455295]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.55864582, -1.82455295]), 'currentState': array([4.05864582, 4.47621351]), 'targetState': array([-1.03087761, -0.25769646]), 'effectorPosition': array([-1.23763728, -0.01679238])}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.9596990696391757
{'reset': False, 'endBeforeDone': False, 'stepCount': 10, 'initial state': array([ 3.55864582, -1.82455295]), 'currentState': array([4.5126074 , 4.40854534]), 'targetState': array([-1.03087761, -0.25769646]), 'effectorPosition': array([-1.07429404, -0.49750613])}
episode index:1572
target Thresh 1.9224019774792651
current state at start:  [ 4.25803382 -2.71412784]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.25803382, -2.71412784]), 'currentState': array([4.18691147, 3.86631585]), 'targetState': array([-0.57828321,  0.43624675]), 'effectorPosition': array([-0.69955614,  0.11513165])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9597183327862583
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 4.25803382, -2.71412784]), 'currentState': array([3.82321552, 3.83672154]), 'targetState': array([-0.57828321,  0.43624675]), 'effectorPosition': array([-0.58372212,  0.35117826])}
episode index:1573
target Thresh 1.9225570184316738
current state at start:  [1.9410633  2.38788822]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.9410633 , 2.38788822]), 'currentState': array([2.0755023 , 2.84004995]), 'targetState': array([ 0.0528426 , -0.43573679]), 'effectorPosition': array([-0.28178155, -0.10411654])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9597250549382366
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([1.9410633 , 2.38788822]), 'currentState': array([3.07897769, 2.81145472]), 'targetState': array([ 0.0528426 , -0.43573679]), 'effectorPosition': array([-0.07418138, -0.32015909])}
episode index:1574
target Thresh 1.9227117496120532
current state at start:  [ 2.41732935 -2.54187244]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.41732935, -2.54187244]), 'currentState': array([2.87471504, 3.24131287]), 'targetState': array([-0.46179248,  0.2171809 ]), 'effectorPosition': array([0.02146267, 0.09734083])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9597317685541488
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 2.41732935, -2.54187244]), 'currentState': array([4.02194236, 3.64150742]), 'targetState': array([-0.46179248,  0.2171809 ]), 'effectorPosition': array([-0.44750042,  0.210942  ])}
episode index:1575
target Thresh 1.9228661716393276
current state at start:  [ 2.91210291 -2.23575986]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.91210291, -2.23575986]), 'currentState': array([3.29742554, 3.54742544]), 'targetState': array([-0.11539233,  0.08491309]), 'effectorPosition': array([-0.14151345,  0.37739377])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9597509742847616
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 2.91210291, -2.23575986]), 'currentState': array([3.69868645, 3.05624949]), 'targetState': array([-0.11539233,  0.08491309]), 'effectorPosition': array([ 0.04197882, -0.07427526])}
episode index:1576
target Thresh 1.923020285131186
current state at start:  [ 1.34560808 -2.06578757]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.34560808, -2.06578757]), 'currentState': array([1.7995302 , 3.71739774]), 'targetState': array([0.52241719, 0.56880945]), 'effectorPosition': array([0.49376646, 0.28051077])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9597701556580751
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.34560808, -2.06578757]), 'currentState': array([1.70852841, 4.00136452]), 'targetState': array([0.52241719, 0.56880945]), 'effectorPosition': array([0.70282271, 0.44812894])}
episode index:1577
target Thresh 1.9231740907040822
current state at start:  [ 0.423412 -2.012325]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.423412, -2.012325]), 'currentState': array([0.38054252, 3.77086031]), 'targetState': array([ 0.2417314 , -0.47992631]), 'effectorPosition': array([ 0.3964418 , -0.47530664])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9597956498560104
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.423412, -2.012325]), 'currentState': array([0.38054252, 3.77086031]), 'targetState': array([ 0.2417314 , -0.47992631]), 'effectorPosition': array([ 0.3964418 , -0.47530664])}
episode index:1578
target Thresh 1.9233275889732389
current state at start:  [-4.05105501  1.97602794]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.05105501,  1.97602794]), 'currentState': array([1.74192453, 2.29507873]), 'targetState': array([-0.63651509, -0.03859404]), 'effectorPosition': array([-0.79549259,  0.20492741])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9598085088491352
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-4.05105501,  1.97602794]), 'currentState': array([1.66957156, 2.45788758]), 'targetState': array([-0.63651509, -0.03859404]), 'effectorPosition': array([-0.65075558,  0.16137487])}
episode index:1579
target Thresh 1.923480780552649
current state at start:  [ 1.72163218 -2.09629503]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.72163218, -2.09629503]), 'currentState': array([1.22163218, 3.73262046]), 'targetState': array([0.91298127, 0.10732604]), 'effectorPosition': array([ 0.58162496, -0.0312343 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9598276173878382
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.72163218, -2.09629503]), 'currentState': array([0.95434165, 4.08813379]), 'targetState': array([0.91298127, 0.10732604]), 'effectorPosition': array([ 0.90227087, -0.13008103])}
episode index:1580
target Thresh 1.9236336660550795
current state at start:  [-2.09119888  2.88307793]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.09119888,  2.88307793]), 'currentState': array([3.70248236, 2.61631507]), 'targetState': array([-0.19099714, -0.47079486]), 'effectorPosition': array([ 0.15258378, -0.4963352 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9598467017538168
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.09119888,  2.88307793]), 'currentState': array([3.2865554 , 2.55643646]), 'targetState': array([-0.19099714, -0.47079486]), 'effectorPosition': array([-0.08484204, -0.57057005])}
episode index:1581
target Thresh 1.9237862460920723
current state at start:  [-1.60504773  2.33371559]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.60504773,  2.33371559]), 'currentState': array([4.17813758, 1.86440131]), 'targetState': array([ 0.39849842, -1.04372421]), 'effectorPosition': array([ 0.46198721, -1.09898052])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9598720831054263
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.60504773,  2.33371559]), 'currentState': array([4.17813758, 1.86440131]), 'targetState': array([ 0.39849842, -1.04372421]), 'effectorPosition': array([ 0.46198721, -1.09898052])}
episode index:1582
target Thresh 1.923938521273948
current state at start:  [-2.97988413  2.2041539 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.97988413,  2.2041539 ]), 'currentState': array([2.89250814, 2.59261728]), 'targetState': array([-0.40581456, -0.42170984]), 'effectorPosition': array([-0.27104137, -0.46948622])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9598974323896301
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.97988413,  2.2041539 ]), 'currentState': array([2.89250814, 2.59261728]), 'targetState': array([-0.40581456, -0.42170984]), 'effectorPosition': array([-0.27104137, -0.46948622])}
episode index:1583
target Thresh 1.9240904922098072
current state at start:  [ 2.03334574 -2.18340972]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.03334574, -2.18340972]), 'currentState': array([1.62568588, 3.59977559]), 'targetState': array([ 0.71706195, -0.0737028 ]), 'effectorPosition': array([0.43599444, 0.12725347])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9599164365358487
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 2.03334574, -2.18340972]), 'currentState': array([1.24650673, 3.899241  ]), 'targetState': array([ 0.71706195, -0.0737028 ]), 'effectorPosition': array([0.73855693, 0.04031687])}
episode index:1584
target Thresh 1.924242159507534
current state at start:  [-1.72578625  2.03717093]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.72578625,  2.03717093]), 'currentState': array([4.38296416, 2.50521569]), 'targetState': array([-0.00253387, -0.0549831 ]), 'effectorPosition': array([ 0.49900637, -0.37747098])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9599354167020722
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.72578625,  2.03717093]), 'currentState': array([4.10868885, 2.92417543]), 'targetState': array([-0.00253387, -0.0549831 ]), 'effectorPosition': array([ 0.16421521, -0.14183689])}
episode index:1585
target Thresh 1.924393523773798
current state at start:  [1.98453806 2.01170478]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.98453806, 2.01170478]), 'currentState': array([1.96921244, 2.16807592]), 'targetState': array([-1.00113308, -0.07373786]), 'effectorPosition': array([-0.93187822,  0.08253906])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9599606781038994
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.98453806, 2.01170478]), 'currentState': array([1.96921244, 2.16807592]), 'targetState': array([-1.00113308, -0.07373786]), 'effectorPosition': array([-0.93187822,  0.08253906])}
episode index:1586
target Thresh 1.9245445856140562
current state at start:  [-2.00345156 -1.78905037]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.00345156, -1.78905037]), 'currentState': array([4.67449817, 4.87806732]), 'targetState': array([-1.1998795 , -0.65286005]), 'effectorPosition': array([-1.02972803, -1.12672225])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9599796064730841
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.00345156, -1.78905037]), 'currentState': array([4.35109171, 4.53335816]), 'targetState': array([-1.1998795 , -0.65286005]), 'effectorPosition': array([-1.211028  , -0.42102167])}
episode index:1587
target Thresh 1.9246953456325562
current state at start:  [-0.30210853 -1.6349874 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.30210853, -1.6349874 ]), 'currentState': array([5.61420682, 4.26198523]), 'targetState': array([-0.04917909, -0.85420614]), 'effectorPosition': array([-0.11537552, -1.05642339])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.960004808232232
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.30210853, -1.6349874 ]), 'currentState': array([5.61420682, 4.26198523]), 'targetState': array([-0.04917909, -0.85420614]), 'effectorPosition': array([-0.11537552, -1.05642339])}
episode index:1588
target Thresh 1.9248458044323384
current state at start:  [ 1.43155909 -2.13702164]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.43155909, -2.13702164]), 'currentState': array([0.97186062, 3.70184081]), 'targetState': array([ 0.73077808, -0.33418528]), 'effectorPosition': array([ 0.52508585, -0.17331564])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.960023685004899
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.43155909, -2.13702164]), 'currentState': array([0.7942001 , 3.92137901]), 'targetState': array([ 0.73077808, -0.33418528]), 'effectorPosition': array([ 0.70404568, -0.28669169])}
episode index:1589
target Thresh 1.9249959626152382
current state at start:  [-2.38170665  2.2406125 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.38170665,  2.2406125 ]), 'currentState': array([3.5528499 , 2.69857612]), 'targetState': array([-0.41836682, -0.08621551]), 'effectorPosition': array([ 0.08287677, -0.43151601])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.9600180034733864
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([-2.38170665,  2.2406125 ]), 'currentState': array([4.1796658, 3.5936491]), 'targetState': array([-0.41836682, -0.08621551]), 'effectorPosition': array([-0.42730176,  0.13532099])}
episode index:1590
target Thresh 1.9251458207818883
current state at start:  [1.15112514 1.98403546]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.15112514, 1.98403546]), 'currentState': array([0.65112514, 2.42095494]), 'targetState': array([0.04426461, 0.3852582 ]), 'effectorPosition': array([-0.2021826 ,  0.67553833])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9600368482229317
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.15112514, 1.98403546]), 'currentState': array([0.19964365, 2.71950838]), 'targetState': array([0.04426461, 0.3852582 ]), 'effectorPosition': array([0.00477538, 0.41893084])}
episode index:1591
target Thresh 1.9252953795317218
current state at start:  [1.77482488 2.4035172 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.77482488, 2.4035172 ]), 'currentState': array([1.28856125, 2.809447  ]), 'targetState': array([0.16693775, 0.78433742]), 'effectorPosition': array([-0.29794962,  0.14330478])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9600494507052038
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([1.77482488, 2.4035172 ]), 'currentState': array([0.28856125, 2.17717942]), 'targetState': array([0.16693775, 0.78433742]), 'effectorPosition': array([0.17848003, 0.91013549])}
episode index:1592
target Thresh 1.9254446394629738
current state at start:  [-3.01861744  2.14961161]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.01861744,  2.14961161]), 'currentState': array([3.70827905, 1.8597735 ]), 'targetState': array([-0.30615459, -1.12409395]), 'effectorPosition': array([-0.08867828, -1.19255702])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9600745295183204
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.01861744,  2.14961161]), 'currentState': array([3.70827905, 1.8597735 ]), 'targetState': array([-0.30615459, -1.12409395]), 'effectorPosition': array([-0.08867828, -1.19255702])}
episode index:1593
target Thresh 1.9255936011726842
current state at start:  [-1.79701454  1.83734905]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.79701454,  1.83734905]), 'currentState': array([4.30324663, 1.9352265 ]), 'targetState': array([ 0.62469615, -0.81846727]), 'effectorPosition': array([ 0.60117797, -0.96215963])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9600995768649212
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.79701454,  1.83734905]), 'currentState': array([4.30324663, 1.9352265 ]), 'targetState': array([ 0.62469615, -0.81846727]), 'effectorPosition': array([ 0.60117797, -0.96215963])}
episode index:1594
target Thresh 1.9257422652567002
current state at start:  [-0.66086396  2.87601425]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.66086396,  2.87601425]), 'currentState': array([5.22818524, 3.32985209]), 'targetState': array([-0.40715816, -0.11073713]), 'effectorPosition': array([-0.15408668, -0.10767711])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9601183232117143
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.66086396,  2.87601425]), 'currentState': array([4.96374846, 3.52103552]), 'targetState': array([-0.40715816, -0.11073713]), 'effectorPosition': array([-0.34107194, -0.16102064])}
episode index:1595
target Thresh 1.925890632309678
current state at start:  [-1.4256528  -1.77341405]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.4256528 , -1.77341405]), 'currentState': array([5.19822303, 4.00977125]), 'targetState': array([-0.00289984,  0.00095178]), 'effectorPosition': array([-0.50964824, -0.6691961 ])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9601308430593261
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.4256528 , -1.77341405]), 'currentState': array([5.90087572, 3.11771622]), 'targetState': array([-0.00289984,  0.00095178]), 'effectorPosition': array([0.00917105, 0.02204425])}
episode index:1596
target Thresh 1.9260387029250865
current state at start:  [1.86536034 1.58038396]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.86536034, 1.58038396]), 'currentState': array([1.40160393, 2.02396757]), 'targetState': array([-0.31297407,  0.13300381]), 'effectorPosition': array([-0.79156192,  0.70554374])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9601433472277298
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([1.86536034, 1.58038396]), 'currentState': array([0.84825704, 2.93521056]), 'targetState': array([-0.31297407,  0.13300381]), 'effectorPosition': array([-0.13968305,  0.15143066])}
episode index:1597
target Thresh 1.9261864776952078
current state at start:  [1.38479789 1.81797878]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.38479789, 1.81797878]), 'currentState': array([0.88479789, 2.31797878]), 'targetState': array([-0.07550288,  0.17432039]), 'effectorPosition': array([-0.36468294,  0.71264112])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9601620309904157
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.38479789, 1.81797878]), 'currentState': array([0.38479789, 2.81611545]), 'targetState': array([-0.07550288,  0.17432039]), 'effectorPosition': array([-0.07136673,  0.31608591])}
episode index:1598
target Thresh 1.9263339572111418
current state at start:  [ 3.98912415 -2.07586763]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.98912415, -2.07586763]), 'currentState': array([3.49065733, 3.83178514]), 'targetState': array([-0.26873234,  0.61885192]), 'effectorPosition': array([-0.43283228,  0.52000891])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9601869452924855
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.98912415, -2.07586763]), 'currentState': array([3.49065733, 3.83178514]), 'targetState': array([-0.26873234,  0.61885192]), 'effectorPosition': array([-0.43283228,  0.52000891])}
episode index:1599
target Thresh 1.926481142062806
current state at start:  [-1.15127087  2.25794163]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.15127087,  2.25794163]), 'currentState': array([4.67114791, 2.56081364]), 'targetState': array([ 0.3628844, -0.1730523]), 'effectorPosition': array([ 0.5414487 , -0.18644665])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9602118284516777
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.15127087,  2.25794163]), 'currentState': array([4.67114791, 2.56081364]), 'targetState': array([ 0.3628844, -0.1730523]), 'effectorPosition': array([ 0.5414487 , -0.18644665])}
episode index:1600
target Thresh 1.926628032838941
current state at start:  [ 0.86826068 -2.96445121]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.86826068, -2.96445121]), 'currentState': array([0.60169303, 3.56745062]), 'targetState': array([ 0.34289924, -0.17231576]), 'effectorPosition': array([ 0.30746165, -0.28999664])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9602366805263487
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.86826068, -2.96445121]), 'currentState': array([0.60169303, 3.56745062]), 'targetState': array([ 0.34289924, -0.17231576]), 'effectorPosition': array([ 0.30746165, -0.28999664])}
episode index:1601
target Thresh 1.926774630127109
current state at start:  [1.16085191 2.10453082]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.16085191, 2.10453082]), 'currentState': array([1.66085191, 2.13068876]), 'targetState': array([-1.19946274,  0.46685878]), 'effectorPosition': array([-0.88604917,  0.39080271])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9602552593774559
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.16085191, 2.10453082]), 'currentState': array([1.82320514, 1.77573717]), 'targetState': array([-1.19946274,  0.46685878]), 'effectorPosition': array([-1.14696313,  0.52674195])}
episode index:1602
target Thresh 1.9269209345137002
current state at start:  [ 1.26410721 -2.43333042]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.26410721, -2.43333042]), 'currentState': array([1.759829  , 3.34985489]), 'targetState': array([0.11109199, 0.34711839]), 'effectorPosition': array([0.19901648, 0.06007543])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9602676391283121
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 1.26410721, -2.43333042]), 'currentState': array([2.04102226, 3.37192768]), 'targetState': array([0.11109199, 0.34711839]), 'effectorPosition': array([0.19155892, 0.12698526])}
episode index:1603
target Thresh 1.9270669465839319
current state at start:  [ 0.31579434 -2.07982593]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.31579434, -2.07982593]), 'currentState': array([0.81579434, 3.76393349]), 'targetState': array([ 0.61004317, -0.14680519]), 'effectorPosition': array([ 0.55301774, -0.26294322])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9602924099268606
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.31579434, -2.07982593]), 'currentState': array([0.81579434, 3.76393349]), 'targetState': array([ 0.61004317, -0.14680519]), 'effectorPosition': array([ 0.55301774, -0.26294322])}
episode index:1604
target Thresh 1.9272126669218526
current state at start:  [ 3.78725102 -2.49310022]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.78725102, -2.49310022]), 'currentState': array([3.92361919, 4.0432562 ]), 'targetState': array([-0.60090328,  0.49722434]), 'effectorPosition': array([-0.82214096,  0.2889156 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9603109193287753
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.78725102, -2.49310022]), 'currentState': array([3.58232666, 4.05442126]), 'targetState': array([-0.60090328,  0.49722434]), 'effectorPosition': array([-0.6889096 ,  0.54989395])}
episode index:1605
target Thresh 1.927358096110344
current state at start:  [-3.29111564  2.15555229]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.29111564,  2.15555229]), 'currentState': array([3.49206967, 2.25468809]), 'targetState': array([ 0.1670026 , -1.34510926]), 'effectorPosition': array([-0.07966911, -0.85441446])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9603294056803763
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.29111564,  2.15555229]), 'currentState': array([3.99206967, 1.78272063]), 'targetState': array([ 0.1670026 , -1.34510926]), 'effectorPosition': array([ 0.2139022 , -1.23837102])}
episode index:1606
target Thresh 1.927503234731123
current state at start:  [ 0.44134402 -2.31694436]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.44134402, -2.31694436]), 'currentState': array([0.4388063 , 3.53480656]), 'targetState': array([-0.0805764 , -0.37162483]), 'effectorPosition': array([ 0.23187585, -0.31443409])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9603478690246947
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.44134402, -2.31694436]), 'currentState': array([0.28114871, 3.4845963 ]), 'targetState': array([-0.0805764 , -0.37162483]), 'effectorPosition': array([ 0.14927857, -0.30695022])}
episode index:1607
target Thresh 1.9276480833647442
current state at start:  [2.13594019 1.93631887]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.13594019, 1.93631887]), 'currentState': array([1.63594019, 1.84878379]), 'targetState': array([-1.17485019,  0.41600911]), 'effectorPosition': array([-1.00680358,  0.66144137])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9603663094046545
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([2.13594019, 1.93631887]), 'currentState': array([1.91732614, 1.75840356]), 'targetState': array([-1.17485019,  0.41600911]), 'effectorPosition': array([-1.20034423,  0.43145849])}
episode index:1608
target Thresh 1.9277926425906025
current state at start:  [-1.12953524  1.64505618]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.12953524,  1.64505618]), 'currentState': array([4.65365006, 2.02474224]), 'targetState': array([ 0.35169412, -1.0094554 ]), 'effectorPosition': array([ 0.86421175, -0.61327613])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.960384726863073
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.12953524,  1.64505618]), 'currentState': array([4.15365006, 1.93544373]), 'targetState': array([ 0.35169412, -1.0094554 ]), 'effectorPosition': array([ 0.45110598, -1.04079949])}
episode index:1609
target Thresh 1.9279369129869348
current state at start:  [-0.67636496  2.09896304]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.67636496,  2.09896304]), 'currentState': array([5.10682034, 2.00743683]), 'targetState': array([ 1.03072482, -0.5323872 ]), 'effectorPosition': array([ 1.05836769, -0.18456091])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9603969723743381
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-0.67636496,  2.09896304]), 'currentState': array([4.97161743, 1.94309745]), 'targetState': array([ 1.03072482, -0.5323872 ]), 'effectorPosition': array([ 1.06346028, -0.37620803])}
episode index:1610
target Thresh 1.928080895130823
current state at start:  [-0.82637965  2.14914433]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.82637965,  2.14914433]), 'currentState': array([4.95680566, 2.58191294]), 'targetState': array([ 0.03663335, -0.49793284]), 'effectorPosition': array([ 0.55205693, -0.01956379])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9604092026832305
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-0.82637965,  2.14914433]), 'currentState': array([3.95680566, 2.62408512]), 'targetState': array([ 0.03663335, -0.49793284]), 'effectorPosition': array([ 0.27029868, -0.43454429])}
episode index:1611
target Thresh 1.9282245895981958
current state at start:  [ 3.97789441 -2.74726286]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.97789441, -2.74726286]), 'currentState': array([3.47789441, 3.80434317]), 'targetState': array([0.42261851, 1.14514154]), 'effectorPosition': array([-0.40288199,  0.51096027])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9604153377932285
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 3.97789441, -2.74726286]), 'currentState': array([1.97789441, 4.67532922]), 'targetState': array([0.42261851, 1.14514154]), 'effectorPosition': array([0.53636724, 1.27992485])}
episode index:1612
target Thresh 1.9283679969638314
current state at start:  [1.79276484 1.99322219]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.79276484, 1.99322219]), 'currentState': array([1.30558693, 2.49322219]), 'targetState': array([-0.15361136,  0.04183667]), 'effectorPosition': array([-0.52958445,  0.35412213])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9604336791833133
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.79276484, 1.99322219]), 'currentState': array([0.81090092, 2.91210828]), 'targetState': array([-0.15361136,  0.04183667]), 'effectorPosition': array([-0.14683988,  0.17569979])}
episode index:1613
target Thresh 1.9285111178013592
current state at start:  [ 3.37475946 -1.74202174]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.37475946, -1.74202174]), 'currentState': array([3.32302655, 4.06115658]), 'targetState': array([-0.14488533,  0.12133008]), 'effectorPosition': array([-0.53087934,  0.7112194 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9604519978455294
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.37475946, -1.74202174]), 'currentState': array([3.65234883, 3.57814799]), 'targetState': array([-0.14488533,  0.12133008]), 'effectorPosition': array([-0.28850726,  0.32301166])}
episode index:1614
target Thresh 1.928653952683263
current state at start:  [-1.86969034  2.099758  ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.86969034,  2.099758  ]), 'currentState': array([4.13018208, 2.38240064]), 'targetState': array([ 0.39385574, -0.428164  ]), 'effectorPosition': array([ 0.42393501, -0.60786042])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9604764857725601
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.86969034,  2.099758  ]), 'currentState': array([4.13018208, 2.38240064]), 'targetState': array([ 0.39385574, -0.428164  ]), 'effectorPosition': array([ 0.42393501, -0.60786042])}
episode index:1615
target Thresh 1.9287965021808824
current state at start:  [ 2.40701549 -2.54301156]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.40701549, -2.54301156]), 'currentState': array([2.47358413, 3.2660914 ]), 'targetState': array([-0.01208259,  0.17949538]), 'effectorPosition': array([0.07084211, 0.10228061])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9605009433927503
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.40701549, -2.54301156]), 'currentState': array([2.47358413, 3.2660914 ]), 'targetState': array([-0.01208259,  0.17949538]), 'effectorPosition': array([0.07084211, 0.10228061])}
episode index:1616
target Thresh 1.9289387668644156
current state at start:  [0.86766042 2.77234043]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.86766042, 2.77234043]), 'currentState': array([1.32917958, 3.27234043]), 'targetState': array([-0.50545456, -0.67346088]), 'effectorPosition': array([ 0.12863074, -0.02290793])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9605070027969601
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([0.86766042, 2.77234043]), 'currentState': array([2.8175117 , 2.35886974]), 'targetState': array([-0.50545456, -0.67346088]), 'effectorPosition': array([-0.50042177, -0.5758352 ])}
episode index:1617
target Thresh 1.9290807473029212
current state at start:  [-0.80076734 -1.58990426]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.80076734, -1.58990426]), 'currentState': array([5.19815046, 4.61901887]), 'targetState': array([-0.16386049, -1.17054726]), 'effectorPosition': array([-0.45711536, -1.26671881])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9605191121895454
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-0.80076734, -1.58990426]), 'currentState': array([5.31682172, 4.52412299]), 'targetState': array([-0.16386049, -1.17054726]), 'effectorPosition': array([-0.34634986, -1.22708197])}
episode index:1618
target Thresh 1.9292224440643218
current state at start:  [-0.84708085 -2.85197677]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.84708085, -2.85197677]), 'currentState': array([5.55810787, 3.77625879]), 'targetState': array([ 0.01274612, -0.50732168]), 'effectorPosition': array([-0.24746761, -0.57290522])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9605373215087613
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.84708085, -2.85197677]), 'currentState': array([5.87467205, 3.8915725 ]), 'targetState': array([ 0.01274612, -0.50732168]), 'effectorPosition': array([-0.02455213, -0.73211473])}
episode index:1619
target Thresh 1.9293638577154042
current state at start:  [1.79015982 2.08905572]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.79015982, 2.08905572]), 'currentState': array([1.37658331, 2.55047015]), 'targetState': array([-0.32482934,  0.05570451]), 'effectorPosition': array([-0.51406808,  0.27404878])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9605555083473362
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.79015982, 2.08905572]), 'currentState': array([1.07869494, 2.80033324]), 'targetState': array([-0.32482934,  0.05570451]), 'effectorPosition': array([-0.26771635,  0.20895003])}
episode index:1620
target Thresh 1.9295049888218232
current state at start:  [-3.26457828  2.36880278]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.26457828,  2.36880278]), 'currentState': array([2.89870068, 2.67318985]), 'targetState': array([-0.22018759, -0.53093748]), 'effectorPosition': array([-0.21312923, -0.41230443])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9605798417783372
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.26457828,  2.36880278]), 'currentState': array([2.89870068, 2.67318985]), 'targetState': array([-0.22018759, -0.53093748]), 'effectorPosition': array([-0.21312923, -0.41230443])}
episode index:1621
target Thresh 1.9296458379481036
current state at start:  [ 3.57878768 -2.89657282]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.57878768, -2.89657282]), 'currentState': array([3.2997142 , 3.88661249]), 'targetState': array([-0.1854135 ,  1.10441458]), 'effectorPosition': array([-0.36837864,  0.62781229])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9605979799769941
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.57878768, -2.89657282]), 'currentState': array([2.88677078, 4.36027215]), 'targetState': array([-0.1854135 ,  1.10441458]), 'effectorPosition': array([-0.39735262,  1.07347093])}
episode index:1622
target Thresh 1.929786405657642
current state at start:  [-2.98052861  2.56627643]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.98052861,  2.56627643]), 'currentState': array([3.8026567 , 2.15763322]), 'targetState': array([ 0.58225033, -0.92737081]), 'effectorPosition': array([ 0.15898124, -0.93127074])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9606160958242049
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.98052861,  2.56627643]), 'currentState': array([4.30062621, 1.84735426]), 'targetState': array([ 0.58225033, -0.92737081]), 'effectorPosition': array([ 0.59064836, -1.05121002])}
episode index:1623
target Thresh 1.9299266925127094
current state at start:  [-2.28866573  2.13454617]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.28866573,  2.13454617]), 'currentState': array([3.95997118, 2.54376347]), 'targetState': array([ 0.12371683, -0.21898134]), 'effectorPosition': array([ 0.29237158, -0.51127298])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.960634189361259
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.28866573,  2.13454617]), 'currentState': array([3.7797044 , 2.79470027]), 'targetState': array([ 0.12371683, -0.21898134]), 'effectorPosition': array([ 0.1546725 , -0.30855936])}
episode index:1624
target Thresh 1.9300666990744533
current state at start:  [-1.25738594  2.35109398]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.25738594,  2.35109398]), 'currentState': array([4.56025732, 2.64097411]), 'targetState': array([ 0.11980435, -0.06119491]), 'effectorPosition': array([ 0.455828  , -0.19403388])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9606461683216521
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.25738594,  2.35109398]), 'currentState': array([3.99394241, 2.85883482]), 'targetState': array([ 0.11980435, -0.06119491]), 'effectorPosition': array([ 0.18390512, -0.21354069])}
episode index:1625
target Thresh 1.9302064259029004
current state at start:  [0.78620307 1.61818801]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.78620307, 1.61818801]), 'currentState': array([1.27322291, 2.03303709]), 'targetState': array([-0.52371957,  0.47834692]), 'effectorPosition': array([-0.6932718,  0.7921266])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9606642211086621
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.78620307, 1.61818801]), 'currentState': array([0.94532867, 2.32432591]), 'targetState': array([-0.52371957,  0.47834692]), 'effectorPosition': array([-0.40633481,  0.68297723])}
episode index:1626
target Thresh 1.9303458735569579
current state at start:  [-0.12670317  2.21751525]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.12670317,  2.21751525]), 'currentState': array([0.2363602 , 2.61886184]), 'targetState': array([-0.33842683,  0.34908869]), 'effectorPosition': array([0.01292134, 0.51663809])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9606761668854853
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-0.12670317,  2.21751525]), 'currentState': array([0.9288525 , 2.59080787]), 'targetState': array([-0.33842683,  0.34908869]), 'effectorPosition': array([-0.33062618,  0.43180806])}
episode index:1627
target Thresh 1.930485042594417
current state at start:  [1.25249917 2.40229052]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.25249917, 2.40229052]), 'currentState': array([0.75249917, 2.85855168]), 'targetState': array([-0.04142576,  0.01153984]), 'effectorPosition': array([-0.16183048,  0.23106208])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.960694179067988
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.25249917, 2.40229052]), 'currentState': array([0.33642353, 3.22044092]), 'targetState': array([-0.04142576,  0.01153984]), 'effectorPosition': array([ 0.02893464, -0.07332541])}
episode index:1628
target Thresh 1.9306239335719535
current state at start:  [-1.7569504   2.71768545]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.7569504 ,  2.71768545]), 'currentState': array([4.13049622, 2.21966293]), 'targetState': array([ 0.62048686, -0.88893453]), 'effectorPosition': array([ 0.44815191, -0.76850009])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9607183078715068
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.7569504 ,  2.71768545]), 'currentState': array([4.13049622, 2.21966293]), 'targetState': array([ 0.62048686, -0.88893453]), 'effectorPosition': array([ 0.44815191, -0.76850009])}
episode index:1629
target Thresh 1.930762547045132
current state at start:  [-3.85018537  2.1684158 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.85018537,  2.1684158 ]), 'currentState': array([2.0357551 , 2.66472362]), 'targetState': array([-0.10376507, -0.24399215]), 'effectorPosition': array([-0.46029593, -0.10608902])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9607362720998065
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.85018537,  2.1684158 ]), 'currentState': array([2.01960435, 3.04627629]), 'targetState': array([-0.10376507, -0.24399215]), 'effectorPosition': array([-0.08771624, -0.03720478])}
episode index:1630
target Thresh 1.9309008835684063
current state at start:  [0.43942012 1.95690595]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.43942012, 1.95690595]), 'currentState': array([0.28754589, 1.7843006 ]), 'targetState': array([0.24868476, 0.9606443 ]), 'effectorPosition': array([0.47859587, 1.16067833])}
done in step count: 43
reward sum = 0.6491026283684022
running average episode reward sum: 0.9605452030355934
{'reset': False, 'endBeforeDone': False, 'stepCount': 44, 'initial state': array([0.43942012, 1.95690595]), 'currentState': array([0.48645914, 2.05414219]), 'targetState': array([0.24868476, 0.9606443 ]), 'effectorPosition': array([0.05921828, 1.0329591 ])}
episode index:1631
target Thresh 1.9310389436951227
current state at start:  [-3.20458946  2.08800571]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.20458946,  2.08800571]), 'currentState': array([2.57859585, 2.52493545]), 'targetState': array([-0.5565115 , -0.20170015]), 'effectorPosition': array([-0.46441474, -0.39075129])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9605693787690276
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.20458946,  2.08800571]), 'currentState': array([2.57859585, 2.52493545]), 'targetState': array([-0.5565115 , -0.20170015]), 'effectorPosition': array([-0.46441474, -0.39075129])}
episode index:1632
target Thresh 1.931176727977522
current state at start:  [-3.21523896  2.19149702]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.21523896,  2.19149702]), 'currentState': array([2.56794635, 2.67005469]), 'targetState': array([-0.27182068, -0.36129399]), 'effectorPosition': array([-0.33818518, -0.32231872])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.96059352489348
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.21523896,  2.19149702]), 'currentState': array([2.56794635, 2.67005469]), 'targetState': array([-0.27182068, -0.36129399]), 'effectorPosition': array([-0.33818518, -0.32231872])}
episode index:1633
target Thresh 1.9313142369667413
current state at start:  [-1.95717349  2.31320314]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.95717349,  2.31320314]), 'currentState': array([3.82601182, 2.80047168]), 'targetState': array([-0.22576145, -0.11603417]), 'effectorPosition': array([ 0.16686324, -0.29562844])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9605935264143531
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([-1.95717349,  2.31320314]), 'currentState': array([3.83911777, 3.16816839]), 'targetState': array([-0.22576145, -0.11603417]), 'effectorPosition': array([-0.01733883,  0.02013934])}
episode index:1634
target Thresh 1.931451471212817
current state at start:  [-1.43690946  2.84331641]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.43690946,  2.84331641]), 'currentState': array([5.00040093, 2.38900644]), 'targetState': array([ 0.90441971, -0.59147571]), 'effectorPosition': array([ 0.73208886, -0.06479808])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9606115120251089
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.43690946,  2.84331641]), 'currentState': array([4.54411927, 2.00111064]), 'targetState': array([ 0.90441971, -0.59147571]), 'effectorPosition': array([ 0.79838558, -0.72682013])}
episode index:1635
target Thresh 1.9315884312646863
current state at start:  [ 0.73189012 -2.69103761]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.73189012, -2.69103761]), 'currentState': array([1.04224685, 3.75810795]), 'targetState': array([0.83171711, 0.62501709]), 'effectorPosition': array([ 0.59213371, -0.13259405])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9606294756485654
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.73189012, -2.69103761]), 'currentState': array([1.44619927, 4.22706657]), 'targetState': array([0.83171711, 0.62501709]), 'effectorPosition': array([0.94396907, 0.41944637])}
episode index:1636
target Thresh 1.9317251176701893
current state at start:  [-3.32882149  2.30871266]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.32882149,  2.30871266]), 'currentState': array([2.45436382, 2.44647118]), 'targetState': array([-1.31394287,  0.01370631]), 'effectorPosition': array([-0.58567435, -0.34789904])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9606353825052248
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-3.32882149,  2.30871266]), 'currentState': array([2.2409396 , 1.71038412]), 'targetState': array([-1.31394287,  0.01370631]), 'effectorPosition': array([-1.31079148,  0.05963098])}
episode index:1637
target Thresh 1.9318615309760718
current state at start:  [-0.10014473 -2.06394972]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.10014473, -2.06394972]), 'currentState': array([0.26199321, 3.80976434]), 'targetState': array([ 0.63106709, -0.35670309]), 'effectorPosition': array([ 0.36817385, -0.54271225])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9606533096221326
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.10014473, -2.06394972]), 'currentState': array([0.53359706, 3.82534394]), 'targetState': array([ 0.63106709, -0.35670309]), 'effectorPosition': array([ 0.51484836, -0.42955119])}
episode index:1638
target Thresh 1.9319976717279876
current state at start:  [ 2.56300056 -2.35044284]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.56300056, -2.35044284]), 'currentState': array([3.05532917, 4.43274247]), 'targetState': array([-0.2033209 ,  1.37866338]), 'effectorPosition': array([-0.63848242,  1.01995509])}
done in step count: 103
reward sum = 0.355160814705073
running average episode reward sum: 0.9602838816203528
{'reset': False, 'endBeforeDone': False, 'stepCount': 104, 'initial state': array([ 2.56300056, -2.35044284]), 'currentState': array([2.41214945, 5.02402039]), 'targetState': array([-0.2033209 ,  1.37866338]), 'effectorPosition': array([-0.33978415,  1.58043364])}
episode index:1639
target Thresh 1.9321335404704996
current state at start:  [-3.73928959  2.91608934]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.73928959,  2.91608934]), 'currentState': array([2.84298426, 2.41608934]), 'targetState': array([-1.02842801, -0.73471938]), 'effectorPosition': array([-0.4358889 , -0.56006227])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9602959646193648
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-3.73928959,  2.91608934]), 'currentState': array([2.82085064, 1.84265206]), 'targetState': array([-1.02842801, -0.73471938]), 'effectorPosition': array([-0.99786855, -0.68353448])}
episode index:1640
target Thresh 1.9322691377470829
current state at start:  [ 1.66931961 -2.53763998]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.66931961, -2.53763998]), 'currentState': array([2.16931961, 3.24554533]), 'targetState': array([-0.24768957,  0.16952735]), 'effectorPosition': array([0.08268636, 0.06292374])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.9602902937389751
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([ 1.66931961, -2.53763998]), 'currentState': array([3.07303279, 3.2882326 ]), 'targetState': array([-0.24768957,  0.16952735]), 'effectorPosition': array([-0.00069739,  0.14650694])}
episode index:1641
target Thresh 1.9324044641001268
current state at start:  [0.38926345 1.65222801]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.38926345, 1.65222801]), 'currentState': array([0.8430294 , 2.07641153]), 'targetState': array([-0.04665813,  0.46898437]), 'effectorPosition': array([-0.31022168,  0.96699069])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9603083873481475
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.38926345, 1.65222801]), 'currentState': array([0.41594785, 2.48287291]), 'targetState': array([-0.04665813,  0.46898437]), 'effectorPosition': array([-0.05594161,  0.64445129])}
episode index:1642
target Thresh 1.9325395200709372
current state at start:  [-0.69242829 -1.68666693]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.69242829, -1.68666693]), 'currentState': array([5.45899542, 4.09651838]), 'targetState': array([-0.16345487, -0.56864769]), 'effectorPosition': array([-0.31231442, -0.86436157])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9603264589322327
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.69242829, -1.68666693]), 'currentState': array([5.57773525, 3.81567369]), 'targetState': array([-0.16345487, -0.56864769]), 'effectorPosition': array([-0.23818821, -0.61701266])}
episode index:1643
target Thresh 1.9326743061997378
current state at start:  [-2.50392702  2.16505261]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.50392702,  2.16505261]), 'currentState': array([3.95469553, 2.56333923]), 'targetState': array([ 0.18802811, -0.42805908]), 'effectorPosition': array([ 0.28530164, -0.49372654])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9603505912564831
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.50392702,  2.16505261]), 'currentState': array([3.95469553, 2.56333923]), 'targetState': array([ 0.18802811, -0.42805908]), 'effectorPosition': array([ 0.28530164, -0.49372654])}
episode index:1644
target Thresh 1.9328088230256735
current state at start:  [ 0.48049157 -2.03424814]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.48049157, -2.03424814]), 'currentState': array([0.04666173, 3.86603374]), 'targetState': array([-0.04793864, -0.78985778]), 'effectorPosition': array([ 0.28176902, -0.65028174])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9603686152131661
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.48049157, -2.03424814]), 'currentState': array([5.9105159 , 4.09447343]), 'targetState': array([-0.04793864, -0.78985778]), 'effectorPosition': array([ 0.09501193, -0.91230363])}
episode index:1645
target Thresh 1.9329430710868116
current state at start:  [ 0.7006263  -2.76101896]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.7006263 , -2.76101896]), 'currentState': array([0.23744879, 3.81345779]), 'targetState': array([-0.45741354, -1.13626564]), 'effectorPosition': array([ 0.35765398, -0.55385871])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9603746482537414
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 0.7006263 , -2.76101896]), 'currentState': array([5.09039341, 4.4999545 ]), 'targetState': array([-0.45741354, -1.13626564]), 'effectorPosition': array([-0.61725806, -1.09421749])}
episode index:1646
target Thresh 1.9330770509201447
current state at start:  [ 3.14240142 -2.84049191]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.14240142, -2.84049191]), 'currentState': array([3.34111455, 3.86693423]), 'targetState': array([-0.16455102,  0.6246301 ]), 'effectorPosition': array([-0.37821783,  0.60033785])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9603987073622697
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.14240142, -2.84049191]), 'currentState': array([3.34111455, 3.86693423]), 'targetState': array([-0.16455102,  0.6246301 ]), 'effectorPosition': array([-0.37821783,  0.60033785])}
episode index:1647
target Thresh 1.9332107630615922
current state at start:  [-1.47600593 -1.84100572]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.47600593, -1.84100572]), 'currentState': array([5.13030301, 3.94217959]), 'targetState': array([-0.16561804, -0.14086786]), 'effectorPosition': array([-0.53272827, -0.56888443])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9604166693116859
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.47600593, -1.84100572]), 'currentState': array([5.39221584, 3.44217959]), 'targetState': array([-0.16561804, -0.14086786]), 'effectorPosition': array([-0.20206941, -0.22100273])}
episode index:1648
target Thresh 1.933344208046003
current state at start:  [-1.05204167  2.25106363]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.05204167,  2.25106363]), 'currentState': array([5.73114364, 1.91412808]), 'targetState': array([1.1623183 , 0.50781677]), 'effectorPosition': array([1.05865358, 0.45387232])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9604406737572215
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.05204167,  2.25106363]), 'currentState': array([5.73114364, 1.91412808]), 'targetState': array([1.1623183 , 0.50781677]), 'effectorPosition': array([1.05865358, 0.45387232])}
episode index:1649
target Thresh 1.933477386407157
current state at start:  [-2.90416677  2.09894928]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.90416677,  2.09894928]), 'currentState': array([2.96959605, 2.51472323]), 'targetState': array([-0.04320357, -0.00144123]), 'effectorPosition': array([-0.28772529, -0.54541575])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.960458588500399
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.90416677,  2.09894928]), 'currentState': array([2.53354134, 2.93631276]), 'targetState': array([-0.04320357, -0.00144123]), 'effectorPosition': array([-0.13368094, -0.15531088])}
episode index:1650
target Thresh 1.933610298677768
current state at start:  [ 2.33431761 -1.73891527]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.33431761, -1.73891527]), 'currentState': array([2.16728675, 4.93814763]), 'targetState': array([0.17035464, 1.37388163]), 'effectorPosition': array([0.11883266, 1.55999053])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9604825384770795
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.33431761, -1.73891527]), 'currentState': array([2.16728675, 4.93814763]), 'targetState': array([0.17035464, 1.37388163]), 'effectorPosition': array([0.11883266, 1.55999053])}
episode index:1651
target Thresh 1.9337429453894852
current state at start:  [-0.28070401 -1.66959612]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.28070401, -1.66959612]), 'currentState': array([5.59194781, 4.37684169]), 'targetState': array([ 0.25335168, -1.05742202]), 'effectorPosition': array([-0.0851816 , -1.15506368])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9605004061898658
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.28070401, -1.66959612]), 'currentState': array([5.97230653, 4.43397885]), 'targetState': array([ 0.25335168, -1.05742202]), 'effectorPosition': array([ 0.39629513, -1.1372315 ])}
episode index:1652
target Thresh 1.9338753270728954
current state at start:  [-3.34624729  2.11496499]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.34624729,  2.11496499]), 'currentState': array([2.4756287 , 2.07504743]), 'targetState': array([-0.95786132, -0.36870365]), 'effectorPosition': array([-0.94733054, -0.36913555])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9605243018909003
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.34624729,  2.11496499]), 'currentState': array([2.4756287 , 2.07504743]), 'targetState': array([-0.95786132, -0.36870365]), 'effectorPosition': array([-0.94733054, -0.36913555])}
episode index:1653
target Thresh 1.9340074442575261
current state at start:  [-0.73352741 -1.62053818]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.73352741, -1.62053818]), 'currentState': array([5.9842764 , 4.19647133]), 'targetState': array([ 0.41821447, -0.72932241]), 'effectorPosition': array([ 0.22805174, -0.98047227])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.960542122748282
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.73352741, -1.62053818]), 'currentState': array([6.18569539, 4.03316346]), 'targetState': array([ 0.41821447, -0.72932241]), 'effectorPosition': array([ 0.29431102, -0.81055523])}
episode index:1654
target Thresh 1.9341392974718457
current state at start:  [1.58647035 2.73004948]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.58647035, 2.73004948]), 'currentState': array([1.08647035, 3.02109249]), 'targetState': array([-0.03701641,  0.69410473]), 'effectorPosition': array([-0.10300711,  0.06238801])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.9605363511030564
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([1.58647035, 2.73004948]), 'currentState': array([0.71577658, 2.53099312]), 'targetState': array([-0.03701641,  0.69410473]), 'effectorPosition': array([-0.23989012,  0.55122037])}
episode index:1655
target Thresh 1.9342708872432672
current state at start:  [-2.48398749  2.2972454 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.48398749,  2.2972454 ]), 'currentState': array([3.30994308, 2.7972454 ]), 'targetState': array([-0.56286275,  0.15053004]), 'effectorPosition': array([-0.00131001, -0.34264597])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9605422464224386
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-2.48398749,  2.2972454 ]), 'currentState': array([3.81651512, 3.75287553]), 'targetState': array([-0.56286275,  0.15053004]), 'effectorPosition': array([-0.49999049,  0.33493979])}
episode index:1656
target Thresh 1.9344022140981503
current state at start:  [-3.04743179  1.97399453]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.04743179,  1.97399453]), 'currentState': array([2.93773053, 2.47399453]), 'targetState': array([ 0.10571472, -0.13543016]), 'effectorPosition': array([-0.33558223, -0.56281675])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9605600241856116
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.04743179,  1.97399453]), 'currentState': array([2.62250269, 2.97399453]), 'targetState': array([ 0.10571472, -0.13543016]), 'effectorPosition': array([-0.09492106, -0.13788921])}
episode index:1657
target Thresh 1.9345332785618021
current state at start:  [ 0.09957777 -2.58620554]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.09957777, -2.58620554]), 'currentState': array([0.53242918, 3.2355856 ]), 'targetState': array([-0.17447779,  0.41757383]), 'effectorPosition': array([ 0.05144628, -0.07862221])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9605777805039556
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.09957777, -2.58620554]), 'currentState': array([1.004786 , 2.8041533]), 'targetState': array([-0.17447779,  0.41757383]), 'effectorPosition': array([-0.24919775,  0.22514318])}
episode index:1658
target Thresh 1.934664081158481
current state at start:  [-2.36967963  1.8302705 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.36967963,  1.8302705 ]), 'currentState': array([4.17737204, 2.3302705 ]), 'targetState': array([ 0.12239725, -0.34586138]), 'effectorPosition': array([ 0.46505945, -0.63768275])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9605955154162498
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.36967963,  1.8302705 ]), 'currentState': array([3.78494376, 2.62315491]), 'targetState': array([ 0.12239725, -0.34586138]), 'effectorPosition': array([ 0.19211847, -0.47529122])}
episode index:1659
target Thresh 1.9347946224113974
current state at start:  [-3.93506858  2.31618834]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.93506858,  2.31618834]), 'currentState': array([2.84811673, 2.78149522]), 'targetState': array([ 0.03649401, -0.94854385]), 'effectorPosition': array([-0.16332797, -0.31874595])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.960607265105758
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-3.93506858,  2.31618834]), 'currentState': array([3.84811673, 2.10040007]), 'targetState': array([ 0.03649401, -0.94854385]), 'effectorPosition': array([ 0.18389622, -0.97764992])}
episode index:1660
target Thresh 1.9349249028427165
current state at start:  [-0.1301267  -1.98891209]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.1301267 , -1.98891209]), 'currentState': array([5.70028363, 4.46574313]), 'targetState': array([ 0.10901351, -1.18198735]), 'effectorPosition': array([ 0.09724302, -1.22565836])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.960630981382034
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.1301267 , -1.98891209]), 'currentState': array([5.70028363, 4.46574313]), 'targetState': array([ 0.10901351, -1.18198735]), 'effectorPosition': array([ 0.09724302, -1.22565836])}
episode index:1661
target Thresh 1.93505492297356
current state at start:  [ 3.42732621 -2.55208706]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.42732621, -2.55208706]), 'currentState': array([3.92732621, 3.23109824]), 'targetState': array([-0.02225024, -0.23730009]), 'effectorPosition': array([-0.0660563 ,  0.06035287])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9606367984810821
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 3.42732621, -2.55208706]), 'currentState': array([3.45993588, 2.79797522]), 'targetState': array([-0.02225024, -0.23730009]), 'effectorPosition': array([ 0.04992534, -0.33826498])}
episode index:1662
target Thresh 1.9351846833240092
current state at start:  [0.55684179 1.95714781]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.55684179, 1.95714781]), 'currentState': array([1.05196303, 2.27676824]), 'targetState': array([-0.54882791,  0.82080049]), 'effectorPosition': array([-0.4866733 ,  0.68235006])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9606604684759822
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.55684179, 1.95714781]), 'currentState': array([1.05196303, 2.27676824]), 'targetState': array([-0.54882791,  0.82080049]), 'effectorPosition': array([-0.4866733 ,  0.68235006])}
episode index:1663
target Thresh 1.935314184413105
current state at start:  [ 1.15343661 -3.02875954]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.15343661, -3.02875954]), 'currentState': array([1.17875088, 3.10934323]), 'targetState': array([ 0.12118847, -0.18547642]), 'effectorPosition': array([-0.02959881,  0.01280022])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9606841100213692
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.15343661, -3.02875954]), 'currentState': array([1.17875088, 3.10934323]), 'targetState': array([ 0.12118847, -0.18547642]), 'effectorPosition': array([-0.02959881,  0.01280022])}
episode index:1664
target Thresh 1.9354434267588523
current state at start:  [-3.13550787  2.13564916]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.13550787,  2.13564916]), 'currentState': array([3.64767744, 2.46430005]), 'targetState': array([ 0.36500844, -1.07210795]), 'effectorPosition': array([ 0.11073058, -0.65512916])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9607017171624975
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.13550787,  2.13564916]), 'currentState': array([4.13323765, 1.96430005]), 'targetState': array([ 0.36500844, -1.07210795]), 'effectorPosition': array([ 0.43550306, -1.02151049])}
episode index:1665
target Thresh 1.9355724108782204
current state at start:  [ 3.25424433 -2.37134626]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.25424433, -2.37134626]), 'currentState': array([3.52919239, 3.41183905]), 'targetState': array([-0.03017408,  0.10443064]), 'effectorPosition': array([-0.13450798,  0.2334466 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9607253055675621
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.25424433, -2.37134626]), 'currentState': array([3.52919239, 3.41183905]), 'targetState': array([-0.03017408,  0.10443064]), 'effectorPosition': array([-0.13450798,  0.2334466 ])}
episode index:1666
target Thresh 1.9357011372871462
current state at start:  [-1.46269507 -2.78157806]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.46269507, -2.78157806]), 'currentState': array([5.03710263, 3.00160724]), 'targetState': array([0.0695435, 0.1329327]), 'effectorPosition': array([0.13535801, 0.03524408])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9607488656722006
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.46269507, -2.78157806]), 'currentState': array([5.03710263, 3.00160724]), 'targetState': array([0.0695435, 0.1329327]), 'effectorPosition': array([0.13535801, 0.03524408])}
episode index:1667
target Thresh 1.9358296065005356
current state at start:  [-1.31032271 -1.76635566]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.31032271, -1.76635566]), 'currentState': array([4.80818266, 4.01682964]), 'targetState': array([-0.62667641, -0.15144631]), 'effectorPosition': array([-0.72982068, -0.43096624])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9607664023234763
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.31032271, -1.76635566]), 'currentState': array([4.73278387, 3.57561097]), 'targetState': array([-0.62667641, -0.15144631]), 'effectorPosition': array([-0.41854167, -0.10127328])}
episode index:1668
target Thresh 1.9359578190322653
current state at start:  [-1.7593182   1.81688811]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.7593182 ,  1.81688811]), 'currentState': array([4.76114996, 2.10948594]), 'targetState': array([ 0.4408866 , -0.04982186]), 'effectorPosition': array([ 0.88109803, -0.44457061])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.9607605447126772
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([-1.7593182 ,  1.81688811]), 'currentState': array([4.55573601, 2.55575633]), 'targetState': array([ 0.4408866 , -0.04982186]), 'effectorPosition': array([ 0.52011105, -0.25096722])}
episode index:1669
target Thresh 1.9360857753951857
current state at start:  [-2.34041663  2.8212811 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.34041663,  2.8212811 ]), 'currentState': array([3.71111649, 2.8543159 ]), 'targetState': array([ 0.00892478, -0.16570213]), 'effectorPosition': array([ 0.11827419, -0.26071658])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9607840413924901
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.34041663,  2.8212811 ]), 'currentState': array([3.71111649, 2.8543159 ]), 'targetState': array([ 0.00892478, -0.16570213]), 'effectorPosition': array([ 0.11827419, -0.26071658])}
episode index:1670
target Thresh 1.9362134761011225
current state at start:  [ 1.9737507 -2.1688912]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.9737507, -2.1688912]), 'currentState': array([2.17526915, 4.61429411]), 'targetState': array([0.65427916, 1.24961153]), 'effectorPosition': array([0.30617859, 1.30781475])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9608015255089517
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.9737507, -2.1688912]), 'currentState': array([1.7630313 , 5.02826493]), 'targetState': array([0.65427916, 1.24961153]), 'effectorPosition': array([0.68261198, 1.46810738])}
episode index:1671
target Thresh 1.9363409216608787
current state at start:  [ 0.90098148 -1.89061316]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.90098148, -1.89061316]), 'currentState': array([1.40098148, 3.94384323]), 'targetState': array([0.22882523, 0.0409881 ]), 'effectorPosition': array([0.76011101, 0.17902596])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9608189887113986
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.90098148, -1.89061316]), 'currentState': array([1.80972266, 3.46508963]), 'targetState': array([0.22882523, 0.0409881 ]), 'effectorPosition': array([0.2965782 , 0.12562723])}
episode index:1672
target Thresh 1.9364681125842365
current state at start:  [ 1.84622184 -2.82418756]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.84622184, -2.82418756]), 'currentState': array([2.23645914, 2.95899775]), 'targetState': array([-0.125128  , -0.58823019]), 'effectorPosition': array([-0.15308236, -0.09906644])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9608305135238843
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 1.84622184, -2.82418756]), 'currentState': array([3.15975113, 2.66926964]), 'targetState': array([-0.125128  , -0.58823019]), 'effectorPosition': array([-0.10120727, -0.45686917])}
episode index:1673
target Thresh 1.93659504937996
current state at start:  [-2.78613065  2.33768063]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.78613065,  2.33768063]), 'currentState': array([3.99705466, 2.83768063]), 'targetState': array([ 0.91893554, -0.26059683]), 'effectorPosition': array([ 0.19584352, -0.23086601])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9608420245671794
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-2.78613065,  2.33768063]), 'currentState': array([4.95130318, 2.16466146]), 'targetState': array([ 0.91893554, -0.26059683]), 'effectorPosition': array([ 0.90947   , -0.23179128])}
episode index:1674
target Thresh 1.9367217325557966
current state at start:  [-1.40148373 -2.6440396 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.40148373, -2.6440396 ]), 'currentState': array([5.31610717, 4.07861615]), 'targetState': array([-0.21905044, -0.89261476]), 'effectorPosition': array([-0.43184107, -0.79318035])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9608654024629603
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.40148373, -2.6440396 ]), 'currentState': array([5.31610717, 4.07861615]), 'targetState': array([-0.21905044, -0.89261476]), 'effectorPosition': array([-0.43184107, -0.79318035])}
episode index:1675
target Thresh 1.936848162618479
current state at start:  [-1.6193856  -2.89681305]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.6193856 , -2.89681305]), 'currentState': array([4.34874535, 3.7961184 ]), 'targetState': array([-0.87890764,  0.18204937]), 'effectorPosition': array([-0.64247934,  0.02338421])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9608827858743785
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.6193856 , -2.89681305]), 'currentState': array([4.23602354, 4.09798123]), 'targetState': array([-0.87890764,  0.18204937]), 'effectorPosition': array([-0.92035199, -0.00168319])}
episode index:1676
target Thresh 1.9369743400737276
current state at start:  [-1.53406246  1.97118971]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.53406246,  1.97118971]), 'currentState': array([4.24912285, 2.0281312 ]), 'targetState': array([ 0.25449144, -0.77007161]), 'effectorPosition': array([ 0.55311005, -0.90052895])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9608942451553121
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.53406246,  1.97118971]), 'currentState': array([4.16428326, 2.2092138 ]), 'targetState': array([ 0.25449144, -0.77007161]), 'effectorPosition': array([ 0.47485329, -0.76332407])}
episode index:1677
target Thresh 1.9371002654262526
current state at start:  [ 1.43718989 -2.43872974]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.43718989, -2.43872974]), 'currentState': array([1.93718989, 3.46422258]), 'targetState': array([-0.15350174,  0.76985755]), 'effectorPosition': array([0.27753304, 0.16175819])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9609056907779847
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 1.43718989, -2.43872974]), 'currentState': array([2.79024197, 4.21989914]), 'targetState': array([-0.15350174,  0.76985755]), 'effectorPosition': array([-0.19170769,  1.00876438])}
episode index:1678
target Thresh 1.9372259391797553
current state at start:  [-0.02687781  1.72718962]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.02687781,  1.72718962]), 'currentState': array([0.42965431, 2.05325307]), 'targetState': array([0.37332892, 0.90520471]), 'effectorPosition': array([0.11831218, 1.02863426])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9609230191336857
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.02687781,  1.72718962]), 'currentState': array([6.26660116, 1.98719461]), 'targetState': array([0.37332892, 0.90520471]), 'effectorPosition': array([0.61061534, 0.90454997])}
episode index:1679
target Thresh 1.937351361836931
current state at start:  [-0.25098019 -1.74692451]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.25098019, -1.74692451]), 'currentState': array([0.12745542, 4.64730471]), 'targetState': array([ 0.82478817, -1.03255934]), 'effectorPosition': array([ 1.05421927, -0.87094493])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9609344340032491
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-0.25098019, -1.74692451]), 'currentState': array([0.10622717, 4.57854439]), 'targetState': array([ 0.82478817, -1.03255934]), 'effectorPosition': array([ 0.96674928, -0.89359116])}
episode index:1680
target Thresh 1.9374765338994706
current state at start:  [-0.23859948  2.62916264]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.23859948,  2.62916264]), 'currentState': array([0.24976346, 2.71739539]), 'targetState': array([-0.29211094,  0.92161072]), 'effectorPosition': array([-0.01585404,  0.42072532])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9609517246433423
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.23859948,  2.62916264]), 'currentState': array([0.73562631, 2.21739539]), 'targetState': array([-0.29211094,  0.92161072]), 'effectorPosition': array([-0.24086251,  0.85850701])}
episode index:1681
target Thresh 1.9376014558680623
current state at start:  [-1.08123231  2.15372543]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.08123231,  2.15372543]), 'currentState': array([5.5228037 , 2.40534805]), 'targetState': array([0.35809096, 0.28280512]), 'effectorPosition': array([0.65047093, 0.30805266])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9609689947238159
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.08123231,  2.15372543]), 'currentState': array([5.73850234, 2.46422074]), 'targetState': array([0.35809096, 0.28280512]), 'effectorPosition': array([0.51357631, 0.42165656])}
episode index:1682
target Thresh 1.9377261282423945
current state at start:  [ 3.05862517 -2.11414539]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.05862517, -2.11414539]), 'currentState': array([3.42674969, 3.66903991]), 'targetState': array([ 0.09833187, -0.06174296]), 'effectorPosition': array([-0.27200765,  0.44477222])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9609862442813181
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.05862517, -2.11414539]), 'currentState': array([3.84633745, 3.16903991]), 'targetState': array([ 0.09833187, -0.06174296]), 'effectorPosition': array([-0.01806611,  0.02066205])}
episode index:1683
target Thresh 1.9378505515211566
current state at start:  [-1.91207957  2.41392141]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.91207957,  2.41392141]), 'currentState': array([3.92972902, 2.59200113]), 'targetState': array([ 0.03465377, -0.34202317]), 'effectorPosition': array([ 0.26651491, -0.4727514 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.96100347335241
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.91207957,  2.41392141]), 'currentState': array([3.65653611, 2.6220554 ]), 'targetState': array([ 0.03465377, -0.34202317]), 'effectorPosition': array([ 0.12966888, -0.49707942])}
episode index:1684
target Thresh 1.9379747262020417
current state at start:  [ 3.73537045 -1.62570279]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.73537045, -1.62570279]), 'currentState': array([3.27612682, 4.27891869]), 'targetState': array([-0.44011548,  0.78357559]), 'effectorPosition': array([-0.69646025,  0.82152164])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9610206819735658
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.73537045, -1.62570279]), 'currentState': array([3.03789861, 4.25000672]), 'targetState': array([-0.44011548,  0.78357559]), 'effectorPosition': array([-0.45830405,  0.94752016])}
episode index:1685
target Thresh 1.9380986527817492
current state at start:  [ 1.4213902  -2.34281353]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.4213902 , -2.34281353]), 'currentState': array([1.0228075 , 3.95610169]), 'targetState': array([ 0.8978608 , -0.05192241]), 'effectorPosition': array([ 0.78434771, -0.11111921])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9610438013792755
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.4213902 , -2.34281353]), 'currentState': array([1.0228075 , 3.95610169]), 'targetState': array([ 0.8978608 , -0.05192241]), 'effectorPosition': array([ 0.78434771, -0.11111921])}
episode index:1686
target Thresh 1.938222331755985
current state at start:  [-0.71240705  1.95920443]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.71240705,  1.95920443]), 'currentState': array([5.10234765, 2.42167601]), 'targetState': array([ 0.15390935, -0.22232202]), 'effectorPosition': array([0.70415346, 0.02113119])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9610609656938106
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.71240705,  1.95920443]), 'currentState': array([4.67156938, 2.77692291]), 'targetState': array([ 0.15390935, -0.22232202]), 'effectorPosition': array([ 0.35366021, -0.08025752])}
episode index:1687
target Thresh 1.9383457636194656
current state at start:  [ 1.89031068 -1.70046582]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.89031068, -1.70046582]), 'currentState': array([2.33549634, 4.95822711]), 'targetState': array([0.39430087, 1.25185925]), 'effectorPosition': array([-0.16091563,  1.56870802])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9610664384629494
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 1.89031068, -1.70046582]), 'currentState': array([1.97738846, 4.89272333]), 'targetState': array([0.39430087, 1.25185925]), 'effectorPosition': array([0.43716514, 1.47227839])}
episode index:1688
target Thresh 1.9384689488659186
current state at start:  [ 3.53473457 -1.84581974]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.53473457, -1.84581974]), 'currentState': array([3.03473457, 4.26548556]), 'targetState': array([-0.13595253,  0.83092196]), 'effectorPosition': array([-0.46840581,  0.95720724])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9604974234016924
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([ 3.53473457, -1.84581974]), 'currentState': array([2.50907713, 4.46989497]), 'targetState': array([-0.13595253,  0.83092196]), 'effectorPosition': array([-0.03899333,  1.23216504])}
episode index:1689
target Thresh 1.9385918879880848
current state at start:  [ 0.34211129 -2.70909648]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.34211129, -2.70909648]), 'currentState': array([0.55289036, 3.1918716 ]), 'targetState': array([0.8757106 , 0.31944833]), 'effectorPosition': array([ 0.02746826, -0.04210623])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9605032231511589
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 0.34211129, -2.70909648]), 'currentState': array([5.62985918, 2.32173926]), 'targetState': array([0.8757106 , 0.31944833]), 'effectorPosition': array([0.69660463, 0.38740833])}
episode index:1690
target Thresh 1.9387145814777211
current state at start:  [1.06162988 1.83210782]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.06162988, 1.83210782]), 'currentState': array([0.63360374, 2.1092555 ]), 'targetState': array([-0.08975513,  0.83619923]), 'effectorPosition': array([-0.11565434,  0.98030428])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9605265802042925
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.06162988, 1.83210782]), 'currentState': array([0.63360374, 2.1092555 ]), 'targetState': array([-0.08975513,  0.83619923]), 'effectorPosition': array([-0.11565434,  0.98030428])}
episode index:1691
target Thresh 1.9388370298256017
current state at start:  [0.009172   2.33603953]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.009172  , 2.33603953]), 'currentState': array([0.509172  , 1.98181318]), 'targetState': array([0.42685181, 1.13196389]), 'effectorPosition': array([0.0774324 , 1.09312434])}
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.9604775225463696
{'reset': False, 'endBeforeDone': False, 'stepCount': 14, 'initial state': array([0.009172  , 2.33603953]), 'currentState': array([0.20548413, 1.69279306]), 'targetState': array([0.42685181, 1.13196389]), 'effectorPosition': array([0.65730352, 1.15089678])}
episode index:1692
target Thresh 1.93895923352152
current state at start:  [-4.12190367  3.0566493 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.12190367,  3.0566493 ]), 'currentState': array([2.55227315, 3.5566493 ]), 'targetState': array([ 0.88258845, -0.35800456]), 'effectorPosition': array([0.15353553, 0.38241323])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.960466301416337
{'reset': False, 'endBeforeDone': False, 'stepCount': 7, 'initial state': array([-4.12190367,  3.0566493 ]), 'currentState': array([4.85605159, 2.12289771]), 'targetState': array([ 0.88258845, -0.35800456]), 'effectorPosition': array([ 0.91073317, -0.34872622])}
episode index:1693
target Thresh 1.939081193054291
current state at start:  [ 1.50761484 -2.28904788]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.50761484, -2.28904788]), 'currentState': array([1.22431128, 4.35881292]), 'targetState': array([0.83843451, 0.34277132]), 'effectorPosition': array([1.10439666, 0.29630775])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9604837357130216
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.50761484, -2.28904788]), 'currentState': array([1.52479609, 4.07061468]), 'targetState': array([0.83843451, 0.34277132]), 'effectorPosition': array([0.81864471, 0.36412295])}
episode index:1694
target Thresh 1.939202908911753
current state at start:  [-1.60033263 -2.0102427 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.60033263, -2.0102427 ]), 'currentState': array([4.31683578, 3.93310857]), 'targetState': array([-1.0428265 ,  0.02080359]), 'effectorPosition': array([-7.71015325e-01, -1.57871316e-04])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9604953087303001
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.60033263, -2.0102427 ]), 'currentState': array([4.02866772, 4.1389319 ]), 'targetState': array([-1.0428265 ,  0.02080359]), 'effectorPosition': array([-0.94018438,  0.17599621])}
episode index:1695
target Thresh 1.9393243815807697
current state at start:  [1.56233308 2.30258467]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.56233308, 2.30258467]), 'currentState': array([1.17661623, 2.80258467]), 'targetState': array([-0.2212819 ,  0.05973647]), 'effectorPosition': array([-0.28519063,  0.18026718])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9605186015907184
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.56233308, 2.30258467]), 'currentState': array([1.17661623, 2.80258467]), 'targetState': array([-0.2212819 ,  0.05973647]), 'effectorPosition': array([-0.28519063,  0.18026718])}
episode index:1696
target Thresh 1.9394456115472316
current state at start:  [0.2586782  2.20980121]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.2586782 , 2.20980121]), 'currentState': array([0.71311248, 2.19200435]), 'targetState': array([0.15999362, 0.96614293]), 'effectorPosition': array([-0.21584026,  0.88846898])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9605359742474122
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.2586782 , 2.20980121]), 'currentState': array([0.29171369, 1.91432914]), 'targetState': array([0.15999362, 0.96614293]), 'effectorPosition': array([0.36437648, 1.09251939])}
episode index:1697
target Thresh 1.9395665992960591
current state at start:  [ 3.23052703 -2.92152692]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.23052703, -2.92152692]), 'currentState': array([2.8149824 , 3.82940694]), 'targetState': array([0.24937024, 1.17564552]), 'effectorPosition': array([-0.01166333,  0.67423515])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9605533264416128
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.23052703, -2.92152692]), 'currentState': array([2.35192196, 4.29986652]), 'targetState': array([0.24937024, 1.17564552]), 'effectorPosition': array([0.22875235, 1.07043423])}
episode index:1698
target Thresh 1.9396873453112031
current state at start:  [ 3.36942135 -1.98523125]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.36942135, -1.98523125]), 'currentState': array([2.91984014, 3.94688324]), 'targetState': array([0.1332002 , 0.46482962]), 'effectorPosition': array([-0.14099503,  0.77091952])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9605706582094518
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.36942135, -1.98523125]), 'currentState': array([2.59014575, 3.80447437]), 'targetState': array([0.1332002 , 0.46482962]), 'effectorPosition': array([0.14203021, 0.63512454])}
episode index:1699
target Thresh 1.9398078500756482
current state at start:  [ 0.396901   -1.71523939]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.396901  , -1.71523939]), 'currentState': array([0.8517231 , 4.46412926]), 'targetState': array([ 1.25116334, -0.32587052]), 'effectorPosition': array([ 1.22618517, -0.07095859])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9605879695869757
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.396901  , -1.71523939]), 'currentState': array([0.48747703, 4.48385412]), 'targetState': array([ 1.25116334, -0.32587052]), 'effectorPosition': array([ 1.13957556, -0.4982631 ])}
episode index:1700
target Thresh 1.939928114071413
current state at start:  [-1.37228464 -2.14768782]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.37228464, -2.14768782]), 'currentState': array([4.46989153, 3.76408318]), 'targetState': array([-1.36401872,  0.08176557]), 'effectorPosition': array([-0.61104179, -0.04207409])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.960599440504326
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.37228464, -2.14768782]), 'currentState': array([3.98148848, 4.60682345]), 'targetState': array([-1.36401872,  0.08176557]), 'effectorPosition': array([-1.33763059, -0.0022939 ])}
episode index:1701
target Thresh 1.9400481377795542
current state at start:  [-0.55596771 -2.51865295]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.55596771, -2.51865295]), 'currentState': array([6.1943401 , 3.28442561]), 'targetState': array([0.36463112, 0.06853616]), 'effectorPosition': array([-0.00248716, -0.1426899 ])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.960588207078296
{'reset': False, 'endBeforeDone': False, 'stepCount': 7, 'initial state': array([-0.55596771, -2.51865295]), 'currentState': array([5.68297763, 2.76130229]), 'targetState': array([0.36463112, 0.06853616]), 'effectorPosition': array([0.26860948, 0.26596082])}
episode index:1702
target Thresh 1.9401679216801666
current state at start:  [ 3.19371097 -1.79741342]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.19371097, -1.79741342]), 'currentState': array([2.78977566, 4.83693435]), 'targetState': array([-0.56353341,  1.28120203]), 'effectorPosition': array([-0.71342796,  1.31888886])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9606113496460714
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.19371097, -1.79741342]), 'currentState': array([2.78977566, 4.83693435]), 'targetState': array([-0.56353341,  1.28120203]), 'effectorPosition': array([-0.71342796,  1.31888886])}
episode index:1703
target Thresh 1.9402874662523857
current state at start:  [-0.92158557 -2.41771787]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.92158557, -2.41771787]), 'currentState': array([5.78895004, 3.36546743]), 'targetState': array([0.18728786, 0.3309484 ]), 'effectorPosition': array([-0.08334296, -0.20727973])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9606285965066078
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.92158557, -2.41771787]), 'currentState': array([6.14302893, 2.86546743]), 'targetState': array([0.18728786, 0.3309484 ]), 'effectorPosition': array([0.07559532, 0.26466445])}
episode index:1704
target Thresh 1.9404067719743905
current state at start:  [-0.48749795 -1.98868286]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.48749795, -1.98868286]), 'currentState': array([5.74199066, 3.88940249]), 'targetState': array([-0.01677806, -0.69169064]), 'effectorPosition': array([-0.12163705, -0.72030855])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9606516882388619
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.48749795, -1.98868286]), 'currentState': array([5.74199066, 3.88940249]), 'targetState': array([-0.01677806, -0.69169064]), 'effectorPosition': array([-0.12163705, -0.72030855])}
episode index:1705
target Thresh 1.9405258393234035
current state at start:  [-3.25504353  2.65402038]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.25504353,  2.65402038]), 'currentState': array([2.90404263, 2.6650011 ]), 'targetState': array([-0.28284489, -0.2792248 ]), 'effectorPosition': array([-0.21626167, -0.41964683])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9606747528999178
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.25504353,  2.65402038]), 'currentState': array([2.90404263, 2.6650011 ]), 'targetState': array([-0.28284489, -0.2792248 ]), 'effectorPosition': array([-0.21626167, -0.41964683])}
episode index:1706
target Thresh 1.9406446687756946
current state at start:  [ 0.79905281 -2.50520433]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.79905281, -2.50520433]), 'currentState': array([0.81606984, 4.13927853]), 'targetState': array([ 1.14748575, -0.49856979]), 'effectorPosition': array([ 0.9256656 , -0.24217132])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9606919323065376
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.79905281, -2.50520433]), 'currentState': array([0.67251089, 4.35531058]), 'targetState': array([ 1.14748575, -0.49856979]), 'effectorPosition': array([ 1.09248762, -0.32771018])}
episode index:1707
target Thresh 1.9407632608065817
current state at start:  [-3.57113174  2.40615257]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.57113174,  2.40615257]), 'currentState': array([2.43275288, 2.88420518]), 'targetState': array([0.0974562 , 0.06468654]), 'effectorPosition': array([-0.19071005, -0.17179365])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9607090915967562
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.57113174,  2.40615257]), 'currentState': array([2.14783353, 3.38056239]), 'targetState': array([0.0974562 , 0.06468654]), 'effectorPosition': array([0.18287259, 0.15294739])}
episode index:1708
target Thresh 1.940881615890433
current state at start:  [1.80647112 1.74082639]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.80647112, 1.74082639]), 'currentState': array([1.94436941, 2.07102101]), 'targetState': array([-0.94385638,  0.06170041]), 'effectorPosition': array([-1.00686356,  0.16425699])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9607320821809594
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.80647112, 1.74082639]), 'currentState': array([1.94436941, 2.07102101]), 'targetState': array([-0.94385638,  0.06170041]), 'effectorPosition': array([-1.00686356,  0.16425699])}
episode index:1709
target Thresh 1.9409997345006689
current state at start:  [-1.0146509   2.22720296]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.0146509 ,  2.22720296]), 'currentState': array([4.83240702, 1.96255208]), 'targetState': array([ 0.93413534, -0.71371617]), 'effectorPosition': array([ 0.99160733, -0.50308194])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9607550458755905
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.0146509 ,  2.22720296]), 'currentState': array([4.83240702, 1.96255208]), 'targetState': array([ 0.93413534, -0.71371617]), 'effectorPosition': array([ 0.99160733, -0.50308194])}
episode index:1710
target Thresh 1.9411176171097644
current state at start:  [ 2.55397002 -2.62398105]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.55397002, -2.62398105]), 'currentState': array([3.05397002, 4.15920425]), 'targetState': array([-0.5272708 ,  1.26072537]), 'effectorPosition': array([-0.39832077,  0.8891239 ])}
done in step count: 21
reward sum = 0.8097278682212584
running average episode reward sum: 0.9606667775075868
{'reset': False, 'endBeforeDone': False, 'stepCount': 22, 'initial state': array([ 2.55397002, -2.62398105]), 'currentState': array([1.34100142, 1.34716225]), 'targetState': array([-0.5272708 ,  1.26072537]), 'effectorPosition': array([-0.67117249,  1.41176372])}
episode index:1711
target Thresh 1.9412352641892496
current state at start:  [-1.42560461  2.53104336]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.42560461,  2.53104336]), 'currentState': array([4.68724098, 2.77393865]), 'targetState': array([0.12830632, 0.13970689]), 'effectorPosition': array([ 0.35763316, -0.07584366])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9606667361714257
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([-1.42560461,  2.53104336]), 'currentState': array([4.26605795, 2.98865627]), 'targetState': array([0.12830632, 0.13970689]), 'effectorPosition': array([ 0.1323788 , -0.07628787])}
episode index:1712
target Thresh 1.9413526762097133
current state at start:  [-3.98732079  1.92573914]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.98732079,  1.92573914]), 'currentState': array([2.09834728, 1.99352517]), 'targetState': array([-1.08111271, -0.32688283]), 'effectorPosition': array([-1.08487425,  0.05046434])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9606838600849276
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.98732079,  1.92573914]), 'currentState': array([2.39019686, 1.9849741 ]), 'targetState': array([-1.08111271, -0.32688283]), 'effectorPosition': array([-1.06159981, -0.26101939])}
episode index:1713
target Thresh 1.9414698536408037
current state at start:  [-0.08100229  2.50624264]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.08100229,  2.50624264]), 'currentState': array([6.01663086, 2.99442087]), 'targetState': array([-0.03439794,  0.1043715 ]), 'effectorPosition': array([0.04905506, 0.13861482])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9607067983229177
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.08100229,  2.50624264]), 'currentState': array([6.01663086, 2.99442087]), 'targetState': array([-0.03439794,  0.1043715 ]), 'effectorPosition': array([0.04905506, 0.13861482])}
episode index:1714
target Thresh 1.9415867969512306
current state at start:  [-0.00314425 -1.89845009]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.00314425, -1.89845009]), 'currentState': array([0.49685575, 4.5418167 ]), 'targetState': array([ 1.3909896 , -0.01240589]), 'effectorPosition': array([ 1.19961046, -0.47057629])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9607181063122338
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-0.00314425, -1.89845009]), 'currentState': array([0.65520377, 4.66239697]), 'targetState': array([ 1.3909896 , -0.01240589]), 'effectorPosition': array([ 1.36186002, -0.21306081])}
episode index:1715
target Thresh 1.9417035066087673
current state at start:  [ 0.14027159 -2.88396197]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.14027159, -2.88396197]), 'currentState': array([6.11409091, 3.6694109 ]), 'targetState': array([-0.63152443, -0.36258745]), 'effectorPosition': array([ 0.04939196, -0.51936933])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9607236895836136
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 0.14027159, -2.88396197]), 'currentState': array([4.99274893, 3.76535471]), 'targetState': array([-0.63152443, -0.36258745]), 'effectorPosition': array([-0.50918097, -0.34258009])}
episode index:1716
target Thresh 1.9418199830802527
current state at start:  [-0.94824057 -2.60282606]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.94824057, -2.60282606]), 'currentState': array([4.90981297, 4.18035925]), 'targetState': array([-0.86689725, -1.05165988]), 'effectorPosition': array([-0.74839584, -0.6521783 ])}
done in step count: 33
reward sum = 0.7177305325982749
running average episode reward sum: 0.9605821676517643
{'reset': False, 'endBeforeDone': False, 'stepCount': 34, 'initial state': array([-0.94824057, -2.60282606]), 'currentState': array([5.04678016, 4.58289406]), 'targetState': array([-0.86689725, -1.05165988]), 'effectorPosition': array([-0.65088797, -1.14807588])}
episode index:1717
target Thresh 1.9419362268315932
current state at start:  [ 2.79598996 -1.83608451]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.79598996, -1.83608451]), 'currentState': array([2.35569758, 3.96806379]), 'targetState': array([0.1605123 , 0.53608957]), 'effectorPosition': array([0.29242158, 0.74802299])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9606051116752499
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.79598996, -1.83608451]), 'currentState': array([2.35569758, 3.96806379]), 'targetState': array([0.1605123 , 0.53608957]), 'effectorPosition': array([0.29242158, 0.74802299])}
episode index:1718
target Thresh 1.9420522383277632
current state at start:  [ 3.7805732  -2.00705561]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.7805732 , -2.00705561]), 'currentState': array([4.0522569 , 4.63651517]), 'targetState': array([-1.30669441,  0.27038788]), 'effectorPosition': array([-1.35437703, -0.11857822])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.960593986042746
{'reset': False, 'endBeforeDone': False, 'stepCount': 7, 'initial state': array([ 3.7805732 , -2.00705561]), 'currentState': array([3.89503868, 4.6030188 ]), 'targetState': array([-1.30669441,  0.27038788]), 'effectorPosition': array([-1.32979527,  0.1154989 ])}
episode index:1719
target Thresh 1.9421680180328094
current state at start:  [ 0.01165634 -1.95931937]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.01165634, -1.95931937]), 'currentState': array([0.34947642, 3.82386594]), 'targetState': array([ 0.00289135, -0.08747879]), 'effectorPosition': array([ 0.42623408, -0.51579253])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9606110825624886
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.01165634, -1.95931937]), 'currentState': array([0.70308291, 3.33712648]), 'targetState': array([ 0.00289135, -0.08747879]), 'effectorPosition': array([ 0.14015957, -0.13589375])}
episode index:1720
target Thresh 1.9422835664098506
current state at start:  [ 0.19540781 -1.64572318]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.19540781, -1.64572318]), 'currentState': array([0.59423214, 4.43109675]), 'targetState': array([ 1.30651806, -0.44445971]), 'effectorPosition': array([ 1.13643574, -0.39155992])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9606339697893552
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.19540781, -1.64572318]), 'currentState': array([0.59423214, 4.43109675]), 'targetState': array([ 1.30651806, -0.44445971]), 'effectorPosition': array([ 1.13643574, -0.39155992])}
episode index:1721
target Thresh 1.9423988839210806
current state at start:  [ 0.06419912 -2.13664881]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.06419912, -2.13664881]), 'currentState': array([0.34475595, 3.64850667]), 'targetState': array([-0.20421649, -0.08870734]), 'effectorPosition': array([ 0.28243035, -0.41441451])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9606510232331478
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.06419912, -2.13664881]), 'currentState': array([0.60084337, 3.17691671]), 'targetState': array([-0.20421649, -0.08870734]), 'effectorPosition': array([ 0.02048046, -0.02877864])}
episode index:1722
target Thresh 1.9425139710277692
current state at start:  [ 3.47542465 -2.25239345]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.47542465, -2.25239345]), 'currentState': array([3.93650204, 3.54631773]), 'targetState': array([-0.10979393, -0.25192762]), 'effectorPosition': array([-0.33765103,  0.21810642])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9606509913043996
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([ 3.47542465, -2.25239345]), 'currentState': array([3.63804816, 2.7757052 ]), 'targetState': array([-0.10979393, -0.25192762]), 'effectorPosition': array([ 0.11221173, -0.34611457])}
episode index:1723
target Thresh 1.9426288281902655
current state at start:  [-2.49872055  1.85263604]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.49872055,  1.85263604]), 'currentState': array([3.34548162, 2.30317682]), 'targetState': array([-0.58064643, -0.40508272]), 'effectorPosition': array([-0.17393429, -0.79527581])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9606622726319493
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-2.49872055,  1.85263604]), 'currentState': array([2.55943383, 2.24311522]), 'targetState': array([-0.58064643, -0.40508272]), 'effectorPosition': array([-0.74523965, -0.4461099 ])}
episode index:1724
target Thresh 1.9427434558679981
current state at start:  [ 1.75316346 -2.81073609]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.75316346, -2.81073609]), 'currentState': array([1.98708487, 3.22395304]), 'targetState': array([ 0.8523117 , -0.81621038]), 'effectorPosition': array([0.07387066, 0.03636653])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.9606566655463075
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([ 1.75316346, -2.81073609]), 'currentState': array([4.37113533, 1.87736142]), 'targetState': array([ 0.8523117 , -0.81621038]), 'effectorPosition': array([ 0.6647297 , -0.97701745])}
episode index:1725
target Thresh 1.9428578545194777
current state at start:  [-1.36011546  2.63586348]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.36011546,  2.63586348]), 'currentState': array([4.99181923, 2.39921962]), 'targetState': array([0.50939405, 0.10568052]), 'effectorPosition': array([ 0.72239111, -0.06647056])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9606736663194556
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.36011546,  2.63586348]), 'currentState': array([5.04130207, 2.42963473]), 'targetState': array([0.50939405, 0.10568052]), 'effectorPosition': array([ 0.69676095, -0.01886305])}
episode index:1726
target Thresh 1.9429720246022992
current state at start:  [-0.29802586  2.85228294]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.29802586,  2.85228294]), 'currentState': array([5.65343645, 3.34451365]), 'targetState': array([ 0.99143669, -0.67981012]), 'effectorPosition': array([-0.10210811, -0.17495647])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9606792397610773
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-0.29802586,  2.85228294]), 'currentState': array([0.47217897, 4.25207825]), 'targetState': array([ 0.99143669, -0.67981012]), 'effectorPosition': array([ 0.9024473 , -0.54510166])}
episode index:1727
target Thresh 1.9430859665731433
current state at start:  [ 2.4929121  -2.24451154]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.4929121 , -2.24451154]), 'currentState': array([2.33228694, 3.78994408]), 'targetState': array([0.04987759, 0.4432495 ]), 'effectorPosition': array([0.29707367, 0.56354806])}
done in step count: 30
reward sum = 0.7397003733882802
running average episode reward sum: 0.9605513584726671
{'reset': False, 'endBeforeDone': False, 'stepCount': 31, 'initial state': array([ 2.4929121 , -2.24451154]), 'currentState': array([2.3226361 , 3.73377294]), 'targetState': array([0.04987759, 0.4432495 ]), 'effectorPosition': array([0.29141252, 0.50559607])}
episode index:1728
target Thresh 1.9431996808877774
current state at start:  [-1.89490854  2.71180764]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.89490854,  2.71180764]), 'currentState': array([4.80507434, 3.02012166]), 'targetState': array([0.33042763, 0.53640331]), 'effectorPosition': array([0.12133437, 0.00387794])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9605626648009074
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.89490854,  2.71180764]), 'currentState': array([5.74607263, 2.46954839]), 'targetState': array([0.33042763, 0.53640331]), 'effectorPosition': array([0.50538153, 0.42366068])}
episode index:1729
target Thresh 1.9433131680010596
current state at start:  [-0.64332693  2.1959393 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.64332693,  2.1959393 ]), 'currentState': array([6.05190686, 2.23802934]), 'targetState': array([0.59329838, 0.49475793]), 'effectorPosition': array([0.55109827, 0.67724525])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9605854609484212
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.64332693,  2.1959393 ]), 'currentState': array([6.05190686, 2.23802934]), 'targetState': array([0.59329838, 0.49475793]), 'effectorPosition': array([0.55109827, 0.67724525])}
episode index:1730
target Thresh 1.943426428366938
current state at start:  [ 2.00251618 -1.9714446 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.00251618, -1.9714446 ]), 'currentState': array([1.50251618, 3.84842811]), 'targetState': array([1.13461111, 0.02911414]), 'effectorPosition': array([0.66426314, 0.19471214])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.960602453749722
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 2.00251618, -1.9714446 ]), 'currentState': array([1.01828126, 4.32827119]), 'targetState': array([1.13461111, 0.02911414]), 'effectorPosition': array([1.11733357, 0.0456396 ])}
episode index:1731
target Thresh 1.9435394624384548
current state at start:  [ 0.87867997 -2.265416  ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.87867997, -2.265416  ]), 'currentState': array([1.33861194, 3.6275351 ]), 'targetState': array([0.02814473, 0.58558158]), 'effectorPosition': array([0.48114728, 0.00519026])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.960047833395363
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([ 0.87867997, -2.265416  ]), 'currentState': array([2.33638181, 4.08947452]), 'targetState': array([0.02814473, 0.58558158]), 'effectorPosition': array([0.2968805 , 0.86316427])}
episode index:1732
target Thresh 1.9436522706677457
current state at start:  [-0.40360207 -2.57988266]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.40360207, -2.57988266]), 'currentState': array([5.72346312, 3.22487434]), 'targetState': array([-0.7227481 ,  0.01886445]), 'effectorPosition': array([-0.04123036, -0.0723318 ])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.9600426067459139
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([-0.40360207, -2.57988266]), 'currentState': array([4.57314471, 3.78709447]), 'targetState': array([-0.7227481 ,  0.01886445]), 'effectorPosition': array([-0.62370237, -0.11575579])}
episode index:1733
target Thresh 1.9437648535060443
current state at start:  [-2.37541954  1.81832291]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.37541954,  1.81832291]), 'currentState': array([4.40776576, 2.31832291]), 'targetState': array([ 0.82297749, -0.61419211]), 'effectorPosition': array([ 0.60357743, -0.52539554])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9600656502252991
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.37541954,  1.81832291]), 'currentState': array([4.40776576, 2.31832291]), 'targetState': array([ 0.82297749, -0.61419211]), 'effectorPosition': array([ 0.60357743, -0.52539554])}
episode index:1734
target Thresh 1.943877211403682
current state at start:  [-0.58896395  2.23329428]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.58896395,  2.23329428]), 'currentState': array([5.40657447, 2.67782644]), 'targetState': array([-0.10428465,  0.12447361]), 'effectorPosition': array([0.4113739 , 0.20499568])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9600659559081665
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([-0.58896395,  2.23329428]), 'currentState': array([4.62379135, 3.09552635]), 'targetState': array([-0.10428465,  0.12447361]), 'effectorPosition': array([ 0.04577553, -0.00513129])}
episode index:1735
target Thresh 1.9439893448100904
current state at start:  [-2.75853663  2.35743419]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.75853663,  2.35743419]), 'currentState': array([3.1009271 , 2.45012349]), 'targetState': array([-0.81156632, -0.44369414]), 'effectorPosition': array([-0.25542414, -0.62780451])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9600831990211226
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.75853663,  2.35743419]), 'currentState': array([2.70775373, 2.2213463 ]), 'targetState': array([-0.81156632, -0.44369414]), 'effectorPosition': array([-0.69233995, -0.55625275])}
episode index:1736
target Thresh 1.9441012541738034
current state at start:  [-2.73864464  1.63701588]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.73864464,  1.63701588]), 'currentState': array([4.03819158, 2.04952261]), 'targetState': array([ 0.0850622 , -0.74061906]), 'effectorPosition': array([ 0.35668575, -0.97543695])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9601004222801778
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.73864464,  1.63701588]), 'currentState': array([3.72589122, 2.18248381]), 'targetState': array([ 0.0850622 , -0.74061906]), 'effectorPosition': array([ 0.09647788, -0.91771044])}
episode index:1737
target Thresh 1.9442129399424586
current state at start:  [0.88223799 2.05565391]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.88223799, 2.05565391]), 'currentState': array([0.47484567, 2.4561497 ]), 'targetState': array([0.20457074, 0.04355175]), 'effectorPosition': array([-0.08854294,  0.66624522])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9601119295170706
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([0.88223799, 2.05565391]), 'currentState': array([5.97776105, 3.12168032]), 'targetState': array([0.20457074, 0.04355175]), 'effectorPosition': array([0.00617627, 0.01892991])}
episode index:1738
target Thresh 1.944324402562799
current state at start:  [-0.01328926  2.67972718]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.01328926,  2.67972718]), 'currentState': array([5.78705953, 2.7279293 ]), 'targetState': array([0.6390819 , 0.22025397]), 'effectorPosition': array([0.26552116, 0.31335231])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.960129116446618
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.01328926,  2.67972718]), 'currentState': array([5.53587775, 2.42671058]), 'targetState': array([0.6390819 , 0.22025397]), 'effectorPosition': array([0.62512818, 0.31444183])}
episode index:1739
target Thresh 1.9444356424806757
current state at start:  [ 1.25058595 -2.79545166]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.25058595, -2.79545166]), 'currentState': array([1.33271809, 3.88703637]), 'targetState': array([0.73781601, 0.65216523]), 'effectorPosition': array([0.7217118, 0.0977654])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.960146283621074
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.25058595, -2.79545166]), 'currentState': array([1.70094706, 4.26466657]), 'targetState': array([0.73781601, 0.65216523]), 'effectorPosition': array([0.82021288, 0.67928176])}
episode index:1740
target Thresh 1.9445466601410482
current state at start:  [-3.43417884  1.82942607]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.43417884,  1.82942607]), 'currentState': array([2.4064798 , 1.72814907]), 'targetState': array([-1.06615514, -0.65436813]), 'effectorPosition': array([-1.28790405, -0.16701719])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9601634310744794
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.43417884,  1.82942607]), 'currentState': array([2.85704192, 1.7187818 ]), 'targetState': array([-1.06615514, -0.65436813]), 'effectorPosition': array([-1.09592904, -0.70996316])}
episode index:1741
target Thresh 1.944657455987987
current state at start:  [ 3.64975673 -2.66016999]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.64975673, -2.66016999]), 'currentState': array([4.06414563, 3.96174899]), 'targetState': array([-1.1208048 , -0.00977665]), 'effectorPosition': array([-0.77485448,  0.18811365])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9601805588407972
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.64975673, -2.66016999]), 'currentState': array([4.32550866, 4.29356   ]), 'targetState': array([-1.1208048 , -0.00977665]), 'effectorPosition': array([-1.06990093, -0.20476853])}
episode index:1742
target Thresh 1.9447680304646762
current state at start:  [ 3.85932584 -1.8960736 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.85932584, -1.8960736 ]), 'currentState': array([4.34793715, 3.92358808]), 'targetState': array([-0.63485941, -0.39313304]), 'effectorPosition': array([-0.76195349, -0.02023148])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9601976669539121
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.85932584, -1.8960736 ]), 'currentState': array([4.75116249, 4.01436319]), 'targetState': array([-0.63485941, -0.39313304]), 'effectorPosition': array([-0.75168665, -0.38672241])}
episode index:1743
target Thresh 1.9448783840134136
current state at start:  [0.90378101 2.48525729]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.90378101, 2.48525729]), 'currentState': array([0.42578767, 1.98525729]), 'targetState': array([0.55021144, 1.1335396 ]), 'effectorPosition': array([0.16590463, 1.08031591])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9602034590026771
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([0.90378101, 2.48525729]), 'currentState': array([0.0615326 , 1.75173203]), 'targetState': array([0.55021144, 1.1335396 ]), 'effectorPosition': array([0.75800802, 1.03224207])}
episode index:1744
target Thresh 1.9449885170756136
current state at start:  [-1.4042892  -1.71708145]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.4042892 , -1.71708145]), 'currentState': array([4.83362225, 4.06610386]), 'targetState': array([-0.60899614, -0.39292   ]), 'effectorPosition': array([-0.74436143, -0.49140237])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9602262650433633
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.4042892 , -1.71708145]), 'currentState': array([4.83362225, 4.06610386]), 'targetState': array([-0.60899614, -0.39292   ]), 'effectorPosition': array([-0.74436143, -0.49140237])}
episode index:1745
target Thresh 1.9450984300918086
current state at start:  [1.47835943 3.03594201]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.47835943, 3.03594201]), 'currentState': array([1.39792415, 2.81239433]), 'targetState': array([-0.21234525,  0.35154217]), 'effectorPosition': array([-0.30922913,  0.10850675])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9602433175834301
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.47835943, 3.03594201]), 'currentState': array([0.95060005, 2.59251302]), 'targetState': array([-0.21234525,  0.35154217]), 'effectorPosition': array([-0.33927296,  0.42294611])}
episode index:1746
target Thresh 1.9452081235016505
current state at start:  [ 1.16690844 -2.2915489 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.16690844, -2.2915489 ]), 'currentState': array([1.47564846, 4.4511293 ]), 'targetState': array([1.0310163 , 0.55480045]), 'effectorPosition': array([1.03216068, 0.64656705])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9602660746998677
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.16690844, -2.2915489 ]), 'currentState': array([1.47564846, 4.4511293 ]), 'targetState': array([1.0310163 , 0.55480045]), 'effectorPosition': array([1.03216068, 0.64656705])}
episode index:1747
target Thresh 1.9453175977439137
current state at start:  [-1.09344225  2.70443842]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.09344225,  2.70443842]), 'currentState': array([5.66831963, 2.25275078]), 'targetState': array([1.0139121 , 0.89498968]), 'effectorPosition': array([0.74981247, 0.42090159])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9602718143596505
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-1.09344225,  2.70443842]), 'currentState': array([5.99521754, 1.8412605 ]), 'targetState': array([1.0139121 , 0.89498968]), 'effectorPosition': array([0.97632572, 0.71584255])}
episode index:1748
target Thresh 1.9454268532564947
current state at start:  [-1.54964036  2.4994774 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.54964036,  2.4994774 ]), 'currentState': array([5.16619462, 2.59649074]), 'targetState': array([0.96532492, 0.68483703]), 'effectorPosition': array([0.52955865, 0.09705013])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9602831512296564
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.54964036,  2.4994774 ]), 'currentState': array([5.95455403, 2.05305287]), 'targetState': array([0.96532492, 0.68483703]), 'effectorPosition': array([0.79346328, 0.66547497])}
episode index:1749
target Thresh 1.9455358904764162
current state at start:  [-0.72728689  1.99307235]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.72728689,  1.99307235]), 'currentState': array([5.05589841, 2.37946092]), 'targetState': array([ 0.17384056, -0.02449336]), 'effectorPosition': array([ 0.74329567, -0.02792867])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9602944751432394
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-0.72728689,  1.99307235]), 'currentState': array([4.14197038, 2.85393128]), 'targetState': array([ 0.17384056, -0.02449336]), 'effectorPosition': array([ 0.21660405, -0.18778367])}
episode index:1750
target Thresh 1.9456447098398266
current state at start:  [0.8212608  2.46161416]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.8212608 , 2.46161416]), 'currentState': array([0.3212608 , 2.83097639]), 'targetState': array([0.08249082, 0.32577146]), 'effectorPosition': array([-0.05110529,  0.30511877])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9603171510569212
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.8212608 , 2.46161416]), 'currentState': array([0.3212608 , 2.83097639]), 'targetState': array([0.08249082, 0.32577146]), 'effectorPosition': array([-0.05110529,  0.30511877])}
episode index:1751
target Thresh 1.9457533117820043
current state at start:  [-1.11129264  1.9825056 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.11129264,  1.9825056 ]), 'currentState': array([4.71396064, 2.34979357]), 'targetState': array([ 0.4986676 , -0.10420291]), 'effectorPosition': array([ 0.71208499, -0.29631502])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9603340933222996
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.11129264,  1.9825056 ]), 'currentState': array([4.41393664, 2.5647762 ]), 'targetState': array([ 0.4986676 , -0.10420291]), 'effectorPosition': array([ 0.47367445, -0.31500219])}
episode index:1752
target Thresh 1.9458616967373565
current state at start:  [-3.17091154  1.72785756]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.17091154,  1.72785756]), 'currentState': array([2.82167755, 1.86499021]), 'targetState': array([-0.85792918, -1.01108211]), 'effectorPosition': array([-0.97498051, -0.68518325])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9603510162582253
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.17091154,  1.72785756]), 'currentState': array([3.16617469, 1.83360641]), 'targetState': array([-0.85792918, -1.01108211]), 'effectorPosition': array([-0.7162456, -0.9835659])}
episode index:1753
target Thresh 1.9459698651394237
current state at start:  [ 1.89476924 -2.20047932]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.89476924, -2.20047932]), 'currentState': array([1.3961335 , 3.66829754]), 'targetState': array([ 0.76629837, -0.00788189]), 'effectorPosition': array([0.51859145, 0.04611465])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9603679198977588
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.89476924, -2.20047932]), 'currentState': array([1.10320742, 4.02384044]), 'targetState': array([ 0.76629837, -0.00788189]), 'effectorPosition': array([ 0.85361306, -0.02259615])}
episode index:1754
target Thresh 1.9460778174208793
current state at start:  [-1.95135084  2.31432197]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.95135084,  2.31432197]), 'currentState': array([3.93555233, 2.75535024]), 'targetState': array([-0.20659356,  0.03701337]), 'effectorPosition': array([ 0.21700132, -0.31661995])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9603848042738855
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.95135084,  2.31432197]), 'currentState': array([3.63610196, 3.08694953]), 'targetState': array([-0.20659356,  0.03701337]), 'effectorPosition': array([ 0.02460695, -0.04878141])}
episode index:1755
target Thresh 1.9461855540135327
current state at start:  [-2.61765444  3.05333742]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.61765444,  3.05333742]), 'currentState': array([3.72519257, 3.4476982 ]), 'targetState': array([0.13964597, 0.31360339]), 'effectorPosition': array([-0.20484352,  0.22585476])}
done in step count: 14
reward sum = 0.8687458127689782
running average episode reward sum: 0.9603326180600444
{'reset': False, 'endBeforeDone': False, 'stepCount': 15, 'initial state': array([-2.61765444,  3.05333742]), 'currentState': array([6.01414006, 2.55318773]), 'targetState': array([0.13964597, 0.31360339]), 'effectorPosition': array([0.3096574 , 0.49036534])}
episode index:1756
target Thresh 1.9462930753483303
current state at start:  [ 3.85538677 -1.67661757]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.85538677, -1.67661757]), 'currentState': array([4.35491482, 4.65430802]), 'targetState': array([-1.26541039, -0.27470476]), 'effectorPosition': array([-1.26480155, -0.53308576])}
done in step count: 30
reward sum = 0.7397003733882802
running average episode reward sum: 0.9602070447847617
{'reset': False, 'endBeforeDone': False, 'stepCount': 31, 'initial state': array([ 3.85538677, -1.67661757]), 'currentState': array([4.34194718, 4.64145669]), 'targetState': array([-1.26541039, -0.27470476]), 'effectorPosition': array([-1.26619283, -0.50498522])}
episode index:1757
target Thresh 1.9464003818553577
current state at start:  [ 0.9920384  -2.39678037]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.9920384 , -2.39678037]), 'currentState': array([1.45729307, 3.38640493]), 'targetState': array([-0.09394948,  0.13169586]), 'effectorPosition': array([0.24419171, 0.00217407])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.960223991858263
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.9920384 , -2.39678037]), 'currentState': array([1.87986353, 2.9461405 ]), 'targetState': array([-0.09394948,  0.13169586]), 'effectorPosition': array([-0.19079939, -0.04093504])}
episode index:1758
target Thresh 1.9465074739638413
current state at start:  [ 3.87695231 -1.60431303]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.87695231, -1.60431303]), 'currentState': array([3.39930572, 4.29315661]), 'targetState': array([-0.91487731,  0.4729225 ]), 'effectorPosition': array([-0.80615746,  0.73211428])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9602409196627779
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.87695231, -1.60431303]), 'currentState': array([3.71922879, 4.36930361]), 'targetState': array([-0.91487731,  0.4729225 ]), 'effectorPosition': array([-1.07016184,  0.42657372])}
episode index:1759
target Thresh 1.9466143521021493
current state at start:  [ 0.52030225 -2.56393724]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.52030225, -2.56393724]), 'currentState': array([0.94107563, 3.25726654]), 'targetState': array([-0.00168161,  0.00143666]), 'effectorPosition': array([ 0.09721398, -0.06256978])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9602635100493332
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.52030225, -2.56393724]), 'currentState': array([0.94107563, 3.25726654]), 'targetState': array([-0.00168161,  0.00143666]), 'effectorPosition': array([ 0.09721398, -0.06256978])}
episode index:1760
target Thresh 1.9467210166977944
current state at start:  [-1.10168691  1.99676777]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.10168691,  1.99676777]), 'currentState': array([4.92688073, 2.28270216]), 'targetState': array([ 0.60472258, -0.05296451]), 'effectorPosition': array([ 0.81356872, -0.1776236 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9602860747795721
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.10168691,  1.99676777]), 'currentState': array([4.92688073, 2.28270216]), 'targetState': array([ 0.60472258, -0.05296451]), 'effectorPosition': array([ 0.81356872, -0.1776236 ])}
episode index:1761
target Thresh 1.9468274681774353
current state at start:  [-3.02470393  2.31910107]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.02470393,  2.31910107]), 'currentState': array([3.75848138, 2.74530349]), 'targetState': array([ 0.30591698, -0.58652508]), 'effectorPosition': array([ 0.16008416, -0.35968546])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9603029385282783
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.02470393,  2.31910107]), 'currentState': array([4.15468498, 2.30294693]), 'targetState': array([ 0.30591698, -0.58652508]), 'effectorPosition': array([ 0.45558324, -0.67490931])}
episode index:1762
target Thresh 1.9469337069668782
current state at start:  [1.2767153  2.71278861]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.2767153 , 2.71278861]), 'currentState': array([0.86487948, 2.82487046]), 'targetState': array([0.0287766 , 0.24747036]), 'effectorPosition': array([-0.2047544,  0.2399017])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9603254552959878
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.2767153 , 2.71278861]), 'currentState': array([0.86487948, 2.82487046]), 'targetState': array([0.0287766 , 0.24747036]), 'effectorPosition': array([-0.2047544,  0.2399017])}
episode index:1763
target Thresh 1.947039733491078
current state at start:  [0.60153722 2.80261812]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.60153722, 2.80261812]), 'currentState': array([1.08548676, 2.31014401]), 'targetState': array([-0.34322222,  1.27568106]), 'effectorPosition': array([-0.50142328,  0.63321607])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.960320163116058
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([0.60153722, 2.80261812]), 'currentState': array([0.82481425, 1.69605829]), 'targetState': array([-0.34322222,  1.27568106]), 'effectorPosition': array([-0.13476644,  1.31604282])}
episode index:1764
target Thresh 1.947145548174141
current state at start:  [-2.1047438   2.16831245]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.1047438 ,  2.16831245]), 'currentState': array([3.84261273, 2.64718099]), 'targetState': array([-0.1824222 , -0.03080733]), 'effectorPosition': array([ 0.21454766, -0.43985592])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9603369788876637
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.1047438 ,  2.16831245]), 'currentState': array([3.52790986, 3.02307729]), 'targetState': array([-0.1824222 , -0.03080733]), 'effectorPosition': array([ 0.03805194, -0.11216732])}
episode index:1765
target Thresh 1.9472511514393267
current state at start:  [ 1.88997262 -2.5268612 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.88997262, -2.5268612 ]), 'currentState': array([2.38152903, 3.30045363]), 'targetState': array([-0.46591881, -0.26764841]), 'effectorPosition': array([0.09986377, 0.1233329 ])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9603481697263456
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 1.88997262, -2.5268612 ]), 'currentState': array([2.73747207, 2.54474609]), 'targetState': array([-0.46591881, -0.26764841]), 'effectorPosition': array([-0.37996032, -0.44878281])}
episode index:1766
target Thresh 1.9473565437090474
current state at start:  [-2.8299613   1.99373064]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.8299613 ,  1.99373064]), 'currentState': array([3.92544729, 1.76446719]), 'targetState': array([-0.21548391, -1.35745655]), 'effectorPosition': array([ 0.1209191 , -1.26509041])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.960364950615012
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.8299613 ,  1.99373064]), 'currentState': array([3.54390395, 1.68360961]), 'targetState': array([-0.21548391, -1.35745655]), 'effectorPosition': array([-0.4275152, -1.2617775])}
episode index:1767
target Thresh 1.947461725404873
current state at start:  [ 2.91832689 -2.24559302]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.91832689, -2.24559302]), 'currentState': array([3.4140667 , 3.76811802]), 'targetState': array([-0.58950089,  0.24847613]), 'effectorPosition': array([-0.3407146 ,  0.51358951])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9603817125207728
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 2.91832689, -2.24559302]), 'currentState': array([3.87581143, 3.90313468]), 'targetState': array([-0.58950089,  0.24847613]), 'effectorPosition': array([-0.66738928,  0.32717874])}
episode index:1768
target Thresh 1.94756669694753
current state at start:  [ 2.63411436 -3.00521548]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.63411436, -3.00521548]), 'currentState': array([2.86366785, 2.90297361]), 'targetState': array([-0.3208857, -0.1215251]), 'effectorPosition': array([-0.09209557, -0.21951718])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9604041083870697
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.63411436, -3.00521548]), 'currentState': array([2.86366785, 2.90297361]), 'targetState': array([-0.3208857, -0.1215251]), 'effectorPosition': array([-0.09209557, -0.21951718])}
episode index:1769
target Thresh 1.947671458756905
current state at start:  [-2.21151526  1.7398698 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.21151526,  1.7398698 ]), 'currentState': array([3.57167005, 1.82002963]), 'targetState': array([-0.21828226, -1.11115706]), 'effectorPosition': array([-0.28067659, -1.19494712])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.960426478947303
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.21151526,  1.7398698 ]), 'currentState': array([3.57167005, 1.82002963]), 'targetState': array([-0.21828226, -1.11115706]), 'effectorPosition': array([-0.28067659, -1.19494712])}
episode index:1770
target Thresh 1.9477760112520452
current state at start:  [-0.56170881  1.78638833]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.56170881,  1.78638833]), 'currentState': array([5.49520109, 2.19266071]), 'targetState': array([0.23653128, 0.18130096]), 'effectorPosition': array([0.87063265, 0.27730077])}
done in step count: 59
reward sum = 0.5526834771623851
running average episode reward sum: 0.9601962457447142
{'reset': False, 'endBeforeDone': False, 'stepCount': 60, 'initial state': array([-0.56170881,  1.78638833]), 'currentState': array([4.62923113, 2.86507429]), 'targetState': array([0.23653128, 0.18130096]), 'effectorPosition': array([ 0.26890914, -0.06053354])}
episode index:1771
target Thresh 1.947880354851161
current state at start:  [ 3.1394179  -2.15679212]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.1394179 , -2.15679212]), 'currentState': array([3.6394179 , 4.26794392]), 'targetState': array([-0.82975759,  0.43718445]), 'effectorPosition': array([-0.93197795,  0.52105974])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9602187083599824
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.1394179 , -2.15679212]), 'currentState': array([3.6394179 , 4.26794392]), 'targetState': array([-0.82975759,  0.43718445]), 'effectorPosition': array([-0.93197795,  0.52105974])}
episode index:1772
target Thresh 1.9479844899716263
current state at start:  [ 3.17535644 -2.03638905]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.17535644, -2.03638905]), 'currentState': array([3.06896896, 4.48807802]), 'targetState': array([-0.45488162,  0.8237743 ]), 'effectorPosition': array([-0.70477368,  1.02879774])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9596771298442689
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([ 3.17535644, -2.03638905]), 'currentState': array([2.82758718, 4.55505889]), 'targetState': array([-0.45488162,  0.8237743 ]), 'effectorPosition': array([-0.4970274 ,  1.19983336])}
episode index:1773
target Thresh 1.9480884170299824
current state at start:  [-0.00277514  2.35338554]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.00277514,  2.35338554]), 'currentState': array([0.44874593, 2.11580068]), 'targetState': array([0.29425643, 1.15548472]), 'effectorPosition': array([0.06291403, 0.97938665])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9596942227812225
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.00277514,  2.35338554]), 'currentState': array([0.2297332 , 2.06639113]), 'targetState': array([0.29425643, 1.15548472]), 'effectorPosition': array([0.31034627, 0.97599961])}
episode index:1774
target Thresh 1.9481921364419374
current state at start:  [ 2.5473503  -2.44324027]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.5473503 , -2.44324027]), 'currentState': array([2.42978771, 3.44399731]), 'targetState': array([0.04862729, 0.09780053]), 'effectorPosition': array([0.16017559, 0.25514226])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9597169302613457
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.5473503 , -2.44324027]), 'currentState': array([2.42978771, 3.44399731]), 'targetState': array([0.04862729, 0.09780053]), 'effectorPosition': array([0.16017559, 0.25514226])}
episode index:1775
target Thresh 1.948295648622369
current state at start:  [-1.19397436  1.79301619]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.19397436,  1.79301619]), 'currentState': array([4.58921095, 2.11062958]), 'targetState': array([ 0.62377219, -0.43481526]), 'effectorPosition': array([ 0.79158092, -0.58771907])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9597396121699824
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.19397436,  1.79301619]), 'currentState': array([4.58921095, 2.11062958]), 'targetState': array([ 0.62377219, -0.43481526]), 'effectorPosition': array([ 0.79158092, -0.58771907])}
episode index:1776
target Thresh 1.9483989539853261
current state at start:  [ 1.51041301 -1.81453811]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.51041301, -1.81453811]), 'currentState': array([1.95940797, 4.27629064]), 'targetState': array([0.45065922, 0.86657361]), 'effectorPosition': array([0.61996877, 0.87796716])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9597622685503032
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.51041301, -1.81453811]), 'currentState': array([1.95940797, 4.27629064]), 'targetState': array([0.45065922, 0.86657361]), 'effectorPosition': array([0.61996877, 0.87796716])}
episode index:1777
target Thresh 1.9485020529440304
current state at start:  [-3.03869159  1.74876903]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.03869159,  1.74876903]), 'currentState': array([3.67737167, 2.03560365]), 'targetState': array([-0.25523991, -1.26653798]), 'effectorPosition': array([-0.01808355, -1.05031987])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9597792751484189
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.03869159,  1.74876903]), 'currentState': array([3.41485455, 1.81643444]), 'targetState': array([-0.25523991, -1.26653798]), 'effectorPosition': array([-0.46697048, -1.13823895])}
episode index:1778
target Thresh 1.948604945910878
current state at start:  [1.92724208 2.35856193]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.92724208, 2.35856193]), 'currentState': array([1.65271516, 2.85856193]), 'targetState': array([-0.01832925, -0.14643065]), 'effectorPosition': array([-0.28158617,  0.01680145])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9597962626272561
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.92724208, 2.35856193]), 'currentState': array([1.48779453, 3.17511827]), 'targetState': array([-0.01832925, -0.14643065]), 'effectorPosition': array([ 0.03345053, -0.00221898])}
episode index:1779
target Thresh 1.9487076332974405
current state at start:  [ 2.80845297 -2.19486765]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.80845297, -2.19486765]), 'currentState': array([2.30845297, 4.54888704]), 'targetState': array([0.71489837, 0.88095988]), 'effectorPosition': array([0.16709614, 1.28317186])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9598076692212858
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 2.80845297, -2.19486765]), 'currentState': array([1.69819916, 4.62689999]), 'targetState': array([0.71489837, 0.88095988]), 'effectorPosition': array([0.87206328, 1.0337968 ])}
episode index:1780
target Thresh 1.948810115514468
current state at start:  [-3.40650916  2.20664109]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.40650916,  2.20664109]), 'currentState': array([2.54258341, 2.69839348]), 'targetState': array([-0.18656162, -0.33053431]), 'effectorPosition': array([-0.32158016, -0.29969558])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9598302365041487
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.40650916,  2.20664109]), 'currentState': array([2.54258341, 2.69839348]), 'targetState': array([-0.18656162, -0.33053431]), 'effectorPosition': array([-0.32158016, -0.29969558])}
episode index:1781
target Thresh 1.948912392971889
current state at start:  [-1.18911673  1.92513727]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.18911673,  1.92513727]), 'currentState': array([4.59596884, 1.73697885]), 'targetState': array([ 0.50828513, -1.15156644]), 'effectorPosition': array([ 0.88260477, -0.94348899])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.959847166786694
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.18911673,  1.92513727]), 'currentState': array([4.1681078 , 1.64501688]), 'targetState': array([ 0.50828513, -1.15156644]), 'effectorPosition': array([ 0.37373756, -1.30844005])}
episode index:1782
target Thresh 1.949014466078814
current state at start:  [-0.13335833 -1.5905805 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.13335833, -1.5905805 ]), 'currentState': array([5.80691803, 4.26455903]), 'targetState': array([-0.02070492, -0.68583609]), 'effectorPosition': array([ 0.09063532, -1.06102038])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.959864078078457
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.13335833, -1.5905805 ]), 'currentState': array([5.62085185, 3.94596502]), 'targetState': array([-0.02070492, -0.68583609]), 'effectorPosition': array([-0.20137002, -0.75652038])}
episode index:1783
target Thresh 1.9491163352435352
current state at start:  [0.4928138  2.46867118]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.4928138 , 2.46867118]), 'currentState': array([0.9928138 , 2.29425081]), 'targetState': array([-0.56063643,  0.94309782]), 'effectorPosition': array([-0.44310232,  0.69260715])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9598809704113727
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.4928138 , 2.46867118]), 'currentState': array([1.2874775 , 1.98219564]), 'targetState': array([-0.56063643,  0.94309782]), 'effectorPosition': array([-0.7122652 ,  0.83240238])}
episode index:1784
target Thresh 1.9492180008735296
current state at start:  [ 2.89355837 -2.25594608]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.89355837, -2.25594608]), 'currentState': array([2.96449788, 3.55801859]), 'targetState': array([-0.03680351,  0.17509728]), 'effectorPosition': array([-0.01286292,  0.41322344])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.959903446058201
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.89355837, -2.25594608]), 'currentState': array([2.96449788, 3.55801859]), 'targetState': array([-0.03680351,  0.17509728]), 'effectorPosition': array([-0.01286292,  0.41322344])}
episode index:1785
target Thresh 1.9493194633754598
current state at start:  [ 4.18449954 -2.23284009]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.18449954, -2.23284009]), 'currentState': array([3.90918113, 3.57238532]), 'targetState': array([-0.24124429,  0.29203359]), 'effectorPosition': array([-0.35572121,  0.2370493 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9599258965363319
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.18449954, -2.23284009]), 'currentState': array([3.90918113, 3.57238532]), 'targetState': array([-0.24124429,  0.29203359]), 'effectorPosition': array([-0.35572121,  0.2370493 ])}
episode index:1786
target Thresh 1.949420723155176
current state at start:  [-3.58150832  2.35863601]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.58150832,  2.35863601]), 'currentState': array([2.21088921, 2.71050148]), 'targetState': array([-0.12314533,  0.13539743]), 'effectorPosition': array([-0.38978651, -0.17619825])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9599427259171174
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.58150832,  2.35863601]), 'currentState': array([1.76205619, 3.0166931 ]), 'targetState': array([-0.12314533,  0.13539743]), 'effectorPosition': array([-0.12378432, -0.01603344])}
episode index:1787
target Thresh 1.9495217806177172
current state at start:  [-2.24568516  2.00676398]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.24568516,  2.00676398]), 'currentState': array([3.72158614, 2.29061799]), 'targetState': array([-0.07923361, -0.29219551]), 'effectorPosition': array([ 0.1270425 , -0.81569543])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9599539995603404
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-2.24568516,  2.00676398]), 'currentState': array([3.437516 , 2.7396954]), 'targetState': array([-0.07923361, -0.29219551]), 'effectorPosition': array([ 0.03785674, -0.39739885])}
episode index:1788
target Thresh 1.9496226361673137
current state at start:  [-0.75091379 -2.35615093]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.75091379, -2.35615093]), 'currentState': array([5.93006619, 3.97373948]), 'targetState': array([ 0.16520606, -0.58466608]), 'effectorPosition': array([ 0.05085511, -0.80674269])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.959976384132973
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.75091379, -2.35615093]), 'currentState': array([5.93006619, 3.97373948]), 'targetState': array([ 0.16520606, -0.58466608]), 'effectorPosition': array([ 0.05085511, -0.80674269])}
episode index:1789
target Thresh 1.9497232902073875
current state at start:  [0.87213877 1.92766456]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.87213877, 1.92766456]), 'currentState': array([0.63371222, 2.3075823 ]), 'targetState': array([-0.16943181,  0.59802077]), 'effectorPosition': array([-0.17417239,  0.79110178])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9599987436949099
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.87213877, 1.92766456]), 'currentState': array([0.63371222, 2.3075823 ]), 'targetState': array([-0.16943181,  0.59802077]), 'effectorPosition': array([-0.17417239,  0.79110178])}
episode index:1790
target Thresh 1.9498237431405554
current state at start:  [-1.5094967  -1.61961881]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.5094967 , -1.61961881]), 'currentState': array([5.27368861, 4.76904219]), 'targetState': array([-0.29228549, -1.20987508]), 'effectorPosition': array([-0.28277935, -1.42593186])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9600210782880451
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.5094967 , -1.61961881]), 'currentState': array([5.27368861, 4.76904219]), 'targetState': array([-0.29228549, -1.20987508]), 'effectorPosition': array([-0.28277935, -1.42593186])}
episode index:1791
target Thresh 1.9499239953686287
current state at start:  [0.57377389 2.28828909]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.57377389, 2.28828909]), 'currentState': array([0.09569156, 2.75728707]), 'targetState': array([ 0.32253883, -0.10199339]), 'effectorPosition': array([0.03678577, 0.38016943])}
done in step count: 17
reward sum = 0.8429431933839268
running average episode reward sum: 0.9599557446469156
{'reset': False, 'endBeforeDone': False, 'stepCount': 18, 'initial state': array([0.57377389, 2.28828909]), 'currentState': array([0.34563642, 3.37866855]), 'targetState': array([ 0.32253883, -0.10199339]), 'effectorPosition': array([ 0.10588687, -0.21149514])}
episode index:1792
target Thresh 1.950024047292617
current state at start:  [-2.15717928  2.78122705]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.15717928,  2.78122705]), 'currentState': array([4.06662491, 2.29730165]), 'targetState': array([ 0.2741775 , -0.47174836]), 'effectorPosition': array([ 0.39493336, -0.71798662])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.95996697959134
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-2.15717928,  2.78122705]), 'currentState': array([4.02536463, 2.32628137]), 'targetState': array([ 0.2741775 , -0.47174836]), 'effectorPosition': array([ 0.36341807, -0.70472948])}
episode index:1793
target Thresh 1.9501238993127274
current state at start:  [-0.83278617 -2.30171857]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.83278617, -2.30171857]), 'currentState': array([5.78505981, 3.48584434]), 'targetState': array([0.18532568, 0.02788035]), 'effectorPosition': array([-0.10970506, -0.32451235])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9599837204053917
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.83278617, -2.30171857]), 'currentState': array([5.9821858 , 3.13428604]), 'targetState': array([0.18532568, 0.02788035]), 'effectorPosition': array([0.0021917 , 0.00697014])}
episode index:1794
target Thresh 1.950223551828369
current state at start:  [-2.72247806  1.92500196]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.72247806,  1.92500196]), 'currentState': array([4.04765613, 2.32112859]), 'targetState': array([ 0.4462388 , -0.78563251]), 'effectorPosition': array([ 0.37948972, -0.70158669])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9600060135973664
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.72247806,  1.92500196]), 'currentState': array([4.04765613, 2.32112859]), 'targetState': array([ 0.4462388 , -0.78563251]), 'effectorPosition': array([ 0.37948972, -0.70158669])}
episode index:1795
target Thresh 1.9503230052381513
current state at start:  [-0.31264418 -2.51128474]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.31264418, -2.51128474]), 'currentState': array([0.16287757, 4.26781211]), 'targetState': array([ 0.80565727, -0.81982934]), 'effectorPosition': array([ 0.70877637, -0.79842608])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9600282819639603
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.31264418, -2.51128474]), 'currentState': array([0.16287757, 4.26781211]), 'targetState': array([ 0.80565727, -0.81982934]), 'effectorPosition': array([ 0.70877637, -0.79842608])}
episode index:1796
target Thresh 1.9504222599398884
current state at start:  [-0.79752099 -2.80407793]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.79752099, -2.80407793]), 'currentState': array([5.97853283, 3.96892655]), 'targetState': array([ 0.67997042, -0.81827896]), 'effectorPosition': array([ 0.08746754, -0.79916701])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9600449607163454
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.79752099, -2.80407793]), 'currentState': array([0.16198725, 4.37756348]), 'targetState': array([ 0.67997042, -0.81827896]), 'effectorPosition': array([ 0.81492973, -0.82382086])}
episode index:1797
target Thresh 1.950521316330599
current state at start:  [-1.4207929 -2.2164699]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.4207929, -2.2164699]), 'currentState': array([4.98988606, 4.4977286 ]), 'targetState': array([-0.8061929 , -1.00855094]), 'effectorPosition': array([-0.72407709, -1.02453948])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9600671826514309
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.4207929, -2.2164699]), 'currentState': array([4.98988606, 4.4977286 ]), 'targetState': array([-0.8061929 , -1.00855094]), 'effectorPosition': array([-0.72407709, -1.02453948])}
episode index:1798
target Thresh 1.950620174806509
current state at start:  [ 2.39495182 -2.60041238]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.39495182, -2.60041238]), 'currentState': array([2.08183268, 4.18277293]), 'targetState': array([0.54397901, 0.95070293]), 'effectorPosition': array([0.51074595, 0.85365949])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9600893798817525
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.39495182, -2.60041238]), 'currentState': array([2.08183268, 4.18277293]), 'targetState': array([0.54397901, 0.95070293]), 'effectorPosition': array([0.51074595, 0.85365949])}
episode index:1799
target Thresh 1.9507188357630525
current state at start:  [0.72921984 2.62731095]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.72921984, 2.62731095]), 'currentState': array([0.95589162, 2.96794059]), 'targetState': array([-0.31067784,  0.29740761]), 'effectorPosition': array([-0.13245604,  0.11195864])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9601059968929293
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.72921984, 2.62731095]), 'currentState': array([1.30878852, 2.56387137]), 'targetState': array([-0.31067784,  0.29740761]), 'effectorPosition': array([-0.48544191,  0.29820733])}
episode index:1800
target Thresh 1.9508172995948734
current state at start:  [-0.78713494  2.51318773]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.78713494,  2.51318773]), 'currentState': array([4.99605037, 2.67729983]), 'targetState': array([ 0.21482764, -0.17310446]), 'effectorPosition': array([0.45952335, 0.0236933 ])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9601116565281914
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-0.78713494,  2.51318773]), 'currentState': array([3.95777167, 2.68217196]), 'targetState': array([ 0.21482764, -0.17310446]), 'effectorPosition': array([ 0.25202395, -0.37929523])}
episode index:1801
target Thresh 1.9509155666958269
current state at start:  [-2.04168485 -1.8614264 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.04168485, -1.8614264 ]), 'currentState': array([4.67955434, 4.65195074]), 'targetState': array([-0.73136365, -1.12697859]), 'effectorPosition': array([-1.02848198, -0.9063233 ])}
done in step count: 66
reward sum = 0.5151371174238033
running average episode reward sum: 0.9598647228216962
{'reset': False, 'endBeforeDone': False, 'stepCount': 67, 'initial state': array([-2.04168485, -1.8614264 ]), 'currentState': array([4.84717601, 4.53876521]), 'targetState': array([-0.73136365, -1.12697859]), 'effectorPosition': array([-0.86486667, -0.952103  ])}
episode index:1802
target Thresh 1.951013637458982
current state at start:  [0.38821898 2.17151811]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.38821898, 2.17151811]), 'currentState': array([0.88821898, 2.67151811]), 'targetState': array([-0.67120779,  0.38572633]), 'effectorPosition': array([-0.28304898,  0.36988406])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9598814367857441
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.38821898, 2.17151811]), 'currentState': array([1.38821898, 2.41736018]), 'targetState': array([-0.67120779,  0.38572633]), 'effectorPosition': array([-0.60597708,  0.36711772])}
episode index:1803
target Thresh 1.9511115122766214
current state at start:  [-3.69926231  2.56660412]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.69926231,  2.56660412]), 'currentState': array([2.28484716, 2.48219056]), 'targetState': array([-1.33307868,  0.33567779]), 'effectorPosition': array([-0.60027887, -0.24279193])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9598872114881911
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-3.69926231,  2.56660412]), 'currentState': array([2.16671489, 1.6992905 ]), 'targetState': array([-1.33307868,  0.33567779]), 'effectorPosition': array([-1.31015796,  0.16493753])}
episode index:1804
target Thresh 1.9512091915402447
current state at start:  [ 3.15341184 -2.50863947]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.15341184, -2.50863947]), 'currentState': array([2.76371715, 4.27454583]), 'targetState': array([0.53579721, 1.27912715]), 'effectorPosition': array([-0.20123225,  1.05429193])}
done in step count: 18
reward sum = 0.8345137614500875
running average episode reward sum: 0.9598177525131008
{'reset': False, 'endBeforeDone': False, 'stepCount': 19, 'initial state': array([ 3.15341184, -2.50863947]), 'currentState': array([1.94747083, 4.94901869]), 'targetState': array([0.53579721, 1.27912715]), 'effectorPosition': array([0.44992051, 1.50546561])}
episode index:1805
target Thresh 1.9513066756405693
current state at start:  [ 3.71957545 -1.95364014]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.71957545, -1.95364014]), 'currentState': array([4.12729065, 3.82954517]), 'targetState': array([-0.36962096, -0.14604043]), 'effectorPosition': array([-0.65495429,  0.16105738])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9598344647210115
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.71957545, -1.95364014]), 'currentState': array([4.4799688 , 3.56006232]), 'targetState': array([-0.36962096, -0.14604043]), 'effectorPosition': array([-0.41531131,  0.00963086])}
episode index:1806
target Thresh 1.9514039649675314
current state at start:  [-3.10415361  1.71197471]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.10415361,  1.71197471]), 'currentState': array([3.10053735, 1.7290192 ]), 'targetState': array([-0.78395628, -1.15720291]), 'effectorPosition': array([-0.88225768, -0.95209996])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.959856692466047
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.10415361,  1.71197471]), 'currentState': array([3.10053735, 1.7290192 ]), 'targetState': array([-0.78395628, -1.15720291]), 'effectorPosition': array([-0.88225768, -0.95209996])}
episode index:1807
target Thresh 1.9515010599102887
current state at start:  [-1.47290812 -2.24571372]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.47290812, -2.24571372]), 'currentState': array([4.43847396, 3.70630988]), 'targetState': array([-0.8454092 , -0.02000244]), 'effectorPosition': array([-0.55722341, -0.00470508])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9598733646494175
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.47290812, -2.24571372]), 'currentState': array([4.3486812 , 4.06580278]), 'targetState': array([-0.8454092 , -0.02000244]), 'effectorPosition': array([-0.88735365, -0.08759608])}
episode index:1808
target Thresh 1.9515979608572207
current state at start:  [0.65130825 2.1802483 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.65130825, 2.1802483 ]), 'currentState': array([1.15130825, 2.59833331]), 'targetState': array([-0.61561793,  0.57117974]), 'effectorPosition': array([-0.41347121,  0.3420304 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9598900184003023
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.65130825, 2.1802483 ]), 'currentState': array([1.35021027, 2.09833331]), 'targetState': array([-0.61561793,  0.57117974]), 'effectorPosition': array([-0.73445777,  0.6736159 ])}
episode index:1809
target Thresh 1.9516946681959317
current state at start:  [ 3.67690625 -2.5138389 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.67690625, -2.5138389 ]), 'currentState': array([3.21294352, 4.03359725]), 'targetState': array([0.1704127 , 0.95324488]), 'effectorPosition': array([-0.42668761,  0.74982104])}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9598694961218645
{'reset': False, 'endBeforeDone': False, 'stepCount': 9, 'initial state': array([ 3.67690625, -2.5138389 ]), 'currentState': array([2.38395467, 4.43636273]), 'targetState': array([0.1704127 , 0.95324488]), 'effectorPosition': array([0.13271841, 1.1988815 ])}
episode index:1810
target Thresh 1.9517911823132512
current state at start:  [ 0.66888444 -1.856837  ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.66888444, -1.856837  ]), 'currentState': array([0.91708613, 3.92634831]), 'targetState': array([ 0.44681274, -0.17728465]), 'effectorPosition': array([ 0.73880657, -0.19759286])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9598861336171036
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.66888444, -1.856837  ]), 'currentState': array([1.07744036, 3.49729193]), 'targetState': array([ 0.44681274, -0.17728465]), 'effectorPosition': array([ 0.33636196, -0.10979178])}
episode index:1811
target Thresh 1.9518875035952357
current state at start:  [-1.84258961  2.07006235]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.84258961,  2.07006235]), 'currentState': array([4.37331372, 2.4822383 ]), 'targetState': array([0.26947176, 0.11025682]), 'effectorPosition': array([ 0.50800632, -0.40143958])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9598972891725026
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.84258961,  2.07006235]), 'currentState': array([4.51106635, 2.79556915]), 'targetState': array([0.26947176, 0.11025682]), 'effectorPosition': array([ 0.32045748, -0.1258943 ])}
episode index:1812
target Thresh 1.9519836324271704
current state at start:  [-2.0289705   2.00759721]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.0289705 ,  2.00759721]), 'currentState': array([3.80767826, 2.22427626]), 'targetState': array([-0.39243195, -0.8771589 ]), 'effectorPosition': array([ 0.18236075, -0.86650935])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9599138929843214
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.0289705 ,  2.00759721]), 'currentState': array([3.36108551, 2.18218218]), 'targetState': array([-0.39243195, -0.8771589 ]), 'effectorPosition': array([-0.23748389, -0.89196175])}
episode index:1813
target Thresh 1.9520795691935706
current state at start:  [-3.24573203  2.0602546 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.24573203,  2.0602546 ]), 'currentState': array([2.58002747, 2.54659381]), 'targetState': array([-0.28277829, -0.23090326]), 'effectorPosition': array([-0.44393539, -0.38291392])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9599359911690047
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.24573203,  2.0602546 ]), 'currentState': array([2.58002747, 2.54659381]), 'targetState': array([-0.28277829, -0.23090326]), 'effectorPosition': array([-0.44393539, -0.38291392])}
episode index:1814
target Thresh 1.952175314278184
current state at start:  [ 2.48546543 -1.83987031]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.48546543, -1.83987031]), 'currentState': array([2.72818085, 4.31043495]), 'targetState': array([-0.19086   ,  0.79137638]), 'effectorPosition': array([-0.18777904,  1.08733816])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9594071008157437
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([ 2.48546543, -1.83987031]), 'currentState': array([2.59980369, 4.31215391]), 'targetState': array([-0.19086   ,  0.79137638]), 'effectorPosition': array([-0.04803734,  1.10382187])}
episode index:1815
target Thresh 1.9522708680639904
current state at start:  [-2.98347461  2.23147967]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.98347461,  2.23147967]), 'currentState': array([3.75211189, 2.63035001]), 'targetState': array([ 0.52780143, -0.55848929]), 'effectorPosition': array([ 0.17572567, -0.47417937])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9594130985575852
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-2.98347461,  2.23147967]), 'currentState': array([4.3214162 , 2.11105006]), 'targetState': array([ 0.52780143, -0.55848929]), 'effectorPosition': array([ 0.60779031, -0.77581166])}
episode index:1816
target Thresh 1.9523662309332057
current state at start:  [ 2.38127281 -2.49696342]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.38127281, -2.49696342]), 'currentState': array([2.35776374, 4.27977165]), 'targetState': array([0.29438312, 0.74602916]), 'effectorPosition': array([0.22965666, 1.05297718])}
done in step count: 98
reward sum = 0.37346428045426916
running average episode reward sum: 0.9590906170946775
{'reset': False, 'endBeforeDone': False, 'stepCount': 99, 'initial state': array([ 2.38127281, -2.49696342]), 'currentState': array([2.3012808 , 4.20508062]), 'targetState': array([0.29438312, 0.74602916]), 'effectorPosition': array([0.30796884, 0.96617931])}
episode index:1817
target Thresh 1.9524614032672811
current state at start:  [ 1.19841018 -2.31281235]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.19841018, -2.31281235]), 'currentState': array([1.68677458, 3.47037296]), 'targetState': array([0.03636967, 0.23918266]), 'effectorPosition': array([0.31452151, 0.09056749])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9591076189554615
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.19841018, -2.31281235]), 'currentState': array([2.04044666, 3.18294714]), 'targetState': array([0.03636967, 0.23918266]), 'effectorPosition': array([0.03647945, 0.01947306])}
episode index:1818
target Thresh 1.9525563854469061
current state at start:  [ 2.14741776 -2.87503798]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.14741776, -2.87503798]), 'currentState': array([2.29662792, 2.91798299]), 'targetState': array([-0.04318762, -0.09953949]), 'effectorPosition': array([-0.18238338, -0.12856744])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9591300996487241
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.14741776, -2.87503798]), 'currentState': array([2.29662792, 2.91798299]), 'targetState': array([-0.04318762, -0.09953949]), 'effectorPosition': array([-0.18238338, -0.12856744])}
episode index:1819
target Thresh 1.9526511778520097
current state at start:  [-1.91534222 -2.39235951]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.91534222, -2.39235951]), 'currentState': array([4.85358551, 4.1073578 ]), 'targetState': array([-0.57573332, -0.76037423]), 'effectorPosition': array([-0.75361569, -0.54266744])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9591470611324335
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.91534222, -2.39235951]), 'currentState': array([5.08407846, 4.30909963]), 'targetState': array([-0.57573332, -0.76037423]), 'effectorPosition': array([-0.6363107 , -0.90012047])}
episode index:1820
target Thresh 1.9527457808617616
current state at start:  [-0.65111447 -2.25348252]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.65111447, -2.25348252]), 'currentState': array([5.50966949, 3.53414497]), 'targetState': array([-0.05486522, -0.04233823]), 'effectorPosition': array([-0.21284807, -0.32683991])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9591640039873855
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.65111447, -2.25348252]), 'currentState': array([5.40248256, 3.19408259]), 'targetState': array([-0.05486522, -0.04233823]), 'effectorPosition': array([-0.03958415, -0.03446238])}
episode index:1821
target Thresh 1.952840194854574
current state at start:  [ 3.50094557 -2.52884771]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.50094557, -2.52884771]), 'currentState': array([3.94104887, 3.25433759]), 'targetState': array([ 0.39820338, -0.24453161]), 'effectorPosition': array([-0.08509025,  0.07387565])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.959180928244253
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.50094557, -2.52884771]), 'currentState': array([4.34987033, 2.75433759]), 'targetState': array([ 0.39820338, -0.24453161]), 'effectorPosition': array([ 0.32684286, -0.2031635 ])}
episode index:1822
target Thresh 1.952934420208103
current state at start:  [1.83329247 1.8711513 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.83329247, 1.8711513 ]), 'currentState': array([1.97513089, 2.31272785]), 'targetState': array([-0.25506011, -0.27796581]), 'effectorPosition': array([-0.80529984,  0.00813207])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9591924033247554
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([1.83329247, 1.8711513 ]), 'currentState': array([2.03927757, 2.73678132]), 'targetState': array([-0.25506011, -0.27796581]), 'effectorPosition': array([-0.38790479, -0.10571867])}
episode index:1823
target Thresh 1.9530284572992498
current state at start:  [ 2.82094758 -2.64196819]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.82094758, -2.64196819]), 'currentState': array([3.21956783, 3.14121712]), 'targetState': array([-0.73855192, -0.1827362 ]), 'effectorPosition': array([ 2.91825381e-05, -3.74400634e-04])}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.959172421028211
{'reset': False, 'endBeforeDone': False, 'stepCount': 9, 'initial state': array([ 2.82094758, -2.64196819]), 'currentState': array([4.2414747 , 3.90729007]), 'targetState': array([-0.73855192, -0.1827362 ]), 'effectorPosition': array([-0.74423359,  0.06571132])}
episode index:1824
target Thresh 1.9531223065041634
current state at start:  [-4.06001789  2.86541445]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.06001789,  2.86541445]), 'currentState': array([1.80610072, 3.36541445]), 'targetState': array([0.63603702, 0.49631174]), 'effectorPosition': array([0.21002595, 0.07600334])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9591893128523051
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-4.06001789,  2.86541445]), 'currentState': array([1.63936884, 3.83883766]), 'targetState': array([0.63603702, 0.49631174]), 'effectorPosition': array([0.62460772, 0.27683387])}
episode index:1825
target Thresh 1.9532159681982404
current state at start:  [ 1.74710053 -1.63312971]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.74710053, -1.63312971]), 'currentState': array([1.7927503 , 4.15005559]), 'targetState': array([0.34438563, 0.2816033 ]), 'effectorPosition': array([0.72249199, 0.64162441])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.959206186174949
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.74710053, -1.63312971]), 'currentState': array([2.01795234, 3.65005559]), 'targetState': array([0.34438563, 0.2816033 ]), 'effectorPosition': array([0.38426818, 0.32457711])}
episode index:1826
target Thresh 1.9533094427561277
current state at start:  [-1.8623271   2.12570119]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.8623271 ,  2.12570119]), 'currentState': array([3.95854044, 1.98956423]), 'targetState': array([ 0.32198802, -0.83537186]), 'effectorPosition': array([ 0.25993415, -1.05790547])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.959228514480272
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.8623271 ,  2.12570119]), 'currentState': array([3.95854044, 1.98956423]), 'targetState': array([ 0.32198802, -0.83537186]), 'effectorPosition': array([ 0.25993415, -1.05790547])}
episode index:1827
target Thresh 1.953402730551724
current state at start:  [-1.50468484 -2.53007482]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.50468484, -2.53007482]), 'currentState': array([4.41202745, 3.6081236 ]), 'targetState': array([-0.68255617,  0.33343604]), 'effectorPosition': array([-0.46127133,  0.03099601])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9592399321419348
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.50468484, -2.53007482]), 'currentState': array([3.9718757, 4.0984671]), 'targetState': array([-0.68255617,  0.33343604]), 'effectorPosition': array([-0.88934392,  0.23856273])}
episode index:1828
target Thresh 1.9534958319581803
current state at start:  [-0.45526585  1.82052653]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.45526585,  1.82052653]), 'currentState': array([5.46081964, 2.17218342]), 'targetState': array([0.21844199, 0.03599563]), 'effectorPosition': array([0.89967416, 0.24292574])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9592459786525188
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-0.45526585,  1.82052653]), 'currentState': array([4.35413397, 2.7752907 ]), 'targetState': array([0.21844199, 0.03599563]), 'effectorPosition': array([ 0.3121632 , -0.18771697])}
episode index:1829
target Thresh 1.9535887473479026
current state at start:  [ 0.4374666  -2.24673265]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.4374666 , -2.24673265]), 'currentState': array([0.61062807, 3.74519033]), 'targetState': array([ 0.50776304, -0.34441137]), 'effectorPosition': array([ 0.47022547, -0.36371727])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9592682486095393
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.4374666 , -2.24673265]), 'currentState': array([0.61062807, 3.74519033]), 'targetState': array([ 0.50776304, -0.34441137]), 'effectorPosition': array([ 0.47022547, -0.36371727])}
episode index:1830
target Thresh 1.9536814770925521
current state at start:  [1.35731905 1.72322982]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.35731905, 1.72322982]), 'currentState': array([0.86578267, 2.20161566]), 'targetState': array([-0.29832009,  0.32216265]), 'effectorPosition': array([-0.34920463,  0.83572897])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9592850327446516
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.35731905, 1.72322982]), 'currentState': array([0.60012658, 2.67419961]), 'targetState': array([-0.29832009,  0.32216265]), 'effectorPosition': array([-0.1659397 ,  0.43240281])}
episode index:1831
target Thresh 1.9537740215630484
current state at start:  [-1.36737806 -2.66286304]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.36737806, -2.66286304]), 'currentState': array([5.27938345, 3.62619247]), 'targetState': array([ 0.13276707, -0.3558296 ]), 'effectorPosition': array([-0.33111614, -0.34733156])}
done in step count: 14
reward sum = 0.8687458127689782
running average episode reward sum: 0.9592356117730492
{'reset': False, 'endBeforeDone': False, 'stepCount': 15, 'initial state': array([-1.36737806, -2.66286304]), 'currentState': array([5.89820099, 3.65120185]), 'targetState': array([ 0.13276707, -0.3558296 ]), 'effectorPosition': array([-0.06544004, -0.49984713])}
episode index:1832
target Thresh 1.9538663811295691
current state at start:  [ 1.11560144 -2.82143962]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.11560144, -2.82143962]), 'currentState': array([0.94880071, 3.52381436]), 'targetState': array([ 0.36468007, -0.37882146]), 'effectorPosition': array([ 0.34517518, -0.15867438])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9592578509373846
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.11560144, -2.82143962]), 'currentState': array([0.94880071, 3.52381436]), 'targetState': array([ 0.36468007, -0.37882146]), 'effectorPosition': array([ 0.34517518, -0.15867438])}
episode index:1833
target Thresh 1.9539585561615531
current state at start:  [-3.22141837  2.50193414]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.22141837,  2.50193414]), 'currentState': array([2.66557469, 2.75326428]), 'targetState': array([-0.33447677, -0.24407395]), 'effectorPosition': array([-0.23968923, -0.30242763])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9592800658496325
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.22141837,  2.50193414]), 'currentState': array([2.66557469, 2.75326428]), 'targetState': array([-0.33447677, -0.24407395]), 'effectorPosition': array([-0.23968923, -0.30242763])}
episode index:1834
target Thresh 1.9540505470277
current state at start:  [-1.85050955  1.90267616]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.85050955,  1.90267616]), 'currentState': array([4.48945774, 2.30084076]), 'targetState': array([ 0.36940539, -0.05851554]), 'effectorPosition': array([ 0.65306087, -0.48959781])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9592914118627934
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.85050955,  1.90267616]), 'currentState': array([4.37819804, 2.63439749]), 'targetState': array([ 0.36940539, -0.05851554]), 'effectorPosition': array([ 0.4175626 , -0.27824597])}
episode index:1835
target Thresh 1.9541423540959741
current state at start:  [ 3.95568232 -2.34794111]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.95568232, -2.34794111]), 'currentState': array([4.35480879, 3.53491443]), 'targetState': array([-0.13025478, -0.06287422]), 'effectorPosition': array([-0.38574249,  0.06261482])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9593081376733257
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.95568232, -2.34794111]), 'currentState': array([4.47715078, 3.40978458]), 'targetState': array([-0.13025478, -0.06287422]), 'effectorPosition': array([-0.2660224 ,  0.02699822])}
episode index:1836
target Thresh 1.9542339777336033
current state at start:  [-0.91448431  2.51798615]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.91448431,  2.51798615]), 'currentState': array([5.74769805, 2.87507564]), 'targetState': array([-0.33364889,  0.63844605]), 'effectorPosition': array([0.16475257, 0.20849089])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9593141207230409
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-0.91448431,  2.51798615]), 'currentState': array([0.76526479, 2.55859862]), 'targetState': array([-0.33364889,  0.63844605]), 'effectorPosition': array([-0.26223567,  0.51146481])}
episode index:1837
target Thresh 1.9543254183070826
current state at start:  [-1.49198092  2.29856432]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.49198092,  2.29856432]), 'currentState': array([5.23841786, 2.33544188]), 'targetState': array([0.95955721, 0.53197882]), 'effectorPosition': array([0.77857584, 0.09621395])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9593308159783602
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.49198092,  2.29856432]), 'currentState': array([5.6675353, 2.0388771]), 'targetState': array([0.95955721, 0.53197882]), 'effectorPosition': array([0.96343247, 0.4116421 ])}
episode index:1838
target Thresh 1.954416676182174
current state at start:  [-0.33311631 -2.78210869]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.33311631, -2.78210869]), 'currentState': array([5.450069, 3.457018]), 'targetState': array([-0.77930214, -0.31014559]), 'effectorPosition': array([-0.19639132, -0.24515592])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.959342109716273
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-0.33311631, -2.78210869]), 'currentState': array([4.450069 , 3.8860154]), 'targetState': array([-0.77930214, -0.31014559]), 'effectorPosition': array([-0.72296516, -0.079769  ])}
episode index:1839
target Thresh 1.9545077517239093
current state at start:  [-0.30164883  2.21760677]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.30164883,  2.21760677]), 'currentState': array([5.48153648, 2.6096436 ]), 'targetState': array([-0.05531976, -0.03096597]), 'effectorPosition': array([0.46054253, 0.25349624])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.959348064547949
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-0.30164883,  2.21760677]), 'currentState': array([3.99582476, 3.04253464]), 'targetState': array([-0.05531976, -0.03096597]), 'effectorPosition': array([ 0.07135448, -0.06865134])}
episode index:1840
target Thresh 1.954598645296591
current state at start:  [-3.12659497  2.44900083]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.12659497,  2.44900083]), 'currentState': array([2.65659033, 2.94900083]), 'targetState': array([-0.4196228 , -0.01586514]), 'effectorPosition': array([-0.10559061, -0.16071007])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.959359336647597
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-3.12659497,  2.44900083]), 'currentState': array([2.22245336, 2.87219424]), 'targetState': array([-0.4196228 , -0.01586514]), 'effectorPosition': array([-0.23348769, -0.13274461])}
episode index:1841
target Thresh 1.9546893572637933
current state at start:  [-2.58495325  2.55889904]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.58495325,  2.55889904]), 'currentState': array([3.46117628, 3.05889904]), 'targetState': array([-0.06280409,  0.2436396 ]), 'effectorPosition': array([ 0.02270622, -0.07949067])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9593759711011
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.58495325,  2.55889904]), 'currentState': array([3.48514962, 3.50758841]), 'targetState': array([-0.06280409,  0.2436396 ]), 'effectorPosition': array([-0.18290915,  0.31465619])}
episode index:1842
target Thresh 1.9547798879883642
current state at start:  [-0.56025118  1.80487763]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.56025118,  1.80487763]), 'currentState': array([5.22293413, 1.89569984]), 'targetState': array([ 1.35227951, -0.30665459]), 'effectorPosition': array([ 1.15949798, -0.13088068])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9593872158264928
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-0.56025118,  1.80487763]), 'currentState': array([5.28072658, 1.68315072]), 'targetState': array([ 1.35227951, -0.30665459]), 'effectorPosition': array([ 1.31536914, -0.21346594])}
episode index:1843
target Thresh 1.9548702378324267
current state at start:  [1.86965085 1.97791356]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.86965085, 1.97791356]), 'currentState': array([1.36965085, 2.45566422]), 'targetState': array([-0.32328059,  0.11398742]), 'effectorPosition': array([-0.57543487,  0.34815526])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9594038171194285
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.86965085, 1.97791356]), 'currentState': array([0.91541023, 2.75912595]), 'targetState': array([-0.32328059,  0.11398742]), 'effectorPosition': array([-0.2518499 ,  0.28474183])}
episode index:1844
target Thresh 1.9549604071573805
current state at start:  [ 0.18333466 -2.79057743]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.18333466, -2.79057743]), 'currentState': array([6.16742016, 3.1045519 ]), 'targetState': array([1.06838841, 0.37695275]), 'effectorPosition': array([0.00495882, 0.03670519])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9594097223676022
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 0.18333466, -2.79057743]), 'currentState': array([5.62725679, 2.14687945]), 'targetState': array([1.06838841, 0.37695275]), 'effectorPosition': array([0.87224255, 0.38691871])}
episode index:1845
target Thresh 1.955050396323903
current state at start:  [-1.88383673 -2.29719051]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.88383673, -2.29719051]), 'currentState': array([4.64886056, 4.25253169]), 'targetState': array([-0.67746304, -0.44689028]), 'effectorPosition': array([-0.92961761, -0.49816728])}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9593898604889783
{'reset': False, 'endBeforeDone': False, 'stepCount': 9, 'initial state': array([-1.88383673, -2.29719051]), 'currentState': array([4.75895041, 4.25448147]), 'targetState': array([-0.67746304, -0.44689028]), 'effectorPosition': array([-0.87003882, -0.59907272])}
episode index:1846
target Thresh 1.9551402056919507
current state at start:  [ 2.69912251 -1.92085157]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.69912251, -1.92085157]), 'currentState': array([2.28213932, 4.57941637]), 'targetState': array([0.28300696, 0.8638427 ]), 'effectorPosition': array([0.18450295, 1.30414588])}
done in step count: 24
reward sum = 0.7856781408072188
running average episode reward sum: 0.9592958097474074
{'reset': False, 'endBeforeDone': False, 'stepCount': 25, 'initial state': array([ 2.69912251, -1.92085157]), 'currentState': array([2.31917362, 4.33396243]), 'targetState': array([0.28300696, 0.8638427 ]), 'effectorPosition': array([0.2518946 , 1.09436352])}
episode index:1847
target Thresh 1.9552298356207614
current state at start:  [-0.32902191  1.75049824]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.32902191,  1.75049824]), 'currentState': array([5.4541634 , 2.00269256]), 'targetState': array([ 1.25489413, -0.25620274]), 'effectorPosition': array([1.06236651, 0.18490558])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9593124245689726
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.32902191,  1.75049824]), 'currentState': array([5.05685255, 1.89969251]), 'targetState': array([ 1.25489413, -0.25620274]), 'effectorPosition': array([ 1.11942269, -0.31764081])}
episode index:1848
target Thresh 1.9553192864688547
current state at start:  [-0.54548898  1.72876564]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.54548898,  1.72876564]), 'currentState': array([5.27697671, 1.98148692]), 'targetState': array([ 0.51900768, -0.06606618]), 'effectorPosition': array([ 1.09600523, -0.01695122])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.9593027802881895
{'reset': False, 'endBeforeDone': False, 'stepCount': 7, 'initial state': array([-0.54548898,  1.72876564]), 'currentState': array([4.53878469, 2.50293687]), 'targetState': array([ 0.51900768, -0.06606618]), 'effectorPosition': array([ 0.55311006, -0.29710885])}
episode index:1849
target Thresh 1.9554085585940344
current state at start:  [-0.20172363  2.46388715]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.20172363,  2.46388715]), 'currentState': array([5.60131107, 2.57921074]), 'targetState': array([1.25612557, 0.26925964]), 'effectorPosition': array([0.45562489, 0.31690854])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9593140220285743
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-0.20172363,  2.46388715]), 'currentState': array([5.70293133, 1.9202355 ]), 'targetState': array([1.25612557, 0.26925964]), 'effectorPosition': array([1.06509423, 0.42524395])}
episode index:1850
target Thresh 1.9554976523533891
current state at start:  [1.42027228 1.74076787]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.42027228, 1.74076787]), 'currentState': array([1.32799751, 1.69201102]), 'targetState': array([-0.95203423,  1.00935278]), 'effectorPosition': array([-0.75219746,  1.09195368])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9593360025677268
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.42027228, 1.74076787]), 'currentState': array([1.32799751, 1.69201102]), 'targetState': array([-0.95203423,  1.00935278]), 'effectorPosition': array([-0.75219746,  1.09195368])}
episode index:1851
target Thresh 1.9555865681032938
current state at start:  [0.10037659 1.97639319]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.10037659, 1.97639319]), 'currentState': array([5.88356189, 2.41386187]), 'targetState': array([0.55231369, 0.0629815 ]), 'effectorPosition': array([0.49215637, 0.51420871])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9593525598017615
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.10037659, 1.97639319]), 'currentState': array([5.38550015, 2.59228614]), 'targetState': array([0.55231369, 0.0629815 ]), 'effectorPosition': array([0.49993295, 0.2104601 ])}
episode index:1852
target Thresh 1.9556753061994119
current state at start:  [ 3.58280783 -1.7643028 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.58280783, -1.7643028 ]), 'currentState': array([3.08280783, 4.71239778]), 'targetState': array([-0.25356592,  1.33827615]), 'effectorPosition': array([-0.93953049,  1.05702416])}
done in step count: 26
reward sum = 0.7700431458051551
running average episode reward sum: 0.9592503960597234
{'reset': False, 'endBeforeDone': False, 'stepCount': 27, 'initial state': array([ 3.58280783, -1.7643028 ]), 'currentState': array([0.69380479, 1.85128719]), 'targetState': array([-0.25356592,  1.33827615]), 'effectorPosition': array([-0.05848787,  1.2012179 ])}
episode index:1853
target Thresh 1.9557638669966955
current state at start:  [ 2.94567532 -1.70101949]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.94567532, -1.70101949]), 'currentState': array([3.44567532, 4.54760017]), 'targetState': array([-1.3242078 ,  0.22461224]), 'effectorPosition': array([-1.09296586,  0.69089624])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9592669816066168
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 2.94567532, -1.70101949]), 'currentState': array([3.90473935, 4.58650472]), 'targetState': array([-1.3242078 ,  0.22461224]), 'effectorPosition': array([-1.31766202,  0.11252874])}
episode index:1854
target Thresh 1.955852250849388
current state at start:  [1.50549749 2.67070468]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.50549749, 2.67070468]), 'currentState': array([2.00476041, 2.57625291]), 'targetState': array([-0.7984351 , -0.66676242]), 'effectorPosition': array([-0.55146881, -0.08407652])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9592729287863437
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([1.50549749, 2.67070468]), 'currentState': array([2.55650764, 2.09622568]), 'targetState': array([-0.7984351 , -0.66676242]), 'effectorPosition': array([-0.89328542, -0.44595087])}
episode index:1855
target Thresh 1.9559404581110251
current state at start:  [-1.65808949  1.66132321]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.65808949,  1.66132321]), 'currentState': array([4.27898243, 1.92628145]), 'targetState': array([ 0.52770018, -0.82610979]), 'effectorPosition': array([ 0.57700084, -0.98538299])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9592948722514373
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.65808949,  1.66132321]), 'currentState': array([4.27898243, 1.92628145]), 'targetState': array([ 0.52770018, -0.82610979]), 'effectorPosition': array([ 0.57700084, -0.98538299])}
episode index:1856
target Thresh 1.9560284891344362
current state at start:  [ 2.5247994 -2.6070444]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.5247994, -2.6070444]), 'currentState': array([3.0247994 , 3.88289544]), 'targetState': array([-0.74703586,  0.56750692]), 'effectorPosition': array([-0.18193743,  0.70122736])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9593114070536714
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 2.5247994, -2.6070444]), 'currentState': array([3.50248187, 4.16724181]), 'targetState': array([-0.74703586,  0.56750692]), 'effectorPosition': array([-0.75236611,  0.62996617])}
episode index:1857
target Thresh 1.9561163442717449
current state at start:  [-1.86975535 -2.52252767]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.86975535, -2.52252767]), 'currentState': array([4.02739234, 4.15789321]), 'targetState': array([-0.78421076,  0.41199697]), 'effectorPosition': array([-0.95794672,  0.17119784])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.95932792405741
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.86975535, -2.52252767]), 'currentState': array([3.58401928, 4.30907105]), 'targetState': array([-0.78421076,  0.41199697]), 'effectorPosition': array([-0.94281413,  0.57110165])}
episode index:1858
target Thresh 1.956204023874372
current state at start:  [ 3.29087586 -2.2733856 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.29087586, -2.2733856 ]), 'currentState': array([3.55422814, 3.51721527]), 'targetState': array([ 0.00230511, -0.01579309]), 'effectorPosition': array([-0.2109855 ,  0.30810117])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9593444232913758
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.29087586, -2.2733856 ]), 'currentState': array([3.90562753, 3.09034898]), 'targetState': array([ 0.00230511, -0.01579309]), 'effectorPosition': array([ 0.03448912, -0.03789248])}
episode index:1859
target Thresh 1.9562915282930367
current state at start:  [-1.6462202   2.16765505]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.6462202 ,  2.16765505]), 'currentState': array([4.33117384, 2.43177083]), 'targetState': array([ 0.47360286, -0.20439846]), 'effectorPosition': array([ 0.51505737, -0.46664751])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.95936090478423
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.6462202 ,  2.16765505]), 'currentState': array([4.30192702, 2.49566483]), 'targetState': array([ 0.47360286, -0.20439846]), 'effectorPosition': array([ 0.47155191, -0.4249183 ])}
episode index:1860
target Thresh 1.956378857877756
current state at start:  [-1.88632036 -2.24889967]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.88632036, -2.24889967]), 'currentState': array([4.75684592, 4.34655026]), 'targetState': array([-0.71642447, -0.70761144]), 'effectorPosition': array([-0.90435755, -0.68313405])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9593827420197032
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.88632036, -2.24889967]), 'currentState': array([4.75684592, 4.34655026]), 'targetState': array([-0.71642447, -0.70761144]), 'effectorPosition': array([-0.90435755, -0.68313405])}
episode index:1861
target Thresh 1.9564660129778486
current state at start:  [-1.74814969  1.64348053]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.74814969,  1.64348053]), 'currentState': array([4.65332816, 2.00171243]), 'targetState': array([ 0.6138818 , -0.31103663]), 'effectorPosition': array([ 0.87262835, -0.63491187])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.9593782346662554
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([-1.74814969,  1.64348053]), 'currentState': array([4.42431522, 2.27140804]), 'targetState': array([ 0.6138818 , -0.31103663]), 'effectorPosition': array([ 0.63200033, -0.55785725])}
episode index:1862
target Thresh 1.9565529939419353
current state at start:  [0.53514215 2.64394697]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.53514215, 2.64394697]), 'currentState': array([0.04911637, 3.07494523]), 'targetState': array([0.62491754, 0.251705  ]), 'effectorPosition': array([-0.0010523 ,  0.06662678])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9593840965907502
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([0.53514215, 2.64394697]), 'currentState': array([5.56259006, 2.48377252]), 'targetState': array([0.62491754, 0.251705  ]), 'effectorPosition': array([0.56021664, 0.32171972])}
episode index:1863
target Thresh 1.9566398011179396
current state at start:  [1.79840285 2.35164572]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.79840285, 2.35164572]), 'currentState': array([1.43311135, 2.85164572]), 'targetState': array([-0.06510066, -0.03878908]), 'effectorPosition': array([-0.27746675,  0.080586  ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.959405886238502
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.79840285, 2.35164572]), 'currentState': array([1.43311135, 2.85164572]), 'targetState': array([-0.06510066, -0.03878908]), 'effectorPosition': array([-0.27746675,  0.080586  ])}
episode index:1864
target Thresh 1.9567264348530906
current state at start:  [ 0.00810036 -1.59840866]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.00810036, -1.59840866]), 'currentState': array([5.91613552, 4.34860425]), 'targetState': array([ 0.17482378, -0.75380449]), 'effectorPosition': array([ 0.26589886, -1.10348092])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9594222905890443
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.00810036, -1.59840866]), 'currentState': array([5.82810687, 4.08950306]), 'targetState': array([ 0.17482378, -0.75380449]), 'effectorPosition': array([ 0.01723003, -0.91265551])}
episode index:1865
target Thresh 1.9568128954939235
current state at start:  [-0.69191933 -2.22933896]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.69191933, -2.22933896]), 'currentState': array([5.23405355, 3.62205546]), 'targetState': array([-0.62155835, -0.05181993]), 'effectorPosition': array([-0.34429451, -0.32847993])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9594333718909794
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-0.69191933, -2.22933896]), 'currentState': array([4.47011906, 3.86248829]), 'targetState': array([-0.62155835, -0.05181993]), 'effectorPosition': array([-0.70046663, -0.08316721])}
episode index:1866
target Thresh 1.9568991833862808
current state at start:  [ 0.66782604 -2.09685863]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.66782604, -2.09685863]), 'currentState': array([1.16782604, 4.2073292 ]), 'targetState': array([0.94149235, 0.45449663]), 'effectorPosition': array([1.00745226, 0.13160708])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9594444413222109
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 0.66782604, -2.09685863]), 'currentState': array([1.26069276, 4.30281942]), 'targetState': array([0.94149235, 0.45449663]), 'effectorPosition': array([1.05717849, 0.29316308])}
episode index:1867
target Thresh 1.9569852988753138
current state at start:  [-1.98799298  3.06693101]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.98799298,  3.06693101]), 'currentState': array([3.92777916, 3.29645574]), 'targetState': array([-0.27607286, -0.16933256]), 'effectorPosition': array([-0.11760902,  0.10051269])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.9594399154167386
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([-1.98799298,  3.06693101]), 'currentState': array([4.40309501, 3.54205662]), 'targetState': array([-0.27607286, -0.16933256]), 'effectorPosition': array([-0.39542993,  0.04329818])}
episode index:1868
target Thresh 1.9570712423054852
current state at start:  [-1.34132458  2.92886884]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.34132458,  2.92886884]), 'currentState': array([5.05418885, 2.59944243]), 'targetState': array([ 0.78479406, -0.09625203]), 'effectorPosition': array([0.53419607, 0.03784401])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9594562664518286
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.34132458,  2.92886884]), 'currentState': array([4.86237346, 2.35087026]), 'targetState': array([ 0.78479406, -0.09625203]), 'effectorPosition': array([ 0.74720994, -0.18711854])}
episode index:1869
target Thresh 1.9571570140205687
current state at start:  [-3.02716891  2.45887328]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.02716891,  2.45887328]), 'currentState': array([3.71122142, 2.77247236]), 'targetState': array([ 0.25610087, -0.58077163]), 'effectorPosition': array([ 0.13786419, -0.34015183])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9594725999991806
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.02716891,  2.45887328]), 'currentState': array([4.00411477, 2.35036377]), 'targetState': array([ 0.25610087, -0.58077163]), 'effectorPosition': array([ 0.34693569, -0.68825282])}
episode index:1870
target Thresh 1.957242614363651
current state at start:  [-0.32603365  1.98509915]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.32603365,  1.98509915]), 'currentState': array([0.16776735, 2.10975405]), 'targetState': array([0.30595096, 1.23898266]), 'effectorPosition': array([0.33661333, 0.92747397])}
done in step count: 20
reward sum = 0.8179069375972308
running average episode reward sum: 0.9593969368979501
{'reset': False, 'endBeforeDone': False, 'stepCount': 21, 'initial state': array([-0.32603365,  1.98509915]), 'currentState': array([0.26554165, 1.98159441]), 'targetState': array([0.30595096, 1.23898266]), 'effectorPosition': array([0.33900781, 1.04230103])}
episode index:1871
target Thresh 1.9573280436771339
current state at start:  [0.30562842 2.42042507]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.30562842, 2.42042507]), 'currentState': array([6.20302331, 2.92042507]), 'targetState': array([ 0.38019886, -0.04724571]), 'effectorPosition': array([0.04184602, 0.21671397])}
done in step count: 80
reward sum = 0.4475232137638106
running average episode reward sum: 0.9591235000800367
{'reset': False, 'endBeforeDone': False, 'stepCount': 81, 'initial state': array([0.30562842, 2.42042507]), 'currentState': array([5.12919862, 2.74512634]), 'targetState': array([ 0.38019886, -0.04724571]), 'effectorPosition': array([0.38450337, 0.08540789])}
episode index:1872
target Thresh 1.9574133023027345
current state at start:  [-1.17001483 -1.98192486]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.17001483, -1.98192486]), 'currentState': array([5.2913608, 4.4942297]), 'targetState': array([-0.42196911, -1.00551174]), 'effectorPosition': array([-0.38844667, -1.19006024])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9591453241590115
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.17001483, -1.98192486]), 'currentState': array([5.2913608, 4.4942297]), 'targetState': array([-0.42196911, -1.00551174]), 'effectorPosition': array([-0.38844667, -1.19006024])}
episode index:1873
target Thresh 1.9574983905814873
current state at start:  [ 2.04457736 -1.7348694 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.04457736, -1.7348694 ]), 'currentState': array([1.54457736, 4.82731307]), 'targetState': array([1.06289604, 0.80826463]), 'effectorPosition': array([1.02228424, 1.08824514])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9591565059497484
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 2.04457736, -1.7348694 ]), 'currentState': array([1.60291529, 4.58060983]), 'targetState': array([1.06289604, 0.80826463]), 'effectorPosition': array([0.96292459, 0.89998893])}
episode index:1874
target Thresh 1.957583308853746
current state at start:  [ 0.15242475 -2.98118455]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.15242475, -2.98118455]), 'currentState': array([6.17036361, 3.32206051]), 'targetState': array([0.43601608, 0.0197785 ]), 'effectorPosition': array([-0.00407049, -0.18017708])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.9591470785595891
{'reset': False, 'endBeforeDone': False, 'stepCount': 7, 'initial state': array([ 0.15242475, -2.98118455]), 'currentState': array([5.29826859, 2.66262732]), 'targetState': array([0.43601608, 0.0197785 ]), 'effectorPosition': array([0.4462218 , 0.16106407])}
episode index:1875
target Thresh 1.9576680574591836
current state at start:  [-4.04037401  2.87523438]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.04037401,  2.87523438]), 'currentState': array([1.93352092, 3.3344893 ]), 'targetState': array([-0.41273201,  0.71372788]), 'effectorPosition': array([0.17264833, 0.08536063])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9591530230806129
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-4.04037401,  2.87523438]), 'currentState': array([3.26298547, 4.13542427]), 'targetState': array([-0.41273201,  0.71372788]), 'effectorPosition': array([-0.55266499,  0.77691466])}
episode index:1876
target Thresh 1.9577526367367946
current state at start:  [-2.31373091  2.09187429]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.31373091,  2.09187429]), 'currentState': array([4.04178704, 2.25763621]), 'targetState': array([ 0.25973486, -0.67130019]), 'effectorPosition': array([ 0.37841048, -0.7672105 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9591747849223387
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.31373091,  2.09187429]), 'currentState': array([4.04178704, 2.25763621]), 'targetState': array([ 0.25973486, -0.67130019]), 'effectorPosition': array([ 0.37841048, -0.7672105 ])}
episode index:1877
target Thresh 1.957837047024896
current state at start:  [ 3.91266058 -2.78759829]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.91266058, -2.78759829]), 'currentState': array([3.94201135, 3.94375684]), 'targetState': array([-0.64873347,  1.14046372]), 'effectorPosition': array([-0.7281875 ,  0.28184711])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9591859272093874
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 3.91266058, -2.78759829]), 'currentState': array([2.94201135, 4.66201636]), 'targetState': array([-0.64873347,  1.14046372]), 'effectorPosition': array([-0.73279036,  1.16718278])}
episode index:1878
target Thresh 1.9579212886611295
current state at start:  [1.18589287 2.63717832]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.18589287, 2.63717832]), 'currentState': array([0.74689191, 2.13717832]), 'targetState': array([-0.39640546,  1.24448788]), 'effectorPosition': array([-0.23322002,  0.93404677])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.9591765042302453
{'reset': False, 'endBeforeDone': False, 'stepCount': 7, 'initial state': array([1.18589287, 2.63717832]), 'currentState': array([0.79985844, 1.8300061 ]), 'targetState': array([-0.39640546,  1.24448788]), 'effectorPosition': array([-0.17509133,  1.20694218])}
episode index:1879
target Thresh 1.9580053619824616
current state at start:  [ 1.86780081 -2.1491438 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.86780081, -2.1491438 ]), 'currentState': array([1.57116139, 4.6132067 ]), 'targetState': array([0.98094753, 0.66155642]), 'effectorPosition': array([0.99475648, 0.90134347])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9591982188556547
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.86780081, -2.1491438 ]), 'currentState': array([1.57116139, 4.6132067 ]), 'targetState': array([0.98094753, 0.66155642]), 'effectorPosition': array([0.99475648, 0.90134347])}
episode index:1880
target Thresh 1.9580892673251853
current state at start:  [-1.00413552  1.8902409 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.00413552,  1.8902409 ]), 'currentState': array([5.03480937, 2.19229754]), 'targetState': array([ 0.41533747, -0.05092951]), 'effectorPosition': array([ 0.90347973, -0.13860647])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9592093309136793
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.00413552,  1.8902409 ]), 'currentState': array([4.56779042, 2.6453028 ]), 'targetState': array([ 0.41533747, -0.05092951]), 'effectorPosition': array([ 0.45381261, -0.18799895])}
episode index:1881
target Thresh 1.9581730050249226
current state at start:  [-0.4468802   2.80549454]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.4468802 ,  2.80549454]), 'currentState': array([6.27165335, 2.69951787]), 'targetState': array([-0.43717681,  1.18228832]), 'effectorPosition': array([0.10106106, 0.42667867])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9592152234052236
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-0.4468802 ,  2.80549454]), 'currentState': array([1.02347723, 1.97239852]), 'targetState': array([-0.43717681,  1.18228832]), 'effectorPosition': array([-0.46900225,  0.9991245 ])}
episode index:1882
target Thresh 1.9582565754166243
current state at start:  [-0.01754881 -2.02851107]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.01754881, -2.02851107]), 'currentState': array([0.25230386, 3.99844558]), 'targetState': array([ 0.70199002, -0.57179686]), 'effectorPosition': array([ 0.52292324, -0.64568788])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9592368828723478
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.01754881, -2.02851107]), 'currentState': array([0.25230386, 3.99844558]), 'targetState': array([ 0.70199002, -0.57179686]), 'effectorPosition': array([ 0.52292324, -0.64568788])}
episode index:1883
target Thresh 1.9583399788345721
current state at start:  [ 3.42082864 -2.53576505]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.42082864, -2.53576505]), 'currentState': array([3.42550152, 4.23318321]), 'targetState': array([-0.59343039,  1.19019555]), 'effectorPosition': array([-0.76591006,  0.70087993])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9592532114907807
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.42082864, -2.53576505]), 'currentState': array([2.92550152, 4.67013788]), 'targetState': array([-0.59343039,  1.19019555]), 'effectorPosition': array([-0.72126488,  1.18122814])}
episode index:1884
target Thresh 1.9584232156123795
current state at start:  [-0.39552645  2.19273311]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.39552645,  2.19273311]), 'currentState': array([5.42456766, 2.60145405]), 'targetState': array([0.00290413, 0.01856494]), 'effectorPosition': array([0.48229178, 0.22829763])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9592590713255337
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-0.39552645,  2.19273311]), 'currentState': array([4.23975941, 2.99992113]), 'targetState': array([0.00290413, 0.01856494]), 'effectorPosition': array([ 0.12115837, -0.07319782])}
episode index:1885
target Thresh 1.958506286082994
current state at start:  [0.07731482 2.88709468]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.07731482, 2.88709468]), 'currentState': array([6.06566084, 2.49423996]), 'targetState': array([0.40733583, 0.62162515]), 'effectorPosition': array([0.32770109, 0.54520249])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9592806730904724
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.07731482, 2.88709468]), 'currentState': array([6.06566084, 2.49423996]), 'targetState': array([0.40733583, 0.62162515]), 'effectorPosition': array([0.32770109, 0.54520249])}
episode index:1886
target Thresh 1.9585891905786974
current state at start:  [-2.15826124  1.98684056]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.15826124,  1.98684056]), 'currentState': array([4.59466621, 2.1677573 ]), 'targetState': array([ 0.92057959, -0.50739161]), 'effectorPosition': array([ 0.7698954 , -0.53197534])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9593022519600588
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.15826124,  1.98684056]), 'currentState': array([4.59466621, 2.1677573 ]), 'targetState': array([ 0.92057959, -0.50739161]), 'effectorPosition': array([ 0.7698954 , -0.53197534])}
episode index:1887
target Thresh 1.9586719294311081
current state at start:  [-4.0307555   1.95589525]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.0307555 ,  1.95589525]), 'currentState': array([1.80007726, 2.40920428]), 'targetState': array([-0.24201494, -0.19587743]), 'effectorPosition': array([-0.70942759,  0.09774154])}
done in step count: 20
reward sum = 0.8179069375972308
running average episode reward sum: 0.9592273603740614
{'reset': False, 'endBeforeDone': False, 'stepCount': 21, 'initial state': array([-4.0307555 ,  1.95589525]), 'currentState': array([1.5065405 , 2.88044856]), 'targetState': array([-0.24201494, -0.19587743]), 'effectorPosition': array([-0.25547613,  0.05041335])}
episode index:1888
target Thresh 1.9587545029711813
current state at start:  [1.24377956 2.5159619 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.24377956, 2.5159619 ]), 'currentState': array([1.36619884, 3.0159619 ]), 'targetState': array([-0.28880782, -0.3120157 ]), 'effectorPosition': array([-0.12108588,  0.03317448])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9592280849106554
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([1.24377956, 2.5159619 ]), 'currentState': array([2.02337143, 2.78565938]), 'targetState': array([-0.28880782, -0.3120157 ]), 'effectorPosition': array([-0.34079137, -0.09600978])}
episode index:1889
target Thresh 1.9588369115292112
current state at start:  [ 4.24992668 -2.48126841]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.24992668, -2.48126841]), 'currentState': array([3.7977634 , 3.56251493]), 'targetState': array([0.1378122 , 0.60046959]), 'effectorPosition': array([-0.31844401,  0.27049666])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9592339425376869
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 4.24992668, -2.48126841]), 'currentState': array([2.67614093, 3.97684092]), 'targetState': array([0.1378122 , 0.60046959]), 'effectorPosition': array([0.03878199, 0.81025225])}
episode index:1890
target Thresh 1.9589191554348326
current state at start:  [-1.79240261  1.75474684]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.79240261,  1.75474684]), 'currentState': array([3.99078269, 1.9656077 ]), 'targetState': array([-0.18553271, -1.14660644]), 'effectorPosition': array([ 0.28648463, -1.07175482])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9592502122666463
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.79240261,  1.75474684]), 'currentState': array([3.50592174, 1.83075447]), 'targetState': array([-0.18553271, -1.14660644]), 'effectorPosition': array([-0.34984394, -1.16770245])}
episode index:1891
target Thresh 1.959001235017021
current state at start:  [-0.67038274  2.52461687]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.67038274,  2.52461687]), 'currentState': array([5.29495934, 2.59504603]), 'targetState': array([0.08439545, 0.08157496]), 'effectorPosition': array([0.51415619, 0.16429995])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9592560520064631
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-0.67038274,  2.52461687]), 'currentState': array([4.26354042, 2.9459741 ]), 'targetState': array([0.08439545, 0.08157496]), 'effectorPosition': array([ 0.16684409, -0.10152732])}
episode index:1892
target Thresh 1.9590831506040947
current state at start:  [ 2.6145107  -2.99483025]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.6145107 , -2.99483025]), 'currentState': array([2.7877826 , 2.78835505]), 'targetState': array([ 0.28691177, -0.30551909]), 'effectorPosition': array([-0.17777643, -0.30311762])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9592618855764544
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 2.6145107 , -2.99483025]), 'currentState': array([3.88854816, 2.8682439 ]), 'targetState': array([ 0.28691177, -0.30551909]), 'effectorPosition': array([ 0.15616832, -0.22330898])}
episode index:1893
target Thresh 1.9591649025237161
current state at start:  [ 1.25547317 -2.44405549]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.25547317, -2.44405549]), 'currentState': array([1.69939039, 3.33912982]), 'targetState': array([-0.13517092, -0.02740599]), 'effectorPosition': array([0.19214065, 0.04445426])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9592781147815356
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.25547317, -2.44405549]), 'currentState': array([1.98489938, 2.87039293]), 'targetState': array([-0.13517092, -0.02740599]), 'effectorPosition': array([-0.25995151, -0.07432909])}
episode index:1894
target Thresh 1.9592464911028933
current state at start:  [ 2.0544943  -2.37790059]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.0544943 , -2.37790059]), 'currentState': array([2.4116597 , 3.40528472]), 'targetState': array([-0.00767702,  0.18863713]), 'effectorPosition': array([0.14804532, 0.21728808])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9592996039030228
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.0544943 , -2.37790059]), 'currentState': array([2.4116597 , 3.40528472]), 'targetState': array([-0.00767702,  0.18863713]), 'effectorPosition': array([0.14804532, 0.21728808])}
episode index:1895
target Thresh 1.9593279166679807
current state at start:  [-2.9397939  2.1329   ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.9397939,  2.1329   ]), 'currentState': array([2.88064369, 2.5306806 ]), 'targetState': array([-0.59839706, -0.17983667]), 'effectorPosition': array([-0.32274258, -0.50753014])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9593157960950571
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.9397939,  2.1329   ]), 'currentState': array([2.41602533, 2.49793217]), 'targetState': array([-0.59839706, -0.17983667]), 'effectorPosition': array([-0.54791674, -0.31619378])}
episode index:1896
target Thresh 1.9594091795446804
current state at start:  [-3.42918612  2.32097166]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.42918612,  2.32097166]), 'currentState': array([2.53634816, 2.43006079]), 'targetState': array([-0.37082722, -0.5454064 ]), 'effectorPosition': array([-0.57106607, -0.39894688])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9593372426970102
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.42918612,  2.32097166]), 'currentState': array([2.53634816, 2.43006079]), 'targetState': array([-0.37082722, -0.5454064 ]), 'effectorPosition': array([-0.57106607, -0.39894688])}
episode index:1897
target Thresh 1.959490280058044
current state at start:  [0.42540619 2.39512819]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.42540619, 2.39512819]), 'currentState': array([0.5624351 , 2.87180692]), 'targetState': array([-0.45336824, -0.01280981]), 'effectorPosition': array([-0.11152381,  0.24475782])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9593430181223542
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([0.42540619, 2.39512819]), 'currentState': array([1.57013493, 2.63900134]), 'targetState': array([-0.45336824, -0.01280981]), 'effectorPosition': array([-0.48161612,  0.12398129])}
episode index:1898
target Thresh 1.959571218532474
current state at start:  [-3.94818237  2.74401451]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.94818237,  2.74401451]), 'currentState': array([1.89679528, 3.22801117]), 'targetState': array([0.14093547, 0.36384375]), 'effectorPosition': array([0.08056998, 0.03117676])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9593539486025426
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-3.94818237,  2.74401451]), 'currentState': array([2.27868624, 3.72024297]), 'targetState': array([0.14093547, 0.36384375]), 'effectorPosition': array([0.30963843, 0.47929213])}
episode index:1899
target Thresh 1.9596519952917244
current state at start:  [-2.20105768  1.81927202]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.20105768,  1.81927202]), 'currentState': array([3.61157706, 2.18618045]), 'targetState': array([-0.40299485, -0.65512054]), 'effectorPosition': array([-0.00709993, -0.91945916])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9593700781032781
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.20105768,  1.81927202]), 'currentState': array([3.1740888 , 2.40153724]), 'targetState': array([-0.40299485, -0.65512054]), 'effectorPosition': array([-0.23952148, -0.6824713 ])}
episode index:1900
target Thresh 1.959732610658902
current state at start:  [-3.9920938   2.64230487]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.9920938 ,  2.64230487]), 'currentState': array([2.7910915 , 2.77099927]), 'targetState': array([ 0.03544635, -0.62461025]), 'effectorPosition': array([-0.18811719, -0.31683862])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9593861906345231
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.9920938 ,  2.64230487]), 'currentState': array([3.27182693, 2.38172256]), 'targetState': array([ 0.03544635, -0.62461025]), 'effectorPosition': array([-0.18328949, -0.71871689])}
episode index:1901
target Thresh 1.9598130649564685
current state at start:  [-1.36638852  2.79073963]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.36638852,  2.79073963]), 'currentState': array([4.45038397, 2.97543302]), 'targetState': array([-0.28743026, -0.79398329]), 'effectorPosition': array([ 0.15618417, -0.05614326])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9593919281788793
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-1.36638852,  2.79073963]), 'currentState': array([3.2600999 , 2.32190165]), 'targetState': array([-0.28743026, -0.79398329]), 'effectorPosition': array([-0.22890718, -0.76335268])}
episode index:1902
target Thresh 1.9598933585062412
current state at start:  [-0.83086479  2.44706651]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.83086479,  2.44706651]), 'currentState': array([5.02311984, 2.52630056]), 'targetState': array([ 0.53894524, -0.19684821]), 'effectorPosition': array([0.60562921, 0.00186826])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9594132671551384
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.83086479,  2.44706651]), 'currentState': array([5.02311984, 2.52630056]), 'targetState': array([ 0.53894524, -0.19684821]), 'effectorPosition': array([0.60562921, 0.00186826])}
episode index:1903
target Thresh 1.9599734916293945
current state at start:  [0.69839542 2.24155299]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.69839542, 2.24155299]), 'currentState': array([0.29494612, 2.74155299]), 'targetState': array([0.00678989, 0.02296826]), 'effectorPosition': array([-0.03766495,  0.39558849])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9594293316156662
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.69839542, 2.24155299]), 'currentState': array([6.2033849 , 3.24155299]), 'targetState': array([0.00678989, 0.02296826]), 'effectorPosition': array([-0.00297916, -0.0998743 ])}
episode index:1904
target Thresh 1.9600534646464611
current state at start:  [ 1.02035327 -2.1428014 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.02035327, -2.1428014 ]), 'currentState': array([1.48973991, 4.63223906]), 'targetState': array([1.14439136, 0.69672407]), 'effectorPosition': array([1.06800206, 0.8362077 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9594506285544506
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.02035327, -2.1428014 ]), 'currentState': array([1.48973991, 4.63223906]), 'targetState': array([1.14439136, 0.69672407]), 'effectorPosition': array([1.06800206, 0.8362077 ])}
episode index:1905
target Thresh 1.9601332778773328
current state at start:  [-0.91873406 -2.30688133]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.91873406, -2.30688133]), 'currentState': array([5.82104371, 4.3313186 ]), 'targetState': array([ 0.43798729, -0.76959888]), 'effectorPosition': array([ 0.14831654, -1.11093368])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9594666565562584
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.91873406, -2.30688133]), 'currentState': array([6.05651022, 4.23678007]), 'targetState': array([ 0.43798729, -0.76959888]), 'effectorPosition': array([ 0.32845612, -0.98810772])}
episode index:1906
target Thresh 1.9602129316412629
current state at start:  [-4.18836916  2.43571575]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.18836916,  2.43571575]), 'currentState': array([1.66824162, 2.01366259]), 'targetState': array([-0.96027652, -0.21118606]), 'effectorPosition': array([-0.95483961,  0.48085277])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9594723368622069
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-4.18836916,  2.43571575]), 'currentState': array([2.04500133, 2.15193239]), 'targetState': array([-0.96027652, -0.21118606]), 'effectorPosition': array([-0.94956233,  0.01958762])}
episode index:1907
target Thresh 1.9602924262568666
current state at start:  [-2.31454467  1.65165068]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.31454467,  1.65165068]), 'currentState': array([4.44605521, 1.43194379]), 'targetState': array([ 0.45150381, -1.33969252]), 'effectorPosition': array([ 0.65583273, -1.3589323 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9594935777758011
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.31454467,  1.65165068]), 'currentState': array([4.44605521, 1.43194379]), 'targetState': array([ 0.45150381, -1.33969252]), 'effectorPosition': array([ 0.65583273, -1.3589323 ])}
episode index:1908
target Thresh 1.9603717620421224
current state at start:  [ 0.71291494 -2.18015546]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.71291494, -2.18015546]), 'currentState': array([0.73182015, 4.20156946]), 'targetState': array([ 1.02229022, -0.32748521]), 'effectorPosition': array([ 0.9631654 , -0.30745373])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.95951479643595
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.71291494, -2.18015546]), 'currentState': array([0.73182015, 4.20156946]), 'targetState': array([ 1.02229022, -0.32748521]), 'effectorPosition': array([ 0.9631654 , -0.30745373])}
episode index:1909
target Thresh 1.9604509393143734
current state at start:  [ 0.24664237 -1.75546493]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.24664237, -1.75546493]), 'currentState': array([0.6923589 , 4.37775649]), 'targetState': array([ 1.37793185, -0.12619494]), 'effectorPosition': array([ 1.11988783, -0.29834062])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.959525574029439
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 0.24664237, -1.75546493]), 'currentState': array([0.57852661, 4.6928391 ]), 'targetState': array([ 1.37793185, -0.12619494]), 'effectorPosition': array([ 1.36758815, -0.30100731])}
episode index:1910
target Thresh 1.960529958390329
current state at start:  [-1.72199859 -2.19987586]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.72199859, -2.19987586]), 'currentState': array([4.78314218, 3.80928907]), 'targetState': array([-0.35485881, -0.16752277]), 'effectorPosition': array([-0.60244801, -0.25798496])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9595415208771473
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.72199859, -2.19987586]), 'currentState': array([4.82810196, 3.67896074]), 'targetState': array([-0.35485881, -0.16752277]), 'effectorPosition': array([-0.49218139, -0.19909732])}
episode index:1911
target Thresh 1.9606088195860656
current state at start:  [-1.61900221 -2.24266549]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.61900221, -2.24266549]), 'currentState': array([5.15870549, 4.18942473]), 'targetState': array([-0.03372648, -1.25075331]), 'effectorPosition': array([-0.5654182 , -0.82547047])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9595574510440525
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.61900221, -2.24266549]), 'currentState': array([5.62807433, 4.5445259 ]), 'targetState': array([-0.03372648, -1.25075331]), 'effectorPosition': array([ 0.05980877, -1.28929097])}
episode index:1912
target Thresh 1.960687523217028
current state at start:  [0.36367715 2.23647177]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.36367715, 2.23647177]), 'currentState': array([6.17258099, 2.7149168 ]), 'targetState': array([0.09344207, 0.10654033]), 'effectorPosition': array([0.13478571, 0.40142233])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9595733645563139
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.36367715, 2.23647177]), 'currentState': array([5.89209185, 3.12295133]), 'targetState': array([0.09344207, 0.10654033]), 'effectorPosition': array([0.00726628, 0.01716654])}
episode index:1913
target Thresh 1.960766069598031
current state at start:  [-2.42260381  2.01721953]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.42260381,  2.01721953]), 'currentState': array([3.59196384, 2.48738517]), 'targetState': array([-0.07358099, -0.29912875]), 'effectorPosition': array([ 0.07901163, -0.63772743])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9595892614400359
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.42260381,  2.01721953]), 'currentState': array([3.49455868, 2.84902219]), 'targetState': array([-0.07358099, -0.29912875]), 'effectorPosition': array([ 0.0598252 , -0.28532364])}
episode index:1914
target Thresh 1.9608444590432597
current state at start:  [-1.69164347  2.4865562 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.69164347,  2.4865562 ]), 'currentState': array([4.16574467, 2.93414452]), 'targetState': array([-0.22726714, -0.11120515]), 'effectorPosition': array([ 0.16480395, -0.12538051])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9596051417212682
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.69164347,  2.4865562 ]), 'currentState': array([3.90078617, 3.22993597]), 'targetState': array([-0.22726714, -0.11120515]), 'effectorPosition': array([-0.06355971,  0.06131583])}
episode index:1915
target Thresh 1.9609226918662725
current state at start:  [1.45120728 1.8533984 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.45120728, 1.8533984 ]), 'currentState': array([1.1511713, 2.3533984]), 'targetState': array([-0.12179234, -0.03702084]), 'effectorPosition': array([-0.5274259,  0.5581829])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9596107230669252
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([1.45120728, 1.8533984 ]), 'currentState': array([0.5261519 , 3.13200342]), 'targetState': array([-0.12179234, -0.03702084]), 'effectorPosition': array([-0.00477597,  0.00831522])}
episode index:1916
target Thresh 1.9610007683800008
current state at start:  [-3.87725833  2.22499986]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.87725833,  2.22499986]), 'currentState': array([1.97609759, 2.72499986]), 'targetState': array([ 0.02341812, -0.07274273]), 'effectorPosition': array([-0.40558692, -0.0809526 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9596265755848872
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.87725833,  2.22499986]), 'currentState': array([1.61360631, 3.15568151]), 'targetState': array([ 0.02341812, -0.07274273]), 'effectorPosition': array([0.01407123, 0.00070209])}
episode index:1917
target Thresh 1.9610786888967506
current state at start:  [0.50597659 2.66637648]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.50597659, 2.66637648]), 'currentState': array([0.95858071, 3.14490883]), 'targetState': array([-0.9302334 , -0.09962078]), 'effectorPosition': array([ 0.00271703, -0.00190124])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.959637249945896
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([0.50597659, 2.66637648]), 'currentState': array([1.91100276, 2.23945517]), 'targetState': array([-0.9302334 , -0.09962078]), 'effectorPosition': array([-0.866503  ,  0.09645801])}
episode index:1918
target Thresh 1.961156453728204
current state at start:  [-1.72884164  2.66220932]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.72884164,  2.66220932]), 'currentState': array([4.38711121, 2.59777861]), 'targetState': array([ 0.36418814, -0.05331657]), 'effectorPosition': array([ 0.444171  , -0.30204156])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.959653072118931
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.72884164,  2.66220932]), 'currentState': array([4.42408915, 2.64576098]), 'targetState': array([ 0.36418814, -0.05331657]), 'effectorPosition': array([ 0.42188792, -0.25072678])}
episode index:1919
target Thresh 1.9612340631854206
current state at start:  [ 4.06092207 -2.46932234]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.06092207, -2.46932234]), 'currentState': array([3.69252237, 4.19708912]), 'targetState': array([-0.77438906,  0.78704076]), 'effectorPosition': array([-0.88766052,  0.47588572])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9596688778105358
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 4.06092207, -2.46932234]), 'currentState': array([3.28635075, 4.35238071]), 'targetState': array([-0.77438906,  0.78704076]), 'effectorPosition': array([-0.77594899,  0.83266993])}
episode index:1920
target Thresh 1.961311517578838
current state at start:  [1.08542847 1.79485125]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.08542847, 1.79485125]), 'currentState': array([0.60071208, 2.19809395]), 'targetState': array([0.06739252, 0.4033882 ]), 'effectorPosition': array([-0.11688837,  0.90134293])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9596846670464491
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.08542847, 1.79485125]), 'currentState': array([0.19359474, 2.62419972]), 'targetState': array([0.06739252, 0.4033882 ]), 'effectorPosition': array([0.0332852 , 0.51055738])}
episode index:1921
target Thresh 1.9613888172182745
current state at start:  [-0.98931058 -2.44898464]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.98931058, -2.44898464]), 'currentState': array([5.49277148, 4.15859406]), 'targetState': array([-0.14772972, -0.79716686]), 'effectorPosition': array([-0.27088739, -0.93529812])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9597056427659879
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.98931058, -2.44898464]), 'currentState': array([5.49277148, 4.15859406]), 'targetState': array([-0.14772972, -0.79716686]), 'effectorPosition': array([-0.27088739, -0.93529812])}
episode index:1922
target Thresh 1.9614659624129283
current state at start:  [-1.69684354 -1.77836865]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.69684354, -1.77836865]), 'currentState': array([4.99777898, 4.05060933]), 'targetState': array([-0.14050475, -0.35582088]), 'effectorPosition': array([-0.64846604, -0.59198667])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9597162482559691
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.69684354, -1.77836865]), 'currentState': array([5.3042057 , 3.72198298]), 'targetState': array([-0.14050475, -0.35582088]), 'effectorPosition': array([-0.36373975, -0.44180996])}
episode index:1923
target Thresh 1.9615429534713802
current state at start:  [-0.81483039  2.48894268]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.81483039,  2.48894268]), 'currentState': array([5.70194017, 2.10509521]), 'targetState': array([0.96417054, 0.33521038]), 'effectorPosition': array([0.88270865, 0.44983321])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9597371857568756
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.81483039,  2.48894268]), 'currentState': array([5.70194017, 2.10509521]), 'targetState': array([0.96417054, 0.33521038]), 'effectorPosition': array([0.88270865, 0.44983321])}
episode index:1924
target Thresh 1.9616197907015949
current state at start:  [-2.3864697   1.99046186]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.3864697 ,  1.99046186]), 'currentState': array([4.39671561, 2.4735916 ]), 'targetState': array([ 1.07436149, -0.14429066]), 'effectorPosition': array([ 0.52208186, -0.39662034])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9597529066993395
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.3864697 ,  1.99046186]), 'currentState': array([4.89671561, 2.13972233]), 'targetState': array([ 1.07436149, -0.14429066]), 'effectorPosition': array([ 0.9127525 , -0.29904483])}
episode index:1925
target Thresh 1.961696474410921
current state at start:  [ 0.87916157 -1.97512359]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.87916157, -1.97512359]), 'currentState': array([1.37585158, 4.38972206]), 'targetState': array([1.09880558, 0.28282288]), 'effectorPosition': array([1.06271575, 0.48625229])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9597738034248332
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.87916157, -1.97512359]), 'currentState': array([1.37585158, 4.38972206]), 'targetState': array([1.09880558, 0.28282288]), 'effectorPosition': array([1.06271575, 0.48625229])}
episode index:1926
target Thresh 1.961773004906094
current state at start:  [0.22377679 2.28091137]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.22377679, 2.28091137]), 'currentState': array([0.72377679, 2.39285855]), 'targetState': array([-0.51887199,  1.22360731]), 'effectorPosition': array([-0.25037857,  0.6871741 ])}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9597545874886645
{'reset': False, 'endBeforeDone': False, 'stepCount': 9, 'initial state': array([0.22377679, 2.28091137]), 'currentState': array([0.8988444 , 1.81078048]), 'targetState': array([-0.51887199,  1.22360731]), 'effectorPosition': array([-0.28562891,  1.20126669])}
episode index:1927
target Thresh 1.9618493824932355
current state at start:  [ 3.39210283 -1.93244399]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.39210283, -1.93244399]), 'currentState': array([3.88273369, 3.85074132]), 'targetState': array([-0.24184649, -0.03176998]), 'effectorPosition': array([-0.61748352,  0.31761777])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9597702749432866
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.39210283, -1.93244399]), 'currentState': array([4.37424963, 3.43318592]), 'targetState': array([-0.24184649, -0.03176998]), 'effectorPosition': array([-0.28520311,  0.05554339])}
episode index:1928
target Thresh 1.961925607477856
current state at start:  [ 1.26388519 -2.57606802]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.26388519, -2.57606802]), 'currentState': array([1.41819102, 3.20711729]), 'targetState': array([ 0.07133664, -0.36991538]), 'effectorPosition': array([ 0.06504302, -0.00783248])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.9597607932815229
{'reset': False, 'endBeforeDone': False, 'stepCount': 7, 'initial state': array([ 1.26388519, -2.57606802]), 'currentState': array([2.90204725, 2.78543698]), 'targetState': array([ 0.07133664, -0.36991538]), 'effectorPosition': array([-0.1436906 , -0.32382817])}
episode index:1929
target Thresh 1.9620016801648557
current state at start:  [-1.5712576  -2.60151712]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.5712576 , -2.60151712]), 'currentState': array([4.88399296, 3.79574401]), 'targetState': array([-0.29259532, -0.3185748 ]), 'effectorPosition': array([-0.56429712, -0.3073102 ])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9597662534922579
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-1.5712576 , -2.60151712]), 'currentState': array([5.0482139 , 3.77056768]), 'targetState': array([-0.29259532, -0.3185748 ]), 'effectorPosition': array([-0.49238686, -0.37455746])}
episode index:1930
target Thresh 1.9620776008585255
current state at start:  [ 2.70343159 -2.42494953]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.70343159, -2.42494953]), 'currentState': array([3.17495863, 3.35823577]), 'targetState': array([-0.53550721, -0.24293377]), 'effectorPosition': array([-0.03053324,  0.21405299])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9597666831952655
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([ 2.70343159, -2.42494953]), 'currentState': array([2.66881141, 2.5467455 ]), 'targetState': array([-0.53550721, -0.24293377]), 'effectorPosition': array([-0.40810201, -0.42069518])}
episode index:1931
target Thresh 1.962153369862548
current state at start:  [1.4721856  1.64229708]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.4721856 , 1.64229708]), 'currentState': array([0.9721856 , 2.03784616]), 'targetState': array([-0.20669715,  1.20652407]), 'effectorPosition': array([-0.42786303,  0.95730096])}
done in step count: 39
reward sum = 0.6757290490602831
running average episode reward sum: 0.9596196657862929
{'reset': False, 'endBeforeDone': False, 'stepCount': 40, 'initial state': array([1.4721856 , 1.64229708]), 'currentState': array([0.6029138 , 1.88631403]), 'targetState': array([-0.20669715,  1.20652407]), 'effectorPosition': array([0.02903644, 1.17411224])}
episode index:1932
target Thresh 1.9622289874799996
current state at start:  [0.33083633 2.61018575]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.33083633, 2.61018575]), 'currentState': array([0.15035291, 2.11328707]), 'targetState': array([0.18310262, 1.1222634 ]), 'effectorPosition': array([0.34999051, 0.91921988])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9596302608893522
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([0.33083633, 2.61018575]), 'currentState': array([0.22877627, 2.1225912 ]), 'targetState': array([0.18310262, 1.1222634 ]), 'effectorPosition': array([0.27025931, 0.93729759])}
episode index:1933
target Thresh 1.9623044540133507
current state at start:  [-0.68070498  2.69563915]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.68070498,  2.69563915]), 'currentState': array([5.14290455, 3.08331271]), 'targetState': array([-0.26986737, -0.67665229]), 'effectorPosition': array([0.05364052, 0.02276588])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9596307602425636
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([-0.68070498,  2.69563915]), 'currentState': array([5.19674411, 3.91917463]), 'targetState': array([-0.26986737, -0.67665229]), 'effectorPosition': array([-0.48704319, -0.58100337])}
episode index:1934
target Thresh 1.9623797697644676
current state at start:  [-1.43025667 -2.76549922]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.43025667, -2.76549922]), 'currentState': array([5.34954867, 3.79380303]), 'targetState': array([-0.0319459 , -0.97152331]), 'effectorPosition': array([-0.36574547, -0.52606266])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9596464549401126
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.43025667, -2.76549922]), 'currentState': array([5.75892189, 4.24734315]), 'targetState': array([-0.0319459 , -0.97152331]), 'effectorPosition': array([ 0.03004612, -1.0498427 ])}
episode index:1935
target Thresh 1.9624549350346134
current state at start:  [-2.16680281  2.80421136]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.16680281,  2.80421136]), 'currentState': array([4.6163825 , 2.30421136]), 'targetState': array([ 0.89091565, -1.02540681]), 'effectorPosition': array([ 0.7077816 , -0.40028006])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9596621334241312
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.16680281,  2.80421136]), 'currentState': array([4.38755112, 1.84898977]), 'targetState': array([ 0.89091565, -1.02540681]), 'effectorPosition': array([ 0.67975722, -0.99432999])}
episode index:1936
target Thresh 1.9625299501244493
current state at start:  [-0.86086192 -2.56766758]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.86086192, -2.56766758]), 'currentState': array([5.13061108, 3.2565003 ]), 'targetState': array([-0.55374018,  0.34370265]), 'effectorPosition': array([-0.1020948, -0.0525918])}
done in step count: 30
reward sum = 0.7397003733882802
running average episode reward sum: 0.9595485754685112
{'reset': False, 'endBeforeDone': False, 'stepCount': 31, 'initial state': array([-0.86086192, -2.56766758]), 'currentState': array([4.01984629, 3.93944306]), 'targetState': array([-0.55374018,  0.34370265]), 'effectorPosition': array([-0.74360935,  0.22483526])}
episode index:1937
target Thresh 1.9626048153340359
current state at start:  [ 2.22348633 -2.37612618]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.22348633, -2.37612618]), 'currentState': array([2.21674387, 3.47452393]), 'targetState': array([0.22360664, 0.05485499]), 'effectorPosition': array([0.22791697, 0.24057641])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9595694482365873
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.22348633, -2.37612618]), 'currentState': array([2.21674387, 3.47452393]), 'targetState': array([0.22360664, 0.05485499]), 'effectorPosition': array([0.22791697, 0.24057641])}
episode index:1938
target Thresh 1.9626795309628338
current state at start:  [ 4.14031513 -2.91820579]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.14031513, -2.91820579]), 'currentState': array([4.62979819, 2.89114441]), 'targetState': array([ 0.62485076, -0.71155446]), 'effectorPosition': array([ 0.24441966, -0.05153812])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9595800364530719
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 4.14031513, -2.91820579]), 'currentState': array([4.2383346 , 2.03467808]), 'targetState': array([ 0.62485076, -0.71155446]), 'effectorPosition': array([ 0.54345095, -0.89989724])}
episode index:1939
target Thresh 1.9627540973097057
current state at start:  [-3.79692107  2.3421338 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.79692107,  2.3421338 ]), 'currentState': array([2.00493447, 2.32130041]), 'targetState': array([-0.63766761, -0.23087015]), 'effectorPosition': array([-0.79725716, -0.01913148])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9590854075683022
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([-3.79692107,  2.3421338 ]), 'currentState': array([2.03246575, 2.18408038]), 'targetState': array([-0.63766761, -0.23087015]), 'effectorPosition': array([-0.92121654,  0.01574209])}
episode index:1940
target Thresh 1.9628285146729174
current state at start:  [-1.2322224  -2.13840835]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.2322224 , -2.13840835]), 'currentState': array([4.5743251 , 3.67066808]), 'targetState': array([-0.93564359,  0.11621039]), 'effectorPosition': array([-0.51874949, -0.0659603 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9591013347153562
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.2322224 , -2.13840835]), 'currentState': array([4.19346524, 4.04313507]), 'targetState': array([-0.93564359,  0.11621039]), 'effectorPosition': array([-0.86929691,  0.05933668])}
episode index:1941
target Thresh 1.962902783350138
current state at start:  [-0.23446366  2.07360169]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.23446366,  2.07360169]), 'currentState': array([6.03715001, 2.15141025]), 'targetState': array([0.60638433, 0.43657682]), 'effectorPosition': array([0.6415145 , 0.70098819])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.959117245459581
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.23446366,  2.07360169]), 'currentState': array([5.94218572, 2.22655504]), 'targetState': array([0.60638433, 0.43657682]), 'effectorPosition': array([0.63283341, 0.61644169])}
episode index:1942
target Thresh 1.9629769036384428
current state at start:  [ 2.86576487 -2.1499643 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.86576487, -2.1499643 ]), 'currentState': array([3.26905562, 4.447354  ]), 'targetState': array([-0.63036103,  0.89647963]), 'effectorPosition': array([-0.85474911,  0.86343379])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.959138286506694
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.86576487, -2.1499643 ]), 'currentState': array([3.26905562, 4.447354  ]), 'targetState': array([-0.63036103,  0.89647963]), 'effectorPosition': array([-0.85474911,  0.86343379])}
episode index:1943
target Thresh 1.9630508758343126
current state at start:  [ 2.40279906 -2.55745699]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.40279906, -2.55745699]), 'currentState': array([2.00593491, 3.98527299]), 'targetState': array([0.81118614, 0.25745879]), 'effectorPosition': array([0.53614048, 0.61896513])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9591541618737173
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 2.40279906, -2.55745699]), 'currentState': array([1.57979764, 4.15459922]), 'targetState': array([0.81118614, 0.25745879]), 'effectorPosition': array([0.84415597, 0.47830553])}
episode index:1944
target Thresh 1.9631247002336365
current state at start:  [-1.1806748   2.04027433]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.1806748 ,  2.04027433]), 'currentState': array([4.64563396, 2.15828678]), 'targetState': array([ 0.4948105 , -0.50725717]), 'effectorPosition': array([ 0.80074807, -0.50025449])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9591700209164556
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.1806748 ,  2.04027433]), 'currentState': array([4.20841303, 2.22605867]), 'targetState': array([ 0.4948105 , -0.50725717]), 'effectorPosition': array([ 0.50566706, -0.7249595 ])}
episode index:1945
target Thresh 1.9631983771317123
current state at start:  [-3.27843551  2.94555479]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.27843551,  2.94555479]), 'currentState': array([3.05926812, 3.39317509]), 'targetState': array([-0.68253937,  0.55001784]), 'effectorPosition': array([-0.0109032 ,  0.25068248])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9591807763013906
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-3.27843551,  2.94555479]), 'currentState': array([3.79443115, 4.11856776]), 'targetState': array([-0.68253937,  0.55001784]), 'effectorPosition': array([-0.8533458 ,  0.39081534])}
episode index:1946
target Thresh 1.9632719068232474
current state at start:  [-0.14060648  1.87744257]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.14060648,  1.87744257]), 'currentState': array([0.34570323, 2.1996364 ]), 'targetState': array([-0.12886211,  0.5958163 ]), 'effectorPosition': array([0.11339188, 0.90040439])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9591966053839273
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.14060648,  1.87744257]), 'currentState': array([0.69373531, 2.63735625]), 'targetState': array([-0.12886211,  0.5958163 ]), 'effectorPosition': array([-0.21323577,  0.45104678])}
episode index:1947
target Thresh 1.9633452896023609
current state at start:  [0.22949536 2.21883354]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.22949536, 2.21883354]), 'currentState': array([6.03978731, 2.61383292]), 'targetState': array([0.61525473, 0.45805867]), 'effectorPosition': array([0.2534204 , 0.45596407])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9592124182148389
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.22949536, 2.21883354]), 'currentState': array([5.79762772, 2.41073379]), 'targetState': array([0.61525473, 0.45805867]), 'effectorPosition': array([0.53740602, 0.47116029])}
episode index:1948
target Thresh 1.9634185257625838
current state at start:  [-3.16448931  1.89890553]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.16448931,  1.89890553]), 'currentState': array([2.68592911, 2.36799343]), 'targetState': array([ 0.04789085, -0.12520799]), 'effectorPosition': array([-0.56303676, -0.50218389])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9592231352911782
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-3.16448931,  1.89890553]), 'currentState': array([2.0159285 , 3.12925522]), 'targetState': array([ 0.04789085, -0.12520799]), 'effectorPosition': array([-0.01116768, -0.00524339])}
episode index:1949
target Thresh 1.9634916155968611
current state at start:  [ 1.82593744 -2.13618534]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.82593744, -2.13618534]), 'currentState': array([2.22949811, 3.71435995]), 'targetState': array([0.26380704, 0.33200043]), 'effectorPosition': array([0.33088805, 0.45793475])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9592440465038494
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.82593744, -2.13618534]), 'currentState': array([2.22949811, 3.71435995]), 'targetState': array([0.26380704, 0.33200043]), 'effectorPosition': array([0.33088805, 0.45793475])}
episode index:1950
target Thresh 1.9635645593975521
current state at start:  [-4.08198358  2.03189601]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.08198358,  2.03189601]), 'currentState': array([2.70120173, 1.59831138]), 'targetState': array([-0.9893511 , -0.86416206]), 'effectorPosition': array([-1.30583028, -0.48967756])}
done in step count: 19
reward sum = 0.8261686238355866
running average episode reward sum: 0.9591758376762388
{'reset': False, 'endBeforeDone': False, 'stepCount': 20, 'initial state': array([-4.08198358,  2.03189601]), 'currentState': array([4.5193433, 4.8181091]), 'targetState': array([-0.9893511 , -0.86416206]), 'effectorPosition': array([-1.18803843, -0.89420987])}
episode index:1951
target Thresh 1.963637357456432
current state at start:  [ 1.98411999 -1.78705615]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.98411999, -1.78705615]), 'currentState': array([1.49502931, 4.07239581]), 'targetState': array([1.17736181, 0.16124953]), 'effectorPosition': array([0.83028917, 0.34093981])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.959191628743003
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.98411999, -1.78705615]), 'currentState': array([1.09323488, 4.4886399 ]), 'targetState': array([1.17736181, 0.16124953]), 'effectorPosition': array([1.22361208, 0.24289887])}
episode index:1952
target Thresh 1.9637100100646934
current state at start:  [-0.04342223 -2.18219643]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.04342223, -2.18219643]), 'currentState': array([0.44101261, 4.33577312]), 'targetState': array([ 1.19981369, -0.74020226]), 'effectorPosition': array([ 0.96867214, -0.57107184])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.95920740363868
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.04342223, -2.18219643]), 'currentState': array([0.45751272, 4.40287584]), 'targetState': array([ 1.19981369, -0.74020226]), 'effectorPosition': array([ 1.04461382, -0.54735004])}
episode index:1953
target Thresh 1.9637825175129466
current state at start:  [ 2.17205216 -2.55230236]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.17205216, -2.55230236]), 'currentState': array([2.67205216, 4.00186387]), 'targetState': array([0.00381279, 0.58342896]), 'effectorPosition': array([0.0328547 , 0.83334072])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9592130799930103
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 2.17205216, -2.55230236]), 'currentState': array([2.61267263, 3.98793777]), 'targetState': array([0.00381279, 0.58342896]), 'effectorPosition': array([0.08668972, 0.81672256])}
episode index:1954
target Thresh 1.9638548800912217
current state at start:  [-0.85907016  1.93427867]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.85907016,  1.93427867]), 'currentState': array([5.91900399, 2.12360865]), 'targetState': array([0.1610708 , 0.66902079]), 'effectorPosition': array([0.74690132, 0.62607744])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9592237638395612
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-0.85907016,  1.93427867]), 'currentState': array([0.42170074, 2.45637928]), 'targetState': array([0.1610708 , 0.66902079]), 'effectorPosition': array([-0.05308686,  0.66978632])}
episode index:1955
target Thresh 1.9639270980889687
current state at start:  [ 0.21259619 -2.55354973]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.21259619, -2.55354973]), 'currentState': array([6.26435119, 3.2825121 ]), 'targetState': array([ 0.06440883, -0.24473291]), 'effectorPosition': array([ 0.00726581, -0.14061529])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9592446105860645
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.21259619, -2.55354973]), 'currentState': array([6.26435119, 3.2825121 ]), 'targetState': array([ 0.06440883, -0.24473291]), 'effectorPosition': array([ 0.00726581, -0.14061529])}
episode index:1956
target Thresh 1.9639991717950602
current state at start:  [1.04310627 2.2064925 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.04310627, 2.2064925 ]), 'currentState': array([0.61080221, 2.7064925 ]), 'targetState': array([ 0.19907434, -0.16610093]), 'effectorPosition': array([-0.16541587,  0.39872538])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9592603261657343
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.04310627, 2.2064925 ]), 'currentState': array([0.11080221, 3.2064925 ]), 'targetState': array([ 0.19907434, -0.16610093]), 'effectorPosition': array([ 0.00926365, -0.0642238 ])}
episode index:1957
target Thresh 1.9640711014977907
current state at start:  [2.05663834 1.95425261]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.05663834, 1.95425261]), 'currentState': array([1.56952722, 2.13242363]), 'targetState': array([-0.6863163 ,  0.53947283]), 'effectorPosition': array([-0.84579568,  0.46850955])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9592811329450164
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.05663834, 1.95425261]), 'currentState': array([1.56952722, 2.13242363]), 'targetState': array([-0.6863163 ,  0.53947283]), 'effectorPosition': array([-0.84579568,  0.46850955])}
episode index:1958
target Thresh 1.9641428874848794
current state at start:  [-3.3414673   2.57336896]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.3414673 ,  2.57336896]), 'currentState': array([2.48446858, 3.07336896]), 'targetState': array([0.20949699, 0.2407883 ]), 'effectorPosition': array([-0.04348348, -0.05255335])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.959296813836826
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.3414673 ,  2.57336896]), 'currentState': array([2.17042362, 3.57336896]), 'targetState': array([0.20949699, 0.2407883 ]), 'effectorPosition': array([0.29368592, 0.31193097])}
episode index:1959
target Thresh 1.9642145300434701
current state at start:  [-0.41811778  1.86791448]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.41811778,  1.86791448]), 'currentState': array([5.36506752, 2.1974837 ]), 'targetState': array([ 0.34235197, -0.12343136]), 'effectorPosition': array([0.8946392 , 0.16337394])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9593024271971133
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-0.41811778,  1.86791448]), 'currentState': array([4.29793454, 2.67912051]), 'targetState': array([ 0.34235197, -0.12343136]), 'effectorPosition': array([ 0.36608639, -0.27581922])}
episode index:1960
target Thresh 1.9642860294601334
current state at start:  [-3.70282569  1.98449099]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.70282569,  1.98449099]), 'currentState': array([2.08035962, 1.70226965]), 'targetState': array([-0.98666819, -0.07482387]), 'effectorPosition': array([-1.28927233,  0.27493104])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.9592933388351572
{'reset': False, 'endBeforeDone': False, 'stepCount': 7, 'initial state': array([-3.70282569,  1.98449099]), 'currentState': array([2.12917558, 1.89686272]), 'targetState': array([-0.98666819, -0.07482387]), 'effectorPosition': array([-1.16353074,  0.07455111])}
episode index:1961
target Thresh 1.964357386020867
current state at start:  [ 1.25662324 -2.22885256]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.25662324, -2.22885256]), 'currentState': array([0.83509004, 4.0711547 ]), 'targetState': array([ 0.89676394, -0.47881497]), 'effectorPosition': array([ 0.86375479, -0.2399118 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9593140863688803
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.25662324, -2.22885256]), 'currentState': array([0.83509004, 4.0711547 ]), 'targetState': array([ 0.89676394, -0.47881497]), 'effectorPosition': array([ 0.86375479, -0.2399118 ])}
episode index:1962
target Thresh 1.964428600011097
current state at start:  [1.06160925 2.33525248]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.06160925, 2.33525248]), 'currentState': array([1.41477094, 2.83525248]), 'targetState': array([-0.55716204,  0.08317264]), 'effectorPosition': array([-0.29067342,  0.09285291])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9593297185205009
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.06160925, 2.33525248]), 'currentState': array([1.69309066, 2.45796205]), 'targetState': array([-0.55716204,  0.08317264]), 'effectorPosition': array([-0.6543076 ,  0.14598682])}
episode index:1963
target Thresh 1.9644996717156797
current state at start:  [4.25129014e-04 2.61757550e+00]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([4.25129014e-04, 2.61757550e+00]), 'currentState': array([5.92453018, 3.1175755 ]), 'targetState': array([-0.03971113, -0.09966304]), 'effectorPosition': array([0.00869962, 0.02238554])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.959350426403128
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([4.25129014e-04, 2.61757550e+00]), 'currentState': array([5.92453018, 3.1175755 ]), 'targetState': array([-0.03971113, -0.09966304]), 'effectorPosition': array([0.00869962, 0.02238554])}
episode index:1964
target Thresh 1.964570601418902
current state at start:  [ 1.38865552 -2.7333007 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.38865552, -2.7333007 ]), 'currentState': array([1.64089448, 3.21169748]), 'targetState': array([ 0.24482156, -0.01891337]), 'effectorPosition': array([0.06970335, 0.00735648])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9593711132090296
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.38865552, -2.7333007 ]), 'currentState': array([1.64089448, 3.21169748]), 'targetState': array([ 0.24482156, -0.01891337]), 'effectorPosition': array([0.06970335, 0.00735648])}
episode index:1965
target Thresh 1.9646413894044825
current state at start:  [0.28696932 1.95150745]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.28696932, 1.95150745]), 'currentState': array([0.38953556, 2.19869951]), 'targetState': array([0.47096444, 1.05997223]), 'effectorPosition': array([0.07432078, 0.90530551])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9588831319713852
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([0.28696932, 1.95150745]), 'currentState': array([0.02269148, 2.25645703]), 'targetState': array([0.47096444, 1.05997223]), 'effectorPosition': array([0.34915931, 0.78212448])}
episode index:1966
target Thresh 1.9647120359555736
current state at start:  [ 1.52532161 -2.09413691]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.52532161, -2.09413691]), 'currentState': array([1.91702555, 4.14737304]), 'targetState': array([0.5413929 , 0.71671581]), 'effectorPosition': array([0.63680829, 0.7236136 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9589040353104947
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.52532161, -2.09413691]), 'currentState': array([1.91702555, 4.14737304]), 'targetState': array([0.5413929 , 0.71671581]), 'effectorPosition': array([0.63680829, 0.7236136 ])}
episode index:1967
target Thresh 1.9647825413547615
current state at start:  [0.29247732 2.08715023]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.29247732, 2.08715023]), 'currentState': array([0.11453275, 2.53840824]), 'targetState': array([-0.11017854,  0.00974724]), 'effectorPosition': array([0.11048167, 0.58371829])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9589198361055605
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.29247732, 2.08715023]), 'currentState': array([6.17356749, 2.97475653]), 'targetState': array([-0.11017854,  0.00974724]), 'effectorPosition': array([0.03196861, 0.16354754])}
episode index:1968
target Thresh 1.9648529058840678
current state at start:  [0.00304715 2.08178541]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.00304715, 2.08178541]), 'currentState': array([0.4018722 , 2.49104935]), 'targetState': array([-0.21926292,  0.38169228]), 'effectorPosition': array([-0.04891003,  0.63725823])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9589356208510631
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.00304715, 2.08178541]), 'currentState': array([0.71426062, 2.94837061]), 'targetState': array([-0.21926292,  0.38169228]), 'effectorPosition': array([-0.11172488,  0.15727777])}
episode index:1969
target Thresh 1.9649231298249508
current state at start:  [-1.26331123 -2.71431105]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.26331123, -2.71431105]), 'currentState': array([4.52920483, 4.03703021]), 'targetState': array([-0.85170215, -0.70401094]), 'effectorPosition': array([-0.83570238, -0.22637754])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9589513895714432
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.26331123, -2.71431105]), 'currentState': array([4.73379622, 4.45198749]), 'targetState': array([-0.85170215, -0.70401094]), 'effectorPosition': array([-0.95017095, -0.76304529])}
episode index:1970
target Thresh 1.9649932134583064
current state at start:  [1.11145142 1.6572069 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.11145142, 1.6572069 ]), 'currentState': array([1.30772087, 2.1572069 ]), 'targetState': array([-0.40360915,  0.62847365]), 'effectorPosition': array([-0.6881296 ,  0.64786415])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9589671422910925
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.11145142, 1.6572069 ]), 'currentState': array([0.80772087, 2.50812102]), 'targetState': array([-0.40360915,  0.62847365]), 'effectorPosition': array([-0.29370959,  0.54934505])}
episode index:1971
target Thresh 1.965063157064469
current state at start:  [1.14912874 1.89205371]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.14912874, 1.89205371]), 'currentState': array([0.64912874, 2.16762053]), 'targetState': array([-0.09681002,  1.20316933]), 'effectorPosition': array([-0.15108995,  0.92365294])}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9589394622366896
{'reset': False, 'endBeforeDone': False, 'stepCount': 11, 'initial state': array([1.14912874, 1.89205371]), 'currentState': array([0.47331605, 2.06729408]), 'targetState': array([-0.09681002,  1.20316933]), 'effectorPosition': array([0.06528116, 1.02129339])}
episode index:1972
target Thresh 1.9651329609232133
current state at start:  [ 0.68986538 -2.60658716]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.68986538, -2.60658716]), 'currentState': array([1.18986538, 3.27937929]), 'targetState': array([-0.22919043,  0.46636411]), 'effectorPosition': array([ 0.13102922, -0.04226684])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9589452197317547
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 0.68986538, -2.60658716]), 'currentState': array([1.05297873, 2.59514653]), 'targetState': array([-0.22919043,  0.46636411]), 'effectorPosition': array([-0.37944694,  0.38375334])}
episode index:1973
target Thresh 1.965202625313755
current state at start:  [-0.07977034  2.64132084]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.07977034,  2.64132084]), 'currentState': array([5.92096122, 2.24167488]), 'targetState': array([0.72074504, 0.73090784]), 'effectorPosition': array([0.63133406, 0.5983883 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9589660174927822
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.07977034,  2.64132084]), 'currentState': array([5.92096122, 2.24167488]), 'targetState': array([0.72074504, 0.73090784]), 'effectorPosition': array([0.63133406, 0.5983883 ])}
episode index:1974
target Thresh 1.9652721505147515
current state at start:  [ 0.23213077 -2.4949101 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.23213077, -2.4949101 ]), 'currentState': array([0.58851555, 3.4001283 ]), 'targetState': array([ 0.64719263, -0.10320519]), 'effectorPosition': array([ 0.16957   , -0.19420406])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9584804650788618
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([ 0.23213077, -2.4949101 ]), 'currentState': array([6.16479612, 3.43491419]), 'targetState': array([ 0.64719263, -0.10320519]), 'effectorPosition': array([ 0.00826187, -0.29215434])}
episode index:1975
target Thresh 1.9653415368043035
current state at start:  [ 2.67171624 -2.7632136 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.67171624, -2.7632136 ]), 'currentState': array([2.54117647, 3.34342856]), 'targetState': array([0.16506902, 0.09779861]), 'effectorPosition': array([0.09651238, 0.17687561])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9585014769892469
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.67171624, -2.7632136 ]), 'currentState': array([2.54117647, 3.34342856]), 'targetState': array([0.16506902, 0.09779861]), 'effectorPosition': array([0.09651238, 0.17687561])}
episode index:1976
target Thresh 1.9654107844599567
current state at start:  [-3.30248553  2.71583614]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.30248553,  2.71583614]), 'currentState': array([2.48069977, 3.21583614]), 'targetState': array([-0.22949639,  0.49314838]), 'effectorPosition': array([0.04335568, 0.06024823])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9585124018870774
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-3.30248553,  2.71583614]), 'currentState': array([3.0457988 , 3.89216346]), 'targetState': array([-0.22949639,  0.49314838]), 'effectorPosition': array([-0.2022315 ,  0.70462975])}
episode index:1977
target Thresh 1.9654798937587017
current state at start:  [1.71859323 2.09061418]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.71859323, 2.09061418]), 'currentState': array([1.2205539 , 2.59061418]), 'targetState': array([-0.08726374,  0.29417209]), 'effectorPosition': array([-0.44095972,  0.31863642])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9585283207941112
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.71859323, 2.09061418]), 'currentState': array([0.75080981, 2.75013512]), 'targetState': array([-0.08726374,  0.29417209]), 'effectorPosition': array([-0.20498817,  0.33056311])}
episode index:1978
target Thresh 1.9655488649769755
current state at start:  [ 2.48235471 -2.67343012]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.48235471, -2.67343012]), 'currentState': array([2.73663146, 4.10975518]), 'targetState': array([0.38383419, 1.24177581]), 'effectorPosition': array([-0.07356742,  0.92787891])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9585442236133158
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 2.48235471, -2.67343012]), 'currentState': array([2.29033367, 4.60975518]), 'targetState': array([0.38383419, 1.24177581]), 'effectorPosition': array([0.15663693, 1.33062296])}
episode index:1979
target Thresh 1.9656176983906635
current state at start:  [1.98459598 1.68819114]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.98459598, 1.68819114]), 'currentState': array([1.48459598, 2.02587148]), 'targetState': array([-0.2917949 ,  1.11433706]), 'effectorPosition': array([-0.84664001,  0.63572089])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9585601103690666
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.98459598, 1.68819114]), 'currentState': array([0.98459598, 1.91190607]), 'targetState': array([-0.2917949 ,  1.11433706]), 'effectorPosition': array([-0.41691562,  1.07569288])}
episode index:1980
target Thresh 1.965686394275099
current state at start:  [-0.4568176  -2.42437016]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.4568176 , -2.42437016]), 'currentState': array([6.24616173, 3.72895245]), 'targetState': array([ 0.83315113, -0.31724936]), 'effectorPosition': array([ 0.14696597, -0.55998896])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.9585514884806426
{'reset': False, 'endBeforeDone': False, 'stepCount': 7, 'initial state': array([-0.4568176 , -2.42437016]), 'currentState': array([0.62679142, 3.87470854]), 'targetState': array([ 0.83315113, -0.31724936]), 'effectorPosition': array([ 0.60058435, -0.3912961 ])}
episode index:1981
target Thresh 1.965754952905066
current state at start:  [ 0.74089258 -2.62332922]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.74089258, -2.62332922]), 'currentState': array([0.68807532, 3.95645723]), 'targetState': array([ 1.07306061, -0.02416144]), 'effectorPosition': array([ 0.70466535, -0.36264704])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.958567355539936
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.74089258, -2.62332922]), 'currentState': array([1.01595567, 4.10604506]), 'targetState': array([ 1.07306061, -0.02416144]), 'effectorPosition': array([ 0.92506109, -0.06729112])}
episode index:1982
target Thresh 1.9658233745547988
current state at start:  [ 0.85724156 -2.05850547]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.85724156, -2.05850547]), 'currentState': array([0.53028645, 3.88064248]), 'targetState': array([ 0.45687676, -0.54815172]), 'effectorPosition': array([ 0.5657475 , -0.44912353])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9585882494604907
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.85724156, -2.05850547]), 'currentState': array([0.53028645, 3.88064248]), 'targetState': array([ 0.45687676, -0.54815172]), 'effectorPosition': array([ 0.5657475 , -0.44912353])}
episode index:1983
target Thresh 1.9658916594979845
current state at start:  [ 2.44280273 -2.37979635]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.44280273, -2.37979635]), 'currentState': array([2.93556607, 3.59796189]), 'targetState': array([-0.15504119,  0.30376111]), 'effectorPosition': array([-0.0100239 ,  0.45230808])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9586091223186256
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.44280273, -2.37979635]), 'currentState': array([2.93556607, 3.59796189]), 'targetState': array([-0.15504119,  0.30376111]), 'effectorPosition': array([-0.0100239 ,  0.45230808])}
episode index:1984
target Thresh 1.9659598080077625
current state at start:  [-0.26435944  2.13626718]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.26435944,  2.13626718]), 'currentState': array([6.15791035, 2.51784771]), 'targetState': array([0.28778606, 0.25795237]), 'effectorPosition': array([0.25980676, 0.55597376])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9586249363627976
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.26435944,  2.13626718]), 'currentState': array([6.05361863, 2.9046199 ]), 'targetState': array([0.28778606, 0.25795237]), 'effectorPosition': array([0.0806349 , 0.22224266])}
episode index:1985
target Thresh 1.9660278203567274
current state at start:  [-1.44799211 -2.72768784]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.44799211, -2.72768784]), 'currentState': array([5.3351932 , 3.46728097]), 'targetState': array([ 0.56705555, -1.04814166]), 'effectorPosition': array([-0.22922255, -0.22933729])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9586357495871869
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.44799211, -2.72768784]), 'currentState': array([0.05200789, 4.40857579]), 'targetState': array([ 0.56705555, -1.04814166]), 'effectorPosition': array([ 0.74949516, -0.91647976])}
episode index:1986
target Thresh 1.966095696816928
current state at start:  [-0.19330963  1.82719936]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.19330963,  1.82719936]), 'currentState': array([5.72676498, 1.89122676]), 'targetState': array([1.21285677, 0.3988798 ]), 'effectorPosition': array([1.08295671, 0.44413347])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9586565670257439
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.19330963,  1.82719936]), 'currentState': array([5.72676498, 1.89122676]), 'targetState': array([1.21285677, 0.3988798 ]), 'effectorPosition': array([1.08295671, 0.44413347])}
episode index:1987
target Thresh 1.9661634376598711
current state at start:  [-2.61413907  2.57966686]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.61413907,  2.57966686]), 'currentState': array([3.21351441, 2.73479349]), 'targetState': array([-0.54939609, -0.30732558]), 'effectorPosition': array([-0.05296414, -0.40051316])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9586723333401173
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.61413907,  2.57966686]), 'currentState': array([2.78902544, 2.50511143]), 'targetState': array([-0.54939609, -0.30732558]), 'effectorPosition': array([-0.38900418, -0.49019524])}
episode index:1988
target Thresh 1.9662310431565195
current state at start:  [-1.7149295   1.77486672]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.7149295 ,  1.77486672]), 'currentState': array([4.06825581, 1.91471397]), 'targetState': array([ 0.03123865, -1.27208195]), 'effectorPosition': array([ 0.35476724, -1.0953467 ])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9586831064254163
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.7149295 ,  1.77486672]), 'currentState': array([4.02414426, 1.69179804]), 'targetState': array([ 0.03123865, -1.27208195]), 'effectorPosition': array([ 0.20820308, -1.30967101])}
episode index:1989
target Thresh 1.9662985135772957
current state at start:  [-2.0300941  -1.63001478]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.0300941 , -1.63001478]), 'currentState': array([3.75309121, 4.27030834]), 'targetState': array([-0.61927568,  0.33662917]), 'effectorPosition': array([-0.98739725,  0.41158798])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9586988435578658
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.0300941 , -1.63001478]), 'currentState': array([3.67252104, 4.0189003 ]), 'targetState': array([-0.61927568,  0.33662917]), 'effectorPosition': array([-0.7004921 ,  0.48048201])}
episode index:1990
target Thresh 1.966365849192081
current state at start:  [-0.05753324 -2.32213719]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.05753324, -2.32213719]), 'currentState': array([0.35035771, 3.82809845]), 'targetState': array([ 1.25130567, -0.1555747 ]), 'effectorPosition': array([ 0.43032731, -0.51757843])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9587095925063551
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-0.05753324, -2.32213719]), 'currentState': array([0.90949703, 4.25673948]), 'targetState': array([ 1.25130567, -0.1555747 ]), 'effectorPosition': array([ 1.05256957, -0.10957195])}
episode index:1991
target Thresh 1.9664330502702183
current state at start:  [-0.08433925 -2.41004798]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.08433925, -2.41004798]), 'currentState': array([4.12391138e-03, 4.15778289e+00]), 'targetState': array([ 0.41129817, -0.7050509 ]), 'effectorPosition': array([ 0.47689326, -0.84814849])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9587303206225668
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.08433925, -2.41004798]), 'currentState': array([4.12391138e-03, 4.15778289e+00]), 'targetState': array([ 0.41129817, -0.7050509 ]), 'effectorPosition': array([ 0.47689326, -0.84814849])}
episode index:1992
target Thresh 1.966500117080512
current state at start:  [0.66046845 2.17986342]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.66046845, 2.17986342]), 'currentState': array([1.16046845, 2.57217598]), 'targetState': array([-0.86214799,  0.69836218]), 'effectorPosition': array([-0.43144504,  0.3597554 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.958746010376394
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.66046845, 2.17986342]), 'currentState': array([1.63987594, 2.07482082]), 'targetState': array([-0.86214799,  0.69836218]), 'effectorPosition': array([-0.90924653,  0.45537216])}
episode index:1993
target Thresh 1.9665670498912293
current state at start:  [0.43486038 1.858098  ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.43486038, 1.858098  ]), 'currentState': array([0.93486038, 2.282794  ]), 'targetState': array([-0.23192686,  0.58926479]), 'effectorPosition': array([-0.40317794,  0.72852776])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9587666994383918
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.43486038, 1.858098  ]), 'currentState': array([0.93486038, 2.282794  ]), 'targetState': array([-0.23192686,  0.58926479]), 'effectorPosition': array([-0.40317794,  0.72852776])}
episode index:1994
target Thresh 1.9666338489701016
current state at start:  [-1.17617663 -2.0419262 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.17617663, -2.0419262 ]), 'currentState': array([4.91505252, 3.74481491]), 'targetState': array([-0.48577238,  0.06836068]), 'effectorPosition': array([-0.52016525, -0.28706149])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9587823552281469
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.17617663, -2.0419262 ]), 'currentState': array([4.78794847, 3.59706564]), 'targetState': array([-0.48577238,  0.06836068]), 'effectorPosition': array([-0.43093629, -0.13486208])}
episode index:1995
target Thresh 1.9667005145843253
current state at start:  [-3.64530963  1.67113042]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.64530963,  1.67113042]), 'currentState': array([2.15789533, 1.94308263]), 'targetState': array([-0.5985566 ,  0.22037028]), 'effectorPosition': array([-1.12797156,  0.01371231])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9587979953307381
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.64530963,  1.67113042]), 'currentState': array([1.6605936, 2.2969622]), 'targetState': array([-0.5985566 ,  0.22037028]), 'effectorPosition': array([-0.77484381,  0.26758508])}
episode index:1996
target Thresh 1.966767047000563
current state at start:  [ 1.33602992 -2.46580515]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.33602992, -2.46580515]), 'currentState': array([1.78811541, 4.20288929]), 'targetState': array([0.13450607, 0.96184269]), 'effectorPosition': array([0.7420055, 0.6884379])}
done in step count: 76
reward sum = 0.46588077516979337
running average episode reward sum: 0.9585511664773775
{'reset': False, 'endBeforeDone': False, 'stepCount': 77, 'initial state': array([ 1.33602992, -2.46580515]), 'currentState': array([2.41380734, 4.43880437]), 'targetState': array([0.13450607, 0.96184269]), 'effectorPosition': array([0.09556088, 1.20436673])}
episode index:1997
target Thresh 1.9668334464849444
current state at start:  [-1.45428074  2.26047535]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.45428074,  2.26047535]), 'currentState': array([4.32890457, 2.42770208]), 'targetState': array([-0.11357626, -0.67367752]), 'effectorPosition': array([ 0.51585953, -0.47143258])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9580714111388002
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([-1.45428074,  2.26047535]), 'currentState': array([2.71086329, 2.43754399]), 'targetState': array([-0.11357626, -0.67367752]), 'effectorPosition': array([-0.48632781, -0.48890679])}
episode index:1998
target Thresh 1.9668997133030675
current state at start:  [-3.51755428  2.0664644 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.51755428,  2.0664644 ]), 'currentState': array([2.34574152, 2.50301242]), 'targetState': array([-0.02530122, -0.46347428]), 'effectorPosition': array([-0.56373419, -0.27625731])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9575921357955592
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([-3.51755428,  2.0664644 ]), 'currentState': array([2.43944792, 2.75617052]), 'targetState': array([-0.02530122, -0.46347428]), 'effectorPosition': array([-0.29881748, -0.23964242])}
episode index:1999
target Thresh 1.9669658477199996
current state at start:  [-2.03789306  2.50075111]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.03789306,  2.50075111]), 'currentState': array([3.75883096, 2.01996231]), 'targetState': array([-0.13770411, -1.29910851]), 'effectorPosition': array([ 0.05998846, -1.06206054])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9576033897276615
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-2.03789306,  2.50075111]), 'currentState': array([3.79471385, 1.73325591]), 'targetState': array([-0.13770411, -1.29910851]), 'effectorPosition': array([-0.0660672 , -1.29311382])}
episode index:2000
target Thresh 1.9670318500002786
current state at start:  [-0.92340552  2.5212573 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.92340552,  2.5212573 ]), 'currentState': array([4.8981833, 2.581405 ]), 'targetState': array([ 0.25588845, -0.64239662]), 'effectorPosition': array([ 0.5504352 , -0.05206017])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9576146324114557
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-0.92340552,  2.5212573 ]), 'currentState': array([3.99457409, 2.31488813]), 'targetState': array([ 0.25588845, -0.64239662]), 'effectorPosition': array([ 0.34191446, -0.72697088])}
episode index:2001
target Thresh 1.9670977204079134
current state at start:  [ 0.42345751 -2.70977513]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.42345751, -2.70977513]), 'currentState': array([0.43001807, 3.255827  ]), 'targetState': array([0.52006089, 0.1254663 ]), 'effectorPosition': array([ 0.05344361, -0.10089144])}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9575972148600154
{'reset': False, 'endBeforeDone': False, 'stepCount': 9, 'initial state': array([ 0.42345751, -2.70977513]), 'currentState': array([5.55527482, 2.61207842]), 'targetState': array([0.52006089, 0.1254663 ]), 'effectorPosition': array([0.43829841, 0.28598849])}
episode index:2002
target Thresh 1.9671634592063862
current state at start:  [-1.39945556 -2.70825527]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.39945556, -2.70825527]), 'currentState': array([5.11750848, 3.32334053]), 'targetState': array([0.04962086, 0.04127695]), 'effectorPosition': array([-0.15962668, -0.08637584])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9576183844981282
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.39945556, -2.70825527]), 'currentState': array([5.11750848, 3.32334053]), 'targetState': array([0.04962086, 0.04127695]), 'effectorPosition': array([-0.15962668, -0.08637584])}
episode index:2003
target Thresh 1.967229066658652
current state at start:  [-2.10808654 -1.73823219]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.10808654, -1.73823219]), 'currentState': array([4.67509877, 4.51127164]), 'targetState': array([-0.70520995, -0.6435272 ]), 'effectorPosition': array([-1.00899684, -0.76314928])}
done in step count: 86
reward sum = 0.421334222154768
running average episode reward sum: 0.9573507776306913
{'reset': False, 'endBeforeDone': False, 'stepCount': 87, 'initial state': array([-2.10808654, -1.73823219]), 'currentState': array([4.96624419, 4.38052764]), 'targetState': array([-0.70520995, -0.6435272 ]), 'effectorPosition': array([-0.74582159, -0.89002439])}
episode index:2004
target Thresh 1.967294543027141
current state at start:  [0.02395089 2.33438442]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.02395089, 2.33438442]), 'currentState': array([5.99592759, 2.74709202]), 'targetState': array([-0.00194316,  0.00012779]), 'effectorPosition': array([0.18255856, 0.34683592])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9573670615321224
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.02395089, 2.33438442]), 'currentState': array([5.82018797, 3.06082208]), 'targetState': array([-0.00194316,  0.00012779]), 'effectorPosition': array([0.03895243, 0.07073222])}
episode index:2005
target Thresh 1.967359888573758
current state at start:  [ 1.50013252 -2.20222358]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.50013252, -2.20222358]), 'currentState': array([1.99661569, 3.58096173]), 'targetState': array([-0.10291729,  0.26333242]), 'effectorPosition': array([0.34815036, 0.2622039 ])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9573783940039409
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 1.50013252, -2.20222358]), 'currentState': array([2.48929286, 3.40543878]), 'targetState': array([-0.10291729,  0.26333242]), 'effectorPosition': array([0.13080596, 0.22825788])}
episode index:2006
target Thresh 1.967425103559886
current state at start:  [1.70190677 1.99597322]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.70190677, 1.99597322]), 'currentState': array([1.26425102, 2.40804888]), 'targetState': array([-0.32807355,  0.37347709]), 'effectorPosition': array([-0.56068252,  0.44723833])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9573996304792752
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.70190677, 1.99597322]), 'currentState': array([1.26425102, 2.40804888]), 'targetState': array([-0.32807355,  0.37347709]), 'effectorPosition': array([-0.56068252,  0.44723833])}
episode index:2007
target Thresh 1.9674901882463849
current state at start:  [-3.55509234  2.2649897 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.55509234,  2.2649897 ]), 'currentState': array([2.2722553 , 2.27686891]), 'targetState': array([-0.51579036,  0.06367491]), 'effectorPosition': array([-0.8078733 , -0.22280041])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9574158657230605
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.55509234,  2.2649897 ]), 'currentState': array([1.77800828, 2.3997549 ]), 'targetState': array([-0.51579036,  0.06367491]), 'effectorPosition': array([-0.71525139,  0.11814895])}
episode index:2008
target Thresh 1.9675551428935933
current state at start:  [-1.31808821 -1.6965252 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.31808821, -1.6965252 ]), 'currentState': array([5.11729176, 4.18641221]), 'targetState': array([-0.23977421, -0.46908012]), 'effectorPosition': array([-0.59875009, -0.79836229])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9574271569795447
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.31808821, -1.6965252 ]), 'currentState': array([5.26936559, 3.90151951]), 'targetState': array([-0.23977421, -0.46908012]), 'effectorPosition': array([-0.43931978, -0.59768331])}
episode index:2009
target Thresh 1.9676199677613302
current state at start:  [1.72293951 1.9223023 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.72293951, 1.9223023 ]), 'currentState': array([1.4815554 , 2.06424131]), 'targetState': array([-0.69732842,  0.12406095]), 'effectorPosition': array([-0.8302932 ,  0.60273358])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9574433623740823
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.72293951, 1.9223023 ]), 'currentState': array([1.65372621, 2.35428079]), 'targetState': array([-0.69732842,  0.12406095]), 'effectorPosition': array([-0.73039787,  0.23455139])}
episode index:2010
target Thresh 1.967684663108895
current state at start:  [-1.10271976 -1.73286529]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.10271976, -1.73286529]), 'currentState': array([5.14353339, 4.70101287]), 'targetState': array([-0.52306474, -1.24148078]), 'effectorPosition': array([-0.49527264, -1.31603696])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9574645243022901
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.10271976, -1.73286529]), 'currentState': array([5.14353339, 4.70101287]), 'targetState': array([-0.52306474, -1.24148078]), 'effectorPosition': array([-0.49527264, -1.31603696])}
episode index:2011
target Thresh 1.967749229195069
current state at start:  [ 3.58239515 -2.62603998]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.58239515, -2.62603998]), 'currentState': array([4.06211702, 3.17529331]), 'targetState': array([ 0.44284378, -0.10958313]), 'effectorPosition': array([-0.02716168,  0.01994668])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9574806950158575
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.58239515, -2.62603998]), 'currentState': array([4.50080909, 2.6767026 ]), 'targetState': array([ 0.44284378, -0.10958313]), 'effectorPosition': array([ 0.41603942, -0.19791281])}
episode index:2012
target Thresh 1.9678136662781167
current state at start:  [ 1.54948684 -2.5231707 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.54948684, -2.5231707 ]), 'currentState': array([1.9035364 , 3.26001461]), 'targetState': array([-0.18245427, -0.19321643]), 'effectorPosition': array([0.10937755, 0.04520984])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9574968496631423
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.54948684, -2.5231707 ]), 'currentState': array([2.14247184, 2.76001461]), 'targetState': array([-0.18245427, -0.19321643]), 'effectorPosition': array([-0.3520873 , -0.14099019])}
episode index:2013
target Thresh 1.9678779746157866
current state at start:  [-0.56454182 -2.45929988]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.56454182, -2.45929988]), 'currentState': array([5.64281119, 3.54316383]), 'targetState': array([-0.09129848, -0.24177175]), 'effectorPosition': array([-0.16974954, -0.36095577])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9575179535113731
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.56454182, -2.45929988]), 'currentState': array([5.64281119, 3.54316383]), 'targetState': array([-0.09129848, -0.24177175]), 'effectorPosition': array([-0.16974954, -0.36095577])}
episode index:2014
target Thresh 1.9679421544653122
current state at start:  [ 1.78719311 -1.6778173 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.78719311, -1.6778173 ]), 'currentState': array([2.19681483, 4.10536801]), 'targetState': array([-0.1868945 ,  0.29096422]), 'effectorPosition': array([0.41389661, 0.82936317])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9575242964624842
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 1.78719311, -1.6778173 ]), 'currentState': array([2.89160697, 3.46632412]), 'targetState': array([-0.1868945 ,  0.29096422]), 'effectorPosition': array([0.02829187, 0.32206629])}
episode index:2015
target Thresh 1.968006206083413
current state at start:  [ 0.6920035 -2.5164792]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.6920035, -2.5164792]), 'currentState': array([1.01686562, 3.33990577]), 'targetState': array([-0.06486779, -0.02038667]), 'effectorPosition': array([ 0.17786482, -0.08696823])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9575404054424135
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.6920035, -2.5164792]), 'currentState': array([1.35813636, 2.9702256 ]), 'targetState': array([-0.06486779, -0.02038667]), 'effectorPosition': array([-0.16359651,  0.05030955])}
episode index:2016
target Thresh 1.9680701297262955
current state at start:  [1.65671434 2.0333643 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.65671434, 2.0333643 ]), 'currentState': array([1.15671434, 2.11186149]), 'targetState': array([-0.67503332,  0.80410907]), 'effectorPosition': array([-0.58959879,  0.78884388])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9575614563073404
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.65671434, 2.0333643 ]), 'currentState': array([1.15671434, 2.11186149]), 'targetState': array([-0.67503332,  0.80410907]), 'effectorPosition': array([-0.58959879,  0.78884388])}
episode index:2017
target Thresh 1.9681339256496542
current state at start:  [ 1.74651305 -1.72237407]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.74651305, -1.72237407]), 'currentState': array([1.2732612 , 4.95201011]), 'targetState': array([1.26388023, 0.58794569]), 'effectorPosition': array([1.29148798, 0.89818038])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9575775309077827
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.74651305, -1.72237407]), 'currentState': array([1.04396392, 4.97037482]), 'targetState': array([1.26388023, 0.58794569]), 'effectorPosition': array([1.4668757 , 0.59878446])}
episode index:2018
target Thresh 1.968197594108673
current state at start:  [ 3.0859608 -2.2344976]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.0859608, -2.2344976]), 'currentState': array([3.42394301, 3.54904242]), 'targetState': array([-0.41553528, -0.00235915]), 'effectorPosition': array([-0.18903002,  0.35776931])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9575790259444802
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([ 3.0859608, -2.2344976]), 'currentState': array([4.27031158, 3.55252485]), 'targetState': array([-0.41553528, -0.00235915]), 'effectorPosition': array([-0.39667791,  0.09565016])}
episode index:2019
target Thresh 1.968261135358026
current state at start:  [1.92642287 1.83309192]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.92642287, 1.83309192]), 'currentState': array([1.42642287, 2.18385816]), 'targetState': array([-0.40371681,  0.64323754]), 'effectorPosition': array([-0.74828911,  0.53787975])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9575950759316364
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.92642287, 1.83309192]), 'currentState': array([0.92642287, 2.30862279]), 'targetState': array([-0.40371681,  0.64323754]), 'effectorPosition': array([-0.3949388 ,  0.70615925])}
episode index:2020
target Thresh 1.968324549651878
current state at start:  [ 0.92904067 -1.90945566]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.92904067, -1.90945566]), 'currentState': array([1.38493347, 4.09742541]), 'targetState': array([0.73598393, 0.55233264]), 'effectorPosition': array([0.88090822, 0.26484554])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9576111100355792
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.92904067, -1.90945566]), 'currentState': array([1.74438873, 4.32442828]), 'targetState': array([0.73598393, 0.55233264]), 'effectorPosition': array([0.8043891 , 0.77224041])}
episode index:2021
target Thresh 1.9683878372438863
current state at start:  [ 1.03933203 -2.71034696]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.03933203, -2.71034696]), 'currentState': array([0.6566818 , 3.07283835]), 'targetState': array([-0.56085761, -0.83108672]), 'effectorPosition': array([-0.04006963,  0.05585443])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9576125862472332
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([ 1.03933203, -2.71034696]), 'currentState': array([5.3714085 , 4.11932687]), 'targetState': array([-0.56085761, -0.83108672]), 'effectorPosition': array([-0.38548361, -0.8565026 ])}
episode index:2022
target Thresh 1.9684509983872014
current state at start:  [-3.07803899  1.88137562]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.07803899,  1.88137562]), 'currentState': array([2.70514631, 2.05136305]), 'targetState': array([-0.56216842, -0.43107988]), 'effectorPosition': array([-0.86215353, -0.57630525])}
done in step count: 51
reward sum = 0.598956006466161
running average episode reward sum: 0.9574352967861451
{'reset': False, 'endBeforeDone': False, 'stepCount': 52, 'initial state': array([-3.07803899,  1.88137562]), 'currentState': array([2.43455876, 2.2433736 ]), 'targetState': array([-0.56216842, -0.43107988]), 'effectorPosition': array([-0.79474175, -0.34982491])}
episode index:2023
target Thresh 1.9685140333344682
current state at start:  [ 3.36783258 -2.16027828]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.36783258, -2.16027828]), 'currentState': array([2.95531968, 4.62290702]), 'targetState': array([0.25072104, 1.1290988 ]), 'effectorPosition': array([-0.71042787,  1.14741756])}
done in step count: 37
reward sum = 0.6894490858690777
running average episode reward sum: 0.9573028925317395
{'reset': False, 'endBeforeDone': False, 'stepCount': 38, 'initial state': array([ 3.36783258, -2.16027828]), 'currentState': array([0.17403135, 2.12195637]), 'targetState': array([0.25072104, 1.1290988 ]), 'effectorPosition': array([0.32161604, 0.92152669])}
episode index:2024
target Thresh 1.968576942337826
current state at start:  [-0.01224475 -1.96997684]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.01224475, -1.96997684]), 'currentState': array([5.96617485, 4.63493461]), 'targetState': array([ 0.42477814, -1.11298571]), 'effectorPosition': array([ 0.56585742, -1.23492975])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9573239775230818
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.01224475, -1.96997684]), 'currentState': array([5.96617485, 4.63493461]), 'targetState': array([ 0.42477814, -1.11298571]), 'effectorPosition': array([ 0.56585742, -1.23492975])}
episode index:2025
target Thresh 1.9686397256489117
current state at start:  [ 3.48184889 -2.05765097]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.48184889, -2.05765097]), 'currentState': array([3.47515222, 3.74134506]), 'targetState': array([0.11142937, 0.12317291]), 'effectorPosition': array([-0.34970714,  0.47618708])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9573401058658642
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.48184889, -2.05765097]), 'currentState': array([3.7053256 , 3.24663387]), 'targetState': array([0.11142937, 0.12317291]), 'effectorPosition': array([-0.06068402,  0.08567944])}
episode index:2026
target Thresh 1.968702383518858
current state at start:  [-0.89154653  2.7209585 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.89154653,  2.7209585 ]), 'currentState': array([4.91641634, 3.15570059]), 'targetState': array([-0.52051472, -0.70204243]), 'effectorPosition': array([-0.01379469, -0.00295583])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9573464990055455
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-0.89154653,  2.7209585 ]), 'currentState': array([5.2020696 , 4.21343523]), 'targetState': array([-0.52051472, -0.70204243]), 'effectorPosition': array([-0.52961294, -0.87321012])}
episode index:2027
target Thresh 1.9687649161982965
current state at start:  [0.3534004  2.73165503]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.3534004 , 2.73165503]), 'currentState': array([0.1374339 , 3.21928275]), 'targetState': array([-0.32111149, -0.53921211]), 'effectorPosition': array([ 0.01362088, -0.0764669 ])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9573528858403554
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([0.3534004 , 2.73165503]), 'currentState': array([5.52935494, 3.8841717 ]), 'targetState': array([-0.32111149, -0.53921211]), 'effectorPosition': array([-0.27086412, -0.67318531])}
episode index:2028
target Thresh 1.9688273239373584
current state at start:  [0.7487661  2.85698708]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.7487661 , 2.85698708]), 'currentState': array([0.34643561, 3.03110549]), 'targetState': array([0.30856331, 0.25037763]), 'effectorPosition': array([-0.0317041 ,  0.10578209])}
done in step count: 71
reward sum = 0.4898902730042049
running average episode reward sum: 0.9571224951982479
{'reset': False, 'endBeforeDone': False, 'stepCount': 72, 'initial state': array([0.7487661 , 2.85698708]), 'currentState': array([6.13259767, 2.88560913]), 'targetState': array([0.30856331, 0.25037763]), 'effectorPosition': array([0.0702009 , 0.24544319])}
episode index:2029
target Thresh 1.9688896069856743
current state at start:  [-2.13385925  2.57329607]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.13385925,  2.57329607]), 'currentState': array([3.96012995, 2.74932726]), 'targetState': array([0.12637465, 0.12977503]), 'effectorPosition': array([ 0.22722364, -0.31666796])}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9571055603210211
{'reset': False, 'endBeforeDone': False, 'stepCount': 9, 'initial state': array([-2.13385925,  2.57329607]), 'currentState': array([4.32811838, 2.93009201]), 'targetState': array([0.12637465, 0.12977503]), 'effectorPosition': array([ 0.18626426, -0.09935615])}
episode index:2030
target Thresh 1.9689517655923767
current state at start:  [1.1002112  1.62532249]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.1002112 , 1.62532249]), 'currentState': array([1.55130166, 2.12532249]), 'targetState': array([-0.60001679,  0.66746605]), 'effectorPosition': array([-0.84075914,  0.48994186])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9571217565000851
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.1002112 , 1.62532249]), 'currentState': array([1.08506894, 2.37069547]), 'targetState': array([-0.60001679,  0.66746605]), 'effectorPosition': array([-0.48420092,  0.57530673])}
episode index:2031
target Thresh 1.9690138000061002
current state at start:  [-0.26110933  2.79834585]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.26110933,  2.79834585]), 'currentState': array([5.97388468, 3.27024709]), 'targetState': array([-0.10676302, -0.00032364]), 'effectorPosition': array([-0.03118111, -0.12472724])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9571428579978705
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.26110933,  2.79834585]), 'currentState': array([5.97388468, 3.27024709]), 'targetState': array([-0.10676302, -0.00032364]), 'effectorPosition': array([-0.03118111, -0.12472724])}
episode index:2032
target Thresh 1.969075710474982
current state at start:  [-1.18313351 -1.83346999]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.18313351, -1.83346999]), 'currentState': array([5.34710283, 4.32574166]), 'targetState': array([-0.33290215, -0.7235757 ]), 'effectorPosition': array([-0.37644184, -1.05077154])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9571590198975273
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.18313351, -1.83346999]), 'currentState': array([5.27229565, 4.23564458]), 'targetState': array([-0.33290215, -0.7235757 ]), 'effectorPosition': array([-0.46543689, -0.93037113])}
episode index:2033
target Thresh 1.9691374972466649
current state at start:  [-0.22237362 -1.63273499]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.22237362, -1.63273499]), 'currentState': array([5.56081169, 4.30706953]), 'targetState': array([-0.19587321, -0.82612848]), 'effectorPosition': array([-0.15318702, -1.0899124 ])}
done in step count: 20
reward sum = 0.8179069375972308
running average episode reward sum: 0.9570905577135054
{'reset': False, 'endBeforeDone': False, 'stepCount': 21, 'initial state': array([-0.22237362, -1.63273499]), 'currentState': array([5.49156378, 4.28012443]), 'targetState': array([-0.19587321, -0.82612848]), 'effectorPosition': array([-0.23773516, -1.05148739])}
episode index:2034
target Thresh 1.9691991605682955
current state at start:  [-1.05519944  2.36808841]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.05519944,  2.36808841]), 'currentState': array([4.819407  , 2.52086684]), 'targetState': array([-0.05444985, -0.02828973]), 'effectorPosition': array([ 0.5982237 , -0.12335059])}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9570736801394093
{'reset': False, 'endBeforeDone': False, 'stepCount': 9, 'initial state': array([-1.05519944,  2.36808841]), 'currentState': array([2.9016176 , 2.90521257]), 'targetState': array([-0.05444985, -0.02828973]), 'effectorPosition': array([-0.08267176, -0.22086475])}
episode index:2035
target Thresh 1.9692607006865275
current state at start:  [-0.85934606 -2.23710233]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.85934606, -2.23710233]), 'currentState': array([5.56962358, 4.29290522]), 'targetState': array([-0.29463337, -0.93373488]), 'effectorPosition': array([-0.14967196, -1.07843417])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9570947637935647
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.85934606, -2.23710233]), 'currentState': array([5.56962358, 4.29290522]), 'targetState': array([-0.29463337, -0.93373488]), 'effectorPosition': array([-0.14967196, -1.07843417])}
episode index:2036
target Thresh 1.9693221178475209
current state at start:  [1.75025725 1.76890693]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.75025725, 1.76890693]), 'currentState': array([1.37484693, 2.17458497]), 'targetState': array([-0.23825005,  0.03817901]), 'effectorPosition': array([-0.72328213,  0.58423654])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9571060574784968
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([1.75025725, 1.76890693]), 'currentState': array([0.94884895, 2.94551103]), 'targetState': array([-0.23825005,  0.03817901]), 'effectorPosition': array([-0.14718077,  0.12908445])}
episode index:2037
target Thresh 1.969383412296945
current state at start:  [1.59742608 2.41808292]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.59742608, 2.41808292]), 'currentState': array([1.86634149, 2.18292694]), 'targetState': array([-0.74358863, -0.1535873 ]), 'effectorPosition': array([-0.9068405 ,  0.16856837])}
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.9570713562097222
{'reset': False, 'endBeforeDone': False, 'stepCount': 13, 'initial state': array([1.59742608, 2.41808292]), 'currentState': array([2.04117087, 2.19550282]), 'targetState': array([-0.74358863, -0.1535873 ]), 'effectorPosition': array([-0.91119462,  0.00243323])}
episode index:2038
target Thresh 1.9694445842799775
current state at start:  [ 2.41734096 -2.19406393]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.41734096, -2.19406393]), 'currentState': array([1.95858755, 4.55730641]), 'targetState': array([0.84867159, 0.80973577]), 'effectorPosition': array([0.59490074, 1.15636056])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.956601973494563
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([ 2.41734096, -2.19406393]), 'currentState': array([1.74443923, 4.65200787]), 'targetState': array([0.84867159, 0.80973577]), 'effectorPosition': array([0.82082113, 1.0979817 ])}
episode index:2039
target Thresh 1.9695056340413062
current state at start:  [-4.31679816  2.63626433]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.31679816,  2.63626433]), 'currentState': array([1.46638715, 3.11305744]), 'targetState': array([0.42078567, 0.2850215 ]), 'effectorPosition': array([-0.02833354,  0.00337841])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9566086877232421
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-4.31679816,  2.63626433]), 'currentState': array([1.63235944, 3.7226013 ]), 'targetState': array([0.42078567, 0.2850215 ]), 'effectorPosition': array([0.53773203, 0.19754832])}
episode index:2040
target Thresh 1.9695665618251306
current state at start:  [-0.97705861  2.16487483]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.97705861,  2.16487483]), 'currentState': array([5.30922052, 2.41408009]), 'targetState': array([-0.01398182,  0.18210073]), 'effectorPosition': array([0.69233399, 0.16435287])}
done in step count: 15
reward sum = 0.8600583546412884
running average episode reward sum: 0.9565613823175185
{'reset': False, 'endBeforeDone': False, 'stepCount': 16, 'initial state': array([-0.97705861,  2.16487483]), 'currentState': array([4.49063798, 3.09726793]), 'targetState': array([-0.01398182,  0.18210073]), 'effectorPosition': array([ 0.0430092 , -0.01070363])}
episode index:2041
target Thresh 1.9696273678751615
current state at start:  [ 0.05032399 -1.8937296 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.05032399, -1.8937296 ]), 'currentState': array([5.93150824, 3.99612692]), 'targetState': array([-0.19590919, -0.65085841]), 'effectorPosition': array([ 0.06258716, -0.82640372])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9565777577424365
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.05032399, -1.8937296 ]), 'currentState': array([5.62390297, 4.01172697]), 'targetState': array([-0.19590919, -0.65085841]), 'effectorPosition': array([-0.18742091, -0.82184283])}
episode index:2042
target Thresh 1.9696880524346236
current state at start:  [0.36161582 2.00424512]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.36161582, 2.00424512]), 'currentState': array([0.86161582, 2.2952251 ]), 'targetState': array([-0.10511858,  0.93348534]), 'effectorPosition': array([-0.34867167,  0.74364812])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9565941171365909
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.36161582, 2.00424512]), 'currentState': array([0.45419292, 2.2718634 ]), 'targetState': array([-0.10511858,  0.93348534]), 'effectorPosition': array([-0.01628453,  0.84241788])}
episode index:2043
target Thresh 1.969748615746255
current state at start:  [-1.04488582  2.67098817]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.04488582,  2.67098817]), 'currentState': array([4.73829949, 3.02919936]), 'targetState': array([-0.37245504, -0.44876342]), 'effectorPosition': array([ 0.11228263, -0.00340165])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9565960750098118
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([-1.04488582,  2.67098817]), 'currentState': array([4.92404299, 3.85738778]), 'targetState': array([-0.37245504, -0.44876342]), 'effectorPosition': array([-0.59001505, -0.37780792])}
episode index:2044
target Thresh 1.9698090580523089
current state at start:  [-0.74084877  2.77420536]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.74084877,  2.77420536]), 'currentState': array([5.223294  , 2.61008224]), 'targetState': array([0.4519355 , 0.01223419]), 'effectorPosition': array([0.50957083, 0.12748538])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9566172994230099
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.74084877,  2.77420536]), 'currentState': array([5.223294  , 2.61008224]), 'targetState': array([0.4519355 , 0.01223419]), 'effectorPosition': array([0.50957083, 0.12748538])}
episode index:2045
target Thresh 1.9698693795945548
current state at start:  [ 0.37566132 -1.60637277]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.37566132, -1.60637277]), 'currentState': array([0.01930774, 4.29499639]), 'targetState': array([ 0.53460366, -0.55190901]), 'effectorPosition': array([ 0.61215995, -0.90249856])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9566336155034483
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.37566132, -1.60637277]), 'currentState': array([0.09597232, 4.11305099]), 'targetState': array([ 0.53460366, -0.55190901]), 'effectorPosition': array([ 0.51302172, -0.78013895])}
episode index:2046
target Thresh 1.969929580614279
current state at start:  [ 2.37904866 -2.71792783]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.37904866, -2.71792783]), 'currentState': array([2.11312212, 3.38377477]), 'targetState': array([ 0.57273436, -0.05917014]), 'effectorPosition': array([0.19034755, 0.14877458])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9566450792965585
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 2.37904866, -2.71792783]), 'currentState': array([1.52730695, 3.70069467]), 'targetState': array([ 0.57273436, -0.05917014]), 'effectorPosition': array([0.5365436 , 0.12906368])}
episode index:2047
target Thresh 1.9699896613522856
current state at start:  [0.64241269 1.88927358]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.64241269, 1.88927358]), 'currentState': array([0.15906209, 2.38927358]), 'targetState': array([0.62262417, 0.60623509]), 'effectorPosition': array([0.15825206, 0.71745663])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.956651746250027
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([0.64241269, 1.88927358]), 'currentState': array([6.1986318 , 2.29522517]), 'targetState': array([0.62262417, 0.60623509]), 'effectorPosition': array([0.39933203, 0.71771741])}
episode index:2048
target Thresh 1.9700496220488974
current state at start:  [ 1.26787501 -2.49130915]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.26787501, -2.49130915]), 'currentState': array([1.07695976, 3.6639539 ]), 'targetState': array([ 0.49860254, -0.49679572]), 'effectorPosition': array([ 0.50252836, -0.11907242])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9566631900049074
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 1.26787501, -2.49130915]), 'currentState': array([0.64298969, 3.93552052]), 'targetState': array([ 0.49860254, -0.49679572]), 'effectorPosition': array([ 0.66682755, -0.39146083])}
episode index:2049
target Thresh 1.9701094629439577
current state at start:  [ 1.39403058 -2.95421664]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.39403058, -2.95421664]), 'currentState': array([1.84695576, 2.86097201]), 'targetState': array([-0.48310998, -0.37943004]), 'effectorPosition': array([-0.27712382, -0.03788034])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9566794518634416
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.39403058, -2.95421664]), 'currentState': array([2.22185231, 2.45774459]), 'targetState': array([-0.48310998, -0.37943004]), 'effectorPosition': array([-0.63881292, -0.2040181 ])}
episode index:2050
target Thresh 1.9701691842768296
current state at start:  [ 4.30192531 -2.63502254]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.30192531, -2.63502254]), 'currentState': array([4.5759681 , 3.15543882]), 'targetState': array([0.38900203, 0.19536022]), 'effectorPosition': array([-0.01373012,  0.00178803])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9566956978644834
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 4.30192531, -2.63502254]), 'currentState': array([4.89623849, 2.75875567]), 'targetState': array([0.38900203, 0.19536022]), 'effectorPosition': array([ 0.38049244, -0.00288   ])}
episode index:2051
target Thresh 1.9702287862863992
current state at start:  [1.81666871 1.75504304]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.81666871, 1.75504304]), 'currentState': array([1.38707097, 2.04500194]), 'targetState': array([-0.73692475,  0.46004322]), 'effectorPosition': array([-0.77541295,  0.69675752])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.956716801325563
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.81666871, 1.75504304]), 'currentState': array([1.38707097, 2.04500194]), 'targetState': array([-0.73692475,  0.46004322]), 'effectorPosition': array([-0.77541295,  0.69675752])}
episode index:2052
target Thresh 1.9702882692110741
current state at start:  [ 0.4190798  -2.96857653]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.4190798 , -2.96857653]), 'currentState': array([0.40283664, 3.40187079]), 'targetState': array([-0.21695388, -0.16358882]), 'effectorPosition': array([ 0.13187397, -0.22354503])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.9567140118704117
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([ 0.4190798 , -2.96857653]), 'currentState': array([0.05709875, 3.31093613]), 'targetState': array([-0.21695388, -0.16358882]), 'effectorPosition': array([ 0.02389899, -0.16744427])}
episode index:2053
target Thresh 1.9703476332887861
current state at start:  [ 3.04050741 -3.04490787]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.04050741, -3.04490787]), 'currentState': array([3.20327089, 3.62170613]), 'targetState': array([-0.40712578,  0.56774664]), 'effectorPosition': array([-0.14131238,  0.4540328 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9567302173174076
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.04050741, -3.04490787]), 'currentState': array([3.47466633, 3.90098188]), 'targetState': array([-0.40712578,  0.56774664]), 'effectorPosition': array([-0.48474158,  0.56081396])}
episode index:2054
target Thresh 1.970406878756992
current state at start:  [4.03020393e-04 1.59533437e+00]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([4.03020393e-04, 1.59533437e+00]), 'currentState': array([0.50040302, 1.80548194]), 'targetState': array([0.19333996, 0.80484246]), 'effectorPosition': array([0.20673637, 1.2215505 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.956746406992679
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([4.03020393e-04, 1.59533437e+00]), 'currentState': array([0.47895195, 2.23380762]), 'targetState': array([0.19333996, 0.80484246]), 'effectorPosition': array([-0.02197318,  0.87665913])}
episode index:2055
target Thresh 1.9704660058526733
current state at start:  [0.90896966 2.61339419]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.90896966, 2.61339419]), 'currentState': array([0.52152516, 3.052318  ]), 'targetState': array([0.02266141, 0.00295011]), 'effectorPosition': array([-0.04096493,  0.07928775])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9567674447324686
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.90896966, 2.61339419]), 'currentState': array([0.52152516, 3.052318  ]), 'targetState': array([0.02266141, 0.00295011]), 'effectorPosition': array([-0.04096493,  0.07928775])}
episode index:2056
target Thresh 1.9705250148123385
current state at start:  [-4.30078391  2.66852743]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.30078391,  2.66852743]), 'currentState': array([1.56511548, 2.49937115]), 'targetState': array([-0.42224469, -0.09290459]), 'effectorPosition': array([-0.59783436,  0.20263235])}
done in step count: 18
reward sum = 0.8345137614500875
running average episode reward sum: 0.956708011731359
{'reset': False, 'endBeforeDone': False, 'stepCount': 19, 'initial state': array([-4.30078391,  2.66852743]), 'currentState': array([1.60291153, 2.61646373]), 'targetState': array([-0.42224469, -0.09290459]), 'effectorPosition': array([-0.50539253,  0.11857383])}
episode index:2057
target Thresh 1.9705839058720238
current state at start:  [-4.08531796  2.31045149]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.08531796,  2.31045149]), 'currentState': array([1.69786735, 2.45445518]), 'targetState': array([-0.32567382,  0.51482872]), 'effectorPosition': array([-0.65797183,  0.14471753])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.956724188596407
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-4.08531796,  2.31045149]), 'currentState': array([1.19786735, 2.52386033]), 'targetState': array([-0.32567382,  0.51482872]), 'effectorPosition': array([-0.472044  ,  0.38312731])}
episode index:2058
target Thresh 1.9706426792672933
current state at start:  [-1.98726321 -2.18542224]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.98726321, -2.18542224]), 'currentState': array([4.70374515, 4.40451435]), 'targetState': array([-0.80571288, -0.50489095]), 'effectorPosition': array([-0.95896856, -0.68870279])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9567452064746991
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.98726321, -2.18542224]), 'currentState': array([4.70374515, 4.40451435]), 'targetState': array([-0.80571288, -0.50489095]), 'effectorPosition': array([-0.95896856, -0.68870279])}
episode index:2059
target Thresh 1.970701335233241
current state at start:  [-2.85663988  2.85959854]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.85663988,  2.85959854]), 'currentState': array([3.80875634, 2.82824191]), 'targetState': array([ 0.48597739, -0.21889954]), 'effectorPosition': array([ 0.15247862, -0.27228325])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.9567424127093715
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([-2.85663988,  2.85959854]), 'currentState': array([4.41290492, 2.40595856]), 'targetState': array([ 0.48597739, -0.21889954]), 'effectorPosition': array([ 0.5648954 , -0.44506451])}
episode index:2060
target Thresh 1.9707598740044903
current state at start:  [-2.88853411  2.65419324]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.88853411,  2.65419324]), 'currentState': array([3.28152992, 2.26962908]), 'targetState': array([-0.02984452, -0.59489987]), 'effectorPosition': array([-0.24640316, -0.80785921])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9562781999909293
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([-2.88853411,  2.65419324]), 'currentState': array([2.54134494, 2.51764461]), 'targetState': array([-0.02984452, -0.59489987]), 'effectorPosition': array([-0.48549322, -0.37568604])}
episode index:2061
target Thresh 1.9708182958151965
current state at start:  [ 1.76822395 -2.05043431]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.76822395, -2.05043431]), 'currentState': array([2.24985741, 3.73275099]), 'targetState': array([-0.20984557,  0.20431217]), 'effectorPosition': array([0.32710317, 0.48209146])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.956284999602961
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 1.76822395, -2.05043431]), 'currentState': array([2.94308326, 3.28667508]), 'targetState': array([-0.20984557,  0.20431217]), 'effectorPosition': array([0.01821149, 0.14380666])}
episode index:2062
target Thresh 1.9708766008990473
current state at start:  [-1.8184659   2.23596282]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.8184659 ,  2.23596282]), 'currentState': array([4.0910094 , 2.55497034]), 'targetState': array([ 0.01221636, -0.07853746]), 'effectorPosition': array([ 0.35275135, -0.45818795])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.9562778232334981
{'reset': False, 'endBeforeDone': False, 'stepCount': 7, 'initial state': array([-1.8184659 ,  2.23596282]), 'currentState': array([3.84798222, 2.82028737]), 'targetState': array([ 0.01221636, -0.07853746]), 'effectorPosition': array([ 0.16605644, -0.27345426])}
episode index:2063
target Thresh 1.9709347894892628
current state at start:  [-1.7706976  -1.77348484]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.7706976 , -1.77348484]), 'currentState': array([4.96226724, 4.1542825 ]), 'targetState': array([-0.2083205 , -0.51508415]), 'effectorPosition': array([-0.70558657, -0.66557171])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9562799153782493
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([-1.7706976 , -1.77348484]), 'currentState': array([5.36849707, 3.93584724]), 'targetState': array([-0.2083205 , -0.51508415]), 'effectorPosition': array([-0.38271899, -0.67222971])}
episode index:2064
target Thresh 1.9709928618185975
current state at start:  [-0.08024091  2.700148  ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.08024091,  2.700148  ]), 'currentState': array([5.93780771, 3.11121831]), 'targetState': array([-0.03235842,  0.01095077]), 'effectorPosition': array([0.01071574, 0.02842011])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9563010873320613
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.08024091,  2.700148  ]), 'currentState': array([5.93780771, 3.11121831]), 'targetState': array([-0.03235842,  0.01095077]), 'effectorPosition': array([0.01071574, 0.02842011])}
episode index:2065
target Thresh 1.971050818119341
current state at start:  [ 2.03648305 -1.96732457]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.03648305, -1.96732457]), 'currentState': array([1.57930654, 3.89491539]), 'targetState': array([1.05140246, 0.13183968]), 'effectorPosition': array([0.68173877, 0.27639176])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.956317398519219
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 2.03648305, -1.96732457]), 'currentState': array([1.28876829, 4.30339806]), 'targetState': array([1.05140246, 0.13183968]), 'effectorPosition': array([1.04890115, 0.32317029])}
episode index:2066
target Thresh 1.971108658623318
current state at start:  [-1.67205364  2.24846641]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.67205364,  2.24846641]), 'currentState': array([4.51453544, 1.75579218]), 'targetState': array([ 0.93406741, -1.05998994]), 'effectorPosition': array([ 0.80335214, -0.99334809])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9563385318532688
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.67205364,  2.24846641]), 'currentState': array([4.51453544, 1.75579218]), 'targetState': array([ 0.93406741, -1.05998994]), 'effectorPosition': array([ 0.80335214, -0.99334809])}
episode index:2067
target Thresh 1.9711663835618911
current state at start:  [-3.44492779  2.52573315]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.44492779,  2.52573315]), 'currentState': array([2.49032726, 2.47721366]), 'targetState': array([-0.0792966 , -0.53412219]), 'effectorPosition': array([-0.54292493, -0.36143168])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9558760857546936
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([-3.44492779,  2.52573315]), 'currentState': array([2.46227416, 2.62035944]), 'targetState': array([-0.0792966 , -0.53412219]), 'effectorPosition': array([-0.41615758, -0.3039759 ])}
episode index:2068
target Thresh 1.97122399316596
current state at start:  [0.40580061 2.46338567]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.40580061, 2.46338567]), 'currentState': array([0.20647511, 2.96338567]), 'targetState': array([-0.00799846,  0.39620199]), 'effectorPosition': array([-0.02084085,  0.1767468 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9558974119578089
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.40580061, 2.46338567]), 'currentState': array([0.20647511, 2.96338567]), 'targetState': array([-0.00799846,  0.39620199]), 'effectorPosition': array([-0.02084085,  0.1767468 ])}
episode index:2069
target Thresh 1.9712814876659632
current state at start:  [ 1.22219806 -1.89947231]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.22219806, -1.89947231]), 'currentState': array([0.75363388, 4.09079914]), 'targetState': array([ 0.77016173, -0.52666036]), 'effectorPosition': array([ 0.86086771, -0.30700172])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9559187175558969
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.22219806, -1.89947231]), 'currentState': array([0.75363388, 4.09079914]), 'targetState': array([ 0.77016173, -0.52666036]), 'effectorPosition': array([ 0.86086771, -0.30700172])}
episode index:2070
target Thresh 1.971338867291879
current state at start:  [ 1.59965744 -1.88875257]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.59965744, -1.88875257]), 'currentState': array([1.69320572, 3.96881686]), 'targetState': array([-0.05562628, -0.15032687]), 'effectorPosition': array([0.6910984 , 0.41053624])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9559303936942088
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 1.59965744, -1.88875257]), 'currentState': array([2.22421421, 3.10348474]), 'targetState': array([-0.05562628, -0.15032687]), 'effectorPosition': array([-0.03069212, -0.02258387])}
episode index:2071
target Thresh 1.9713961322732256
current state at start:  [ 2.12851777 -2.17490714]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.12851777, -2.17490714]), 'currentState': array([1.63017761, 3.69834001]), 'targetState': array([ 1.33493387, -0.16459921]), 'effectorPosition': array([0.51853361, 0.1821157 ])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.955942058562117
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 2.12851777, -2.17490714]), 'currentState': array([0.85406943, 4.61427016]), 'targetState': array([ 1.33493387, -0.16459921]), 'effectorPosition': array([1.34290107, 0.02634017])}
episode index:2072
target Thresh 1.971453282839063
current state at start:  [-0.54302384  2.12099349]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.54302384,  2.12099349]), 'currentState': array([5.84748111, 2.00136056]), 'targetState': array([0.49442325, 0.36470693]), 'effectorPosition': array([0.911713  , 0.57793788])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9559443035941662
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([-0.54302384,  2.12099349]), 'currentState': array([5.80020525, 2.29201551]), 'targetState': array([0.49442325, 0.36470693]), 'effectorPosition': array([0.649623  , 0.50733462])}
episode index:2073
target Thresh 1.971510319217994
current state at start:  [-3.26074458  2.94858592]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.26074458,  2.94858592]), 'currentState': array([3.4760375 , 2.48448619]), 'targetState': array([ 0.27301751, -1.15802428]), 'effectorPosition': array([ 0.00380212, -0.64533677])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9559607238913724
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.26074458,  2.94858592]), 'currentState': array([3.93467855, 1.98448619]), 'targetState': array([ 0.27301751, -1.15802428]), 'effectorPosition': array([ 0.23282303, -1.06855609])}
episode index:2074
target Thresh 1.9715672416381635
current state at start:  [ 4.33403616 -2.76061693]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.33403616, -2.76061693]), 'currentState': array([4.75716738, 3.36165464]), 'targetState': array([-0.11808105, -0.22397012]), 'effectorPosition': array([-0.21699179, -0.03386332])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9559819476388948
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.33403616, -2.76061693]), 'currentState': array([4.75716738, 3.36165464]), 'targetState': array([-0.11808105, -0.22397012]), 'effectorPosition': array([-0.21699179, -0.03386332])}
episode index:2075
target Thresh 1.971624050327262
current state at start:  [0.77611602 1.62247521]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.77611602, 1.62247521]), 'currentState': array([0.35033554, 2.03789878]), 'targetState': array([0.32448503, 0.60058172]), 'effectorPosition': array([0.20986202, 1.02730515])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9559983339839627
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.77611602, 1.62247521]), 'currentState': array([6.23478455, 2.42384324]), 'targetState': array([0.32448503, 0.60058172]), 'effectorPosition': array([0.27824357, 0.64498439])}
episode index:2076
target Thresh 1.9716807455125238
current state at start:  [ 0.32561601 -1.66007245]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.32561601, -1.66007245]), 'currentState': array([0.82561601, 4.12960199]), 'targetState': array([0.76144974, 0.2059004 ]), 'effectorPosition': array([ 0.91855395, -0.23569598])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9560147045501717
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.32561601, -1.66007245]), 'currentState': array([1.24943353, 3.96403924]), 'targetState': array([0.76144974, 0.2059004 ]), 'effectorPosition': array([0.79623625, 0.07174339])}
episode index:2077
target Thresh 1.97173732742073
current state at start:  [-2.83305989  2.44454558]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.83305989,  2.44454558]), 'currentState': array([3.04103839, 2.88027717]), 'targetState': array([0.02492269, 0.04338227]), 'effectorPosition': array([-0.05971215, -0.25363861])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9560310593603015
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.83305989,  2.44454558]), 'currentState': array([2.73343148, 3.16847737]), 'targetState': array([0.02492269, 0.04338227]), 'effectorPosition': array([0.01033817, 0.02481666])}
episode index:2078
target Thresh 1.971793796278208
current state at start:  [-3.00216537  2.4909087 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.00216537,  2.4909087 ]), 'currentState': array([3.63428152, 2.29243937]), 'targetState': array([ 0.21506711, -0.67554906]), 'effectorPosition': array([ 0.05607225, -0.82195975])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9560522084418983
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.00216537,  2.4909087 ]), 'currentState': array([3.63428152, 2.29243937]), 'targetState': array([ 0.21506711, -0.67554906]), 'effectorPosition': array([ 0.05607225, -0.82195975])}
episode index:2079
target Thresh 1.9718501523108336
current state at start:  [-1.5314727   2.17718446]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.5314727 ,  2.17718446]), 'currentState': array([4.97598132, 2.56455785]), 'targetState': array([0.09909581, 0.36086857]), 'effectorPosition': array([ 0.56888568, -0.01418245])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.9560497747118301
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([-1.5314727 ,  2.17718446]), 'currentState': array([0.04512254, 2.84451974]), 'targetState': array([0.09909581, 0.36086857]), 'effectorPosition': array([0.0305541 , 0.29440046])}
episode index:2080
target Thresh 1.9719063957440308
current state at start:  [-0.45382601  2.10504085]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.45382601,  2.10504085]), 'currentState': array([0.04617399, 2.23416071]), 'targetState': array([0.08719665, 0.69643255]), 'effectorPosition': array([0.34745055, 0.80482028])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9560613317638667
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-0.45382601,  2.10504085]), 'currentState': array([0.24450645, 2.54021353]), 'targetState': array([0.08719665, 0.69643255]), 'effectorPosition': array([0.033263  , 0.59142314])}
episode index:2081
target Thresh 1.9719625268027738
current state at start:  [-4.2299294   2.34571692]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.2299294 ,  2.34571692]), 'currentState': array([2.46315809, 1.97970318]), 'targetState': array([-0.62157491, -0.46220034]), 'effectorPosition': array([-1.04483233, -0.33632175])}
done in step count: 181
reward sum = 0.16216989001100654
running average episode reward sum: 0.955680019832189
{'reset': False, 'endBeforeDone': False, 'stepCount': 182, 'initial state': array([-4.2299294 ,  2.34571692]), 'currentState': array([4.81316843, 4.17054333]), 'targetState': array([-0.62157491, -0.46220034]), 'effectorPosition': array([-0.80368807, -0.56802218])}
episode index:2082
target Thresh 1.9720185457115864
current state at start:  [-2.92394613  1.64648936]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.92394613,  1.64648936]), 'currentState': array([3.41347079, 1.68616981]), 'targetState': array([-0.05534714, -1.07904964]), 'effectorPosition': array([-0.58562326, -1.19449152])}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.9556597784628427
{'reset': False, 'endBeforeDone': False, 'stepCount': 10, 'initial state': array([-2.92394613,  1.64648936]), 'currentState': array([3.49505318, 1.92286674]), 'targetState': array([-0.05534714, -1.07904964]), 'effectorPosition': array([-0.28974238, -1.10741385])}
episode index:2083
target Thresh 1.9720744526945446
current state at start:  [-2.03426434  2.12210199]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.03426434,  2.12210199]), 'currentState': array([3.74892097, 2.45546835]), 'targetState': array([-0.33216742, -0.27928933]), 'effectorPosition': array([ 0.17572159, -0.64939005])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9556715060163633
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-2.03426434,  2.12210199]), 'currentState': array([2.74892097, 2.55404489]), 'targetState': array([-0.33216742, -0.27928933]), 'effectorPosition': array([-0.36704974, -0.44796147])}
episode index:2084
target Thresh 1.9721302479752765
current state at start:  [-2.3781541  2.1720925]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.3781541,  2.1720925]), 'currentState': array([4.02796729, 2.47386221]), 'targetState': array([ 0.38719999, -0.30292934]), 'effectorPosition': array([ 0.34396738, -0.55787851])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.955687970521871
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.3781541,  2.1720925]), 'currentState': array([4.22335278, 2.41559202]), 'targetState': array([ 0.38719999, -0.30292934]), 'effectorPosition': array([ 0.46760695, -0.53448364])}
episode index:2085
target Thresh 1.9721859317769628
current state at start:  [-3.66512824  2.08721463]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.66512824,  2.08721463]), 'currentState': array([2.32579768, 1.99854333]), 'targetState': array([-0.3692042 , -0.76902505]), 'effectorPosition': array([-1.06367189, -0.19737882])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9552298267200868
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([-3.66512824,  2.08721463]), 'currentState': array([2.44551084, 2.19679306]), 'targetState': array([-0.3692042 , -0.76902505]), 'effectorPosition': array([-0.83738819, -0.35632909])}
episode index:2086
target Thresh 1.9722415043223394
current state at start:  [-1.60130349  1.92397156]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.60130349,  1.92397156]), 'currentState': array([4.19315383, 2.31714966]), 'targetState': array([-0.00747761, -0.06127572]), 'effectorPosition': array([ 0.4781031 , -0.64302831])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.9552277952026839
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([-1.60130349,  1.92397156]), 'currentState': array([4.08579957, 2.90710917]), 'targetState': array([-0.00747761, -0.06127572]), 'effectorPosition': array([ 0.17215664, -0.15840813])}
episode index:2087
target Thresh 1.9722969658336962
current state at start:  [-0.0959221  -2.80941831]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.0959221 , -2.80941831]), 'currentState': array([5.80975379, 3.973767  ]), 'targetState': array([-0.04822664, -0.91492177]), 'effectorPosition': array([-0.04633   , -0.80704042])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9552492378295024
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.0959221 , -2.80941831]), 'currentState': array([5.80975379, 3.973767  ]), 'targetState': array([-0.04822664, -0.91492177]), 'effectorPosition': array([-0.04633   , -0.80704042])}
episode index:2088
target Thresh 1.9723523165328793
current state at start:  [-2.17241653  1.60977901]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.17241653,  1.60977901]), 'currentState': array([3.62911196, 1.92014272]), 'targetState': array([-0.46187976, -0.68376198]), 'effectorPosition': array([-0.14095018, -1.13822913])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9552658729478225
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.17241653,  1.60977901]), 'currentState': array([3.15876098, 2.22461874]), 'targetState': array([-0.46187976, -0.68376198]), 'effectorPosition': array([-0.37809038, -0.80037353])}
episode index:2089
target Thresh 1.9724075566412917
current state at start:  [ 3.98046367 -2.64106142]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.98046367, -2.64106142]), 'currentState': array([4.44571312, 3.30075026]), 'targetState': array([-0.08542298,  0.00672608]), 'effectorPosition': array([-0.15621504,  0.02957326])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9552872768363642
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.98046367, -2.64106142]), 'currentState': array([4.44571312, 3.30075026]), 'targetState': array([-0.08542298,  0.00672608]), 'effectorPosition': array([-0.15621504,  0.02957326])}
episode index:2090
target Thresh 1.972462686379894
current state at start:  [-2.30630301  2.3635704 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.30630301,  2.3635704 ]), 'currentState': array([3.49271288, 1.97514589]), 'targetState': array([-0.64252379, -1.23448665]), 'effectorPosition': array([-0.25335728, -1.07189942])}
done in step count: 37
reward sum = 0.6894490858690777
running average episode reward sum: 0.9551601423595745
{'reset': False, 'endBeforeDone': False, 'stepCount': 38, 'initial state': array([-2.30630301,  2.3635704 ]), 'currentState': array([5.15130227, 4.76430922]), 'targetState': array([-0.64252379, -1.23448665]), 'effectorPosition': array([-0.45698426, -1.37657518])}
episode index:2091
target Thresh 1.9725177059692052
current state at start:  [0.68047431 2.59089922]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.68047431, 2.59089922]), 'currentState': array([1.03116498, 3.07198443]), 'targetState': array([-0.42407649,  0.25762775]), 'effectorPosition': array([-0.05842425,  0.03781475])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.955176796211219
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.68047431, 2.59089922]), 'currentState': array([1.47261769, 2.62994649]), 'targetState': array([-0.42407649,  0.25762775]), 'effectorPosition': array([-0.47470286,  0.17543597])}
episode index:2092
target Thresh 1.9725726156293033
current state at start:  [-1.93274222  2.14930153]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.93274222,  2.14930153]), 'currentState': array([4.0160647, 2.5669787]), 'targetState': array([0.12275951, 0.2119487 ]), 'effectorPosition': array([ 0.31397642, -0.47182035])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9551887040964502
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.93274222,  2.14930153]), 'currentState': array([4.27517211, 3.1170553 ]), 'targetState': array([0.12275951, 0.2119487 ]), 'effectorPosition': array([ 0.02209952, -0.01066127])}
episode index:2093
target Thresh 1.9726274155798276
current state at start:  [-4.06250047  2.76948936]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.06250047,  2.76948936]), 'currentState': array([2.48135765, 2.96188406]), 'targetState': array([-0.06409465, -0.39893189]), 'effectorPosition': array([-0.1223433 , -0.13130298])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9552053284020392
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-4.06250047,  2.76948936]), 'currentState': array([2.68438001, 2.70345114]), 'targetState': array([-0.06409465, -0.39893189]), 'effectorPosition': array([-0.272044 , -0.3389818])}
episode index:2094
target Thresh 1.9726821060399777
current state at start:  [-1.09484976 -2.66268654]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.09484976, -2.66268654]), 'currentState': array([5.42013518, 3.37738493]), 'targetState': array([ 0.23915726, -0.01853457]), 'effectorPosition': array([-0.15951707, -0.17290224])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9552125330185538
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-1.09484976, -2.66268654]), 'currentState': array([5.31653654, 3.04407167]), 'targetState': array([ 0.23915726, -0.01853457]), 'effectorPosition': array([0.0828304 , 0.05139973])}
episode index:2095
target Thresh 1.9727366872285155
current state at start:  [ 0.52287738 -2.1694116 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.52287738, -2.1694116 ]), 'currentState': array([0.99293931, 4.37892301]), 'targetState': array([ 1.27583144, -0.05275446]), 'effectorPosition': array([1.15893086, 0.0473201 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9552339010848617
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.52287738, -2.1694116 ]), 'currentState': array([0.99293931, 4.37892301]), 'targetState': array([ 1.27583144, -0.05275446]), 'effectorPosition': array([1.15893086, 0.0473201 ])}
episode index:2096
target Thresh 1.9727911593637657
current state at start:  [0.51286893 2.65445269]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.51286893, 2.65445269]), 'currentState': array([0.20241805, 3.13987867]), 'targetState': array([-0.1144555 , -0.16579708]), 'effectorPosition': array([-0.00034314,  0.00167928])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9552552487715166
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.51286893, 2.65445269]), 'currentState': array([0.20241805, 3.13987867]), 'targetState': array([-0.1144555 , -0.16579708]), 'effectorPosition': array([-0.00034314,  0.00167928])}
episode index:2097
target Thresh 1.9728455226636172
current state at start:  [-0.67211892 -2.54558165]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.67211892, -2.54558165]), 'currentState': array([6.11106639, 4.19923719]), 'targetState': array([ 0.66333334, -0.87327806]), 'effectorPosition': array([ 0.35234144, -0.94551809])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9552577944155721
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([-0.67211892, -2.54558165]), 'currentState': array([6.15138189, 4.60553109]), 'targetState': array([ 0.66333334, -0.87327806]), 'effectorPosition': array([ 0.75492441, -1.10307745])}
episode index:2098
target Thresh 1.9728997773455232
current state at start:  [ 3.38837833 -1.80208858]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.38837833, -1.80208858]), 'currentState': array([3.83508248, 3.98298328]), 'targetState': array([-0.29111307,  0.0175903 ]), 'effectorPosition': array([-0.73311176,  0.36013028])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9552743462047977
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.38837833, -1.80208858]), 'currentState': array([4.31323672, 3.59727119]), 'targetState': array([-0.29111307,  0.0175903 ]), 'effectorPosition': array([-0.44513356,  0.07701203])}
episode index:2099
target Thresh 1.9729539236265026
current state at start:  [ 3.12126086 -2.20608216]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.12126086, -2.20608216]), 'currentState': array([3.14824094, 3.7694122 ]), 'targetState': array([0.05231671, 0.54374962]), 'effectorPosition': array([-0.19459065,  0.58610076])}
done in step count: 57
reward sum = 0.5639051904523875
running average episode reward sum: 0.9550879799401537
{'reset': False, 'endBeforeDone': False, 'stepCount': 58, 'initial state': array([ 3.12126086, -2.20608216]), 'currentState': array([6.06738011, 2.59805364]), 'targetState': array([0.05231671, 0.54374962]), 'effectorPosition': array([0.25151665, 0.47431194])}
episode index:2100
target Thresh 1.9730079617231402
current state at start:  [ 4.12503708 -2.4477153 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.12503708, -2.4477153 ]), 'currentState': array([4.24861473, 3.42892741]), 'targetState': array([0.25430292, 0.30750173]), 'effectorPosition': array([-0.2718014 ,  0.09010434])}
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.9550510608744986
{'reset': False, 'endBeforeDone': False, 'stepCount': 14, 'initial state': array([ 4.12503708, -2.4477153 ]), 'currentState': array([5.63885706, 2.53437961]), 'targetState': array([0.25430292, 0.30750173]), 'effectorPosition': array([0.48564411, 0.34880799])}
episode index:2101
target Thresh 1.9730618918515888
current state at start:  [-1.94502555 -2.34890862]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.94502555, -2.34890862]), 'currentState': array([3.97460338, 4.06623246]), 'targetState': array([-0.67940185,  0.33420138]), 'effectorPosition': array([-0.85841978,  0.2426336 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9550724447656145
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.94502555, -2.34890862]), 'currentState': array([3.97460338, 4.06623246]), 'targetState': array([-0.67940185,  0.33420138]), 'effectorPosition': array([-0.85841978,  0.2426336 ])}
episode index:2102
target Thresh 1.9731157142275688
current state at start:  [-3.17677123  2.07212432]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.17677123,  2.07212432]), 'currentState': array([2.60641408, 2.49690266]), 'targetState': array([-0.15910652,  0.09977288]), 'effectorPosition': array([-0.47913123, -0.41456128])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9550843456477992
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-3.17677123,  2.07212432]), 'currentState': array([1.72620731, 2.98565889]), 'targetState': array([-0.15910652,  0.09977288]), 'effectorPosition': array([-0.15530892, -0.01205186])}
episode index:2103
target Thresh 1.97316942906637
current state at start:  [-2.65110846  2.37192317]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.65110846,  2.37192317]), 'currentState': array([3.30863207, 2.82230764]), 'targetState': array([-0.02927087,  0.19790681]), 'effectorPosition': array([ 0.00235168, -0.31792184])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9551009405405522
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.65110846,  2.37192317]), 'currentState': array([3.23963211, 3.22110465]), 'targetState': array([-0.02927087,  0.19790681]), 'effectorPosition': array([-0.01091887,  0.07873757])}
episode index:2104
target Thresh 1.9732230365828514
current state at start:  [ 1.90909924 -2.05037508]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.90909924, -2.05037508]), 'currentState': array([1.42558093, 4.01545677]), 'targetState': array([ 1.14948216e+00, -6.59145341e-04]), 'effectorPosition': array([0.81056765, 0.24339991])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9551175196661861
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.90909924, -2.05037508]), 'currentState': array([1.10113095, 4.4590345 ]), 'targetState': array([ 1.14948216e+00, -6.59145341e-04]), 'effectorPosition': array([1.20239898, 0.23006778])}
episode index:2105
target Thresh 1.9732765369914438
current state at start:  [-0.24217054  2.16515533]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.24217054,  2.16515533]), 'currentState': array([5.76139689, 2.61594955]), 'targetState': array([0.00147859, 0.08810463]), 'effectorPosition': array([0.3671318, 0.367711 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9551340830471613
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.24217054,  2.16515533]), 'currentState': array([5.48642826, 2.86655117]), 'targetState': array([0.00147859, 0.08810463]), 'effectorPosition': array([0.22048361, 0.16296967])}
episode index:2106
target Thresh 1.9733299305061482
current state at start:  [ 3.36288625 -1.73802004]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.36288625, -1.73802004]), 'currentState': array([3.86288625, 4.2450074 ]), 'targetState': array([-1.35012035, -0.18978663]), 'effectorPosition': array([-1.00214458,  0.30758051])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.95514593208226
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 3.36288625, -1.73802004]), 'currentState': array([3.98746303, 4.59264035]), 'targetState': array([-1.35012035, -0.18978663]), 'effectorPosition': array([-1.32705467e+00, -7.93445372e-04])}
episode index:2107
target Thresh 1.9733832173405392
current state at start:  [ 3.10312322 -1.62752157]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.10312322, -1.62752157]), 'currentState': array([3.17795285, 4.15566374]), 'targetState': array([-0.06142863,  0.33183024]), 'effectorPosition': array([-0.50214214,  0.83128555])}
done in step count: 156
reward sum = 0.20849246173476124
running average episode reward sum: 0.9547917321437649
{'reset': False, 'endBeforeDone': False, 'stepCount': 157, 'initial state': array([ 3.10312322, -1.62752157]), 'currentState': array([0.14174756, 3.01043879]), 'targetState': array([-0.06142863,  0.33183024]), 'effectorPosition': array([-0.00997326,  0.13067986])}
episode index:2108
target Thresh 1.9734363977077642
current state at start:  [ 1.77238979 -2.40206832]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.77238979, -2.40206832]), 'currentState': array([2.0509304 , 3.40547085]), 'targetState': array([ 0.07377794, -0.01406423]), 'effectorPosition': array([0.21534732, 0.15117581])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9548131680223122
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.77238979, -2.40206832]), 'currentState': array([2.0509304 , 3.40547085]), 'targetState': array([ 0.07377794, -0.01406423]), 'effectorPosition': array([0.21534732, 0.15117581])}
episode index:2109
target Thresh 1.9734894718205445
current state at start:  [-0.48627493  2.21022243]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.48627493,  2.21022243]), 'currentState': array([0.01372507, 2.10366453]), 'targetState': array([0.40023419, 0.60823101]), 'effectorPosition': array([0.48012593, 0.86802486])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9548298442459984
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.48627493,  2.21022243]), 'currentState': array([0.1020499 , 2.37301041]), 'targetState': array([0.40023419, 0.60823101]), 'effectorPosition': array([0.20882711, 0.7201371 ])}
episode index:2110
target Thresh 1.9735424398911767
current state at start:  [-0.8461422   2.63003425]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.8461422 ,  2.63003425]), 'currentState': array([4.98252777, 2.56651106]), 'targetState': array([ 0.60206852, -0.53502476]), 'effectorPosition': array([ 0.56710381, -0.00986974])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9548465046703253
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.8461422 ,  2.63003425]), 'currentState': array([4.5565962 , 2.20398783]), 'targetState': array([ 0.60206852, -0.53502476]), 'effectorPosition': array([ 0.73302981, -0.52841853])}
episode index:2111
target Thresh 1.9735953021315333
current state at start:  [ 1.6565515  -2.77011416]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.6565515 , -2.77011416]), 'currentState': array([2.14692136, 3.11114862]), 'targetState': array([-0.22585227,  0.35307042]), 'effectorPosition': array([-0.02577825, -0.01619411])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9548538211927352
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 1.6565515 , -2.77011416]), 'currentState': array([3.13605235, 3.52575464]), 'targetState': array([-0.22585227,  0.35307042]), 'effectorPosition': array([-0.07080965,  0.37518039])}
episode index:2112
target Thresh 1.9736480587530632
current state at start:  [-2.05661327  2.29888525]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.05661327,  2.29888525]), 'currentState': array([3.78886095, 2.63597472]), 'targetState': array([-0.10893371,  0.01009518]), 'effectorPosition': array([ 0.19225033, -0.46183234])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.9548519926213709
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([-2.05661327,  2.29888525]), 'currentState': array([4.28356573, 3.10963472]), 'targetState': array([-0.10893371,  0.01009518]), 'effectorPosition': array([ 0.02884707, -0.01375025])}
episode index:2113
target Thresh 1.973700709966793
current state at start:  [-1.58243023  1.85897884]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.58243023,  1.85897884]), 'currentState': array([4.47721823, 2.19000935]), 'targetState': array([0.22859424, 0.07335782]), 'effectorPosition': array([ 0.69414865, -0.59780322])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9548592996258074
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-1.58243023,  1.85897884]), 'currentState': array([4.46850597, 2.84069366]), 'targetState': array([0.22859424, 0.07335782]), 'effectorPosition': array([ 0.27675912, -0.11516737])}
episode index:2114
target Thresh 1.9737532559833275
current state at start:  [-0.82235754 -1.94256473]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.82235754, -1.94256473]), 'currentState': array([5.59291605, 4.34170211]), 'targetState': array([-0.10488588, -0.84838519]), 'effectorPosition': array([-0.10174792, -1.1247826 ])}
done in step count: 18
reward sum = 0.8345137614500875
running average episode reward sum: 0.9548023986621309
{'reset': False, 'endBeforeDone': False, 'stepCount': 19, 'initial state': array([-0.82235754, -1.94256473]), 'currentState': array([5.66573848, 4.28308516]), 'targetState': array([-0.10488588, -0.84838519]), 'effectorPosition': array([-0.05044258, -1.07934227])}
episode index:2115
target Thresh 1.973805697012851
current state at start:  [ 3.11986014 -2.0614714 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.11986014, -2.0614714 ]), 'currentState': array([3.43388471, 3.74829797]), 'targetState': array([0.1993033 , 0.30124389]), 'effectorPosition': array([-0.3351909 ,  0.49455545])}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.9547828877211203
{'reset': False, 'endBeforeDone': False, 'stepCount': 10, 'initial state': array([ 3.11986014, -2.0614714 ]), 'currentState': array([6.17086555, 2.56374626]), 'targetState': array([0.1993033 , 0.30124389]), 'effectorPosition': array([0.22255852, 0.52458158])}
episode index:2116
target Thresh 1.9738580332651277
current state at start:  [-2.83755097  2.36630881]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.83755097,  2.36630881]), 'currentState': array([3.94563434, 2.72684306]), 'targetState': array([ 0.50260335, -0.33061589]), 'effectorPosition': array([ 0.23137626, -0.34063252])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9547995231071755
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.83755097,  2.36630881]), 'currentState': array([4.44563434, 2.34309102]), 'targetState': array([ 0.50260335, -0.33061589]), 'effectorPosition': array([ 0.61131081, -0.48035145])}
episode index:2117
target Thresh 1.9739102649495024
current state at start:  [ 0.84811716 -1.99215896]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.84811716, -1.99215896]), 'currentState': array([0.77625283, 4.67151209]), 'targetState': array([ 1.32603506, -0.24222193]), 'effectorPosition': array([ 1.38440984, -0.04096802])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9548208642199673
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.84811716, -1.99215896]), 'currentState': array([0.77625283, 4.67151209]), 'targetState': array([ 1.32603506, -0.24222193]), 'effectorPosition': array([ 1.38440984, -0.04096802])}
episode index:2118
target Thresh 1.9739623922749021
current state at start:  [-3.95777608  2.41856721]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.95777608,  2.41856721]), 'currentState': array([2.82540923, 2.67539787]), 'targetState': array([ 0.09587758, -0.78511968]), 'effectorPosition': array([-0.24119008, -0.39402668])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9548327939678577
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-3.95777608,  2.41856721]), 'currentState': array([3.73991152, 2.23700211]), 'targetState': array([ 0.09587758, -0.78511968]), 'effectorPosition': array([ 0.12718062, -0.8647601 ])}
episode index:2119
target Thresh 1.9740144154498365
current state at start:  [-2.0149656   2.10911016]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.0149656 ,  2.10911016]), 'currentState': array([3.79992292, 2.34689004]), 'targetState': array([-0.17355176, -0.53581452]), 'effectorPosition': array([ 0.19970082, -0.74774697])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9548493822725898
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.0149656 ,  2.10911016]), 'currentState': array([3.44234345, 2.3780868 ]), 'targetState': array([-0.17355176, -0.53581452]), 'effectorPosition': array([-0.06028835, -0.74265248])}
episode index:2120
target Thresh 1.9740663346823977
current state at start:  [-1.026123   -2.50916593]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.026123  , -2.50916593]), 'currentState': array([5.491202  , 3.37350886]), 'targetState': array([0.03505108, 0.14573845]), 'effectorPosition': array([-0.14478438, -0.18050477])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9548659549353561
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.026123  , -2.50916593]), 'currentState': array([5.6377538 , 3.10655137]), 'targetState': array([0.03505108, 0.14573845]), 'effectorPosition': array([0.02156493, 0.02761739])}
episode index:2121
target Thresh 1.9741181501802634
current state at start:  [-2.62890165  2.36726551]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.62890165,  2.36726551]), 'currentState': array([4.12610422, 1.91739033]), 'targetState': array([ 0.16897095, -1.14141086]), 'effectorPosition': array([ 0.41814139, -1.07040419])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9548778465682801
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-2.62890165,  2.36726551]), 'currentState': array([4.09644134, 1.66802468]), 'targetState': array([ 0.16897095, -1.14141086]), 'effectorPosition': array([ 0.29072256, -1.31199463])}
episode index:2122
target Thresh 1.974169862150695
current state at start:  [ 0.27943112 -2.08994265]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.27943112, -2.08994265]), 'currentState': array([0.33284517, 3.70413142]), 'targetState': array([-0.06938856, -0.0290422 ]), 'effectorPosition': array([ 0.31989734, -0.45371582])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9548943902109704
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.27943112, -2.08994265]), 'currentState': array([0.40590299, 3.29475354]), 'targetState': array([-0.06938856, -0.0290422 ]), 'effectorPosition': array([ 0.07099423, -0.13554429])}
episode index:2123
target Thresh 1.9742214708005408
current state at start:  [ 1.80427059 -1.60621763]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.80427059, -1.60621763]), 'currentState': array([2.26224956, 4.22350592]), 'targetState': array([-0.09062936,  0.54533706]), 'effectorPosition': array([0.34189542, 0.97150777])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.954910918275843
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.80427059, -1.60621763]), 'currentState': array([2.68714168, 3.85930613]), 'targetState': array([-0.09062936,  0.54533706]), 'effectorPosition': array([0.06704394, 0.69920111])}
episode index:2124
target Thresh 1.9742729763362357
current state at start:  [-0.53319294 -1.67101149]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.53319294, -1.67101149]), 'currentState': array([5.60926629, 4.318711  ]), 'targetState': array([ 0.08272242, -0.86947831]), 'effectorPosition': array([-0.09466223, -1.10628378])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9549227719613602
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-0.53319294, -1.67101149]), 'currentState': array([5.81903528, 4.30642235]), 'targetState': array([ 0.08272242, -0.86947831]), 'effectorPosition': array([ 0.12979823, -1.09240029])}
episode index:2125
target Thresh 1.9743243789638014
current state at start:  [ 1.77195111 -2.20210883]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.77195111, -2.20210883]), 'currentState': array([2.13547966, 4.54356477]), 'targetState': array([0.85238454, 0.72684744]), 'effectorPosition': array([0.38751729, 1.23035912])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.9549209221391299
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([ 1.77195111, -2.20210883]), 'currentState': array([1.76623051, 4.44577352]), 'targetState': array([0.85238454, 0.72684744]), 'effectorPosition': array([0.80327521, 0.90984227])}
episode index:2126
target Thresh 1.9743756788888487
current state at start:  [-2.35836555  3.06667344]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.35836555,  3.06667344]), 'currentState': array([4.29882216, 2.58282207]), 'targetState': array([ 0.20550861, -0.54698583]), 'effectorPosition': array([ 0.4243268 , -0.35232333])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9549374144183311
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.35836555,  3.06667344]), 'currentState': array([4.03666499, 2.35637322]), 'targetState': array([ 0.20550861, -0.54698583]), 'effectorPosition': array([ 0.36850986, -0.67062224])}
episode index:2127
target Thresh 1.9744268763165775
current state at start:  [ 2.1378867  -2.81520291]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.1378867 , -2.81520291]), 'currentState': array([2.32176655, 3.21989655]), 'targetState': array([0.08350036, 0.03189008]), 'effectorPosition': array([0.05509296, 0.05561595])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9549585904453902
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.1378867 , -2.81520291]), 'currentState': array([2.32176655, 3.21989655]), 'targetState': array([0.08350036, 0.03189008]), 'effectorPosition': array([0.05509296, 0.05561595])}
episode index:2128
target Thresh 1.9744779714517775
current state at start:  [-2.80135014  2.13837166]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.80135014,  2.13837166]), 'currentState': array([2.98183517, 2.2856649 ]), 'targetState': array([-0.65685503, -0.43753261]), 'effectorPosition': array([-0.46022818, -0.69076312])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9549750495386521
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.80135014,  2.13837166]), 'currentState': array([2.48183517, 2.13722687]), 'targetState': array([-0.65685503, -0.43753261]), 'effectorPosition': array([-0.88333242, -0.38272295])}
episode index:2129
target Thresh 1.974528964498829
current state at start:  [-3.9115555   2.31107067]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.9115555 ,  2.31107067]), 'currentState': array([2.7905427 , 1.95000713]), 'targetState': array([-0.5753426 , -1.05289836]), 'effectorPosition': array([-0.91085504, -0.65571959])}
done in step count: 14
reward sum = 0.8687458127689782
running average episode reward sum: 0.9549345663289011
{'reset': False, 'endBeforeDone': False, 'stepCount': 15, 'initial state': array([-3.9115555 ,  2.31107067]), 'currentState': array([5.1748808 , 4.61895187]), 'targetState': array([-0.5753426 , -1.05289836]), 'effectorPosition': array([-0.48648923, -1.25567743])}
episode index:2130
target Thresh 1.974579855661705
current state at start:  [-3.76000069  2.15939419]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.76000069,  2.15939419]), 'currentState': array([2.03241052, 1.74918635]), 'targetState': array([-1.01082816,  0.48390515]), 'effectorPosition': array([-1.24748717,  0.29813588])}
done in step count: 14
reward sum = 0.8687458127689782
running average episode reward sum: 0.9548941211137157
{'reset': False, 'endBeforeDone': False, 'stepCount': 15, 'initial state': array([-3.76000069,  2.15939419]), 'currentState': array([1.74803673, 2.16269288]), 'targetState': array([-1.01082816,  0.48390515]), 'effectorPosition': array([-0.89482508,  0.2888186 ])}
episode index:2131
target Thresh 1.9746306451439695
current state at start:  [ 1.03254327 -2.69990569]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.03254327, -2.69990569]), 'currentState': array([1.3540717 , 3.33415745]), 'targetState': array([ 0.15295525, -0.05518408]), 'effectorPosition': array([ 0.19087455, -0.02310117])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.954915277717321
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.03254327, -2.69990569]), 'currentState': array([1.3540717 , 3.33415745]), 'targetState': array([ 0.15295525, -0.05518408]), 'effectorPosition': array([ 0.19087455, -0.02310117])}
episode index:2132
target Thresh 1.9746813331487807
current state at start:  [-2.18241486  1.91037588]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.18241486,  1.91037588]), 'currentState': array([4.60077045, 1.81990765]), 'targetState': array([ 1.20822491, -0.65812099]), 'effectorPosition': array([ 0.87917584, -0.85671712])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9549317262509743
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.18241486,  1.91037588]), 'currentState': array([5.04124025, 1.74666436]), 'targetState': array([ 1.20822491, -0.65812099]), 'effectorPosition': array([ 1.19826631, -0.4628522 ])}
episode index:2133
target Thresh 1.9747319198788906
current state at start:  [-0.01121277 -2.11581399]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.01121277, -2.11581399]), 'currentState': array([5.95470706, 3.75936429]), 'targetState': array([-0.3954381 , -0.20691415]), 'effectorPosition': array([-0.01191133, -0.60787806])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9549435201936871
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-0.01121277, -2.11581399]), 'currentState': array([5.35609824, 3.65414982]), 'targetState': array([-0.3954381 , -0.20691415]), 'effectorPosition': array([-0.31513925, -0.3971154 ])}
episode index:2134
target Thresh 1.9747824055366465
current state at start:  [-1.80436472  2.21841452]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.80436472,  2.21841452]), 'currentState': array([4.03908368, 2.17188415]), 'targetState': array([-0.06591463, -1.05682265]), 'effectorPosition': array([ 0.3738201 , -0.85391956])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.954959940090552
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.80436472,  2.21841452]), 'currentState': array([3.6648339 , 2.11330635]), 'targetState': array([-0.06591463, -1.05682265]), 'effectorPosition': array([ 0.00894856, -0.98353721])}
episode index:2135
target Thresh 1.974832790323991
current state at start:  [ 4.49147818 -2.72850467]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.49147818, -2.72850467]), 'currentState': array([4.81684036, 3.36925892]), 'targetState': array([0.03418811, 0.01919927]), 'effectorPosition': array([-0.22178413, -0.0491959 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9549763446129814
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 4.49147818, -2.72850467]), 'currentState': array([4.76934445, 3.28062433]), 'targetState': array([0.03418811, 0.01919927]), 'effectorPosition': array([-0.1378102 , -0.01752256])}
episode index:2136
target Thresh 1.9748830744424632
current state at start:  [-1.00000007 -2.24944956]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.00000007, -2.24944956]), 'currentState': array([5.78318524, 4.34921094]), 'targetState': array([ 0.15962666, -0.77404495]), 'effectorPosition': array([ 0.11767028, -1.12945127])}
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.9549484372239527
{'reset': False, 'endBeforeDone': False, 'stepCount': 12, 'initial state': array([-1.00000007, -2.24944956]), 'currentState': array([5.87696143, 4.16041099]), 'targetState': array([ 0.15962666, -0.77404495]), 'effectorPosition': array([ 0.1004605 , -0.97013541])}
episode index:2137
target Thresh 1.9749332580931998
current state at start:  [ 1.18843129 -1.65858133]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.18843129, -1.65858133]), 'currentState': array([0.75026723, 4.12460398]), 'targetState': array([ 0.50959005, -0.29001177]), 'effectorPosition': array([ 0.89327492, -0.30499451])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9549648317809106
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.18843129, -1.65858133]), 'currentState': array([0.71832941, 3.98923479]), 'targetState': array([ 0.50959005, -0.29001177]), 'effectorPosition': array([ 0.74808148, -0.34186057])}
episode index:2138
target Thresh 1.974983341476935
current state at start:  [-3.41879777  2.31096556]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.41879777,  2.31096556]), 'currentState': array([2.36438754, 2.64052968]), 'targetState': array([-0.24626294,  0.23863644]), 'effectorPosition': array([-0.42450237, -0.2562281 ])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9549765826776938
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-3.41879777,  2.31096556]), 'currentState': array([1.43281316, 2.72689234]), 'targetState': array([-0.24626294,  0.23863644]), 'effectorPosition': array([-0.38742735,  0.13937658])}
episode index:2139
target Thresh 1.975033324794003
current state at start:  [-1.97626979  1.60090076]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.97626979,  1.60090076]), 'currentState': array([3.82882344, 1.70586641]), 'targetState': array([ 0.18662592, -0.75914557]), 'effectorPosition': array([-0.04029216, -1.31493613])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9549837426857883
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-1.97626979,  1.60090076]), 'currentState': array([3.82078429, 2.07705018]), 'targetState': array([ 0.18662592, -0.75914557]), 'effectorPosition': array([ 0.14858585, -1.00404853])}
episode index:2140
target Thresh 1.9750832082443368
current state at start:  [-2.67983628  2.17683998]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.67983628,  2.17683998]), 'currentState': array([3.41367497, 2.58405528]), 'targetState': array([ 0.12379207, -0.22612235]), 'effectorPosition': array([-0.00367978, -0.55033186])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9550000977802835
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.67983628,  2.17683998]), 'currentState': array([3.5725876 , 2.86825499]), 'targetState': array([ 0.12379207, -0.22612235]), 'effectorPosition': array([ 0.07904727, -0.26076999])}
episode index:2141
target Thresh 1.9751329920274705
current state at start:  [-1.22518412 -2.7791847 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.22518412, -2.7791847 ]), 'currentState': array([5.53667   , 3.73296328]), 'targetState': array([ 0.32720467, -0.98851038]), 'effectorPosition': array([-0.25392946, -0.52456187])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9550164376039155
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.22518412, -2.7791847 ]), 'currentState': array([5.97906092, 4.17472415]), 'targetState': array([ 0.32720467, -0.98851038]), 'effectorPosition': array([ 0.20827336, -0.96558729])}
episode index:2142
target Thresh 1.975182676342539
current state at start:  [-3.46397331  2.38804116]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.46397331,  2.38804116]), 'currentState': array([3.31235645, 1.88804116]), 'targetState': array([-0.39852973, -1.32803581]), 'effectorPosition': array([-0.51658735, -1.05320338])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9550327621780621
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.46397331,  2.38804116]), 'currentState': array([3.5892152 , 1.75403995]), 'targetState': array([-0.39852973, -1.32803581]), 'effectorPosition': array([-0.31163424, -1.24034044])}
episode index:2143
target Thresh 1.9752322613882798
current state at start:  [0.81334979 1.58662486]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.81334979, 1.58662486]), 'currentState': array([1.31334979, 2.03696186]), 'targetState': array([-0.50595005,  1.14128263]), 'effectorPosition': array([-0.72368507,  0.75983641])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9550490715240612
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.81334979, 1.58662486]), 'currentState': array([1.08993099, 1.97563965]), 'targetState': array([-0.50595005,  1.14128263]), 'effectorPosition': array([-0.53456516,  0.9625438 ])}
episode index:2144
target Thresh 1.9752817473630333
current state at start:  [-3.91548371  1.82198062]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.91548371,  1.82198062]), 'currentState': array([2.8677016, 1.527278 ]), 'targetState': array([-0.72176335, -1.09741406]), 'effectorPosition': array([-1.27483214, -0.67956766])}
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.9550129279116951
{'reset': False, 'endBeforeDone': False, 'stepCount': 14, 'initial state': array([-3.91548371,  1.82198062]), 'currentState': array([4.7469614 , 4.74359629]), 'targetState': array([-0.72176335, -1.09741406]), 'effectorPosition': array([-0.96327176, -1.06513474])}
episode index:2145
target Thresh 1.975331134464743
current state at start:  [-0.30398633 -2.20418121]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.30398633, -2.20418121]), 'currentState': array([6.06911873, 3.60495924]), 'targetState': array([ 0.0796932 , -0.07998467]), 'effectorPosition': array([ 0.00808975, -0.45916107])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9550200509648584
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-0.30398633, -2.20418121]), 'currentState': array([0.43383834, 3.4475006 ]), 'targetState': array([ 0.0796932 , -0.07998467]), 'effectorPosition': array([ 0.16871935, -0.25374389])}
episode index:2146
target Thresh 1.975380422890958
current state at start:  [-1.11026129  2.46945718]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.11026129,  2.46945718]), 'currentState': array([4.72792718, 2.72388226]), 'targetState': array([ 0.00130713, -0.23462693]), 'effectorPosition': array([ 0.40695572, -0.07966635])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.955036343442285
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.11026129,  2.46945718]), 'currentState': array([4.32025037, 2.92165096]), 'targetState': array([ 0.00130713, -0.23462693]), 'effectorPosition': array([ 0.19240577, -0.10563936])}
episode index:2147
target Thresh 1.9754296128388316
current state at start:  [-1.35157025  2.47590971]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.35157025,  2.47590971]), 'currentState': array([4.58862948, 2.67833099]), 'targetState': array([0.22570354, 0.04677731]), 'effectorPosition': array([ 0.43043951, -0.15975726])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9550526207498071
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.35157025,  2.47590971]), 'currentState': array([4.31184634, 2.88919126]), 'targetState': array([0.22570354, 0.04677731]), 'effectorPosition': array([ 0.21760939, -0.12655088])}
episode index:2148
target Thresh 1.9754787045051236
current state at start:  [0.88908535 1.59622508]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.88908535, 1.59622508]), 'currentState': array([0.40837618, 2.06671708]), 'targetState': array([0.72123489, 0.55972745]), 'effectorPosition': array([0.13177619, 1.0153579 ])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9550597153888254
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([0.88908535, 1.59622508]), 'currentState': array([5.95452569, 2.30956756]), 'targetState': array([0.72123489, 0.55972745]), 'effectorPosition': array([0.54776414, 0.59430165])}
episode index:2149
target Thresh 1.975527698086201
current state at start:  [-0.07270157 -2.12204581]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.07270157, -2.12204581]), 'currentState': array([0.42729843, 3.92836503]), 'targetState': array([1.17078588, 0.05351882]), 'effectorPosition': array([ 0.56088086, -0.52263167])}
done in step count: 19
reward sum = 0.8261686238355866
running average episode reward sum: 0.9549997660439169
{'reset': False, 'endBeforeDone': False, 'stepCount': 20, 'initial state': array([-0.07270157, -2.12204581]), 'currentState': array([0.75084138, 4.672276  ]), 'targetState': array([1.17078588, 0.05351882]), 'effectorPosition': array([ 1.38350108, -0.07563273])}
episode index:2150
target Thresh 1.9755765937780383
current state at start:  [-3.36114492  2.2044777 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.36114492,  2.2044777 ]), 'currentState': array([3.42204039, 2.05007878]), 'targetState': array([-0.13363993, -1.11190095]), 'effectorPosition': array([-0.27220576, -1.00180778])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9550206866547751
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.36114492,  2.2044777 ]), 'currentState': array([3.42204039, 2.05007878]), 'targetState': array([-0.13363993, -1.11190095]), 'effectorPosition': array([-0.27220576, -1.00180778])}
episode index:2151
target Thresh 1.975625391776218
current state at start:  [1.2547212  2.79903684]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.2547212 , 2.79903684]), 'currentState': array([1.7547212 , 2.66377527]), 'targetState': array([-0.98974998, -0.75878871]), 'effectorPosition': array([-0.47256967,  0.0260099 ])}
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.9549846737999166
{'reset': False, 'endBeforeDone': False, 'stepCount': 14, 'initial state': array([1.2547212 , 2.79903684]), 'currentState': array([4.51117367, 4.79012108]), 'targetState': array([-0.98974998, -0.75878871]), 'effectorPosition': array([-1.1922459 , -0.85665478])}
episode index:2152
target Thresh 1.9756740922759324
current state at start:  [-1.22898983  1.96635753]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.22898983,  1.96635753]), 'currentState': array([4.61415945, 2.30842793]), 'targetState': array([ 0.31820762, -0.49712181]), 'effectorPosition': array([ 0.70438106, -0.39846361])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9550009373048863
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.22898983,  1.96635753]), 'currentState': array([4.22845836, 2.47604829]), 'targetState': array([ 0.31820762, -0.49712181]), 'effectorPosition': array([ 0.44728731, -0.47620639])}
episode index:2153
target Thresh 1.9757226954719835
current state at start:  [-3.29700384  1.62066007]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.29700384,  1.62066007]), 'currentState': array([2.57934001, 2.03259403]), 'targetState': array([-0.23080496,  0.10236077]), 'effectorPosition': array([-0.94634246, -0.46186523])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9550125896088304
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-3.29700384,  1.62066007]), 'currentState': array([1.77883771, 2.75436205]), 'targetState': array([-0.23080496,  0.10236077]), 'effectorPosition': array([-0.38477574, -0.00555119])}
episode index:2154
target Thresh 1.975771201558784
current state at start:  [0.28016159 1.61574595]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.28016159, 1.61574595]), 'currentState': array([0.78016159, 2.11574595]), 'targetState': array([-0.31663703,  0.59603378]), 'effectorPosition': array([-0.25917103,  0.94661521])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9550196830707288
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([0.28016159, 1.61574595]), 'currentState': array([0.98839567, 2.517049  ]), 'targetState': array([-0.31663703,  0.59603378]), 'effectorPosition': array([-0.3845025 ,  0.47926793])}
episode index:2155
target Thresh 1.9758196107303585
current state at start:  [ 0.7798564  -2.47280755]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.7798564 , -2.47280755]), 'currentState': array([1.2798564 , 3.38528491]), 'targetState': array([0.12420813, 0.3835365 ]), 'effectorPosition': array([ 0.23962269, -0.04090936])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9550313158707889
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 0.7798564 , -2.47280755]), 'currentState': array([2.16830267, 3.71713274]), 'targetState': array([0.12420813, 0.3835365 ]), 'effectorPosition': array([0.35935228, 0.4393962 ])}
episode index:2156
target Thresh 1.9758679231803435
current state at start:  [ 2.95432467 -2.42055189]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.95432467, -2.42055189]), 'currentState': array([3.41924924, 3.48955683]), 'targetState': array([-0.50063693,  0.36086285]), 'effectorPosition': array([-0.15110066,  0.31149783])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9550475275926846
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 2.95432467, -2.42055189]), 'currentState': array([3.87119431, 3.52922637]), 'targetState': array([-0.50063693,  0.36086285]), 'effectorPosition': array([-0.30727077,  0.23231976])}
episode index:2157
target Thresh 1.9759161391019893
current state at start:  [-0.90015953  2.58415796]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.90015953,  2.58415796]), 'currentState': array([5.88302578, 2.38799395]), 'targetState': array([0.054117  , 0.77820808]), 'effectorPosition': array([0.51594467, 0.52472741])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9550637242898149
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.90015953,  2.58415796]), 'currentState': array([0.09984047, 2.46747558]), 'targetState': array([0.054117  , 0.77820808]), 'effectorPosition': array([0.15543458, 0.64290226])}
episode index:2158
target Thresh 1.9759642586881592
current state at start:  [0.38463113 2.37580682]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.38463113, 2.37580682]), 'currentState': array([0.22484803, 2.87305833]), 'targetState': array([0.01722053, 0.3527205 ]), 'effectorPosition': array([-0.0242179 ,  0.26663062])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9550845377570266
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.38463113, 2.37580682]), 'currentState': array([0.22484803, 2.87305833]), 'targetState': array([0.01722053, 0.3527205 ]), 'effectorPosition': array([-0.0242179 ,  0.26663062])}
episode index:2159
target Thresh 1.976012282131332
current state at start:  [0.5182886  2.62558695]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.5182886 , 2.62558695]), 'currentState': array([0.88526698, 3.11981219]), 'targetState': array([-0.86957608, -0.31481457]), 'effectorPosition': array([-0.01670842,  0.01397135])}
done in step count: 85
reward sum = 0.4255901233886546
running average episode reward sum: 0.9548394014540783
{'reset': False, 'endBeforeDone': False, 'stepCount': 86, 'initial state': array([0.5182886 , 2.62558695]), 'currentState': array([4.56825014, 4.32318833]), 'targetState': array([-0.86957608, -0.31481457]), 'effectorPosition': array([-1.00475429, -0.48121812])}
episode index:2160
target Thresh 1.9760602096236013
current state at start:  [-2.00923849  1.85229677]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.00923849,  1.85229677]), 'currentState': array([3.82901883, 2.12212029]), 'targetState': array([-0.28950254, -0.52540453]), 'effectorPosition': array([ 0.17249552, -0.96052815])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.95485109076391
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-2.00923849,  1.85229677]), 'currentState': array([3.0110873, 2.3526931]), 'targetState': array([-0.28950254, -0.52540453]), 'effectorPosition': array([-0.38520275, -0.66510574])}
episode index:2161
target Thresh 1.976108041356677
current state at start:  [ 0.28326728 -2.16878296]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.28326728, -2.16878296]), 'currentState': array([0.59433454, 3.72372024]), 'targetState': array([ 0.43914855, -0.11941441]), 'effectorPosition': array([ 0.44432774, -0.36329504])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9548719737006519
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.28326728, -2.16878296]), 'currentState': array([0.59433454, 3.72372024]), 'targetState': array([ 0.43914855, -0.11941441]), 'effectorPosition': array([ 0.44432774, -0.36329504])}
episode index:2162
target Thresh 1.9761557775218863
current state at start:  [-1.19185401 -2.22398355]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.19185401, -2.22398355]), 'currentState': array([5.57810678, 4.41916491]), 'targetState': array([-0.09702434, -1.39511328]), 'effectorPosition': array([-0.078992  , -1.18982348])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9548928373281597
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.19185401, -2.22398355]), 'currentState': array([5.57810678, 4.41916491]), 'targetState': array([-0.09702434, -1.39511328]), 'effectorPosition': array([-0.078992  , -1.18982348])}
episode index:2163
target Thresh 1.976203418310174
current state at start:  [ 1.65802647 -2.60889387]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.65802647, -2.60889387]), 'currentState': array([1.66579878, 4.04773367]), 'targetState': array([0.84445199, 0.28654934]), 'effectorPosition': array([0.74722864, 0.45615091])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9549136816732021
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.65802647, -2.60889387]), 'currentState': array([1.66579878, 4.04773367]), 'targetState': array([0.84445199, 0.28654934]), 'effectorPosition': array([0.74722864, 0.45615091])}
episode index:2164
target Thresh 1.9762509639121033
current state at start:  [-3.75519318  2.02660613]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.75519318,  2.02660613]), 'currentState': array([2.02799213, 1.52660613]), 'targetState': array([-1.22514441,  0.00654978]), 'effectorPosition': array([-1.35735228,  0.49592987])}
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.9548861641547658
{'reset': False, 'endBeforeDone': False, 'stepCount': 12, 'initial state': array([-3.75519318,  2.02660613]), 'currentState': array([4.12849907, 4.29267599]), 'targetState': array([-1.22514441,  0.00654978]), 'effectorPosition': array([-1.08854062,  0.00908761])}
episode index:2165
target Thresh 1.9762984145178564
current state at start:  [-1.47300279  2.47188721]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.47300279,  2.47188721]), 'currentState': array([5.20764983, 2.75785957]), 'targetState': array([-0.12527884,  0.6790988 ]), 'effectorPosition': array([0.36396447, 0.11394246])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9548932799607885
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-1.47300279,  2.47188721]), 'currentState': array([0.38975346, 2.66667843]), 'targetState': array([-0.12527884,  0.6790988 ]), 'effectorPosition': array([-0.07137325,  0.46501824])}
episode index:2166
target Thresh 1.976345770317236
current state at start:  [-1.71489532  1.85552573]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.71489532,  1.85552573]), 'currentState': array([4.91975712, 1.91538008]), 'targetState': array([ 0.99161124, -0.15756318]), 'effectorPosition': array([ 1.05738781, -0.45422589])}
done in step count: 42
reward sum = 0.6556592205741436
running average episode reward sum: 0.9547551931774999
{'reset': False, 'endBeforeDone': False, 'stepCount': 43, 'initial state': array([-1.71489532,  1.85552573]), 'currentState': array([5.03250511, 1.9200348 ]), 'targetState': array([ 0.99161124, -0.15756318]), 'effectorPosition': array([ 1.09889908, -0.3287189 ])}
episode index:2167
target Thresh 1.9763930314996654
current state at start:  [ 2.13005776 -3.02706924]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.13005776, -3.02706924]), 'currentState': array([2.55072144, 2.85667586]), 'targetState': array([ 0.41624275, -0.84784294]), 'effectorPosition': array([-0.19006382, -0.21096363])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9547623628300934
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 2.13005776, -3.02706924]), 'currentState': array([3.95306141, 2.07078961]), 'targetState': array([ 0.41624275, -0.84784294]), 'effectorPosition': array([ 0.27812702, -0.98173626])}
episode index:2168
target Thresh 1.9764401982541893
current state at start:  [-0.80499916  2.64555728]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.80499916,  2.64555728]), 'currentState': array([5.94395532, 2.32147869]), 'targetState': array([0.23272831, 0.93498168]), 'effectorPosition': array([0.54307027, 0.58377987])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9547786088592173
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.80499916,  2.64555728]), 'currentState': array([0.09826253, 2.27829508]), 'targetState': array([0.23272831, 0.93498168]), 'effectorPosition': array([0.27381803, 0.79066676])}
episode index:2169
target Thresh 1.976487270769475
current state at start:  [-1.23967365  2.43477037]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.23967365,  2.43477037]), 'currentState': array([4.54351166, 2.68431431]), 'targetState': array([ 0.03244392, -0.3631593 ]), 'effectorPosition': array([ 0.41795834, -0.17548768])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9547948399150424
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.23967365,  2.43477037]), 'currentState': array([4.05787048, 2.70988356]), 'targetState': array([ 0.03244392, -0.3631593 ]), 'effectorPosition': array([ 0.27609861, -0.32751436])}
episode index:2170
target Thresh 1.976534249233812
current state at start:  [ 0.10990162 -2.19070881]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.10990162, -2.19070881]), 'currentState': array([6.25879133, 3.63524998]), 'targetState': array([-0.01481288, -0.14570144]), 'effectorPosition': array([ 0.10780082, -0.47662095])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9548110560182597
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.10990162, -2.19070881]), 'currentState': array([6.15756356, 3.4888099 ]), 'targetState': array([-0.01481288, -0.14570144]), 'effectorPosition': array([ 0.01657194, -0.34507799])}
episode index:2171
target Thresh 1.976581133835115
current state at start:  [-0.84629781  1.95485506]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.84629781,  1.95485506]), 'currentState': array([4.9368875 , 2.25324402]), 'targetState': array([ 0.16251208, -0.6978932 ]), 'effectorPosition': array([ 0.83877136, -0.18728006])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9548226991784724
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-0.84629781,  1.95485506]), 'currentState': array([4.03088322, 2.35575995]), 'targetState': array([ 0.16251208, -0.6978932 ]), 'effectorPosition': array([ 0.36468986, -0.67335162])}
episode index:2172
target Thresh 1.976627924760922
current state at start:  [-1.27889906 -2.31741308]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.27889906, -2.31741308]), 'currentState': array([5.18152863, 3.919586  ]), 'targetState': array([-0.23691776, -0.2440257 ]), 'effectorPosition': array([-0.49595764, -0.5739158 ])}
done in step count: 35
reward sum = 0.7034476949995692
running average episode reward sum: 0.9547070180904932
{'reset': False, 'endBeforeDone': False, 'stepCount': 36, 'initial state': array([-1.27889906, -2.31741308]), 'currentState': array([5.01881043, 3.72285729]), 'targetState': array([-0.23691776, -0.2440257 ]), 'effectorPosition': array([-0.47396455, -0.32221072])}
episode index:2173
target Thresh 1.9766746221983968
current state at start:  [-3.61477996  2.61147859]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.61477996,  2.61147859]), 'currentState': array([2.27289924, 2.32552781]), 'targetState': array([-1.0425197,  0.5718373]), 'effectorPosition': array([-0.75954007, -0.2300276 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9547232522128066
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.61477996,  2.61147859]), 'currentState': array([1.87795007, 1.82552781]), 'targetState': array([-1.0425197,  0.5718373]), 'effectorPosition': array([-1.14859902,  0.42041547])}
episode index:2174
target Thresh 1.9767212263343295
current state at start:  [ 3.18152227 -1.71954067]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.18152227, -1.71954067]), 'currentState': array([2.94504984, 4.208447  ]), 'targetState': array([-0.29601754,  0.77467393]), 'effectorPosition': array([-0.33615915,  0.95980966])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.954744069108341
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.18152227, -1.71954067]), 'currentState': array([2.94504984, 4.208447  ]), 'targetState': array([-0.29601754,  0.77467393]), 'effectorPosition': array([-0.33615915,  0.95980966])}
episode index:2175
target Thresh 1.9767677373551362
current state at start:  [ 0.47148316 -2.50627885]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.47148316, -2.50627885]), 'currentState': array([0.03024017, 4.06544602]), 'targetState': array([-0.36818184, -1.16920977]), 'effectorPosition': array([ 0.42119432, -0.78555426])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9547557216501111
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 0.47148316, -2.50627885]), 'currentState': array([5.3540101 , 4.54903179]), 'targetState': array([-0.36818184, -1.16920977]), 'effectorPosition': array([-0.28930032, -1.26136518])}
episode index:2176
target Thresh 1.9768141554468615
current state at start:  [-0.31125362 -1.69189327]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.31125362, -1.69189327]), 'currentState': array([0.02902918, 4.10035087]), 'targetState': array([ 0.69251354, -0.29157922]), 'effectorPosition': array([ 0.44904037, -0.8057848 ])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9547673634867442
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-0.31125362, -1.69189327]), 'currentState': array([0.5819574 , 4.01072312]), 'targetState': array([ 0.69251354, -0.29157922]), 'effectorPosition': array([ 0.71596559, -0.44318332])}
episode index:2177
target Thresh 1.9768604807951777
current state at start:  [ 3.91057916 -2.0816318 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.91057916, -2.0816318 ]), 'currentState': array([4.39732007, 3.73603641]), 'targetState': array([-0.65654864, -0.26618   ]), 'effectorPosition': array([-0.58563677,  0.01045299])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9547835400875306
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.91057916, -2.0816318 ]), 'currentState': array([4.76155008, 3.89008294]), 'targetState': array([-0.65654864, -0.26618   ]), 'effectorPosition': array([-0.66657652, -0.30040226])}
episode index:2178
target Thresh 1.9769067135853862
current state at start:  [ 0.3246555  -2.37848973]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.3246555 , -2.37848973]), 'currentState': array([0.37149691, 3.40469558]), 'targetState': array([ 0.0426261 , -0.04461327]), 'effectorPosition': array([ 0.12647599, -0.22984467])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9548042911017172
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.3246555 , -2.37848973]), 'currentState': array([0.37149691, 3.40469558]), 'targetState': array([ 0.0426261 , -0.04461327]), 'effectorPosition': array([ 0.12647599, -0.22984467])}
episode index:2179
target Thresh 1.9769528540024184
current state at start:  [ 1.15962561 -3.07904341]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.15962561, -3.07904341]), 'currentState': array([1.44107556, 2.98539291]), 'targetState': array([0.00257912, 0.10683213]), 'effectorPosition': array([-0.15268345,  0.03219562])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9548250230782761
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.15962561, -3.07904341]), 'currentState': array([1.44107556, 2.98539291]), 'targetState': array([0.00257912, 0.10683213]), 'effectorPosition': array([-0.15268345,  0.03219562])}
episode index:2180
target Thresh 1.9769989022308356
current state at start:  [1.59449542 1.71487347]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.59449542, 1.71487347]), 'currentState': array([1.12148759, 1.75942712]), 'targetState': array([-0.62773234,  1.24534264]), 'effectorPosition': array([-0.53187249,  1.15848321])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9548457360433937
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.59449542, 1.71487347]), 'currentState': array([1.12148759, 1.75942712]), 'targetState': array([-0.62773234,  1.24534264]), 'effectorPosition': array([-0.53187249,  1.15848321])}
episode index:2181
target Thresh 1.9770448584548312
current state at start:  [-1.30692742  1.67474033]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.30692742,  1.67474033]), 'currentState': array([5.17591022, 1.85496114]), 'targetState': array([0.39790895, 0.329211  ]), 'effectorPosition': array([ 1.18036475, -0.21453985])}
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.9548184640535748
{'reset': False, 'endBeforeDone': False, 'stepCount': 12, 'initial state': array([-1.30692742,  1.67474033]), 'currentState': array([5.61056453, 2.41496646]), 'targetState': array([0.39790895, 0.329211  ]), 'effectorPosition': array([0.61148234, 0.36228338])}
episode index:2182
target Thresh 1.97709072285823
current state at start:  [ 0.180106   -2.36367374]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.180106  , -2.36367374]), 'currentState': array([0.5204366 , 3.54032452]), 'targetState': array([0.19846977, 0.22337394]), 'effectorPosition': array([ 0.26112065, -0.29783861])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9548211106618874
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([ 0.180106  , -2.36367374]), 'currentState': array([1.60021675, 3.50685134]), 'targetState': array([0.19846977, 0.22337394]), 'effectorPosition': array([0.35509581, 0.07644725])}
episode index:2183
target Thresh 1.9771364956244897
current state at start:  [-0.697167    2.13188475]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.697167  ,  2.13188475]), 'currentState': array([5.14528314, 2.16590306]), 'targetState': array([ 1.05792644, -0.19813552]), 'effectorPosition': array([ 0.93603139, -0.05148735])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9548417969665294
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.697167  ,  2.13188475]), 'currentState': array([5.14528314, 2.16590306]), 'targetState': array([ 1.05792644, -0.19813552]), 'effectorPosition': array([ 0.93603139, -0.05148735])}
episode index:2184
target Thresh 1.9771821769367015
current state at start:  [1.45691963 1.67933441]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.45691963, 1.67933441]), 'currentState': array([1.82239138, 2.17933441]), 'targetState': array([-0.77432263,  0.52741662]), 'effectorPosition': array([-0.90128568,  0.21058715])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9548578876772997
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.45691963, 1.67933441]), 'currentState': array([1.37278303, 2.00180181]), 'targetState': array([-0.77432263,  0.52741662]), 'effectorPosition': array([-0.77625805,  0.74956946])}
episode index:2185
target Thresh 1.9772277669775904
current state at start:  [-1.76311285  1.94371193]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.76311285,  1.94371193]), 'currentState': array([4.06737923, 2.3229846 ]), 'targetState': array([-0.15034518, -0.49019221]), 'effectorPosition': array([ 0.39305565, -0.69212046])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9548694348467064
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.76311285,  1.94371193]), 'currentState': array([3.38192352, 2.58699783]), 'targetState': array([-0.15034518, -0.49019221]), 'effectorPosition': array([-0.02023511, -0.54714055])}
episode index:2186
target Thresh 1.977273265929517
current state at start:  [ 1.33754481 -1.6626752 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.33754481, -1.6626752 ]), 'currentState': array([0.83754481, 4.24040351]), 'targetState': array([ 0.67673252, -0.21215041]), 'effectorPosition': array([ 1.02676078, -0.19092183])}
done in step count: 41
reward sum = 0.6622820409839835
running average episode reward sum: 0.9547356500301253
{'reset': False, 'endBeforeDone': False, 'stepCount': 42, 'initial state': array([ 1.33754481, -1.6626752 ]), 'currentState': array([0.58274019, 3.97737613]), 'targetState': array([ 0.67673252, -0.21215041]), 'effectorPosition': array([ 0.68327294, -0.43811496])}
episode index:2187
target Thresh 1.977318673974477
current state at start:  [-1.90517168  2.37305074]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.90517168,  2.37305074]), 'currentState': array([4.16324281, 2.01436066]), 'targetState': array([ 0.53712964, -0.62906522]), 'effectorPosition': array([ 0.47247229, -0.95835628])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9542992991845906
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([-1.90517168,  2.37305074]), 'currentState': array([4.11458642, 1.67639341]), 'targetState': array([ 0.53712964, -0.62906522]), 'effectorPosition': array([ 0.31846527, -1.2991451 ])}
episode index:2188
target Thresh 1.9773639912941026
current state at start:  [ 1.91253722 -2.30860621]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.91253722, -2.30860621]), 'currentState': array([1.63554046, 3.4824282 ]), 'targetState': array([ 0.28518528, -0.19792764]), 'effectorPosition': array([0.32985257, 0.07903099])}
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.9542682738636821
{'reset': False, 'endBeforeDone': False, 'stepCount': 13, 'initial state': array([ 1.91253722, -2.30860621]), 'currentState': array([4.01402985, 2.6741963 ]), 'targetState': array([ 0.28518528, -0.19792764]), 'effectorPosition': array([ 0.27612449, -0.37184194])}
episode index:2189
target Thresh 1.9774092180696634
current state at start:  [0.36769429 2.65202779]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.36769429, 2.65202779]), 'currentState': array([6.19678912, 3.11609525]), 'targetState': array([ 0.48457425, -0.40321827]), 'effectorPosition': array([0.00252373, 0.02537151])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9538325349258447
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([0.36769429, 2.65202779]), 'currentState': array([5.80108299, 4.16740401]), 'targetState': array([ 0.48457425, -0.40321827]), 'effectorPosition': array([ 0.03022632, -0.98095662])}
episode index:2190
target Thresh 1.9774543544820662
current state at start:  [-3.09094668  2.37540657]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.09094668,  2.37540657]), 'currentState': array([2.69780445, 2.77327148]), 'targetState': array([-0.36238722,  0.17519897]), 'effectorPosition': array([-0.21516253, -0.29637619])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9538445237277957
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-3.09094668,  2.37540657]), 'currentState': array([1.73470055, 2.63418212]), 'targetState': array([-0.36238722,  0.17519897]), 'effectorPosition': array([-0.49996196,  0.04501818])}
episode index:2191
target Thresh 1.9774994007118567
current state at start:  [ 2.32870465 -2.73925223]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.32870465, -2.73925223]), 'currentState': array([2.60719913, 3.20485233]), 'targetState': array([-0.11387915,  0.1303136 ]), 'effectorPosition': array([0.03047653, 0.05542232])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9538655800582119
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.32870465, -2.73925223]), 'currentState': array([2.60719913, 3.20485233]), 'targetState': array([-0.11387915,  0.1303136 ]), 'effectorPosition': array([0.03047653, 0.05542232])}
episode index:2192
target Thresh 1.9775443569392204
current state at start:  [ 0.28190695 -1.63346376]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.28190695, -1.63346376]), 'currentState': array([6.0713159 , 4.43613414]), 'targetState': array([ 0.30961904, -0.75351857]), 'effectorPosition': array([ 0.50866949, -1.09350196])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.953430620833379
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([ 0.28190695, -1.63346376]), 'currentState': array([5.60692203, 4.36176966]), 'targetState': array([ 0.30961904, -0.75351857]), 'effectorPosition': array([-0.07577302, -1.14337195])}
episode index:2193
target Thresh 1.9775892233439816
current state at start:  [-2.09188218  2.16132831]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.09188218,  2.16132831]), 'currentState': array([3.78831872, 2.28600098]), 'targetState': array([ 0.34378009, -0.26379852]), 'effectorPosition': array([ 0.18020589, -0.80992713])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9534427764300822
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-2.09188218,  2.16132831]), 'currentState': array([3.93626083, 2.60466577]), 'targetState': array([ 0.34378009, -0.26379852]), 'effectorPosition': array([ 0.26644658, -0.45873409])}
episode index:2194
target Thresh 1.9776340001056065
current state at start:  [-1.22961981 -2.38673726]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.22961981, -2.38673726]), 'currentState': array([4.5535655 , 3.44568688]), 'targetState': array([-0.83866557,  0.34243729]), 'effectorPosition': array([-0.30291693,  0.00205271])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.953454920951071
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.22961981, -2.38673726]), 'currentState': array([4.01429604, 4.15042064]), 'targetState': array([-0.83866557,  0.34243729]), 'effectorPosition': array([-0.94851648,  0.18603973])}
episode index:2195
target Thresh 1.977678687403202
current state at start:  [ 0.67087841 -2.7179844 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.67087841, -2.7179844 ]), 'currentState': array([0.1824624 , 3.44807929]), 'targetState': array([-0.60822186, -0.80490145]), 'effectorPosition': array([ 0.10057288, -0.28824668])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9534625912967217
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 0.67087841, -2.7179844 ]), 'currentState': array([4.99951247, 4.23833439]), 'targetState': array([-0.60822186, -0.80490145]), 'effectorPosition': array([-0.69938455, -0.77321812])}
episode index:2196
target Thresh 1.9777232854155171
current state at start:  [ 0.88534508 -2.38337595]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.88534508, -2.38337595]), 'currentState': array([1.1891023 , 3.39980936]), 'targetState': array([-0.03784768, -0.02568273]), 'effectorPosition': array([ 0.24932932, -0.0643514 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9534792218878473
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.88534508, -2.38337595]), 'currentState': array([1.57581083, 2.95213136]), 'targetState': array([-0.03784768, -0.02568273]), 'effectorPosition': array([-0.18841722,  0.01694957])}
episode index:2197
target Thresh 1.9777677943209444
current state at start:  [ 3.16269068 -1.95513994]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.16269068, -1.95513994]), 'currentState': array([2.77436701, 4.40343223]), 'targetState': array([0.30069641, 0.94808135]), 'effectorPosition': array([-0.30750703,  1.13899497])}
done in step count: 111
reward sum = 0.3277227574378037
running average episode reward sum: 0.9531945283189437
{'reset': False, 'endBeforeDone': False, 'stepCount': 112, 'initial state': array([ 3.16269068, -1.95513994]), 'currentState': array([0.30009928, 2.21130865]), 'targetState': array([0.30069641, 0.94808135]), 'effectorPosition': array([0.14738848, 0.88490906])}
episode index:2198
target Thresh 1.9778122142975192
current state at start:  [0.3613419  2.53585713]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.3613419 , 2.53585713]), 'currentState': array([6.14452721, 2.59146741]), 'targetState': array([0.760257  , 0.59404797]), 'effectorPosition': array([0.21838246, 0.49738415])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.953211265686693
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.3613419 , 2.53585713]), 'currentState': array([5.68617226, 2.33366135]), 'targetState': array([0.760257  , 0.59404797]), 'effectorPosition': array([0.66192582, 0.42410334])}
episode index:2199
target Thresh 1.9778565455229218
current state at start:  [0.30357111 1.87422365]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.30357111, 1.87422365]), 'currentState': array([0.80357111, 2.34039009]), 'targetState': array([-0.5623549 ,  0.78534692]), 'effectorPosition': array([-0.30585668,  0.71747098])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9532234878386537
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([0.30357111, 1.87422365]), 'currentState': array([1.38862025, 2.0343191 ]), 'targetState': array([-0.5623549 ,  0.78534692]), 'effectorPosition': array([-0.77951233,  0.70580213])}
episode index:2200
target Thresh 1.9779007881744768
current state at start:  [ 1.58721683 -2.06331912]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.58721683, -2.06331912]), 'currentState': array([1.71939715, 4.703787  ]), 'targetState': array([1.07627639, 0.53071047]), 'effectorPosition': array([0.84216164, 1.12852117])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.95324019684009
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.58721683, -2.06331912]), 'currentState': array([1.32431244, 4.5572986 ]), 'targetState': array([1.07627639, 0.53071047]), 'effectorPosition': array([1.16444244, 0.57890848])}
episode index:2201
target Thresh 1.977944942429155
current state at start:  [ 1.78064416 -1.76418558]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.78064416, -1.76418558]), 'currentState': array([1.33690767, 4.38475435]), 'targetState': array([1.08930831, 0.3101802 ]), 'effectorPosition': array([1.07820702, 0.44029632])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9532614319913888
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.78064416, -1.76418558]), 'currentState': array([1.33690767, 4.38475435]), 'targetState': array([1.08930831, 0.3101802 ]), 'effectorPosition': array([1.07820702, 0.44029632])}
episode index:2202
target Thresh 1.9779890084635736
current state at start:  [ 0.51855324 -2.43876815]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.51855324, -2.43876815]), 'currentState': array([0.81968657, 3.40318358]), 'targetState': array([-0.09951735,  0.16869337]), 'effectorPosition': array([ 0.21224905, -0.15162724])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.953278108599654
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.51855324, -2.43876815]), 'currentState': array([1.25427834, 3.04069406]), 'targetState': array([-0.09951735,  0.16869337]), 'effectorPosition': array([-0.0941408 ,  0.03618568])}
episode index:2203
target Thresh 1.9780329864539967
current state at start:  [ 4.14313957 -2.60401963]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.14313957, -2.60401963]), 'currentState': array([4.64313957, 3.88209279]), 'targetState': array([-0.66459901, -0.56693664]), 'effectorPosition': array([-0.69115993, -0.21455885])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.953294770074881
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 4.14313957, -2.60401963]), 'currentState': array([4.93683293, 4.28574963]), 'targetState': array([-0.66459901, -0.56693664]), 'effectorPosition': array([-0.75706377, -0.77409753])}
episode index:2204
target Thresh 1.9780768765763364
current state at start:  [-1.27674647  2.23495373]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.27674647,  2.23495373]), 'currentState': array([5.50643883, 2.59352162]), 'targetState': array([0.06780751, 0.71419699]), 'effectorPosition': array([0.46969211, 0.26893672])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9533069266417405
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.27674647,  2.23495373]), 'currentState': array([0.19500992, 2.61479413]), 'targetState': array([0.06780751, 0.71419699]), 'effectorPosition': array([0.0355845 , 0.51951087])}
episode index:2205
target Thresh 1.9781206790061532
current state at start:  [1.68868155 1.84933303]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.68868155, 1.84933303]), 'currentState': array([2.11104123, 2.32644601]), 'targetState': array([-0.58793293, -0.21254105]), 'effectorPosition': array([-0.7857984 , -0.10486913])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.953328093039455
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.68868155, 1.84933303]), 'currentState': array([2.11104123, 2.32644601]), 'targetState': array([-0.58793293, -0.21254105]), 'effectorPosition': array([-0.7857984 , -0.10486913])}
episode index:2206
target Thresh 1.9781643939186566
current state at start:  [-3.30432216  2.229156  ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.30432216,  2.229156  ]), 'currentState': array([2.47886314, 2.70312448]), 'targetState': array([-0.01100024, -0.02564814]), 'effectorPosition': array([-0.33578737, -0.27647913])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9533447092184131
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.30432216,  2.229156  ]), 'currentState': array([2.05694258, 3.06546642]), 'targetState': array([-0.01100024, -0.02564814]), 'effectorPosition': array([-0.06859442, -0.03297287])}
episode index:2207
target Thresh 1.9782080214887068
current state at start:  [0.52790106 2.05537232]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.52790106, 2.05537232]), 'currentState': array([0.17782588, 2.55537232]), 'targetState': array([0.13195859, 0.51987907]), 'effectorPosition': array([0.06647097, 0.57402649])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9533658393319917
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.52790106, 2.05537232]), 'currentState': array([0.17782588, 2.55537232]), 'targetState': array([0.13195859, 0.51987907]), 'effectorPosition': array([0.06647097, 0.57402649])}
episode index:2208
target Thresh 1.9782515618908139
current state at start:  [ 1.06332569 -2.80347031]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.06332569, -2.80347031]), 'currentState': array([0.81908308, 3.96234057]), 'targetState': array([ 0.49776146, -0.47389011]), 'effectorPosition': array([ 0.75187117, -0.26709807])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9529342567881565
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([ 1.06332569, -2.80347031]), 'currentState': array([5.07296598, 4.22351551]), 'targetState': array([ 0.49776146, -0.47389011]), 'effectorPosition': array([-0.6389671 , -0.80774861])}
episode index:2209
target Thresh 1.9782950152991394
current state at start:  [0.02654774 2.92958582]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.02654774, 2.92958582]), 'currentState': array([5.80973305, 3.40417335]), 'targetState': array([-0.4759117 , -0.67236994]), 'effectorPosition': array([-0.08784936, -0.24664927])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.952951028617664
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.02654774, 2.92958582]), 'currentState': array([5.30973305, 3.86678532]), 'targetState': array([-0.4759117 , -0.67236994]), 'effectorPosition': array([-0.40689309, -0.58111508])}
episode index:2210
target Thresh 1.978338381887497
current state at start:  [ 0.62444726 -2.73883569]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.62444726, -2.73883569]), 'currentState': array([0.82490613, 3.12077759]), 'targetState': array([0.50377329, 0.31375417]), 'effectorPosition': array([-0.01514022,  0.01428373])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9525200240818803
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([ 0.62444726, -2.73883569]), 'currentState': array([4.44660279, 2.77249315]), 'targetState': array([0.50377329, 0.31375417]), 'effectorPosition': array([ 0.33041755, -0.1597468 ])}
episode index:2211
target Thresh 1.9783816618293537
current state at start:  [ 1.04137068 -2.0705793 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.04137068, -2.0705793 ]), 'currentState': array([1.31162624, 3.84528716]), 'targetState': array([0.58432359, 0.06822493]), 'effectorPosition': array([0.68630701, 0.06378772])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9525414888087872
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.04137068, -2.0705793 ]), 'currentState': array([1.31162624, 3.84528716]), 'targetState': array([0.58432359, 0.06822493]), 'effectorPosition': array([0.68630701, 0.06378772])}
episode index:2212
target Thresh 1.9784248552978287
current state at start:  [ 0.89163072 -2.08016184]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.89163072, -2.08016184]), 'currentState': array([1.39163072, 3.70302346]), 'targetState': array([0.13840651, 0.40379996]), 'effectorPosition': array([0.55123173, 0.05617069])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.952553941818815
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 0.89163072, -2.08016184]), 'currentState': array([2.37371273, 3.716986  ]), 'targetState': array([0.13840651, 0.40379996]), 'effectorPosition': array([0.26214667, 0.50331151])}
episode index:2213
target Thresh 1.9784679624656962
current state at start:  [-1.65530835  2.09464605]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.65530835,  2.09464605]), 'currentState': array([4.25655206, 2.44482092]), 'targetState': array([ 0.10086171, -0.02236688]), 'effectorPosition': array([ 0.4736125 , -0.49178795])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9525619567502428
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-1.65530835,  2.09464605]), 'currentState': array([4.12706479, 2.81208356]), 'targetState': array([ 0.10086171, -0.02236688]), 'effectorPosition': array([ 0.23999128, -0.22361032])}
episode index:2214
target Thresh 1.9785109835053847
current state at start:  [ 1.36867016 -1.70108897]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.36867016, -1.70108897]), 'currentState': array([1.00221958, 4.13418513]), 'targetState': array([ 0.53471441, -0.07823282]), 'effectorPosition': array([ 0.94985714, -0.06877597])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9525788588013713
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.36867016, -1.70108897]), 'currentState': array([1.10976692, 3.85291716]), 'targetState': array([ 0.53471441, -0.07823282]), 'effectorPosition': array([ 0.69256015, -0.07324435])}
episode index:2215
target Thresh 1.9785539185889787
current state at start:  [-0.04178017  2.29405348]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.04178017,  2.29405348]), 'currentState': array([0.45527643, 2.05019134]), 'targetState': array([0.52427711, 0.97284874]), 'effectorPosition': array([0.09373558, 1.03379335])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.952595745597941
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.04178017,  2.29405348]), 'currentState': array([0.07734829, 2.16238675]), 'targetState': array([0.52427711, 0.97284874]), 'effectorPosition': array([0.37685633, 0.86175146])}
episode index:2216
target Thresh 1.9785967678882184
current state at start:  [-1.71613166  2.47440075]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.71613166,  2.47440075]), 'currentState': array([4.43050653, 2.89885189]), 'targetState': array([-0.04484574,  0.51932267]), 'effectorPosition': array([ 0.22272263, -0.09502078])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9521660677695252
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([-1.71613166,  2.47440075]), 'currentState': array([4.02807869, 3.5326887 ]), 'targetState': array([-0.04484574,  0.51932267]), 'effectorPosition': array([-0.34310796,  0.18246458])}
episode index:2217
target Thresh 1.9786395315745011
current state at start:  [-4.25275975  2.42467784]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.25275975,  2.42467784]), 'currentState': array([1.73536188, 2.92467784]), 'targetState': array([ 0.27995551, -0.00812564]), 'effectorPosition': array([-0.21614913, -0.01214047])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.952183125448619
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-4.25275975,  2.42467784]), 'currentState': array([1.88235925, 3.33361505]), 'targetState': array([ 0.27995551, -0.00812564]), 'effectorPosition': array([0.17602218, 0.07599759])}
episode index:2218
target Thresh 1.9786822098188817
current state at start:  [-2.9715354   3.10628299]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.9715354 ,  3.10628299]), 'currentState': array([3.09615465, 3.51428039]), 'targetState': array([-0.26286165,  0.69333646]), 'effectorPosition': array([-0.0520379 ,  0.36686231])}
done in step count: 73
reward sum = 0.4801414565714212
running average episode reward sum: 0.9519703982431763
{'reset': False, 'endBeforeDone': False, 'stepCount': 74, 'initial state': array([-2.9715354 ,  3.10628299]), 'currentState': array([3.41106886, 3.83861948]), 'targetState': array([-0.26286165,  0.69333646]), 'effectorPosition': array([-0.39572981,  0.55667726])}
episode index:2219
target Thresh 1.978724802792073
current state at start:  [ 2.69106101 -2.60691753]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.69106101, -2.60691753]), 'currentState': array([3.10132383, 3.17626778]), 'targetState': array([0.54607797, 0.0220896 ]), 'effectorPosition': array([0.00079503, 0.03466427])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9515415827484722
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([ 2.69106101, -2.60691753]), 'currentState': array([4.27608866, 2.51809886]), 'targetState': array([0.54607797, 0.0220896 ]), 'effectorPosition': array([ 0.44966554, -0.41726963])}
episode index:2220
target Thresh 1.9787673106644472
current state at start:  [-2.064994    2.13722168]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.064994  ,  2.13722168]), 'currentState': array([4.45051779, 1.82537742]), 'targetState': array([ 0.88860082, -0.38704256]), 'effectorPosition': array([ 0.74108502, -0.97319727])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9511131534000938
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([-2.064994  ,  2.13722168]), 'currentState': array([4.09236927, 2.09967574]), 'targetState': array([ 0.88860082, -0.38704256]), 'effectorPosition': array([ 0.41479839, -0.90488118])}
episode index:2221
target Thresh 1.9788097336060357
current state at start:  [-1.24729776 -1.57748988]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.24729776, -1.57748988]), 'currentState': array([4.53588754, 4.29619421]), 'targetState': array([-0.74203871, -0.33170834]), 'effectorPosition': array([-1.00502404, -0.42586463])}
done in step count: 152
reward sum = 0.21704489667280757
running average episode reward sum: 0.9507827896481913
{'reset': False, 'endBeforeDone': False, 'stepCount': 153, 'initial state': array([-1.24729776, -1.57748988]), 'currentState': array([4.46044142, 4.0264669 ]), 'targetState': array([-0.74203871, -0.33170834]), 'effectorPosition': array([-0.84079758, -0.16212894])}
episode index:2222
target Thresh 1.9788520717865303
current state at start:  [-3.29872469  2.07159286]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.29872469,  2.07159286]), 'currentState': array([2.48446062, 1.67107361]), 'targetState': array([-0.78082443, -0.08944344]), 'effectorPosition': array([-1.32026613, -0.23807297])}
done in step count: 14
reward sum = 0.8687458127689782
running average episode reward sum: 0.9507458859248987
{'reset': False, 'endBeforeDone': False, 'stepCount': 15, 'initial state': array([-3.29872469,  2.07159286]), 'currentState': array([1.99186176, 2.16873425]), 'targetState': array([-0.78082443, -0.08944344]), 'effectorPosition': array([-0.932948  ,  0.06106799])}
episode index:2223
target Thresh 1.978894325375284
current state at start:  [-2.83501639  2.68350455]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.83501639,  2.68350455]), 'currentState': array([3.81513489, 2.66913279]), 'targetState': array([ 0.09921931, -0.29428684]), 'effectorPosition': array([ 0.1982339 , -0.42402855])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9507680325589253
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.83501639,  2.68350455]), 'currentState': array([3.81513489, 2.66913279]), 'targetState': array([ 0.09921931, -0.29428684]), 'effectorPosition': array([ 0.1982339 , -0.42402855])}
episode index:2224
target Thresh 1.978936494541311
current state at start:  [ 0.33688666 -2.67355889]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.33688666, -2.67355889]), 'currentState': array([6.14349078, 4.10828665]), 'targetState': array([ 0.63466016, -0.86408599]), 'effectorPosition': array([ 0.31317167, -0.87514369])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9503407210836179
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([ 0.33688666, -2.67355889]), 'currentState': array([4.78612359, 4.82465048]), 'targetState': array([ 0.63466016, -0.86408599]), 'effectorPosition': array([-0.90908472, -1.18220839])}
episode index:2225
target Thresh 1.9789785794532881
current state at start:  [-2.68344211  2.82278426]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.68344211,  2.82278426]), 'currentState': array([3.09974319, 2.73043484]), 'targetState': array([-0.7231623 , -0.14752239]), 'effectorPosition': array([-0.09998947, -0.39583421])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9503453281316485
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([-2.68344211,  2.82278426]), 'currentState': array([1.99942941, 2.27331537]), 'targetState': array([-0.7231623 , -0.14752239]), 'effectorPosition': array([-0.84124546,  0.00463157])}
episode index:2226
target Thresh 1.979020580279555
current state at start:  [-0.10810703 -2.31187573]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.10810703, -2.31187573]), 'currentState': array([5.70829606, 3.47130958]), 'targetState': array([0.20466456, 0.16898567]), 'effectorPosition': array([-0.13084298, -0.30101835])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9503631344504039
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.10810703, -2.31187573]), 'currentState': array([5.25785241, 3.10942624]), 'targetState': array([0.20466456, 0.16898567]), 'effectorPosition': array([0.02776229, 0.01624329])}
episode index:2227
target Thresh 1.979062497188115
current state at start:  [-0.870331    2.63187838]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.870331  ,  2.63187838]), 'currentState': array([4.95393011, 2.96062795]), 'targetState': array([ 0.24565524, -0.29682963]), 'effectorPosition': array([0.17865992, 0.02719532])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9503764813379936
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-0.870331  ,  2.63187838]), 'currentState': array([4.52110931, 2.65254204]), 'targetState': array([ 0.24565524, -0.29682963]), 'effectorPosition': array([ 0.43893443, -0.20439676])}
episode index:2228
target Thresh 1.979104330346636
current state at start:  [-0.49782476  2.89189454]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.49782476,  2.89189454]), 'currentState': array([5.37365017, 3.19060879]), 'targetState': array([-0.372168  ,  0.01228771]), 'effectorPosition': array([-0.03793137, -0.03103727])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9503942577034766
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.49782476,  2.89189454]), 'currentState': array([4.95752836, 3.37247788]), 'targetState': array([-0.372168  ,  0.01228771]), 'effectorPosition': array([-0.21555784, -0.08127985])}
episode index:2229
target Thresh 1.9791460799224503
current state at start:  [-1.22850429 -2.26579747]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.22850429, -2.26579747]), 'currentState': array([4.6415631 , 3.55140549]), 'targetState': array([-0.48970086,  0.27795478]), 'effectorPosition': array([-0.40329855, -0.05440088])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9504075786641478
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.22850429, -2.26579747]), 'currentState': array([3.8464428 , 3.92275864]), 'targetState': array([-0.48970086,  0.27795478]), 'effectorPosition': array([-0.67702998,  0.34848862])}
episode index:2230
target Thresh 1.9791877460825567
current state at start:  [-2.92370379  1.73198218]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.92370379,  1.73198218]), 'currentState': array([2.92493806, 1.72890878]), 'targetState': array([-0.93595393, -0.21276066]), 'effectorPosition': array([-1.03513076, -0.78332326])}
done in step count: 19
reward sum = 0.8261686238355866
running average episode reward sum: 0.950351891100352
{'reset': False, 'endBeforeDone': False, 'stepCount': 20, 'initial state': array([-2.92370379,  1.73198218]), 'currentState': array([2.24509946, 1.94790118]), 'targetState': array([-0.93595393, -0.21276066]), 'effectorPosition': array([-1.12070235, -0.0869807 ])}
episode index:2231
target Thresh 1.9792293289936196
current state at start:  [-1.7785279  -2.28155952]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.7785279 , -2.28155952]), 'currentState': array([4.93896298, 4.4728796 ]), 'targetState': array([-0.95550442, -0.95713349]), 'effectorPosition': array([-0.77527592, -0.96150672])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9503741348767407
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.7785279 , -2.28155952]), 'currentState': array([4.93896298, 4.4728796 ]), 'targetState': array([-0.95550442, -0.95713349]), 'effectorPosition': array([-0.77527592, -0.96150672])}
episode index:2232
target Thresh 1.9792708288219707
current state at start:  [-2.05614996 -1.85975877]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.05614996, -1.85975877]), 'currentState': array([4.10578194, 4.23386052]), 'targetState': array([-0.59167522, -0.27867129]), 'effectorPosition': array([-1.03687601,  0.06277966])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9499485306963212
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([-2.05614996, -1.85975877]), 'currentState': array([4.29185384, 4.1817296 ]), 'targetState': array([-0.59167522, -0.27867129]), 'effectorPosition': array([-0.98896006, -0.09876085])}
episode index:2233
target Thresh 1.9793122457336094
current state at start:  [-1.04920886  2.28688299]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.04920886,  2.28688299]), 'currentState': array([5.72308912, 1.96493661]), 'targetState': array([0.86636528, 0.71602618]), 'effectorPosition': array([1.0123992, 0.4549932])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.949966458838355
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.04920886,  2.28688299]), 'currentState': array([6.21856137, 1.6901558 ]), 'targetState': array([0.86636528, 0.71602618]), 'effectorPosition': array([0.94320439, 0.93392342])}
episode index:2234
target Thresh 1.9793535798942035
current state at start:  [ 2.75690238 -2.08221384]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.75690238, -2.08221384]), 'currentState': array([3.13148843, 4.49000178]), 'targetState': array([0.50068198, 0.85771858]), 'effectorPosition': array([-0.76954633,  0.98319944])}
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.9499420166886549
{'reset': False, 'endBeforeDone': False, 'stepCount': 12, 'initial state': array([ 2.75690238, -2.08221384]), 'currentState': array([0.02270288, 2.20974879]), 'targetState': array([0.50068198, 0.85771858]), 'effectorPosition': array([0.38531858, 0.81167716])}
episode index:2235
target Thresh 1.9793948314690897
current state at start:  [-1.22837753  2.10208491]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.22837753,  2.10208491]), 'currentState': array([4.66036516, 2.31569427]), 'targetState': array([0.27900938, 0.01454774]), 'effectorPosition': array([ 0.71741299, -0.35989586])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9499511208851269
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-1.22837753,  2.10208491]), 'currentState': array([4.30830518, 2.79844898]), 'targetState': array([0.27900938, 0.01454774]), 'effectorPosition': array([ 0.286431  , -0.18588709])}
episode index:2236
target Thresh 1.9794360006232743
current state at start:  [ 3.17444543 -2.57998226]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.17444543, -2.57998226]), 'currentState': array([3.44135962, 3.73615995]), 'targetState': array([-0.19698307,  0.5681066 ]), 'effectorPosition': array([-0.32936724,  0.48449491])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9499734940988572
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.17444543, -2.57998226]), 'currentState': array([3.44135962, 3.73615995]), 'targetState': array([-0.19698307,  0.5681066 ]), 'effectorPosition': array([-0.32936724,  0.48449491])}
episode index:2237
target Thresh 1.979477087521434
current state at start:  [-0.71867336 -1.61587057]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.71867336, -1.61587057]), 'currentState': array([5.06906297, 4.38625592]), 'targetState': array([-0.67480847, -1.17851796]), 'effectorPosition': array([-0.65037417, -0.9675995 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9499958473186523
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.71867336, -1.61587057]), 'currentState': array([5.06906297, 4.38625592]), 'targetState': array([-0.67480847, -1.17851796]), 'effectorPosition': array([-0.65037417, -0.9675995 ])}
episode index:2238
target Thresh 1.9795180923279163
current state at start:  [-0.26376667 -1.95094035]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.26376667, -1.95094035]), 'currentState': array([5.55787102, 3.83876032]), 'targetState': array([-0.25489141, -0.12296614]), 'effectorPosition': array([-0.25131294, -0.63522775])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9500137142917121
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.26376667, -1.95094035]), 'currentState': array([5.07764936, 3.52528575]), 'targetState': array([-0.25489141, -0.12296614]), 'effectorPosition': array([-0.32368015, -0.20162897])}
episode index:2239
target Thresh 1.9795590152067408
current state at start:  [0.02370545 2.38519247]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.02370545, 2.38519247]), 'currentState': array([5.87322164, 2.88519247]), 'targetState': array([0.19536678, 0.11463745]), 'effectorPosition': array([0.13106083, 0.21955579])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.950036029597832
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.02370545, 2.38519247]), 'currentState': array([5.87322164, 2.88519247]), 'targetState': array([0.19536678, 0.11463745]), 'effectorPosition': array([0.13106083, 0.21955579])}
episode index:2240
target Thresh 1.9795998563215986
current state at start:  [ 3.64439882 -2.05228344]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.64439882, -2.05228344]), 'currentState': array([4.14439882, 3.78129542]), 'targetState': array([-0.05251516, -0.14804199]), 'effectorPosition': array([-0.60959003,  0.1544459 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.950053862694843
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.64439882, -2.05228344]), 'currentState': array([4.64439882, 3.38932213]), 'targetState': array([-0.05251516, -0.14804199]), 'effectorPosition': array([-0.24671089, -0.01379923])}
episode index:2241
target Thresh 1.9796406158358548
current state at start:  [-3.98078261  1.87153969]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.98078261,  1.87153969]), 'currentState': array([2.8024027 , 2.31221468]), 'targetState': array([-0.28518017, -0.97724883]), 'effectorPosition': array([-0.55155463, -0.58746762])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9500716798836498
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.98078261,  1.87153969]), 'currentState': array([3.26575907, 2.09270632]), 'targetState': array([-0.28518017, -0.97724883]), 'effectorPosition': array([-0.390243  , -0.92229978])}
episode index:2242
target Thresh 1.979681293912547
current state at start:  [ 0.03563241 -2.31933256]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.03563241, -2.31933256]), 'currentState': array([5.88296897, 3.46385275]), 'targetState': array([-0.06209771,  0.10295685]), 'effectorPosition': array([-0.07598622, -0.31174028])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9500894811855296
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.03563241, -2.31933256]), 'currentState': array([5.4276617 , 3.12480701]), 'targetState': array([-0.06209771,  0.10295685]), 'effectorPosition': array([0.01276352, 0.01090155])}
episode index:2243
target Thresh 1.9797218907143879
current state at start:  [-3.77666704  2.58590089]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.77666704,  2.58590089]), 'currentState': array([2.0196261 , 2.08590089]), 'targetState': array([-1.03027448,  0.01339021]), 'effectorPosition': array([-1.00420409,  0.07951385])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9501117229497071
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.77666704,  2.58590089]), 'currentState': array([2.0196261 , 2.08590089]), 'targetState': array([-1.03027448,  0.01339021]), 'effectorPosition': array([-1.00420409,  0.07951385])}
episode index:2244
target Thresh 1.9797624064037644
current state at start:  [ 0.50357957 -1.86012002]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.50357957, -1.86012002]), 'currentState': array([0.0160958 , 4.29503495]), 'targetState': array([ 0.40409503, -0.68412528]), 'effectorPosition': array([ 0.60929353, -0.90447518])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9496885106009545
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([ 0.50357957, -1.86012002]), 'currentState': array([4.71102713, 4.84971808]), 'targetState': array([ 0.40409503, -0.68412528]), 'effectorPosition': array([-0.99213253, -1.13554777])}
episode index:2245
target Thresh 1.9798028411427397
current state at start:  [ 1.66002433 -2.17512105]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.66002433, -2.17512105]), 'currentState': array([1.16002433, 3.7560712 ]), 'targetState': array([ 0.4060058 , -0.08014712]), 'effectorPosition': array([ 0.60161785, -0.06251064])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9497109110859941
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.66002433, -2.17512105]), 'currentState': array([1.16002433, 3.7560712 ]), 'targetState': array([ 0.4060058 , -0.08014712]), 'effectorPosition': array([ 0.60161785, -0.06251064])}
episode index:2246
target Thresh 1.9798431950930526
current state at start:  [1.63620904 2.33649758]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.63620904, 2.33649758]), 'currentState': array([2.00106239, 2.34233544]), 'targetState': array([-0.84561608, -0.55013251]), 'effectorPosition': array([-0.7777873 , -0.02383688])}
done in step count: 37
reward sum = 0.6894490858690777
running average episode reward sum: 0.9495950847285322
{'reset': False, 'endBeforeDone': False, 'stepCount': 38, 'initial state': array([1.63620904, 2.33649758]), 'currentState': array([2.59869447, 1.902334  ]), 'targetState': array([-0.84561608, -0.55013251]), 'effectorPosition': array([-1.06600535, -0.46112677])}
episode index:2247
target Thresh 1.9798834684161188
current state at start:  [-1.13442002 -2.60425457]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.13442002, -2.60425457]), 'currentState': array([4.71248903, 3.92805896]), 'targetState': array([-0.11873827, -0.01228357]), 'effectorPosition': array([-0.70783229, -0.29371974])}
done in step count: 28
reward sum = 0.7547192872036326
running average episode reward sum: 0.9495083962065014
{'reset': False, 'endBeforeDone': False, 'stepCount': 29, 'initial state': array([-1.13442002, -2.60425457]), 'currentState': array([4.66497656, 3.45879115]), 'targetState': array([-0.11873827, -0.01228357]), 'effectorPosition': array([-0.31391992, -0.03504831])}
episode index:2248
target Thresh 1.9799236612730322
current state at start:  [ 0.83203506 -1.78387872]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.83203506, -1.78387872]), 'currentState': array([1.10700422, 3.99930659]), 'targetState': array([0.46569372, 0.2962706 ]), 'effectorPosition': array([ 0.83115565, -0.02904835])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9495264004767519
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.83203506, -1.78387872]), 'currentState': array([1.50388297, 3.61428935]), 'targetState': array([0.46569372, 0.2962706 ]), 'effectorPosition': array([0.46160204, 0.07896867])}
episode index:2249
target Thresh 1.9799637738245637
current state at start:  [ 2.25160136 -2.2411481 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.25160136, -2.2411481 ]), 'currentState': array([2.75160136, 4.44279109]), 'targetState': array([-0.04935752,  1.04057887]), 'effectorPosition': array([-0.31212012,  1.1704244 ])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9491043887432067
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([ 2.25160136, -2.2411481 ]), 'currentState': array([0.91123387, 1.94346501]), 'targetState': array([-0.04935752,  1.04057887]), 'effectorPosition': array([-0.34635634,  1.07323475])}
episode index:2250
target Thresh 1.9800038062311638
current state at start:  [-1.02420301 -2.63341747]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.02420301, -2.63341747]), 'currentState': array([4.7589823 , 3.47581194]), 'targetState': array([-0.83484093,  0.37045635]), 'effectorPosition': array([-0.32509852, -0.07055181])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9491181584505621
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.02420301, -2.63341747]), 'currentState': array([3.77484   , 4.28227005]), 'targetState': array([-0.83484093,  0.37045635]), 'effectorPosition': array([-1.0078445 ,  0.38767467])}
episode index:2251
target Thresh 1.9800437586529622
current state at start:  [0.34219558 2.82183877]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.34219558, 2.82183877]), 'currentState': array([6.26155738, 3.18238226]), 'targetState': array([-0.12768323,  0.25550373]), 'effectorPosition': array([-5.02952237e-05, -4.07867456e-02])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.9491105861545837
{'reset': False, 'endBeforeDone': False, 'stepCount': 8, 'initial state': array([0.34219558, 2.82183877]), 'currentState': array([4.22567675, 3.47600784]), 'targetState': array([-0.12768323,  0.25550373]), 'effectorPosition': array([-0.31601346,  0.10454981])}
episode index:2252
target Thresh 1.9800836312497687
current state at start:  [-0.0450812  -2.62924074]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.0450812 , -2.62924074]), 'currentState': array([5.73810411, 3.76797201]), 'targetState': array([ 0.37642132, -0.30602484]), 'effectorPosition': array([-0.14161193, -0.59969615])}
done in step count: 91
reward sum = 0.40068465295154054
running average episode reward sum: 0.9488671658557807
{'reset': False, 'endBeforeDone': False, 'stepCount': 92, 'initial state': array([-0.0450812 , -2.62924074]), 'currentState': array([4.33393789, 2.52248543]), 'targetState': array([ 0.37642132, -0.30602484]), 'effectorPosition': array([ 0.47066762, -0.38688274])}
episode index:2253
target Thresh 1.9801234241810735
current state at start:  [ 2.14553963 -2.74837761]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.14553963, -2.74837761]), 'currentState': array([2.5824533 , 3.39268045]), 'targetState': array([-0.70744348,  0.68502514]), 'effectorPosition': array([0.10521419, 0.22725433])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9488723694246112
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([ 2.14553963, -2.74837761]), 'currentState': array([3.3093745 , 4.05339258]), 'targetState': array([-0.70744348,  0.68502514]), 'effectorPosition': array([-0.51426043,  0.71476485])}
episode index:2254
target Thresh 1.9801631376060487
current state at start:  [-0.49273283  2.2209051 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.49273283,  2.2209051 ]), 'currentState': array([6.15106937, 2.36707146]), 'targetState': array([-0.10202809,  0.44160912]), 'effectorPosition': array([0.37488811, 0.6557034 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9488906078417177
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.49273283,  2.2209051 ]), 'currentState': array([0.0586889 , 2.67763299]), 'targetState': array([-0.10202809,  0.44160912]), 'effectorPosition': array([0.07928262, 0.45292282])}
episode index:2255
target Thresh 1.9802027716835475
current state at start:  [ 1.74285438 -2.42418834]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.74285438, -2.42418834]), 'currentState': array([2.09043523, 3.35899697]), 'targetState': array([-0.35199775,  0.27951735]), 'effectorPosition': array([0.17553474, 0.1275395 ])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9488957964065041
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([ 1.74285438, -2.42418834]), 'currentState': array([1.14606991, 2.54808665]), 'targetState': array([-0.35199775,  0.27951735]), 'effectorPosition': array([-0.43911007,  0.3862802 ])}
episode index:2256
target Thresh 1.980242326572107
current state at start:  [ 3.26176083 -2.05027672]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.26176083, -2.05027672]), 'currentState': array([3.05958189, 4.34613579]), 'targetState': array([-0.77940543,  0.92071364]), 'effectorPosition': array([-0.56323734,  0.98311973])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9489184389424339
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.26176083, -2.05027672]), 'currentState': array([3.05958189, 4.34613579]), 'targetState': array([-0.77940543,  0.92071364]), 'effectorPosition': array([-0.56323734,  0.98311973])}
episode index:2257
target Thresh 1.9802818024299462
current state at start:  [ 3.93002897 -2.56515551]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.93002897, -2.56515551]), 'currentState': array([4.35864871, 3.32897362]), 'targetState': array([-0.35986524, -0.10147622]), 'effectorPosition': array([-0.18081589,  0.04811056])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9489410614229731
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.93002897, -2.56515551]), 'currentState': array([4.35864871, 3.32897362]), 'targetState': array([-0.35986524, -0.10147622]), 'effectorPosition': array([-0.18081589,  0.04811056])}
episode index:2258
target Thresh 1.980321199414969
current state at start:  [1.87956089 1.62733134]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.87956089, 1.62733134]), 'currentState': array([1.37956089, 2.07241555]), 'targetState': array([-0.29136215,  0.46040489]), 'effectorPosition': array([-0.76214447,  0.67634606])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9489592371372612
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.87956089, 1.62733134]), 'currentState': array([1.09013888, 2.43601387]), 'targetState': array([-0.29136215,  0.46040489]), 'effectorPosition': array([-0.46460133,  0.51153974])}
episode index:2259
target Thresh 1.9803605176847632
current state at start:  [1.67349016 2.08238818]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.67349016, 2.08238818]), 'currentState': array([1.31182095, 2.1392129 ]), 'targetState': array([-0.56069818,  0.32656219]), 'effectorPosition': array([-0.69641366,  0.66212646])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9489773967668463
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.67349016, 2.08238818]), 'currentState': array([1.47316737, 2.39656564]), 'targetState': array([-0.56069818,  0.32656219]), 'effectorPosition': array([-0.64893931,  0.32975536])}
episode index:2260
target Thresh 1.980399757396602
current state at start:  [-3.16234177  2.54115658]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.16234177,  2.54115658]), 'currentState': array([3.54714597, 2.05727364]), 'targetState': array([-0.43264669, -1.02186663]), 'effectorPosition': array([-0.14053599, -1.02236004])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9489955403330705
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.16234177,  2.54115658]), 'currentState': array([3.24624646, 1.99253979]), 'targetState': array([-0.43264669, -1.02186663]), 'effectorPosition': array([-0.49210718, -0.96908565])}
episode index:2261
target Thresh 1.9804389187074443
current state at start:  [ 3.46232476 -1.76818939]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.46232476, -1.76818939]), 'currentState': array([3.92762306, 4.04690282]), 'targetState': array([-0.38352012, -0.12534807]), 'effectorPosition': array([-0.8269121 ,  0.28518964])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.949013667857238
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.46232476, -1.76818939]), 'currentState': array([4.41006705, 3.60701828]), 'targetState': array([-0.38352012, -0.12534807]), 'effectorPosition': array([-0.46011912,  0.03208032])}
episode index:2262
target Thresh 1.9804780017739352
current state at start:  [-3.96636793  2.6939581 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.96636793,  2.6939581 ]), 'currentState': array([1.81681738, 2.2222262 ]), 'targetState': array([-0.70807324, -0.1243661 ]), 'effectorPosition': array([-0.86715147,  0.18814932])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9490187859934035
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([-3.96636793,  2.6939581 ]), 'currentState': array([2.10817096, 2.15720053]), 'targetState': array([-0.70807324, -0.1243661 ]), 'effectorPosition': array([-0.94416043, -0.04268487])}
episode index:2263
target Thresh 1.9805170067524072
current state at start:  [-0.54312805  1.73575579]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.54312805,  1.73575579]), 'currentState': array([6.15538102, 1.6672028 ]), 'targetState': array([0.35291856, 0.44103665]), 'effectorPosition': array([1.0232368 , 0.87205049])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9490281853812156
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-0.54312805,  1.73575579]), 'currentState': array([5.92357415, 2.33461392]), 'targetState': array([0.35291856, 0.44103665]), 'effectorPosition': array([0.54274446, 0.5675045 ])}
episode index:2264
target Thresh 1.98055593379888
current state at start:  [0.99047475 2.55833935]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.99047475, 2.55833935]), 'currentState': array([0.50457357, 2.30160269]), 'targetState': array([0.61560181, 0.69385134]), 'effectorPosition': array([-0.06889263,  0.81259659])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9490419036216655
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([0.99047475, 2.55833935]), 'currentState': array([5.92568561, 2.32954169]), 'targetState': array([0.61560181, 0.69385134]), 'effectorPosition': array([0.54620931, 0.57064208])}
episode index:2265
target Thresh 1.9805947830690624
current state at start:  [0.83972815 3.00355787]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.83972815, 3.00355787]), 'currentState': array([0.50940717, 3.17064261]), 'targetState': array([-0.01082515, -0.01734355]), 'effectorPosition': array([ 0.01453285, -0.02515227])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9490643917489286
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.83972815, 3.00355787]), 'currentState': array([0.50940717, 3.17064261]), 'targetState': array([-0.01082515, -0.01734355]), 'effectorPosition': array([ 0.01453285, -0.02515227])}
episode index:2266
target Thresh 1.9806335547183511
current state at start:  [-2.10747508  2.08638213]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.10747508,  2.08638213]), 'currentState': array([4.47302812, 2.09314318]), 'targetState': array([0.7958235, 0.0520989]), 'effectorPosition': array([ 0.7231442 , -0.69226558])}
done in step count: 129
reward sum = 0.2734891510222162
running average episode reward sum: 0.9487663876727369
{'reset': False, 'endBeforeDone': False, 'stepCount': 130, 'initial state': array([-2.10747508,  2.08638213]), 'currentState': array([4.83351764, 2.40284813]), 'targetState': array([0.7958235, 0.0520989]), 'effectorPosition': array([ 0.69992579, -0.17741148])}
episode index:2267
target Thresh 1.980672248901833
current state at start:  [ 2.77153991 -2.39935835]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.77153991, -2.39935835]), 'currentState': array([2.98860458, 3.44272529]), 'targetState': array([-0.2192035 ,  0.25368867]), 'effectorPosition': array([0.00072652, 0.29999526])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9487889774488953
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.77153991, -2.39935835]), 'currentState': array([2.98860458, 3.44272529]), 'targetState': array([-0.2192035 ,  0.25368867]), 'effectorPosition': array([0.00072652, 0.29999526])}
episode index:2268
target Thresh 1.9807108657742845
current state at start:  [-3.64036904  2.42042501]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.64036904,  2.42042501]), 'currentState': array([3.14281627, 2.00228666]), 'targetState': array([-0.30976162, -1.31842534]), 'effectorPosition': array([-0.5806631 , -0.90905465])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9488071400855418
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.64036904,  2.42042501]), 'currentState': array([3.64281627, 1.81500761]), 'targetState': array([-0.30976162, -1.31842534]), 'effectorPosition': array([-0.19870384, -1.21529198])}
episode index:2269
target Thresh 1.9807494054901735
current state at start:  [-0.86449659  2.73009308]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.86449659,  2.73009308]), 'currentState': array([5.91868871, 2.59213259]), 'targetState': array([0.06506094, 0.59426074]), 'effectorPosition': array([0.32368618, 0.43544693])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9488252867198653
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.86449659,  2.73009308]), 'currentState': array([0.13550341, 2.69798661]), 'targetState': array([0.06506094, 0.59426074]), 'effectorPosition': array([0.03792279, 0.43834029])}
episode index:2270
target Thresh 1.9807878682036588
current state at start:  [-3.50453631  2.26564147]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.50453631,  2.26564147]), 'currentState': array([2.35977586, 2.67544021]), 'targetState': array([ 0.05851767, -0.03268192]), 'effectorPosition': array([-0.39238578, -0.24377248])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9488434173730048
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.50453631,  2.26564147]), 'currentState': array([2.0577777 , 2.98893099]), 'targetState': array([ 0.05851767, -0.03268192]), 'effectorPosition': array([-0.1398337 , -0.06088427])}
episode index:2271
target Thresh 1.9808262540685913
current state at start:  [-1.22531544  1.98866225]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.22531544,  1.98866225]), 'currentState': array([4.87072953, 2.3130774 ]), 'targetState': array([0.24233912, 0.0641578 ]), 'effectorPosition': array([ 0.77880265, -0.20377714])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9488571746716964
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.22531544,  1.98866225]), 'currentState': array([4.34932055, 2.86079758]), 'targetState': array([0.24233912, 0.0641578 ]), 'effectorPosition': array([ 0.24514557, -0.13502898])}
episode index:2272
target Thresh 1.9808645632385145
current state at start:  [ 1.93561172 -2.20410391]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.93561172, -2.20410391]), 'currentState': array([1.81981906, 3.61880942]), 'targetState': array([0.51046864, 0.13917481]), 'effectorPosition': array([0.41760574, 0.22147684])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9488796748148237
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.93561172, -2.20410391]), 'currentState': array([1.81981906, 3.61880942]), 'targetState': array([0.51046864, 0.13917481]), 'effectorPosition': array([0.41760574, 0.22147684])}
episode index:2273
target Thresh 1.980902795866665
current state at start:  [ 0.59745908 -1.73984739]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.59745908, -1.73984739]), 'currentState': array([0.51459628, 4.52346684]), 'targetState': array([ 1.04269116, -0.17046806]), 'effectorPosition': array([ 1.19043906, -0.45525179])}
done in step count: 44
reward sum = 0.6426116020847181
running average episode reward sum: 0.9487449922850392
{'reset': False, 'endBeforeDone': False, 'stepCount': 45, 'initial state': array([ 0.59745908, -1.73984739]), 'currentState': array([4.91711993, 1.99530393]), 'targetState': array([ 1.04269116, -0.17046806]), 'effectorPosition': array([ 1.01177961, -0.3905864 ])}
episode index:2274
target Thresh 1.9809409521059735
current state at start:  [-0.74364255  2.21124676]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.74364255,  2.21124676]), 'currentState': array([5.05373999, 2.51826683]), 'targetState': array([ 0.00676157, -0.29613425]), 'effectorPosition': array([0.61301348, 0.01820455])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9483279615191995
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([-0.74364255,  2.21124676]), 'currentState': array([4.53837351, 2.80253986]), 'targetState': array([ 0.00676157, -0.29613425]), 'effectorPosition': array([ 0.3177142 , -0.11365493])}
episode index:2275
target Thresh 1.9809790321090652
current state at start:  [ 2.04604383 -1.80667411]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.04604383, -1.80667411]), 'currentState': array([2.47433658, 4.33858733]), 'targetState': array([0.22026594, 0.87305076]), 'effectorPosition': array([0.07741654, 1.12414069])}
done in step count: 25
reward sum = 0.7778213593991467
running average episode reward sum: 0.9482530464919061
{'reset': False, 'endBeforeDone': False, 'stepCount': 26, 'initial state': array([ 2.04604383, -1.80667411]), 'currentState': array([0.50422171, 2.02919224]), 'targetState': array([0.22026594, 0.87305076]), 'effectorPosition': array([0.05486073, 1.05449984])}
episode index:2276
target Thresh 1.98101703602826
current state at start:  [-3.62103135  2.02239913]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.62103135,  2.02239913]), 'currentState': array([2.16215396, 2.42411453]), 'targetState': array([-0.14123584,  0.1383103 ]), 'effectorPosition': array([-0.68327503, -0.16187277])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9482627285092571
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-3.62103135,  2.02239913]), 'currentState': array([1.12625796, 2.71623966]), 'targetState': array([-0.14123584,  0.1383103 ]), 'effectorPosition': array([-0.33421772,  0.25789971])}
episode index:2277
target Thresh 1.9810549640155735
current state at start:  [ 4.45239845 -2.63570455]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.45239845, -2.63570455]), 'currentState': array([3.95239845, 3.35875947]), 'targetState': array([0.4039569 , 0.61265096]), 'effectorPosition': array([-0.17235872,  0.13141096])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9478464586547753
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([ 4.45239845, -2.63570455]), 'currentState': array([3.86404175, 3.28021173]), 'targetState': array([0.4039569 , 0.61265096]), 'effectorPosition': array([-0.09856099,  0.09731511])}
episode index:2278
target Thresh 1.9810928162227177
current state at start:  [1.33782951 1.86080931]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.33782951, 1.86080931]), 'currentState': array([1.83782951, 2.15728552]), 'targetState': array([-1.27752209,  0.09983046]), 'effectorPosition': array([-0.9212037 ,  0.21095755])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9478606111520749
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([1.33782951, 1.86080931]), 'currentState': array([2.07541246, 1.96748473]), 'targetState': array([-1.27752209,  0.09983046]), 'effectorPosition': array([-1.10405902,  0.09122297])}
episode index:2279
target Thresh 1.9811305928011018
current state at start:  [ 3.69321512 -3.06805423]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.69321512, -3.06805423]), 'currentState': array([4.19321512, 2.91785402]), 'targetState': array([0.09195906, 0.03990751]), 'effectorPosition': array([ 0.18027281, -0.13172781])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9478834793050783
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.69321512, -3.06805423]), 'currentState': array([4.19321512, 2.91785402]), 'targetState': array([0.09195906, 0.03990751]), 'effectorPosition': array([ 0.18027281, -0.13172781])}
episode index:2280
target Thresh 1.9811682939018318
current state at start:  [-2.03304523  1.70865552]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.03304523,  1.70865552]), 'currentState': array([4.31772025, 1.67951793]), 'targetState': array([ 0.38326257, -0.60340642]), 'effectorPosition': array([ 0.57489252, -1.20519024])}
done in step count: 23
reward sum = 0.7936142836436554
running average episode reward sum: 0.9478158470404306
{'reset': False, 'endBeforeDone': False, 'stepCount': 24, 'initial state': array([-2.03304523,  1.70865552]), 'currentState': array([4.38868651, 2.30706124]), 'targetState': array([ 0.38326257, -0.60340642]), 'effectorPosition': array([ 0.59801749, -0.54710615])}
episode index:2281
target Thresh 1.9812059196757124
current state at start:  [ 3.80597975 -2.74909241]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.80597975, -2.74909241]), 'currentState': array([3.94986679, 3.81213125]), 'targetState': array([-0.95606229, -0.0857499 ]), 'effectorPosition': array([-0.59889349,  0.27267637])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9478343326464602
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.80597975, -2.74909241]), 'currentState': array([4.31623068, 4.10645797]), 'targetState': array([-0.95606229, -0.0857499 ]), 'effectorPosition': array([-0.92442008, -0.07995221])}
episode index:2282
target Thresh 1.9812434702732464
current state at start:  [ 0.25691115 -2.66253189]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.25691115, -2.66253189]), 'currentState': array([6.04009645, 4.11575078]), 'targetState': array([ 0.01763345, -1.29903833]), 'effectorPosition': array([ 0.22613821, -0.90836786])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9478528020583539
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.25691115, -2.66253189]), 'currentState': array([5.54009645, 4.52793124]), 'targetState': array([ 0.01763345, -1.29903833]), 'effectorPosition': array([-0.06376854, -1.27636459])}
episode index:2283
target Thresh 1.9812809458446368
current state at start:  [ 3.35267454 -2.58635487]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.35267454, -2.58635487]), 'currentState': array([3.02159988, 3.95068618]), 'targetState': array([-1.22400905,  0.31594379]), 'effectorPosition': array([-0.22099139,  0.75554841])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.9478458898630162
{'reset': False, 'endBeforeDone': False, 'stepCount': 8, 'initial state': array([ 3.35267454, -2.58635487]), 'currentState': array([1.90873318, 1.65683383]), 'targetState': array([-1.22400905,  0.31594379]), 'effectorPosition': array([-1.24300249,  0.53205453])}
episode index:2284
target Thresh 1.9813183465397854
current state at start:  [ 0.71798551 -1.84170067]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.71798551, -1.84170067]), 'currentState': array([0.21798551, 3.98351658]), 'targetState': array([ 0.2683874 , -0.17204322]), 'effectorPosition': array([ 0.48738401, -0.65604796])}
done in step count: 58
reward sum = 0.5582661385478637
running average episode reward sum: 0.9476753954423094
{'reset': False, 'endBeforeDone': False, 'stepCount': 59, 'initial state': array([ 0.71798551, -1.84170067]), 'currentState': array([3.88740163, 2.85024772]), 'targetState': array([ 0.2683874 , -0.17204322]), 'effectorPosition': array([ 0.16395723, -0.23958544])}
episode index:2285
target Thresh 1.9813556725082953
current state at start:  [-3.49319878  2.28398081]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.49319878,  2.28398081]), 'currentState': array([2.33424745, 1.86068284]), 'targetState': array([-1.16676077,  0.01346078]), 'effectorPosition': array([-1.18609198, -0.14662495])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9476982845956592
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.49319878,  2.28398081]), 'currentState': array([2.33424745, 1.86068284]), 'targetState': array([-1.16676077,  0.01346078]), 'effectorPosition': array([-1.18609198, -0.14662495])}
episode index:2286
target Thresh 1.9813929238994705
current state at start:  [-3.23171976  1.88026001]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.23171976,  1.88026001]), 'currentState': array([3.55146555, 1.93672422]), 'targetState': array([ 0.05723438, -1.15733798]), 'effectorPosition': array([-0.21688353, -1.11235324])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9477167811918131
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.23171976,  1.88026001]), 'currentState': array([4.0480342 , 1.71954317]), 'targetState': array([ 0.05723438, -1.15733798]), 'effectorPosition': array([ 0.25344186, -1.2803786 ])}
episode index:2287
target Thresh 1.9814301008623163
current state at start:  [-1.51707402  2.52092476]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.51707402,  2.52092476]), 'currentState': array([4.28755998, 2.86202229]), 'targetState': array([ 0.04801411, -0.14257623]), 'effectorPosition': array([ 0.23541127, -0.14910858])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9477396322489846
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.51707402,  2.52092476]), 'currentState': array([4.28755998, 2.86202229]), 'targetState': array([ 0.04801411, -0.14257623]), 'effectorPosition': array([ 0.23541127, -0.14910858])}
episode index:2288
target Thresh 1.981467203545541
current state at start:  [-0.24324264 -2.92644935]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.24324264, -2.92644935]), 'currentState': array([5.53994266, 3.80945254]), 'targetState': array([ 0.23296622, -0.51957184]), 'effectorPosition': array([-0.26088186, -0.60136757])}
done in step count: 155
reward sum = 0.21059844619672852
running average episode reward sum: 0.9474175959073279
{'reset': False, 'endBeforeDone': False, 'stepCount': 156, 'initial state': array([-0.24324264, -2.92644935]), 'currentState': array([4.16896878, 2.35049766]), 'targetState': array([ 0.23296622, -0.51957184]), 'effectorPosition': array([ 0.45514873, -0.62185651])}
episode index:2289
target Thresh 1.9815042320975549
current state at start:  [-0.74350669  1.62293332]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.74350669,  1.62293332]), 'currentState': array([5.05108578, 1.93471977]), 'targetState': array([ 1.06464811, -0.56446313]), 'effectorPosition': array([ 1.09540977, -0.29696892])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9474361908436129
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.74350669,  1.62293332]), 'currentState': array([4.62242372, 2.03966643]), 'targetState': array([ 1.06464811, -0.56446313]), 'effectorPosition': array([ 0.83922634, -0.62605264])}
episode index:2290
target Thresh 1.9815411866664727
current state at start:  [-2.11791038  1.94996696]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.11791038,  1.94996696]), 'currentState': array([4.66527492, 1.78743579]), 'targetState': array([ 1.21745553, -0.32762895]), 'effectorPosition': array([ 0.93856832, -0.83017576])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9474547695468674
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.11791038,  1.94996696]), 'currentState': array([5.06618262, 1.91371149]), 'targetState': array([ 1.21745553, -0.32762895]), 'effectorPosition': array([ 1.11341726, -0.29636817])}
episode index:2291
target Thresh 1.9815780674001127
current state at start:  [ 1.35102293 -2.69312548]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.35102293, -2.69312548]), 'currentState': array([0.96356013, 4.01175375]), 'targetState': array([ 0.40547742, -0.48889525]), 'effectorPosition': array([ 0.83050597, -0.14440573])}
done in step count: 41
reward sum = 0.6622820409839835
running average episode reward sum: 0.9473303486356269
{'reset': False, 'endBeforeDone': False, 'stepCount': 42, 'initial state': array([ 1.35102293, -2.69312548]), 'currentState': array([4.45072997, 2.36365407]), 'targetState': array([ 0.40547742, -0.48889525]), 'effectorPosition': array([ 0.603517 , -0.4593949])}
episode index:2292
target Thresh 1.9816148744459974
current state at start:  [ 0.47565926 -2.606483  ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.47565926, -2.606483  ]), 'currentState': array([0.01522509, 4.13767357]), 'targetState': array([ 0.77666122, -0.80878215]), 'effectorPosition': array([ 0.4691298 , -0.83230123])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9469172084923058
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([ 0.47565926, -2.606483  ]), 'currentState': array([4.78626331, 5.55389219]), 'targetState': array([ 0.77666122, -0.80878215]), 'effectorPosition': array([-0.53568416, -1.79006528])}
episode index:2293
target Thresh 1.9816516079513555
current state at start:  [-1.04578534 -2.07017271]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.04578534, -2.07017271]), 'currentState': array([4.73739997, 3.92357044]), 'targetState': array([-0.02419408, -0.00497891]), 'effectorPosition': array([-0.69719928, -0.30801095])}
done in step count: 32
reward sum = 0.7249803359578534
running average episode reward sum: 0.9468204618172689
{'reset': False, 'endBeforeDone': False, 'stepCount': 33, 'initial state': array([-1.04578534, -2.07017271]), 'currentState': array([4.64475928, 3.41372425]), 'targetState': array([-0.02419408, -0.00497891]), 'effectorPosition': array([-0.27065762, -0.01855172])}
episode index:2294
target Thresh 1.9816882680631211
current state at start:  [-2.46145235  2.47959078]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.46145235,  2.47959078]), 'currentState': array([3.32173295, 2.74005181]), 'targetState': array([-0.71816456, -0.20817326]), 'effectorPosition': array([-0.00822771, -0.3987638 ])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.946834962705366
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-2.46145235,  2.47959078]), 'currentState': array([2.32173295, 2.35223961]), 'targetState': array([-0.71816456, -0.20817326]), 'effectorPosition': array([-0.72073075, -0.26821207])}
episode index:2295
target Thresh 1.9817248549279345
current state at start:  [ 3.00004673 -2.63421201]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.00004673, -2.63421201]), 'currentState': array([3.45037144, 3.15294201]), 'targetState': array([ 0.71753887, -0.2166595 ]), 'effectorPosition': array([-0.0035103 ,  0.01079279])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9468409561928636
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([ 3.00004673, -2.63421201]), 'currentState': array([4.61735595, 2.36690936]), 'targetState': array([ 0.71753887, -0.2166595 ]), 'effectorPosition': array([ 0.66925593, -0.35044442])}
episode index:2296
target Thresh 1.9817613686921431
current state at start:  [-3.86231332  2.02442357]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.86231332,  2.02442357]), 'currentState': array([2.22222964, 2.11458285]), 'targetState': array([-0.33026132, -0.54606265]), 'effectorPosition': array([-0.97313572, -0.13508076])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.946428748549767
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([-3.86231332,  2.02442357]), 'currentState': array([2.45386213, 2.44423259]), 'targetState': array([-0.33026132, -0.54606265]), 'effectorPosition': array([-0.58804845, -0.34802097])}
episode index:2297
target Thresh 1.9817978095018023
current state at start:  [0.16950996 2.39395157]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.16950996, 2.39395157]), 'currentState': array([5.97827352, 2.89395157]), 'targetState': array([-0.26590405, -0.09082089]), 'effectorPosition': array([0.10268604, 0.22465287])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9464477090595363
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.16950996, 2.39395157]), 'currentState': array([5.47827352, 3.39395157]), 'targetState': array([-0.26590405, -0.09082089]), 'effectorPosition': array([-0.15801257, -0.19590759])}
episode index:2298
target Thresh 1.981834177502675
current state at start:  [ 1.55601982 -2.20395768]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.55601982, -2.20395768]), 'currentState': array([1.2646089 , 4.57922762]), 'targetState': array([ 1.24743265, -0.02590137]), 'effectorPosition': array([1.20645444, 0.52813952])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.9464496848493756
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([ 1.55601982, -2.20395768]), 'currentState': array([0.68269848, 4.81265698]), 'targetState': array([ 1.24743265, -0.02590137]), 'effectorPosition': array([ 1.48125834, -0.07793515])}
episode index:2299
target Thresh 1.9818704728402337
current state at start:  [1.44937126 2.58238179]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.44937126, 2.58238179]), 'currentState': array([1.07510696, 2.78577787]), 'targetState': array([-0.03868561,  0.23278313]), 'effectorPosition': array([-0.27663411,  0.22078867])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9464729675950934
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.44937126, 2.58238179]), 'currentState': array([1.07510696, 2.78577787]), 'targetState': array([-0.03868561,  0.23278313]), 'effectorPosition': array([-0.27663411,  0.22078867])}
episode index:2300
target Thresh 1.9819066956596596
current state at start:  [-2.39559162  2.10815002]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.39559162,  2.10815002]), 'currentState': array([3.38759369, 2.11326955]), 'targetState': array([-0.76195469, -0.84997441]), 'effectorPosition': array([-0.26061547, -0.94845566])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9464918841671944
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.39559162,  2.10815002]), 'currentState': array([2.88759369, 2.14183863]), 'targetState': array([-0.76195469, -0.84997441]), 'effectorPosition': array([-0.65615669, -0.69888472])}
episode index:2301
target Thresh 1.981942846105844
current state at start:  [-2.23835669  2.36899179]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.23835669,  2.36899179]), 'currentState': array([3.54482862, 2.83329585]), 'targetState': array([-0.35240397,  0.18174988]), 'effectorPosition': array([ 0.07570063, -0.29760022])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.9464856172096532
{'reset': False, 'endBeforeDone': False, 'stepCount': 8, 'initial state': array([-2.23835669,  2.36899179]), 'currentState': array([1.83763183, 2.83096238]), 'targetState': array([-0.35240397,  0.18174988]), 'effectorPosition': array([-0.30746102, -0.03443102])}
episode index:2302
target Thresh 1.9819789243233885
current state at start:  [ 2.17904815 -2.44933228]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.17904815, -2.44933228]), 'currentState': array([1.7254104 , 3.34985368]), 'targetState': array([-0.3238069 , -0.37902881]), 'effectorPosition': array([0.20096478, 0.0531909 ])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9460746377840302
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([ 2.17904815, -2.44933228]), 'currentState': array([2.07576603, 2.40041761]), 'targetState': array([-0.3238069 , -0.37902881]), 'effectorPosition': array([-0.71779596, -0.09704385])}
episode index:2303
target Thresh 1.9820149304566066
current state at start:  [ 3.46484762 -2.86888241]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.46484762, -2.86888241]), 'currentState': array([3.14712035, 3.91430289]), 'targetState': array([0.86989078, 0.99270563]), 'effectorPosition': array([-0.28783307,  0.69649798])}
done in step count: 84
reward sum = 0.4298890135238935
running average episode reward sum: 0.9458505988846118
{'reset': False, 'endBeforeDone': False, 'stepCount': 85, 'initial state': array([ 3.46484762, -2.86888241]), 'currentState': array([1.58839951, 4.92085778]), 'targetState': array([0.86989078, 0.99270563]), 'effectorPosition': array([0.95695211, 1.22399626])}
episode index:2304
target Thresh 1.9820508646495223
current state at start:  [ 3.08261676 -2.12383759]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.08261676, -2.12383759]), 'currentState': array([3.53251795, 3.69647041]), 'targetState': array([ 0.04622389, -0.07243342]), 'effectorPosition': array([-0.33946506,  0.42992299])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.945869752637807
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.08261676, -2.12383759]), 'currentState': array([4.02206044, 3.22542364]), 'targetState': array([ 0.04622389, -0.07243342]), 'effectorPosition': array([-0.06679735,  0.05061258])}
episode index:2305
target Thresh 1.9820867270458729
current state at start:  [-1.80984292  1.97333545]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.80984292,  1.97333545]), 'currentState': array([4.05113509, 1.87889747]), 'targetState': array([ 0.26687679, -0.99817457]), 'effectorPosition': array([ 0.32418005, -1.13508054])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.945893226292344
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.80984292,  1.97333545]), 'currentState': array([4.05113509, 1.87889747]), 'targetState': array([ 0.26687679, -0.99817457]), 'effectorPosition': array([ 0.32418005, -1.13508054])}
episode index:2306
target Thresh 1.9821225177891075
current state at start:  [-0.09326487 -2.18206669]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.09326487, -2.18206669]), 'currentState': array([5.69893978, 4.35092618]), 'targetState': array([ 0.34191578, -0.89946735]), 'effectorPosition': array([ 0.02321684, -1.13673885])}
done in step count: 194
reward sum = 0.14230748778208857
running average episode reward sum: 0.9455449013081609
{'reset': False, 'endBeforeDone': False, 'stepCount': 195, 'initial state': array([-0.09326487, -2.18206669]), 'currentState': array([4.188831  , 1.88433716]), 'targetState': array([ 0.34191578, -0.89946735]), 'effectorPosition': array([ 0.47806267, -1.07452247])}
episode index:2307
target Thresh 1.9821582370223898
current state at start:  [ 0.98793807 -2.22564364]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.98793807, -2.22564364]), 'currentState': array([0.54437253, 3.72069841]), 'targetState': array([ 0.05400868, -0.86882077]), 'effectorPosition': array([ 0.4229034, -0.383729 ])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9455598731880102
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 0.98793807, -2.22564364]), 'currentState': array([5.8287178 , 3.96969477]), 'targetState': array([ 0.05400868, -0.86882077]), 'effectorPosition': array([-0.03251195, -0.80398562])}
episode index:2308
target Thresh 1.982193884888596
current state at start:  [-0.06601898  2.93418353]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.06601898,  2.93418353]), 'currentState': array([5.71716633, 3.43418353]), 'targetState': array([ 0.63296686, -0.18008816]), 'effectorPosition': array([-0.11880827, -0.26624239])}
done in step count: 14
reward sum = 0.8687458127689782
running average episode reward sum: 0.9455266059465987
{'reset': False, 'endBeforeDone': False, 'stepCount': 15, 'initial state': array([-0.06601898,  2.93418353]), 'currentState': array([4.67229348, 2.47267427]), 'targetState': array([ 0.63296686, -0.18008816]), 'effectorPosition': array([ 0.61100087, -0.24019199])}
episode index:2309
target Thresh 1.9822294615303182
current state at start:  [ 1.17816243 -2.17902742]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.17816243, -2.17902742]), 'currentState': array([0.67816243, 3.68402271]), 'targetState': array([ 0.23052906, -0.3609413 ]), 'effectorPosition': array([ 0.43563758, -0.31193968])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9455501875024659
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.17816243, -2.17902742]), 'currentState': array([0.67816243, 3.68402271]), 'targetState': array([ 0.23052906, -0.3609413 ]), 'effectorPosition': array([ 0.43563758, -0.31193968])}
episode index:2310
target Thresh 1.9822649670898629
current state at start:  [ 3.07277106 -2.0413374 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.07277106, -2.0413374 ]), 'currentState': array([3.54364183, 3.75030196]), 'targetState': array([-0.02973607, -0.02353673]), 'effectorPosition': array([-0.38904281,  0.45593007])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9455694215191243
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.07277106, -2.0413374 ]), 'currentState': array([4.04364183, 3.25030196]), 'targetState': array([-0.02973607, -0.02353673]), 'effectorPosition': array([-0.08878523,  0.06263596])}
episode index:2311
target Thresh 1.9823004017092523
current state at start:  [ 0.68895523 -2.57941826]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.68895523, -2.57941826]), 'currentState': array([0.18895523, 4.14162024]), 'targetState': array([ 0.81636143, -0.98206172]), 'effectorPosition': array([ 0.60959701, -0.74015761])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9451604382053184
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([ 0.68895523, -2.57941826]), 'currentState': array([4.53593132, 6.03719319]), 'targetState': array([ 0.81636143, -0.98206172]), 'effectorPosition': array([-0.58553944, -1.89655898])}
episode index:2312
target Thresh 1.982335765530225
current state at start:  [0.4866528  2.18544661]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.4866528 , 2.18544661]), 'currentState': array([6.2698381 , 2.68544661]), 'targetState': array([0.03654081, 0.01433846]), 'effectorPosition': array([0.10811325, 0.43908762])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9451798240945507
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.4866528 , 2.18544661]), 'currentState': array([5.7698381, 3.1411653]), 'targetState': array([0.03654081, 0.01433846]), 'effectorPosition': array([0.00020995, 0.00037222])}
episode index:2313
target Thresh 1.982371058694236
current state at start:  [0.59904475 2.10054657]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.59904475, 2.10054657]), 'currentState': array([0.19525994, 2.58343208]), 'targetState': array([-0.11915394,  0.06952726]), 'effectorPosition': array([0.0461262 , 0.54900899])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9451991932284769
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.59904475, 2.10054657]), 'currentState': array([6.00017325, 3.08343208]), 'targetState': array([-0.11915394,  0.06952726]), 'effectorPosition': array([0.01785572, 0.05534322])}
episode index:2314
target Thresh 1.9824062813424583
current state at start:  [ 0.5519925  -1.76709123]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.5519925 , -1.76709123]), 'currentState': array([1.00356838, 4.148207  ]), 'targetState': array([1.15593997, 0.47104083]), 'effectorPosition': array([ 0.96268041, -0.06161923])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9452185456288101
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.5519925 , -1.76709123]), 'currentState': array([1.44819852, 4.39089294]), 'targetState': array([1.15593997, 0.47104083]), 'effectorPosition': array([1.02529128, 0.5628545 ])}
episode index:2315
target Thresh 1.9824414336157827
current state at start:  [-1.54999111 -2.88989452]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.54999111, -2.88989452]), 'currentState': array([4.960396  , 3.41790244]), 'targetState': array([ 0.3627364 , -0.11368956]), 'effectorPosition': array([-0.25514926, -0.1037374 ])}
done in step count: 21
reward sum = 0.8097278682212584
running average episode reward sum: 0.945160043609204
{'reset': False, 'endBeforeDone': False, 'stepCount': 22, 'initial state': array([-1.54999111, -2.88989452]), 'currentState': array([1.19923488, 3.43653216]), 'targetState': array([ 0.3627364 , -0.11368956]), 'effectorPosition': array([ 0.28652378, -0.06530441])}
episode index:2316
target Thresh 1.982476515654818
current state at start:  [0.30312518 2.51039667]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.30312518, 2.51039667]), 'currentState': array([6.11158965, 2.88131453]), 'targetState': array([0.93027802, 0.23271725]), 'effectorPosition': array([0.07713053, 0.24781849])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.945158455394181
{'reset': False, 'endBeforeDone': False, 'stepCount': 7, 'initial state': array([0.30312518, 2.51039667]), 'currentState': array([5.20372772, 2.19415258]), 'targetState': array([0.93027802, 0.23271725]), 'effectorPosition': array([0.91225801, 0.01607447])}
episode index:2317
target Thresh 1.9825115275998928
current state at start:  [ 3.13691307 -1.67285664]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.13691307, -1.67285664]), 'currentState': array([3.23614935, 4.60124739]), 'targetState': array([-0.96438621,  0.87446032]), 'effectorPosition': array([-0.97894872,  0.90544662])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9451821143866771
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.13691307, -1.67285664]), 'currentState': array([3.23614935, 4.60124739]), 'targetState': array([-0.96438621,  0.87446032]), 'effectorPosition': array([-0.97894872,  0.90544662])}
episode index:2318
target Thresh 1.9825464695910546
current state at start:  [ 0.22195421 -2.58070667]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.22195421, -2.58070667]), 'currentState': array([6.02444981, 3.20247863]), 'targetState': array([-0.00653947,  0.01751849]), 'effectorPosition': array([-0.01377726, -0.05929709])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9452057529746949
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.22195421, -2.58070667]), 'currentState': array([6.02444981, 3.20247863]), 'targetState': array([-0.00653947,  0.01751849]), 'effectorPosition': array([-0.01377726, -0.05929709])}
episode index:2319
target Thresh 1.9825813417680713
current state at start:  [-0.23130076  1.74688113]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.23130076,  1.74688113]), 'currentState': array([5.83232207, 1.81560606]), 'targetState': array([0.6023309 , 0.38182243]), 'effectorPosition': array([1.10466978, 0.54310332])}
done in step count: 15
reward sum = 0.8600583546412884
running average episode reward sum: 0.945169051509896
{'reset': False, 'endBeforeDone': False, 'stepCount': 16, 'initial state': array([-0.23130076,  1.74688113]), 'currentState': array([5.78871241, 2.17820863]), 'targetState': array([0.6023309 , 0.38182243]), 'effectorPosition': array([0.76751952, 0.51906137])}
episode index:2320
target Thresh 1.982616144270432
current state at start:  [-1.66225363  2.09179841]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.66225363,  2.09179841]), 'currentState': array([4.14049974, 2.49452601]), 'targetState': array([ 0.18027377, -0.41321759]), 'effectorPosition': array([ 0.3975184 , -0.49625389])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.945192675356725
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.66225363,  2.09179841]), 'currentState': array([4.14049974, 2.49452601]), 'targetState': array([ 0.18027377, -0.41321759]), 'effectorPosition': array([ 0.3975184 , -0.49625389])}
episode index:2321
target Thresh 1.9826508772373466
current state at start:  [ 0.29652253 -2.44845249]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.29652253, -2.44845249]), 'currentState': array([6.14731959, 3.42357753]), 'targetState': array([0.37667004, 0.10883903]), 'effectorPosition': array([ 0.00144087, -0.28104785])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9447856156343492
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([ 0.29652253, -2.44845249]), 'currentState': array([4.66369508, 3.67318677]), 'targetState': array([0.37667004, 0.10883903]), 'effectorPosition': array([-0.51302437, -0.11316275])}
episode index:2322
target Thresh 1.982685540807747
current state at start:  [ 4.07278752 -2.04095523]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.07278752, -2.04095523]), 'currentState': array([4.20450007, 4.41423205]), 'targetState': array([-1.28879093, -0.18200315]), 'effectorPosition': array([-1.1786907 , -0.15221802])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9448093842027373
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.07278752, -2.04095523]), 'currentState': array([4.20450007, 4.41423205]), 'targetState': array([-1.28879093, -0.18200315]), 'effectorPosition': array([-1.1786907 , -0.15221802])}
episode index:2323
target Thresh 1.9827201351202874
current state at start:  [-1.7112793  -1.93766256]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.7112793 , -1.93766256]), 'currentState': array([4.07190601, 4.74538772]), 'targetState': array([-1.1314727 ,  0.01636339]), 'effectorPosition': array([-1.41866939, -0.23100363])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.944824569493528
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.7112793 , -1.93766256]), 'currentState': array([4.09080938, 4.20869114]), 'targetState': array([-1.1314727 ,  0.01636339]), 'effectorPosition': array([-1.01324621,  0.08942755])}
episode index:2324
target Thresh 1.9827546603133455
current state at start:  [-1.61103371  1.66227441]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.61103371,  1.66227441]), 'currentState': array([4.24537161, 2.15798419]), 'targetState': array([ 0.03636071, -0.24028259]), 'effectorPosition': array([ 0.54256316, -0.77303364])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9448397417217028
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.61103371,  1.66227441]), 'currentState': array([4.00401356, 2.8800705 ]), 'targetState': array([ 0.03636071, -0.24028259]), 'effectorPosition': array([ 0.17422691, -0.19403581])}
episode index:2325
target Thresh 1.9827891165250218
current state at start:  [-2.17600509  2.05734541]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.17600509,  2.05734541]), 'currentState': array([3.73452841, 2.22927142]), 'targetState': array([ 0.00617911, -0.95274595]), 'effectorPosition': array([ 0.12012478, -0.87278124])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9448634563641269
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.17600509,  2.05734541]), 'currentState': array([3.73452841, 2.22927142]), 'targetState': array([ 0.00617911, -0.95274595]), 'effectorPosition': array([ 0.12012478, -0.87278124])}
episode index:2326
target Thresh 1.982823503893141
current state at start:  [-2.86994187  2.57561718]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.86994187,  2.57561718]), 'currentState': array([3.01444667, 2.99293325]), 'targetState': array([-0.76253742, -0.09418339]), 'effectorPosition': array([-0.02972165, -0.14551828])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9448785988409796
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-2.86994187,  2.57561718]), 'currentState': array([2.14104193, 2.45216409]), 'targetState': array([-0.76253742, -0.09418339]), 'effectorPosition': array([-0.65873981, -0.1511377 ])}
episode index:2327
target Thresh 1.9828578225552531
current state at start:  [-0.59532256  2.15992397]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.59532256,  2.15992397]), 'currentState': array([5.23638612, 2.6341921 ]), 'targetState': array([-0.11483366,  0.0582408 ]), 'effectorPosition': array([0.48374912, 0.13403613])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9448979808861508
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.59532256,  2.15992397]), 'currentState': array([4.79278862, 3.03351646]), 'targetState': array([-0.11483366,  0.0582408 ]), 'effectorPosition': array([0.10798607, 0.00284734])}
episode index:2328
target Thresh 1.9828920726486325
current state at start:  [-1.41151568 -2.33481671]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.41151568, -2.33481671]), 'currentState': array([4.41092238, 4.28597571]), 'targetState': array([0.04429729, 0.31567963]), 'effectorPosition': array([-1.04350756, -0.28961379])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9444922711476853
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([-1.41151568, -2.33481671]), 'currentState': array([4.30271462, 3.28157718]), 'targetState': array([0.04429729, 0.31567963]), 'effectorPosition': array([-0.13187816,  0.046603  ])}
episode index:2329
target Thresh 1.9829262543102797
current state at start:  [0.62925177 2.16574847]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.62925177, 2.16574847]), 'currentState': array([0.33931493, 2.66574847]), 'targetState': array([-0.19779153,  0.12527908]), 'effectorPosition': array([-0.04771144,  0.46894666])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.944511802361785
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.62925177, 2.16574847]), 'currentState': array([2.26479201e-03, 3.16574847e+00]), 'targetState': array([-0.19779153,  0.12527908]), 'effectorPosition': array([ 0.00034644, -0.02415274])}
episode index:2330
target Thresh 1.9829603676769214
current state at start:  [-0.00488625  2.55083025]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.00488625,  2.55083025]), 'currentState': array([5.84348359, 3.05083025]), 'targetState': array([ 0.00486007, -0.00369838]), 'effectorPosition': array([0.04230632, 0.08026416])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9445356068223763
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.00488625,  2.55083025]), 'currentState': array([5.84348359, 3.05083025]), 'targetState': array([ 0.00486007, -0.00369838]), 'effectorPosition': array([0.04230632, 0.08026416])}
episode index:2331
target Thresh 1.982994412885011
current state at start:  [ 2.10270462 -2.93837867]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.10270462, -2.93837867]), 'currentState': array([1.65318844, 2.88213962]), 'targetState': array([-0.52347144, -0.56881734]), 'effectorPosition': array([-0.25843613,  0.01224206])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9445424937877182
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([ 2.10270462, -2.93837867]), 'currentState': array([2.5782125 , 2.28158241]), 'targetState': array([-0.52347144, -0.56881734]), 'effectorPosition': array([-0.69858209, -0.45510839])}
episode index:2332
target Thresh 1.9830283900707295
current state at start:  [ 1.1214714  -1.65923295]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.1214714 , -1.65923295]), 'currentState': array([1.6214714 , 4.19146701]), 'targetState': array([0.57920308, 0.84674837]), 'effectorPosition': array([0.84080306, 0.5456099 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.944561978359605
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.1214714 , -1.65923295]), 'currentState': array([2.1214714 , 4.29955879]), 'targetState': array([0.57920308, 0.84674837]), 'effectorPosition': array([0.46725181, 0.98958023])}
episode index:2333
target Thresh 1.9830622993699858
current state at start:  [-2.24793541  2.25179878]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.24793541,  2.25179878]), 'currentState': array([4.30714229, 1.9437817 ]), 'targetState': array([ 0.24722886, -0.85218644]), 'effectorPosition': array([ 0.60523417, -0.95126089])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9445814462352007
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.24793541,  2.25179878]), 'currentState': array([3.95007259, 2.04254532]), 'targetState': array([ 0.24722886, -0.85218644]), 'effectorPosition': array([ 0.26748288, -1.00973414])}
episode index:2334
target Thresh 1.983096140918417
current state at start:  [ 2.7306652  -3.06934016]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.7306652 , -3.06934016]), 'currentState': array([3.11792048, 3.70013122]), 'targetState': array([0.88378345, 0.64323756]), 'effectorPosition': array([-0.13938309,  0.53339606])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.9445801180566848
{'reset': False, 'endBeforeDone': False, 'stepCount': 7, 'initial state': array([ 2.7306652 , -3.06934016]), 'currentState': array([5.86715898, 2.22336816]), 'targetState': array([0.88378345, 0.64323756]), 'effectorPosition': array([0.6803563 , 0.56802439])}
episode index:2335
target Thresh 1.983129914851389
current state at start:  [ 0.6937329  -2.84170827]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.6937329 , -2.84170827]), 'currentState': array([0.69551652, 2.96441457]), 'targetState': array([0.56984654, 0.78973675]), 'effectorPosition': array([-0.10092075,  0.14534455])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.944595323485599
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 0.6937329 , -2.84170827]), 'currentState': array([6.18222272, 2.24753811]), 'targetState': array([0.56984654, 0.78973675]), 'effectorPosition': array([0.45041908, 0.73797715])}
episode index:2336
target Thresh 1.9831636213039983
current state at start:  [ 1.68657876 -2.40485342]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.68657876, -2.40485342]), 'currentState': array([1.34773401, 4.32208912]), 'targetState': array([ 1.19549717, -0.28344395]), 'effectorPosition': array([1.03893441, 0.39960457])}
done in step count: 82
reward sum = 0.43861750180991077
running average episode reward sum: 0.944378816073671
{'reset': False, 'endBeforeDone': False, 'stepCount': 83, 'initial state': array([ 1.68657876, -2.40485342]), 'currentState': array([4.91268268, 1.88711616]), 'targetState': array([ 1.19549717, -0.28344395]), 'effectorPosition': array([ 1.06845404, -0.48606973])}
episode index:2337
target Thresh 1.9831972604110701
current state at start:  [-3.32376949  1.86924684]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.32376949,  1.86924684]), 'currentState': array([2.45941582, 1.92948312]), 'targetState': array([-0.71338208, -0.09317235]), 'effectorPosition': array([-1.09407961, -0.31764761])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9443857524269329
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([-3.32376949,  1.86924684]), 'currentState': array([2.17110505, 2.22323409]), 'targetState': array([-0.71338208, -0.09317235]), 'effectorPosition': array([-0.87761205, -0.12468581])}
episode index:2338
target Thresh 1.9832308323071612
current state at start:  [ 1.5371914  -1.85835245]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.5371914 , -1.85835245]), 'currentState': array([1.10612473, 3.98696944]), 'targetState': array([ 0.3436148 , -0.04538353]), 'effectorPosition': array([ 0.81970451, -0.03443405])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9444052540291444
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.5371914 , -1.85835245]), 'currentState': array([1.13201053, 3.7157509 ]), 'targetState': array([ 0.3436148 , -0.04538353]), 'effectorPosition': array([ 0.55979997, -0.08558296])}
episode index:2339
target Thresh 1.9832643371265593
current state at start:  [0.16849549 2.56635239]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.16849549, 2.56635239]), 'currentState': array([0.66216664, 2.97166791]), 'targetState': array([-0.61976602,  0.5331008 ]), 'effectorPosition': array([-0.09261357,  0.14222424])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9444247389633199
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.16849549, 2.56635239]), 'currentState': array([1.13069687, 2.53632357]), 'targetState': array([-0.61976602,  0.5331008 ]), 'effectorPosition': array([-0.43908   ,  0.40312616])}
episode index:2340
target Thresh 1.9832977750032834
current state at start:  [ 3.04726618 -2.16236215]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.04726618, -2.16236215]), 'currentState': array([2.91571827, 3.76012496]), 'targetState': array([-1.18538247,  0.35928928]), 'effectorPosition': array([-0.05070337,  0.60660403])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.9444275434532545
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([ 3.04726618, -2.16236215]), 'currentState': array([1.80488524, 1.91731886]), 'targetState': array([-1.18538247,  0.35928928]), 'effectorPosition': array([-1.06808425,  0.42419078])}
episode index:2341
target Thresh 1.9833311460710854
current state at start:  [-0.85506904  2.49963675]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.85506904,  2.49963675]), 'currentState': array([5.91704435, 2.13234739]), 'targetState': array([0.91531601, 0.7968375 ]), 'effectorPosition': array([0.73954704, 0.62295326])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9444512720854265
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.85506904,  2.49963675]), 'currentState': array([5.91704435, 2.13234739]), 'targetState': array([0.91531601, 0.7968375 ]), 'effectorPosition': array([0.73954704, 0.62295326])}
episode index:2342
target Thresh 1.9833644504634493
current state at start:  [0.45370411 2.4294825 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.45370411, 2.4294825 ]), 'currentState': array([6.26425567, 2.9294825 ]), 'targetState': array([ 0.19705114, -0.18327742]), 'effectorPosition': array([0.02639202, 0.2100613 ])}
done in step count: 24
reward sum = 0.7856781408072188
running average episode reward sum: 0.9443835071979838
{'reset': False, 'endBeforeDone': False, 'stepCount': 25, 'initial state': array([0.45370411, 2.4294825 ]), 'currentState': array([2.83162481, 3.04357889]), 'targetState': array([ 0.19705114, -0.18327742]), 'effectorPosition': array([-0.03441988, -0.0917294 ])}
episode index:2343
target Thresh 1.983397688313593
current state at start:  [-0.8013438  -2.06765018]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.8013438 , -2.06765018]), 'currentState': array([5.03591461, 4.71553513]), 'targetState': array([ 0.28410376, -1.0227105 ]), 'effectorPosition': array([-0.62920434, -1.26901307])}
done in step count: 148
reward sum = 0.22594815553398728
running average episode reward sum: 0.9440770074745776
{'reset': False, 'endBeforeDone': False, 'stepCount': 149, 'initial state': array([-0.8013438 , -2.06765018]), 'currentState': array([4.10729726, 1.81538775]), 'targetState': array([ 0.28410376, -1.0227105 ]), 'effectorPosition': array([ 0.36688295, -1.17519234])}
episode index:2344
target Thresh 1.9834308597544679
current state at start:  [1.68333884 2.33498379]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.68333884, 2.33498379]), 'currentState': array([1.18333884, 1.8865394 ]), 'targetState': array([-0.80802896,  0.9737851 ]), 'effectorPosition': array([-0.61959403,  0.99752566])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9441008552325841
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.68333884, 2.33498379]), 'currentState': array([1.18333884, 1.8865394 ]), 'targetState': array([-0.80802896,  0.9737851 ]), 'effectorPosition': array([-0.61959403,  0.99752566])}
episode index:2345
target Thresh 1.9834639649187595
current state at start:  [ 2.30263111 -1.9470214 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.30263111, -1.9470214 ]), 'currentState': array([2.05998802, 3.86748456]), 'targetState': array([0.39010623, 0.22150096]), 'effectorPosition': array([0.46748598, 0.53445442])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9441204200854261
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 2.30263111, -1.9470214 ]), 'currentState': array([2.10254622, 3.59718251]), 'targetState': array([0.39010623, 0.22150096]), 'effectorPosition': array([0.32752098, 0.31100916])}
episode index:2346
target Thresh 1.9834970039388888
current state at start:  [ 2.2145909 -1.9157361]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.2145909, -1.9157361]), 'currentState': array([2.65226983, 4.15297397]), 'targetState': array([-0.59258121,  0.79036427]), 'effectorPosition': array([-0.01585684,  0.96869377])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9441357501152151
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 2.2145909, -1.9157361]), 'currentState': array([3.28825005, 4.16011309]), 'targetState': array([-0.59258121,  0.79036427]), 'effectorPosition': array([-0.59467792,  0.77272629])}
episode index:2347
target Thresh 1.983529976947012
current state at start:  [-1.9843838   2.50773241]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.9843838 ,  2.50773241]), 'currentState': array([3.79908243, 2.98607766]), 'targetState': array([ 0.01879405, -0.00170473]), 'effectorPosition': array([ 0.08510529, -0.12997423])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9441595423851831
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.9843838 ,  2.50773241]), 'currentState': array([3.79908243, 2.98607766]), 'targetState': array([ 0.01879405, -0.00170473]), 'effectorPosition': array([ 0.08510529, -0.12997423])}
episode index:2348
target Thresh 1.983562884075021
current state at start:  [-2.10151111  2.43273799]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.10151111,  2.43273799]), 'currentState': array([4.316469  , 1.96666781]), 'targetState': array([ 0.28985783, -1.27419334]), 'effectorPosition': array([ 0.61434284, -0.92269065])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9441790572670965
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.10151111,  2.43273799]), 'currentState': array([3.86455144, 1.78054925]), 'targetState': array([ 0.28985783, -1.27419334]), 'effectorPosition': array([ 0.05338669, -1.25726424])}
episode index:2349
target Thresh 1.9835957254545442
current state at start:  [ 1.53077288 -2.29665658]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.53077288, -2.29665658]), 'currentState': array([1.06852935, 3.51749471]), 'targetState': array([ 0.00522981, -0.44067542]), 'effectorPosition': array([ 0.35538488, -0.11553311])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9441901721363446
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 1.53077288, -2.29665658]), 'currentState': array([5.96161421, 3.55808978]), 'targetState': array([ 0.00522981, -0.44067542]), 'effectorPosition': array([-0.04675787, -0.41084104])}
episode index:2350
target Thresh 1.9836285012169474
current state at start:  [-2.80832028  2.43633328]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.80832028,  2.43633328]), 'currentState': array([3.1078376, 2.8834319]), 'targetState': array([ 0.141419  , -0.01621749]), 'effectorPosition': array([-0.04173607, -0.25403887])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9442096573885196
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.80832028,  2.43633328]), 'currentState': array([3.34186557, 3.09291209]), 'targetState': array([ 0.141419  , -0.01621749]), 'effectorPosition': array([ 0.00851954, -0.04792438])}
episode index:2351
target Thresh 1.9836612114933339
current state at start:  [ 0.28748969 -2.42639163]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.28748969, -2.42639163]), 'currentState': array([6.070675  , 3.42531252]), 'targetState': array([ 0.13971035, -0.19500408]), 'effectorPosition': array([-0.01996113, -0.28206379])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9442333777722829
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.28748969, -2.42639163]), 'currentState': array([6.070675  , 3.42531252]), 'targetState': array([ 0.13971035, -0.19500408]), 'effectorPosition': array([-0.01996113, -0.28206379])}
episode index:2352
target Thresh 1.9836938564145443
current state at start:  [0.69413519 1.86629884]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.69413519, 1.86629884]), 'currentState': array([0.19413519, 2.03618983]), 'targetState': array([0.63129286, 0.78267992]), 'effectorPosition': array([0.36847042, 0.98319916])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9442528281004714
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.69413519, 1.86629884]), 'currentState': array([6.11729652, 1.97862416]), 'targetState': array([0.63129286, 0.78267992]), 'effectorPosition': array([0.74668633, 0.80574625])}
episode index:2353
target Thresh 1.9837264361111586
current state at start:  [ 3.85446749 -1.93408926]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.85446749, -1.93408926]), 'currentState': array([4.35446749, 3.88497554]), 'targetState': array([-0.20809743, -0.31552026]), 'effectorPosition': array([-0.72631492, -0.01000195])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9438517011556539
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([ 3.85446749, -1.93408926]), 'currentState': array([4.81028071, 4.28126343]), 'targetState': array([-0.20809743, -0.31552026]), 'effectorPosition': array([-0.84725404, -0.66811177])}
episode index:2354
target Thresh 1.9837589507134958
current state at start:  [ 1.98756038 -1.69106251]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.98756038, -1.69106251]), 'currentState': array([2.47748538, 4.16130668]), 'targetState': array([-0.22363173,  0.91109821]), 'effectorPosition': array([0.14996808, 0.96451561])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9434509148706621
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([ 1.98756038, -1.69106251]), 'currentState': array([1.36334516, 1.96175955]), 'targetState': array([-0.22363173,  0.91109821]), 'effectorPosition': array([-0.77724248,  0.79607529])}
episode index:2355
target Thresh 1.9837914003516142
current state at start:  [-4.07846981  1.92061616]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.07846981,  1.92061616]), 'currentState': array([1.7047155 , 1.59689529]), 'targetState': array([-0.65031654,  0.9388389 ]), 'effectorPosition': array([-1.12074363,  0.83171011])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9434664705095117
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-4.07846981,  1.92061616]), 'currentState': array([1.25424394, 1.81590649]), 'targetState': array([-0.65031654,  0.9388389 ]), 'effectorPosition': array([-0.68615699,  1.02169574])}
episode index:2356
target Thresh 1.9838237851553124
current state at start:  [-0.72214707 -2.41083389]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.72214707, -2.41083389]), 'currentState': array([5.07897852, 4.29756115]), 'targetState': array([-0.83731176, -1.05955166]), 'effectorPosition': array([-0.64040309, -0.88533561])}
done in step count: 14
reward sum = 0.8687458127689782
running average episode reward sum: 0.943434768915222
{'reset': False, 'endBeforeDone': False, 'stepCount': 15, 'initial state': array([-0.72214707, -2.41083389]), 'currentState': array([4.79800371, 4.9070755 ]), 'targetState': array([-0.83731176, -1.05955166]), 'effectorPosition': array([-0.87546196, -1.27298245])}
episode index:2357
target Thresh 1.9838561052541295
current state at start:  [-3.56281343  2.39158558]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.56281343,  2.39158558]), 'currentState': array([3.17640279, 2.00411164]), 'targetState': array([-0.36196688, -1.21007849]), 'effectorPosition': array([-0.54817999, -0.92721878])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9430346693524929
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([-3.56281343,  2.39158558]), 'currentState': array([3.47180131, 2.18565087]), 'targetState': array([-0.36196688, -1.21007849]), 'effectorPosition': array([-0.13544075, -0.90993207])}
episode index:2358
target Thresh 1.9838883607773463
current state at start:  [ 3.70691    -1.99907408]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.70691   , -1.99907408]), 'currentState': array([3.20691   , 4.56068726]), 'targetState': array([-0.62226393,  1.00162666]), 'effectorPosition': array([-0.91159061,  0.93100028])}
done in step count: 18
reward sum = 0.8345137614500875
running average episode reward sum: 0.9429886664241748
{'reset': False, 'endBeforeDone': False, 'stepCount': 19, 'initial state': array([ 3.70691   , -1.99907408]), 'currentState': array([1.38823377, 1.85682524]), 'targetState': array([-0.62226393,  1.00162666]), 'effectorPosition': array([-0.81310199,  0.88009984])}
episode index:2359
target Thresh 1.9839205518539844
current state at start:  [0.73474055 2.05346651]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.73474055, 2.05346651]), 'currentState': array([1.23474055, 2.42480636]), 'targetState': array([-0.93141369,  0.65641172]), 'effectorPosition': array([-0.53906778,  0.44895891])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9430085864807747
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.73474055, 2.05346651]), 'currentState': array([1.73474055, 1.98673592]), 'targetState': array([-0.93141369,  0.65641172]), 'effectorPosition': array([-0.99973712,  0.43866447])}
episode index:2360
target Thresh 1.9839526786128088
current state at start:  [0.34569499 2.66183049]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.34569499, 2.66183049]), 'currentState': array([6.2068652 , 3.16183049]), 'targetState': array([0.00477862, 0.1898661 ]), 'effectorPosition': array([-0.00133877, -0.02019316])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9430327251565558
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.34569499, 2.66183049]), 'currentState': array([6.2068652 , 3.16183049]), 'targetState': array([0.00477862, 0.1898661 ]), 'effectorPosition': array([-0.00133877, -0.02019316])}
episode index:2361
target Thresh 1.9839847411823262
current state at start:  [0.35310569 2.44218703]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.35310569, 2.44218703]), 'currentState': array([6.14979106, 2.94218703]), 'targetState': array([0.02805216, 0.01320965]), 'effectorPosition': array([0.04598481, 0.19369156])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9430568433931533
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.35310569, 2.44218703]), 'currentState': array([6.14979106, 2.94218703]), 'targetState': array([0.02805216, 0.01320965]), 'effectorPosition': array([0.04598481, 0.19369156])}
episode index:2362
target Thresh 1.9840167396907868
current state at start:  [1.26033627 1.91916428]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.26033627, 1.91916428]), 'currentState': array([1.76033627, 2.36008123]), 'targetState': array([-1.19474131,  0.41159643]), 'effectorPosition': array([-0.74640522,  0.1522488 ])}
done in step count: 21
reward sum = 0.8097278682212584
running average episode reward sum: 0.9430004197896104
{'reset': False, 'endBeforeDone': False, 'stepCount': 22, 'initial state': array([1.26033627, 1.91916428]), 'currentState': array([1.93738084, 1.5540571 ]), 'targetState': array([-1.19474131,  0.41159643]), 'effectorPosition': array([-1.29785473,  0.59080453])}
episode index:2363
target Thresh 1.9840486742661851
current state at start:  [ 2.75751181 -2.47416064]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.75751181, -2.47416064]), 'currentState': array([3.00664994, 3.68026843]), 'targetState': array([-0.61646927,  0.43063733]), 'effectorPosition': array([-0.07130818,  0.52738755])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9430078629326774
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([ 2.75751181, -2.47416064]), 'currentState': array([3.65787843, 3.70083253]), 'targetState': array([-0.61646927,  0.43063733]), 'effectorPosition': array([-0.39438889,  0.38618666])}
episode index:2364
target Thresh 1.984080545036259
current state at start:  [ 0.46670783 -2.56872164]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.46670783, -2.56872164]), 'currentState': array([0.38697967, 3.21446367]), 'targetState': array([1.04306358, 0.42387245]), 'effectorPosition': array([ 0.02993436, -0.06642115])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9430152997813315
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([ 0.46670783, -2.56872164]), 'currentState': array([5.87043429, 1.97330413]), 'targetState': array([1.04306358, 0.42387245]), 'effectorPosition': array([0.9262638 , 0.59881671])}
episode index:2365
target Thresh 1.9841123521284918
current state at start:  [-3.43568312  2.23810907]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.43568312,  2.23810907]), 'currentState': array([2.59965468, 2.01964427]), 'targetState': array([-0.70956967, -1.00083679]), 'effectorPosition': array([-0.94966633, -0.47987301])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9430351580654475
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.43568312,  2.23810907]), 'currentState': array([3.0421148 , 1.82254063]), 'targetState': array([-0.70956967, -1.00083679]), 'effectorPosition': array([-0.84337741, -0.88911598])}
episode index:2366
target Thresh 1.9841440956701122
current state at start:  [-1.49206876 -2.27672509]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.49206876, -2.27672509]), 'currentState': array([4.40093134, 3.72905487]), 'targetState': array([-0.39323423,  0.37115104]), 'effectorPosition': array([-0.5789601 ,  0.01026403])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9426367486197079
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([-1.49206876, -2.27672509]), 'currentState': array([4.54694911, 3.81394295]), 'targetState': array([-0.39323423,  0.37115104]), 'effectorPosition': array([-0.65016472, -0.11209741])}
episode index:2367
target Thresh 1.9841757757880938
current state at start:  [-1.64411992 -1.72117529]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.64411992, -1.72117529]), 'currentState': array([5.12600479, 4.47770418]), 'targetState': array([-0.38456867, -0.57561268]), 'effectorPosition': array([-0.58211167, -1.09365129])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9422386756684328
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([-1.64411992, -1.72117529]), 'currentState': array([4.71884653, 4.12552431]), 'targetState': array([-0.38456867, -0.57561268]), 'effectorPosition': array([-0.82978196, -0.45161472])}
episode index:2368
target Thresh 1.9842073926091577
current state at start:  [-1.12849013 -1.80378178]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.12849013, -1.80378178]), 'currentState': array([5.18194061, 4.56968199]), 'targetState': array([ 0.13817379, -1.11972089]), 'effectorPosition': array([-0.49457362, -1.21282758])}
done in step count: 59
reward sum = 0.5526834771623851
running average episode reward sum: 0.9420742370029594
{'reset': False, 'endBeforeDone': False, 'stepCount': 60, 'initial state': array([-1.12849013, -1.80378178]), 'currentState': array([3.66566536, 2.08975758]), 'targetState': array([ 0.13817379, -1.11972089]), 'effectorPosition': array([-0.00185223, -1.00401181])}
episode index:2369
target Thresh 1.984238946259771
current state at start:  [ 2.2270815  -2.58691238]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.2270815 , -2.58691238]), 'currentState': array([2.31916967, 4.14630856]), 'targetState': array([1.18051385, 0.08614385]), 'effectorPosition': array([0.30298295, 0.91408167])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.942082052097051
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([ 2.2270815 , -2.58691238]), 'currentState': array([0.95186487, 4.63751434]), 'targetState': array([1.18051385, 0.08614385]), 'effectorPosition': array([1.34898288, 0.17503085])}
episode index:2370
target Thresh 1.9842704368661481
current state at start:  [ 3.49729201 -3.11309399]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.49729201, -3.11309399]), 'currentState': array([3.96530023, 2.68167724]), 'targetState': array([ 0.35418559, -0.92393631]), 'effectorPosition': array([ 0.25504847, -0.37784942])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9420980866596419
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 3.49729201, -3.11309399]), 'currentState': array([3.9950723 , 2.32023942]), 'targetState': array([ 0.35418559, -0.92393631]), 'effectorPosition': array([ 0.34211903, -0.72145148])}
episode index:2371
target Thresh 1.9843018645542518
current state at start:  [-0.60682408 -2.0199918 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.60682408, -2.0199918 ]), 'currentState': array([5.18587014, 3.89751708]), 'targetState': array([-0.68354336, -0.64519592]), 'effectorPosition': array([-0.48630273, -0.55518842])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9421224972470535
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.60682408, -2.0199918 ]), 'currentState': array([5.18587014, 3.89751708]), 'targetState': array([-0.68354336, -0.64519592]), 'effectorPosition': array([-0.48630273, -0.55518842])}
episode index:2372
target Thresh 1.9843332294497928
current state at start:  [ 3.87867414 -2.44564781]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.87867414, -2.44564781]), 'currentState': array([4.33861713, 3.3613334 ]), 'targetState': array([-0.1730262 ,  0.05830677]), 'effectorPosition': array([-0.2117067 ,  0.05720389])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9421468872608558
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.87867414, -2.44564781]), 'currentState': array([4.33861713, 3.3613334 ]), 'targetState': array([-0.1730262 ,  0.05830677]), 'effectorPosition': array([-0.2117067 ,  0.05720389])}
episode index:2373
target Thresh 1.9843645316782306
current state at start:  [-1.22049922  1.99582692]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.22049922,  1.99582692]), 'currentState': array([4.56268609, 1.62980701]), 'targetState': array([ 0.71056351, -1.15429563]), 'effectorPosition': array([ 0.84674593, -1.07938336])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9421712567270476
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.22049922,  1.99582692]), 'currentState': array([4.56268609, 1.62980701]), 'targetState': array([ 0.71056351, -1.15429563]), 'effectorPosition': array([ 0.84674593, -1.07938336])}
episode index:2374
target Thresh 1.9843957713647744
current state at start:  [0.89381065 2.23458296]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.89381065, 2.23458296]), 'currentState': array([1.31737681, 2.73458296]), 'targetState': array([-1.0887644 , -0.06667176]), 'effectorPosition': array([-0.36274015,  0.17833175])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9421872267242152
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([0.89381065, 2.23458296]), 'currentState': array([2.15250116, 2.12114766]), 'targetState': array([-1.0887644 , -0.06667176]), 'effectorPosition': array([-0.97424845, -0.06976041])}
episode index:2375
target Thresh 1.9844269486343828
current state at start:  [-1.11004553  2.08258488]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.11004553,  2.08258488]), 'currentState': array([5.50999841, 1.78686678]), 'targetState': array([1.03016093, 0.32526196]), 'effectorPosition': array([1.24442941, 0.15036368])}
done in step count: 16
reward sum = 0.8514577710948755
running average episode reward sum: 0.9421490409263914
{'reset': False, 'endBeforeDone': False, 'stepCount': 17, 'initial state': array([-1.11004553,  2.08258488]), 'currentState': array([5.66602483, 2.04407957]), 'targetState': array([1.03016093, 0.32526196]), 'effectorPosition': array([0.95890639, 0.41094572])}
episode index:2376
target Thresh 1.984458063611765
current state at start:  [ 1.27227876 -1.78222363]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.27227876, -1.78222363]), 'currentState': array([0.87981418, 4.03636725]), 'targetState': array([ 0.33249406, -0.32183533]), 'effectorPosition': array([ 0.8396791 , -0.20868562])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9417526803706798
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([ 1.27227876, -1.78222363]), 'currentState': array([4.96518018, 3.96350337]), 'targetState': array([ 0.33249406, -0.32183533]), 'effectorPosition': array([-0.62934089, -0.49222368])}
episode index:2377
target Thresh 1.984489116421381
current state at start:  [ 3.61118893 -2.07029087]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.61118893, -2.07029087]), 'currentState': array([4.10472865, 3.71289443]), 'targetState': array([-0.21474203,  0.11209718]), 'effectorPosition': array([-0.53459765,  0.17835301])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9417729694033246
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.61118893, -2.07029087]), 'currentState': array([4.56145967, 3.36866968]), 'targetState': array([-0.21474203,  0.11209718]), 'effectorPosition': array([-0.22643109,  0.00847039])}
episode index:2378
target Thresh 1.9845201071874419
current state at start:  [-3.8507002   2.30219942]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.8507002 ,  2.30219942]), 'currentState': array([2.90485517, 2.72185015]), 'targetState': array([ 0.14325224, -1.10206876]), 'effectorPosition': array([-0.1799628 , -0.37579991])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9417890799668374
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-3.8507002 ,  2.30219942]), 'currentState': array([3.87939302, 2.02838057]), 'targetState': array([ 0.14325224, -1.10206876]), 'effectorPosition': array([ 0.19040678, -1.03931753])}
episode index:2379
target Thresh 1.984551036033911
current state at start:  [-0.63272556  1.81326442]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.63272556,  1.81326442]), 'currentState': array([5.78324569, 1.51071485]), 'targetState': array([1.08771186, 0.33251982]), 'effectorPosition': array([1.40881558, 0.36787136])}
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.9417620765815568
{'reset': False, 'endBeforeDone': False, 'stepCount': 14, 'initial state': array([-0.63272556,  1.81326442]), 'currentState': array([5.66157252, 1.97267258]), 'targetState': array([1.08771186, 0.33251982]), 'effectorPosition': array([1.03091281, 0.3936079 ])}
episode index:2380
target Thresh 1.9845819030845036
current state at start:  [-2.84824952  2.09810727]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.84824952,  2.09810727]), 'currentState': array([2.97115134, 2.58961247]), 'targetState': array([ 0.04966467, -0.16644768]), 'effectorPosition': array([-0.23530318, -0.49158594])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.941782336104202
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.84824952,  2.09810727]), 'currentState': array([2.53705223, 3.01390343]), 'targetState': array([ 0.04966467, -0.16644768]), 'effectorPosition': array([-0.07907773, -0.10014544])}
episode index:2381
target Thresh 1.984612708462688
current state at start:  [-2.46600752  2.29971498]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.46600752,  2.29971498]), 'currentState': array([3.31717778, 2.79971498]), 'targetState': array([-0.5908641 ,  0.02523521]), 'effectorPosition': array([ 0.00158073, -0.34021148])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.9417862016431592
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([-2.46600752,  2.29971498]), 'currentState': array([1.7263114 , 2.45575026]), 'targetState': array([-0.5908641 ,  0.02523521]), 'effectorPosition': array([-0.66070471,  0.12529033])}
episode index:2382
target Thresh 1.9846434522916856
current state at start:  [ 2.81506946 -2.62083058]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.81506946, -2.62083058]), 'currentState': array([2.98078122, 3.50215026]), 'targetState': array([-0.24015146,  0.13393366]), 'effectorPosition': array([-0.00698071,  0.35853978])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9418022796114164
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 2.81506946, -2.62083058]), 'currentState': array([3.53305848, 3.4087572 ]), 'targetState': array([-0.24015146,  0.13393366]), 'effectorPosition': array([-0.13351954,  0.23049052])}
episode index:2383
target Thresh 1.9846741346944718
current state at start:  [-3.94135569  1.98171814]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.94135569,  1.98171814]), 'currentState': array([1.89295371, 1.68084248]), 'targetState': array([-1.13640956, -0.29660806]), 'effectorPosition': array([-1.22465865,  0.52968184])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9418224967760088
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.94135569,  1.98171814]), 'currentState': array([2.39295371, 2.09825118]), 'targetState': array([-1.13640956, -0.29660806]), 'effectorPosition': array([-0.95200096, -0.2949961 ])}
episode index:2384
target Thresh 1.9847047557937767
current state at start:  [0.74328212 1.90922058]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.74328212, 1.90922058]), 'currentState': array([0.27482823, 1.72637791]), 'targetState': array([0.58541687, 0.83282043]), 'effectorPosition': array([0.54522855, 1.18017646])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9418385460436081
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([0.74328212, 1.90922058]), 'currentState': array([0.12780794, 1.9652534 ]), 'targetState': array([0.58541687, 0.83282043]), 'effectorPosition': array([0.4929992 , 0.99415178])}
episode index:2385
target Thresh 1.9847353157120842
current state at start:  [-1.42303328  2.43089664]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.42303328,  2.43089664]), 'currentState': array([5.31704553, 2.2613125 ]), 'targetState': array([0.61123758, 0.83866586]), 'effectorPosition': array([0.84062661, 0.13955828])}
done in step count: 21
reward sum = 0.8097278682212584
running average episode reward sum: 0.9417831769414193
{'reset': False, 'endBeforeDone': False, 'stepCount': 22, 'initial state': array([-1.42303328,  2.43089664]), 'currentState': array([0.1737271 , 1.82930574]), 'targetState': array([0.61123758, 0.83866586]), 'effectorPosition': array([0.56604469, 1.08088568])}
episode index:2386
target Thresh 1.984765814571634
current state at start:  [-1.41642201  1.91328175]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.41642201,  1.91328175]), 'currentState': array([4.3667633 , 2.34203399]), 'targetState': array([ 0.34278058, -0.02171836]), 'effectorPosition': array([ 0.5720008 , -0.52798542])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9417992292342802
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.41642201,  1.91328175]), 'currentState': array([4.39741034, 2.79721185]), 'targetState': array([ 0.34278058, -0.02171836]), 'effectorPosition': array([ 0.30281453, -0.16041819])}
episode index:2387
target Thresh 1.984796252494422
current state at start:  [-3.7675482   2.17906895]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.7675482 ,  2.17906895]), 'currentState': array([2.0156371 , 1.79224497]), 'targetState': array([-0.69991595,  0.38845831]), 'effectorPosition': array([-1.21643464,  0.28460591])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9418194138116527
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.7675482 ,  2.17906895]), 'currentState': array([1.5156371 , 2.15855703]), 'targetState': array([-0.69991595,  0.38845831]), 'effectorPosition': array([-0.80635776,  0.49070292])}
episode index:2388
target Thresh 1.9848266296021997
current state at start:  [-2.00200519 -2.15232214]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.00200519, -2.15232214]), 'currentState': array([4.76635895, 4.07811066]), 'targetState': array([-0.67999332, -0.25046587]), 'effectorPosition': array([-0.78234986, -0.45026214])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9418437673429161
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.00200519, -2.15232214]), 'currentState': array([4.76635895, 4.07811066]), 'targetState': array([-0.67999332, -0.25046587]), 'effectorPosition': array([-0.78234986, -0.45026214])}
episode index:2389
target Thresh 1.9848569460164756
current state at start:  [-1.33966315  2.6004802 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.33966315,  2.6004802 ]), 'currentState': array([5.27825945, 2.48406902]), 'targetState': array([0.64261641, 0.18772341]), 'effectorPosition': array([0.6276757 , 0.15168057])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9418681004946554
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.33966315,  2.6004802 ]), 'currentState': array([5.27825945, 2.48406902]), 'targetState': array([0.64261641, 0.18772341]), 'effectorPosition': array([0.6276757 , 0.15168057])}
episode index:2390
target Thresh 1.9848872018585153
current state at start:  [-2.4845506   1.93962761]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.4845506 ,  1.93962761]), 'currentState': array([4.28555316, 1.50846302]), 'targetState': array([ 0.71859904, -1.01750121]), 'effectorPosition': array([ 0.468731  , -1.38017287])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.94188823094196
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.4845506 ,  1.93962761]), 'currentState': array([4.65571654, 1.53302245]), 'targetState': array([ 0.71859904, -1.01750121]), 'effectorPosition': array([ 0.93890115, -1.09270052])}
episode index:2391
target Thresh 1.9849173972493424
current state at start:  [-1.38866489 -2.32489294]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.38866489, -2.32489294]), 'currentState': array([4.39896829, 3.90490499]), 'targetState': array([-0.46996213,  0.23538775]), 'effectorPosition': array([-0.74318245, -0.05079026])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9414944649591247
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([-1.38866489, -2.32489294]), 'currentState': array([4.5090086 , 3.86301996]), 'targetState': array([-0.46996213,  0.23538775]), 'effectorPosition': array([-0.69716546, -0.11060143])}
episode index:2392
target Thresh 1.9849475323097383
current state at start:  [ 3.53327134 -2.30466365]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.53327134, -2.30466365]), 'currentState': array([4.00883045, 3.47852166]), 'targetState': array([ 0.08246599, -0.3619086 ]), 'effectorPosition': array([-0.28846432,  0.17099598])}
done in step count: 34
reward sum = 0.7105532272722921
running average episode reward sum: 0.9413979579646881
{'reset': False, 'endBeforeDone': False, 'stepCount': 35, 'initial state': array([ 3.53327134, -2.30466365]), 'currentState': array([4.13945117, 2.79222552]), 'targetState': array([ 0.08246599, -0.3619086 ]), 'effectorPosition': array([ 0.25489282, -0.23632727])}
episode index:2393
target Thresh 1.9849776071602434
current state at start:  [-0.77756174  2.67109857]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.77756174,  2.67109857]), 'currentState': array([5.00562356, 2.87728418]), 'targetState': array([ 0.73201557, -0.11334185]), 'effectorPosition': array([0.26012817, 0.04226774])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9414141242312025
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-0.77756174,  2.67109857]), 'currentState': array([4.73803277, 2.43945722]), 'targetState': array([ 0.73201557, -0.11334185]), 'effectorPosition': array([ 0.65170214, -0.21989725])}
episode index:2394
target Thresh 1.985007621921157
current state at start:  [-3.09618538  2.32107836]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.09618538,  2.32107836]), 'currentState': array([2.68748371, 2.17320183]), 'targetState': array([-0.627564  , -1.07837072]), 'effectorPosition': array([-0.75089865, -0.55036247])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9414344106093939
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.09618538,  2.32107836]), 'currentState': array([3.0411116 , 1.91510159]), 'targetState': array([-0.627564  , -1.07837072]), 'effectorPosition': array([-0.75354054, -0.8701098 ])}
episode index:2395
target Thresh 1.9850375767125383
current state at start:  [ 3.08113827 -1.94065227]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.08113827, -1.94065227]), 'currentState': array([2.81855203, 4.6478027 ]), 'targetState': array([0.06481904, 0.84624192]), 'effectorPosition': array([-0.57028211,  1.24326004])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9410414914063016
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([ 3.08113827, -1.94065227]), 'currentState': array([0.55259288, 1.61875717]), 'targetState': array([0.06481904, 0.84624192]), 'effectorPosition': array([0.286067  , 1.34991879])}
episode index:2396
target Thresh 1.9850674716542067
current state at start:  [-3.16213062  2.1463693 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.16213062,  2.1463693 ]), 'currentState': array([2.62105468, 2.61731934]), 'targetState': array([-0.05195834, -0.10793055]), 'effectorPosition': array([-0.36548661, -0.36748288])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9410619163160193
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.16213062,  2.1463693 ]), 'currentState': array([2.12105468, 2.95451023]), 'targetState': array([-0.05195834, -0.10793055]), 'effectorPosition': array([-0.16766267, -0.08238385])}
episode index:2397
target Thresh 1.9850973068657416
current state at start:  [-1.62483266  2.11972775]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.62483266,  2.11972775]), 'currentState': array([4.22632254, 2.5279447 ]), 'targetState': array([ 0.61537182, -0.05920715]), 'effectorPosition': array([ 0.42392623, -0.43032662])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9410823241907832
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.62483266,  2.11972775]), 'currentState': array([4.62188125, 2.43478848]), 'targetState': array([ 0.61537182, -0.05920715]), 'effectorPosition': array([ 0.62509648, -0.29727446])}
episode index:2398
target Thresh 1.9851270824664842
current state at start:  [-0.06620917  2.31358811]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.06620917,  2.31358811]), 'currentState': array([0.35122722, 2.0939129 ]), 'targetState': array([-0.27968095,  1.03276067]), 'effectorPosition': array([0.17182848, 0.98555076])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9406900431052514
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([-0.06620917,  2.31358811]), 'currentState': array([1.24500587, 1.27197766]), 'targetState': array([-0.27968095,  1.03276067]), 'effectorPosition': array([-0.491134  ,  1.53217827])}
episode index:2399
target Thresh 1.9851567985755367
current state at start:  [-2.71997536  2.12601611]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.71997536,  2.12601611]), 'currentState': array([3.08063268, 2.60292998]), 'targetState': array([-0.3782358 , -0.11659094]), 'effectorPosition': array([-0.17259389, -0.50340876])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9407064639206243
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-2.71997536,  2.12601611]), 'currentState': array([2.1903021 , 2.91809344]), 'targetState': array([-0.3782358 , -0.11659094]), 'effectorPosition': array([-0.1948958 , -0.10844324])}
episode index:2400
target Thresh 1.985186455311764
current state at start:  [-0.9793293   2.60116801]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.9793293 ,  2.60116801]), 'currentState': array([5.80385601, 2.18404359]), 'targetState': array([1.16826709, 0.71345524]), 'effectorPosition': array([0.75378639, 0.52986222])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9407228710576837
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-0.9793293 ,  2.60116801]), 'currentState': array([5.86667114, 1.94397421]), 'targetState': array([1.16826709, 0.71345524]), 'effectorPosition': array([0.9578275 , 0.59448603])}
episode index:2401
target Thresh 1.9852160527937925
current state at start:  [ 2.94621076 -2.29232919]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.94621076, -2.29232919]), 'currentState': array([3.12993929, 3.52914012]), 'targetState': array([-0.27151568, -0.04252177]), 'effectorPosition': array([-0.06975234,  0.37875745])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9407351841838045
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 2.94621076, -2.29232919]), 'currentState': array([4.16359162, 3.32317542]), 'targetState': array([-0.27151568, -0.04252177]), 'effectorPosition': array([-0.16264445,  0.08017846])}
episode index:2402
target Thresh 1.9852455911400126
current state at start:  [-3.05400685  2.09227763]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.05400685,  2.09227763]), 'currentState': array([2.95597035, 2.43148212]), 'targetState': array([ 0.21090485, -0.22712828]), 'effectorPosition': array([-0.35787471, -0.59610909])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9407474870617972
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-3.05400685,  2.09227763]), 'currentState': array([3.45244025, 2.85033244]), 'targetState': array([ 0.21090485, -0.22712828]), 'effectorPosition': array([ 0.04773351, -0.28627959])}
episode index:2403
target Thresh 1.9852750704685775
current state at start:  [-0.1132042 -1.9874087]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.1132042, -1.9874087]), 'currentState': array([5.77153681, 3.79577661]), 'targetState': array([ 0.3948707 , -0.53965462]), 'effectorPosition': array([-0.11792044, -0.63166862])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9403561611520377
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([-0.1132042, -1.9874087]), 'currentState': array([5.05011389, 4.4343872 ]), 'targetState': array([ 0.3948707 , -0.53965462]), 'effectorPosition': array([-0.66687573, -1.00319857])}
episode index:2404
target Thresh 1.985304490897405
current state at start:  [ 3.83633681 -2.25870612]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.83633681, -2.25870612]), 'currentState': array([4.33633681, 3.52718309]), 'targetState': array([ 0.08690225, -0.07414069]), 'effectorPosition': array([-0.3767895 ,  0.06983279])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9403768030808726
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.83633681, -2.25870612]), 'currentState': array([4.83633681, 3.09090084]), 'targetState': array([ 0.08690225, -0.07414069]), 'effectorPosition': array([0.05044019, 0.00498968])}
episode index:2405
target Thresh 1.985333852544176
current state at start:  [1.10325325 2.04410241]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.10325325, 2.04410241]), 'currentState': array([0.65777546, 1.59013028]), 'targetState': array([0.28782856, 0.93213242]), 'effectorPosition': array([0.16481141, 1.39074502])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9399859565293011
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([1.10325325, 2.04410241]), 'currentState': array([0.96553145, 1.799237  ]), 'targetState': array([0.28782856, 0.93213242]), 'effectorPosition': array([-0.36085799,  1.19032078])}
episode index:2406
target Thresh 1.9853631555263378
current state at start:  [ 0.65698231 -2.24635148]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.65698231, -2.24635148]), 'currentState': array([1.15698231, 3.55649341]), 'targetState': array([0.55801316, 0.58894402]), 'effectorPosition': array([ 0.40319107, -0.08440555])}
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.9399600051651423
{'reset': False, 'endBeforeDone': False, 'stepCount': 14, 'initial state': array([ 0.65698231, -2.24635148]), 'currentState': array([6.05492644, 2.4072707 ]), 'targetState': array([0.55801316, 0.58894402]), 'effectorPosition': array([0.40265796, 0.59438709])}
episode index:2407
target Thresh 1.9853923999611023
current state at start:  [ 0.55400841 -2.93052793]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.55400841, -2.93052793]), 'currentState': array([0.05400841, 3.82832762]), 'targetState': array([-0.24783957, -0.96328465]), 'effectorPosition': array([ 0.2605748 , -0.62085453])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9399766745982134
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 0.55400841, -2.93052793]), 'currentState': array([5.33719372, 4.14595361]), 'targetState': array([-0.24783957, -0.96328465]), 'effectorPosition': array([-0.41335808, -0.86941358])}
episode index:2408
target Thresh 1.9854215859654472
current state at start:  [-1.49643722  1.6989802 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.49643722,  1.6989802 ]), 'currentState': array([4.28674808, 2.0981481 ]), 'targetState': array([ 0.51190483, -0.08253702]), 'effectorPosition': array([ 0.58192733, -0.80923869])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9399892616988368
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-1.49643722,  1.6989802 ]), 'currentState': array([4.67530835, 2.66228232]), 'targetState': array([ 0.51190483, -0.08253702]), 'effectorPosition': array([ 0.45667278, -0.12970581])}
episode index:2409
target Thresh 1.9854507136561164
current state at start:  [-2.92325903  2.25239361]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.92325903,  2.25239361]), 'currentState': array([3.01897225, 2.59837676]), 'targetState': array([ 0.24385637, -0.13766475]), 'effectorPosition': array([-0.20609107, -0.49540366])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.939997812216804
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([-2.92325903,  2.25239361]), 'currentState': array([4.01678976, 2.6994943 ]), 'targetState': array([ 0.24385637, -0.13766475]), 'effectorPosition': array([ 0.26682405, -0.34798437])}
episode index:2410
target Thresh 1.9854797831496207
current state at start:  [-1.23912524  2.37714111]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.23912524,  2.37714111]), 'currentState': array([4.75939863, 1.87714111]), 'targetState': array([ 1.22468302, -0.38632117]), 'effectorPosition': array([ 0.98520954, -0.65284831])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9400185514070915
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.23912524,  2.37714111]), 'currentState': array([5.04939034, 1.60203444]), 'targetState': array([ 1.22468302, -0.38632117]), 'effectorPosition': array([ 1.26362114, -0.58377695])}
episode index:2411
target Thresh 1.9855087945622383
current state at start:  [-3.30017749  2.47879752]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.30017749,  2.47879752]), 'currentState': array([2.53004569, 2.45479384]), 'targetState': array([-0.55514327, -0.34366004]), 'effectorPosition': array([-0.54966843, -0.38897962])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9400434193376855
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.30017749,  2.47879752]), 'currentState': array([2.53004569, 2.45479384]), 'targetState': array([-0.55514327, -0.34366004]), 'effectorPosition': array([-0.54966843, -0.38897962])}
episode index:2412
target Thresh 1.985537748010015
current state at start:  [ 0.4437151  -1.94265619]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.4437151 , -1.94265619]), 'currentState': array([6.25608507, 4.49915439]), 'targetState': array([ 1.10218481, -0.65182601]), 'effectorPosition': array([ 0.76160497, -0.99835525])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9396538447751751
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([ 0.4437151 , -1.94265619]), 'currentState': array([5.83465441, 4.19124924]), 'targetState': array([ 1.10218481, -0.65182601]), 'effectorPosition': array([ 0.07638566, -0.9992134 ])}
episode index:2413
target Thresh 1.9855666436087642
current state at start:  [ 1.52081658 -2.77681489]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.52081658, -2.77681489]), 'currentState': array([1.60418109, 3.92729758]), 'targetState': array([ 0.65628541, -0.15076683]), 'effectorPosition': array([0.69714594, 0.31655629])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9396705996033545
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 1.52081658, -2.77681489]), 'currentState': array([1.1121268 , 3.99568951]), 'targetState': array([ 0.65628541, -0.15076683]), 'effectorPosition': array([ 0.82795811, -0.02618967])}
episode index:2414
target Thresh 1.9855954814740688
current state at start:  [1.48299775 1.91383577]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.48299775, 1.91383577]), 'currentState': array([1.82137126, 2.34627125]), 'targetState': array([-0.81592683,  0.19414363]), 'effectorPosition': array([-0.76616225,  0.11351132])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9396955807215311
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.48299775, 1.91383577]), 'currentState': array([1.82137126, 2.34627125]), 'targetState': array([-0.81592683,  0.19414363]), 'effectorPosition': array([-0.76616225,  0.11351132])}
episode index:2415
target Thresh 1.98562426172128
current state at start:  [-0.1430219   1.91678193]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.1430219 ,  1.91678193]), 'currentState': array([0.28066281, 1.7572743 ]), 'targetState': array([0.06078118, 1.35470063]), 'effectorPosition': array([0.5105368 , 1.16985213])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9397164020871265
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.1430219 ,  1.91678193]), 'currentState': array([0.73579077, 1.48326925]), 'targetState': array([0.06078118, 1.35470063]), 'effectorPosition': array([0.137497  , 1.46830695])}
episode index:2416
target Thresh 1.985652984465519
current state at start:  [ 1.06948066 -2.56551231]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.06948066, -2.56551231]), 'currentState': array([1.46297741, 3.27079528]), 'targetState': array([ 0.33044528, -0.00220362]), 'effectorPosition': array([ 0.12899222, -0.00557821])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9397413435839874
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.06948066, -2.56551231]), 'currentState': array([1.46297741, 3.27079528]), 'targetState': array([ 0.33044528, -0.00220362]), 'effectorPosition': array([ 0.12899222, -0.00557821])}
episode index:2417
target Thresh 1.9856816498216767
current state at start:  [ 3.92235484 -2.96218375]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.92235484, -2.96218375]), 'currentState': array([4.32881772, 2.82100156]), 'targetState': array([0.70739815, 0.78827597]), 'effectorPosition': array([ 0.27316104, -0.16517996])}
done in step count: 88
reward sum = 0.41294967113388814
running average episode reward sum: 0.9395234810230072
{'reset': False, 'endBeforeDone': False, 'stepCount': 89, 'initial state': array([ 3.92235484, -2.96218375]), 'currentState': array([6.06710454, 2.24557005]), 'targetState': array([0.70739815, 0.78827597]), 'effectorPosition': array([0.53396869, 0.6822288 ])}
episode index:2418
target Thresh 1.9857102579044146
current state at start:  [-3.58533135  1.84439935]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.58533135,  1.84439935]), 'currentState': array([2.19785396, 2.02672916]), 'targetState': array([-0.82430933,  0.12555328]), 'effectorPosition': array([-1.0554535 , -0.07360586])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9395443477112986
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.58533135,  1.84439935]), 'currentState': array([1.72166891, 2.3728533 ]), 'targetState': array([-0.82430933,  0.12555328]), 'effectorPosition': array([-0.72959851,  0.17352422])}
episode index:2419
target Thresh 1.9857388088281651
current state at start:  [0.71832615 2.55207878]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.71832615, 2.55207878]), 'currentState': array([0.75243773, 3.00187793]), 'targetState': array([-0.90892505, -0.42627049]), 'effectorPosition': array([-0.08806001,  0.10832315])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.9395412572155117
{'reset': False, 'endBeforeDone': False, 'stepCount': 8, 'initial state': array([0.71832615, 2.55207878]), 'currentState': array([4.82966808, 4.24515409]), 'targetState': array([-0.90892505, -0.42627049]), 'effectorPosition': array([-0.82237744, -0.65027441])}
episode index:2420
target Thresh 1.9857673027071319
current state at start:  [-1.89813322 -2.3615104 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.89813322, -2.3615104 ]), 'currentState': array([4.88505209, 4.25810111]), 'targetState': array([-0.65064017, -0.74637974]), 'effectorPosition': array([-0.78879869, -0.70721395])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.939566229847806
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.89813322, -2.3615104 ]), 'currentState': array([4.88505209, 4.25810111]), 'targetState': array([-0.65064017, -0.74637974]), 'effectorPosition': array([-0.78879869, -0.70721395])}
episode index:2421
target Thresh 1.9857957396552903
current state at start:  [ 3.65842699 -1.84431827]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.65842699, -1.84431827]), 'currentState': array([4.15842699, 4.19420952]), 'targetState': array([-1.05320489, -0.39329184]), 'effectorPosition': array([-1.00430546,  0.0277797 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.939587053039446
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.65842699, -1.84431827]), 'currentState': array([4.65842699, 4.32558489]), 'targetState': array([-1.05320489, -0.39329184]), 'effectorPosition': array([-0.9583609 , -0.57191195])}
episode index:2422
target Thresh 1.9858241197863886
current state at start:  [ 2.40353258 -2.0698283 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.40353258, -2.0698283 ]), 'currentState': array([2.80840625, 4.70288319]), 'targetState': array([0.02886103, 0.66158366]), 'effectorPosition': array([-0.60898106,  1.26890929])}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.939580102004113
{'reset': False, 'endBeforeDone': False, 'stepCount': 9, 'initial state': array([ 2.40353258, -2.0698283 ]), 'currentState': array([0.33891751, 2.41969788]), 'targetState': array([0.02886103, 0.66158366]), 'effectorPosition': array([0.01555891, 0.70615007])}
episode index:2423
target Thresh 1.9858524432139473
current state at start:  [-1.69725372 -2.01091868]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.69725372, -2.01091868]), 'currentState': array([5.06044077, 4.53140628]), 'targetState': array([-0.70846924, -0.74642581]), 'effectorPosition': array([-0.64500933, -1.10633193])}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9395731567039578
{'reset': False, 'endBeforeDone': False, 'stepCount': 9, 'initial state': array([-1.69725372, -2.01091868]), 'currentState': array([4.91727515, 4.46457425]), 'targetState': array([-0.70846924, -0.74642581]), 'effectorPosition': array([-0.795623  , -0.93616877])}
episode index:2424
target Thresh 1.9858807100512597
current state at start:  [2.23994255 1.77740469]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.23994255, 1.77740469]), 'currentState': array([2.21385939, 1.85176995]), 'targetState': array([-1.25983021, -0.20696249]), 'effectorPosition': array([-1.20225314,  0.00222211])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.939598074989853
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.23994255, 1.77740469]), 'currentState': array([2.21385939, 1.85176995]), 'targetState': array([-1.25983021, -0.20696249]), 'effectorPosition': array([-1.20225314,  0.00222211])}
episode index:2425
target Thresh 1.9859089204113936
current state at start:  [-0.96348922 -2.03467694]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.96348922, -2.03467694]), 'currentState': array([5.21804975, 4.40811375]), 'targetState': array([ 0.39380869, -0.82632279]), 'effectorPosition': array([-0.49540474, -1.07488166])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9392107715788928
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([-0.96348922, -2.03467694]), 'currentState': array([5.25442588, 4.18017841]), 'targetState': array([ 0.39380869, -0.82632279]), 'effectorPosition': array([-0.48406973, -0.86648583])}
episode index:2426
target Thresh 1.9859370744071905
current state at start:  [-2.34764785  1.87499133]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.34764785,  1.87499133]), 'currentState': array([4.29538387, 2.15128851]), 'targetState': array([ 0.23656156, -0.80542501]), 'effectorPosition': array([ 0.5816417 , -0.75154627])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9392316983314353
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.34764785,  1.87499133]), 'currentState': array([3.97797957, 2.17067857]), 'targetState': array([ 0.23656156, -0.80542501]), 'effectorPosition': array([ 0.32081594, -0.87634843])}
episode index:2427
target Thresh 1.985965172151266
current state at start:  [-0.3769355   2.81989745]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.3769355 ,  2.81989745]), 'currentState': array([5.46804191, 3.31989745]), 'targetState': array([ 1.05211356, -0.46249024]), 'effectorPosition': array([-0.11821569, -0.13316723])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9388448648477733
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([-0.3769355 ,  2.81989745]), 'currentState': array([5.90302224, 4.11608078]), 'targetState': array([ 1.05211356, -0.46249024]), 'effectorPosition': array([ 0.10007752, -0.93102158])}
episode index:2428
target Thresh 1.9859932137560115
current state at start:  [ 3.17277311 -2.71123321]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.17277311, -2.71123321]), 'currentState': array([3.40110101, 3.94734936]), 'targetState': array([0.88080825, 0.70552085]), 'effectorPosition': array([-0.48224393,  0.61831192])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.9388459497734847
{'reset': False, 'endBeforeDone': False, 'stepCount': 7, 'initial state': array([ 3.17277311, -2.71123321]), 'currentState': array([6.20262133, 1.71584683]), 'targetState': array([0.88080825, 0.70552085]), 'effectorPosition': array([0.93231464, 0.91744461])}
episode index:2429
target Thresh 1.9860211993335934
current state at start:  [ 1.80929317 -2.96769632]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.80929317, -2.96769632]), 'currentState': array([2.14309718, 3.13274608]), 'targetState': array([ 0.0726463 , -0.26578628]), 'effectorPosition': array([-0.00745803, -0.00475806])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9388549004155532
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([ 1.80929317, -2.96769632]), 'currentState': array([2.82909414, 2.78687337]), 'targetState': array([ 0.0726463 , -0.26578628]), 'effectorPosition': array([-0.16602207, -0.31136574])}
episode index:2430
target Thresh 1.9860491289959539
current state at start:  [-1.35820081 -2.64754273]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.35820081, -2.64754273]), 'currentState': array([4.8027954 , 3.15579834]), 'targetState': array([0.27084239, 0.69578774]), 'effectorPosition': array([-0.01413808, -0.00138298])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9388638436938683
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([-1.35820081, -2.64754273]), 'currentState': array([0.19094436, 2.41670962]), 'targetState': array([0.27084239, 0.69578774]), 'effectorPosition': array([0.12101619, 0.6987139 ])}
episode index:2431
target Thresh 1.9860770028548118
current state at start:  [-1.4068932   1.75991513]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.4068932 ,  1.75991513]), 'currentState': array([4.40366643, 1.37266405]), 'targetState': array([ 0.44271415, -1.22622813]), 'effectorPosition': array([ 0.57043376, -1.43815239])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9388889819160336
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.4068932 ,  1.75991513]), 'currentState': array([4.40366643, 1.37266405]), 'targetState': array([ 0.44271415, -1.22622813]), 'effectorPosition': array([ 0.57043376, -1.43815239])}
episode index:2432
target Thresh 1.9861048210216627
current state at start:  [-1.84083836 -2.37012686]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.84083836, -2.37012686]), 'currentState': array([3.97570037, 4.17283415]), 'targetState': array([-0.72059105,  0.46017467]), 'effectorPosition': array([-0.96215088,  0.21623471])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.938901891911136
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-1.84083836, -2.37012686]), 'currentState': array([3.83308088, 4.19445415]), 'targetState': array([-0.72059105,  0.46017467]), 'effectorPosition': array([-0.94298129,  0.34729311])}
episode index:2433
target Thresh 1.986132583607779
current state at start:  [ 3.38484213 -1.64394709]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.38484213, -1.64394709]), 'currentState': array([3.86958417, 4.2554763 ]), 'targetState': array([-0.88067435, -0.16112242]), 'effectorPosition': array([-1.01428333,  0.29811095])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9389228853820024
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.38484213, -1.64394709]), 'currentState': array([4.35820898, 4.12031511]), 'targetState': array([-0.88067435, -0.16112242]), 'effectorPosition': array([-0.93154754, -0.12670046])}
episode index:2434
target Thresh 1.9861602907242113
current state at start:  [ 1.54566689 -2.03420787]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.54566689, -2.03420787]), 'currentState': array([1.44252092, 3.75465937]), 'targetState': array([0.04891071, 0.02839629]), 'effectorPosition': array([0.59394764, 0.10701177])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9389438616097715
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.54566689, -2.03420787]), 'currentState': array([1.80098856, 3.25465937]), 'targetState': array([0.04891071, 0.02839629]), 'effectorPosition': array([0.10839302, 0.03195971])}
episode index:2435
target Thresh 1.986187942481788
current state at start:  [-3.24248714  2.51145471]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.24248714,  2.51145471]), 'currentState': array([3.41578334, 2.03948898]), 'targetState': array([-0.38794699, -1.00124745]), 'effectorPosition': array([-0.28623028, -1.00728923])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9389689257059908
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.24248714,  2.51145471]), 'currentState': array([3.41578334, 2.03948898]), 'targetState': array([-0.38794699, -1.00124745]), 'effectorPosition': array([-0.28623028, -1.00728923])}
episode index:2436
target Thresh 1.9862155389911165
current state at start:  [-3.67644805  1.79296745]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.67644805,  1.79296745]), 'currentState': array([2.74911025, 2.17698116]), 'targetState': array([-0.49948376, -0.80634023]), 'effectorPosition': array([-0.71188287, -0.59476917])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9389858034549831
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-3.67644805,  1.79296745]), 'currentState': array([2.85975913, 2.28101177]), 'targetState': array([-0.49948376, -0.80634023]), 'effectorPosition': array([-0.54514764, -0.63152179])}
episode index:2437
target Thresh 1.9862430803625821
current state at start:  [ 1.0928869  -1.81888135]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.0928869 , -1.81888135]), 'currentState': array([1.56387464, 3.96752228]), 'targetState': array([0.39018823, 1.10896247]), 'effectorPosition': array([0.7373903 , 0.31702983])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9390067280639022
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.0928869 , -1.81888135]), 'currentState': array([2.03152729, 4.33948715]), 'targetState': array([0.39018823, 1.10896247]), 'effectorPosition': array([0.55154253, 0.98344401])}
episode index:2438
target Thresh 1.9862705667063512
current state at start:  [-1.80130218  2.61752382]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.80130218,  2.61752382]), 'currentState': array([4.96308972, 2.11752382]), 'targetState': array([1.08787275, 0.44891648]), 'effectorPosition': array([ 0.94663213, -0.25317687])}
done in step count: 25
reward sum = 0.7778213593991467
running average episode reward sum: 0.938940641401883
{'reset': False, 'endBeforeDone': False, 'stepCount': 26, 'initial state': array([-1.80130218,  2.61752382]), 'currentState': array([5.62453574, 2.15337118]), 'targetState': array([1.08787275, 0.44891648]), 'effectorPosition': array([0.86682084, 0.38505825])}
episode index:2439
target Thresh 1.9862979981323687
current state at start:  [-1.2862173   2.17390868]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.2862173 ,  2.17390868]), 'currentState': array([4.55611497, 2.48509076]), 'targetState': array([ 0.02080622, -0.07462403]), 'effectorPosition': array([ 0.57055965, -0.30032881])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9389615673685215
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.2862173 ,  2.17390868]), 'currentState': array([4.10499904, 2.84415993]), 'targetState': array([ 0.02080622, -0.07462403]), 'effectorPosition': array([ 0.21558942, -0.20331541])}
episode index:2440
target Thresh 1.9863253747503604
current state at start:  [-3.30427286  2.34347918]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.30427286,  2.34347918]), 'currentState': array([3.09168266, 2.69975694]), 'targetState': array([ 0.5079454 , -0.12960602]), 'effectorPosition': array([-0.11724481, -0.42227619])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9389744053171621
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-3.30427286,  2.34347918]), 'currentState': array([4.55853023, 2.52004087]), 'targetState': array([ 0.5079454 , -0.12960602]), 'effectorPosition': array([ 0.54675688, -0.27405335])}
episode index:2441
target Thresh 1.9863526966698328
current state at start:  [-0.41608388  3.08936505]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.41608388,  3.08936505]), 'currentState': array([5.37896755, 3.58936505]), 'targetState': array([ 0.56293407, -0.83362102]), 'effectorPosition': array([-0.27932434, -0.34518157])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9385898949136743
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([-0.41608388,  3.08936505]), 'currentState': array([5.196805  , 4.59371799]), 'targetState': array([ 0.56293407, -0.83362102]), 'effectorPosition': array([-0.46816591, -1.24259221])}
episode index:2442
target Thresh 1.9863799640000739
current state at start:  [ 1.54746841 -1.9448169 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.54746841, -1.9448169 ]), 'currentState': array([2.04340886, 4.83836841]), 'targetState': array([0.35746418, 1.15030087]), 'effectorPosition': array([0.37091585, 1.45386188])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.9385872242026606
{'reset': False, 'endBeforeDone': False, 'stepCount': 8, 'initial state': array([ 1.54746841, -1.9448169 ]), 'currentState': array([0.53602648, 1.70912748]), 'targetState': array([0.35746418, 1.15030087]), 'effectorPosition': array([0.23534915, 1.29183202])}
episode index:2443
target Thresh 1.9864071768501528
current state at start:  [ 0.97189107 -1.98675757]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.97189107, -1.98675757]), 'currentState': array([0.47189107, 3.86937959]), 'targetState': array([ 0.17810162, -0.86192841]), 'effectorPosition': array([ 0.52805241, -0.47735087])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9382031868768821
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([ 0.97189107, -1.98675757]), 'currentState': array([5.24569309, 4.35364355]), 'targetState': array([ 0.17810162, -0.86192841]), 'effectorPosition': array([-0.4764219 , -1.03480556])}
episode index:2444
target Thresh 1.9864343353289209
current state at start:  [-0.4798282   2.98704238]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.4798282 ,  2.98704238]), 'currentState': array([5.30335711, 3.41908239]), 'targetState': array([-0.386066  , -0.30668066]), 'effectorPosition': array([-0.2061684 , -0.18439718])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9382284616470756
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.4798282 ,  2.98704238]), 'currentState': array([5.30335711, 3.41908239]), 'targetState': array([-0.386066  , -0.30668066]), 'effectorPosition': array([-0.2061684 , -0.18439718])}
episode index:2445
target Thresh 1.9864614395450122
current state at start:  [-0.27482694 -2.21516446]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.27482694, -2.21516446]), 'currentState': array([5.50835836, 3.72213301]), 'targetState': array([ 0.2010881 , -0.65359808]), 'effectorPosition': array([-0.26664354, -0.50652584])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9378448850069909
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([-0.27482694, -2.21516446]), 'currentState': array([4.58726733, 4.82426369]), 'targetState': array([ 0.2010881 , -0.65359808]), 'effectorPosition': array([-1.12470769, -0.97893594])}
episode index:2446
target Thresh 1.9864884896068435
current state at start:  [1.55227135 2.09135122]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.55227135, 2.09135122]), 'currentState': array([1.14570828, 2.31705921]), 'targetState': array([-0.08039751,  0.29994745]), 'effectorPosition': array([-0.5364642 ,  0.59532088])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9378621531373519
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([1.55227135, 2.09135122]), 'currentState': array([0.60352881, 2.86141374]), 'targetState': array([-0.08039751,  0.29994745]), 'effectorPosition': array([-0.12483836,  0.24980677])}
episode index:2447
target Thresh 1.9865154856226155
current state at start:  [-3.41049219  1.9826075 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.41049219,  1.9826075 ]), 'currentState': array([2.45119777, 1.6814812 ]), 'targetState': array([-0.9562209 , -0.23763194]), 'effectorPosition': array([-1.31877595, -0.19977985])}
done in step count: 34
reward sum = 0.7105532272722921
running average episode reward sum: 0.9377692981839756
{'reset': False, 'endBeforeDone': False, 'stepCount': 35, 'initial state': array([-3.41049219,  1.9826075 ]), 'currentState': array([2.50226935, 2.14927642]), 'targetState': array([-0.9562209 , -0.23763194]), 'effectorPosition': array([-0.86330537, -0.4014971 ])}
episode index:2448
target Thresh 1.9865424277003119
current state at start:  [ 0.82748617 -2.99104483]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.82748617, -2.99104483]), 'currentState': array([0.32748617, 3.67514929]), 'targetState': array([ 1.09122714, -0.2135362 ]), 'effectorPosition': array([ 0.29520711, -0.4368587 ])}
done in step count: 28
reward sum = 0.7547192872036326
running average episode reward sum: 0.9376945533856985
{'reset': False, 'endBeforeDone': False, 'stepCount': 29, 'initial state': array([ 0.82748617, -2.99104483]), 'currentState': array([5.04566151, 2.07517352]), 'targetState': array([ 1.09122714, -0.2135362 ]), 'effectorPosition': array([ 0.99634834, -0.2019045 ])}
episode index:2449
target Thresh 1.9865693159477011
current state at start:  [0.52847243 2.12629589]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.52847243, 2.12629589]), 'currentState': array([0.97499792, 2.57702213]), 'targetState': array([-0.96972593,  0.33883043]), 'effectorPosition': array([-0.3557806 ,  0.42869945])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9377118617312554
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([0.52847243, 2.12629589]), 'currentState': array([1.92776657, 1.81211346]), 'targetState': array([-0.96972593,  0.33883043]), 'effectorPosition': array([-1.1757385 ,  0.37373167])}
episode index:2450
target Thresh 1.9865961504723362
current state at start:  [0.14718333 2.99668103]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.14718333, 2.99668103]), 'currentState': array([0.61534897, 2.49668103]), 'targetState': array([-0.23236521,  0.68073754]), 'effectorPosition': array([-0.182991  ,  0.60680187])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9377372750883622
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.14718333, 2.99668103]), 'currentState': array([0.61534897, 2.49668103]), 'targetState': array([-0.23236521,  0.68073754]), 'effectorPosition': array([-0.182991  ,  0.60680187])}
episode index:2451
target Thresh 1.9866229313815553
current state at start:  [-3.3717479   2.68578439]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.3717479 ,  2.68578439]), 'currentState': array([3.4114374 , 2.96575101]), 'targetState': array([ 0.70601539, -0.38937695]), 'effectorPosition': array([ 0.03177267, -0.17271709])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9377505547477879
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-3.3717479 ,  2.68578439]), 'currentState': array([4.70112092, 2.43462433]), 'targetState': array([ 0.70601539, -0.38937695]), 'effectorPosition': array([ 0.64678993, -0.24696905])}
episode index:2452
target Thresh 1.9866496587824822
current state at start:  [ 1.32210829 -2.26641048]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.32210829, -2.26641048]), 'currentState': array([1.78855487, 3.52926478]), 'targetState': array([-0.07687431,  0.15553228]), 'effectorPosition': array([0.3530746 , 0.15412707])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9377718549700675
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.32210829, -2.26641048]), 'currentState': array([2.28855487, 3.13108611]), 'targetState': array([-0.07687431,  0.15553228]), 'effectorPosition': array([-0.00795054, -0.00686843])}
episode index:2453
target Thresh 1.9866763327820263
current state at start:  [ 1.47653667 -2.30728573]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.47653667, -2.30728573]), 'currentState': array([1.27300208, 3.47589957]), 'targetState': array([ 0.51614423, -0.25261569]), 'effectorPosition': array([ 0.32991681, -0.04334748])}
done in step count: 18
reward sum = 0.8345137614500875
running average episode reward sum: 0.9377297775073455
{'reset': False, 'endBeforeDone': False, 'stepCount': 19, 'initial state': array([ 1.47653667, -2.30728573]), 'currentState': array([1.14698711, 3.51227671]), 'targetState': array([ 0.51614423, -0.25261569]), 'effectorPosition': array([ 0.35813546, -0.08706012])}
episode index:2454
target Thresh 1.9867029534868839
current state at start:  [-0.21249369  2.92344716]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.21249369,  2.92344716]), 'currentState': array([5.57069161, 3.39910731]), 'targetState': array([0.74835117, 0.05738027]), 'effectorPosition': array([-0.14153619, -0.21427938])}
done in step count: 108
reward sum = 0.337754400898902
running average episode reward sum: 0.9374853883519042
{'reset': False, 'endBeforeDone': False, 'stepCount': 109, 'initial state': array([-0.21249369,  2.92344716]), 'currentState': array([5.01641509, 2.61728002]), 'targetState': array([0.74835117, 0.05738027]), 'effectorPosition': array([0.51787333, 0.02169593])}
episode index:2455
target Thresh 1.9867295210035376
current state at start:  [0.00506162 2.04077156]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.00506162, 2.04077156]), 'currentState': array([0.41494613, 1.85063002]), 'targetState': array([0.56552845, 0.95001343]), 'effectorPosition': array([0.27492172, 1.17133531])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9375067705227706
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.00506162, 2.04077156]), 'currentState': array([0.14740028, 1.95133073]), 'targetState': array([0.56552845, 0.95001343]), 'effectorPosition': array([0.48540593, 1.01071642])}
episode index:2456
target Thresh 1.9867560354382576
current state at start:  [-1.18748123  1.74933269]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.18748123,  1.74933269]), 'currentState': array([4.59570407, 2.03411355]), 'targetState': array([ 0.28924475, -0.53049079]), 'effectorPosition': array([ 0.82410185, -0.65346768])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9375281352885325
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.18748123,  1.74933269]), 'currentState': array([4.09570407, 2.41840159]), 'targetState': array([ 0.28924475, -0.53049079]), 'effectorPosition': array([ 0.39512227, -0.58692662])}
episode index:2457
target Thresh 1.9867824968971017
current state at start:  [-0.13960875 -1.78459416]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.13960875, -1.78459416]), 'currentState': array([5.64357655, 4.04558834]), 'targetState': array([ 0.56196904, -0.68262166]), 'effectorPosition': array([-0.16292354, -0.85819913])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9371467161936227
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([-0.13960875, -1.78459416]), 'currentState': array([4.45452348, 4.30707673]), 'targetState': array([ 0.56196904, -0.68262166]), 'effectorPosition': array([-1.04305712, -0.35131236])}
episode index:2458
target Thresh 1.986808905485916
current state at start:  [-3.12540915  1.75499098]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.12540915,  1.75499098]), 'currentState': array([2.65777616, 2.21779336]), 'targetState': array([-0.2184008 , -0.12247487]), 'effectorPosition': array([-0.72276878, -0.52155456])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9371682100056625
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.12540915,  1.75499098]), 'currentState': array([2.16543235, 2.70564331]), 'targetState': array([-0.2184008 , -0.12247487]), 'effectorPosition': array([-0.40218577, -0.15908321])}
episode index:2459
target Thresh 1.9868352613103344
current state at start:  [-1.99070508  2.34303273]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.99070508,  2.34303273]), 'currentState': array([4.17481132, 1.96812601]), 'targetState': array([ 0.40899605, -0.85698659]), 'effectorPosition': array([ 0.47812453, -0.99874024])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.937193751383709
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.99070508,  2.34303273]), 'currentState': array([4.17481132, 1.96812601]), 'targetState': array([ 0.40899605, -0.85698659]), 'effectorPosition': array([ 0.47812453, -0.99874024])}
episode index:2460
target Thresh 1.9868615644757806
current state at start:  [-1.2621453   2.21201143]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.2621453 ,  2.21201143]), 'currentState': array([4.57259984, 2.56948665]), 'targetState': array([ 0.29163064, -0.23864526]), 'effectorPosition': array([ 0.51393549, -0.2331202 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9372192720048452
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.2621453 ,  2.21201143]), 'currentState': array([4.57259984, 2.56948665]), 'targetState': array([ 0.29163064, -0.23864526]), 'effectorPosition': array([ 0.51393549, -0.2331202 ])}
episode index:2461
target Thresh 1.9868878150874671
current state at start:  [-0.91695641  2.0183491 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.91695641,  2.0183491 ]), 'currentState': array([5.8662289 , 2.38589575]), 'targetState': array([0.19757605, 0.77432729]), 'effectorPosition': array([0.52661849, 0.51680305])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9372407101559399
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.91695641,  2.0183491 ]), 'currentState': array([0.07361357, 2.30683703]), 'targetState': array([0.19757605, 0.77432729]), 'effectorPosition': array([0.273243 , 0.7632959])}
episode index:2462
target Thresh 1.9869140132503966
current state at start:  [-3.62748651  2.12285985]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.62748651,  2.12285985]), 'currentState': array([3.1556988 , 2.51318682]), 'targetState': array([-0.20698248, -1.2168398 ]), 'effectorPosition': array([-0.18272321, -0.59049206])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9372621308988728
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.62748651,  2.12285985]), 'currentState': array([3.6556988 , 2.01318682]), 'targetState': array([-0.20698248, -1.2168398 ]), 'effectorPosition': array([-0.05355533, -1.06814312])}
episode index:2463
target Thresh 1.9869401590693614
current state at start:  [ 1.9472839  -2.50267293]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.9472839 , -2.50267293]), 'currentState': array([2.4035546 , 3.91107446]), 'targetState': array([-0.11499876,  0.39622433]), 'effectorPosition': array([0.25971563, 0.70427635])}
done in step count: 80
reward sum = 0.4475232137638106
running average episode reward sum: 0.9370633732214642
{'reset': False, 'endBeforeDone': False, 'stepCount': 81, 'initial state': array([ 1.9472839 , -2.50267293]), 'currentState': array([1.06311834, 2.73297146]), 'targetState': array([-0.11499876,  0.39622433]), 'effectorPosition': array([-0.30720474,  0.26511533])}
episode index:2464
target Thresh 1.9869662526489453
current state at start:  [0.451247   2.18283885]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.451247  , 2.18283885]), 'currentState': array([0.74183544, 2.68283885]), 'targetState': array([-0.33159013,  0.50531097]), 'effectorPosition': array([-0.22296955,  0.39632623])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9370889053215771
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.451247  , 2.18283885]), 'currentState': array([0.74183544, 2.68283885]), 'targetState': array([-0.33159013,  0.50531097]), 'effectorPosition': array([-0.22296955,  0.39632623])}
episode index:2465
target Thresh 1.9869922940935223
current state at start:  [2.10507883 1.85523321]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.10507883, 1.85523321]), 'currentState': array([2.60507883, 2.35523321]), 'targetState': array([-0.73079643, -0.69561159]), 'effectorPosition': array([-0.61410478, -0.45828142])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9371103615643501
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([2.10507883, 1.85523321]), 'currentState': array([2.65902949, 2.05193739]), 'targetState': array([-0.73079643, -0.69561159]), 'effectorPosition': array([-0.88723049, -0.53594782])}
episode index:2466
target Thresh 1.9870182835072585
current state at start:  [-0.5560497   2.33062142]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.5560497 ,  2.33062142]), 'currentState': array([6.22713561, 2.31426729]), 'targetState': array([-0.00584496,  1.19237099]), 'effectorPosition': array([0.3638834 , 0.71686455])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9371318004125201
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.5560497 ,  2.33062142]), 'currentState': array([0.4439503 , 1.93587346]), 'targetState': array([-0.00584496,  1.19237099]), 'effectorPosition': array([0.17944577, 1.1197127 ])}
episode index:2467
target Thresh 1.9870442209941113
current state at start:  [-1.46470151 -1.78299453]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.46470151, -1.78299453]), 'currentState': array([4.38359103, 4.37523854]), 'targetState': array([-0.01996652, -0.04348642]), 'effectorPosition': array([-1.10923683, -0.32862602])}
done in step count: 21
reward sum = 0.8097278682212584
running average episode reward sum: 0.9370801780737068
{'reset': False, 'endBeforeDone': False, 'stepCount': 22, 'initial state': array([-1.46470151, -1.78299453]), 'currentState': array([4.75018668, 3.39211895]), 'targetState': array([-0.01996652, -0.04348642]), 'effectorPosition': array([-0.24655711, -0.04056397])}
episode index:2468
target Thresh 1.9870701066578307
current state at start:  [2.08487996 1.62691087]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.08487996, 1.62691087]), 'currentState': array([1.58487996, 2.02088884]), 'targetState': array([-0.44680926,  0.65570399]), 'effectorPosition': array([-0.90827387,  0.55221456])}
done in step count: 29
reward sum = 0.7471720943315961
running average episode reward sum: 0.937003261069356
{'reset': False, 'endBeforeDone': False, 'stepCount': 30, 'initial state': array([2.08487996, 1.62691087]), 'currentState': array([1.2306101 , 2.10923335]), 'targetState': array([-0.44680926,  0.65570399]), 'effectorPosition': array([-0.64674994,  0.74573785])}
episode index:2469
target Thresh 1.9870959406019597
current state at start:  [-1.50254587 -2.01363086]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.50254587, -2.01363086]), 'currentState': array([4.28063944, 4.34773446]), 'targetState': array([-0.80298551, -0.16895995]), 'effectorPosition': array([-1.1177422 , -0.19338888])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9370207091417977
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.50254587, -2.01363086]), 'currentState': array([4.3472265 , 3.93130306]), 'targetState': array([-0.80298551, -0.16895995]), 'effectorPosition': array([-0.76900995, -0.02284071])}
episode index:2470
target Thresh 1.9871217229298337
current state at start:  [-1.4753598  -2.64054765]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.4753598 , -2.64054765]), 'currentState': array([4.31631309, 3.32339572]), 'targetState': array([-0.07421363,  0.32115549]), 'effectorPosition': array([-0.17316407,  0.05454926])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9366415020559451
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([-1.4753598 , -2.64054765]), 'currentState': array([4.49762843, 3.39895117]), 'targetState': array([-0.07421363,  0.32115549]), 'effectorPosition': array([-0.25569857,  0.02206539])}
episode index:2471
target Thresh 1.9871474537445823
current state at start:  [-1.27369114  2.41450016]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.27369114,  2.41450016]), 'currentState': array([4.50949416, 2.81614171]), 'targetState': array([-0.01551521,  0.17033329]), 'effectorPosition': array([ 0.30259975, -0.1158452 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.936663087208835
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.27369114,  2.41450016]), 'currentState': array([4.20402516, 3.22091009]), 'targetState': array([-0.01551521,  0.17033329]), 'effectorPosition': array([-0.07074482,  0.03582079])}
episode index:2472
target Thresh 1.987173133149129
current state at start:  [-1.41841453 -2.6248019 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.41841453, -2.6248019 ]), 'currentState': array([4.36477077, 3.85220933]), 'targetState': array([-0.7251428 ,  0.30978783]), 'effectorPosition': array([-0.69573834, -0.00535042])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9366846549050707
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.41841453, -2.6248019 ]), 'currentState': array([3.86477077, 4.0912361 ]), 'targetState': array([-0.7251428 ,  0.30978783]), 'effectorPosition': array([-0.85155466,  0.33302927])}
episode index:2473
target Thresh 1.9871987612461908
current state at start:  [ 3.6443421  -2.98820876]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.6443421 , -2.98820876]), 'currentState': array([3.1443421 , 3.76113607]), 'targetState': array([-0.51222093,  0.81344893]), 'effectorPosition': array([-0.18745213,  0.5801503 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9367062051658204
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.6443421 , -2.98820876]), 'currentState': array([3.21999284, 4.21535582]), 'targetState': array([-0.51222093,  0.81344893]), 'effectorPosition': array([-0.59041642,  0.83532561])}
episode index:2474
target Thresh 1.9872243381382808
current state at start:  [-1.41385452 -3.02215541]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.41385452, -3.02215541]), 'currentState': array([4.37755363, 3.68291619]), 'targetState': array([-0.59712964,  0.58411945]), 'effectorPosition': array([-0.53363763,  0.03429252])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9367237380122181
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.41385452, -3.02215541]), 'currentState': array([3.57785328, 3.9445669 ]), 'targetState': array([-0.59712964,  0.58411945]), 'effectorPosition': array([-0.58081824,  0.52298192])}
episode index:2475
target Thresh 1.987249863927706
current state at start:  [-4.19585917  2.14909269]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.19585917,  2.14909269]), 'currentState': array([1.59876117, 2.44670137]), 'targetState': array([-0.52925045,  0.22937613]), 'effectorPosition': array([-0.64653514,  0.21388242])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9367492938530856
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.19585917,  2.14909269]), 'currentState': array([1.59876117, 2.44670137]), 'targetState': array([-0.52925045,  0.22937613]), 'effectorPosition': array([-0.64653514,  0.21388242])}
episode index:2476
target Thresh 1.9872753387165702
current state at start:  [ 2.39961884 -3.00648863]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.39961884, -3.00648863]), 'currentState': array([2.84649951, 3.68661254]), 'targetState': array([ 0.72721672, -0.0794304 ]), 'effectorPosition': array([0.01215548, 0.53816195])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9367589211103108
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([ 2.39961884, -3.00648863]), 'currentState': array([4.74522809, 2.52724638]), 'targetState': array([ 0.72721672, -0.0794304 ]), 'effectorPosition': array([ 0.58211721, -0.1638251 ])}
episode index:2477
target Thresh 1.9873007626067722
current state at start:  [0.12931281 3.05643057]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.12931281, 3.05643057]), 'currentState': array([5.9456585 , 3.55263622]), 'targetState': array([ 0.813454  , -0.18584862]), 'effectorPosition': array([-0.0537223 , -0.40460502])}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.9367495419038431
{'reset': False, 'endBeforeDone': False, 'stepCount': 10, 'initial state': array([0.12931281, 3.05643057]), 'currentState': array([4.6273261 , 2.36459491]), 'targetState': array([ 0.813454  , -0.18584862]), 'effectorPosition': array([ 0.67422505, -0.34550988])}
episode index:2478
target Thresh 1.9873261357000078
current state at start:  [-1.36160083  2.50083181]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.36160083,  2.50083181]), 'currentState': array([4.8448319 , 2.93262035]), 'targetState': array([0.06893545, 0.30001407]), 'effectorPosition': array([0.20851077, 0.00583081])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9363716679458343
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([-1.36160083,  2.50083181]), 'currentState': array([4.45284702, 3.32515114]), 'targetState': array([0.06893545, 0.30001407]), 'effectorPosition': array([-0.1807275 ,  0.03060702])}
episode index:2479
target Thresh 1.9873514580977694
current state at start:  [-1.54547611  2.2367724 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.54547611,  2.2367724 ]), 'currentState': array([4.28044123, 2.200982  ]), 'targetState': array([ 0.46407764, -0.61556134]), 'effectorPosition': array([ 0.56177468, -0.71121   ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.93639732453134
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.54547611,  2.2367724 ]), 'currentState': array([4.28044123, 2.200982  ]), 'targetState': array([ 0.46407764, -0.61556134]), 'effectorPosition': array([ 0.56177468, -0.71121   ])}
episode index:2480
target Thresh 1.9873767299013463
current state at start:  [ 3.12264504 -2.19015969]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.12264504, -2.19015969]), 'currentState': array([3.59940599, 3.70428141]), 'targetState': array([-0.43981599,  0.09867897]), 'effectorPosition': array([-0.37408307,  0.41038301])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9364189298015811
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.12264504, -2.19015969]), 'currentState': array([4.09940599, 3.42233079]), 'targetState': array([-0.43981599,  0.09867897]), 'effectorPosition': array([-0.24914397,  0.12737701])}
episode index:2481
target Thresh 1.987401951211826
current state at start:  [ 0.42962967 -2.47480046]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.42962967, -2.47480046]), 'currentState': array([0.70131294, 3.36629109]), 'targetState': array([-0.08608373, -0.04253518]), 'effectorPosition': array([ 0.16296913, -0.15400771])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9364405176622573
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.42962967, -2.47480046]), 'currentState': array([1.20131294, 3.19808349]), 'targetState': array([-0.08608373, -0.04253518]), 'effectorPosition': array([ 0.05322656, -0.01890237])}
episode index:2482
target Thresh 1.9874271221300936
current state at start:  [-1.30976824 -1.95472185]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.30976824, -1.95472185]), 'currentState': array([4.56087807, 4.82846346]), 'targetState': array([-0.1267876, -1.3126618]), 'effectorPosition': array([-1.15030411, -0.95311514])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.9364425473166024
{'reset': False, 'endBeforeDone': False, 'stepCount': 7, 'initial state': array([-1.30976824, -1.95472185]), 'currentState': array([3.95606887, 1.49196886]), 'targetState': array([-0.1267876, -1.3126618]), 'effectorPosition': array([-0.0151812 , -1.46876181])}
episode index:2483
target Thresh 1.9874522427568333
current state at start:  [ 2.37055589 -2.47894685]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.37055589, -2.47894685]), 'currentState': array([2.24240969, 4.15080853]), 'targetState': array([0.7076123 , 0.16676104]), 'effectorPosition': array([0.37170272, 0.89262979])}
done in step count: 38
reward sum = 0.682554595010387
running average episode reward sum: 0.9363403379960282
{'reset': False, 'endBeforeDone': False, 'stepCount': 39, 'initial state': array([ 2.37055589, -2.47894685]), 'currentState': array([1.62910227, 4.01493124]), 'targetState': array([0.7076123 , 0.16676104]), 'effectorPosition': array([0.7443291 , 0.40178581])}
episode index:2484
target Thresh 1.9874773131925272
current state at start:  [ 2.38793476 -3.0916292 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.38793476, -3.0916292 ]), 'currentState': array([2.85687684, 3.20654364]), 'targetState': array([ 0.74234103, -0.6996266 ]), 'effectorPosition': array([0.01620723, 0.06288461])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9363500988298326
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([ 2.38793476, -3.0916292 ]), 'currentState': array([4.52817117, 2.08189516]), 'targetState': array([ 0.74234103, -0.6996266 ]), 'effectorPosition': array([ 0.76387079, -0.66198906])}
episode index:2485
target Thresh 1.987502333537457
current state at start:  [ 3.87436532 -2.52574218]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.87436532, -2.52574218]), 'currentState': array([3.37436532, 4.18713653]), 'targetState': array([-0.64244833,  0.94336813]), 'effectorPosition': array([-0.68470296,  0.72685554])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9363757021689999
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.87436532, -2.52574218]), 'currentState': array([3.37436532, 4.18713653]), 'targetState': array([-0.64244833,  0.94336813]), 'effectorPosition': array([-0.68470296,  0.72685554])}
episode index:2486
target Thresh 1.9875273038917043
current state at start:  [-1.64899087 -2.23470549]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.64899087, -2.23470549]), 'currentState': array([4.13419444, 3.80216978]), 'targetState': array([0.0111375 , 0.00611247]), 'effectorPosition': array([-0.62880227,  0.15915775])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9363972640097039
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.64899087, -2.23470549]), 'currentState': array([4.58839464, 3.35504223]), 'targetState': array([0.0111375 , 0.00611247]), 'effectorPosition': array([-0.21301283,  0.003679  ])}
episode index:2487
target Thresh 1.9875522243551507
current state at start:  [ 3.54154425 -1.79832109]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.54154425, -1.79832109]), 'currentState': array([3.96506142, 4.35019782]), 'targetState': array([-1.10202486,  0.25865347]), 'effectorPosition': array([-1.12477348,  0.16197668])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9364228278103431
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.54154425, -1.79832109]), 'currentState': array([3.96506142, 4.35019782]), 'targetState': array([-1.10202486,  0.25865347]), 'effectorPosition': array([-1.12477348,  0.16197668])}
episode index:2488
target Thresh 1.9875770950274778
current state at start:  [0.72546625 1.84896917]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.72546625, 1.84896917]), 'currentState': array([1.1199086 , 2.19225857]), 'targetState': array([-0.35314559,  0.83116561]), 'effectorPosition': array([-0.54972269,  0.73031206])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9364483710695595
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.72546625, 1.84896917]), 'currentState': array([1.1199086 , 2.19225857]), 'targetState': array([-0.35314559,  0.83116561]), 'effectorPosition': array([-0.54972269,  0.73031206])}
episode index:2489
target Thresh 1.9876019160081686
current state at start:  [ 1.9678538  -2.20158841]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.9678538 , -2.20158841]), 'currentState': array([2.25093533, 3.7224717 ]), 'targetState': array([-0.09734036,  0.19583338]), 'effectorPosition': array([0.32350008, 0.47263783])}
done in step count: 67
reward sum = 0.5099857462495653
running average episode reward sum: 0.9362771009391098
{'reset': False, 'endBeforeDone': False, 'stepCount': 68, 'initial state': array([ 1.9678538 , -2.20158841]), 'currentState': array([2.89670459, 3.52966302]), 'targetState': array([-0.09734036,  0.19583338]), 'effectorPosition': array([0.01960245, 0.3851413 ])}
episode index:2490
target Thresh 1.9876266873965067
current state at start:  [-0.39900837  2.2507355 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.39900837,  2.2507355 ]), 'currentState': array([0.09416734, 2.67413656]), 'targetState': array([-0.21422522,  1.09011539]), 'effectorPosition': array([0.06443649, 0.4587079 ])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9359012369885119
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([-0.39900837,  2.2507355 ]), 'currentState': array([0.74796652, 1.0771101 ]), 'targetState': array([-0.21422522,  1.09011539]), 'effectorPosition': array([0.48152455, 1.64799406])}
episode index:2491
target Thresh 1.987651409291578
current state at start:  [ 3.41046495 -2.29965732]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.41046495, -2.29965732]), 'currentState': array([3.83295913, 3.93764572]), 'targetState': array([-1.02200148,  0.18991837]), 'effectorPosition': array([-0.68709527,  0.35893569])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.935922945962433
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.41046495, -2.29965732]), 'currentState': array([4.15012975, 4.23647346]), 'targetState': array([-1.02200148,  0.18991837]), 'effectorPosition': array([-1.0408925 ,  0.01542594])}
episode index:2492
target Thresh 1.98767608179227
current state at start:  [1.63267654 2.19345552]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.63267654, 2.19345552]), 'currentState': array([1.28506431, 1.72937498]), 'targetState': array([-1.07120162,  0.88751779]), 'effectorPosition': array([-0.71006703,  1.08626659])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9359446375204102
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.63267654, 2.19345552]), 'currentState': array([1.78396574, 1.3660858 ]), 'targetState': array([-1.07120162,  0.88751779]), 'effectorPosition': array([-1.21152285,  0.96890653])}
episode index:2493
target Thresh 1.9877007049972728
current state at start:  [ 1.54802224 -2.42335132]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.54802224, -2.42335132]), 'currentState': array([2.00639206, 3.68730962]), 'targetState': array([-0.17075378,  0.5996477 ]), 'effectorPosition': array([0.40927728, 0.35068697])}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9359319821224505
{'reset': False, 'endBeforeDone': False, 'stepCount': 11, 'initial state': array([ 1.54802224, -2.42335132]), 'currentState': array([0.44225727, 2.35333702]), 'targetState': array([-0.17075378,  0.5996477 ]), 'effectorPosition': array([-0.03694944,  0.76711669])}
episode index:2494
target Thresh 1.987725279005079
current state at start:  [-0.79625704 -2.12342941]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.79625704, -2.12342941]), 'currentState': array([5.02868642, 4.27467362]), 'targetState': array([ 0.59590737, -0.37125412]), 'effectorPosition': array([-0.68158808, -0.8292738 ])}
done in step count: 14
reward sum = 0.8687458127689782
running average episode reward sum: 0.9359050537980603
{'reset': False, 'endBeforeDone': False, 'stepCount': 15, 'initial state': array([-0.79625704, -2.12342941]), 'currentState': array([4.60583705, 2.57010396]), 'targetState': array([ 0.59590737, -0.37125412]), 'effectorPosition': array([ 0.52091783, -0.21552544])}
episode index:2495
target Thresh 1.987749803913985
current state at start:  [-0.30555541 -3.00952125]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.30555541, -3.00952125]), 'currentState': array([0.01210343, 2.80410335]), 'targetState': array([-0.15704445,  0.54986959]), 'effectorPosition': array([0.05239931, 0.33177757])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.9359110974663705
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([-0.30555541, -3.00952125]), 'currentState': array([0.72505601, 2.69477385]), 'targetState': array([-0.15704445,  0.54986959]), 'effectorPosition': array([-0.21307882,  0.38851628])}
episode index:2496
target Thresh 1.9877742798220903
current state at start:  [0.57686907 2.42794736]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.57686907, 2.42794736]), 'currentState': array([0.24876893, 2.08111735]), 'targetState': array([0.25627754, 0.71875192]), 'effectorPosition': array([0.28095474, 0.97167363])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9359327590212497
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.57686907, 2.42794736]), 'currentState': array([0.15072203, 2.44426285]), 'targetState': array([0.25627754, 0.71875192]), 'effectorPosition': array([0.13437024, 0.66994429])}
episode index:2497
target Thresh 1.9877987068272986
current state at start:  [-3.76675283  2.75008114]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.76675283,  2.75008114]), 'currentState': array([3.01643247, 2.87887074]), 'targetState': array([ 0.23455168, -1.01998597]), 'effectorPosition': array([-0.06646549, -0.25339503])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9359504400624743
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-3.76675283,  2.75008114]), 'currentState': array([4.01564787, 1.87887074]), 'targetState': array([ 0.23455168, -1.01998597]), 'effectorPosition': array([ 0.28369341, -1.14589245])}
episode index:2498
target Thresh 1.987823085027318
current state at start:  [1.03483742 2.23222208]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.03483742, 2.23222208]), 'currentState': array([1.53421783, 2.607898  ]), 'targetState': array([-1.16506358, -0.09877054]), 'effectorPosition': array([-0.50329165,  0.15757754])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9359720685378393
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.03483742, 2.23222208]), 'currentState': array([2.03421783, 2.107898  ]), 'targetState': array([-1.16506358, -0.09877054]), 'effectorPosition': array([-0.98687334,  0.05277474])}
episode index:2499
target Thresh 1.9878474145196612
current state at start:  [-1.94678923  2.2522147 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.94678923,  2.2522147 ]), 'currentState': array([4.51277662, 2.48261502]), 'targetState': array([ 0.71130793, -0.06563803]), 'effectorPosition': array([ 0.55863247, -0.32663814])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9359936797104241
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.94678923,  2.2522147 ]), 'currentState': array([4.78760747, 2.52048315]), 'targetState': array([ 0.71130793, -0.06563803]), 'effectorPosition': array([ 0.59432739, -0.14250739])}
episode index:2500
target Thresh 1.9878716954016462
current state at start:  [ 1.68119783 -2.41423772]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.68119783, -2.41423772]), 'currentState': array([2.05551429, 3.36894758]), 'targetState': array([-0.05523878,  0.10351695]), 'effectorPosition': array([0.18744554, 0.12779733])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9360192720016235
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.68119783, -2.41423772]), 'currentState': array([2.05551429, 3.36894758]), 'targetState': array([-0.05523878,  0.10351695]), 'effectorPosition': array([0.18744554, 0.12779733])}
episode index:2501
target Thresh 1.9878959277703967
current state at start:  [ 0.45193462 -2.33075106]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.45193462, -2.33075106]), 'currentState': array([0.45152058, 3.45243425]), 'targetState': array([-0.16991595, -0.06693148]), 'effectorPosition': array([ 0.17657802, -0.25429748])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9360408470327978
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.45193462, -2.33075106]), 'currentState': array([0.59407303, 3.18179536]), 'targetState': array([-0.16991595, -0.06693148]), 'effectorPosition': array([ 0.02316662, -0.03285343])}
episode index:2502
target Thresh 1.987920111722842
current state at start:  [-0.68178954 -2.29905891]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.68178954, -2.29905891]), 'currentState': array([5.13408265, 4.4841264 ]), 'targetState': array([ 0.60588477, -1.24568334]), 'effectorPosition': array([-0.57204412, -1.10462414])}
done in step count: 38
reward sum = 0.682554595010387
running average episode reward sum: 0.9359395740595567
{'reset': False, 'endBeforeDone': False, 'stepCount': 39, 'initial state': array([-0.68178954, -2.29905891]), 'currentState': array([4.37639945, 1.84659915]), 'targetState': array([ 0.60588477, -1.24568334]), 'effectorPosition': array([ 0.66848579, -1.0042349 ])}
episode index:2503
target Thresh 1.9879442473557183
current state at start:  [1.55044143 2.20827791]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.55044143, 2.20827791]), 'currentState': array([1.18562548, 2.53427392]), 'targetState': array([-0.0108371 ,  0.16654233]), 'effectorPosition': array([-0.46167192,  0.38012745])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9359572100124085
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([1.55044143, 2.20827791]), 'currentState': array([0.63948761, 2.99062015]), 'targetState': array([-0.0108371 ,  0.16654233]), 'effectorPosition': array([-0.08062906,  0.12746918])}
episode index:2504
target Thresh 1.987968334765568
current state at start:  [-4.06803918  2.91219275]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.06803918,  2.91219275]), 'currentState': array([2.71514612, 2.60335021]), 'targetState': array([-0.09804487, -0.70764181]), 'effectorPosition': array([-0.34076882, -0.40823358])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9359787839804673
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-4.06803918,  2.91219275]), 'currentState': array([3.21514612, 2.41838168]), 'targetState': array([-0.09804487, -0.70764181]), 'effectorPosition': array([-0.20100514, -0.67840088])}
episode index:2505
target Thresh 1.9879923740487404
current state at start:  [-2.87258197  2.32513802]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.87258197,  2.32513802]), 'currentState': array([2.92343878, 2.76014809]), 'targetState': array([-0.67342259, -0.09406059]), 'effectorPosition': array([-0.15073638, -0.34788338])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9359963902119197
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-2.87258197,  2.32513802]), 'currentState': array([1.95507273, 2.30104489]), 'targetState': array([-0.67342259, -0.09406059]), 'effectorPosition': array([-0.81549238,  0.02936836])}
episode index:2506
target Thresh 1.9880163653013934
current state at start:  [ 3.17115365 -2.08829783]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.17115365, -2.08829783]), 'currentState': array([3.65595989, 3.70254044]), 'targetState': array([ 0.04556306, -0.11445274]), 'effectorPosition': array([-0.39514908,  0.38775592])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9360179313406743
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.17115365, -2.08829783]), 'currentState': array([4.15595989, 3.20254044]), 'targetState': array([ 0.04556306, -0.11445274]), 'effectorPosition': array([-0.05270222,  0.03059345])}
episode index:2507
target Thresh 1.9880403086194913
current state at start:  [0.63530731 2.79977441]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.63530731, 2.79977441]), 'currentState': array([0.22896349, 3.25670281]), 'targetState': array([-0.15489855, -0.11607561]), 'effectorPosition': array([ 0.03251384, -0.11035658])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9360434425323247
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.63530731, 2.79977441]), 'currentState': array([0.22896349, 3.25670281]), 'targetState': array([-0.15489855, -0.11607561]), 'effectorPosition': array([ 0.03251384, -0.11035658])}
episode index:2508
target Thresh 1.988064204098808
current state at start:  [ 3.05182103 -2.00313138]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.05182103, -2.00313138]), 'currentState': array([3.32415397, 4.07890144]), 'targetState': array([0.33613713, 0.39703205]), 'effectorPosition': array([-0.54758255,  0.71849492])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.9360418570023825
{'reset': False, 'endBeforeDone': False, 'stepCount': 8, 'initial state': array([ 3.05182103, -2.00313138]), 'currentState': array([5.87595753, 2.37369987]), 'targetState': array([0.33613713, 0.39703205]), 'effectorPosition': array([0.5327905 , 0.52667098])}
episode index:2509
target Thresh 1.9880880518349249
current state at start:  [ 3.20223935 -2.25298259]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.20223935, -2.25298259]), 'currentState': array([3.54105623, 3.83162704]), 'targetState': array([-0.25452558,  0.40285657]), 'effectorPosition': array([-0.45833933,  0.49747041])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.936067338334254
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.20223935, -2.25298259]), 'currentState': array([3.54105623, 3.83162704]), 'targetState': array([-0.25452558,  0.40285657]), 'effectorPosition': array([-0.45833933,  0.49747041])}
episode index:2510
target Thresh 1.9881118519232333
current state at start:  [ 3.12691274 -2.05770112]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.12691274, -2.05770112]), 'currentState': array([3.13532783, 4.70756599]), 'targetState': array([-0.50853245,  0.87965632]), 'effectorPosition': array([-0.98889279,  1.00620331])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9356945516602858
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([ 3.12691274, -2.05770112]), 'currentState': array([1.56420435, 1.8263215 ]), 'targetState': array([-0.50853245,  0.87965632]), 'effectorPosition': array([-0.96258387,  0.75360809])}
episode index:2511
target Thresh 1.9881356044589338
current state at start:  [ 1.25400549 -2.99694064]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.25400549, -2.99694064]), 'currentState': array([1.72912261, 3.01898838]), 'targetState': array([ 0.06756004, -0.03733426]), 'effectorPosition': array([-0.12195123, -0.01186948])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9357201509629689
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.25400549, -2.99694064]), 'currentState': array([1.72912261, 3.01898838]), 'targetState': array([ 0.06756004, -0.03733426]), 'effectorPosition': array([-0.12195123, -0.01186948])}
episode index:2512
target Thresh 1.988159309537036
current state at start:  [-0.87293715  2.06430366]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.87293715,  2.06430366]), 'currentState': array([4.91960549, 1.94861338]), 'targetState': array([ 0.36875287, -0.63568506]), 'effectorPosition': array([ 1.03943031, -0.42638001])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9357378110700271
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-0.87293715,  2.06430366]), 'currentState': array([4.03246968, 2.27937485]), 'targetState': array([ 0.36875287, -0.63568506]), 'effectorPosition': array([ 0.37085908, -0.74896816])}
episode index:2513
target Thresh 1.9881829672523608
current state at start:  [0.56069773 2.57776328]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.56069773, 2.57776328]), 'currentState': array([1.06069773, 2.12232282]), 'targetState': array([-0.79675607,  1.00603146]), 'effectorPosition': array([-0.51087869,  0.83128033])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9357593950751701
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.56069773, 2.57776328]), 'currentState': array([1.56069773, 1.67357027]), 'targetState': array([-0.79675607,  1.00603146]), 'effectorPosition': array([-0.98561029,  0.90740627])}
episode index:2514
target Thresh 1.9882065776995386
current state at start:  [ 0.75342666 -2.47333254]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.75342666, -2.47333254]), 'currentState': array([0.29866623, 3.52476882]), 'targetState': array([ 0.09503255, -0.71871145]), 'effectorPosition': array([ 0.17931688, -0.33597881])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9357809619160944
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.75342666, -2.47333254]), 'currentState': array([6.08359366, 4.02476882]), 'targetState': array([ 0.09503255, -0.71871145]), 'effectorPosition': array([ 0.20483382, -0.82984531])}
episode index:2515
target Thresh 1.9882301409730117
current state at start:  [-1.01316165  1.61265894]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.01316165,  1.61265894]), 'currentState': array([4.77002366, 1.47377334]), 'targetState': array([ 0.76617701, -0.68852165]), 'effectorPosition': array([ 1.05682716, -1.0377177 ])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9357985767960961
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.01316165,  1.61265894]), 'currentState': array([4.33689708, 2.09790638]), 'targetState': array([ 0.76617701, -0.68852165]), 'effectorPosition': array([ 0.62179777, -0.77928942])}
episode index:2516
target Thresh 1.9882536571670328
current state at start:  [-0.48847594  2.25768529]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.48847594,  2.25768529]), 'currentState': array([5.34219663, 2.75768529]), 'targetState': array([0.03324912, 0.1006164 ]), 'effectorPosition': array([0.3455597 , 0.16177774])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9358201109332449
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.48847594,  2.25768529]), 'currentState': array([4.92684365, 2.90684147]), 'targetState': array([0.03324912, 0.1006164 ]), 'effectorPosition': array([0.23310974, 0.02270144])}
episode index:2517
target Thresh 1.9882771263756671
current state at start:  [0.03970072 2.05503641]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.03970072, 2.05503641]), 'currentState': array([0.53970072, 2.37849657]), 'targetState': array([-0.14353422,  1.1373098 ]), 'effectorPosition': array([-0.11728834,  0.73542116])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9354484587843437
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([0.03970072, 2.05503641]), 'currentState': array([1.29099238, 1.74763246]), 'targetState': array([-0.14353422,  1.1373098 ]), 'effectorPosition': array([-0.71853627,  1.06389556])}
episode index:2518
target Thresh 1.9883005486927912
current state at start:  [-0.47973466 -3.02576584]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.47973466, -3.02576584]), 'currentState': array([5.30345065, 3.74798918]), 'targetState': array([ 0.31368062, -0.43877337]), 'effectorPosition': array([-0.37387214, -0.4656239 ])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9350771017145604
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([-0.47973466, -3.02576584]), 'currentState': array([4.24302782, 4.33714595]), 'targetState': array([ 0.31368062, -0.43877337]), 'effectorPosition': array([-1.11634391, -0.14414908])}
episode index:2519
target Thresh 1.9883239242120945
current state at start:  [-0.84045126  2.50818897]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.84045126,  2.50818897]), 'currentState': array([5.01768951, 2.77660931]), 'targetState': array([0.54112937, 0.01489902]), 'effectorPosition': array([0.36022721, 0.04446285])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9351028647694355
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.84045126,  2.50818897]), 'currentState': array([5.01768951, 2.77660931]), 'targetState': array([0.54112937, 0.01489902]), 'effectorPosition': array([0.36022721, 0.04446285])}
episode index:2520
target Thresh 1.9883472530270792
current state at start:  [-0.34116028 -1.88544607]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.34116028, -1.88544607]), 'currentState': array([5.49346452, 4.31745292]), 'targetState': array([-0.24379461, -1.37990149]), 'effectorPosition': array([-0.22232626, -1.08677168])}
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.9350835399011082
{'reset': False, 'endBeforeDone': False, 'stepCount': 13, 'initial state': array([-0.34116028, -1.88544607]), 'currentState': array([3.75640378, 1.75283177]), 'targetState': array([-0.24379461, -1.37990149]), 'effectorPosition': array([-0.1017269 , -1.27576962])}
episode index:2521
target Thresh 1.98837053523106
current state at start:  [ 1.7853918  -2.71779396]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.7853918 , -2.71779396]), 'currentState': array([1.47918123, 3.9116406 ]), 'targetState': array([ 0.65357693, -0.12157547]), 'effectorPosition': array([0.71906067, 0.21724909])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9351053148654612
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.7853918 , -2.71779396]), 'currentState': array([1.15577668, 3.66716661]), 'targetState': array([ 0.65357693, -0.12157547]), 'effectorPosition': array([ 0.51353715, -0.0787867 ])}
episode index:2522
target Thresh 1.9883937709171668
current state at start:  [1.08932319 2.78489706]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.08932319, 2.78489706]), 'currentState': array([1.49975195, 2.68105567]), 'targetState': array([-0.99694679, -0.49470973]), 'effectorPosition': array([-0.43591249,  0.13547085])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9351192640074092
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([1.08932319, 2.78489706]), 'currentState': array([2.77039742, 1.87012162]), 'targetState': array([-0.99694679, -0.49470973]), 'effectorPosition': array([-1.00370255, -0.63468895])}
episode index:2523
target Thresh 1.9884169601783415
current state at start:  [-0.35326787  1.92233824]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.35326787,  1.92233824]), 'currentState': array([5.8037349 , 2.20184987]), 'targetState': array([0.55732828, 0.41946293]), 'effectorPosition': array([0.73622551, 0.52723862])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9351449695288009
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.35326787,  1.92233824]), 'currentState': array([5.8037349 , 2.20184987]), 'targetState': array([0.55732828, 0.41946293]), 'effectorPosition': array([0.73622551, 0.52723862])}
episode index:2524
target Thresh 1.9884401031073415
current state at start:  [-3.31291174  2.35730061]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.31291174,  2.35730061]), 'currentState': array([3.45332811, 2.26721494]), 'targetState': array([ 0.28835261, -1.16731009]), 'effectorPosition': array([-0.10595409, -0.84013392])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9351666942933439
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.31291174,  2.35730061]), 'currentState': array([3.91164465, 1.77069561]), 'targetState': array([ 0.28835261, -1.16731009]), 'effectorPosition': array([ 0.1069837 , -1.26151228])}
episode index:2525
target Thresh 1.9884631997967386
current state at start:  [0.799435   2.59404647]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.799435  , 2.59404647]), 'currentState': array([0.299435  , 3.08442708]), 'targetState': array([ 0.16447336, -0.39548033]), 'effectorPosition': array([-0.01529272,  0.055074  ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9351884018569647
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.799435  , 2.59404647]), 'currentState': array([6.08262031, 3.58442708]), 'targetState': array([ 0.16447336, -0.39548033]), 'effectorPosition': array([ 0.00915815, -0.43912943])}
episode index:2526
target Thresh 1.9884862503389193
current state at start:  [0.0419444  2.21928583]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.0419444 , 2.21928583]), 'currentState': array([5.82512971, 1.91049705]), 'targetState': array([1.08921485, 0.79934048]), 'effectorPosition': array([1.01499277, 0.55079925])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9352061745511251
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([0.0419444 , 2.21928583]), 'currentState': array([6.11363234, 1.59103695]), 'targetState': array([1.08921485, 0.79934048]), 'effectorPosition': array([1.13441846, 0.82013186])}
episode index:2527
target Thresh 1.988509254826086
current state at start:  [ 0.41249618 -1.78671521]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.41249618, -1.78671521]), 'currentState': array([0.85134897, 4.10600838]), 'targetState': array([ 1.01514066, -0.13510666]), 'effectorPosition': array([ 0.90149473, -0.21797498])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9352318050200527
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.41249618, -1.78671521]), 'currentState': array([0.85134897, 4.10600838]), 'targetState': array([ 1.01514066, -0.13510666]), 'effectorPosition': array([ 0.90149473, -0.21797498])}
episode index:2528
target Thresh 1.988532213350257
current state at start:  [-0.45502043 -1.64035087]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.45502043, -1.64035087]), 'currentState': array([5.32816488, 4.1895634 ]), 'targetState': array([-0.54258947, -1.06072633]), 'effectorPosition': array([-0.41809115, -0.90914207])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9352574152197284
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.45502043, -1.64035087]), 'currentState': array([5.32816488, 4.1895634 ]), 'targetState': array([-0.54258947, -1.06072633]), 'effectorPosition': array([-0.41809115, -0.90914207])}
episode index:2529
target Thresh 1.988555126003266
current state at start:  [-1.30450584  2.03795573]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.30450584,  2.03795573]), 'currentState': array([4.47867947, 1.70140794]), 'targetState': array([ 0.48637931, -0.78821845]), 'effectorPosition': array([ 0.76310235, -1.07572937])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.935279052605017
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.30450584,  2.03795573]), 'currentState': array([3.97867947, 2.15554383]), 'targetState': array([ 0.48637931, -0.78821845]), 'effectorPosition': array([ 0.31929639, -0.89110723])}
episode index:2530
target Thresh 1.9885779928767635
current state at start:  [1.44000745 2.380941  ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.44000745, 2.380941  ]), 'currentState': array([1.83516896, 2.85104456]), 'targetState': array([-0.39194567, -0.11605936]), 'effectorPosition': array([-0.28747622, -0.03440082])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9353046238999182
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.44000745, 2.380941  ]), 'currentState': array([1.83516896, 2.85104456]), 'targetState': array([-0.39194567, -0.11605936]), 'effectorPosition': array([-0.28747622, -0.03440082])}
episode index:2531
target Thresh 1.9886008140622176
current state at start:  [ 2.18958061 -2.31351044]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.18958061, -2.31351044]), 'currentState': array([1.70256435, 3.53051959]), 'targetState': array([ 0.32896021, -0.21235325]), 'effectorPosition': array([0.36609607, 0.12385749])}
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.9352853033026892
{'reset': False, 'endBeforeDone': False, 'stepCount': 13, 'initial state': array([ 2.18958061, -2.31351044]), 'currentState': array([4.2460614 , 2.70232999]), 'targetState': array([ 0.32896021, -0.21235325]), 'effectorPosition': array([ 0.33718058, -0.27600417])}
episode index:2532
target Thresh 1.9886235896509126
current state at start:  [-2.23506771  2.39357186]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.23506771,  2.39357186]), 'currentState': array([3.55915283, 2.89357186]), 'targetState': array([-0.00797372, -0.13985304]), 'effectorPosition': array([ 0.0715815 , -0.23680311])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.935310851939364
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.23506771,  2.39357186]), 'currentState': array([3.55915283, 2.89357186]), 'targetState': array([-0.00797372, -0.13985304]), 'effectorPosition': array([ 0.0715815 , -0.23680311])}
episode index:2533
target Thresh 1.988646319733951
current state at start:  [1.25646569 2.77328619]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.25646569, 2.77328619]), 'currentState': array([0.81392088, 3.27328619]), 'targetState': array([ 0.36832796, -0.387128  ]), 'effectorPosition': array([ 0.10140851, -0.08387163])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9353324340814557
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.25646569, 2.77328619]), 'currentState': array([0.34468638, 3.77328619]), 'targetState': array([ 0.36832796, -0.387128  ]), 'effectorPosition': array([ 0.38115611, -0.49057394])}
episode index:2534
target Thresh 1.9886690044022532
current state at start:  [ 0.0170235 -1.7414956]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.0170235, -1.7414956]), 'currentState': array([5.85193241, 4.32898308]), 'targetState': array([ 0.34886266, -1.20216404]), 'effectorPosition': array([ 0.1809512 , -1.10412597])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.935357943969392
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.0170235, -1.7414956]), 'currentState': array([5.85193241, 4.32898308]), 'targetState': array([ 0.34886266, -1.20216404]), 'effectorPosition': array([ 0.1809512 , -1.10412597])}
episode index:2535
target Thresh 1.988691643746558
current state at start:  [1.41231309 2.36868306]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.41231309, 2.36868306]), 'currentState': array([0.96804206, 1.97579908]), 'targetState': array([-0.14221323,  0.82276733]), 'effectorPosition': array([-0.41359728,  1.02024248])}
done in step count: 24
reward sum = 0.7856781408072188
running average episode reward sum: 0.9352989219649905
{'reset': False, 'endBeforeDone': False, 'stepCount': 25, 'initial state': array([1.41231309, 2.36868306]), 'currentState': array([0.91817495, 2.1839589 ]), 'targetState': array([-0.14221323,  0.82276733]), 'effectorPosition': array([-0.39195045,  0.83394321])}
episode index:2536
target Thresh 1.9887142378574227
current state at start:  [-3.79507324  1.72349513]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.79507324,  1.72349513]), 'currentState': array([2.91262046, 2.21329979]), 'targetState': array([-0.37150908, -1.24175813]), 'effectorPosition': array([-0.57205477, -0.68873085])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9353204832886148
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.79507324,  1.72349513]), 'currentState': array([3.39368996, 1.87730209]), 'targetState': array([-0.37150908, -1.24175813]), 'effectorPosition': array([-0.43838929, -1.09743184])}
episode index:2537
target Thresh 1.9887367868252237
current state at start:  [-1.03573731 -2.10879539]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.03573731, -2.10879539]), 'currentState': array([4.74744799, 4.65166729]), 'targetState': array([-0.03728029, -1.28385171]), 'effectorPosition': array([-0.9646189 , -0.97372563])}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9353155282890637
{'reset': False, 'endBeforeDone': False, 'stepCount': 9, 'initial state': array([-1.03573731, -2.10879539]), 'currentState': array([4.01026111, 1.6112987 ]), 'targetState': array([-0.03728029, -1.28385171]), 'effectorPosition': array([ 0.14315086, -1.37786982])}
episode index:2538
target Thresh 1.988759290740157
current state at start:  [ 2.26136623 -2.44948458]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.26136623, -2.44948458]), 'currentState': array([2.54353146, 4.27189918]), 'targetState': array([0.3372938 , 0.82900696]), 'effectorPosition': array([0.03524101, 1.0705106 ])}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.9353069429086754
{'reset': False, 'endBeforeDone': False, 'stepCount': 10, 'initial state': array([ 2.26136623, -2.44948458]), 'currentState': array([0.30951911, 2.01419921]), 'targetState': array([0.3372938 , 0.82900696]), 'effectorPosition': array([0.26870633, 1.03429464])}
episode index:2539
target Thresh 1.9887817496922382
current state at start:  [ 3.14401973 -2.80789485]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.14401973, -2.80789485]), 'currentState': array([3.64401973, 2.97529046]), 'targetState': array([ 0.63694308, -0.33470027]), 'effectorPosition': array([ 0.06762351, -0.15172278])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9353245779705226
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 3.14401973, -2.80789485]), 'currentState': array([4.60624341, 2.17770995]), 'targetState': array([ 0.63694308, -0.33470027]), 'effectorPosition': array([ 0.77126772, -0.51427242])}
episode index:2540
target Thresh 1.9888041637713034
current state at start:  [-0.96881253 -1.75001765]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.96881253, -1.75001765]), 'currentState': array([4.81437278, 4.76061567]), 'targetState': array([-0.31483438, -1.09292796]), 'effectorPosition': array([-0.8869325 , -1.14445041])}
done in step count: 17
reward sum = 0.8429431933839268
running average episode reward sum: 0.9352882216601777
{'reset': False, 'endBeforeDone': False, 'stepCount': 18, 'initial state': array([-0.96881253, -1.75001765]), 'currentState': array([3.65065465, 1.8851271 ]), 'targetState': array([-0.31483438, -1.09292796]), 'effectorPosition': array([-0.1397458 , -1.16709507])}
episode index:2541
target Thresh 1.9888265330670085
current state at start:  [-3.29339296  1.67126804]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.29339296,  1.67126804]), 'currentState': array([2.48979235, 2.10837021]), 'targetState': array([-0.5684856 , -0.25991139]), 'effectorPosition': array([-0.90897117, -0.38686464])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9353097447830493
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.29339296,  1.67126804]), 'currentState': array([2.09467906, 2.5475364 ]), 'targetState': array([-0.5684856 , -0.25991139]), 'effectorPosition': array([-0.57036184, -0.13165546])}
episode index:2542
target Thresh 1.9888488576688312
current state at start:  [ 3.73886715 -2.88045307]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.73886715, -2.88045307]), 'currentState': array([3.27067732, 3.81880198]), 'targetState': array([-0.71262534,  0.64615271]), 'effectorPosition': array([-0.29950223,  0.59300044])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.935331250978573
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.73886715, -2.88045307]), 'currentState': array([3.31374828, 4.19731743]), 'targetState': array([-0.71262534,  0.64615271]), 'effectorPosition': array([-0.64898312,  0.77047173])}
episode index:2543
target Thresh 1.9888711376660697
current state at start:  [ 4.18715172 -2.5715889 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.18715172, -2.5715889 ]), 'currentState': array([4.64492899, 3.6183728 ]), 'targetState': array([ 0.17180166, -0.79114534]), 'effectorPosition': array([-0.46539457, -0.08033383])}
done in step count: 28
reward sum = 0.7547192872036326
running average episode reward sum: 0.9352602557097934
{'reset': False, 'endBeforeDone': False, 'stepCount': 29, 'initial state': array([ 4.18715172, -2.5715889 ]), 'currentState': array([3.49260378, 2.32435853]), 'targetState': array([ 0.17180166, -0.79114534]), 'effectorPosition': array([-0.04575304, -0.79336306])}
episode index:2544
target Thresh 1.988893373147844
current state at start:  [ 0.03691783 -2.44826007]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.03691783, -2.44826007]), 'currentState': array([5.82010313, 3.41266153]), 'targetState': array([-0.71545954, -0.64999469]), 'effectorPosition': array([-0.0869421 , -0.25587221])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9352778744698289
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 0.03691783, -2.44826007]), 'currentState': array([4.82010313, 4.31471426]), 'targetState': array([-0.71545954, -0.64999469]), 'effectorPosition': array([-0.85074917, -0.70829   ])}
episode index:2545
target Thresh 1.988915564203096
current state at start:  [ 0.59489949 -1.80644596]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.59489949, -1.80644596]), 'currentState': array([0.27834074, 4.13022432]), 'targetState': array([ 0.84075721, -0.42109335]), 'effectorPosition': array([ 0.66234149, -0.67943883])}
done in step count: 17
reward sum = 0.8429431933839268
running average episode reward sum: 0.9352416079022383
{'reset': False, 'endBeforeDone': False, 'stepCount': 18, 'initial state': array([ 0.59489949, -1.80644596]), 'currentState': array([4.45275662, 2.24684241]), 'targetState': array([ 0.84075721, -0.42109335]), 'effectorPosition': array([ 0.65782015, -0.56200118])}
episode index:2546
target Thresh 1.9889377109205901
current state at start:  [-1.38983577  2.66705824]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.38983577,  2.66705824]), 'currentState': array([4.39334954, 3.13621799]), 'targetState': array([-0.24937029,  0.17871417]), 'effectorPosition': array([ 0.00509889, -0.00169949])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9352631070746362
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.38983577,  2.66705824]), 'currentState': array([4.00332842, 3.56426034]), 'targetState': array([-0.24937029,  0.17871417]), 'effectorPosition': array([-0.36862718,  0.2002952 ])}
episode index:2547
target Thresh 1.988959813388913
current state at start:  [ 3.67515572 -2.5949241 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.67515572, -2.5949241 ]), 'currentState': array([4.07758869, 3.2514075 ]), 'targetState': array([-0.15770366,  0.29840192]), 'effectorPosition': array([-0.09181632,  0.0601411 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9352885140184846
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.67515572, -2.5949241 ]), 'currentState': array([4.07758869, 3.2514075 ]), 'targetState': array([-0.15770366,  0.29840192]), 'effectorPosition': array([-0.09181632,  0.0601411 ])}
episode index:2548
target Thresh 1.988981871696475
current state at start:  [ 1.67317531 -2.64807416]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.67317531, -2.64807416]), 'currentState': array([1.54205841, 4.09780436]), 'targetState': array([1.3067012 , 0.24520078]), 'effectorPosition': array([0.82884109, 0.39972996])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9353099779203995
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.67317531, -2.64807416]), 'currentState': array([1.1859631 , 4.57719978]), 'targetState': array([1.3067012 , 0.24520078]), 'effectorPosition': array([1.2432126 , 0.42996145])}
episode index:2549
target Thresh 1.989003885931509
current state at start:  [-3.41739147  2.22348536]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.41739147,  2.22348536]), 'currentState': array([2.36579384, 2.72348536]), 'targetState': array([0.03957545, 0.12134901]), 'effectorPosition': array([-0.34583113, -0.22952708])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9353314249878816
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.41739147,  2.22348536]), 'currentState': array([1.86579384, 3.22348536]), 'targetState': array([0.03957545, 0.12134901]), 'effectorPosition': array([0.07729327, 0.02698924])}
episode index:2550
target Thresh 1.989025856182072
current state at start:  [ 3.14535128 -2.33568546]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.14535128, -2.33568546]), 'currentState': array([3.46836238, 3.48929183]), 'targetState': array([-0.18936599,  0.01060356]), 'effectorPosition': array([-0.16604543,  0.30349723])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9353489744096818
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 3.14535128, -2.33568546]), 'currentState': array([4.03176226, 3.26815101]), 'targetState': array([-0.18936599,  0.01060356]), 'effectorPosition': array([-0.10312895,  0.0732125 ])}
episode index:2551
target Thresh 1.9890477825360449
current state at start:  [-2.14254842  2.69308646]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.14254842,  2.69308646]), 'currentState': array([3.64063689, 2.19308646]), 'targetState': array([-0.10139862, -1.03034801]), 'effectorPosition': array([ 0.02264062, -0.91306755])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9353743078836593
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.14254842,  2.69308646]), 'currentState': array([3.64063689, 2.19308646]), 'targetState': array([-0.10139862, -1.03034801]), 'effectorPosition': array([ 0.02264062, -0.91306755])}
episode index:2552
target Thresh 1.9890696650811337
current state at start:  [-0.18537566  2.12131593]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.18537566,  2.12131593]), 'currentState': array([5.59861148, 2.62131593]), 'targetState': array([-0.00941985,  0.00862978]), 'effectorPosition': array([0.416856  , 0.30144283])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9353957045511547
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.18537566,  2.12131593]), 'currentState': array([5.12285564, 3.04220448]), 'targetState': array([-0.00941985,  0.00862978]), 'effectorPosition': array([0.09295173, 0.03506931])}
episode index:2553
target Thresh 1.989091503904868
current state at start:  [-0.73303343 -2.17979539]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.73303343, -2.17979539]), 'currentState': array([5.05962062, 4.02035512]), 'targetState': array([-0.03224398, -0.53361706]), 'effectorPosition': array([-0.60084635, -0.60230783])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.935029457211863
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([-0.73303343, -2.17979539]), 'currentState': array([4.74827446, 3.91711488]), 'targetState': array([-0.03224398, -0.53361706]), 'effectorPosition': array([-0.68937929, -0.31087802])}
episode index:2554
target Thresh 1.9891132990946034
current state at start:  [-0.35089853 -2.55977856]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.35089853, -2.55977856]), 'currentState': array([5.43228677, 3.23016993]), 'targetState': array([-0.09762343,  0.05549306]), 'effectorPosition': array([-0.06392707, -0.061271  ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9350548859957332
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.35089853, -2.55977856]), 'currentState': array([5.43228677, 3.23016993]), 'targetState': array([-0.09762343,  0.05549306]), 'effectorPosition': array([-0.06392707, -0.061271  ])}
episode index:2555
target Thresh 1.9891350507375207
current state at start:  [ 3.57596023 -1.96437715]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.57596023, -1.96437715]), 'currentState': array([4.06728096, 4.08909092]), 'targetState': array([-1.37529647, -0.31202901]), 'effectorPosition': array([-0.8990876 ,  0.15559258])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9350686747727301
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 3.57596023, -1.96437715]), 'currentState': array([4.30885471, 4.48868876]), 'targetState': array([-1.37529647, -0.31202901]), 'effectorPosition': array([-1.20232489, -0.33277103])}
episode index:2556
target Thresh 1.9891567589206265
current state at start:  [-1.48563558 -1.95233329]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.48563558, -1.95233329]), 'currentState': array([4.40287817, 4.83085202]), 'targetState': array([-0.13886045, -1.31930799]), 'effectorPosition': array([-1.28639854, -0.76259498])}
done in step count: 61
reward sum = 0.5416850759668536
running average episode reward sum: 0.9349148290164511
{'reset': False, 'endBeforeDone': False, 'stepCount': 62, 'initial state': array([-1.48563558, -1.95233329]), 'currentState': array([3.78569447, 1.91922994]), 'targetState': array([-0.13886045, -1.31930799]), 'effectorPosition': array([ 0.03777502, -1.14704887])}
episode index:2557
target Thresh 1.9891784237307535
current state at start:  [-0.08206268 -2.54042365]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.08206268, -2.54042365]), 'currentState': array([5.70112263, 3.24276165]), 'targetState': array([-0.29710516,  0.10400954]), 'effectorPosition': array([-0.05125141, -0.08717644])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9349248685711747
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([-0.08206268, -2.54042365]), 'currentState': array([4.71207892, 3.57052658]), 'targetState': array([-0.29710516,  0.10400954]), 'effectorPosition': array([-0.41592961, -0.09046139])}
episode index:2558
target Thresh 1.989200045254561
current state at start:  [0.84432613 2.661826  ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.84432613, 2.661826  ]), 'currentState': array([0.4300804 , 3.14093904]), 'targetState': array([ 0.01537674, -0.00062185]), 'effectorPosition': array([-0.00027233,  0.00059418])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9349502984779465
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.84432613, 2.661826  ]), 'currentState': array([0.4300804 , 3.14093904]), 'targetState': array([ 0.01537674, -0.00062185]), 'effectorPosition': array([-0.00027233,  0.00059418])}
episode index:2559
target Thresh 1.9892216235785352
current state at start:  [ 0.59660837 -2.48802532]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.59660837, -2.48802532]), 'currentState': array([0.95384025, 3.96544214]), 'targetState': array([1.12885428, 0.0811034 ]), 'effectorPosition': array([ 0.78397564, -0.16303048])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9349679350801037
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 0.59660837, -2.48802532]), 'currentState': array([0.97550252, 4.31009781]), 'targetState': array([1.12885428, 0.0811034 ]), 'effectorPosition': array([ 1.10308494, -0.01217991])}
episode index:2560
target Thresh 1.9892431587889894
current state at start:  [-3.92060482  2.18902173]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.92060482,  2.18902173]), 'currentState': array([1.94046096, 2.58482995]), 'targetState': array([-0.20002179,  0.48248048]), 'effectorPosition': array([-0.54731113, -0.05009959])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9349779421378622
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([-3.92060482,  2.18902173]), 'currentState': array([0.76099915, 2.37651059]), 'targetState': array([-0.20002179,  0.48248048]), 'effectorPosition': array([-0.27584435,  0.69372823])}
episode index:2561
target Thresh 1.9892646509720642
current state at start:  [ 3.1340676  -1.84831134]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.1340676 , -1.84831134]), 'currentState': array([3.6340676 , 3.98251664]), 'targetState': array([-0.42950517,  0.22940527]), 'effectorPosition': array([-0.64599157,  0.49914516])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.934999418350923
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.1340676 , -1.84831134]), 'currentState': array([4.1340676, 3.5603123]), 'targetState': array([-0.42950517,  0.22940527]), 'effectorPosition': array([-0.38769404,  0.14990926])}
episode index:2562
target Thresh 1.9892861002137285
current state at start:  [ 0.99005638 -2.31258882]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.99005638, -2.31258882]), 'currentState': array([1.49005638, 3.59413417]), 'targetState': array([0.43971426, 0.22943425]), 'effectorPosition': array([0.44394675, 0.06506795])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.935024779483053
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.99005638, -2.31258882]), 'currentState': array([1.49005638, 3.59413417]), 'targetState': array([0.43971426, 0.22943425]), 'effectorPosition': array([0.44394675, 0.06506795])}
episode index:2563
target Thresh 1.9893075065997796
current state at start:  [-2.28875605  1.86980138]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.28875605,  1.86980138]), 'currentState': array([4.49442926, 1.81048919]), 'targetState': array([ 0.89437963, -0.82011513]), 'effectorPosition': array([ 0.78352578, -0.95460924])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9350501208327086
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.28875605,  1.86980138]), 'currentState': array([4.49442926, 1.81048919]), 'targetState': array([ 0.89437963, -0.82011513]), 'effectorPosition': array([ 0.78352578, -0.95460924])}
episode index:2564
target Thresh 1.989328870215843
current state at start:  [0.25349576 2.83297849]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.25349576, 2.83297849]), 'currentState': array([6.09962971, 3.33297849]), 'targetState': array([ 0.2133865, -0.2194277]), 'effectorPosition': array([-0.01676843, -0.19035675])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9350754424230272
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.25349576, 2.83297849]), 'currentState': array([6.09962971, 3.33297849]), 'targetState': array([ 0.2133865, -0.2194277]), 'effectorPosition': array([-0.01676843, -0.19035675])}
episode index:2565
target Thresh 1.9893501911473725
current state at start:  [-0.27607871 -2.4002393 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.27607871, -2.4002393 ]), 'currentState': array([5.60756933, 3.39763397]), 'targetState': array([-0.18234404,  0.08817771]), 'effectorPosition': array([-0.13294041, -0.21800605])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9350853880845926
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([-0.27607871, -2.4002393 ]), 'currentState': array([4.75967588, 3.43411772]), 'targetState': array([-0.18234404,  0.08817771]), 'effectorPosition': array([-0.28604054, -0.05606483])}
episode index:2566
target Thresh 1.989371469479653
current state at start:  [0.53501027 1.60996038]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.53501027, 1.60996038]), 'currentState': array([0.09293928, 2.10996038]), 'targetState': array([0.10252999, 0.62121991]), 'effectorPosition': array([0.40484125, 0.89959209])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9351067806096862
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.53501027, 1.60996038]), 'currentState': array([0.16197031, 2.60996038]), 'targetState': array([0.10252999, 0.62121991]), 'effectorPosition': array([0.05446193, 0.52256329])}
episode index:2567
target Thresh 1.9893927052977969
current state at start:  [-2.83831101  2.26437004]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.83831101,  2.26437004]), 'currentState': array([3.48332224, 2.38240527]), 'targetState': array([-0.14107308, -0.67750606]), 'effectorPosition': array([-0.02805386, -0.74055505])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9351320505549316
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.83831101,  2.26437004]), 'currentState': array([3.48332224, 2.38240527]), 'targetState': array([-0.14107308, -0.67750606]), 'effectorPosition': array([-0.02805386, -0.74055505])}
episode index:2568
target Thresh 1.9894138986867478
current state at start:  [0.98152263 2.04736316]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.98152263, 2.04736316]), 'currentState': array([0.48152263, 2.54736316]), 'targetState': array([0.15373707, 0.25825105]), 'effectorPosition': array([-0.10736453,  0.5755976 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9351534082619947
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.98152263, 2.04736316]), 'currentState': array([0.00332589, 3.0383755 ]), 'targetState': array([0.15373707, 0.25825105]), 'effectorPosition': array([0.00497945, 0.10305111])}
episode index:2569
target Thresh 1.9894350497312794
current state at start:  [ 2.45784425 -2.24686106]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.45784425, -2.24686106]), 'currentState': array([2.30540269, 3.5368752 ]), 'targetState': array([-0.27611759, -0.01783238]), 'effectorPosition': array([0.2340697 , 0.31533439])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9351747493482739
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 2.45784425, -2.24686106]), 'currentState': array([1.96955621, 3.04918079]), 'targetState': array([-0.27611759, -0.01783238]), 'effectorPosition': array([-0.08669711, -0.03189807])}
episode index:2570
target Thresh 1.9894561585159958
current state at start:  [ 3.58028084 -2.08261231]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.58028084, -2.08261231]), 'currentState': array([3.10153594, 4.35568245]), 'targetState': array([-0.3668506 ,  0.94912155]), 'effectorPosition': array([-0.61276278,  0.96236262])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9351999633703089
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.58028084, -2.08261231]), 'currentState': array([3.10153594, 4.35568245]), 'targetState': array([-0.3668506 ,  0.94912155]), 'effectorPosition': array([-0.61276278,  0.96236262])}
episode index:2571
target Thresh 1.9894772251253323
current state at start:  [ 2.3900929  -1.93347758]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.3900929 , -1.93347758]), 'currentState': array([2.60556224, 3.93047029]), 'targetState': array([-0.35026453,  0.36854385]), 'effectorPosition': array([0.10846125, 0.76088886])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9348363552974588
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([ 2.3900929 , -1.93347758]), 'currentState': array([2.08700968, 3.49176369]), 'targetState': array([-0.35026453,  0.36854385]), 'effectorPosition': array([0.26840204, 0.22210862])}
episode index:2572
target Thresh 1.9894982496435554
current state at start:  [-1.29189784  1.69158076]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.29189784,  1.69158076]), 'currentState': array([4.984375  , 2.06074377]), 'targetState': array([0.75022581, 0.13044413]), 'effectorPosition': array([ 0.99214763, -0.27291767])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9348577947240823
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.29189784,  1.69158076]), 'currentState': array([5.25506472, 2.26659142]), 'targetState': array([0.75022581, 0.13044413]), 'effectorPosition': array([0.84267132, 0.08895631])}
episode index:2573
target Thresh 1.9895192321547628
current state at start:  [1.10857165 1.84966079]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.10857165, 1.84966079]), 'currentState': array([0.78441465, 1.48822779]), 'targetState': array([-0.18102835,  1.00404631]), 'effectorPosition': array([0.06217332, 1.47006258])}
done in step count: 62
reward sum = 0.536268225207185
running average episode reward sum: 0.9347029425214728
{'reset': False, 'endBeforeDone': False, 'stepCount': 63, 'initial state': array([1.10857165, 1.84966079]), 'currentState': array([0.82282537, 1.79524333]), 'targetState': array([-0.18102835,  1.00404631]), 'effectorPosition': array([-0.18591008,  1.23300564])}
episode index:2574
target Thresh 1.989540172742885
current state at start:  [-1.3947079   2.26897206]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.3947079 ,  2.26897206]), 'currentState': array([4.91941532, 2.48274971]), 'targetState': array([0.80986041, 0.02408341]), 'effectorPosition': array([ 0.64215122, -0.07899102])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9347283006020469
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.3947079 ,  2.26897206]), 'currentState': array([4.91941532, 2.48274971]), 'targetState': array([0.80986041, 0.02408341]), 'effectorPosition': array([ 0.64215122, -0.07899102])}
episode index:2575
target Thresh 1.989561071491684
current state at start:  [ 2.50284929 -2.48249659]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.50284929, -2.48249659]), 'currentState': array([2.20142914, 3.42697016]), 'targetState': array([ 0.71111013, -0.0071277 ]), 'effectorPosition': array([0.20352229, 0.198665  ])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9347383424147013
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([ 2.50284929, -2.48249659]), 'currentState': array([1.13361648, 3.77052659]), 'targetState': array([ 0.71111013, -0.0071277 ]), 'effectorPosition': array([ 0.61396737, -0.07572217])}
episode index:2576
target Thresh 1.9895819284847553
current state at start:  [ 1.91300227 -2.20421235]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.91300227, -2.20421235]), 'currentState': array([2.08518893, 3.57897296]), 'targetState': array([-0.01269692,  0.10698828]), 'effectorPosition': array([0.32243935, 0.29035166])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9347597865969229
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.91300227, -2.20421235]), 'currentState': array([2.15374338, 3.12260294]), 'targetState': array([-0.01269692,  0.10698828]), 'effectorPosition': array([-0.01595175, -0.01030244])}
episode index:2577
target Thresh 1.9896027438055266
current state at start:  [-0.13946131 -2.65450502]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.13946131, -2.65450502]), 'currentState': array([5.68055761, 4.06293514]), 'targetState': array([-0.23212322, -1.01091154]), 'effectorPosition': array([-0.12578986, -0.88015559])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9347850931188015
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.13946131, -2.65450502]), 'currentState': array([5.68055761, 4.06293514]), 'targetState': array([-0.23212322, -1.01091154]), 'effectorPosition': array([-0.12578986, -0.88015559])}
episode index:2578
target Thresh 1.9896235175372592
current state at start:  [-2.49527257  2.05426878]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.49527257,  2.05426878]), 'currentState': array([3.34399171, 2.10192337]), 'targetState': array([-0.40349069, -0.95560816]), 'effectorPosition': array([-0.31009409, -0.94383832])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9348103800156148
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.49527257,  2.05426878]), 'currentState': array([3.34399171, 2.10192337]), 'targetState': array([-0.40349069, -0.95560816]), 'effectorPosition': array([-0.31009409, -0.94383832])}
episode index:2579
target Thresh 1.9896442497630482
current state at start:  [0.89187537 2.15079639]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.89187537, 2.15079639]), 'currentState': array([0.45303492, 2.65079639]), 'targetState': array([0.18733407, 0.27084673]), 'effectorPosition': array([-0.10016426,  0.47544868])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9348241352946784
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([0.89187537, 2.15079639]), 'currentState': array([5.53235247, 2.9860245 ]), 'targetState': array([0.18733407, 0.27084673]), 'effectorPosition': array([0.11453772, 0.10504185])}
episode index:2580
target Thresh 1.9896649405658224
current state at start:  [-0.37736119  2.2488584 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.37736119,  2.2488584 ]), 'currentState': array([5.40582412, 2.7488584 ]), 'targetState': array([ 0.39756634, -0.09928732]), 'effectorPosition': array([0.34299305, 0.18607425])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9348378799148666
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-0.37736119,  2.2488584 ]), 'currentState': array([4.8374767 , 2.81935501]), 'targetState': array([ 0.39756634, -0.09928732]), 'effectorPosition': array([ 0.32063703, -0.01155791])}
episode index:2581
target Thresh 1.9896855900283452
current state at start:  [0.49262934 2.5848252 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.49262934, 2.5848252 ]), 'currentState': array([0.02567508, 3.0848252 ]), 'targetState': array([-0.0135204,  0.2283668]), 'effectorPosition': array([0.00015374, 0.05675963])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9348631169869367
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.49262934, 2.5848252 ]), 'currentState': array([0.02567508, 3.0848252 ]), 'targetState': array([-0.0135204,  0.2283668]), 'effectorPosition': array([0.00015374, 0.05675963])}
episode index:2582
target Thresh 1.989706198233214
current state at start:  [0.71869246 2.04209759]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.71869246, 2.04209759]), 'currentState': array([0.228768  , 2.54209759]), 'targetState': array([0.05593941, 0.18179005]), 'effectorPosition': array([0.04188234, 0.589071  ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9348844630508208
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.71869246, 2.04209759]), 'currentState': array([6.03973473, 3.04209759]), 'targetState': array([0.05593941, 0.18179005]), 'effectorPosition': array([0.02874374, 0.09520978])}
episode index:2583
target Thresh 1.9897267652628623
current state at start:  [-3.65598798  2.26911778]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.65598798,  2.26911778]), 'currentState': array([2.15681658, 2.76911778]), 'targetState': array([-0.26214789,  0.4520066 ]), 'effectorPosition': array([-0.34112362, -0.14413743])}
done in step count: 47
reward sum = 0.6235253948912
running average episode reward sum: 0.9347639680554031
{'reset': False, 'endBeforeDone': False, 'stepCount': 48, 'initial state': array([-3.65598798,  2.26911778]), 'currentState': array([2.92839201, 3.69475447]), 'targetState': array([-0.26214789,  0.4520066 ]), 'effectorPosition': array([-0.03459108,  0.54503964])}
episode index:2584
target Thresh 1.989747291199558
current state at start:  [-0.16791179 -2.48177685]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.16791179, -2.48177685]), 'currentState': array([5.6572097 , 3.97611713]), 'targetState': array([ 0.33354522, -0.50270142]), 'effectorPosition': array([-0.16794048, -0.79292861])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9344023572360393
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([-0.16791179, -2.48177685]), 'currentState': array([4.23723352, 4.27048078]), 'targetState': array([ 0.33354522, -0.50270142]), 'effectorPosition': array([-1.06563039, -0.09540232])}
episode index:2585
target Thresh 1.9897677761254047
current state at start:  [ 1.55470214 -1.92833491]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.55470214, -1.92833491]), 'currentState': array([2.03243477, 4.6940014 ]), 'targetState': array([0.49539253, 0.77775619]), 'effectorPosition': array([0.45794658, 1.32420234])}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9343907484648765
{'reset': False, 'endBeforeDone': False, 'stepCount': 11, 'initial state': array([ 1.55470214, -1.92833491]), 'currentState': array([0.17188559, 2.20847258]), 'targetState': array([0.49539253, 0.77775619]), 'effectorPosition': array([0.26127901, 0.86085617])}
episode index:2586
target Thresh 1.9897882201223422
current state at start:  [-3.2547342   2.36831159]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.2547342 ,  2.36831159]), 'currentState': array([3.52845111, 2.28578314]), 'targetState': array([ 0.41105697, -1.1421243 ]), 'effectorPosition': array([-0.03405602, -0.82923173])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9344122441168033
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.2547342 ,  2.36831159]), 'currentState': array([4.02845111, 1.84142477]), 'targetState': array([ 0.41105697, -1.1421243 ]), 'effectorPosition': array([ 0.28394651, -1.17673288])}
episode index:2587
target Thresh 1.9898086232721468
current state at start:  [-3.79358874  2.33962937]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.79358874,  2.33962937]), 'currentState': array([2.00769027, 2.83962937]), 'targetState': array([0.04703822, 0.03945401]), 'effectorPosition': array([-0.2886056 , -0.08484037])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9344337231569436
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.79358874,  2.33962937]), 'currentState': array([2.13505485, 3.31313829]), 'targetState': array([0.04703822, 0.03945401]), 'effectorPosition': array([0.13639407, 0.10369411])}
episode index:2588
target Thresh 1.9898289856564308
current state at start:  [ 2.4908133  -1.64562289]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.4908133 , -1.64562289]), 'currentState': array([2.94019882, 5.11469313]), 'targetState': array([-0.94837893,  0.97440789]), 'effectorPosition': array([-1.17935014,  1.1799205 ])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.9344364448356782
{'reset': False, 'endBeforeDone': False, 'stepCount': 7, 'initial state': array([ 2.4908133 , -1.64562289]), 'currentState': array([1.43697418, 1.71552273]), 'targetState': array([-0.94837893,  0.97440789]), 'effectorPosition': array([-0.86651747,  0.98015513])}
episode index:2589
target Thresh 1.9898493073566437
current state at start:  [1.07871164 2.04481555]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.07871164, 2.04481555]), 'currentState': array([1.56260676, 2.07204738]), 'targetState': array([-1.05263068,  0.62429378]), 'effectorPosition': array([-0.87269843,  0.52664154])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9344617589496412
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.07871164, 2.04481555]), 'currentState': array([1.56260676, 2.07204738]), 'targetState': array([-1.05263068,  0.62429378]), 'effectorPosition': array([-0.87269843,  0.52664154])}
episode index:2590
target Thresh 1.9898695884540727
current state at start:  [-0.43720673  2.26230668]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.43720673,  2.26230668]), 'currentState': array([0.06279327, 1.8449399 ]), 'targetState': array([0.58573712, 0.91667224]), 'effectorPosition': array([0.66743143, 1.00652377])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9344870535235704
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.43720673,  2.26230668]), 'currentState': array([0.06279327, 1.8449399 ]), 'targetState': array([0.58573712, 0.91667224]), 'effectorPosition': array([0.66743143, 1.00652377])}
episode index:2591
target Thresh 1.989889829029842
current state at start:  [-4.14208245  2.48950104]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.14208245,  2.48950104]), 'currentState': array([2.60430772, 2.07622296]), 'targetState': array([-0.89562545, -0.53137556]), 'effectorPosition': array([-0.89095434, -0.48768721])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9345123285800814
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.14208245,  2.48950104]), 'currentState': array([2.60430772, 2.07622296]), 'targetState': array([-0.89562545, -0.53137556]), 'effectorPosition': array([-0.89095434, -0.48768721])}
episode index:2592
target Thresh 1.9899100291649139
current state at start:  [-0.95518882 -2.50023438]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.95518882, -2.50023438]), 'currentState': array([4.82799649, 3.28295093]), 'targetState': array([0.55588437, 0.29643986]), 'effectorPosition': array([-0.13879697, -0.02615932])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9345223878478869
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([-0.95518882, -2.50023438]), 'currentState': array([5.40053175, 2.41119054]), 'targetState': array([0.55588437, 0.29643986]), 'effectorPosition': array([0.67735047, 0.22668033])}
episode index:2593
target Thresh 1.9899301889400889
current state at start:  [ 0.0218387  -2.48172468]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.0218387 , -2.48172468]), 'currentState': array([5.81447367, 3.30146063]), 'targetState': array([ 0.95750813, -0.00324835]), 'effectorPosition': array([-0.06053465, -0.14778003])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.934532439359896
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([ 0.0218387 , -2.48172468]), 'currentState': array([5.02558554, 2.32829163]), 'targetState': array([ 0.95750813, -0.00324835]), 'effectorPosition': array([ 0.78761848, -0.07382109])}
episode index:2594
target Thresh 1.9899503084360062
current state at start:  [-0.66704805  1.93773888]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.66704805,  1.93773888]), 'currentState': array([6.11613726, 1.84711617]), 'targetState': array([0.45740396, 1.20453253]), 'effectorPosition': array([0.87702542, 0.82776356])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.934538781406347
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([-0.66704805,  1.93773888]), 'currentState': array([0.49539118, 1.62841936]), 'targetState': array([0.45740396, 1.20453253]), 'effectorPosition': array([0.35452828, 1.326321  ])}
episode index:2595
target Thresh 1.989970387733144
current state at start:  [0.94718259 2.56307122]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.94718259, 2.56307122]), 'currentState': array([1.44718259, 3.00508654]), 'targetState': array([-0.65737586,  0.10521614]), 'effectorPosition': array([-0.1338972 ,  0.02601039])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9345601455121226
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.94718259, 2.56307122]), 'currentState': array([1.94718259, 2.50508654]), 'targetState': array([-0.65737586,  0.10521614]), 'effectorPosition': array([-0.62475848, -0.03636018])}
episode index:2596
target Thresh 1.9899904269118194
current state at start:  [2.17008452 1.91099346]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.17008452, 1.91099346]), 'currentState': array([2.67008452, 2.38372988]), 'targetState': array([-0.79521877, -0.94948421]), 'effectorPosition': array([-0.55605369, -0.48804797])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9345814931649866
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([2.17008452, 1.91099346]), 'currentState': array([3.17008452, 1.88372988]), 'targetState': array([-0.79521877, -0.94948421]), 'effectorPosition': array([-0.66476357, -0.97076636])}
episode index:2597
target Thresh 1.990010426052189
current state at start:  [-3.49113737  2.06766278]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.49113737,  2.06766278]), 'currentState': array([2.34237405, 1.59724027]), 'targetState': array([-0.99025437, -0.59645426]), 'effectorPosition': array([-1.39539155e+00,  8.35097723e-04])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9345952412430601
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-3.49113737,  2.06766278]), 'currentState': array([2.83241319, 2.06002662]), 'targetState': array([-0.99025437, -0.59645426]), 'effectorPosition': array([-0.77350398, -0.67955748])}
episode index:2598
target Thresh 1.9900303852342494
current state at start:  [1.85054862 2.16167945]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.85054862, 2.16167945]), 'currentState': array([1.97408902, 2.62223411]), 'targetState': array([-0.23206153, -0.11045741]), 'effectorPosition': array([-0.50825443, -0.07349815])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9346165589647826
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.85054862, 2.16167945]), 'currentState': array([2.40987002, 2.98058493]), 'targetState': array([-0.23206153, -0.11045741]), 'effectorPosition': array([-0.11673653, -0.11063506])}
episode index:2599
target Thresh 1.9900503045378375
current state at start:  [ 2.02961725 -2.75775103]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.02961725, -2.75775103]), 'currentState': array([2.07627146, 4.00835084]), 'targetState': array([0.528012  , 0.56415002]), 'effectorPosition': array([0.49612784, 0.67768373])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9346417064421039
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.02961725, -2.75775103]), 'currentState': array([2.07627146, 4.00835084]), 'targetState': array([0.528012  , 0.56415002]), 'effectorPosition': array([0.49612784, 0.67768373])}
episode index:2600
target Thresh 1.9900701840426307
current state at start:  [-2.32181367  2.12014094]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.32181367,  2.12014094]), 'currentState': array([3.46137164, 2.57362166]), 'targetState': array([-0.55360371, -0.08439727]), 'effectorPosition': array([ 0.02005322, -0.56000853])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9346554155130604
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-2.32181367,  2.12014094]), 'currentState': array([1.96137164, 2.61763707]), 'targetState': array([-0.55360371, -0.08439727]), 'effectorPosition': array([-0.51370561, -0.06642785])}
episode index:2601
target Thresh 1.9900900238281465
current state at start:  [1.0889918 2.7977858]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.0889918, 2.7977858]), 'currentState': array([1.443236  , 3.29745475]), 'targetState': array([-0.55918118, -0.47558503]), 'effectorPosition': array([ 0.15551267, -0.00772432])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9346691140466834
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([1.0889918, 2.7977858]), 'currentState': array([2.73872332, 2.58695363]), 'targetState': array([-0.55918118, -0.47558503]), 'effectorPosition': array([-0.3443805 , -0.42570045])}
episode index:2602
target Thresh 1.9901098239737447
current state at start:  [-2.42157466  1.78517708]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.42157466,  1.78517708]), 'currentState': array([3.36161065, 2.20373874]), 'targetState': array([-0.70745332, -0.66472187]), 'effectorPosition': array([-0.22266259, -0.87600334])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9346903706298386
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.42157466,  1.78517708]), 'currentState': array([2.86161065, 2.01399832]), 'targetState': array([-0.70745332, -0.66472187]), 'effectorPosition': array([-0.79856417, -0.71037081])}
episode index:2603
target Thresh 1.9901295845586253
current state at start:  [-0.70890474 -2.54401627]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.70890474, -2.54401627]), 'currentState': array([5.07428057, 3.23916903]), 'targetState': array([0.42464167, 0.11136177]), 'effectorPosition': array([-0.08942738, -0.03894023])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9347078090435753
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-0.70890474, -2.54401627]), 'currentState': array([4.91680062, 2.7481643 ]), 'targetState': array([0.42464167, 0.11136177]), 'effectorPosition': array([0.3908843 , 0.00300888])}
episode index:2604
target Thresh 1.9901493056618313
current state at start:  [0.89300338 3.00403751]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.89300338, 3.00403751]), 'currentState': array([0.5034515 , 2.52082417]), 'targetState': array([0.38876736, 0.81240044]), 'effectorPosition': array([-0.11720365,  0.59949971])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9347290344527716
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.89300338, 3.00403751]), 'currentState': array([0.10834182, 2.22532759]), 'targetState': array([0.38876736, 0.81240044]), 'effectorPosition': array([0.30313565, 0.83098368])}
episode index:2605
target Thresh 1.9901689873622466
current state at start:  [-0.82529859 -1.84679542]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.82529859, -1.84679542]), 'currentState': array([4.95788672, 4.21296937]), 'targetState': array([-0.32911599, -0.83183053]), 'effectorPosition': array([-0.72489552, -0.71881447])}
done in step count: 97
reward sum = 0.37723664692350417
running average episode reward sum: 0.934515107980197
{'reset': False, 'endBeforeDone': False, 'stepCount': 98, 'initial state': array([-0.82529859, -1.84679542]), 'currentState': array([3.27408708, 2.03589251]), 'targetState': array([-0.32911599, -0.83183053]), 'effectorPosition': array([-0.42858317, -0.95880078])}
episode index:2606
target Thresh 1.9901886297385982
current state at start:  [ 1.39532761 -2.56194477]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.39532761, -2.56194477]), 'currentState': array([0.89737664, 4.21350913]), 'targetState': array([ 0.83952058, -0.47987799]), 'effectorPosition': array([ 1.01169613, -0.13995182])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9345363910227822
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.39532761, -2.56194477]), 'currentState': array([0.4768544, 3.9651779]), 'targetState': array([ 0.83952058, -0.47987799]), 'effectorPosition': array([ 0.62136792, -0.50468893])}
episode index:2607
target Thresh 1.990208232869456
current state at start:  [0.97428798 2.97912891]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.97428798, 2.97912891]), 'currentState': array([1.34396558, 3.27910264]), 'targetState': array([-0.01673923,  0.10447038]), 'effectorPosition': array([ 0.13568855, -0.02162953])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.934561492099844
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.97428798, 2.97912891]), 'currentState': array([1.34396558, 3.27910264]), 'targetState': array([-0.01673923,  0.10447038]), 'effectorPosition': array([ 0.13568855, -0.02162953])}
episode index:2608
target Thresh 1.9902277968332318
current state at start:  [-0.9931887  -2.09302753]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.9931887 , -2.09302753]), 'currentState': array([4.85525579, 3.69746466]), 'targetState': array([-0.62394276, -0.15090658]), 'effectorPosition': array([-0.50087127, -0.22415783])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9345865739349917
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.9931887 , -2.09302753]), 'currentState': array([4.85525579, 3.69746466]), 'targetState': array([-0.62394276, -0.15090658]), 'effectorPosition': array([-0.50087127, -0.22415783])}
episode index:2609
target Thresh 1.9902473217081822
current state at start:  [ 0.32357885 -2.7124286 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.32357885, -2.7124286 ]), 'currentState': array([6.16735135, 4.04714131]), 'targetState': array([-0.30722039, -1.33447065]), 'effectorPosition': array([ 0.2892508 , -0.82572754])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9346040120292695
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 0.32357885, -2.7124286 ]), 'currentState': array([5.24242045, 4.53248349]), 'targetState': array([-0.30722039, -1.33447065]), 'effectorPosition': array([-0.43376901, -1.20580731])}
episode index:2610
target Thresh 1.9902668075724064
current state at start:  [-2.96514395  2.37728206]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.96514395,  2.37728206]), 'currentState': array([2.83605627, 1.87728206]), 'targetState': array([-0.87565876, -0.6328324 ]), 'effectorPosition': array([-0.95273639, -0.69919479])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9346290583670599
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.96514395,  2.37728206]), 'currentState': array([2.83605627, 1.87728206]), 'targetState': array([-0.87565876, -0.6328324 ]), 'effectorPosition': array([-0.95273639, -0.69919479])}
episode index:2611
target Thresh 1.9902862545038478
current state at start:  [ 2.86674049 -2.15120498]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.86674049, -2.15120498]), 'currentState': array([2.94021443, 3.63198033]), 'targetState': array([0.11384499, 0.33629992]), 'effectorPosition': array([-0.02126518,  0.48502279])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.93465408552695
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.86674049, -2.15120498]), 'currentState': array([2.94021443, 3.63198033]), 'targetState': array([0.11384499, 0.33629992]), 'effectorPosition': array([-0.02126518,  0.48502279])}
episode index:2612
target Thresh 1.9903056625802942
current state at start:  [-1.57201131  1.62482506]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.57201131,  1.62482506]), 'currentState': array([5.0966474, 1.6983695]), 'targetState': array([ 1.36161117, -0.22276322]), 'effectorPosition': array([ 1.24672064, -0.43730175])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.934679093530958
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.57201131,  1.62482506]), 'currentState': array([5.0966474, 1.6983695]), 'targetState': array([ 1.36161117, -0.22276322]), 'effectorPosition': array([ 1.24672064, -0.43730175])}
episode index:2613
target Thresh 1.9903250318793781
current state at start:  [-4.20611979  2.50177273]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.20611979,  2.50177273]), 'currentState': array([2.33930417, 2.95252538]), 'targetState': array([-0.03437076, -0.12840554]), 'effectorPosition': array([-0.14750732, -0.11782049])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9347040824010686
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.20611979,  2.50177273]), 'currentState': array([2.33930417, 2.95252538]), 'targetState': array([-0.03437076, -0.12840554]), 'effectorPosition': array([-0.14750732, -0.11782049])}
episode index:2614
target Thresh 1.9903443624785766
current state at start:  [-4.31273722  2.75154183]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.31273722,  2.75154183]), 'currentState': array([1.53987951, 3.18710155]), 'targetState': array([0.09956389, 0.45775006]), 'effectorPosition': array([ 0.04550345, -0.00037142])}
done in step count: 123
reward sum = 0.29048849430996376
running average episode reward sum: 0.9344577284476877
{'reset': False, 'endBeforeDone': False, 'stepCount': 124, 'initial state': array([-4.31273722,  2.75154183]), 'currentState': array([2.26042183, 3.74774858]), 'targetState': array([0.09956389, 0.45775006]), 'effectorPosition': array([0.32617285, 0.49992306])}
episode index:2615
target Thresh 1.9903636544552121
current state at start:  [-3.9632843   2.74700048]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.9632843 ,  2.74700048]), 'currentState': array([2.81990101, 2.84955332]), 'targetState': array([ 0.03945024, -1.15680427]), 'effectorPosition': array([-0.13119697, -0.25974968])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9344751757991986
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-3.9632843 ,  2.74700048]), 'currentState': array([3.81990101, 1.84955332]), 'targetState': array([ 0.03945024, -1.15680427]), 'effectorPosition': array([ 0.03886966, -1.2033983 ])}
episode index:2616
target Thresh 1.9903829078864528
current state at start:  [ 0.56088964 -2.00324667]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.56088964, -2.00324667]), 'currentState': array([0.36185894, 4.00634843]), 'targetState': array([ 0.96053012, -0.42257407]), 'effectorPosition': array([ 0.59781396, -0.58733851])}
done in step count: 138
reward sum = 0.2498370564584527
running average episode reward sum: 0.9342135639843951
{'reset': False, 'endBeforeDone': False, 'stepCount': 139, 'initial state': array([ 0.56088964, -2.00324667]), 'currentState': array([4.93400183, 1.99493315]), 'targetState': array([ 0.96053012, -0.42257407]), 'effectorPosition': array([ 1.01845215, -0.37374687])}
episode index:2617
target Thresh 1.9904021228493118
current state at start:  [-2.2998684   2.60680011]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.2998684 ,  2.60680011]), 'currentState': array([3.49383763, 3.0438242 ]), 'targetState': array([-0.67091919,  0.2802451 ]), 'effectorPosition': array([ 0.02919466, -0.09326699])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.934223641312896
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([-2.2998684 ,  2.60680011]), 'currentState': array([1.54017115, 2.59504384]), 'targetState': array([-0.67091919,  0.2802451 ]), 'effectorPosition': array([-0.51503751,  0.16152306])}
episode index:2618
target Thresh 1.9904212994206498
current state at start:  [ 2.50919631 -2.76303348]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.50919631, -2.76303348]), 'currentState': array([2.0689682 , 4.02015183]), 'targetState': array([-0.23501958,  1.29623644]), 'effectorPosition': array([0.50340795, 0.68560811])}
done in step count: 32
reward sum = 0.7249803359578534
running average episode reward sum: 0.9341437469618632
{'reset': False, 'endBeforeDone': False, 'stepCount': 33, 'initial state': array([ 2.50919631, -2.76303348]), 'currentState': array([0.75867258, 1.71150944]), 'targetState': array([-0.23501958,  1.29623644]), 'effectorPosition': array([-0.05719505,  1.31004973])}
episode index:2619
target Thresh 1.9904404376771725
current state at start:  [-4.14791967  3.04040893]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.14791967,  3.04040893]), 'currentState': array([1.69313752, 3.54040893]), 'targetState': array([0.58333055, 0.80954071]), 'effectorPosition': array([0.37584804, 0.12528217])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.934165066142412
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-4.14791967,  3.04040893]), 'currentState': array([1.85512066, 4.04040893]), 'targetState': array([0.58333055, 0.80954071]), 'effectorPosition': array([0.64528881, 0.58183228])}
episode index:2620
target Thresh 1.9904595376954333
current state at start:  [ 1.32857408 -2.26050161]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.32857408, -2.26050161]), 'currentState': array([1.82857408, 3.93840685]), 'targetState': array([0.25428413, 0.85380712]), 'effectorPosition': array([0.61476653, 0.47337623])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9338086506269055
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([ 1.32857408, -2.26050161]), 'currentState': array([1.94105197, 4.04388245]), 'targetState': array([0.25428413, 0.85380712]), 'effectorPosition': array([0.59399816, 0.63838611])}
episode index:2621
target Thresh 1.9904785995518322
current state at start:  [-2.22806641  2.75416451]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.22806641,  2.75416451]), 'currentState': array([3.64933029, 3.13861745]), 'targetState': array([-0.11362392, -0.03143831]), 'effectorPosition': array([ 0.00144268, -0.00260202])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9338338952300227
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.22806641,  2.75416451]), 'currentState': array([3.64933029, 3.13861745]), 'targetState': array([-0.11362392, -0.03143831]), 'effectorPosition': array([ 0.00144268, -0.00260202])}
episode index:2622
target Thresh 1.9904976233226164
current state at start:  [ 0.71830073 -2.60707731]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.71830073, -2.60707731]), 'currentState': array([0.25933691, 4.14597928]), 'targetState': array([ 0.28053299, -1.07043514]), 'effectorPosition': array([ 0.66429058, -0.69678276])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9338553081559738
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.71830073, -2.60707731]), 'currentState': array([6.11096415, 4.39452188]), 'targetState': array([ 0.28053299, -1.07043514]), 'effectorPosition': array([ 0.5145028 , -1.05366239])}
episode index:2623
target Thresh 1.9905166090838813
current state at start:  [2.23547869 1.62785167]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.23547869, 1.62785167]), 'currentState': array([2.66871019, 2.06975958]), 'targetState': array([-1.12868811, -0.22366926]), 'effectorPosition': array([-0.86418132, -0.54420561])}
done in step count: 20
reward sum = 0.8179069375972308
running average episode reward sum: 0.9338111205147548
{'reset': False, 'endBeforeDone': False, 'stepCount': 21, 'initial state': array([2.23547869, 1.62785167]), 'currentState': array([2.32712506, 2.17941365]), 'targetState': array([-1.12868811, -0.22366926]), 'effectorPosition': array([-0.8906553 , -0.25152721])}
episode index:2624
target Thresh 1.99053555691157
current state at start:  [ 3.60213109 -2.42738918]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.60213109, -2.42738918]), 'currentState': array([3.68361094, 3.57556936]), 'targetState': array([-0.35612566,  0.54850064]), 'effectorPosition': array([-0.29632504,  0.31239379])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9338363353259873
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.60213109, -2.42738918]), 'currentState': array([3.68361094, 3.57556936]), 'targetState': array([-0.35612566,  0.54850064]), 'effectorPosition': array([-0.29632504,  0.31239379])}
episode index:2625
target Thresh 1.9905544668814734
current state at start:  [ 2.57930497 -1.96799315]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.57930497, -1.96799315]), 'currentState': array([2.07930497, 4.72976264]), 'targetState': array([0.31746904, 0.91246872]), 'effectorPosition': array([0.37800625, 1.37544787])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9334807236217504
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([ 2.57930497, -1.96799315]), 'currentState': array([1.83687275, 4.17234017]), 'targetState': array([0.31746904, 0.91246872]), 'effectorPosition': array([0.69975577, 0.69425223])}
episode index:2626
target Thresh 1.9905733390692322
current state at start:  [-0.38226328  1.6314531 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.38226328,  1.6314531 ]), 'currentState': array([0.03548398, 1.32111219]), 'targetState': array([0.44008368, 1.22779063]), 'effectorPosition': array([1.21193645, 1.01262325])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9331253826534894
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([-0.38226328,  1.6314531 ]), 'currentState': array([1.46531451, 5.47426454]), 'targetState': array([0.44008368, 1.22779063]), 'effectorPosition': array([0.89748446, 1.60470591])}
episode index:2627
target Thresh 1.9905921735503342
current state at start:  [ 3.53812763 -2.21620577]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.53812763, -2.21620577]), 'currentState': array([4.03812763, 3.56697953]), 'targetState': array([0.0837339 , 0.29495937]), 'effectorPosition': array([-0.37800721,  0.18802195])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9327703121121448
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([ 3.53812763, -2.21620577]), 'currentState': array([3.86739459, 3.31663064]), 'targetState': array([0.0837339 , 0.29495937]), 'effectorPosition': array([-0.12701558,  0.12011326])}
episode index:2628
target Thresh 1.9906109704001183
current state at start:  [-2.17414552  2.50892272]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.17414552,  2.50892272]), 'currentState': array([3.69765914, 2.96039933]), 'targetState': array([ 0.31153929, -0.03983474]), 'effectorPosition': array([ 0.08121609, -0.16169491])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9327883150364081
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-2.17414552,  2.50892272]), 'currentState': array([3.89364505, 2.99838224]), 'targetState': array([ 0.31153929, -0.03983474]), 'effectorPosition': array([ 0.09002252, -0.11122113])}
episode index:2629
target Thresh 1.9906297296937714
current state at start:  [-3.15828802  2.14231189]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.15828802,  2.14231189]), 'currentState': array([2.68712257, 2.40860276]), 'targetState': array([-0.16220972, -0.49658006]), 'effectorPosition': array([-0.52447703, -0.4884357 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9328100685287896
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.15828802,  2.14231189]), 'currentState': array([2.9029439, 2.4762937]), 'targetState': array([-0.16220972, -0.49658006]), 'effectorPosition': array([-0.3531455 , -0.54938484])}
episode index:2630
target Thresh 1.9906484515063305
current state at start:  [0.8783654  2.48994059]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.8783654 , 2.48994059]), 'currentState': array([0.3783654 , 2.87916319]), 'targetState': array([0.64879097, 0.33258554]), 'effectorPosition': array([-0.06401725,  0.25372559])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.932824317457513
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([0.8783654 , 2.48994059]), 'currentState': array([5.48224974, 2.57086278]), 'targetState': array([0.64879097, 0.33258554]), 'effectorPosition': array([0.4982178 , 0.26223128])}
episode index:2631
target Thresh 1.9906671359126835
current state at start:  [-1.86442215 -2.55345938]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.86442215, -2.55345938]), 'currentState': array([4.70024401, 4.0089342 ]), 'targetState': array([-0.63332702, -0.63101693]), 'effectorPosition': array([-0.76684457, -0.34385608])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9324699009235246
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([-1.86442215, -2.55345938]), 'currentState': array([4.46956026, 4.74275965]), 'targetState': array([-0.63332702, -0.63101693]), 'effectorPosition': array([-1.21796487, -0.75979838])}
episode index:2632
target Thresh 1.9906857829875675
current state at start:  [-1.80188935  1.99954097]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.80188935,  1.99954097]), 'currentState': array([4.27804117, 2.44736878]), 'targetState': array([ 0.77918871, -0.0720247 ]), 'effectorPosition': array([ 0.482983  , -0.47919353])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9324917505623685
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.80188935,  1.99954097]), 'currentState': array([4.74684008, 2.43713451]), 'targetState': array([ 0.77918871, -0.0720247 ]), 'effectorPosition': array([ 0.65543579, -0.21558933])}
episode index:2633
target Thresh 1.990704392805571
current state at start:  [-1.28475373  2.37347829]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.28475373,  2.37347829]), 'currentState': array([4.49843158, 2.87347829]), 'targetState': array([-0.05079949,  0.19833792]), 'effectorPosition': array([ 0.25128711, -0.09116198])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9325135836107503
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.28475373,  2.37347829]), 'currentState': array([4.01343627, 3.36846331]), 'targetState': array([-0.05079949,  0.19833792]), 'effectorPosition': array([-0.18867472,  0.12510697])}
episode index:2634
target Thresh 1.9907229654411336
current state at start:  [1.14647299 1.69020067]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.14647299, 1.69020067]), 'currentState': array([0.64647299, 1.85321993]), 'targetState': array([-0.25181751,  1.38565769]), 'effectorPosition': array([-0.00274646,  1.20109299])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9325354000875583
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.14647299, 1.69020067]), 'currentState': array([1.07846985, 1.57943302]), 'targetState': array([-0.25181751,  1.38565769]), 'effectorPosition': array([-0.41260768,  1.34628441])}
episode index:2635
target Thresh 1.9907415009685454
current state at start:  [ 3.84673349 -2.37236032]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.84673349, -2.37236032]), 'currentState': array([4.24222575, 3.62506074]), 'targetState': array([ 0.26363769, -0.55793998]), 'effectorPosition': array([-0.46633627,  0.10841714])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9321816309676465
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([ 3.84673349, -2.37236032]), 'currentState': array([4.22369553, 4.35336946]), 'targetState': array([ 0.26363769, -0.55793998]), 'effectorPosition': array([-1.13117229, -0.13317796])}
episode index:2636
target Thresh 1.9907599994619487
current state at start:  [ 1.63305271 -3.00992768]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.63305271, -3.00992768]), 'currentState': array([1.78524237, 3.05544266]), 'targetState': array([0.04576817, 0.08446879]), 'effectorPosition': array([-0.08486181, -0.01468691])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9322073489687964
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.63305271, -3.00992768]), 'currentState': array([1.78524237, 3.05544266]), 'targetState': array([0.04576817, 0.08446879]), 'effectorPosition': array([-0.08486181, -0.01468691])}
episode index:2637
target Thresh 1.9907784609953376
current state at start:  [-2.11892167  1.82145377]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.11892167,  1.82145377]), 'currentState': array([4.12227834, 2.09739106]), 'targetState': array([ 0.49114539, -1.00254986]), 'effectorPosition': array([ 0.44153059, -0.89435233])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9322330474718408
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.11892167,  1.82145377]), 'currentState': array([4.12227834, 2.09739106]), 'targetState': array([ 0.49114539, -1.00254986]), 'effectorPosition': array([ 0.44153059, -0.89435233])}
episode index:2638
target Thresh 1.990796885642558
current state at start:  [-1.44063538  2.84097573]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.44063538,  2.84097573]), 'currentState': array([4.35155926, 2.46696478]), 'targetState': array([ 0.40884994, -0.41545684]), 'effectorPosition': array([ 0.50704524, -0.4254718 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.932258726498945
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.44063538,  2.84097573]), 'currentState': array([4.35155926, 2.46696478]), 'targetState': array([ 0.40884994, -0.41545684]), 'effectorPosition': array([ 0.50704524, -0.4254718 ])}
episode index:2639
target Thresh 1.990815273477309
current state at start:  [-1.31071367  2.30539971]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.31071367,  2.30539971]), 'currentState': array([4.52855612, 2.53337027]), 'targetState': array([0.48172818, 0.04486985]), 'effectorPosition': array([ 0.52899916, -0.2807664 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.932280598193453
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.31071367,  2.30539971]), 'currentState': array([4.54484959, 2.72497828]), 'targetState': array([0.48172818, 0.04486985]), 'effectorPosition': array([ 0.38473697, -0.151819  ])}
episode index:2640
target Thresh 1.9908336245731415
current state at start:  [-0.64488111  1.67543666]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.64488111,  1.67543666]), 'currentState': array([5.55821386, 1.84561642]), 'targetState': array([0.35077692, 0.35667595]), 'effectorPosition': array([1.18362018, 0.23726718])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9322913196670638
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([-0.64488111,  1.67543666]), 'currentState': array([5.74095013, 2.62403471]), 'targetState': array([0.35077692, 0.35667595]), 'effectorPosition': array([0.36750481, 0.35620249])}
episode index:2641
target Thresh 1.99085193900346
current state at start:  [-0.06996418 -2.3068808 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.06996418, -2.3068808 ]), 'currentState': array([5.71322113, 4.47630451]), 'targetState': array([ 0.76923891, -0.74440632]), 'effectorPosition': array([ 0.12036322, -1.23195684])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9319384463439498
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([-0.06996418, -2.3068808 ]), 'currentState': array([4.28872616, 4.61654929]), 'targetState': array([ 0.76923891, -0.74440632]), 'effectorPosition': array([-1.27916846, -0.41514093])}
episode index:2642
target Thresh 1.9908702168415224
current state at start:  [0.70334084 2.15361241]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.70334084, 2.15361241]), 'currentState': array([0.28255153, 2.65361241]), 'targetState': array([0.65152878, 0.16232158]), 'effectorPosition': array([-0.01862644,  0.48279378])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.9319456546691698
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([0.70334084, 2.15361241]), 'currentState': array([5.17029027, 2.54350918]), 'targetState': array([0.65152878, 0.16232158]), 'effectorPosition': array([0.58179009, 0.09320832])}
episode index:2643
target Thresh 1.99088845816044
current state at start:  [ 2.46822163 -2.45205835]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.46822163, -2.45205835]), 'currentState': array([2.01838594, 4.07436811]), 'targetState': array([0.17671048, 0.73421287]), 'effectorPosition': array([0.54912885, 0.71221054])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9315931790055278
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([ 2.46822163, -2.45205835]), 'currentState': array([1.99658  , 3.8536887]), 'targetState': array([0.17671048, 0.73421287]), 'effectorPosition': array([0.49471143, 0.49119521])}
episode index:2644
target Thresh 1.9909066630331782
current state at start:  [-4.03473072  2.87964469]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.03473072,  2.87964469]), 'currentState': array([1.74845458, 3.37964469]), 'targetState': array([0.44861027, 0.48662771]), 'effectorPosition': array([0.22711465, 0.06943053])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9316115180682858
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-4.03473072,  2.87964469]), 'currentState': array([1.75319551, 3.80081737]), 'targetState': array([0.44861027, 0.48662771]), 'effectorPosition': array([0.56433656, 0.31715862])}
episode index:2645
target Thresh 1.9909248315325563
current state at start:  [0.28225582 1.99637003]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.28225582, 1.99637003]), 'currentState': array([6.06734573, 2.49637003]), 'targetState': array([0.11656827, 0.12150172]), 'effectorPosition': array([0.32516481, 0.54436755])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9316335847659167
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.28225582, 1.99637003]), 'currentState': array([5.6185463 , 2.94297032]), 'targetState': array([0.11656827, 0.12150172]), 'effectorPosition': array([0.13717707, 0.14319133])}
episode index:2646
target Thresh 1.9909429637312483
current state at start:  [ 3.33825674 -1.64263115]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.33825674, -1.64263115]), 'currentState': array([2.86463135, 4.59028821]), 'targetState': array([-0.24831594,  0.71282793]), 'effectorPosition': array([-0.57333648,  1.19485986])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9316556347905612
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.33825674, -1.64263115]), 'currentState': array([2.77524804, 4.09028821]), 'targetState': array([-0.24831594,  0.71282793]), 'effectorPosition': array([-0.09847099,  0.90819391])}
episode index:2647
target Thresh 1.9909610597017833
current state at start:  [ 3.94304897 -1.81077501]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.94304897, -1.81077501]), 'currentState': array([4.44304897, 4.69834771]), 'targetState': array([-0.38251953, -0.48606056]), 'effectorPosition': array([-1.22621081, -0.68434306])}
done in step count: 186
reward sum = 0.1542219517938446
running average episode reward sum: 0.9313620420099733
{'reset': False, 'endBeforeDone': False, 'stepCount': 187, 'initial state': array([ 3.94304897, -1.81077501]), 'currentState': array([5.37046454, 3.83695237]), 'targetState': array([-0.38251953, -0.48606056]), 'effectorPosition': array([-0.36487452, -0.57551715])}
episode index:2648
target Thresh 1.9909791195165452
current state at start:  [ 1.14171122 -2.07952178]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.14171122, -2.07952178]), 'currentState': array([1.26889242, 3.70974469]), 'targetState': array([0.56057508, 0.01914873]), 'effectorPosition': array([ 0.56045216, -0.00999274])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9313879529038918
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.14171122, -2.07952178]), 'currentState': array([1.26889242, 3.70974469]), 'targetState': array([0.56057508, 0.01914873]), 'effectorPosition': array([ 0.56045216, -0.00999274])}
episode index:2649
target Thresh 1.9909971432477729
current state at start:  [0.46711613 1.98512731]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.46711613, 1.98512731]), 'currentState': array([0.96711613, 1.67331414]), 'targetState': array([-0.05846174,  1.18731323]), 'effectorPosition': array([-0.30934865,  1.30369734])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9314100706575128
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.46711613, 1.98512731]), 'currentState': array([0.46897833, 2.08345054]), 'targetState': array([-0.05846174,  1.18731323]), 'effectorPosition': array([0.0606249 , 1.00764114])}
episode index:2650
target Thresh 1.9910151309675617
current state at start:  [-3.30737366  2.23487966]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.30737366,  2.23487966]), 'currentState': array([2.47729589, 2.73487966]), 'targetState': array([-0.00562651,  0.00130873]), 'effectorPosition': array([-0.3081123 , -0.26117927])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9314321717247864
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.30737366,  2.23487966]), 'currentState': array([2.05641239, 3.21601727]), 'targetState': array([-0.00562651,  0.00130873]), 'effectorPosition': array([0.06446738, 0.03715406])}
episode index:2651
target Thresh 1.9910330827478622
current state at start:  [0.7597916  2.01152787]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.7597916 , 2.01152787]), 'currentState': array([0.3216293 , 2.51152787]), 'targetState': array([-0.12898884,  0.26584763]), 'effectorPosition': array([-0.00408804,  0.61968106])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9314542561245884
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.7597916 , 2.01152787]), 'currentState': array([0.11873721, 3.01152787]), 'targetState': array([-0.12898884,  0.26584763]), 'effectorPosition': array([-0.00697683,  0.12978574])}
episode index:2652
target Thresh 1.9910509986604819
current state at start:  [ 1.08255864 -1.86863929]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.08255864, -1.86863929]), 'currentState': array([1.11003546, 4.18424129]), 'targetState': array([1.04920106, 0.14953185]), 'effectorPosition': array([0.99423176, 0.06028783])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.93148009319352
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.08255864, -1.86863929]), 'currentState': array([1.11003546, 4.18424129]), 'targetState': array([1.04920106, 0.14953185]), 'effectorPosition': array([0.99423176, 0.06028783])}
episode index:2653
target Thresh 1.9910688787770843
current state at start:  [ 0.82232435 -2.9393689 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.82232435, -2.9393689 ]), 'currentState': array([1.32098098, 2.94411698]), 'targetState': array([0.0121577 , 0.13487712]), 'effectorPosition': array([-0.1852996 ,  0.06733598])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.931505910792166
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.82232435, -2.9393689 ]), 'currentState': array([1.32098098, 2.94411698]), 'targetState': array([0.0121577 , 0.13487712]), 'effectorPosition': array([-0.1852996 ,  0.06733598])}
episode index:2654
target Thresh 1.99108672316919
current state at start:  [0.6820656  2.49814112]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.6820656 , 2.49814112]), 'currentState': array([0.21404361, 2.99814112]), 'targetState': array([0.40296692, 0.45405463]), 'effectorPosition': array([-0.02032942,  0.1418795 ])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9315242136506248
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([0.6820656 , 2.49814112]), 'currentState': array([5.80801496, 2.63813697]), 'targetState': array([0.40296692, 0.45405463]), 'effectorPosition': array([0.3310517 , 0.37224132])}
episode index:2655
target Thresh 1.9911045319081764
current state at start:  [0.99198251 1.9131657 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.99198251, 1.9131657 ]), 'currentState': array([0.58372705, 2.4131657 ]), 'targetState': array([0.10964915, 0.74967665]), 'effectorPosition': array([-0.15513489,  0.69533314])}
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.9315072184164627
{'reset': False, 'endBeforeDone': False, 'stepCount': 13, 'initial state': array([0.99198251, 1.9131657 ]), 'currentState': array([0.57189577, 2.36726562]), 'targetState': array([0.10964915, 0.74967665]), 'effectorPosition': array([-0.13870422,  0.74227867])}
episode index:2656
target Thresh 1.9911223050652784
current state at start:  [ 2.72895897 -2.13119107]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.72895897, -2.13119107]), 'currentState': array([2.39878208, 3.7003221 ]), 'targetState': array([-0.08347961,  0.13400025]), 'effectorPosition': array([0.24653435, 0.4933175 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9315292330124669
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 2.72895897, -2.13119107]), 'currentState': array([1.96765322, 3.24619189]), 'targetState': array([-0.08347961,  0.13400025]), 'effectorPosition': array([0.09418148, 0.0453969 ])}
episode index:2657
target Thresh 1.991140042711589
current state at start:  [1.2422356  2.86424784]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.2422356 , 2.86424784]), 'currentState': array([1.64211476, 2.79650667]), 'targetState': array([-0.5595648 , -0.28869749]), 'effectorPosition': array([-0.34161858,  0.03469878])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9315475064387226
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([1.2422356 , 2.86424784]), 'currentState': array([2.37468684, 2.69735255]), 'targetState': array([-0.5595648 , -0.28869749]), 'effectorPosition': array([-0.36811417, -0.24210936])}
episode index:2658
target Thresh 1.9911577449180586
current state at start:  [ 1.69362326 -2.09119362]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.69362326, -2.09119362]), 'currentState': array([1.51132859, 3.69730478]), 'targetState': array([0.02790417, 0.04994565]), 'effectorPosition': array([0.535559  , 0.11885541])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9315694893246049
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.69362326, -2.09119362]), 'currentState': array([1.85927303, 3.25062013]), 'targetState': array([0.02790417, 0.04994565]), 'effectorPosition': array([0.10262612, 0.03664831])}
episode index:2659
target Thresh 1.9911754117554963
current state at start:  [-2.90290694  2.47510694]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.90290694,  2.47510694]), 'currentState': array([3.75591501, 2.97510694]), 'targetState': array([ 0.46238828, -0.09045555]), 'effectorPosition': array([ 0.08422175, -0.14338838])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9315877338774905
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-2.90290694,  2.47510694]), 'currentState': array([4.41011473, 2.84269898]), 'targetState': array([ 0.46238828, -0.09045555]), 'effectorPosition': array([ 0.26791391, -0.12998634])}
episode index:2660
target Thresh 1.991193043294569
current state at start:  [-0.33376026 -1.82546397]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.33376026, -1.82546397]), 'currentState': array([5.44942505, 4.09237502]), 'targetState': array([-0.00791767, -0.87384118]), 'effectorPosition': array([-0.32106454, -0.85721906])}
done in step count: 66
reward sum = 0.5151371174238033
running average episode reward sum: 0.9314312323305332
{'reset': False, 'endBeforeDone': False, 'stepCount': 67, 'initial state': array([-0.33376026, -1.82546397]), 'currentState': array([5.66690062, 3.93701131]), 'targetState': array([-0.00791767, -0.87384118]), 'effectorPosition': array([-0.16796681, -0.75618481])}
episode index:2661
target Thresh 1.9912106396058031
current state at start:  [-2.89838137  1.74453823]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.89838137,  1.74453823]), 'currentState': array([3.8808461 , 2.06813074]), 'targetState': array([ 0.38501862, -1.09149118]), 'effectorPosition': array([ 0.2056985 , -1.00175795])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.931456990695548
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.89838137,  1.74453823]), 'currentState': array([3.8808461 , 2.06813074]), 'targetState': array([ 0.38501862, -1.09149118]), 'effectorPosition': array([ 0.2056985 , -1.00175795])}
episode index:2662
target Thresh 1.991228200759584
current state at start:  [ 2.55739505 -2.3416354 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.55739505, -2.3416354 ]), 'currentState': array([2.15302784, 3.95552482]), 'targetState': array([0.19786385, 0.67581784]), 'effectorPosition': array([0.43490128, 0.66149126])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9314827297151892
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.55739505, -2.3416354 ]), 'currentState': array([2.15302784, 3.95552482]), 'targetState': array([0.19786385, 0.67581784]), 'effectorPosition': array([0.43490128, 0.66149126])}
episode index:2663
target Thresh 1.9912457268261563
current state at start:  [-0.16459752  2.37393493]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.16459752,  2.37393493]), 'currentState': array([5.64311147, 2.7979999 ]), 'targetState': array([1.19192903, 0.50817318]), 'effectorPosition': array([0.24807795, 0.23527949])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.9314864825003564
{'reset': False, 'endBeforeDone': False, 'stepCount': 7, 'initial state': array([-0.16459752,  2.37393493]), 'currentState': array([5.68239337, 2.02697296]), 'targetState': array([1.19192903, 0.50817318]), 'effectorPosition': array([0.96899996, 0.42426551])}
episode index:2664
target Thresh 1.9912632178756242
current state at start:  [ 2.08936681 -2.19924465]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.08936681, -2.19924465]), 'currentState': array([1.6382369 , 3.65596544]), 'targetState': array([0.49981241, 0.37879741]), 'effectorPosition': array([0.48215038, 0.16225924])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9315121911373169
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.08936681, -2.19924465]), 'currentState': array([1.6382369 , 3.65596544]), 'targetState': array([0.49981241, 0.37879741]), 'effectorPosition': array([0.48215038, 0.16225924])}
episode index:2665
target Thresh 1.9912806739779518
current state at start:  [-4.08686798  2.52154691]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.08686798,  2.52154691]), 'currentState': array([1.96833756, 3.02154691]), 'targetState': array([ 0.11260666, -0.33561431]), 'effectorPosition': array([-0.11320468, -0.03972886])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9315267398278131
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-4.08686798,  2.52154691]), 'currentState': array([3.350492  , 2.63763722]), 'targetState': array([ 0.11260666, -0.33561431]), 'effectorPosition': array([-0.02147393, -0.49817681])}
episode index:2666
target Thresh 1.991298095202964
current state at start:  [ 2.59840324 -2.55317121]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.59840324, -2.55317121]), 'currentState': array([2.12827417, 4.21937982]), 'targetState': array([0.53066213, 0.8117566 ]), 'effectorPosition': array([0.46887501, 0.91301619])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9315524140910947
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.59840324, -2.55317121]), 'currentState': array([2.12827417, 4.21937982]), 'targetState': array([0.53066213, 0.8117566 ]), 'effectorPosition': array([0.46887501, 0.91301619])}
episode index:2667
target Thresh 1.991315481620345
current state at start:  [-3.55915623  2.28753459]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.55915623,  2.28753459]), 'currentState': array([2.22402908, 2.7623448 ]), 'targetState': array([0.32502227, 0.08903797]), 'effectorPosition': array([-0.33718694, -0.16857712])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9315706103376873
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-3.55915623,  2.28753459]), 'currentState': array([1.52440076, 3.56217396]), 'targetState': array([0.32502227, 0.08903797]), 'effectorPosition': array([0.41189366, 0.06811836])}
episode index:2668
target Thresh 1.9913328332996412
current state at start:  [0.71329878 2.85231753]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.71329878, 2.85231753]), 'currentState': array([0.24671082, 3.29040687]), 'targetState': array([ 0.1720396 , -0.14746759]), 'effectorPosition': array([ 0.04692654, -0.14107704])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9315962489250468
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.71329878, 2.85231753]), 'currentState': array([0.24671082, 3.29040687]), 'targetState': array([ 0.1720396 , -0.14746759]), 'effectorPosition': array([ 0.04692654, -0.14107704])}
episode index:2669
target Thresh 1.991350150310259
current state at start:  [1.27265667 1.88843933]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.27265667, 1.88843933]), 'currentState': array([0.7755423 , 2.32318571]), 'targetState': array([-0.3640488 ,  0.63822961]), 'effectorPosition': array([-0.28503998,  0.74295492])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9316218683074718
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.27265667, 1.88843933]), 'currentState': array([0.7755423 , 2.32318571]), 'targetState': array([-0.3640488 ,  0.63822961]), 'effectorPosition': array([-0.28503998,  0.74295492])}
episode index:2670
target Thresh 1.9913674327214665
current state at start:  [ 3.04073978 -2.48782244]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.04073978, -2.48782244]), 'currentState': array([2.59185779, 4.19285018]), 'targetState': array([0.5320167 , 0.94993044]), 'effectorPosition': array([0.02418847, 1.00322242])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9316363487012167
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 3.04073978, -2.48782244]), 'currentState': array([1.93142612, 4.3632977 ]), 'targetState': array([0.5320167 , 0.94993044]), 'effectorPosition': array([0.64706984, 0.94721304])}
episode index:2671
target Thresh 1.9913846806023934
current state at start:  [-3.17962637  2.61361449]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.17962637,  2.61361449]), 'currentState': array([3.59694902, 2.57797338]), 'targetState': array([ 0.80869885, -1.01106138]), 'effectorPosition': array([ 0.09604093, -0.54783394])}
done in step count: 65
reward sum = 0.5203405226503064
running average episode reward sum: 0.9314824206226049
{'reset': False, 'endBeforeDone': False, 'stepCount': 66, 'initial state': array([-3.17962637,  2.61361449]), 'currentState': array([4.3371304 , 1.73395352]), 'targetState': array([ 0.80869885, -1.01106138]), 'effectorPosition': array([ 0.61107758, -1.14092754])}
episode index:2672
target Thresh 1.991401894022031
current state at start:  [-1.6597102   2.37080499]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.6597102 ,  2.37080499]), 'currentState': array([4.23925216, 2.58402297]), 'targetState': array([ 0.19657492, -0.25678346]), 'effectorPosition': array([ 0.40198176, -0.37593026])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9315080538359896
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.6597102 ,  2.37080499]), 'currentState': array([4.23925216, 2.58402297]), 'targetState': array([ 0.19657492, -0.25678346]), 'effectorPosition': array([ 0.40198176, -0.37593026])}
episode index:2673
target Thresh 1.9914190730492334
current state at start:  [0.82734658 1.78921055]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.82734658, 1.78921055]), 'currentState': array([0.3859296 , 2.28921055]), 'targetState': array([0.67266838, 0.91543181]), 'effectorPosition': array([0.03327962, 0.82614113])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9315262258427824
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([0.82734658, 1.78921055]), 'currentState': array([0.16670816, 1.87641252]), 'targetState': array([0.67266838, 0.91543181]), 'effectorPosition': array([0.53117897, 1.05645026])}
episode index:2674
target Thresh 1.9914362177527165
current state at start:  [-3.96053004  2.89840895]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.96053004,  2.89840895]), 'currentState': array([1.82991258, 2.46261677]), 'targetState': array([-0.93012629,  0.53352246]), 'effectorPosition': array([-0.66385868,  0.05347062])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9315480851976076
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.96053004,  2.89840895]), 'currentState': array([1.39594213, 2.09791428]), 'targetState': array([-0.93012629,  0.53352246]), 'effectorPosition': array([-0.76462951,  0.63972847])}
episode index:2675
target Thresh 1.9914533282010594
current state at start:  [-3.24095375  2.34441023]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.24095375,  2.34441023]), 'currentState': array([2.62038782, 2.84441023]), 'targetState': array([ 0.12854473, -0.14258695]), 'effectorPosition': array([-0.18382043, -0.23211928])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9315699282150971
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.24095375,  2.34441023]), 'currentState': array([2.91487524, 3.09319095]), 'targetState': array([ 0.12854473, -0.14258695]), 'effectorPosition': array([-0.01201666, -0.04688142])}
episode index:2676
target Thresh 1.9914704044627034
current state at start:  [0.4895437  2.47732052]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.4895437 , 2.47732052]), 'currentState': array([6.27272901, 2.97732052]), 'targetState': array([ 0.03559966, -0.09435063]), 'effectorPosition': array([0.01517155, 0.16338461])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.9315736302028392
{'reset': False, 'endBeforeDone': False, 'stepCount': 7, 'initial state': array([0.4895437 , 2.47732052]), 'currentState': array([4.90272676, 3.03800454]), 'targetState': array([ 0.03559966, -0.09435063]), 'effectorPosition': array([0.10254968, 0.01429922])}
episode index:2677
target Thresh 1.9914874466059542
current state at start:  [0.00218142 1.93599291]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.00218142, 1.93599291]), 'currentState': array([5.90907962, 2.43599291]), 'targetState': array([0.03333691, 0.19302534]), 'effectorPosition': array([0.45924667, 0.51637871])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9315954473685588
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.00218142, 1.93599291]), 'currentState': array([5.53200321, 2.93599291]), 'targetState': array([0.03333691, 0.19302534]), 'effectorPosition': array([0.15472929, 0.13483844])}
episode index:2678
target Thresh 1.9915044546989797
current state at start:  [-1.06312185 -1.7191701 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.06312185, -1.7191701 ]), 'currentState': array([4.72006345, 4.11579573]), 'targetState': array([-0.92047099, -0.87130686]), 'effectorPosition': array([-0.82386735, -0.44450829])}
done in step count: 53
reward sum = 0.5870367819374844
running average episode reward sum: 0.9314668327118096
{'reset': False, 'endBeforeDone': False, 'stepCount': 54, 'initial state': array([-1.06312185, -1.7191701 ]), 'currentState': array([3.12866027, 1.81395783]), 'targetState': array([-0.92047099, -0.87130686]), 'effectorPosition': array([-0.77171578, -0.96068211])}
episode index:2679
target Thresh 1.991521428809813
current state at start:  [-0.96805157 -2.86977326]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.96805157, -2.86977326]), 'currentState': array([4.89026235, 3.91341204]), 'targetState': array([ 0.30854533, -0.2300244 ]), 'effectorPosition': array([-0.63629985, -0.40228922])}
done in step count: 31
reward sum = 0.7323033696543975
running average episode reward sum: 0.9313925179867882
{'reset': False, 'endBeforeDone': False, 'stepCount': 32, 'initial state': array([-0.96805157, -2.86977326]), 'currentState': array([4.03118908, 2.73578463]), 'targetState': array([ 0.30854533, -0.2300244 ]), 'effectorPosition': array([ 0.25551357, -0.31168152])}
episode index:2680
target Thresh 1.9915383690063502
current state at start:  [ 0.20522798 -2.44770353]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.20522798, -2.44770353]), 'currentState': array([5.98841329, 3.39341305]), 'targetState': array([-0.05790525, -0.52393601]), 'effectorPosition': array([-0.04220932, -0.24758329])}
done in step count: 15
reward sum = 0.8600583546412884
running average episode reward sum: 0.9313659106897552
{'reset': False, 'endBeforeDone': False, 'stepCount': 16, 'initial state': array([ 0.20522798, -2.44770353]), 'currentState': array([5.59934215, 3.78918494]), 'targetState': array([-0.05790525, -0.52393601]), 'effectorPosition': array([-0.22419258, -0.59553378])}
episode index:2681
target Thresh 1.991555275356352
current state at start:  [-1.84278915 -2.29099281]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.84278915, -2.29099281]), 'currentState': array([4.3692442 , 3.53152125]), 'targetState': array([-0.04219968,  0.0981116 ]), 'effectorPosition': array([-0.38321695,  0.05720458])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9313877727663062
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.84278915, -2.29099281]), 'currentState': array([4.85417906, 3.07035228]), 'targetState': array([-0.04219968,  0.0981116 ]), 'effectorPosition': array([0.07082426, 0.00754779])}
episode index:2682
target Thresh 1.991572147927444
current state at start:  [-1.35819869  2.78454236]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.35819869,  2.78454236]), 'currentState': array([4.5669433 , 2.77618371]), 'targetState': array([0.05465782, 0.09340954]), 'effectorPosition': array([ 0.34398952, -0.11711443])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9314096185461175
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.35819869,  2.78454236]), 'currentState': array([4.1944813 , 2.96608803]), 'targetState': array([0.05465782, 0.09340954]), 'effectorPosition': array([ 0.1441019 , -0.09978744])}
episode index:2683
target Thresh 1.9915889867871164
current state at start:  [-0.79399603  2.14940019]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.79399603,  2.14940019]), 'currentState': array([5.75101695, 2.094671  ]), 'targetState': array([1.18471023, 0.2694753 ]), 'effectorPosition': array([0.87000245, 0.49256258])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.931062595588388
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([-0.79399603,  2.14940019]), 'currentState': array([5.38117774, 2.51864577]), 'targetState': array([1.18471023, 0.2694753 ]), 'effectorPosition': array([0.57421031, 0.21437619])}
episode index:2684
target Thresh 1.9916057920027248
current state at start:  [-3.8223604   2.63615077]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.8223604 ,  2.63615077]), 'currentState': array([2.84175903, 2.57640905]), 'targetState': array([-0.19464354, -0.38561918]), 'effectorPosition': array([-0.30675864, -0.46574518])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.931088270599342
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.8223604 ,  2.63615077]), 'currentState': array([2.84175903, 2.57640905]), 'targetState': array([-0.19464354, -0.38561918]), 'effectorPosition': array([-0.30675864, -0.46574518])}
episode index:2685
target Thresh 1.9916225636414902
current state at start:  [0.79868169 1.67524693]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.79868169, 1.67524693]), 'currentState': array([0.29868169, 2.1426184 ]), 'targetState': array([0.29811095, 0.36666661]), 'effectorPosition': array([0.19107157, 0.93870195])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9311102034844502
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.79868169, 1.67524693]), 'currentState': array([6.08186699, 2.61392147]), 'targetState': array([0.29811095, 0.36666661]), 'effectorPosition': array([0.23395592, 0.4661551 ])}
episode index:2686
target Thresh 1.9916393017704987
current state at start:  [-1.75294644 -2.36346588]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.75294644, -2.36346588]), 'currentState': array([4.03023886, 4.2111961 ]), 'targetState': array([-0.80198557,  0.41443491]), 'effectorPosition': array([-1.00829518,  0.14965533])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.931132120044374
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.75294644, -2.36346588]), 'currentState': array([3.53552368, 4.2000199 ]), 'targetState': array([-0.80198557,  0.41443491]), 'effectorPosition': array([-0.80524604,  0.6091731 ])}
episode index:2687
target Thresh 1.9916560064567033
current state at start:  [2.00711682 2.09163565]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.00711682, 2.09163565]), 'currentState': array([1.50711682, 2.55136759]), 'targetState': array([-0.04591546,  0.14505267]), 'effectorPosition': array([-0.54465367,  0.2042584 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9311540202973335
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([2.00711682, 2.09163565]), 'currentState': array([1.02845194, 2.97150064]), 'targetState': array([-0.04591546,  0.14505267]), 'effectorPosition': array([-0.13753413,  0.09972949])}
episode index:2688
target Thresh 1.9916726777669227
current state at start:  [-1.56226957 -2.03228236]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.56226957, -2.03228236]), 'currentState': array([4.27051127, 3.86491498]), 'targetState': array([-0.03434305, -0.14009796]), 'effectorPosition': array([-0.70538129,  0.05670493])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9311722225954752
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.56226957, -2.03228236]), 'currentState': array([4.81697943, 3.42320661]), 'targetState': array([-0.03434305, -0.14009796]), 'effectorPosition': array([-0.27227524, -0.06818997])}
episode index:2689
target Thresh 1.991689315767842
current state at start:  [1.14847672 2.77870831]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.14847672, 2.77870831]), 'currentState': array([1.64847672, 2.34427593]), 'targetState': array([-0.88644897, -0.19181584]), 'effectorPosition': array([-0.73671351,  0.24493892])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9311904113603097
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([1.14847672, 2.77870831]), 'currentState': array([2.35830262, 2.26106006]), 'targetState': array([-0.88644897, -0.19181584]), 'effectorPosition': array([-0.80148806, -0.29006163])}
episode index:2690
target Thresh 1.991705920526013
current state at start:  [-1.4025841   2.36194745]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.4025841 ,  2.36194745]), 'currentState': array([4.41540501, 2.11635278]), 'targetState': array([ 0.85767184, -1.06371712]), 'effectorPosition': array([ 0.67662707, -0.71020287])}
done in step count: 124
reward sum = 0.2875836093668641
running average episode reward sum: 0.9309512412369378
{'reset': False, 'endBeforeDone': False, 'stepCount': 125, 'initial state': array([-1.4025841 ,  2.36194745]), 'currentState': array([4.40809069, 1.79811258]), 'targetState': array([ 0.85767184, -1.06371712]), 'effectorPosition': array([ 0.69741457, -1.03096346])}
episode index:2691
target Thresh 1.9917224921078553
current state at start:  [ 3.74615793 -2.60406965]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.74615793, -2.60406965]), 'currentState': array([4.24615793, 3.17911565]), 'targetState': array([0.00535487, 0.1911297 ]), 'effectorPosition': array([-0.03382669,  0.01623471])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9309768908501485
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.74615793, -2.60406965]), 'currentState': array([4.24615793, 3.17911565]), 'targetState': array([0.00535487, 0.1911297 ]), 'effectorPosition': array([-0.03382669,  0.01623471])}
episode index:2692
target Thresh 1.991739030579655
current state at start:  [-2.32359335  1.91617291]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.32359335,  1.91617291]), 'currentState': array([4.45959196, 2.16251737]), 'targetState': array([ 0.50828691, -1.1943814 ]), 'effectorPosition': array([ 0.69299989, -0.63574412])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9309988080834012
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.32359335,  1.91617291]), 'currentState': array([4.12499425, 1.66300297]), 'targetState': array([ 0.50828691, -1.1943814 ]), 'effectorPosition': array([ 0.32568504, -1.30758448])}
episode index:2693
target Thresh 1.991755536007566
current state at start:  [ 2.09123046 -2.15951362]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.09123046, -2.15951362]), 'currentState': array([1.83701549, 3.62367169]), 'targetState': array([-0.44767718,  0.01901907]), 'effectorPosition': array([0.41730691, 0.23192465])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9310133961279138
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 2.09123046, -2.15951362]), 'currentState': array([2.11502271, 2.72507479]), 'targetState': array([-0.44767718,  0.01901907]), 'effectorPosition': array([-0.39039474, -0.13632825])}
episode index:2694
target Thresh 1.99177200845761
current state at start:  [ 2.54138418 -2.07789985]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.54138418, -2.07789985]), 'currentState': array([2.34039061, 3.70528545]), 'targetState': array([-0.23485972,  0.04662364]), 'effectorPosition': array([0.27608311, 0.48291052])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9310279733464192
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 2.54138418, -2.07789985]), 'currentState': array([1.94720662, 3.01542648]), 'targetState': array([-0.23485972,  0.04662364]), 'effectorPosition': array([-0.11994397, -0.03886185])}
episode index:2695
target Thresh 1.991788447995677
current state at start:  [-2.59520874  2.29499185]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.59520874,  2.29499185]), 'currentState': array([3.23029568, 2.74855712]), 'targetState': array([ 0.02073751, -0.00642059]), 'effectorPosition': array([-0.04202128, -0.38824317])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9310498472435458
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.59520874,  2.29499185]), 'currentState': array([3.2126218 , 3.15415123]), 'targetState': array([ 0.02073751, -0.00642059]), 'effectorPosition': array([-0.00096991,  0.01252099])}
episode index:2696
target Thresh 1.9918048546875247
current state at start:  [-3.17194032  2.18747867]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.17194032,  2.18747867]), 'currentState': array([2.65331314, 2.01790736]), 'targetState': array([-0.69662357, -0.577678  ]), 'effectorPosition': array([-0.92429811, -0.53004555])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9310754127432701
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.17194032,  2.18747867]), 'currentState': array([2.65331314, 2.01790736]), 'targetState': array([-0.69662357, -0.577678  ]), 'effectorPosition': array([-0.92429811, -0.53004555])}
episode index:2697
target Thresh 1.9918212285987804
current state at start:  [2.17310364 1.61015374]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.17310364, 1.61015374]), 'currentState': array([2.67310364, 1.66590567]), 'targetState': array([-1.27157717, -0.28538288]), 'effectorPosition': array([-1.25701589, -0.47956126])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9311009592915491
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.17310364, 1.61015374]), 'currentState': array([2.67310364, 1.66590567]), 'targetState': array([-1.27157717, -0.28538288]), 'effectorPosition': array([-1.25701589, -0.47956126])}
episode index:2698
target Thresh 1.9918375697949398
current state at start:  [-1.1108903  -2.61298283]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.1108903 , -2.61298283]), 'currentState': array([4.7250762 , 4.12953667]), 'targetState': array([-0.01068083, -0.94587794]), 'effectorPosition': array([-0.829125  , -0.46014849])}
done in step count: 27
reward sum = 0.7623427143471035
running average episode reward sum: 0.9310384330800099
{'reset': False, 'endBeforeDone': False, 'stepCount': 28, 'initial state': array([-1.1108903 , -2.61298283]), 'currentState': array([3.76628396, 1.88556985]), 'targetState': array([-0.01068083, -0.94587794]), 'effectorPosition': array([-0.00390135, -1.17506703])}
episode index:2699
target Thresh 1.991853878341367
current state at start:  [ 1.68429468 -2.37213101]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.68429468, -2.37213101]), 'currentState': array([1.39855553, 3.58275766]), 'targetState': array([0.54434568, 0.20447627]), 'effectorPosition': array([0.43708489, 0.0211459 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9310639744010913
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.68429468, -2.37213101]), 'currentState': array([1.39855553, 3.58275766]), 'targetState': array([0.54434568, 0.20447627]), 'effectorPosition': array([0.43708489, 0.0211459 ])}
episode index:2700
target Thresh 1.9918701543032973
current state at start:  [ 1.90868844 -2.58952975]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.90868844, -2.58952975]), 'currentState': array([1.56196268, 3.19365556]), 'targetState': array([ 0.31372838, -0.30205183]), 'effectorPosition': array([0.05204933, 0.00089522])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9310749081425199
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([ 1.90868844, -2.58952975]), 'currentState': array([1.01058182, 3.4467332 ]), 'targetState': array([ 0.31372838, -0.30205183]), 'effectorPosition': array([ 0.27905095, -0.12050349])}
episode index:2701
target Thresh 1.9918863977458336
current state at start:  [ 1.9052024  -2.40564036]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.9052024 , -2.40564036]), 'currentState': array([1.90601778, 4.37754494]), 'targetState': array([0.3576981 , 0.71916539]), 'effectorPosition': array([0.67102162, 0.9447149 ])}
done in step count: 193
reward sum = 0.1437449371536248
running average episode reward sum: 0.9307835202924131
{'reset': False, 'endBeforeDone': False, 'stepCount': 194, 'initial state': array([ 1.9052024 , -2.40564036]), 'currentState': array([1.97641241, 4.02122373]), 'targetState': array([0.3576981 , 0.71916539]), 'effectorPosition': array([0.56492218, 0.63717505])}
episode index:2702
target Thresh 1.9919026087339502
current state at start:  [-2.63098017  2.82240674]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.63098017,  2.82240674]), 'currentState': array([4.15220513, 2.46027216]), 'targetState': array([ 0.7359268 , -0.27019888]), 'effectorPosition': array([ 0.41492958, -0.5237843 ])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.930801765382945
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-2.63098017,  2.82240674]), 'currentState': array([5.02110713, 2.19177364]), 'targetState': array([ 0.7359268 , -0.27019888]), 'effectorPosition': array([ 0.90191572, -0.15128599])}
episode index:2703
target Thresh 1.9919187873324908
current state at start:  [ 1.38480444 -2.25953027]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.38480444, -2.25953027]), 'currentState': array([1.20322419, 3.52365504]), 'targetState': array([ 0.39159673, -0.22234326]), 'effectorPosition': array([ 0.37384055, -0.06669247])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9308273564460431
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.38480444, -2.25953027]), 'currentState': array([1.20322419, 3.52365504]), 'targetState': array([ 0.39159673, -0.22234326]), 'effectorPosition': array([ 0.37384055, -0.06669247])}
episode index:2704
target Thresh 1.99193493360617
current state at start:  [-1.34542009  2.16618141]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.34542009,  2.16618141]), 'currentState': array([4.43776521, 2.57782751]), 'targetState': array([ 0.2443431 , -0.08478498]), 'effectorPosition': array([ 0.47238199, -0.29386565])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9308492317301664
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.34542009,  2.16618141]), 'currentState': array([4.1937116 , 2.93969124]), 'targetState': array([ 0.2443431 , -0.08478498]), 'effectorPosition': array([ 0.16408779, -0.11705165])}
episode index:2705
target Thresh 1.991951047619573
current state at start:  [ 2.02321555 -1.68820219]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.02321555, -1.68820219]), 'currentState': array([2.02319366, 4.65639722]), 'targetState': array([0.35566307, 0.96589073]), 'effectorPosition': array([0.48533182, 1.28550691])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9308602246267923
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([ 2.02321555, -1.68820219]), 'currentState': array([2.10824433, 4.45807218]), 'targetState': array([0.35566307, 0.96589073]), 'effectorPosition': array([0.44823995, 1.13838151])}
episode index:2706
target Thresh 1.9919671294371557
current state at start:  [-3.90082233  2.13447813]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.90082233,  2.13447813]), 'currentState': array([1.88236298, 1.98162955]), 'targetState': array([-1.23479259,  0.26716332]), 'effectorPosition': array([-1.05677136,  0.29066747])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.930885765733321
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.90082233,  2.13447813]), 'currentState': array([1.88236298, 1.98162955]), 'targetState': array([-1.23479259,  0.26716332]), 'effectorPosition': array([-1.05677136,  0.29066747])}
episode index:2707
target Thresh 1.9919831791232454
current state at start:  [-2.05056268  2.63047738]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.05056268,  2.63047738]), 'currentState': array([4.71930746, 2.24599243]), 'targetState': array([ 0.74479537, -0.53821756]), 'effectorPosition': array([ 0.78315977, -0.36954021])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9309112879764032
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.05056268,  2.63047738]), 'currentState': array([4.71930746, 2.24599243]), 'targetState': array([ 0.74479537, -0.53821756]), 'effectorPosition': array([ 0.78315977, -0.36954021])}
episode index:2708
target Thresh 1.991999196742041
current state at start:  [0.23889354 2.12821706]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.23889354, 2.12821706]), 'currentState': array([0.71766076, 2.52933442]), 'targetState': array([-0.22361917,  0.83860998]), 'effectorPosition': array([-0.24110416,  0.55241675])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9309294454928387
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([0.23889354, 2.12821706]), 'currentState': array([0.56607998, 2.39124294]), 'targetState': array([-0.22361917,  0.83860998]), 'effectorPosition': array([-0.13906045,  0.71955632])}
episode index:2709
target Thresh 1.9920151823576127
current state at start:  [0.39018654 2.2826738 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.39018654, 2.2826738 ]), 'currentState': array([0.39317109, 2.7826738 ]), 'targetState': array([-0.31775735,  0.12909395]), 'effectorPosition': array([-0.07571465,  0.34887393])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9309475896088931
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([0.39018654, 2.2826738 ]), 'currentState': array([1.09080674, 2.80122563]), 'targetState': array([-0.31775735,  0.12909395]), 'effectorPosition': array([-0.26961913,  0.2050393 ])}
episode index:2710
target Thresh 1.9920311360339034
current state at start:  [-1.17553741 -2.29908929]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.17553741, -2.29908929]), 'currentState': array([4.60764789, 3.53249713]), 'targetState': array([-0.30028016, -0.02748622]), 'effectorPosition': array([-0.3868234 , -0.03518576])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9309730608041683
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.17553741, -2.29908929]), 'currentState': array([4.60764789, 3.53249713]), 'targetState': array([-0.30028016, -0.02748622]), 'effectorPosition': array([-0.3868234 , -0.03518576])}
episode index:2711
target Thresh 1.9920470578347274
current state at start:  [-0.31006523  2.08952772]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.31006523,  2.08952772]), 'currentState': array([5.5533164 , 2.57846697]), 'targetState': array([0.08998006, 0.10513576]), 'effectorPosition': array([0.47101949, 0.29488867])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9309948258997419
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.31006523,  2.08952772]), 'currentState': array([5.24128069, 2.96566045]), 'targetState': array([0.08998006, 0.10513576]), 'effectorPosition': array([0.15890041, 0.07498698])}
episode index:2712
target Thresh 1.9920629478237721
current state at start:  [ 2.6471492  -2.68661503]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.6471492 , -2.68661503]), 'currentState': array([2.53504873, 3.11040699]), 'targetState': array([-0.23662801,  0.27316519]), 'effectorPosition': array([-0.01817342, -0.02534154])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.9310021960523407
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([ 2.6471492 , -2.68661503]), 'currentState': array([1.40105651, 2.89662884]), 'targetState': array([-0.23662801,  0.27316519]), 'effectorPosition': array([-0.23399279,  0.07039298])}
episode index:2713
target Thresh 1.9920788060645978
current state at start:  [ 0.89796492 -2.93601293]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.89796492, -2.93601293]), 'currentState': array([1.32352325, 2.84717238]), 'targetState': array([-0.67881612, -0.02538274]), 'effectorPosition': array([-0.27082676,  0.11274663])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9310239343736183
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.89796492, -2.93601293]), 'currentState': array([1.76698556, 2.34717238]), 'targetState': array([-0.67881612, -0.02538274]), 'effectorPosition': array([-0.7581147 ,  0.15448339])}
episode index:2714
target Thresh 1.992094632620637
current state at start:  [-0.56751075 -1.7894298 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.56751075, -1.7894298 ]), 'currentState': array([5.21567456, 4.00119831]), 'targetState': array([-0.27251018, -0.95704838]), 'effectorPosition': array([-0.49615916, -0.66959208])}
done in step count: 40
reward sum = 0.6689717585696803
running average episode reward sum: 0.9309274142352006
{'reset': False, 'endBeforeDone': False, 'stepCount': 41, 'initial state': array([-0.56751075, -1.7894298 ]), 'currentState': array([5.55361391, 4.02373434]), 'targetState': array([-0.27251018, -0.95704838]), 'effectorPosition': array([-0.24292356, -0.81852925])}
episode index:2715
target Thresh 1.9921104275551962
current state at start:  [1.82021191 2.38076578]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.82021191, 2.38076578]), 'currentState': array([2.09331357, 1.95045013]), 'targetState': array([-0.85226308,  0.20041082]), 'effectorPosition': array([-1.11897094,  0.08189106])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9309491640826839
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.82021191, 2.38076578]), 'currentState': array([1.60663023, 2.34131436]), 'targetState': array([-0.85226308,  0.20041082]), 'effectorPosition': array([-0.72796232,  0.27759101])}
episode index:2716
target Thresh 1.9921261909314552
current state at start:  [-1.40675804  2.04501959]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.40675804,  2.04501959]), 'currentState': array([4.37642727, 1.54501959]), 'targetState': array([ 0.25034049, -1.22215257]), 'effectorPosition': array([ 0.60560573, -1.2979944 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.930970897919974
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.40675804,  2.04501959]), 'currentState': array([3.87642727, 2.02578651]), 'targetState': array([ 0.25034049, -1.22215257]), 'effectorPosition': array([ 0.18636219, -1.04228697])}
episode index:2717
target Thresh 1.9921419228124673
current state at start:  [-4.12853652  1.99227392]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.12853652,  1.99227392]), 'currentState': array([2.00248775, 2.4733653 ]), 'targetState': array([-0.54847353, -0.26638607]), 'effectorPosition': array([-0.65274407, -0.06389622])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9309962949406068
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.12853652,  1.99227392]), 'currentState': array([2.00248775, 2.4733653 ]), 'targetState': array([-0.54847353, -0.26638607]), 'effectorPosition': array([-0.65274407, -0.06389622])}
episode index:2718
target Thresh 1.9921576232611602
current state at start:  [ 1.78924922 -2.41451982]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.78924922, -2.41451982]), 'currentState': array([2.10740183, 4.10672809]), 'targetState': array([0.15207973, 0.79292645]), 'effectorPosition': array([0.48639508, 0.79044845])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9306538910071972
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([ 1.78924922, -2.41451982]), 'currentState': array([1.98076885, 3.79152095]), 'targetState': array([0.15207973, 0.79292645]), 'effectorPosition': array([0.47372286, 0.42817318])}
episode index:2719
target Thresh 1.9921732923403357
current state at start:  [ 2.14234784 -1.66673763]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.14234784, -1.66673763]), 'currentState': array([1.64234784, 5.11644768]), 'targetState': array([1.00811917, 0.98145003]), 'effectorPosition': array([0.81752301, 1.4553223 ])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9306720697237387
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 2.14234784, -1.66673763]), 'currentState': array([1.47760632, 4.97081875]), 'targetState': array([1.00811917, 0.98145003]), 'effectorPosition': array([1.07943413, 1.16014979])}
episode index:2720
target Thresh 1.99218893011267
current state at start:  [-2.27667214  2.14293295]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.27667214,  2.14293295]), 'currentState': array([3.50651316, 2.64293295]), 'targetState': array([-0.07731183, -0.09636889]), 'effectorPosition': array([ 0.0569181 , -0.49021591])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9306938734467363
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.27667214,  2.14293295]), 'currentState': array([3.08334713, 3.12160981]), 'targetState': array([-0.07731183, -0.09636889]), 'effectorPosition': array([-0.00136249, -0.01993601])}
episode index:2721
target Thresh 1.9922045366407144
current state at start:  [ 2.89267283 -2.75283265]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.89267283, -2.75283265]), 'currentState': array([2.39267283, 4.03035266]), 'targetState': array([0.04141285, 1.16526352]), 'effectorPosition': array([0.25781355, 0.82023286])}
done in step count: 177
reward sum = 0.1688221565806905
running average episode reward sum: 0.9304139793553086
{'reset': False, 'endBeforeDone': False, 'stepCount': 178, 'initial state': array([ 2.89267283, -2.75283265]), 'currentState': array([2.23405128, 4.61232556]), 'targetState': array([0.04141285, 1.16526352]), 'effectorPosition': array([0.22987051, 1.32187992])}
episode index:2722
target Thresh 1.992220111986895
current state at start:  [2.25088278 1.57821895]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.25088278, 1.57821895]), 'currentState': array([1.86830699, 1.99904634]), 'targetState': array([-0.52966842, -0.29773506]), 'effectorPosition': array([-1.04113592,  0.29236456])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.930435861845446
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([2.25088278, 1.57821895]), 'currentState': array([2.28185815, 2.41754074]), 'targetState': array([-0.52966842, -0.29773506]), 'effectorPosition': array([-0.66562838, -0.24224631])}
episode index:2723
target Thresh 1.9922356562135133
current state at start:  [ 3.88863044 -1.74856994]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.88863044, -1.74856994]), 'currentState': array([3.38863044, 4.78475231]), 'targetState': array([-0.9684879 ,  0.65688543]), 'effectorPosition': array([-1.28363906,  0.70489089])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.9304399162828746
{'reset': False, 'endBeforeDone': False, 'stepCount': 7, 'initial state': array([ 3.88863044, -1.74856994]), 'currentState': array([3.50057593, 4.45614501]), 'targetState': array([-0.9684879 ,  0.65688543]), 'effectorPosition': array([-1.03881316,  0.64340446])}
episode index:2724
target Thresh 1.9922511693827458
current state at start:  [-0.03979087  1.69489906]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.03979087,  1.69489906]), 'currentState': array([0.16434779, 2.15951476]), 'targetState': array([0.27506137, 0.45095518]), 'effectorPosition': array([0.3026462 , 0.89320432])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9304617731943303
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.03979087,  1.69489906]), 'currentState': array([6.08387387, 2.61560724]), 'targetState': array([0.27506137, 0.45095518]), 'effectorPosition': array([0.23190061, 0.46536316])}
episode index:2725
target Thresh 1.9922666515566458
current state at start:  [ 3.19042004 -2.33925944]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.19042004, -2.33925944]), 'currentState': array([3.6618963 , 3.44392586]), 'targetState': array([0.01155797, 0.02935552]), 'effectorPosition': array([-0.18737735,  0.23579858])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9304836140699009
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.19042004, -2.33925944]), 'currentState': array([4.1618963 , 2.94392586]), 'targetState': array([0.01155797, 0.02935552]), 'effectorPosition': array([ 0.15718372, -0.1193247 ])}
episode index:2726
target Thresh 1.9922821027971416
current state at start:  [-1.3648412  1.9469405]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.3648412,  1.9469405]), 'currentState': array([4.78461085, 2.25288679]), 'targetState': array([ 1.02905314, -0.57695627]), 'effectorPosition': array([ 0.80090173, -0.31260544])}
done in step count: 40
reward sum = 0.6689717585696803
running average episode reward sum: 0.9303877167998238
{'reset': False, 'endBeforeDone': False, 'stepCount': 41, 'initial state': array([-1.3648412,  1.9469405]), 'currentState': array([4.59276368, 2.09605289]), 'targetState': array([ 1.02905314, -0.57695627]), 'effectorPosition': array([ 0.79951329, -0.59825455])}
episode index:2727
target Thresh 1.9922975231660383
current state at start:  [ 1.42140143 -2.38227116]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.42140143, -2.38227116]), 'currentState': array([1.75101046, 3.40091415]), 'targetState': array([0.00737421, 0.00292518]), 'effectorPosition': array([0.24627903, 0.07885597])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9304095688097944
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.42140143, -2.38227116]), 'currentState': array([1.98983343, 2.90091415]), 'targetState': array([0.00737421, 0.00292518]), 'effectorPosition': array([-0.22946661, -0.07065508])}
episode index:2728
target Thresh 1.9923129127250174
current state at start:  [-1.52040104  2.17662143]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.52040104,  2.17662143]), 'currentState': array([4.26278427, 2.58569803]), 'targetState': array([-0.14797449, -0.3071133 ]), 'effectorPosition': array([ 0.40981999, -0.36495234])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9304277771026455
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.52040104,  2.17662143]), 'currentState': array([3.42588999, 2.6478839 ]), 'targetState': array([-0.14797449, -0.3071133 ]), 'effectorPosition': array([ 0.01829447, -0.48836728])}
episode index:2729
target Thresh 1.9923282715356372
current state at start:  [ 2.71521453 -1.98823077]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.71521453, -1.98823077]), 'currentState': array([2.26812295, 3.94314665]), 'targetState': array([0.75409379, 0.39816112]), 'effectorPosition': array([0.3552445 , 0.69470796])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9304459720560878
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 2.71521453, -1.98823077]), 'currentState': array([1.45872588, 3.99819289]), 'targetState': array([0.75409379, 0.39816112]), 'effectorPosition': array([0.78946209, 0.25832007])}
episode index:2730
target Thresh 1.9923435996593328
current state at start:  [-1.24844009 -2.56251167]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.24844009, -2.56251167]), 'currentState': array([4.53474522, 4.22067363]), 'targetState': array([ 0.20992874, -1.10938664]), 'effectorPosition': array([-0.9609304 , -0.36377928])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9301052741534674
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([-1.24844009, -2.56251167]), 'currentState': array([3.9427413 , 5.47809632]), 'targetState': array([ 0.20992874, -1.10938664]), 'effectorPosition': array([-1.6958745 , -0.71421555])}
episode index:2731
target Thresh 1.9923588971574169
current state at start:  [-0.87377986 -1.6140801 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.87377986, -1.6140801 ]), 'currentState': array([4.96276689, 4.201448  ]), 'targetState': array([ 0.01611454, -0.64066059]), 'effectorPosition': array([-0.71847497, -0.7111942 ])}
done in step count: 52
reward sum = 0.5929664464014994
running average episode reward sum: 0.9299818704829873
{'reset': False, 'endBeforeDone': False, 'stepCount': 53, 'initial state': array([-0.87377986, -1.6140801 ]), 'currentState': array([5.68218698, 3.83644184]), 'targetState': array([ 0.01611454, -0.64066059]), 'effectorPosition': array([-0.17082773, -0.65917929])}
episode index:2732
target Thresh 1.9923741640910795
current state at start:  [-2.91092173  2.85388171]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.91092173,  2.85388171]), 'currentState': array([3.87226358, 2.61655433]), 'targetState': array([ 0.50297625, -0.33883618]), 'effectorPosition': array([ 0.2342052 , -0.46318297])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9299966224513433
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-2.91092173,  2.85388171]), 'currentState': array([4.50266167, 2.4834351 ]), 'targetState': array([ 0.50297625, -0.33883618]), 'effectorPosition': array([ 0.55477014, -0.33164596])}
episode index:2733
target Thresh 1.992389400521388
current state at start:  [ 1.78525128 -2.08280265]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.78525128, -2.08280265]), 'currentState': array([1.97905683, 3.71399597]), 'targetState': array([0.00403767, 0.0253657 ]), 'effectorPosition': array([0.43385355, 0.36134169])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9300185695535922
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.78525128, -2.08280265]), 'currentState': array([2.15238617, 3.21399597]), 'targetState': array([0.00403767, 0.0253657 ]), 'effectorPosition': array([0.05900738, 0.04192947])}
episode index:2734
target Thresh 1.9924046065092889
current state at start:  [1.78258283 1.83751148]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.78258283, 1.83751148]), 'currentState': array([1.34220875, 2.16351986]), 'targetState': array([-0.83870044,  1.1139961 ]), 'effectorPosition': array([-0.70782976,  0.61784539])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9300368808627135
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([1.78258283, 1.83751148]), 'currentState': array([1.64102469, 1.35608903]), 'targetState': array([-0.83870044,  1.1139961 ]), 'effectorPosition': array([-1.05975171,  1.14151182])}
episode index:2735
target Thresh 1.9924197821156053
current state at start:  [0.77527989 1.8952168 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.77527989, 1.8952168 ]), 'currentState': array([1.27527989, 1.81124805]), 'targetState': array([-1.05715811,  0.93321862]), 'effectorPosition': array([-0.70725038,  1.01168875])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9300587972074273
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.77527989, 1.8952168 ]), 'currentState': array([1.75027485, 1.37734761]), 'targetState': array([-1.05715811,  0.93321862]), 'effectorPosition': array([-1.17841891,  0.99790666])}
episode index:2736
target Thresh 1.9924349274010402
current state at start:  [ 2.83992774 -2.2812561 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.83992774, -2.2812561 ]), 'currentState': array([2.35926226, 4.45045138]), 'targetState': array([0.56263181, 1.24659528]), 'effectorPosition': array([0.15528421, 1.20746914])}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9300494158693935
{'reset': False, 'endBeforeDone': False, 'stepCount': 11, 'initial state': array([ 2.83992774, -2.2812561 ]), 'currentState': array([0.23821279, 1.69328793]), 'targetState': array([0.56263181, 1.24659528]), 'effectorPosition': array([0.61882787, 1.17161471])}
episode index:2737
target Thresh 1.9924500424261746
current state at start:  [ 0.21309373 -2.08944411]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.21309373, -2.08944411]), 'currentState': array([5.99627904, 3.87783917]), 'targetState': array([ 0.68579282, -0.57189439]), 'effectorPosition': array([ 0.05839007, -0.71735768])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9297097338329182
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([ 0.21309373, -2.08944411]), 'currentState': array([5.09512628, 4.02587073]), 'targetState': array([ 0.68579282, -0.57189439]), 'effectorPosition': array([-0.5807512 , -0.62851567])}
episode index:2738
target Thresh 1.9924651272514688
current state at start:  [ 0.36068478 -2.29841209]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.36068478, -2.29841209]), 'currentState': array([6.14387008, 3.50919747]), 'targetState': array([ 0.01951884, -0.41952792]), 'effectorPosition': array([ 0.01625642, -0.36517683])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9297353965806974
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.36068478, -2.29841209]), 'currentState': array([6.14387008, 3.50919747]), 'targetState': array([ 0.01951884, -0.41952792]), 'effectorPosition': array([ 0.01625642, -0.36517683])}
episode index:2739
target Thresh 1.9924801819372617
current state at start:  [-4.00171727  2.03362167]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.00171727,  2.03362167]), 'currentState': array([1.78146804, 2.49071125]), 'targetState': array([-0.23570753,  0.7878563 ]), 'effectorPosition': array([-0.63524599,  0.07322834])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9297537778228213
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-4.00171727,  2.03362167]), 'currentState': array([0.78146804, 2.13881764]), 'targetState': array([-0.23570753,  0.7878563 ]), 'effectorPosition': array([-0.26573107,  0.92382722])}
episode index:2740
target Thresh 1.9924952065437727
current state at start:  [-1.79454964 -1.78080625]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.79454964, -1.78080625]), 'currentState': array([3.98863566, 4.42571467]), 'targetState': array([-1.13033936, -0.52949064]), 'effectorPosition': array([-1.19370033,  0.09773365])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9297757574733784
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.79454964, -1.78080625]), 'currentState': array([4.28876225, 4.47287798]), 'targetState': array([-1.13033936, -0.52949064]), 'effectorPosition': array([-1.19913384, -0.29601148])}
episode index:2741
target Thresh 1.9925102011310996
current state at start:  [-1.0726737   2.92959947]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.0726737 ,  2.92959947]), 'currentState': array([4.77382977, 3.05237515]), 'targetState': array([-0.02571597, -0.00137033]), 'effectorPosition': array([0.08917528, 0.00150114])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9298013680651094
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.0726737 ,  2.92959947]), 'currentState': array([4.77382977, 3.05237515]), 'targetState': array([-0.02571597, -0.00137033]), 'effectorPosition': array([0.08917528, 0.00150114])}
episode index:2742
target Thresh 1.992525165759221
current state at start:  [ 1.11700796 -1.6376737 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.11700796, -1.6376737 ]), 'currentState': array([0.89274823, 4.17955456]), 'targetState': array([0.61883249, 0.008984  ]), 'effectorPosition': array([ 0.97946765, -0.15712861])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9298233143399671
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.11700796, -1.6376737 ]), 'currentState': array([1.27531626, 3.7464057 ]), 'targetState': array([0.61883249, 0.008984  ]), 'effectorPosition': array([0.59562249, 0.00412562])}
episode index:2743
target Thresh 1.9925401004879955
current state at start:  [0.67317203 1.99995237]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.67317203, 1.99995237]), 'currentState': array([0.45888428, 2.49995237]), 'targetState': array([-0.07364208,  0.6201496 ]), 'effectorPosition': array([-0.08679929,  0.62468846])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9298488889338665
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.67317203, 1.99995237]), 'currentState': array([0.45888428, 2.49995237]), 'targetState': array([-0.07364208,  0.6201496 ]), 'effectorPosition': array([-0.08679929,  0.62468846])}
episode index:2744
target Thresh 1.9925550053771621
current state at start:  [1.41583663 1.9522487 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.41583663, 1.9522487 ]), 'currentState': array([0.95971402, 2.44037436]), 'targetState': array([-0.48425844,  0.71636695]), 'effectorPosition': array([-0.39302137,  0.56340098])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9298744448941821
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.41583663, 1.9522487 ]), 'currentState': array([0.95971402, 2.44037436]), 'targetState': array([-0.48425844,  0.71636695]), 'effectorPosition': array([-0.39302137,  0.56340098])}
episode index:2745
target Thresh 1.9925698804863403
current state at start:  [-0.21247159  2.87008522]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.21247159,  2.87008522]), 'currentState': array([5.67389841, 2.56099287]), 'targetState': array([0.39588349, 0.5055638 ]), 'effectorPosition': array([0.44829124, 0.35604402])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9298999822412709
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.21247159,  2.87008522]), 'currentState': array([5.67389841, 2.56099287]), 'targetState': array([0.39588349, 0.5055638 ]), 'effectorPosition': array([0.44829124, 0.35604402])}
episode index:2746
target Thresh 1.9925847258750304
current state at start:  [-2.05326137  1.79509995]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.05326137,  1.79509995]), 'currentState': array([3.81049985, 2.29509995]), 'targetState': array([ 0.14166994, -0.25721727]), 'effectorPosition': array([ 0.19977328, -0.79678262])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9299218606605495
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.05326137,  1.79509995]), 'currentState': array([3.46548597, 2.78671063]), 'targetState': array([ 0.14166994, -0.25721727]), 'effectorPosition': array([ 0.05151637, -0.34924359])}
episode index:2747
target Thresh 1.992599541602614
current state at start:  [-1.01866963  2.88158644]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.01866963,  2.88158644]), 'currentState': array([4.93220631, 3.11904303]), 'targetState': array([-0.0561481 , -0.00064918]), 'effectorPosition': array([0.02206059, 0.00466844])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9299473621668594
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.01866963,  2.88158644]), 'currentState': array([4.93220631, 3.11904303]), 'targetState': array([-0.0561481 , -0.00064918]), 'effectorPosition': array([0.02206059, 0.00466844])}
episode index:2748
target Thresh 1.9926143277283546
current state at start:  [-2.24103006  2.19731233]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.24103006,  2.19731233]), 'currentState': array([3.79326332, 2.69731233]), 'targetState': array([ 0.34491491, -0.11072314]), 'effectorPosition': array([ 0.18349997, -0.40060868])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.929965606123874
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-2.24103006,  2.19731233]), 'currentState': array([4.77968702, 2.61371607]), 'targetState': array([ 0.34491491, -0.11072314]), 'effectorPosition': array([ 0.51171369, -0.10194084])}
episode index:2749
target Thresh 1.9926290843113958
current state at start:  [-1.7270229 -1.6020666]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.7270229, -1.6020666]), 'currentState': array([4.05616241, 5.17578681]), 'targetState': array([-0.61467558, -1.12726803]), 'effectorPosition': array([-1.59159759, -0.60066418])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.9299663696663407
{'reset': False, 'endBeforeDone': False, 'stepCount': 8, 'initial state': array([-1.7270229, -1.6020666]), 'currentState': array([3.29976544, 1.59201013]), 'targetState': array([-0.61467558, -1.12726803]), 'effectorPosition': array([-0.8090907 , -1.14146739])}
episode index:2750
target Thresh 1.9926438114107647
current state at start:  [-3.77838186  1.93531753]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.77838186,  1.93531753]), 'currentState': array([3.00480345, 1.6421686 ]), 'targetState': array([-0.83743271, -0.964067  ]), 'effectorPosition': array([-1.05602922, -0.86149805])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9299918271837284
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.77838186,  1.93531753]), 'currentState': array([3.00480345, 1.6421686 ]), 'targetState': array([-0.83743271, -0.964067  ]), 'effectorPosition': array([-1.05602922, -0.86149805])}
episode index:2751
target Thresh 1.9926585090853692
current state at start:  [ 1.41364979 -1.75791674]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.41364979, -1.75791674]), 'currentState': array([1.31048405, 4.0544412 ]), 'targetState': array([0.17307308, 0.05853064]), 'effectorPosition': array([0.86458586, 0.17176332])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9300100350953624
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 1.41364979, -1.75791674]), 'currentState': array([1.93004685, 3.1711856 ]), 'targetState': array([0.17307308, 0.05853064]), 'effectorPosition': array([0.02754577, 0.01081244])}
episode index:2752
target Thresh 1.9926731773940005
current state at start:  [ 3.02941687 -1.60572961]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.02941687, -1.60572961]), 'currentState': array([3.52941687, 4.21978289]), 'targetState': array([-0.79587791,  0.34511503]), 'effectorPosition': array([-0.82114384,  0.61634029])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9300318258563156
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.02941687, -1.60572961]), 'currentState': array([3.97772837, 3.79404355]), 'targetState': array([-0.79587791,  0.34511503]), 'effectorPosition': array([-0.5882182 ,  0.25456438])}
episode index:2753
target Thresh 1.9926878163953314
current state at start:  [ 0.32787241 -2.35793404]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.32787241, -2.35793404]), 'currentState': array([6.14526828, 3.46911957]), 'targetState': array([-0.38447299, -0.58103499]), 'effectorPosition': array([ 0.00842668, -0.32595602])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.930050006021219
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 0.32787241, -2.35793404]), 'currentState': array([5.16265558, 3.76611018]), 'targetState': array([-0.38447299, -0.58103499]), 'effectorPosition': array([-0.44428185, -0.42440899])}
episode index:2754
target Thresh 1.9927024261479183
current state at start:  [-1.01587151 -1.89597385]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.01587151, -1.89597385]), 'currentState': array([4.7673138 , 3.98847024]), 'targetState': array([-1.05773584, -0.38964583]), 'effectorPosition': array([-0.72954882, -0.37829492])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9300610934999771
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([-1.01587151, -1.89597385]), 'currentState': array([4.23152636, 4.46339868]), 'targetState': array([-1.05773584, -0.38964583]), 'effectorPosition': array([-1.20781662, -0.21983623])}
episode index:2755
target Thresh 1.9927170067102
current state at start:  [-3.73509404  2.1159033 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.73509404,  2.1159033 ]), 'currentState': array([2.04809127, 2.55141834]), 'targetState': array([-0.63552867,  0.39279805]), 'effectorPosition': array([-0.57201793, -0.10539507])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9300828420146723
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.73509404,  2.1159033 ]), 'currentState': array([1.54809127, 2.24880836]), 'targetState': array([-0.63552867,  0.39279805]), 'effectorPosition': array([-0.77015778,  0.39033959])}
episode index:2756
target Thresh 1.992731558140499
current state at start:  [-0.5566345   1.94313371]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.5566345 ,  1.94313371]), 'currentState': array([5.22655081, 2.38377392]), 'targetState': array([ 0.96257847, -0.40094857]), 'effectorPosition': array([0.73305834, 0.09975698])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9300974289417616
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-0.5566345 ,  1.94313371]), 'currentState': array([4.72590803, 2.17661925]), 'targetState': array([ 0.96257847, -0.40094857]), 'effectorPosition': array([ 0.82777925, -0.41940913])}
episode index:2757
target Thresh 1.9927460804970205
current state at start:  [-3.74962795  2.15848331]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.74962795,  2.15848331]), 'currentState': array([2.03355735, 2.58973782]), 'targetState': array([-0.68296447,  0.35619953]), 'effectorPosition': array([-0.53539642, -0.10121044])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9301191485106732
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.74962795,  2.15848331]), 'currentState': array([1.60875693, 2.16428201]), 'targetState': array([-0.68296447,  0.35619953]), 'effectorPosition': array([-0.84512608,  0.4089668 ])}
episode index:2758
target Thresh 1.9927605738378547
current state at start:  [ 0.90636157 -2.36422412]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.90636157, -2.36422412]), 'currentState': array([0.59205618, 3.45695921]), 'targetState': array([ 0.51638062, -0.41987656]), 'effectorPosition': array([ 0.21401647, -0.22985092])}
done in step count: 123
reward sum = 0.29048849430996376
running average episode reward sum: 0.9298873142757328
{'reset': False, 'endBeforeDone': False, 'stepCount': 124, 'initial state': array([ 0.90636157, -2.36422412]), 'currentState': array([4.6703737 , 2.33345003]), 'targetState': array([ 0.51638062, -0.41987656]), 'effectorPosition': array([ 0.70938169, -0.33925298])}
episode index:2759
target Thresh 1.9927750382209743
current state at start:  [ 0.66107709 -1.81157653]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.66107709, -1.81157653]), 'currentState': array([1.12209261, 4.02337794]), 'targetState': array([1.31490917, 0.36704934]), 'effectorPosition': array([ 0.8534678 , -0.00666663])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9299090942343284
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.66107709, -1.81157653]), 'currentState': array([1.34433592, 4.45158772]), 'targetState': array([1.31490917, 0.36704934]), 'effectorPosition': array([1.108148  , 0.50625924])}
episode index:2760
target Thresh 1.9927894737042373
current state at start:  [ 1.1302024  -1.65195377]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.1302024 , -1.65195377]), 'currentState': array([1.02578085, 4.15815826]), 'targetState': array([0.75629687, 0.09395073]), 'effectorPosition': array([ 0.97269911, -0.03574591])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9299308584160616
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.1302024 , -1.65195377]), 'currentState': array([1.34316036, 3.70639055]), 'targetState': array([0.75629687, 0.09395073]), 'effectorPosition': array([0.55648526, 0.03050529])}
episode index:2761
target Thresh 1.9928038803453854
current state at start:  [0.03568753 1.84295763]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.03568753, 1.84295763]), 'currentState': array([0.41128477, 2.34295763]), 'targetState': array([-0.18468754,  0.46627819]), 'effectorPosition': array([-0.00930527,  0.7775236 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9299526068380688
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.03568753, 1.84295763]), 'currentState': array([0.49483341, 2.84295763]), 'targetState': array([-0.18468754,  0.46627819]), 'effectorPosition': array([-0.10076693,  0.27994298])}
episode index:2762
target Thresh 1.9928182582020453
current state at start:  [0.29300638 1.64780362]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.29300638, 1.64780362]), 'currentState': array([0.30171916, 2.13266461]), 'targetState': array([-0.10983409,  0.2438982 ]), 'effectorPosition': array([0.19464877, 0.94687671])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9299707564555723
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([0.29300638, 1.64780362]), 'currentState': array([5.82810477, 3.05823039]), 'targetState': array([-0.10983409,  0.2438982 ]), 'effectorPosition': array([0.03971738, 0.07326509])}
episode index:2763
target Thresh 1.9928326073317286
current state at start:  [0.69114769 1.84203334]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.69114769, 1.84203334]), 'currentState': array([0.94520445, 2.33375977]), 'targetState': array([-0.52785532,  0.22801028]), 'effectorPosition': array([-0.40500219,  0.67367675])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9299924747057692
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.69114769, 1.84203334]), 'currentState': array([1.14580409, 2.7891029 ]), 'targetState': array([-0.52785532,  0.22801028]), 'effectorPosition': array([-0.2891734 ,  0.19835979])}
episode index:2764
target Thresh 1.9928469277918315
current state at start:  [ 1.29447398 -2.4819671 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.29447398, -2.4819671 ]), 'currentState': array([1.62941203, 3.3012182 ]), 'targetState': array([0.09641603, 0.52981351]), 'effectorPosition': array([0.15793079, 0.02200284])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9300035428921323
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([ 1.29447398, -2.4819671 ]), 'currentState': array([0.1993965 , 2.67138874]), 'targetState': array([0.09641603, 0.52981351]), 'effectorPosition': array([0.01663108, 0.46558734])}
episode index:2765
target Thresh 1.992861219639636
current state at start:  [0.29358577 2.16025728]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.29358577, 2.16025728]), 'currentState': array([0.06710651, 1.66025728]), 'targetState': array([0.72123117, 1.15107768]), 'effectorPosition': array([0.84182062, 1.05482449])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9300288489142248
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.29358577, 2.16025728]), 'currentState': array([0.06710651, 1.66025728]), 'targetState': array([0.72123117, 1.15107768]), 'effectorPosition': array([0.84182062, 1.05482449])}
episode index:2766
target Thresh 1.9928754829323096
current state at start:  [ 1.41805002 -2.82363837]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.41805002, -2.82363837]), 'currentState': array([1.05917829, 3.64820482]), 'targetState': array([0.64828986, 0.0455156 ]), 'effectorPosition': array([ 0.48458289, -0.12803399])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9300541366450111
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.41805002, -2.82363837]), 'currentState': array([1.05917829, 3.64820482]), 'targetState': array([0.64828986, 0.0455156 ]), 'effectorPosition': array([ 0.48458289, -0.12803399])}
episode index:2767
target Thresh 1.9928897177269056
current state at start:  [ 2.55854809 -2.12859654]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.55854809, -2.12859654]), 'currentState': array([2.50661916, 3.65458876]), 'targetState': array([-0.42914749,  0.88302877]), 'effectorPosition': array([0.18748256, 0.47148104])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.9300617001974877
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([ 2.55854809, -2.12859654]), 'currentState': array([0.87908975, 2.18083316]), 'targetState': array([-0.42914749,  0.88302877]), 'effectorPosition': array([-0.35881443,  0.85173758])}
episode index:2768
target Thresh 1.9929039240803628
current state at start:  [ 2.91447437 -2.85373169]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.91447437, -2.85373169]), 'currentState': array([3.32229218, 2.93924848]), 'targetState': array([ 0.2310764 , -0.06622988]), 'effectorPosition': array([ 0.01604755, -0.20136071])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9300797710894352
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 2.91447437, -2.85373169]), 'currentState': array([4.17346391, 3.06378088]), 'targetState': array([ 0.2310764 , -0.06622988]), 'effectorPosition': array([ 0.06516254, -0.04249072])}
episode index:2769
target Thresh 1.992918102049507
current state at start:  [-3.25522707  2.65068095]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.25522707,  2.65068095]), 'currentState': array([2.94407979, 2.15068095]), 'targetState': array([-0.48811664, -0.73876039]), 'effectorPosition': array([-0.60743567, -0.73155113])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9301050130493307
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.25522707,  2.65068095]), 'currentState': array([2.94407979, 2.15068095]), 'targetState': array([-0.48811664, -0.73876039]), 'effectorPosition': array([-0.60743567, -0.73155113])}
episode index:2770
target Thresh 1.99293225169105
current state at start:  [ 3.64167689 -1.60958947]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.64167689, -1.60958947]), 'currentState': array([3.14167689, 4.96567192]), 'targetState': array([-0.92258518,  0.74410122]), 'effectorPosition': array([-1.25066505,  0.96798964])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9301230552676457
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 3.64167689, -1.60958947]), 'currentState': array([3.30938325, 4.33417026]), 'targetState': array([-0.92258518,  0.74410122]), 'effectorPosition': array([-0.77707755,  0.81093719])}
episode index:2771
target Thresh 1.9929463730615902
current state at start:  [ 3.04306775 -2.95458386]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.04306775, -2.95458386]), 'currentState': array([3.493792  , 2.87030265]), 'targetState': array([ 0.31350473, -0.0675376 ]), 'effectorPosition': array([ 0.05811233, -0.26414189])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9301446558970585
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.04306775, -2.95458386]), 'currentState': array([3.95385379, 2.90121834]), 'targetState': array([ 0.31350473, -0.0675376 ]), 'effectorPosition': array([ 0.15302233, -0.18462477])}
episode index:2772
target Thresh 1.9929604662176132
current state at start:  [-3.58581607  1.71896146]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.58581607,  1.71896146]), 'currentState': array([2.19736923, 2.17536814]), 'targetState': array([-1.04632114, -0.22329458]), 'effectorPosition': array([-0.91953074, -0.13282898])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9301698471498904
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.58581607,  1.71896146]), 'currentState': array([2.19736923, 2.17536814]), 'targetState': array([-1.04632114, -0.22329458]), 'effectorPosition': array([-0.91953074, -0.13282898])}
episode index:2773
target Thresh 1.9929745312154918
current state at start:  [-0.78410891 -2.02223917]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.78410891, -2.02223917]), 'currentState': array([4.99907639, 4.38944228]), 'targetState': array([ 0.34406933, -0.59904698]), 'effectorPosition': array([-0.71656631, -0.92293451])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9298345299735566
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([-0.78410891, -2.02223917]), 'currentState': array([4.51181018, 4.2014611 ]), 'targetState': array([ 0.34406933, -0.59904698]), 'effectorPosition': array([-0.95661547, -0.32697579])}
episode index:2774
target Thresh 1.9929885681114858
current state at start:  [ 0.58976949 -2.59670728]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.58976949, -2.59670728]), 'currentState': array([0.08976949, 3.20170356]), 'targetState': array([-0.43123841, -1.10281161]), 'effectorPosition': array([ 0.00718448, -0.0596709 ])}
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.9298188724390495
{'reset': False, 'endBeforeDone': False, 'stepCount': 13, 'initial state': array([ 0.58976949, -2.59670728]), 'currentState': array([3.46308357, 1.90361184]), 'targetState': array([-0.43123841, -1.10281161]), 'effectorPosition': array([-0.34015631, -1.10945167])}
episode index:2775
target Thresh 1.993002576961743
current state at start:  [ 2.12348303 -1.99423623]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.12348303, -1.99423623]), 'currentState': array([1.83396086, 4.74048505]), 'targetState': array([1.11879115, 0.78161062]), 'effectorPosition': array([0.69774521, 1.25273156])}
done in step count: 74
reward sum = 0.47534004200570695
running average episode reward sum: 0.9296551552811124
{'reset': False, 'endBeforeDone': False, 'stepCount': 75, 'initial state': array([ 2.12348303, -1.99423623]), 'currentState': array([1.62365814, 4.56303948]), 'targetState': array([1.11879115, 0.78161062]), 'effectorPosition': array([0.94251148, 0.9022651 ])}
episode index:2776
target Thresh 1.9930165578222987
current state at start:  [-0.20794532 -2.11844016]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.20794532, -2.11844016]), 'currentState': array([5.57523999, 4.45365479]), 'targetState': array([ 0.01806065, -0.99118326]), 'effectorPosition': array([-0.06330451, -1.21830964])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9296804865179575
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.20794532, -2.11844016]), 'currentState': array([5.57523999, 4.45365479]), 'targetState': array([ 0.01806065, -0.99118326]), 'effectorPosition': array([-0.06330451, -1.21830964])}
episode index:2777
target Thresh 1.9930305107490762
current state at start:  [-1.84169669  1.76159081]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.84169669,  1.76159081]), 'currentState': array([3.94148862, 2.24827489]), 'targetState': array([ 0.01445389, -0.0500599 ]), 'effectorPosition': array([ 0.29885802, -0.81056957])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9296986360908454
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.84169669,  1.76159081]), 'currentState': array([3.44349252, 3.16841659]), 'targetState': array([ 0.01445389, -0.0500599 ]), 'effectorPosition': array([-0.0083182 ,  0.02550074])}
episode index:2778
target Thresh 1.9930444357978876
current state at start:  [0.98515877 2.36596995]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.98515877, 2.36596995]), 'currentState': array([0.48515877, 2.86596995]), 'targetState': array([ 0.0126111 , -0.00567575]), 'effectorPosition': array([-0.0935266 ,  0.25834268])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9297203350343174
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.98515877, 2.36596995]), 'currentState': array([6.26834408, 3.36596995]), 'targetState': array([ 0.0126111 , -0.00567575]), 'effectorPosition': array([ 0.02176235, -0.22284682])}
episode index:2779
target Thresh 1.993058333024433
current state at start:  [-1.41118847 -2.11148537]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.41118847, -2.11148537]), 'currentState': array([4.37199684, 4.20269458]), 'targetState': array([-0.8240517 ,  0.18957673]), 'effectorPosition': array([-0.99377488, -0.1912863 ])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9297384572159598
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.41118847, -2.11148537]), 'currentState': array([3.82638068, 4.03515915]), 'targetState': array([-0.8240517 ,  0.18957673]), 'effectorPosition': array([-0.78211127,  0.3674626 ])}
episode index:2780
target Thresh 1.993072202484301
current state at start:  [ 1.89632643 -2.12816801]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.89632643, -2.12816801]), 'currentState': array([1.40400738, 4.28378589]), 'targetState': array([1.26150561, 0.20401571]), 'effectorPosition': array([0.99394541, 0.42528957])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9297565663647496
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 1.89632643, -2.12816801]), 'currentState': array([1.02547449, 4.43404443]), 'targetState': array([1.26150561, 0.20401571]), 'effectorPosition': array([1.19822924, 0.1213182 ])}
episode index:2781
target Thresh 1.9930860442329699
current state at start:  [-1.44441663 -2.25180089]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.44441663, -2.25180089]), 'currentState': array([4.33876868, 4.53138442]), 'targetState': array([ 0.24291151, -0.73216923]), 'effectorPosition': array([-1.21508642, -0.40438765])}
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.9297409762516479
{'reset': False, 'endBeforeDone': False, 'stepCount': 13, 'initial state': array([-1.44441663, -2.25180089]), 'currentState': array([6.00446134, 4.09514273]), 'targetState': array([ 0.24291151, -0.73216923]), 'effectorPosition': array([ 0.18059169, -0.89989063])}
episode index:2782
target Thresh 1.9930998583258064
current state at start:  [ 0.90793529 -2.7766754 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.90793529, -2.7766754 ]), 'currentState': array([1.34827152, 3.00650991]), 'targetState': array([-0.09068742,  0.27379357]), 'effectorPosition': array([-0.12934127,  0.03860641])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9297662220381188
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.90793529, -2.7766754 ]), 'currentState': array([1.34827152, 3.00650991]), 'targetState': array([-0.09068742,  0.27379357]), 'effectorPosition': array([-0.12934127,  0.03860641])}
episode index:2783
target Thresh 1.993113644818067
current state at start:  [1.21250823 2.25101075]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.21250823, 2.25101075]), 'currentState': array([1.65708184, 1.75101075]), 'targetState': array([-1.36769842,  0.33207772]), 'effectorPosition': array([-1.05087705,  0.73292317])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9297807812256051
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([1.21250823, 2.25101075]), 'currentState': array([1.91496414, 1.86973396]), 'targetState': array([-1.36769842,  0.33207772]), 'effectorPosition': array([-1.13765074,  0.34167315])}
episode index:2784
target Thresh 1.9931274037648976
current state at start:  [-1.67170328 -2.72002517]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.67170328, -2.72002517]), 'currentState': array([4.83931716, 3.12440204]), 'targetState': array([ 0.27378731, -0.0329437 ]), 'effectorPosition': array([0.01707019, 0.00202945])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9298024039253445
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.67170328, -2.72002517]), 'currentState': array([4.98630069, 2.69379946]), 'targetState': array([ 0.27378731, -0.0329437 ]), 'effectorPosition': array([0.44350598, 0.02220052])}
episode index:2785
target Thresh 1.9931411352213344
current state at start:  [ 3.56402365 -2.58721553]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.56402365, -2.58721553]), 'currentState': array([4.01898739, 3.24338348]), 'targetState': array([0.29316349, 0.45965882]), 'effectorPosition': array([-0.08145821,  0.06096712])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.9298100089669722
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([ 3.56402365, -2.58721553]), 'currentState': array([5.9100762, 2.477756 ]), 'targetState': array([0.29316349, 0.45965882]), 'effectorPosition': array([0.42234666, 0.49634171])}
episode index:2786
target Thresh 1.9931548392423026
current state at start:  [-0.0638189   1.89292309]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.0638189 ,  1.89292309]), 'currentState': array([0.30266028, 1.70538077]), 'targetState': array([0.70680383, 0.80777535]), 'effectorPosition': array([0.53110193, 1.20398243])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9298280534560405
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-0.0638189 ,  1.89292309]), 'currentState': array([6.21744384, 2.04494078]), 'targetState': array([0.70680383, 0.80777535]), 'effectorPosition': array([0.60069564, 0.85206211])}
episode index:2787
target Thresh 1.993168515882619
current state at start:  [-2.67744517  2.30648321]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.67744517,  2.30648321]), 'currentState': array([3.28626982, 2.7976231 ]), 'targetState': array([ 0.13620797, -0.14134396]), 'effectorPosition': array([-0.00934559, -0.34214875])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.929853222733854
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.67744517,  2.30648321]), 'currentState': array([3.28626982, 2.7976231 ]), 'targetState': array([ 0.13620797, -0.14134396]), 'effectorPosition': array([-0.00934559, -0.34214875])}
episode index:2788
target Thresh 1.9931821651969894
current state at start:  [1.42336671 1.89369893]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.42336671, 1.89369893]), 'currentState': array([1.29518211, 2.08862159]), 'targetState': array([-0.75906129,  0.75834689]), 'effectorPosition': array([-0.69867201,  0.72240851])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9298783739627052
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.42336671, 1.89369893]), 'currentState': array([1.29518211, 2.08862159]), 'targetState': array([-0.75906129,  0.75834689]), 'effectorPosition': array([-0.69867201,  0.72240851])}
episode index:2789
target Thresh 1.993195787240012
current state at start:  [ 3.25817003 -1.91077493]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.25817003, -1.91077493]), 'currentState': array([2.91394486, 4.73077478]), 'targetState': array([-0.80432754,  1.12277089]), 'effectorPosition': array([-0.76646191,  1.20387112])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9299035071620017
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.25817003, -1.91077493]), 'currentState': array([2.91394486, 4.73077478]), 'targetState': array([-0.80432754,  1.12277089]), 'effectorPosition': array([-0.76646191,  1.20387112])}
episode index:2790
target Thresh 1.993209382066174
current state at start:  [-1.45954349 -1.86535293]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.45954349, -1.86535293]), 'currentState': array([4.41510157, 4.85875735]), 'targetState': array([-0.64365417, -1.06451579]), 'effectorPosition': array([-1.28156101, -0.8057878 ])}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9299009421986429
{'reset': False, 'endBeforeDone': False, 'stepCount': 9, 'initial state': array([-1.45954349, -1.86535293]), 'currentState': array([3.44334264, 1.67943805]), 'targetState': array([-0.64365417, -1.06451579]), 'effectorPosition': array([-0.55584933, -1.21415619])}
episode index:2791
target Thresh 1.9932229497298555
current state at start:  [ 1.892963   -1.85610038]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.892963  , -1.85610038]), 'currentState': array([2.07709049, 3.93739587]), 'targetState': array([0.33315135, 0.24000089]), 'effectorPosition': array([0.47917746, 0.60907033])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9299224676491448
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.892963  , -1.85610038]), 'currentState': array([2.24049839, 3.43739587]), 'targetState': array([0.33315135, 0.24000089]), 'effectorPosition': array([0.2015841 , 0.21500521])}
episode index:2792
target Thresh 1.9932364902853268
current state at start:  [1.71573243 2.24520381]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.71573243, 2.24520381]), 'currentState': array([1.26014796, 2.42628357]), 'targetState': array([-0.41196908,  0.76482325]), 'effectorPosition': array([-0.54953478,  0.43385528])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9299439776857903
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.71573243, 2.24520381]), 'currentState': array([0.86707533, 2.17758296]), 'targetState': array([-0.41196908,  0.76482325]), 'effectorPosition': array([-0.34824635,  0.85922239])}
episode index:2793
target Thresh 1.9932500037867502
current state at start:  [-1.9197505   2.28076583]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.9197505 ,  2.28076583]), 'currentState': array([3.9305221, 2.7555772]), 'targetState': array([-0.15602894,  0.33375204]), 'effectorPosition': array([ 0.21531694, -0.31749871])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9299584211440273
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-1.9197505 ,  2.28076583]), 'currentState': array([3.30373808, 3.29048479]), 'targetState': array([-0.15602894,  0.33375204]), 'effectorPosition': array([-0.03486667,  0.14461071])}
episode index:2794
target Thresh 1.9932634902881798
current state at start:  [-1.82466922 -2.4390081 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.82466922, -2.4390081 ]), 'currentState': array([4.05799788, 3.34417721]), 'targetState': array([0.09208498, 0.70867169]), 'effectorPosition': array([-0.17208472,  0.10624115])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9296256989897718
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([-1.82466922, -2.4390081 ]), 'currentState': array([3.83395413, 3.53744891]), 'targetState': array([0.09208498, 0.70867169]), 'effectorPosition': array([-0.30567586,  0.24744455])}
episode index:2795
target Thresh 1.9932769498435614
current state at start:  [2.20142485 1.77653761]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.20142485, 1.77653761]), 'currentState': array([1.70617042, 2.26032023]), 'targetState': array([-0.64381896,  0.98164216]), 'effectorPosition': array([-0.81359288,  0.25637235])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9296402459500759
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([2.20142485, 1.77653761]), 'currentState': array([1.42745764, 1.69020163]), 'targetState': array([-0.64381896,  0.98164216]), 'effectorPosition': array([-0.85686526,  1.01367569])}
episode index:2796
target Thresh 1.9932903825067336
current state at start:  [ 0.08748026 -1.70674216]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.08748026, -1.70674216]), 'currentState': array([0.37316827, 4.09292612]), 'targetState': array([0.2919587 , 0.01763189]), 'effectorPosition': array([ 0.68736492, -0.60525503])}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.9296344815602059
{'reset': False, 'endBeforeDone': False, 'stepCount': 10, 'initial state': array([ 0.08748026, -1.70674216]), 'currentState': array([4.8435943 , 3.05376262]), 'targetState': array([0.2919587 , 0.01763189]), 'effectorPosition': array([0.08746751, 0.00765452])}
episode index:2797
target Thresh 1.9933037883314269
current state at start:  [-1.37951602  2.17830905]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.37951602,  2.17830905]), 'currentState': array([5.40366929, 2.63332039]), 'targetState': array([1.05407965, 0.7031674 ]), 'effectorPosition': array([0.45553589, 0.21287029])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9296490149835225
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-1.37951602,  2.17830905]), 'currentState': array([5.8656943 , 1.66660834]), 'targetState': array([1.05407965, 0.7031674 ]), 'effectorPosition': array([1.230269  , 0.54323769])}
episode index:2798
target Thresh 1.9933171673712644
current state at start:  [-4.05441332  1.84052646]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.05441332,  1.84052646]), 'currentState': array([1.75843334, 2.34052646]), 'targetState': array([-0.24074921,  0.01786174]), 'effectorPosition': array([-0.76221271,  0.16476902])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9296705766073224
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-4.05441332,  1.84052646]), 'currentState': array([1.35025254, 2.81851146]), 'targetState': array([-0.24074921,  0.01786174]), 'effectorPosition': array([-0.29848152,  0.11993932])}
episode index:2799
target Thresh 1.9933305196797626
current state at start:  [ 0.77147281 -2.59111451]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.77147281, -2.59111451]), 'currentState': array([0.39760246, 3.67610169]), 'targetState': array([1.12559306, 0.46981532]), 'effectorPosition': array([ 0.32585196, -0.41567153])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9296816214049627
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([ 0.77147281, -2.59111451]), 'currentState': array([5.72252226, 1.9660594 ]), 'targetState': array([1.12559306, 0.46981532]), 'effectorPosition': array([1.01154959, 0.45460473])}
episode index:2800
target Thresh 1.9933438453103307
current state at start:  [0.25074202 1.83077252]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.25074202, 1.83077252]), 'currentState': array([0.4284678 , 2.33077252]), 'targetState': array([0.01833333, 0.4747787 ]), 'effectorPosition': array([-0.01818612,  0.78858156])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9297031559921082
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.25074202, 1.83077252]), 'currentState': array([0.16392769, 2.82485971]), 'targetState': array([0.01833333, 0.4747787 ]), 'effectorPosition': array([-0.00175406,  0.31540578])}
episode index:2801
target Thresh 1.9933571443162712
current state at start:  [-0.93305485 -2.29722493]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.93305485, -2.29722493]), 'currentState': array([4.92785226, 3.82944603]), 'targetState': array([-0.34344461, -0.25647073]), 'effectorPosition': array([-0.57158424, -0.35786892])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.929728244087757
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.93305485, -2.29722493]), 'currentState': array([4.92785226, 3.82944603]), 'targetState': array([-0.34344461, -0.25647073]), 'effectorPosition': array([-0.57158424, -0.35786892])}
episode index:2802
target Thresh 1.99337041675078
current state at start:  [-2.24041732  1.68478794]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.24041732,  1.68478794]), 'currentState': array([4.54276798, 2.12335647]), 'targetState': array([ 0.6947722 , -1.17003265]), 'effectorPosition': array([ 0.75876164, -0.61200047])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9297497466763807
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.24041732,  1.68478794]), 'currentState': array([4.47572048, 1.70725334]), 'targetState': array([ 0.6947722 , -1.17003265]), 'effectorPosition': array([ 0.76051773, -1.07216833])}
episode index:2803
target Thresh 1.993383662666947
current state at start:  [ 0.30025392 -2.24150669]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.30025392, -2.24150669]), 'currentState': array([0.70560526, 3.54167861]), 'targetState': array([-0.10238679,  0.05573691]), 'effectorPosition': array([ 0.31270244, -0.24527974])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9297712339279225
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.30025392, -2.24150669]), 'currentState': array([1.20560526, 3.0475849 ]), 'targetState': array([-0.10238679,  0.05573691]), 'effectorPosition': array([-0.0861023 ,  0.03764765])}
episode index:2804
target Thresh 1.9933968821177557
current state at start:  [-0.73662198 -2.06439367]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.73662198, -2.06439367]), 'currentState': array([5.08775109, 3.767593  ]), 'targetState': array([-0.11674046, -0.4284349 ]), 'effectorPosition': array([-0.47559689, -0.39121959])}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9297687289227531
{'reset': False, 'endBeforeDone': False, 'stepCount': 9, 'initial state': array([-0.73662198, -2.06439367]), 'currentState': array([3.39652701, 2.78101186]), 'targetState': array([-0.11674046, -0.4284349 ]), 'effectorPosition': array([ 0.02674475, -0.35763191])}
episode index:2805
target Thresh 1.9934100751560841
current state at start:  [-0.82633967 -2.60559808]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.82633967, -2.60559808]), 'currentState': array([4.95904454, 4.12780531]), 'targetState': array([ 0.11276401, -0.23472882]), 'effectorPosition': array([-0.69928148, -0.63820134])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.9297762917598797
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([-0.82633967, -2.60559808]), 'currentState': array([4.03542058, 2.89975258]), 'targetState': array([ 0.11276401, -0.23472882]), 'effectorPosition': array([ 0.16844636, -0.17270769])}
episode index:2806
target Thresh 1.9934232418347044
current state at start:  [ 0.02026897 -2.71038083]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.02026897, -2.71038083]), 'currentState': array([5.81496996, 3.37193024]), 'targetState': array([0.85578164, 0.08878968]), 'effectorPosition': array([-0.07946514, -0.21565374])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9297872713531252
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([ 0.02026897, -2.71038083]), 'currentState': array([5.21372152, 2.3516068 ]), 'targetState': array([0.85578164, 0.08878968]), 'effectorPosition': array([0.76525604, 0.08168516])}
episode index:2807
target Thresh 1.9934363822062835
current state at start:  [-0.17835742 -2.87760469]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.17835742, -2.87760469]), 'currentState': array([5.60482789, 3.6919934 ]), 'targetState': array([0.04500456, 0.01310625]), 'effectorPosition': array([-0.2132202 , -0.49990716])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9298016986069169
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-0.17835742, -2.87760469]), 'currentState': array([4.73311174, 3.12327729]), 'targetState': array([0.04500456, 0.01310625]), 'effectorPosition': array([0.01831388, 0.00021181])}
episode index:2808
target Thresh 1.9934494963233824
current state at start:  [-3.37545725  1.91729525]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.37545725,  1.91729525]), 'currentState': array([2.40772806, 2.41729525]), 'targetState': array([-0.38043328, -0.06083962]), 'effectorPosition': array([-0.63019534, -0.32391901])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9298231291164907
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.37545725,  1.91729525]), 'currentState': array([1.95069499, 2.88853601]), 'targetState': array([-0.38043328, -0.06083962]), 'effectorPosition': array([-0.24432419, -0.06326411])}
episode index:2809
target Thresh 1.993462584238458
current state at start:  [-0.41667972  2.20637837]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.41667972,  2.20637837]), 'currentState': array([5.37136316, 2.70637837]), 'targetState': array([ 0.10316708, -0.03613489]), 'effectorPosition': array([0.3904088 , 0.18444927])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9298445443730328
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.41667972,  2.20637837]), 'currentState': array([4.90283754, 3.19648584]), 'targetState': array([ 0.10316708, -0.03613489]), 'effectorPosition': array([-0.05358849, -0.01186505])}
episode index:2810
target Thresh 1.9934756460038616
current state at start:  [ 0.36381842 -2.6729529 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.36381842, -2.6729529 ]), 'currentState': array([6.14700372, 4.11023241]), 'targetState': array([ 0.95764658, -0.85259531]), 'effectorPosition': array([ 0.31768185, -0.87534915])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9295137565593106
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([ 0.36381842, -2.6729529 ]), 'currentState': array([2.18947906, 0.88219095]), 'targetState': array([ 0.95764658, -0.85259531]), 'effectorPosition': array([-1.57751897,  0.88450881])}
episode index:2811
target Thresh 1.9934886816718407
current state at start:  [ 2.69630756 -1.68911279]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.69630756, -1.68911279]), 'currentState': array([3.07887941, 4.66489703]), 'targetState': array([-0.46561201,  1.2823943 ]), 'effectorPosition': array([-0.88805192,  1.0566057 ])}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.929508067900322
{'reset': False, 'endBeforeDone': False, 'stepCount': 10, 'initial state': array([ 2.69630756, -1.68911279]), 'currentState': array([0.97880004, 1.74882084]), 'targetState': array([-0.46561201,  1.2823943 ]), 'effectorPosition': array([-0.35751169,  1.23207714])}
episode index:2812
target Thresh 1.9935016912945378
current state at start:  [-1.12833068  2.44279791]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.12833068,  2.44279791]), 'currentState': array([4.65485463, 1.98744906]), 'targetState': array([-0.10063542, -0.77719001]), 'effectorPosition': array([ 0.87870442, -0.64689637])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.929526052945505
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.12833068,  2.44279791]), 'currentState': array([3.65485463, 2.09028686]), 'targetState': array([-0.10063542, -0.77719001]), 'effectorPosition': array([-0.01243466, -1.00347869])}
episode index:2813
target Thresh 1.9935146749239914
current state at start:  [-1.02423901 -2.68082484]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.02423901, -2.68082484]), 'currentState': array([4.7589463 , 3.25183204]), 'targetState': array([0.07315456, 0.21960085]), 'effectorPosition': array([-0.10961452, -0.01118384])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9295440252081401
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.02423901, -2.68082484]), 'currentState': array([4.45570935, 3.07928527]), 'targetState': array([0.07315456, 0.21960085]), 'effectorPosition': array([ 0.05973447, -0.01768467])}
episode index:2814
target Thresh 1.993527632612136
current state at start:  [ 1.84789269 -2.39887552]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.84789269, -2.39887552]), 'currentState': array([1.60050173, 3.38430979]), 'targetState': array([ 0.00695789, -0.00141143]), 'effectorPosition': array([0.23936439, 0.03643693])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9295690539736078
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.84789269, -2.39887552]), 'currentState': array([1.60050173, 3.38430979]), 'targetState': array([ 0.00695789, -0.00141143]), 'effectorPosition': array([0.23936439, 0.03643693])}
episode index:2815
target Thresh 1.9935405644108024
current state at start:  [-0.07434231 -2.0211292 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.07434231, -2.0211292 ]), 'currentState': array([5.96951338, 3.76205611]), 'targetState': array([0.40170836, 0.05311834]), 'effectorPosition': array([-0.00210044, -0.61055501])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9295800720687876
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([-0.07434231, -2.0211292 ]), 'currentState': array([4.89058786, 2.58971458]), 'targetState': array([0.40170836, 0.05311834]), 'effectorPosition': array([ 0.54230045, -0.05317396])}
episode index:2816
target Thresh 1.993553470371718
current state at start:  [-0.91195919  2.95557263]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.91195919,  2.95557263]), 'currentState': array([4.87122612, 3.39452406]), 'targetState': array([-0.8138059 , -0.21678898]), 'effectorPosition': array([-0.24206058, -0.07099745])}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9295776455946516
{'reset': False, 'endBeforeDone': False, 'stepCount': 9, 'initial state': array([-0.91195919,  2.95557263]), 'currentState': array([2.18996451, 2.1466643 ]), 'targetState': array([-0.8138059 , -0.21678898]), 'effectorPosition': array([-0.94733773, -0.11586744])}
episode index:2817
target Thresh 1.9935663505465064
current state at start:  [-3.96776528  2.20721566]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.96776528,  2.20721566]), 'currentState': array([2.76437005, 2.63389437]), 'targetState': array([-0.16799422, -0.58413141]), 'effectorPosition': array([-0.29634052, -0.40552511])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9296026357842916
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.96776528,  2.20721566]), 'currentState': array([2.76437005, 2.63389437]), 'targetState': array([-0.16799422, -0.58413141]), 'effectorPosition': array([-0.29634052, -0.40552511])}
episode index:2818
target Thresh 1.9935792049866883
current state at start:  [-0.11877748 -2.82106651]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.11877748, -2.82106651]), 'currentState': array([0.17621115, 2.9621188 ]), 'targetState': array([-0.80469226,  0.62911393]), 'effectorPosition': array([-0.01547973,  0.17856336])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9296170722384298
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-0.11877748, -2.82106651]), 'currentState': array([1.44907782, 1.91307948]), 'targetState': array([-0.80469226,  0.62911393]), 'effectorPosition': array([-0.85435589,  0.77382082])}
episode index:2819
target Thresh 1.9935920337436817
current state at start:  [ 1.11401631 -2.17025745]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.11401631, -2.17025745]), 'currentState': array([1.04181114, 3.84041345]), 'targetState': array([0.98404095, 0.00833593]), 'effectorPosition': array([ 0.67367782, -0.12229292])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9296384846241608
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.11401631, -2.17025745]), 'currentState': array([0.8244819 , 4.30635515]), 'targetState': array([0.98404095, 0.00833593]), 'effectorPosition': array([ 1.08528035, -0.17952453])}
episode index:2820
target Thresh 1.9936048368688015
current state at start:  [-3.15771946  2.82138102]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.15771946,  2.82138102]), 'currentState': array([2.66568119, 2.41079741]), 'targetState': array([-0.53610893, -0.80955018]), 'effectorPosition': array([-0.53277677, -0.47629952])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9296598818291858
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.15771946,  2.82138102]), 'currentState': array([3.0950169 , 1.99720152]), 'targetState': array([-0.53610893, -0.80955018]), 'effectorPosition': array([-0.62815347, -0.88216897])}
episode index:2821
target Thresh 1.9936176144132602
current state at start:  [ 2.78948705 -2.19324877]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.78948705, -2.19324877]), 'currentState': array([2.9101451 , 3.58993654]), 'targetState': array([-0.36895173,  0.13947872]), 'effectorPosition': array([0.00323469, 0.44458643])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9296742826506497
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 2.78948705, -2.19324877]), 'currentState': array([1.65084723, 2.73462015]), 'targetState': array([-0.36895173,  0.13947872]), 'effectorPosition': array([-0.40109463,  0.04976225])}
episode index:2822
target Thresh 1.9936303664281683
current state at start:  [0.27985671 2.29624668]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.27985671, 2.29624668]), 'currentState': array([6.06557206, 2.79624668]), 'targetState': array([0.30298944, 0.24323819]), 'effectorPosition': array([0.13073602, 0.31779131])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9296991943464872
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.27985671, 2.29624668]), 'currentState': array([6.06557206, 2.79624668]), 'targetState': array([0.30298944, 0.24323819]), 'effectorPosition': array([0.13073602, 0.31779131])}
episode index:2823
target Thresh 1.9936430929645332
current state at start:  [0.41483522 2.8159366 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.41483522, 2.8159366 ]), 'currentState': array([0.47507704, 3.30368948]), 'targetState': array([-0.4904292, -0.0021057]), 'effectorPosition': array([ 0.08547718, -0.13751927])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9297135710482058
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([0.41483522, 2.8159366 ]), 'currentState': array([1.66096139, 2.44561052]), 'targetState': array([-0.4904292, -0.0021057]), 'effectorPosition': array([-0.65947687,  0.17390078])}
episode index:2824
target Thresh 1.9936557940732618
current state at start:  [1.47674693 2.17530962]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.47674693, 2.17530962]), 'currentState': array([1.97674693, 2.13657091]), 'targetState': array([-0.90654112, -0.11671478]), 'effectorPosition': array([-0.95876789,  0.09286769])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9297384512000472
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.47674693, 2.17530962]), 'currentState': array([1.97674693, 2.13657091]), 'targetState': array([-0.90654112, -0.11671478]), 'effectorPosition': array([-0.95876789,  0.09286769])}
episode index:2825
target Thresh 1.993668469805158
current state at start:  [-0.06949689 -1.89900286]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.06949689, -1.89900286]), 'currentState': array([5.71368841, 3.9542511 ]), 'targetState': array([-0.2817442 , -0.52508357]), 'effectorPosition': array([-0.12840925, -0.77998078])}
done in step count: 16
reward sum = 0.8514577710948755
running average episode reward sum: 0.9297107510301587
{'reset': False, 'endBeforeDone': False, 'stepCount': 17, 'initial state': array([-0.06949689, -1.89900286]), 'currentState': array([3.02981304, 2.38825369]), 'targetState': array([-0.2817442 , -0.52508357]), 'effectorPosition': array([-0.3452093 , -0.64962519])}
episode index:2826
target Thresh 1.9936811202109253
current state at start:  [-0.58769312 -2.01746076]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.58769312, -2.01746076]), 'currentState': array([5.19549218, 4.71227522]), 'targetState': array([ 0.8569273 , -1.05834511]), 'effectorPosition': array([-0.42108103, -1.34998639])}
done in step count: 87
reward sum = 0.41712087993322033
running average episode reward sum: 0.9295294316558759
{'reset': False, 'endBeforeDone': False, 'stepCount': 88, 'initial state': array([-0.58769312, -2.01746076]), 'currentState': array([6.03215739, 4.93531985]), 'targetState': array([ 0.8569273 , -1.05834511]), 'effectorPosition': array([ 0.94056425, -1.24800509])}
episode index:2827
target Thresh 1.9936937453411647
current state at start:  [ 0.26488511 -2.48120819]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.26488511, -2.48120819]), 'currentState': array([0.57969565, 3.32296293]), 'targetState': array([-0.10278971, -0.01731662]), 'effectorPosition': array([ 0.11252814, -0.14192434])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9295543505272847
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.26488511, -2.48120819]), 'currentState': array([0.57969565, 3.32296293]), 'targetState': array([-0.10278971, -0.01731662]), 'effectorPosition': array([ 0.11252814, -0.14192434])}
episode index:2828
target Thresh 1.9937063452463772
current state at start:  [-1.38210737  1.73453093]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.38210737,  1.73453093]), 'currentState': array([4.70018395, 2.23453093]), 'targetState': array([ 0.72901078, -0.20081175]), 'effectorPosition': array([ 0.78295247, -0.39352216])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9295792517819588
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.38210737,  1.73453093]), 'currentState': array([4.70018395, 2.23453093]), 'targetState': array([ 0.72901078, -0.20081175]), 'effectorPosition': array([ 0.78295247, -0.39352216])}
episode index:2829
target Thresh 1.9937189199769625
current state at start:  [ 3.36469672 -2.73419084]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.36469672, -2.73419084]), 'currentState': array([2.86469672, 4.04899447]), 'targetState': array([-0.61503273,  1.11666969]), 'effectorPosition': array([-0.15417927,  0.86292459])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9296006018696682
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.36469672, -2.73419084]), 'currentState': array([2.84449741, 4.40589159]), 'targetState': array([-0.61503273,  1.11666969]), 'effectorPosition': array([-0.38858692,  1.11604568])}
episode index:2830
target Thresh 1.993731469583219
current state at start:  [-1.62846709  2.75041504]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.62846709,  2.75041504]), 'currentState': array([4.2089392 , 2.33798339]), 'targetState': array([ 0.27421012, -0.93684953]), 'effectorPosition': array([ 0.4829723 , -0.61523302])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9296219368743062
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.62846709,  2.75041504]), 'currentState': array([3.89370054, 2.05259831]), 'targetState': array([ 0.27421012, -0.93684953]), 'effectorPosition': array([ 0.21353799, -1.01372973])}
episode index:2831
target Thresh 1.9937439941153456
current state at start:  [ 1.08054424 -1.66294992]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.08054424, -1.66294992]), 'currentState': array([0.60090593, 4.21010709]), 'targetState': array([ 0.43899614, -0.24023958]), 'effectorPosition': array([ 0.92328798, -0.42975065])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9296432568118504
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.08054424, -1.66294992]), 'currentState': array([0.9139897 , 3.81254071]), 'targetState': array([ 0.43899614, -0.24023958]), 'effectorPosition': array([ 0.62473195, -0.2079539 ])}
episode index:2832
target Thresh 1.9937564936234402
current state at start:  [-2.4780274   2.07219529]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.4780274 ,  2.07219529]), 'currentState': array([4.16976974, 2.57219529]), 'targetState': array([ 0.40087712, -0.86442095]), 'effectorPosition': array([ 0.3802128 , -0.41350475])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9296610671694885
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-2.4780274 ,  2.07219529]), 'currentState': array([3.98902518, 2.32377535]), 'targetState': array([ 0.40087712, -0.86442095]), 'effectorPosition': array([ 0.33765164, -0.71997255])}
episode index:2833
target Thresh 1.9937689681575013
current state at start:  [0.8531403  2.10477411]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.8531403 , 2.10477411]), 'currentState': array([0.43112955, 2.58532586]), 'targetState': array([-0.08699468,  0.72005774]), 'effectorPosition': array([-0.08368626,  0.54270817])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.929685886835272
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.8531403 , 2.10477411]), 'currentState': array([0.43112955, 2.58532586]), 'targetState': array([-0.08699468,  0.72005774]), 'effectorPosition': array([-0.08368626,  0.54270817])}
episode index:2834
target Thresh 1.9937814177674265
current state at start:  [-2.12358257  1.89151111]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.12358257,  1.89151111]), 'currentState': array([3.65960274, 2.39151111]), 'targetState': array([ 0.17561255, -0.43048854]), 'effectorPosition': array([ 0.10438585, -0.72514621])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9297071616547303
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.12358257,  1.89151111]), 'currentState': array([3.73895081, 2.86192283]), 'targetState': array([ 0.17561255, -0.43048854]), 'effectorPosition': array([ 0.12313563, -0.2500887 ])}
episode index:2835
target Thresh 1.9937938425030144
current state at start:  [-2.68494906  2.67440356]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.68494906,  2.67440356]), 'currentState': array([4.09823625, 2.79118002]), 'targetState': array([ 0.83869121, -0.09196859]), 'effectorPosition': array([ 0.24553506, -0.24748788])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9297214747147957
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-2.68494906,  2.67440356]), 'currentState': array([5.07982086, 2.34213588]), 'targetState': array([ 0.83869121, -0.09196859]), 'effectorPosition': array([ 0.77793042, -0.02513318])}
episode index:2836
target Thresh 1.993806242413964
current state at start:  [ 0.59390073 -2.52421942]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.59390073, -2.52421942]), 'currentState': array([1.07953571, 3.26251645]), 'targetState': array([0.48163046, 0.17504556]), 'effectorPosition': array([ 0.10980836, -0.05046661])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.9297223008949833
{'reset': False, 'endBeforeDone': False, 'stepCount': 8, 'initial state': array([ 0.59390073, -2.52421942]), 'currentState': array([4.82772829, 2.77349199]), 'targetState': array([0.48163046, 0.17504556]), 'effectorPosition': array([ 0.36516227, -0.02513023])}
episode index:2837
target Thresh 1.993818617549875
current state at start:  [ 3.79083549 -1.87606303]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.79083549, -1.87606303]), 'currentState': array([3.87369541, 3.90712227]), 'targetState': array([-0.35960366,  0.26232543]), 'effectorPosition': array([-0.6706718 ,  0.32888963])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9297435403943156
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.79083549, -1.87606303]), 'currentState': array([4.17430986, 3.40712227]), 'targetState': array([-0.35960366,  0.26232543]), 'effectorPosition': array([-0.24329979,  0.10439304])}
episode index:2838
target Thresh 1.9938309679602484
current state at start:  [ 3.38825057 -1.90896054]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.38825057, -1.90896054]), 'currentState': array([3.81830711, 3.87422476]), 'targetState': array([0.11012973, 0.27679321]), 'effectorPosition': array([-0.61888516,  0.36076039])}
done in step count: 17
reward sum = 0.8429431933839268
running average episode reward sum: 0.9297129661262599
{'reset': False, 'endBeforeDone': False, 'stepCount': 18, 'initial state': array([ 3.38825057, -1.90896054]), 'currentState': array([5.26521333, 2.88998203]), 'targetState': array([0.11012973, 0.27679321]), 'effectorPosition': array([0.22841346, 0.10393223])}
episode index:2839
target Thresh 1.993843293694485
current state at start:  [ 2.79423828 -2.28119393]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.79423828, -2.28119393]), 'currentState': array([2.345062  , 3.50199138]), 'targetState': array([-0.97983609,  0.09437257]), 'effectorPosition': array([0.20720119, 0.29249802])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9297272569832576
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 2.79423828, -2.28119393]), 'currentState': array([2.14202849, 2.09449174]), 'targetState': array([-0.97983609,  0.09437257]), 'effectorPosition': array([-0.99877985, -0.04765966])}
episode index:2840
target Thresh 1.9938555948018881
current state at start:  [ 4.10838098 -2.34351683]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.10838098, -2.34351683]), 'currentState': array([4.51400775, 3.62760442]), 'targetState': array([ 0.03595384, -0.45541412]), 'effectorPosition': array([-0.48076347, -0.02146816])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.929734741246868
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([ 4.10838098, -2.34351683]), 'currentState': array([3.57067331, 2.81180331]), 'targetState': array([ 0.03595384, -0.45541412]), 'effectorPosition': array([ 0.08572605, -0.31690673])}
episode index:2841
target Thresh 1.9938678713316624
current state at start:  [-1.69056977  2.51433569]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.69056977,  2.51433569]), 'currentState': array([5.08836206, 2.74928167]), 'targetState': array([0.85730226, 0.326439  ]), 'effectorPosition': array([0.38351499, 0.06971577])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9297559464751414
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.69056977,  2.51433569]), 'currentState': array([5.53503998, 2.33268111]), 'targetState': array([0.85730226, 0.326439  ]), 'effectorPosition': array([0.7192128 , 0.31962507])}
episode index:2842
target Thresh 1.993880123332914
current state at start:  [-1.96294052  1.86959863]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.96294052,  1.86959863]), 'currentState': array([4.66177425, 2.3642253 ]), 'targetState': array([ 0.8169683, -0.2354804]), 'effectorPosition': array([ 0.68597491, -0.32235589])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9297806541970988
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.96294052,  1.86959863]), 'currentState': array([4.66177425, 2.3642253 ]), 'targetState': array([ 0.8169683, -0.2354804]), 'effectorPosition': array([ 0.68597491, -0.32235589])}
episode index:2843
target Thresh 1.9938923508546504
current state at start:  [ 1.1289609  -2.53815335]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.1289609 , -2.53815335]), 'currentState': array([1.49937226, 3.27229303]), 'targetState': array([0.48253363, 0.04301842]), 'effectorPosition': array([ 0.13060496, -0.00079329])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9298018283693219
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.1289609 , -2.53815335]), 'currentState': array([1.17796628, 3.49322625]), 'targetState': array([0.48253363, 0.04301842]), 'effectorPosition': array([ 0.34161963, -0.07532214])}
episode index:2844
target Thresh 1.9939045539457825
current state at start:  [-0.63767386  2.31410266]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.63767386,  2.31410266]), 'currentState': array([5.14551144, 2.79211329]), 'targetState': array([ 0.02017539, -0.18962646]), 'effectorPosition': array([0.33616137, 0.0888443 ])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9298160628760462
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-0.63767386,  2.31410266]), 'currentState': array([3.91601228, 3.02129933]), 'targetState': array([ 0.02017539, -0.18962646]), 'effectorPosition': array([ 0.07875284, -0.0908352 ])}
episode index:2845
target Thresh 1.993916732655122
current state at start:  [-2.56851289  2.04960363]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.56851289,  2.04960363]), 'currentState': array([3.39050454, 2.54960363]), 'targetState': array([-0.04164268, -0.69104867]), 'effectorPosition': array([-0.02745703, -0.58273602])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9298407234302009
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.56851289,  2.04960363]), 'currentState': array([3.39050454, 2.54960363]), 'targetState': array([-0.04164268, -0.69104867]), 'effectorPosition': array([-0.02745703, -0.58273602])}
episode index:2846
target Thresh 1.993928887031384
current state at start:  [-0.01093362 -2.65665564]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.01093362, -2.65665564]), 'currentState': array([5.98265007, 3.2004354 ]), 'targetState': array([0.06762755, 0.09459378]), 'effectorPosition': array([-0.0157561 , -0.05668523])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9298653666604677
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.01093362, -2.65665564]), 'currentState': array([5.98265007, 3.2004354 ]), 'targetState': array([0.06762755, 0.09459378]), 'effectorPosition': array([-0.0157561 , -0.05668523])}
episode index:2847
target Thresh 1.993941017123186
current state at start:  [0.5457565  2.24527949]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.5457565 , 2.24527949]), 'currentState': array([0.99344096, 2.74527949]), 'targetState': array([-0.53029017,  0.32627399]), 'effectorPosition': array([-0.28114409,  0.27563943])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9298864813491402
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.5457565 , 2.24527949]), 'currentState': array([1.49344096, 2.37311607]), 'targetState': array([-0.53029017,  0.32627399]), 'effectorPosition': array([-0.6712448 ,  0.33390078])}
episode index:2848
target Thresh 1.9939531229790486
current state at start:  [-0.09728005  1.74469324]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.09728005,  1.74469324]), 'currentState': array([0.40271995, 1.86459868]), 'targetState': array([0.10463193, 1.19830036]), 'effectorPosition': array([0.27844449, 1.15900009])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9299110912187966
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.09728005,  1.74469324]), 'currentState': array([0.40271995, 1.86459868]), 'targetState': array([0.10463193, 1.19830036]), 'effectorPosition': array([0.27844449, 1.15900009])}
episode index:2849
target Thresh 1.9939652046473948
current state at start:  [1.08622213 2.61487245]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.08622213, 2.61487245]), 'currentState': array([1.58622213, 2.22373041]), 'targetState': array([-0.66251021,  0.66688339]), 'effectorPosition': array([-0.80026429,  0.38018142])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.929932175046439
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.08622213, 2.61487245]), 'currentState': array([1.16592165, 2.15868685]), 'targetState': array([-0.66251021,  0.66688339]), 'effectorPosition': array([-0.58939572,  0.73715589])}
episode index:2850
target Thresh 1.9939772621765517
current state at start:  [ 0.40668288 -1.99555227]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.40668288, -1.99555227]), 'currentState': array([0.72565422, 3.86981625]), 'targetState': array([ 0.04139072, -0.06713529]), 'effectorPosition': array([ 0.63141311, -0.32954783])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9299532440836026
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.40668288, -1.99555227]), 'currentState': array([1.17646927, 3.43137471]), 'targetState': array([ 0.04139072, -0.06713529]), 'effectorPosition': array([ 0.27983231, -0.07128484])}
episode index:2851
target Thresh 1.9939892956147494
current state at start:  [ 4.08056621 -2.41523197]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.08056621, -2.41523197]), 'currentState': array([4.37154732, 3.45731593]), 'targetState': array([0.28735166, 0.44210522]), 'effectorPosition': array([-0.30916471,  0.0572109 ])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9299639883914274
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([ 4.08056621, -2.41523197]), 'currentState': array([5.58298494, 2.57497373]), 'targetState': array([0.28735166, 0.44210522]), 'effectorPosition': array([0.46539583, 0.30978272])}
episode index:2852
target Thresh 1.9940013050101213
current state at start:  [-3.62232253  2.46262919]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.62232253,  2.46262919]), 'currentState': array([2.27843837, 2.9585207 ]), 'targetState': array([ 0.02104989, -0.08901171]), 'effectorPosition': array([-0.14920283, -0.10564257])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9299885365903788
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.62232253,  2.46262919]), 'currentState': array([2.27843837, 2.9585207 ]), 'targetState': array([ 0.02104989, -0.08901171]), 'effectorPosition': array([-0.14920283, -0.10564257])}
episode index:2853
target Thresh 1.9940132904107053
current state at start:  [-1.32851054 -2.43885759]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.32851054, -2.43885759]), 'currentState': array([4.48846041, 4.33251327]), 'targetState': array([-1.06004506,  0.5269012 ]), 'effectorPosition': array([-1.0452434, -0.4072544])}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.9299827652907618
{'reset': False, 'endBeforeDone': False, 'stepCount': 10, 'initial state': array([-1.32851054, -2.43885759]), 'currentState': array([1.60331817, 1.77457055]), 'targetState': array([-1.06004506,  0.5269012 ]), 'effectorPosition': array([-1.00472785,  0.76536798])}
episode index:2854
target Thresh 1.994025251864443
current state at start:  [ 0.95890208 -1.8321323 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.95890208, -1.8321323 ]), 'currentState': array([1.43570613, 4.03316216]), 'targetState': array([1.12015502, 0.54762737]), 'effectorPosition': array([0.82104494, 0.26363219])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9300037870892588
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.95890208, -1.8321323 ]), 'currentState': array([1.61188403, 4.33018056]), 'targetState': array([1.12015502, 0.54762737]), 'effectorPosition': array([0.90130418, 0.66461258])}
episode index:2855
target Thresh 1.9940371894191802
current state at start:  [ 2.95058777 -1.92782951]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.95058777, -1.92782951]), 'currentState': array([3.20941179, 4.04923472]), 'targetState': array([-0.01400697,  0.96546088]), 'effectorPosition': array([-0.43691491,  0.76019345])}
done in step count: 192
reward sum = 0.14519690621578263
running average episode reward sum: 0.929728994764023
{'reset': False, 'endBeforeDone': False, 'stepCount': 193, 'initial state': array([ 2.95058777, -1.92782951]), 'currentState': array([2.92907503, 4.11881707]), 'targetState': array([-0.01400697,  0.96546088]), 'effectorPosition': array([-0.25591761,  0.903247  ])}
episode index:2856
target Thresh 1.994049103122667
current state at start:  [ 1.2723551  -2.58344529]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.2723551 , -2.58344529]), 'currentState': array([1.62913327, 3.19974002]), 'targetState': array([-0.01895058,  0.56939112]), 'effectorPosition': array([0.0579172 , 0.00507551])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9297431949758663
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 1.2723551 , -2.58344529]), 'currentState': array([0.34533583, 2.73882546]), 'targetState': array([-0.01895058,  0.56939112]), 'effectorPosition': array([-0.05738945,  0.39591249])}
episode index:2857
target Thresh 1.9940609930225586
current state at start:  [-0.28881569  2.64214742]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.28881569,  2.64214742]), 'currentState': array([5.49436962, 3.09481638]), 'targetState': array([0.05333235, 0.12692527]), 'effectorPosition': array([0.03394735, 0.03217449])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9297677774828726
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.28881569,  2.64214742]), 'currentState': array([5.49436962, 3.09481638]), 'targetState': array([0.05333235, 0.12692527]), 'effectorPosition': array([0.03394735, 0.03217449])}
episode index:2858
target Thresh 1.9940728591664143
current state at start:  [-2.28774511  2.03839045]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.28774511,  2.03839045]), 'currentState': array([4.2541822 , 1.82576581]), 'targetState': array([ 0.33225499, -1.17059489]), 'effectorPosition': array([ 0.53707772, -1.0986882 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9297923427933018
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.28774511,  2.03839045]), 'currentState': array([4.2541822 , 1.82576581]), 'targetState': array([ 0.33225499, -1.17059489]), 'effectorPosition': array([ 0.53707772, -1.0986882 ])}
episode index:2859
target Thresh 1.9940847016016987
current state at start:  [-3.98037195  2.37018207]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.98037195,  2.37018207]), 'currentState': array([1.80281336, 2.87018207]), 'targetState': array([ 0.05951972, -0.11697804]), 'effectorPosition': array([-0.26932434, -0.0260196 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9298133944216957
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.98037195,  2.37018207]), 'currentState': array([1.90642384, 3.03063451]), 'targetState': array([ 0.05951972, -0.11697804]), 'effectorPosition': array([-0.10657768, -0.030664  ])}
episode index:2860
target Thresh 1.9940965203757817
current state at start:  [-3.25909245  2.3728485 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.25909245,  2.3728485 ]), 'currentState': array([2.52409286, 2.85443785]), 'targetState': array([-0.28318955,  0.2160431 ]), 'effectorPosition': array([-0.19737144, -0.20721327])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9298241538119711
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([-3.25909245,  2.3728485 ]), 'currentState': array([0.85236958, 2.85517865]), 'targetState': array([-0.28318955,  0.2160431 ]), 'effectorPosition': array([-0.18587551,  0.21661954])}
episode index:2861
target Thresh 1.994108315535938
current state at start:  [ 2.67897278 -2.80974677]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.67897278, -2.80974677]), 'currentState': array([2.82097633, 2.97343854]), 'targetState': array([ 0.00739895, -0.61675578]), 'effectorPosition': array([-0.06613051, -0.15438911])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.929845179614273
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 2.67897278, -2.80974677]), 'currentState': array([3.30101983, 2.47343854]), 'targetState': array([ 0.00739895, -0.61675578]), 'effectorPosition': array([-0.1139531 , -0.64581847])}
episode index:2862
target Thresh 1.994120087129349
current state at start:  [1.97901058 2.23542484]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.97901058, 2.23542484]), 'currentState': array([1.49469828, 2.53192821]), 'targetState': array([-0.50784965,  0.22188471]), 'effectorPosition': array([-0.5572387 ,  0.22316952])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9298696835683022
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.97901058, 2.23542484]), 'currentState': array([1.49469828, 2.53192821]), 'targetState': array([-0.50784965,  0.22188471]), 'effectorPosition': array([-0.5572387 ,  0.22316952])}
episode index:2863
target Thresh 1.9941318352031006
current state at start:  [-3.80982979  1.60242156]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.80982979,  1.60242156]), 'currentState': array([1.98622878, 2.10242156]), 'targetState': array([-0.50229773,  0.0292704 ]), 'effectorPosition': array([-0.98765953,  0.10324138])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9298906787905199
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.80982979,  1.60242156]), 'currentState': array([1.61653213, 2.54406953]), 'targetState': array([-0.50229773,  0.0292704 ]), 'effectorPosition': array([-0.56992999,  0.14736535])}
episode index:2864
target Thresh 1.994143559804185
current state at start:  [-1.3969708 -1.9358322]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.3969708, -1.9358322]), 'currentState': array([4.43318055, 4.0253098 ]), 'targetState': array([-0.14690682, -0.2193276 ]), 'effectorPosition': array([-0.84395275, -0.13849247])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.929908203859005
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.3969708, -1.9358322]), 'currentState': array([4.71679259, 3.16777551]), 'targetState': array([-0.14690682, -0.2193276 ]), 'effectorPosition': array([-0.02617811, -0.00045803])}
episode index:2865
target Thresh 1.994155260979501
current state at start:  [0.64363692 2.88412992]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.64363692, 2.88412992]), 'currentState': array([0.14363692, 3.35057614]), 'targetState': array([-0.26801855, -0.65765834]), 'effectorPosition': array([ 0.05123099, -0.20221465])}
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.9298899250101356
{'reset': False, 'endBeforeDone': False, 'stepCount': 14, 'initial state': array([0.64363692, 2.88412992]), 'currentState': array([2.89013208, 2.44882482]), 'targetState': array([-0.26801855, -0.65765834]), 'effectorPosition': array([-0.38218195, -0.56122588])}
episode index:2866
target Thresh 1.994166938775853
current state at start:  [-1.55989293  2.06843287]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.55989293,  2.06843287]), 'currentState': array([4.24752783, 2.55064273]), 'targetState': array([0.16334673, 0.02487376]), 'effectorPosition': array([ 0.4220013, -0.4013618])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9299108912030165
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.55989293,  2.06843287]), 'currentState': array([4.1528825 , 3.01787043]), 'targetState': array([0.16334673, 0.02487376]), 'effectorPosition': array([ 0.1005323 , -0.07197868])}
episode index:2867
target Thresh 1.9941785932399523
current state at start:  [ 1.70095417 -2.13143815]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.70095417, -2.13143815]), 'currentState': array([1.43755439, 3.65174716]), 'targetState': array([-0.04095411,  0.15967915]), 'effectorPosition': array([0.50089955, 0.06133102])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9299318427751213
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.70095417, -2.13143815]), 'currentState': array([1.70183689, 3.19561078]), 'targetState': array([-0.04095411,  0.15967915]), 'effectorPosition': array([0.05333837, 0.00850101])}
episode index:2868
target Thresh 1.9941902244184169
current state at start:  [-3.84734817  2.54351973]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.84734817,  2.54351973]), 'currentState': array([1.93583713, 2.85656991]), 'targetState': array([-0.62592032,  0.35016532]), 'effectorPosition': array([-0.27705471, -0.06269107])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9299527797417385
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.84734817,  2.54351973]), 'currentState': array([1.56465243, 2.44806486]), 'targetState': array([-0.62592032,  0.35016532]), 'effectorPosition': array([-0.63782269,  0.23492748])}
episode index:2869
target Thresh 1.9942018323577715
current state at start:  [-2.04289415  2.00697981]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.04289415,  2.00697981]), 'currentState': array([3.74029116, 2.50697981]), 'targetState': array([-0.02767159,  0.02300408]), 'effectorPosition': array([ 0.17328536, -0.59947444])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.929973702118135
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.04289415,  2.00697981]), 'currentState': array([3.24029116, 3.00697981]), 'targetState': array([-0.02767159,  0.02300408]), 'effectorPosition': array([ 0.00422189, -0.13444495])}
episode index:2870
target Thresh 1.9942134171044477
current state at start:  [-0.41276735  1.98723036]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.41276735,  1.98723036]), 'currentState': array([5.37041796, 2.48723036]), 'targetState': array([-0.00646411, -0.12102008]), 'effectorPosition': array([0.60789189, 0.20879411])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9299877478505914
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-0.41276735,  1.98723036]), 'currentState': array([4.02313528, 3.04449564]), 'targetState': array([-0.00646411, -0.12102008]), 'effectorPosition': array([ 0.07181859, -0.06528794])}
episode index:2871
target Thresh 1.9942249787047845
current state at start:  [1.21910745 1.94200875]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.21910745, 1.94200875]), 'currentState': array([0.72455421, 2.44200875]), 'targetState': array([-0.00790371,  0.30808948]), 'effectorPosition': array([-0.25089329,  0.63783399])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9300086434815625
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.21910745, 1.94200875]), 'currentState': array([0.25545782, 2.9339494 ]), 'targetState': array([-0.00790371,  0.30808948]), 'effectorPosition': array([-0.03130939,  0.20489205])}
episode index:2872
target Thresh 1.9942365172050285
current state at start:  [ 1.62728374 -2.47509242]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.62728374, -2.47509242]), 'currentState': array([1.12728374, 3.30809288]), 'targetState': array([ 0.28060535, -0.6683781 ]), 'effectorPosition': array([ 0.15563172, -0.05862686])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.930026078690932
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 1.62728374, -2.47509242]), 'currentState': array([0.23054336, 3.95413167]), 'targetState': array([ 0.28060535, -0.6683781 ]), 'effectorPosition': array([ 0.46998278, -0.63545395])}
episode index:2873
target Thresh 1.9942480326513337
current state at start:  [-0.92409844  2.94048785]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.92409844,  2.94048785]), 'currentState': array([4.91116917, 3.23362936]), 'targetState': array([ 0.16256277, -0.2552076 ]), 'effectorPosition': array([-0.08926123, -0.02229823])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9300400915375949
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-0.92409844,  2.94048785]), 'currentState': array([4.12933686, 2.88578041]), 'targetState': array([ 0.16256277, -0.2552076 ]), 'effectorPosition': array([ 0.19331028, -0.16647808])}
episode index:2874
target Thresh 1.994259525089762
current state at start:  [0.92810891 1.70432367]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.92810891, 1.70432367]), 'currentState': array([1.42810891, 1.85610988]), 'targetState': array([-0.96300698,  0.89955077]), 'effectorPosition': array([-0.84764239,  0.84769434])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9300644254187992
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.92810891, 1.70432367]), 'currentState': array([1.42810891, 1.85610988]), 'targetState': array([-0.96300698,  0.89955077]), 'effectorPosition': array([-0.84764239,  0.84769434])}
episode index:2875
target Thresh 1.9942709945662827
current state at start:  [0.56294252 2.81779719]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.56294252, 2.81779719]), 'currentState': array([0.10192495, 2.3557418 ]), 'targetState': array([0.28490881, 0.77673673]), 'effectorPosition': array([0.219712  , 0.73358941])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9300887423779721
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.56294252, 2.81779719]), 'currentState': array([0.10192495, 2.3557418 ]), 'targetState': array([0.28490881, 0.77673673]), 'effectorPosition': array([0.219712  , 0.73358941])}
episode index:2876
target Thresh 1.994282441126774
current state at start:  [ 0.61169017 -2.89101343]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.61169017, -2.89101343]), 'currentState': array([0.89396028, 2.98779245]), 'targetState': array([0.05587837, 0.08970307]), 'effectorPosition': array([-0.11203093,  0.10515218])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.930113042432759
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.61169017, -2.89101343]), 'currentState': array([0.89396028, 2.98779245]), 'targetState': array([0.05587837, 0.08970307]), 'effectorPosition': array([-0.11203093,  0.10515218])}
episode index:2877
target Thresh 1.9942938648170223
current state at start:  [ 0.54278879 -2.21986931]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.54278879, -2.21986931]), 'currentState': array([0.75442697, 3.60063875]), 'targetState': array([-0.06622432, -0.13806809]), 'effectorPosition': array([ 0.3788963 , -0.25196518])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9301338509656176
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.54278879, -2.21986931]), 'currentState': array([1.06297473, 3.1385313 ]), 'targetState': array([-0.06622432, -0.13806809]), 'effectorPosition': array([-0.00267274,  0.00149275])}
episode index:2878
target Thresh 1.9943052656827223
current state at start:  [1.26445651 2.26155796]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.26445651, 2.26155796]), 'currentState': array([0.96120882, 2.76155796]), 'targetState': array([-0.22342776, -0.1257905 ]), 'effectorPosition': array([-0.26328931,  0.27087858])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9301478020420451
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([1.26445651, 2.26155796]), 'currentState': array([1.04495701, 2.95605484]), 'targetState': array([-0.22342776, -0.1257905 ]), 'effectorPosition': array([-0.15093841,  0.10743947])}
episode index:2879
target Thresh 1.9943166437694775
current state at start:  [ 2.38461862 -2.34617274]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.38461862, -2.34617274]), 'currentState': array([2.6896366 , 4.41825036]), 'targetState': array([0.0944628 , 1.10749557]), 'effectorPosition': array([-0.22081848,  1.17107133])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9298248340552249
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([ 2.38461862, -2.34617274]), 'currentState': array([2.79763621, 4.44137723]), 'targetState': array([0.0944628 , 1.10749557]), 'effectorPosition': array([-0.36449532,  1.15400623])}
episode index:2880
target Thresh 1.9943279991228
current state at start:  [-4.07171225  2.6566011 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.07171225,  2.6566011 ]), 'currentState': array([1.79921786, 3.06677583]), 'targetState': array([-0.00955959,  0.00166606]), 'effectorPosition': array([-0.07343895, -0.01420094])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9298491919746781
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.07171225,  2.6566011 ]), 'currentState': array([1.79921786, 3.06677583]), 'targetState': array([-0.00955959,  0.00166606]), 'effectorPosition': array([-0.07343895, -0.01420094])}
episode index:2881
target Thresh 1.9943393317881115
current state at start:  [-0.56262646 -2.24514836]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.56262646, -2.24514836]), 'currentState': array([5.22055885, 4.49234015]), 'targetState': array([ 0.10196634, -1.38084209]), 'effectorPosition': array([-0.47220029, -1.15778769])}
done in step count: 20
reward sum = 0.8179069375972308
running average episode reward sum: 0.9298103501098699
{'reset': False, 'endBeforeDone': False, 'stepCount': 21, 'initial state': array([-0.56262646, -2.24514836]), 'currentState': array([3.76123851, 1.91768868]), 'targetState': array([ 0.10196634, -1.38084209]), 'effectorPosition': array([ 0.00883965, -1.14889862])}
episode index:2882
target Thresh 1.9943506418107426
current state at start:  [-3.81069784  2.74816524]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.81069784,  2.74816524]), 'currentState': array([2.21174275, 2.24816524]), 'targetState': array([-0.93035322, -0.38512734]), 'effectorPosition': array([-0.84776136, -0.16676543])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9298346961556174
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.81069784,  2.74816524]), 'currentState': array([2.21174275, 2.24816524]), 'targetState': array([-0.93035322, -0.38512734]), 'effectorPosition': array([-0.84776136, -0.16676543])}
episode index:2883
target Thresh 1.9943619292359336
current state at start:  [-1.63889942 -2.322793  ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.63889942, -2.322793  ]), 'currentState': array([4.25739845, 4.00026842]), 'targetState': array([ 0.2252758 , -0.41245197]), 'effectorPosition': array([-0.83226382,  0.02135445])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.9298387341075055
{'reset': False, 'endBeforeDone': False, 'stepCount': 7, 'initial state': array([-1.63889942, -2.322793  ]), 'currentState': array([3.94909413, 2.81858777]), 'targetState': array([ 0.2252758 , -0.41245197]), 'effectorPosition': array([ 0.1936036 , -0.25679924])}
episode index:2884
target Thresh 1.9943731941088338
current state at start:  [-0.27989929 -1.73469333]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.27989929, -1.73469333]), 'currentState': array([5.55127983, 4.09860739]), 'targetState': array([-0.46507971, -0.62789475]), 'effectorPosition': array([-0.23086738, -0.8915012 ])}
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.9298205997189064
{'reset': False, 'endBeforeDone': False, 'stepCount': 14, 'initial state': array([-0.27989929, -1.73469333]), 'currentState': array([2.92296221, 2.30637231]), 'targetState': array([-0.46507971, -0.62789475]), 'effectorPosition': array([-0.48196831, -0.65243996])}
episode index:2885
target Thresh 1.994384436474503
current state at start:  [-1.31516342  3.06619645]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.31516342,  3.06619645]), 'currentState': array([4.47180165, 3.20442088]), 'targetState': array([ 0.53263405, -0.86625822]), 'effectorPosition': array([-0.06144864,  0.01304421])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9298380215485257
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.31516342,  3.06619645]), 'currentState': array([4.38818879, 2.20442088]), 'targetState': array([ 0.53263405, -0.86625822]), 'effectorPosition': array([ 0.63395828, -0.64339542])}
episode index:2886
target Thresh 1.9943956563779106
current state at start:  [ 2.75670719 -2.60347418]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.75670719, -2.60347418]), 'currentState': array([2.99694613, 3.17971113]), 'targetState': array([0.07323585, 0.29073548]), 'effectorPosition': array([0.00477433, 0.03781598])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9298588604742103
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 2.75670719, -2.60347418]), 'currentState': array([3.00811391, 3.32128417]), 'targetState': array([0.07323585, 0.29073548]), 'effectorPosition': array([0.00782745, 0.17927907])}
episode index:2887
target Thresh 1.9944068538639363
current state at start:  [ 1.86825147 -2.78742228]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.86825147, -2.78742228]), 'currentState': array([1.65264892, 2.99576302]), 'targetState': array([ 0.37996308, -0.0848723 ]), 'effectorPosition': array([-0.14569462, -0.00130222])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9298796849685058
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.86825147, -2.78742228]), 'currentState': array([1.25476163, 3.33703806]), 'targetState': array([ 0.37996308, -0.0848723 ]), 'effectorPosition': array([ 0.19050285, -0.04226261])}
episode index:2888
target Thresh 1.9944180289773699
current state at start:  [-1.79333236 -1.64046779]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.79333236, -1.64046779]), 'currentState': array([4.0418898, 4.2453473]), 'targetState': array([-0.32947   , -0.37311885]), 'effectorPosition': array([-1.04120488,  0.12409224])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.9298804415150405
{'reset': False, 'endBeforeDone': False, 'stepCount': 8, 'initial state': array([-1.79333236, -1.64046779]), 'currentState': array([2.72779021, 2.71493204]), 'targetState': array([-0.32947   , -0.37311885]), 'effectorPosition': array([-0.24848057, -0.34285838])}
episode index:2889
target Thresh 1.994429181762912
current state at start:  [-2.47127677  2.87198765]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.47127677,  2.87198765]), 'currentState': array([3.8425144 , 3.25986234]), 'targetState': array([0.03179499, 0.06772524]), 'effectorPosition': array([-0.08143589,  0.08567157])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9299047043380456
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.47127677,  2.87198765]), 'currentState': array([3.8425144 , 3.25986234]), 'targetState': array([0.03179499, 0.06772524]), 'effectorPosition': array([-0.08143589,  0.08567157])}
episode index:2890
target Thresh 1.9944403122651737
current state at start:  [-3.94064609  2.26193391]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.94064609,  2.26193391]), 'currentState': array([1.91096148, 2.50119513]), 'targetState': array([-0.64639587,  0.01735299]), 'effectorPosition': array([-0.62938498, -0.01256822])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9299289503759779
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.94064609,  2.26193391]), 'currentState': array([1.91096148, 2.50119513]), 'targetState': array([-0.64639587,  0.01735299]), 'effectorPosition': array([-0.62938498, -0.01256822])}
episode index:2891
target Thresh 1.9944514205286772
current state at start:  [-0.02717972 -1.67577355]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.02717972, -1.67577355]), 'currentState': array([0.47282028, 4.10741175]), 'targetState': array([ 0.94591173, -0.03296602]), 'effectorPosition': array([ 0.75851489, -0.53588102])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.929939554476816
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([-0.02717972, -1.67577355]), 'currentState': array([0.90659666, 4.06736694]), 'targetState': array([ 0.94591173, -0.03296602]), 'effectorPosition': array([ 0.87503107, -0.17857359])}
episode index:2892
target Thresh 1.9944625065978554
current state at start:  [-0.19889344  1.62603859]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.19889344,  1.62603859]), 'currentState': array([0.30110656, 1.42586778]), 'targetState': array([0.48570412, 1.04354433]), 'effectorPosition': array([0.79946502, 1.28440614])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9299501512467859
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([-0.19889344,  1.62603859]), 'currentState': array([0.41516167, 1.7563193 ]), 'targetState': array([0.48570412, 1.04354433]), 'effectorPosition': array([0.34984373, 1.22828672])}
episode index:2893
target Thresh 1.9944735705170524
current state at start:  [2.07618649 1.85110115]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.07618649, 1.85110115]), 'currentState': array([2.31667467, 1.8702253 ]), 'targetState': array([-0.84674617, -0.06201096]), 'effectorPosition': array([-1.1802533 , -0.13058661])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.9299574214260027
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([2.07618649, 1.85110115]), 'currentState': array([1.93820347, 2.1870448 ]), 'targetState': array([-0.84674617, -0.06201096]), 'effectorPosition': array([-0.91317968,  0.10073375])}
episode index:2894
target Thresh 1.9944846123305242
current state at start:  [-1.05185755 -2.79162065]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.05185755, -2.79162065]), 'currentState': array([4.79650121, 3.03946491]), 'targetState': array([0.4895327 , 0.21750987]), 'effectorPosition': array([0.10202762, 0.00337307])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9299781615222285
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.05185755, -2.79162065]), 'currentState': array([5.15801074, 2.53946491]), 'targetState': array([0.4895327 , 0.21750987]), 'effectorPosition': array([0.58688685, 0.08543507])}
episode index:2895
target Thresh 1.994495632082438
current state at start:  [ 2.48305559 -1.98464971]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.48305559, -1.98464971]), 'currentState': array([2.32590297, 3.80273638]), 'targetState': array([0.01055548, 0.20367247]), 'effectorPosition': array([0.3027152 , 0.57426697])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9299988872951834
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 2.48305559, -1.98464971]), 'currentState': array([2.12242573, 3.30803806]), 'targetState': array([0.01055548, 0.20367247]), 'effectorPosition': array([0.13386044, 0.09859795])}
episode index:2896
target Thresh 1.9945066298168728
current state at start:  [-0.35090352  1.97990295]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.35090352,  1.97990295]), 'currentState': array([5.43228179, 2.47990295]), 'targetState': array([ 0.02563699, -0.01738017]), 'effectorPosition': array([0.60113383, 0.24643027])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9300195987597001
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.35090352,  1.97990295]), 'currentState': array([4.99319425, 2.92550856]), 'targetState': array([ 0.02563699, -0.01738017]), 'effectorPosition': array([0.21245347, 0.03707373])}
episode index:2897
target Thresh 1.9945176055778195
current state at start:  [-0.76491031  1.98250019]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.76491031,  1.98250019]), 'currentState': array([6.018275  , 2.10868367]), 'targetState': array([0.59906475, 0.8295212 ]), 'effectorPosition': array([0.69551655, 0.70114985])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.930043746586215
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.76491031,  1.98250019]), 'currentState': array([6.018275  , 2.10868367]), 'targetState': array([0.59906475, 0.8295212 ]), 'effectorPosition': array([0.69551655, 0.70114985])}
episode index:2898
target Thresh 1.9945285594091813
current state at start:  [ 0.03310453 -2.22841384]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.03310453, -2.22841384]), 'currentState': array([5.81628983, 4.30782093]), 'targetState': array([-0.47413913, -1.07835043]), 'effectorPosition': array([ 0.12769815, -1.09382345])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9300644282879789
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.03310453, -2.22841384]), 'currentState': array([5.32620307, 4.55323954]), 'targetState': array([-0.47413913, -1.07835043]), 'effectorPosition': array([-0.32241886, -1.25661815])}
episode index:2899
target Thresh 1.9945394913547734
current state at start:  [-3.99739671  2.33862795]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.99739671,  2.33862795]), 'currentState': array([1.78578859, 2.47060965]), 'targetState': array([-0.66014134,  0.2702178 ]), 'effectorPosition': array([-0.65369191,  0.07915285])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9300885440023624
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.99739671,  2.33862795]), 'currentState': array([1.78578859, 2.47060965]), 'targetState': array([-0.66014134,  0.2702178 ]), 'effectorPosition': array([-0.65369191,  0.07915285])}
episode index:2900
target Thresh 1.9945504014583235
current state at start:  [-1.574195   -2.83652873]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.574195  , -2.83652873]), 'currentState': array([4.65775351, 3.65787905]), 'targetState': array([ 0.15484046, -0.69356667]), 'effectorPosition': array([-0.50003511, -0.1031895 ])}
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.9300704235194244
{'reset': False, 'endBeforeDone': False, 'stepCount': 14, 'initial state': array([-1.574195  , -2.83652873]), 'currentState': array([3.3482465, 2.5753483]), 'targetState': array([ 0.15484046, -0.69356667]), 'effectorPosition': array([-0.04268198, -0.55707705])}
episode index:2901
target Thresh 1.9945612897634724
current state at start:  [-1.51752354 -1.58846604]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.51752354, -1.58846604]), 'currentState': array([4.28297367, 5.11188377]), 'targetState': array([-1.04528331, -0.67638062]), 'effectorPosition': array([-1.41589168, -0.87929328])}
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.930058455163373
{'reset': False, 'endBeforeDone': False, 'stepCount': 12, 'initial state': array([-1.51752354, -1.58846604]), 'currentState': array([2.95348897, 1.70813503]), 'targetState': array([-1.04528331, -0.67638062]), 'effectorPosition': array([-1.03310378, -0.81171537])}
episode index:2902
target Thresh 1.9945721563137728
current state at start:  [-2.92230539  1.65256994]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.92230539,  1.65256994]), 'currentState': array([3.84137293, 1.94651126]), 'targetState': array([ 0.01139624, -1.36155654]), 'effectorPosition': array([ 0.11484191, -1.11934623])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9300689744726519
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([-2.92230539,  1.65256994]), 'currentState': array([4.01671084, 1.76177625]), 'targetState': array([ 0.01139624, -1.36155654]), 'effectorPosition': array([ 0.23441429, -1.25116256])}
episode index:2903
target Thresh 1.9945830011526915
current state at start:  [ 3.89098708 -2.44287766]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.89098708, -2.44287766]), 'currentState': array([3.87785101, 3.51922696]), 'targetState': array([-0.73163145,  0.15472815]), 'effectorPosition': array([-0.29981482,  0.2259027 ])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9300794865372274
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([ 3.89098708, -2.44287766]), 'currentState': array([2.05893108, 2.40881568]), 'targetState': array([-0.73163145,  0.15472815]), 'effectorPosition': array([-0.71118852, -0.08701489])}
episode index:2904
target Thresh 1.9945938243236074
current state at start:  [-1.72362683 -1.9853464 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.72362683, -1.9853464 ]), 'currentState': array([4.20038983, 3.80022628]), 'targetState': array([-0.0232943 ,  0.07967308]), 'effectorPosition': array([-0.63603058,  0.11750159])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9301001132200027
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.72362683, -1.9853464 ]), 'currentState': array([4.63052421, 3.32501603]), 'targetState': array([-0.0232943 ,  0.07967308]), 'effectorPosition': array([-0.18315748, -0.0018036 ])}
episode index:2905
target Thresh 1.9946046258698136
current state at start:  [ 3.03422865 -2.16638492]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.03422865, -2.16638492]), 'currentState': array([3.47552782, 3.65023502]), 'targetState': array([-0.12506112,  0.21879789]), 'effectorPosition': array([-0.27921859,  0.41859771])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9301207257068506
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.03422865, -2.16638492]), 'currentState': array([3.94245666, 3.17613943]), 'targetState': array([-0.12506112,  0.21879789]), 'effectorPosition': array([-0.02521354,  0.02361438])}
episode index:2906
target Thresh 1.9946154058345158
current state at start:  [-2.55660782  2.48473433]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.55660782,  2.48473433]), 'currentState': array([3.3654249 , 1.98473433]), 'targetState': array([-0.17290962, -1.273519  ]), 'effectorPosition': array([-0.37964849, -1.02539325])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9301413240124209
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.55660782,  2.48473433]), 'currentState': array([3.8654249, 1.7265653]), 'targetState': array([-0.17290962, -1.273519  ]), 'effectorPosition': array([ 0.02121145, -1.29971937])}
episode index:2907
target Thresh 1.9946261642608343
current state at start:  [-2.61975958  2.48348066]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.61975958,  2.48348066]), 'currentState': array([3.2529669 , 2.98285475]), 'targetState': array([-0.13618435, -0.16438608]), 'effectorPosition': array([ 0.00507425, -0.15849008])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9301653469408898
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.61975958,  2.48348066]), 'currentState': array([3.2529669 , 2.98285475]), 'targetState': array([-0.13618435, -0.16438608]), 'effectorPosition': array([ 0.00507425, -0.15849008])}
episode index:2908
target Thresh 1.9946369011918028
current state at start:  [1.48656996 2.66722248]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.48656996, 2.66722248]), 'currentState': array([1.06691836, 2.38506545]), 'targetState': array([0.00978279, 0.80526092]), 'effectorPosition': array([-0.46938901,  0.57028565])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9301791433152656
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([1.48656996, 2.66722248]), 'currentState': array([0.43088556, 2.46419766]), 'targetState': array([0.00978279, 0.80526092]), 'effectorPosition': array([-0.06117387,  0.66169599])}
episode index:2909
target Thresh 1.9946476166703688
current state at start:  [-0.33572164 -1.71760489]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.33572164, -1.71760489]), 'currentState': array([5.47331459, 4.06922697]), 'targetState': array([-0.50907482, -0.44019675]), 'effectorPosition': array([-0.30348181, -0.84168962])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9301997003106899
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.33572164, -1.71760489]), 'currentState': array([4.97407923, 4.02049588]), 'targetState': array([-0.50907482, -0.44019675]), 'effectorPosition': array([-0.65016755, -0.54889889])}
episode index:2910
target Thresh 1.9946583107393943
current state at start:  [-2.36263083  2.28538627]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.36263083,  2.28538627]), 'currentState': array([3.43094393, 2.74641539]), 'targetState': array([ 0.09125402, -0.10366374]), 'effectorPosition': array([ 0.03597648, -0.3909591 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9302202431824483
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.36263083,  2.28538627]), 'currentState': array([3.57179638, 3.09258292]), 'targetState': array([ 0.09125402, -0.10366374]), 'effectorPosition': array([ 0.01934029, -0.04502695])}
episode index:2911
target Thresh 1.9946689834416558
current state at start:  [-0.015595   -2.66139733]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.015595  , -2.66139733]), 'currentState': array([5.82351142, 3.54094017]), 'targetState': array([-0.09178896, -0.26639461]), 'effectorPosition': array([-0.10198369, -0.38336608])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9302442060110259
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.015595  , -2.66139733]), 'currentState': array([5.82351142, 3.54094017]), 'targetState': array([-0.09178896, -0.26639461]), 'effectorPosition': array([-0.10198369, -0.38336608])}
episode index:2912
target Thresh 1.9946796348198437
current state at start:  [-1.89565793  2.16977678]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.89565793,  2.16977678]), 'currentState': array([3.92294369, 2.66164444]), 'targetState': array([-0.15532352,  0.20585336]), 'effectorPosition': array([ 0.24495825, -0.40737916])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9302613209420211
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.89565793,  2.16977678]), 'currentState': array([3.147952 , 3.2253909]), 'targetState': array([-0.15532352,  0.20585336]), 'effectorPosition': array([-0.00404122,  0.0836762 ])}
episode index:2913
target Thresh 1.9946902649165639
current state at start:  [ 3.71132035 -2.27339838]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.71132035, -2.27339838]), 'currentState': array([4.19019467, 3.50978693]), 'targetState': array([-0.10489854,  0.24281722]), 'effectorPosition': array([-0.34539116,  0.12143863])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9302784241263238
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 3.71132035, -2.27339838]), 'currentState': array([4.32708628, 3.20579853]), 'targetState': array([-0.10489854,  0.24281722]), 'effectorPosition': array([-0.06023215,  0.02220512])}
episode index:2914
target Thresh 1.9947008737743368
current state at start:  [-1.67841467  2.07904814]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.67841467,  2.07904814]), 'currentState': array([4.1387505, 2.3288972]), 'targetState': array([-0.01454789, -0.7731287 ]), 'effectorPosition': array([ 0.44034329, -0.65651389])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9302989118024382
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.67841467,  2.07904814]), 'currentState': array([3.72415121, 2.2426187 ]), 'targetState': array([-0.01454789, -0.7731287 ]), 'effectorPosition': array([ 0.11529914, -0.8613242 ])}
episode index:2915
target Thresh 1.9947114614355976
current state at start:  [-1.15515127  2.52082833]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.15515127,  2.52082833]), 'currentState': array([4.7155127 , 2.22998022]), 'targetState': array([ 0.08260691, -0.47706437]), 'effectorPosition': array([ 0.79169901, -0.3850569 ])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9303126292538092
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-1.15515127,  2.52082833]), 'currentState': array([3.49907426, 2.84256331]), 'targetState': array([ 0.08260691, -0.47706437]), 'effectorPosition': array([ 0.06151113, -0.29149718])}
episode index:2916
target Thresh 1.9947220279426972
current state at start:  [-1.57806    -2.20309115]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.57806   , -2.20309115]), 'currentState': array([4.29606227, 4.42465743]), 'targetState': array([-0.80487041, -0.57459691]), 'effectorPosition': array([-1.16662516, -0.26726429])}
done in step count: 14
reward sum = 0.8687458127689782
running average episode reward sum: 0.9302915230431527
{'reset': False, 'endBeforeDone': False, 'stepCount': 15, 'initial state': array([-1.57806   , -2.20309115]), 'currentState': array([2.58334957, 2.26390849]), 'targetState': array([-0.80487041, -0.57459691]), 'effectorPosition': array([-0.71372647, -0.46122212])}
episode index:2917
target Thresh 1.9947325733379013
current state at start:  [-0.16400523  2.37083175]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.16400523,  2.37083175]), 'currentState': array([5.64028351, 2.87083175]), 'targetState': array([ 1.16395718, -0.23605351]), 'effectorPosition': array([0.18950952, 0.19222597])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.9302986164382373
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([-0.16400523,  2.37083175]), 'currentState': array([4.90889481, 2.07553532]), 'targetState': array([ 1.16395718, -0.23605351]), 'effectorPosition': array([ 0.95928326, -0.3355855 ])}
episode index:2918
target Thresh 1.994743097663392
current state at start:  [-1.97688223 -1.97062169]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.97688223, -1.97062169]), 'currentState': array([4.33919365, 3.87657868]), 'targetState': array([-0.14531545, -0.1586858 ]), 'effectorPosition': array([-0.71854225,  0.0040974 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9303190691218829
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.97688223, -1.97062169]), 'currentState': array([4.71418945, 3.37697866]), 'targetState': array([-0.14531545, -0.1586858 ]), 'effectorPosition': array([-0.23316834, -0.02799547])}
episode index:2919
target Thresh 1.9947536009612663
current state at start:  [ 2.17054215 -2.42958527]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.17054215, -2.42958527]), 'currentState': array([2.0026418 , 3.35360004]), 'targetState': array([-0.30202535,  0.56023274]), 'effectorPosition': array([0.1817338 , 0.10840598])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9303327608790329
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 2.17054215, -2.42958527]), 'currentState': array([0.91579724, 2.52919328]), 'targetState': array([-0.30202535,  0.56023274]), 'effectorPosition': array([-0.34516832,  0.49428388])}
episode index:2920
target Thresh 1.9947640832735374
current state at start:  [-0.02981119  1.79279893]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.02981119,  1.79279893]), 'currentState': array([0.42603071, 2.07618244]), 'targetState': array([0.20110837, 0.75491377]), 'effectorPosition': array([0.10814711, 1.0099572 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9303531878694885
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.02981119,  1.79279893]), 'currentState': array([0.1456461 , 2.36226853]), 'targetState': array([0.20110837, 0.75491377]), 'effectorPosition': array([0.18355718, 0.73724443])}
episode index:2921
target Thresh 1.9947745446421346
current state at start:  [-1.9210009   1.76967494]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.9210009 ,  1.76967494]), 'currentState': array([4.65202114, 2.2364382 ]), 'targetState': array([ 1.0270902 , -0.13351477]), 'effectorPosition': array([ 0.76201503, -0.42919097])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9303736008784311
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.9210009 ,  1.76967494]), 'currentState': array([5.07452491, 2.29237081]), 'targetState': array([ 1.0270902 , -0.13351477]), 'effectorPosition': array([ 0.82232514, -0.0514417 ])}
episode index:2922
target Thresh 1.9947849851089035
current state at start:  [ 0.56345318 -2.55116828]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.56345318, -2.55116828]), 'currentState': array([1.00152479, 3.23201703]), 'targetState': array([-0.1725324 ,  0.52393547]), 'effectorPosition': array([ 0.0782623 , -0.04523284])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.930387259927053
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 0.56345318, -2.55116828]), 'currentState': array([0.44745071, 2.70996242]), 'targetState': array([-0.1725324 ,  0.52393547]), 'effectorPosition': array([-0.09832183,  0.41684881])}
episode index:2923
target Thresh 1.9947954047156056
current state at start:  [-1.88743367 -2.34416262]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.88743367, -2.34416262]), 'currentState': array([3.89575164, 3.82950374]), 'targetState': array([-0.49606764,  0.90694667]), 'effectorPosition': array([-0.60047659,  0.30705027])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.930404261548145
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.88743367, -2.34416262]), 'currentState': array([3.06634442, 4.2349596 ]), 'targetState': array([-0.49606764,  0.90694667]), 'effectorPosition': array([-0.47220211,  0.92629915])}
episode index:2924
target Thresh 1.9948058035039198
current state at start:  [-2.06204458 -2.02786181]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.06204458, -2.02786181]), 'currentState': array([4.20596813, 3.7553235 ]), 'targetState': array([-0.0744015, -0.0340515]), 'effectorPosition': array([-0.5921546 ,  0.11976163])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9304246361595815
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.06204458, -2.02786181]), 'currentState': array([4.65543493, 3.2553235 ]), 'targetState': array([-0.0744015, -0.0340515]), 'effectorPosition': array([-1.13669561e-01,  1.00743635e-05])}
episode index:2925
target Thresh 1.9948161815154413
current state at start:  [ 0.9498871  -2.19944817]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.9498871 , -2.19944817]), 'currentState': array([1.44134912, 3.58373714]), 'targetState': array([2.30561963e-04, 3.25688580e-01]), 'effectorPosition': array([0.43671223, 0.04012613])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9304349476338947
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([ 0.9498871 , -2.19944817]), 'currentState': array([0.79460005, 2.94194437]), 'targetState': array([2.30561963e-04, 3.25688580e-01]), 'effectorPosition': array([-0.12760531,  0.15311466])}
episode index:2926
target Thresh 1.9948265387916817
current state at start:  [-1.2784984   2.82070665]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.2784984 ,  2.82070665]), 'currentState': array([5.08666222, 2.32070665]), 'targetState': array([ 0.68246471, -0.05767221]), 'effectorPosition': array([ 0.79750919, -0.0288583 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9304587143070638
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.2784984 ,  2.82070665]), 'currentState': array([5.08666222, 2.32070665]), 'targetState': array([ 0.68246471, -0.05767221]), 'effectorPosition': array([ 0.79750919, -0.0288583 ])}
episode index:2927
target Thresh 1.9948368753740704
current state at start:  [ 4.10778268 -2.3672956 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.10778268, -2.3672956 ]), 'currentState': array([4.51080375, 3.4158897 ]), 'targetState': array([0.0644716 , 0.12821239]), 'effectorPosition': array([-0.27287048,  0.01760725])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9304790494456201
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 4.10778268, -2.3672956 ]), 'currentState': array([4.84171181, 2.9158897 ]), 'targetState': array([0.0644716 , 0.12821239]), 'effectorPosition': array([0.22519363, 0.00370958])}
episode index:2928
target Thresh 1.9948471913039536
current state at start:  [-0.98596415 -2.68925431]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.98596415, -2.68925431]), 'currentState': array([4.79722116, 4.01763002]), 'targetState': array([-0.75443544, -1.13121138]), 'effectorPosition': array([-0.7349595 , -0.42359646])}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.9304732584582652
{'reset': False, 'endBeforeDone': False, 'stepCount': 10, 'initial state': array([-0.98596415, -2.68925431]), 'currentState': array([3.3060028 , 1.78625933]), 'targetState': array([-0.75443544, -1.13121138]), 'effectorPosition': array([-0.61571241, -1.09238214])}
episode index:2929
target Thresh 1.9948574866225954
current state at start:  [ 2.37360769 -2.13000741]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.37360769, -2.13000741]), 'currentState': array([2.87360769, 4.6531779 ]), 'targetState': array([0.0764492 , 1.37552226]), 'effectorPosition': array([-0.64291732,  1.21173609])}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9304706207231013
{'reset': False, 'endBeforeDone': False, 'stepCount': 9, 'initial state': array([ 2.37360769, -2.13000741]), 'currentState': array([0.69873649, 1.70465252]), 'targetState': array([0.0764492 , 1.37552226]), 'effectorPosition': array([0.02597693, 1.31621106])}
episode index:2930
target Thresh 1.9948677613711767
current state at start:  [-1.73941139  2.18297519]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.73941139,  2.18297519]), 'currentState': array([4.04377392, 2.68297519]), 'targetState': array([0.00932263, 0.00103478]), 'effectorPosition': array([ 0.28332811, -0.35551984])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9304909309855635
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.73941139,  2.18297519]), 'currentState': array([3.63023576, 3.12598796]), 'targetState': array([0.00932263, 0.00103478]), 'effectorPosition': array([ 0.00721748, -0.01383508])}
episode index:2931
target Thresh 1.9948780155907966
current state at start:  [-1.28231044 -1.61407345]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.28231044, -1.61407345]), 'currentState': array([4.50087486, 5.10115806]), 'targetState': array([-1.03249607, -0.56395989]), 'effectorPosition': array([-1.19427194, -1.15404238])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.9304914679626854
{'reset': False, 'endBeforeDone': False, 'stepCount': 8, 'initial state': array([-1.28231044, -1.61407345]), 'currentState': array([2.92520724, 1.59306434]), 'targetState': array([-1.03249607, -0.56395989]), 'effectorPosition': array([-1.16958047, -0.76651757])}
episode index:2932
target Thresh 1.994888249322472
current state at start:  [-2.29769946  1.59965837]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.29769946,  1.59965837]), 'currentState': array([3.48548584, 2.08726916]), 'targetState': array([-0.26291412, -0.44620936]), 'effectorPosition': array([-0.18336788, -0.98931492])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9305117572678464
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.29769946,  1.59965837]), 'currentState': array([2.98548584, 2.5467009 ]), 'targetState': array([-0.26291412, -0.44620936]), 'effectorPosition': array([-0.25683221, -0.52689552])}
episode index:2933
target Thresh 1.994898462607138
current state at start:  [0.98017537 2.01518831]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.98017537, 2.01518831]), 'currentState': array([0.48017537, 2.45899019]), 'targetState': array([-0.1527862 ,  0.02444833]), 'effectorPosition': array([-0.09266758,  0.66298218])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9305286585094048
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([0.98017537, 2.01518831]), 'currentState': array([5.76336068, 3.31347985]), 'targetState': array([-0.1527862 ,  0.02444833]), 'effectorPosition': array([-0.07217166, -0.15576838])}
episode index:2934
target Thresh 1.9949086554856477
current state at start:  [ 0.397549   -2.53309665]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.397549  , -2.53309665]), 'currentState': array([6.18073431, 4.12896695]), 'targetState': array([-0.27253952, -1.20715383]), 'effectorPosition': array([ 0.36140762, -0.87613828])}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9305197499630673
{'reset': False, 'endBeforeDone': False, 'stepCount': 11, 'initial state': array([ 0.397549  , -2.53309665]), 'currentState': array([3.50135565, 1.74430864]), 'targetState': array([-0.27253952, -1.20715383]), 'effectorPosition': array([-0.4276237 , -1.21319908])}
episode index:2935
target Thresh 1.9949188279987724
current state at start:  [-3.93542362  1.95016507]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.93542362,  1.95016507]), 'currentState': array([2.84776168, 2.42112253]), 'targetState': array([-0.16764886, -0.8820009 ]), 'effectorPosition': array([-0.42892786, -0.55949047])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9305400089038155
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.93542362,  1.95016507]), 'currentState': array([3.34776168, 2.0240605 ]), 'targetState': array([-0.16764886, -0.8820009 ]), 'effectorPosition': array([-0.36615335, -0.99505119])}
episode index:2936
target Thresh 1.9949289801872023
current state at start:  [ 1.34098768 -1.72027253]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.34098768, -1.72027253]), 'currentState': array([0.91159358, 4.06291278]), 'targetState': array([ 0.36051479, -0.34760341]), 'effectorPosition': array([ 0.87161302, -0.17536269])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9305602540488942
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.34098768, -1.72027253]), 'currentState': array([0.81169478, 3.56291278]), 'targetState': array([ 0.36051479, -0.34760341]), 'effectorPosition': array([ 0.35687524, -0.21803753])}
episode index:2937
target Thresh 1.9949391120915463
current state at start:  [-1.56484379 -2.05720832]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.56484379, -2.05720832]), 'currentState': array([4.25216531, 4.62760057]), 'targetState': array([-1.16939922, -0.56754188]), 'effectorPosition': array([-1.29926954, -0.37752475])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9305838890883602
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.56484379, -2.05720832]), 'currentState': array([4.25216531, 4.62760057]), 'targetState': array([-1.16939922, -0.56754188]), 'effectorPosition': array([-1.29926954, -0.37752475])}
episode index:2938
target Thresh 1.9949492237523319
current state at start:  [-0.41026853  1.60485876]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.41026853,  1.60485876]), 'currentState': array([6.20186888, 1.85083242]), 'targetState': array([0.59562767, 0.51268668]), 'effectorPosition': array([0.79928128, 0.8990933 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9306041055262341
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.41026853,  1.60485876]), 'currentState': array([5.94410845, 2.06713662]), 'targetState': array([0.59562767, 0.51268668]), 'effectorPosition': array([0.78644612, 0.65504292])}
episode index:2939
target Thresh 1.9949593152100058
current state at start:  [-0.43642515 -1.96589837]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.43642515, -1.96589837]), 'currentState': array([5.42234922, 3.81728694]), 'targetState': array([-0.78159116, -0.754442  ]), 'effectorPosition': array([-0.33110654, -0.57430188])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9306243082114292
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.43642515, -1.96589837]), 'currentState': array([4.98024592, 4.24863505]), 'targetState': array([-0.78159116, -0.754442  ]), 'effectorPosition': array([-0.71620806, -0.76969386])}
episode index:2940
target Thresh 1.9949693865049336
current state at start:  [ 1.60135926 -2.03421022]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.60135926, -2.03421022]), 'currentState': array([1.26116748, 3.74897509]), 'targetState': array([ 0.02773372, -0.1116162 ]), 'effectorPosition': array([ 0.59807854, -0.00355121])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.930644497157974
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.60135926, -2.03421022]), 'currentState': array([1.54397763, 3.24897509]), 'targetState': array([ 0.02773372, -0.1116162 ]), 'effectorPosition': array([0.1072921, 0.0028839])}
episode index:2941
target Thresh 1.994979437677401
current state at start:  [-1.09621681 -1.9548471 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.09621681, -1.9548471 ]), 'currentState': array([4.7986774 , 4.14150806]), 'targetState': array([-0.18689969, -0.34127741]), 'effectorPosition': array([-0.79868347, -0.53043165])}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.9306386755231424
{'reset': False, 'endBeforeDone': False, 'stepCount': 10, 'initial state': array([-1.09621681, -1.9548471 ]), 'currentState': array([3.07979894, 2.82190172]), 'targetState': array([-0.18689969, -0.34127741]), 'effectorPosition': array([-0.06997845, -0.3105444 ])}
episode index:2942
target Thresh 1.9949894687676122
current state at start:  [ 4.48571212 -3.12211222]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.48571212, -3.12211222]), 'currentState': array([4.1080519 , 3.16166519]), 'targetState': array([-0.42834091, -0.08972954]), 'effectorPosition': array([-0.01663063,  0.01123902])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9306488547057713
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([ 4.48571212, -3.12211222]), 'currentState': array([2.33141685, 2.56161758]), 'targetState': array([-0.42834091, -0.08972954]), 'effectorPosition': array([-0.50970653, -0.25931955])}
episode index:2943
target Thresh 1.994999479815692
current state at start:  [ 3.51500448 -2.11083772]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.51500448, -2.11083772]), 'currentState': array([4.01041358, 3.73358874]), 'targetState': array([0.08956844, 0.04507446]), 'effectorPosition': array([-0.53596956,  0.23039026])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9306690147415368
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.51500448, -2.11083772]), 'currentState': array([4.51041358, 3.2713599 ]), 'targetState': array([0.08956844, 0.04507446]), 'effectorPosition': array([-0.12845955,  0.01772191])}
episode index:2944
target Thresh 1.9950094708616841
current state at start:  [0.53556829 1.95533258]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.53556829, 1.95533258]), 'currentState': array([0.06988716, 2.45533258]), 'targetState': array([0.50403648, 0.54576789]), 'effectorPosition': array([0.18157832, 0.64790962])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9306891610862765
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.53556829, 1.95533258]), 'currentState': array([5.94194084, 2.61294843]), 'targetState': array([0.50403648, 0.54576789]), 'effectorPosition': array([0.2974273 , 0.42959709])}
episode index:2945
target Thresh 1.9950194419455534
current state at start:  [ 4.11418795 -2.0920014 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.11418795, -2.0920014 ]), 'currentState': array([4.46899202, 4.0326252 ]), 'targetState': array([-0.66274382, -0.49237328]), 'effectorPosition': array([-0.84430329, -0.17301242])}
done in step count: 17
reward sum = 0.8429431933839268
running average episode reward sum: 0.9306593763043003
{'reset': False, 'endBeforeDone': False, 'stepCount': 18, 'initial state': array([ 4.11418795, -2.0920014 ]), 'currentState': array([2.40474837, 2.32792244]), 'targetState': array([-0.66274382, -0.49237328]), 'effectorPosition': array([-0.7203123 , -0.32784017])}
episode index:2946
target Thresh 1.9950293931071834
current state at start:  [ 2.16169229 -2.14963085]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.16169229, -2.14963085]), 'currentState': array([1.82522243, 3.63355446]), 'targetState': array([ 0.29542626, -0.04109126]), 'effectorPosition': array([0.42730136, 0.23366167])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9306728271436948
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 2.16169229, -2.14963085]), 'currentState': array([1.3451395 , 3.30677835]), 'targetState': array([ 0.29542626, -0.04109126]), 'effectorPosition': array([ 0.16331231, -0.02352482])}
episode index:2947
target Thresh 1.9950393243863795
current state at start:  [1.69237067 2.62151613]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.69237067, 2.62151613]), 'currentState': array([1.20768326, 3.05045049]), 'targetState': array([0.12321145, 0.11585769]), 'effectorPosition': array([-0.08360716,  0.03620756])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9306963438237682
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.69237067, 2.62151613]), 'currentState': array([1.20768326, 3.05045049]), 'targetState': array([0.12321145, 0.11585769]), 'effectorPosition': array([-0.08360716,  0.03620756])}
episode index:2948
target Thresh 1.9950492358228664
current state at start:  [-0.17131214 -1.75994833]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.17131214, -1.75994833]), 'currentState': array([5.61187317, 4.02590297]), 'targetState': array([-0.25492287, -0.91353573]), 'effectorPosition': array([-0.19439535, -0.83340521])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9307198445549232
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.17131214, -1.75994833]), 'currentState': array([5.61187317, 4.02590297]), 'targetState': array([-0.25492287, -0.91353573]), 'effectorPosition': array([-0.19439535, -0.83340521])}
episode index:2949
target Thresh 1.99505912745629
current state at start:  [ 0.03978948 -2.27797119]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.03978948, -2.27797119]), 'currentState': array([5.82297478, 4.4521023 ]), 'targetState': array([ 1.05823964, -0.90034564]), 'effectorPosition': array([ 0.23620062, -1.19561452])}
done in step count: 18
reward sum = 0.8345137614500875
running average episode reward sum: 0.9306872323233623
{'reset': False, 'endBeforeDone': False, 'stepCount': 19, 'initial state': array([ 0.03978948, -2.27797119]), 'currentState': array([4.7398234, 1.7614542]), 'targetState': array([ 1.05823964, -0.90034564]), 'effectorPosition': array([ 1.00374297, -0.7832562 ])}
episode index:2950
target Thresh 1.995068999326217
current state at start:  [-0.78420575 -1.70227911]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.78420575, -1.70227911]), 'currentState': array([5.05587714, 5.05087732]), 'targetState': array([-0.01998377, -1.29298825]), 'effectorPosition': array([-0.43955486, -1.57191434])}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9306845408499989
{'reset': False, 'endBeforeDone': False, 'stepCount': 9, 'initial state': array([-0.78420575, -1.70227911]), 'currentState': array([3.7497022 , 1.80312488]), 'targetState': array([-0.01998377, -1.29298825]), 'effectorPosition': array([-0.07579406, -1.23845347])}
episode index:2951
target Thresh 1.9950788514721345
current state at start:  [-0.80884566 -1.59111464]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.80884566, -1.59111464]), 'currentState': array([4.97433964, 4.60692736]), 'targetState': array([-1.00678225, -0.98419638]), 'effectorPosition': array([-0.7288154 , -1.12173778])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.930704634162719
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.80884566, -1.59111464]), 'currentState': array([4.4751311 , 4.99767189]), 'targetState': array([-1.00678225, -0.98419638]), 'effectorPosition': array([-1.23388523, -1.01999271])}
episode index:2952
target Thresh 1.9950886839334514
current state at start:  [ 1.85357681 -2.32109241]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.85357681, -2.32109241]), 'currentState': array([1.59241623, 3.46209289]), 'targetState': array([-0.19668926,  0.23708655]), 'effectorPosition': array([0.3138669 , 0.05772079])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9307147565385527
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([ 1.85357681, -2.32109241]), 'currentState': array([0.95951389, 2.88677944]), 'targetState': array([-0.19668926,  0.23708655]), 'effectorPosition': array([-0.18788735,  0.17110684])}
episode index:2953
target Thresh 1.9950984967494976
current state at start:  [0.55012253 2.40076738]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.55012253, 2.40076738]), 'currentState': array([0.16044882, 2.79535638]), 'targetState': array([0.11533152, 0.46765572]), 'effectorPosition': array([0.00436458, 0.34448177])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9307382112587496
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.55012253, 2.40076738]), 'currentState': array([0.16044882, 2.79535638]), 'targetState': array([0.11533152, 0.46765572]), 'effectorPosition': array([0.00436458, 0.34448177])}
episode index:2954
target Thresh 1.995108289959524
current state at start:  [0.96224831 2.22421523]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.96224831, 2.22421523]), 'currentState': array([0.53056247, 2.62233307]), 'targetState': array([ 0.02788138, -0.03081427]), 'effectorPosition': array([-0.13741354,  0.49471591])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9307582660095925
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.96224831, 2.22421523]), 'currentState': array([0.08070464, 3.01522895]), 'targetState': array([ 0.02788138, -0.03081427]), 'effectorPosition': array([-0.00221266,  0.12626026])}
episode index:2955
target Thresh 1.995118063602704
current state at start:  [ 1.54416386 -1.79759241]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.54416386, -1.79759241]), 'currentState': array([1.10501603, 3.98559289]), 'targetState': array([0.19071914, 0.03045344]), 'effectorPosition': array([ 0.81838692, -0.03585203])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9307783071915919
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.54416386, -1.79759241]), 'currentState': array([1.3987038 , 3.48559289]), 'targetState': array([0.19071914, 0.03045344]), 'effectorPosition': array([ 3.42306593e-01, -3.16329381e-05])}
episode index:2956
target Thresh 1.9951278177181317
current state at start:  [ 1.56174799 -2.43301837]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.56174799, -2.43301837]), 'currentState': array([1.58415831, 3.35016694]), 'targetState': array([-0.28561752,  0.3304068 ]), 'effectorPosition': array([0.20675722, 0.02443766])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9307916723227412
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 1.56174799, -2.43301837]), 'currentState': array([1.11681939, 2.60103149]), 'targetState': array([-0.28561752,  0.3304068 ]), 'effectorPosition': array([-0.39996427,  0.3538199 ])}
episode index:2957
target Thresh 1.995137552344824
current state at start:  [-0.134963   -2.75115255]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.134963  , -2.75115255]), 'currentState': array([5.79257737, 3.11082995]), 'targetState': array([0.1262088 , 0.14336727]), 'effectorPosition': array([0.01490926, 0.02690694])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9308150693233083
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.134963  , -2.75115255]), 'currentState': array([5.79257737, 3.11082995]), 'targetState': array([0.1262088 , 0.14336727]), 'effectorPosition': array([0.01490926, 0.02690694])}
episode index:2958
target Thresh 1.995147267521719
current state at start:  [-1.32355786 -2.06378307]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.32355786, -2.06378307]), 'currentState': array([4.48754895, 4.71940223]), 'targetState': array([-0.09306095, -1.0762282 ]), 'effectorPosition': array([-1.19931983, -0.75872152])}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9308123419238843
{'reset': False, 'endBeforeDone': False, 'stepCount': 9, 'initial state': array([-1.32355786, -2.06378307]), 'currentState': array([3.81797073, 2.00347442]), 'targetState': array([-0.09306095, -1.0762282 ]), 'effectorPosition': array([ 0.11543355, -1.0714793 ])}
episode index:2959
target Thresh 1.9951569632876778
current state at start:  [-3.06327031  2.53908402]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.06327031,  2.53908402]), 'currentState': array([3.54180097, 3.00841961]), 'targetState': array([0.64362083, 0.13708209]), 'effectorPosition': array([ 0.0435776 , -0.12573726])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9308256820110722
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-3.06327031,  2.53908402]), 'currentState': array([5.04180097, 2.37785   ]), 'targetState': array([0.64362083, 0.13708209]), 'effectorPosition': array([ 0.74429   , -0.03908081])}
episode index:2960
target Thresh 1.9951666396814831
current state at start:  [-1.29973264  2.35598078]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.29973264,  2.35598078]), 'currentState': array([4.52743655, 1.98757216]), 'targetState': array([ 0.52130306, -0.52815495]), 'effectorPosition': array([ 0.7893493 , -0.75319247])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9308456665831724
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.29973264,  2.35598078]), 'currentState': array([4.38722763, 2.48570868]), 'targetState': array([ 0.52130306, -0.52815495]), 'effectorPosition': array([ 0.5116175 , -0.39144509])}
episode index:2961
target Thresh 1.9951762967418407
current state at start:  [ 2.02253557 -2.61023152]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.02253557, -2.61023152]), 'currentState': array([1.75262094, 3.17761988]), 'targetState': array([-0.18685489,  0.03255188]), 'effectorPosition': array([0.03530833, 0.00715141])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9308690137585326
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.02253557, -2.61023152]), 'currentState': array([1.75262094, 3.17761988]), 'targetState': array([-0.18685489,  0.03255188]), 'effectorPosition': array([0.03530833, 0.00715141])}
episode index:2962
target Thresh 1.995185934507379
current state at start:  [-4.17287499  2.37155042]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.17287499,  2.37155042]), 'currentState': array([1.64585247, 2.84589524]), 'targetState': array([0.23175852, 0.11163603]), 'effectorPosition': array([-0.29384108,  0.0214273 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9308889702169333
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-4.17287499,  2.37155042]), 'currentState': array([1.19015869, 3.15873272]), 'targetState': array([0.23175852, 0.11163603]), 'effectorPosition': array([ 0.01596711, -0.00623106])}
episode index:2963
target Thresh 1.9951955530166487
current state at start:  [-0.39447919  2.10347603]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.39447919,  2.10347603]), 'currentState': array([0.10552081, 1.61012147]), 'targetState': array([0.80899583, 0.94792406]), 'effectorPosition': array([0.85009784, 1.09485325])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.930912287028601
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.39447919,  2.10347603]), 'currentState': array([0.10552081, 1.61012147]), 'targetState': array([0.80899583, 0.94792406]), 'effectorPosition': array([0.85009784, 1.09485325])}
episode index:2964
target Thresh 1.9952051523081242
current state at start:  [-0.43636065  2.7628024 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.43636065,  2.7628024 ]), 'currentState': array([5.38541297, 2.96129235]), 'targetState': array([0.85211523, 0.15592652]), 'effectorPosition': array([0.15032607, 0.09910752])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9309288764764835
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-0.43636065,  2.7628024 ]), 'currentState': array([5.34791328, 2.14808028]), 'targetState': array([0.85211523, 0.15592652]), 'effectorPosition': array([0.94399009, 0.1318431 ])}
episode index:2965
target Thresh 1.9952147324202025
current state at start:  [ 0.27121201 -2.42305216]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.27121201, -2.42305216]), 'currentState': array([0.39425405, 3.38629339]), 'targetState': array([ 0.29928019, -0.17714151]), 'effectorPosition': array([ 0.12056384, -0.21223718])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9309521641108474
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.27121201, -2.42305216]), 'currentState': array([0.39425405, 3.38629339]), 'targetState': array([ 0.29928019, -0.17714151]), 'effectorPosition': array([ 0.12056384, -0.21223718])}
episode index:2966
target Thresh 1.995224293391204
current state at start:  [ 0.03700043 -2.63358173]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.03700043, -2.63358173]), 'currentState': array([6.18270405, 3.18370741]), 'targetState': array([-0.01819165, -0.02933904]), 'effectorPosition': array([-0.00334115, -0.04197889])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9309754360474464
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.03700043, -2.63358173]), 'currentState': array([6.18270405, 3.18370741]), 'targetState': array([-0.01819165, -0.02933904]), 'effectorPosition': array([-0.00334115, -0.04197889])}
episode index:2967
target Thresh 1.995233835259373
current state at start:  [-0.0885298  -2.90896704]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.0885298 , -2.90896704]), 'currentState': array([5.6946555 , 3.87421826]), 'targetState': array([-0.03172634, -0.58905216]), 'effectorPosition': array([-0.15787841, -0.69873644])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9309986923021474
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.0885298 , -2.90896704]), 'currentState': array([5.6946555 , 3.87421826]), 'targetState': array([-0.03172634, -0.58905216]), 'effectorPosition': array([-0.15787841, -0.69873644])}
episode index:2968
target Thresh 1.9952433580628763
current state at start:  [-1.90780424 -1.75180225]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.90780424, -1.75180225]), 'currentState': array([3.87538107, 4.41214913]), 'targetState': array([-0.84617827,  0.28667869]), 'effectorPosition': array([-1.16273638,  0.23779286])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.931018564753376
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.90780424, -1.75180225]), 'currentState': array([3.71586044, 4.11039761]), 'targetState': array([-0.84617827,  0.28667869]), 'effectorPosition': array([-0.81187025,  0.45639555])}
episode index:2969
target Thresh 1.9952528618398058
current state at start:  [2.30938409 1.61000765]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.30938409, 1.61000765]), 'currentState': array([2.75758631, 2.11000765]), 'targetState': array([-0.47459568, -0.7045366 ]), 'effectorPosition': array([-0.77258853, -0.61334184])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9310384238224825
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([2.30938409, 1.61000765]), 'currentState': array([3.11874158, 2.22546206]), 'targetState': array([-0.47459568, -0.7045366 ]), 'effectorPosition': array([-0.40912884, -0.784108  ])}
episode index:2970
target Thresh 1.9952623466281763
current state at start:  [1.70433778 2.15441609]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.70433778, 2.15441609]), 'currentState': array([1.20433778, 2.61011607]), 'targetState': array([-0.027618  ,  0.03322165]), 'effectorPosition': array([-0.42373032,  0.31037603])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9310582695229798
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.70433778, 2.15441609]), 'currentState': array([0.73118818, 3.00899565]), 'targetState': array([-0.027618  ,  0.03322165]), 'effectorPosition': array([-0.08174876,  0.1042754 ])}
episode index:2971
target Thresh 1.9952718124659268
current state at start:  [-2.02098356  2.00319871]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.02098356,  2.00319871]), 'currentState': array([3.76220174, 2.39916933]), 'targetState': array([0.01020293, 0.00703135]), 'effectorPosition': array([ 0.17906541, -0.70304398])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9310747707781875
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-2.02098356,  2.00319871]), 'currentState': array([2.96164392, 3.09213126]), 'targetState': array([0.01020293, 0.00703135]), 'effectorPosition': array([-0.01005217, -0.04842401])}
episode index:2972
target Thresh 1.995281259390921
current state at start:  [-1.45008781 -2.14870532]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.45008781, -2.14870532]), 'currentState': array([4.33817658, 3.63447999]), 'targetState': array([-0.00038398, -0.01575724]), 'effectorPosition': array([-0.48393611,  0.06217058])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.931094590902379
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.45008781, -2.14870532]), 'currentState': array([4.70716009, 3.13447999]), 'targetState': array([-0.00038398, -0.01575724]), 'effectorPosition': array([ 7.11237881e-03, -6.24854467e-05])}
episode index:2973
target Thresh 1.9952906874409464
current state at start:  [ 1.64105193 -2.07989063]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.64105193, -2.07989063]), 'currentState': array([1.99902094, 3.70329467]), 'targetState': array([0.49201486, 0.82331195]), 'effectorPosition': array([0.42072934, 0.36095323])}
done in step count: 15
reward sum = 0.8600583546412884
running average episode reward sum: 0.9310707051470793
{'reset': False, 'endBeforeDone': False, 'stepCount': 16, 'initial state': array([ 1.64105193, -2.07989063]), 'currentState': array([2.0317875 , 4.13525761]), 'targetState': array([0.49201486, 0.82331195]), 'effectorPosition': array([0.54842728, 0.77973275])}
episode index:2974
target Thresh 1.9953000966537153
current state at start:  [ 3.76399377 -2.16501616]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.76399377, -2.16501616]), 'currentState': array([4.23887214, 3.68148722]), 'targetState': array([-0.16222969, -0.4191814 ]), 'effectorPosition': array([-0.52234798,  0.10782776])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.9310774007251477
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([ 3.76399377, -2.16501616]), 'currentState': array([3.28968275, 2.5038098 ]), 'targetState': array([-0.16222969, -0.4191814 ]), 'effectorPosition': array([-0.10657727, -0.61790418])}
episode index:2975
target Thresh 1.9953094870668646
current state at start:  [1.13668778 1.66992741]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.13668778, 1.66992741]), 'currentState': array([0.63668778, 2.01439231]), 'targetState': array([0.32260518, 1.34987797]), 'effectorPosition': array([-0.07802212,  1.06561353])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9310971999856565
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.13668778, 1.66992741]), 'currentState': array([0.37819356, 1.56808775]), 'targetState': array([0.32260518, 1.34987797]), 'effectorPosition': array([0.5626094 , 1.29957216])}
episode index:2976
target Thresh 1.995318858717956
current state at start:  [-0.4919265   2.76363908]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.4919265 ,  2.76363908]), 'currentState': array([6.21456828, 2.52555848]), 'targetState': array([-0.23516101,  0.87753606]), 'effectorPosition': array([0.2230071 , 0.56383966])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9311136604492154
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-0.4919265 ,  2.76363908]), 'currentState': array([0.80962669, 2.22389386]), 'targetState': array([-0.23516101,  0.87753606]), 'effectorPosition': array([-0.30439712,  0.83189158])}
episode index:2977
target Thresh 1.995328211644476
current state at start:  [ 4.01272761 -2.12631966]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.01272761, -2.12631966]), 'currentState': array([4.25651595, 3.81757783]), 'targetState': array([-0.25498385, -0.38292919]), 'effectorPosition': array([-0.65858542,  0.07799595])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.9311203348580304
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([ 4.01272761, -2.12631966]), 'currentState': array([3.07604178, 2.43601753]), 'targetState': array([-0.25498385, -0.38292919]), 'effectorPosition': array([-0.28072594, -0.63143922])}
episode index:2978
target Thresh 1.9953375458838363
current state at start:  [ 3.33629323 -2.16869349]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.33629323, -2.16869349]), 'currentState': array([3.24277246, 3.66726375]), 'targetState': array([-0.9502041 ,  0.36908851]), 'effectorPosition': array([-0.18500691,  0.48559002])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9311302293444828
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([ 3.33629323, -2.16869349]), 'currentState': array([1.84984172, 1.99246862]), 'targetState': array([-0.9502041 ,  0.36908851]), 'effectorPosition': array([-1.03981774,  0.31655237])}
episode index:2979
target Thresh 1.9953468614733738
current state at start:  [ 3.48198253 -1.69486434]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.48198253, -1.69486434]), 'currentState': array([3.93936157, 4.15552377]), 'targetState': array([-0.78372549,  0.10944991]), 'effectorPosition': array([-0.93688579,  0.25532287])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9311533400057765
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.48198253, -1.69486434]), 'currentState': array([3.93936157, 4.15552377]), 'targetState': array([-0.78372549,  0.10944991]), 'effectorPosition': array([-0.93688579,  0.25532287])}
episode index:2980
target Thresh 1.995356158450351
current state at start:  [-4.22498106  2.58359855]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.22498106,  2.58359855]), 'currentState': array([1.6546848 , 2.09750595]), 'targetState': array([-1.26300346,  0.33130256]), 'effectorPosition': array([-0.90309536,  0.42312584])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9311730805827622
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-4.22498106,  2.58359855]), 'currentState': array([2.12020312, 1.60517758]), 'targetState': array([-1.26300346,  0.33130256]), 'effectorPosition': array([-1.35656213,  0.30164587])}
episode index:2981
target Thresh 1.995365436851956
current state at start:  [-0.15622855 -2.1696193 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.15622855, -2.1696193 ]), 'currentState': array([5.75690126, 3.6213532 ]), 'targetState': array([-0.12642983, -0.34551907]), 'effectorPosition': array([-0.13423833, -0.45581699])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9311961613739819
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.15622855, -2.1696193 ]), 'currentState': array([5.75690126, 3.6213532 ]), 'targetState': array([-0.12642983, -0.34551907]), 'effectorPosition': array([-0.13423833, -0.45581699])}
episode index:2982
target Thresh 1.995374696715302
current state at start:  [ 2.54072365 -2.19543451]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.54072365, -2.19543451]), 'currentState': array([2.24157056, 3.62224952]), 'targetState': array([ 0.11660071, -0.05241303]), 'effectorPosition': array([0.29175493, 0.37615987])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9312158743604471
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 2.54072365, -2.19543451]), 'currentState': array([1.98516503, 3.17513991]), 'targetState': array([ 0.11660071, -0.05241303]), 'effectorPosition': array([0.03047588, 0.01401904])}
episode index:2983
target Thresh 1.995383938077429
current state at start:  [1.71863896 2.05046893]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.71863896, 2.05046893]), 'currentState': array([1.21863896, 2.30264837]), 'targetState': array([-0.28668508,  1.23265558]), 'effectorPosition': array([-0.58385426,  0.56799386])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9312355741344549
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.71863896, 2.05046893]), 'currentState': array([0.72591595, 1.95164965]), 'targetState': array([-0.28668508,  1.23265558]), 'effectorPosition': array([-0.14636572,  1.11137371])}
episode index:2984
target Thresh 1.995393160975302
current state at start:  [ 2.31321349 -2.83131821]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.31321349, -2.83131821]), 'currentState': array([2.09069365, 3.70003405]), 'targetState': array([0.05917926, 0.67755944]), 'effectorPosition': array([0.38438255, 0.3950773 ])}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9312265779873442
{'reset': False, 'endBeforeDone': False, 'stepCount': 11, 'initial state': array([ 2.31321349, -2.83131821]), 'currentState': array([0.39409431, 2.51481421]), 'targetState': array([0.05917926, 0.67755944]), 'effectorPosition': array([-0.04970626,  0.61456223])}
episode index:2985
target Thresh 1.9954023654458126
current state at start:  [ 1.53747677 -2.22986958]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.53747677, -2.22986958]), 'currentState': array([1.18368669, 3.57608905]), 'targetState': array([ 0.32083006, -0.11759513]), 'effectorPosition': array([ 0.42488254, -0.07287338])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9312496099438119
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.53747677, -2.22986958]), 'currentState': array([1.18368669, 3.57608905]), 'targetState': array([ 0.32083006, -0.11759513]), 'effectorPosition': array([ 0.42488254, -0.07287338])}
episode index:2986
target Thresh 1.995411551525779
current state at start:  [-2.37923738  2.1029597 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.37923738,  2.1029597 ]), 'currentState': array([3.41042772, 1.91370132]), 'targetState': array([-0.16069232, -1.10344598]), 'effectorPosition': array([-0.38978814, -1.08425848])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9312726264788157
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.37923738,  2.1029597 ]), 'currentState': array([3.41042772, 1.91370132]), 'targetState': array([-0.16069232, -1.10344598]), 'effectorPosition': array([-0.38978814, -1.08425848])}
episode index:2987
target Thresh 1.9954207192519453
current state at start:  [-0.94169966 -1.69061757]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.94169966, -1.69061757]), 'currentState': array([4.90860417, 5.06686938]), 'targetState': array([-0.23155316, -1.16194235]), 'effectorPosition': array([-0.65720219, -1.50409159])}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9312697724185577
{'reset': False, 'endBeforeDone': False, 'stepCount': 9, 'initial state': array([-0.94169966, -1.69061757]), 'currentState': array([3.66542923, 1.90958064]), 'targetState': array([-0.23155316, -1.16194235]), 'effectorPosition': array([-0.10635656, -1.15065494])}
episode index:2988
target Thresh 1.9954298686609826
current state at start:  [-3.37353996  1.84804844]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.37353996,  1.84804844]), 'currentState': array([2.52015918, 2.20862575]), 'targetState': array([-0.61657685, -0.64629415]), 'effectorPosition': array([-0.79664951, -0.41766435])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.931289421206641
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.37353996,  1.84804844]), 'currentState': array([3.02015918, 2.14425422]), 'targetState': array([-0.61657685, -0.64629415]), 'effectorPosition': array([-0.55584849, -0.77842946])}
episode index:2989
target Thresh 1.9954389997894884
current state at start:  [-0.78726807 -2.86601842]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.78726807, -2.86601842]), 'currentState': array([5.00370726, 3.90855053]), 'targetState': array([-0.61727055, -0.39084223]), 'effectorPosition': array([-0.58429623, -0.46749092])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9313124013333278
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.78726807, -2.86601842]), 'currentState': array([5.00370726, 3.90855053]), 'targetState': array([-0.61727055, -0.39084223]), 'effectorPosition': array([-0.58429623, -0.46749092])}
episode index:2990
target Thresh 1.9954481126739874
current state at start:  [ 0.13409023 -2.37752853]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.13409023, -2.37752853]), 'currentState': array([0.59933074, 3.42516702]), 'targetState': array([0.01757778, 0.25944533]), 'effectorPosition': array([ 0.19080394, -0.20849663])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9313320227304078
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.13409023, -2.37752853]), 'currentState': array([1.06197165, 2.96172148]), 'targetState': array([0.01757778, 0.25944533]), 'effectorPosition': array([-0.14837967,  0.10124217])}
episode index:2991
target Thresh 1.995457207350931
current state at start:  [-3.82256702  2.0889729 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.82256702,  2.0889729 ]), 'currentState': array([1.9676651 , 2.36594641]), 'targetState': array([-1.14511111,  0.17425469]), 'effectorPosition': array([-0.75631726, -0.00684157])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9313516310115807
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.82256702,  2.0889729 ]), 'currentState': array([2.14201501, 1.95329777]), 'targetState': array([-1.14511111,  0.17425469]), 'effectorPosition': array([-1.11931072,  0.02566891])}
episode index:2992
target Thresh 1.9954662838566977
current state at start:  [-3.98768318  2.38601672]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.98768318,  2.38601672]), 'currentState': array([2.79550213, 2.78339558]), 'targetState': array([-0.2174208 , -0.55328354]), 'effectorPosition': array([-0.17863306, -0.30826835])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9313745673192949
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.98768318,  2.38601672]), 'currentState': array([2.79550213, 2.78339558]), 'targetState': array([-0.2174208 , -0.55328354]), 'effectorPosition': array([-0.17863306, -0.30826835])}
episode index:2993
target Thresh 1.995475342227594
current state at start:  [-0.38553426 -1.63068611]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.38553426, -1.63068611]), 'currentState': array([5.43834111, 4.2191658 ]), 'targetState': array([-0.32100246, -0.85778972]), 'effectorPosition': array([-0.30919282, -0.97850145])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9313974883054942
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.38553426, -1.63068611]), 'currentState': array([5.43834111, 4.2191658 ]), 'targetState': array([-0.32100246, -0.85778972]), 'effectorPosition': array([-0.30919282, -0.97850145])}
episode index:2994
target Thresh 1.9954843824998532
current state at start:  [-2.04426567 -1.63212533]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.04426567, -1.63212533]), 'currentState': array([3.94337451, 4.95227661]), 'targetState': array([-1.05913933, -0.60257846]), 'effectorPosition': array([-1.55867553, -0.21381659])}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.9313915182751696
{'reset': False, 'endBeforeDone': False, 'stepCount': 10, 'initial state': array([-2.04426567, -1.63212533]), 'currentState': array([2.85084297, 1.66368654]), 'targetState': array([-1.05913933, -0.60257846]), 'effectorPosition': array([-1.15460025, -0.69381906])}
episode index:2995
target Thresh 1.9954934047096362
current state at start:  [-3.26377352  2.52820909]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.26377352,  2.52820909]), 'currentState': array([2.51941179, 2.88224703]), 'targetState': array([-0.30892794,  0.20216065]), 'effectorPosition': array([-0.17663548, -0.18890185])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9314045047510457
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-3.26377352,  2.52820909]), 'currentState': array([1.25280799, 2.54086016]), 'targetState': array([-0.30892794,  0.20216065]), 'effectorPosition': array([-0.48216964,  0.34302893])}
episode index:2996
target Thresh 1.9955024088930322
current state at start:  [-0.88106384  2.47734677]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.88106384,  2.47734677]), 'currentState': array([5.55167414, 2.73030188]), 'targetState': array([-0.03298949,  0.3256396 ]), 'effectorPosition': array([0.32911887, 0.24180505])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9314240561341784
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.88106384,  2.47734677]), 'currentState': array([5.8578869 , 2.77473585]), 'targetState': array([-0.03298949,  0.3256396 ]), 'effectorPosition': array([0.20860294, 0.29927593])}
episode index:2997
target Thresh 1.9955113950860577
current state at start:  [ 2.58837235 -1.71943197]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.58837235, -1.71943197]), 'currentState': array([2.62255582, 4.06375334]), 'targetState': array([0.61665468, 0.46007062]), 'effectorPosition': array([0.05154266, 0.88833775])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.9314242700407072
{'reset': False, 'endBeforeDone': False, 'stepCount': 8, 'initial state': array([ 2.58837235, -1.71943197]), 'currentState': array([5.87965027, 2.13421037]), 'targetState': array([0.61665468, 0.46007062]), 'effectorPosition': array([0.76047988, 0.59457466])}
episode index:2998
target Thresh 1.9955203633246577
current state at start:  [-2.45506491  1.57123896]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.45506491,  1.57123896]), 'currentState': array([3.3281204 , 2.01270613]), 'targetState': array([-0.31266066, -0.86251104]), 'effectorPosition': array([-0.39477254, -0.99439503])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9314471362394265
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.45506491,  1.57123896]), 'currentState': array([3.3281204 , 2.01270613]), 'targetState': array([-0.31266066, -0.86251104]), 'effectorPosition': array([-0.39477254, -0.99439503])}
episode index:2999
target Thresh 1.9955293136447048
current state at start:  [-1.17102119  2.0364136 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.17102119,  2.0364136 ]), 'currentState': array([5.61216412, 1.78590082]), 'targetState': array([1.27715343, 0.32463048]), 'effectorPosition': array([1.22347268, 0.2760717 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9314699871940133
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.17102119,  2.0364136 ]), 'currentState': array([5.61216412, 1.78590082]), 'targetState': array([1.27715343, 0.32463048]), 'effectorPosition': array([1.22347268, 0.2760717 ])}
episode index:3000
target Thresh 1.9955382460820006
current state at start:  [-4.08786787  2.18470652]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.08786787,  2.18470652]), 'currentState': array([1.75785848, 2.39927764]), 'targetState': array([-0.61777983,  0.33300705]), 'effectorPosition': array([-0.7131313 ,  0.13278767])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9314928229197068
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.08786787,  2.18470652]), 'currentState': array([1.75785848, 2.39927764]), 'targetState': array([-0.61777983,  0.33300705]), 'effectorPosition': array([-0.7131313 ,  0.13278767])}
episode index:3001
target Thresh 1.9955471606722748
current state at start:  [-3.52447182  2.00247674]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.52447182,  2.00247674]), 'currentState': array([2.43935803, 2.41842629]), 'targetState': array([-0.13121775, -0.43416515]), 'effectorPosition': array([-0.61851709, -0.34352349])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9315123123191339
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.52447182,  2.00247674]), 'currentState': array([2.93935803, 2.7634217 ]), 'targetState': array([-0.13121775, -0.43416515]), 'effectorPosition': array([-0.14337987, -0.34750423])}
episode index:3002
target Thresh 1.9955560574511857
current state at start:  [-0.48773172 -2.55309555]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.48773172, -2.55309555]), 'currentState': array([5.36874202, 4.13424218]), 'targetState': array([-0.78983119, -0.66086902]), 'effectorPosition': array([-0.38671174, -0.87034953])}
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.9314943332018112
{'reset': False, 'endBeforeDone': False, 'stepCount': 14, 'initial state': array([-0.48773172, -2.55309555]), 'currentState': array([2.97200786, 1.94220194]), 'targetState': array([-0.78983119, -0.66086902]), 'effectorPosition': array([-0.7852014, -0.8109301])}
episode index:3003
target Thresh 1.9955649364543204
current state at start:  [-2.43748735  2.02941011]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.43748735,  2.02941011]), 'currentState': array([3.34569795, 2.52568539]), 'targetState': array([-0.02337301, -0.06137469]), 'effectorPosition': array([-0.06284167, -0.60295241])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9315138091228491
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.43748735,  2.02941011]), 'currentState': array([2.90214892, 3.02568539]), 'targetState': array([-0.02337301, -0.06137469]), 'effectorPosition': array([-0.03394562, -0.11075719])}
episode index:3004
target Thresh 1.9955737977171952
current state at start:  [-2.53071268  3.10125424]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.53071268,  3.10125424]), 'currentState': array([3.73192197, 2.61468108]), 'targetState': array([-0.14685553, -0.6526537 ]), 'effectorPosition': array([ 0.16723235, -0.49325939])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9315332720815437
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.53071268,  3.10125424]), 'currentState': array([3.38979196, 2.26423241]), 'targetState': array([-0.14685553, -0.6526537 ]), 'effectorPosition': array([-0.16083479, -0.83412541])}
episode index:3005
target Thresh 1.9955826412752549
current state at start:  [-2.47132772  2.47645147]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.47132772,  2.47645147]), 'currentState': array([4.31185759, 2.76165588]), 'targetState': array([1.05979671, 0.14305236]), 'effectorPosition': array([ 0.31370444, -0.21026972])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.9315397447288553
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([-2.47132772,  2.47645147]), 'currentState': array([5.54579316, 2.15392087]), 'targetState': array([1.05979671, 0.14305236]), 'effectorPosition': array([0.89388093, 0.31576453])}
episode index:3006
target Thresh 1.995591467163874
current state at start:  [-0.61520146 -1.60616768]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.61520146, -1.60616768]), 'currentState': array([5.22066699, 4.28132566]), 'targetState': array([-0.74994864, -1.01984147]), 'effectorPosition': array([-0.51034676, -0.95072184])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9315625116910339
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.61520146, -1.60616768]), 'currentState': array([5.22066699, 4.28132566]), 'targetState': array([-0.74994864, -1.01984147]), 'effectorPosition': array([-0.51034676, -0.95072184])}
episode index:3007
target Thresh 1.9956002754183555
current state at start:  [-3.28221255  1.79051116]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.28221255,  1.79051116]), 'currentState': array([2.50983263, 2.28583058]), 'targetState': array([-0.03737051,  0.13402418]), 'effectorPosition': array([-0.72381133, -0.40596871])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9315786478241154
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-3.28221255,  1.79051116]), 'currentState': array([1.5430947 , 2.90654112]), 'targetState': array([-0.03737051,  0.13402418]), 'effectorPosition': array([-0.23204212,  0.0339378 ])}
episode index:3008
target Thresh 1.995609066073933
current state at start:  [-0.29300893  1.75083782]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.29300893,  1.75083782]), 'currentState': array([0.08928477, 2.19267   ]), 'targetState': array([0.08620158, 0.67367409]), 'effectorPosition': array([0.3433049 , 0.84677245])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9315980633615616
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.29300893,  1.75083782]), 'currentState': array([0.27625462, 2.54585509]), 'targetState': array([0.08620158, 0.67367409]), 'effectorPosition': array([0.01268581, 0.58682991])}
episode index:3009
target Thresh 1.995617839165769
current state at start:  [-1.19081439 -2.60914442]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.19081439, -2.60914442]), 'currentState': array([4.59237092, 4.12771947]), 'targetState': array([-1.36657852,  0.28576329]), 'effectorPosition': array([-0.88154412, -0.34501062])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9316141769617737
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.19081439, -2.60914442]), 'currentState': array([3.59237092, 4.93975535]), 'targetState': array([-1.36657852,  0.28576329]), 'effectorPosition': array([-1.52745758,  0.34307183])}
episode index:3010
target Thresh 1.9956265947289558
current state at start:  [ 0.14807988 -1.99075565]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.14807988, -1.99075565]), 'currentState': array([5.93126518, 4.04043252]), 'targetState': array([ 0.10254524, -0.94800851]), 'effectorPosition': array([ 0.08458209, -0.86475964])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9316368889587974
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.14807988, -1.99075565]), 'currentState': array([5.93126518, 4.04043252]), 'targetState': array([ 0.10254524, -0.94800851]), 'effectorPosition': array([ 0.08458209, -0.86475964])}
episode index:3011
target Thresh 1.9956353327985155
current state at start:  [0.85192831 2.39305024]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.85192831, 2.39305024]), 'currentState': array([0.49050759, 2.88183723]), 'targetState': array([-0.21070071,  0.20672034]), 'effectorPosition': array([-0.09140078,  0.24236387])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9316595858748138
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.85192831, 2.39305024]), 'currentState': array([0.49050759, 2.88183723]), 'targetState': array([-0.21070071,  0.20672034]), 'effectorPosition': array([-0.09140078,  0.24236387])}
episode index:3012
target Thresh 1.9956440534094009
current state at start:  [ 3.64301515 -2.04809249]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.64301515, -2.04809249]), 'currentState': array([4.14301515, 3.73509282]), 'targetState': array([-0.12548843, -0.23038964]), 'effectorPosition': array([-0.56322876,  0.15747027])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9316789487736272
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.64301515, -2.04809249]), 'currentState': array([4.6204536 , 3.24065908]), 'targetState': array([-0.12548843, -0.23038964]), 'effectorPosition': array([-0.09893692,  0.00419766])}
episode index:3013
target Thresh 1.9956527565964939
current state at start:  [ 2.30157907 -1.87431938]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.30157907, -1.87431938]), 'currentState': array([2.41314488, 3.91467986]), 'targetState': array([0.09326179, 0.41676776]), 'effectorPosition': array([0.25279519, 0.71033676])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9316982988238017
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 2.30157907, -1.87431938]), 'currentState': array([2.58724775, 3.42546842]), 'targetState': array([0.09326179, 0.41676776]), 'effectorPosition': array([0.1134002 , 0.25920287])}
episode index:3014
target Thresh 1.9956614423946075
current state at start:  [ 1.60722248 -1.96193227]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.60722248, -1.96193227]), 'currentState': array([1.15188174, 3.85855076]), 'targetState': array([ 1.14353153, -0.17636653]), 'effectorPosition': array([ 0.70041968, -0.04238185])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9317176360381222
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.60722248, -1.96193227]), 'currentState': array([0.71461354, 4.33674074]), 'targetState': array([ 1.14353153, -0.17636653]), 'effectorPosition': array([ 1.087858  , -0.28777366])}
episode index:3015
target Thresh 1.995670110838485
current state at start:  [-0.8672478   2.83853975]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.8672478 ,  2.83853975]), 'currentState': array([4.95680758, 3.18915963]), 'targetState': array([0.04282593, 0.02098415]), 'effectorPosition': array([-0.04586208, -0.01260398])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9317402760792236
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.8672478 ,  2.83853975]), 'currentState': array([4.95680758, 3.18915963]), 'targetState': array([0.04282593, 0.02098415]), 'effectorPosition': array([-0.04586208, -0.01260398])}
episode index:3016
target Thresh 1.9956787619627998
current state at start:  [-0.96884741 -1.99142148]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.96884741, -1.99142148]), 'currentState': array([4.81433789, 4.79176382]), 'targetState': array([ 0.01584231, -0.90175045]), 'effectorPosition': array([-0.88183344, -1.1751395 ])}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.9317342359636798
{'reset': False, 'endBeforeDone': False, 'stepCount': 10, 'initial state': array([-0.96884741, -1.99142148]), 'currentState': array([3.35237318, 2.29188574]), 'targetState': array([ 0.01584231, -0.90175045]), 'effectorPosition': array([-0.17513146, -0.80555717])}
episode index:3017
target Thresh 1.995687395802157
current state at start:  [-0.87522625  2.98117623]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.87522625,  2.98117623]), 'currentState': array([5.54105496, 2.53243038]), 'targetState': array([0.87410486, 0.8709454 ]), 'effectorPosition': array([0.51928515, 0.30014606])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9317535420485161
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.87522625,  2.98117623]), 'currentState': array([6.00415751, 2.0802798 ]), 'targetState': array([0.87410486, 0.8709454 ]), 'effectorPosition': array([0.73290248, 0.69814123])}
episode index:3018
target Thresh 1.9956960123910916
current state at start:  [-1.13643064 -2.59852458]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.13643064, -2.59852458]), 'currentState': array([4.66946469, 3.71024858]), 'targetState': array([0.02502002, 0.00546381]), 'effectorPosition': array([-0.54475709, -0.13412189])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9317728353436308
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.13643064, -2.59852458]), 'currentState': array([4.60120803, 3.30153792]), 'targetState': array([0.02502002, 0.00546381]), 'effectorPosition': array([-0.15969703,  0.00498549])}
episode index:3019
target Thresh 1.99570461176407
current state at start:  [-1.92137263  2.58700526]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.92137263,  2.58700526]), 'currentState': array([3.89952782, 3.08700526]), 'targetState': array([-0.54597386, -0.01260571]), 'effectorPosition': array([ 0.03642424, -0.04064872])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.931782379441199
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([-1.92137263,  2.58700526]), 'currentState': array([2.1157507 , 2.47833098]), 'targetState': array([-0.54597386, -0.01260571]), 'effectorPosition': array([-0.63641058, -0.13785891])}
episode index:3020
target Thresh 1.9957131939554897
current state at start:  [ 1.80621787 -1.79363463]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.80621787, -1.79363463]), 'currentState': array([2.29762559, 3.98955067]), 'targetState': array([0.6257736 , 0.94736547]), 'effectorPosition': array([0.3354885 , 0.75127607])}
done in step count: 25
reward sum = 0.7778213593991467
running average episode reward sum: 0.931731415846349
{'reset': False, 'endBeforeDone': False, 'stepCount': 26, 'initial state': array([ 1.80621787, -1.79363463]), 'currentState': array([6.24798335, 1.82562812]), 'targetState': array([0.6257736 , 0.94736547]), 'effectorPosition': array([0.78151211, 0.94078347])}
episode index:3021
target Thresh 1.9957217589996794
current state at start:  [-3.49000841  2.17794862]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.49000841,  2.17794862]), 'currentState': array([2.33288208, 2.67794862]), 'targetState': array([ 0.25427564, -0.16135786]), 'effectorPosition': array([-0.39640061, -0.23239832])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9317441781177433
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-3.49000841,  2.17794862]), 'currentState': array([3.39819781, 3.01251998]), 'targetState': array([ 0.25427564, -0.16135786]), 'effectorPosition': array([ 0.02462159, -0.12661128])}
episode index:3022
target Thresh 1.9957303069308996
current state at start:  [ 1.24454785 -1.79867848]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.24454785, -1.79867848]), 'currentState': array([0.74454785, 4.04643796]), 'targetState': array([ 1.27185408, -0.54703061]), 'effectorPosition': array([ 0.8139103 , -0.31927348])}
done in step count: 40
reward sum = 0.6689717585696803
running average episode reward sum: 0.9316572537315216
{'reset': False, 'endBeforeDone': False, 'stepCount': 41, 'initial state': array([ 1.24454785, -1.79867848]), 'currentState': array([4.83603109, 1.88799113]), 'targetState': array([ 1.27185408, -0.54703061]), 'effectorPosition': array([ 1.0277222 , -0.56566953])}
episode index:3023
target Thresh 1.9957388377833416
current state at start:  [ 3.28054303 -2.03028041]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.28054303, -2.03028041]), 'currentState': array([3.78054303, 3.7529049 ]), 'targetState': array([0.22797783, 0.15481527]), 'effectorPosition': array([-0.48764902,  0.35271418])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9316700320867692
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 3.28054303, -2.03028041]), 'currentState': array([4.93978249, 2.99996784]), 'targetState': array([0.22797783, 0.15481527]), 'effectorPosition': array([0.13977532, 0.02206681])}
episode index:3024
target Thresh 1.9957473515911293
current state at start:  [-0.05086024 -2.70276867]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.05086024, -2.70276867]), 'currentState': array([5.87033527, 3.16161047]), 'targetState': array([0.10604273, 0.04030659]), 'effectorPosition': array([-0.00784753, -0.0184151 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9316926205059141
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.05086024, -2.70276867]), 'currentState': array([5.87033527, 3.16161047]), 'targetState': array([0.10604273, 0.04030659]), 'effectorPosition': array([-0.00784753, -0.0184151 ])}
episode index:3025
target Thresh 1.9957558483883175
current state at start:  [ 2.21012671 -2.92633762]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.21012671, -2.92633762]), 'currentState': array([1.76188941, 3.85684769]), 'targetState': array([0.92112359, 0.69250046]), 'effectorPosition': array([0.59732496, 0.36517238])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9317118893028387
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 2.21012671, -2.92633762]), 'currentState': array([1.56692074, 4.30767776]), 'targetState': array([0.92112359, 0.69250046]), 'effectorPosition': array([0.9215588 , 0.60267962])}
episode index:3026
target Thresh 1.9957643282088937
current state at start:  [-2.83664058  2.5168489 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.83664058,  2.5168489 ]), 'currentState': array([3.36223232, 3.0168489 ]), 'targetState': array([0.52349632, 0.33632767]), 'effectorPosition': array([ 0.01964785, -0.12310482])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.9317182580377569
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([-2.83664058,  2.5168489 ]), 'currentState': array([5.57434058, 2.5861483 ]), 'targetState': array([0.52349632, 0.33632767]), 'effectorPosition': array([0.4573839 , 0.30243603])}
episode index:3027
target Thresh 1.995772791086777
current state at start:  [ 1.54048788 -1.93898846]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.54048788, -1.93898846]), 'currentState': array([1.08332255, 3.89556965]), 'targetState': array([ 1.06727332, -0.29113006]), 'effectorPosition': array([ 0.73175513, -0.08117875])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9317375056407826
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.54048788, -1.93898846]), 'currentState': array([0.74375006, 4.39556965]), 'targetState': array([ 1.06727332, -0.29113006]), 'effectorPosition': array([ 1.15001373, -0.23318849])}
episode index:3028
target Thresh 1.9957812370558192
current state at start:  [-0.74739272  1.90594142]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.74739272,  1.90594142]), 'currentState': array([6.03579258, 1.73305437]), 'targetState': array([1.0342456 , 0.68788455]), 'effectorPosition': array([1.05458605, 0.75150133])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9317600419545361
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.74739272,  1.90594142]), 'currentState': array([6.03579258, 1.73305437]), 'targetState': array([1.0342456 , 0.68788455]), 'effectorPosition': array([1.05458605, 0.75150133])}
episode index:3029
target Thresh 1.9957896661498038
current state at start:  [-1.56437146  1.93349672]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.56437146,  1.93349672]), 'currentState': array([4.267362  , 2.43349672]), 'targetState': array([ 0.08289412, -0.56690901]), 'effectorPosition': array([ 0.48355293, -0.49696408])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.9317601427155766
{'reset': False, 'endBeforeDone': False, 'stepCount': 8, 'initial state': array([-1.56437146,  1.93349672]), 'currentState': array([3.78323973, 2.72996861]), 'targetState': array([ 0.08289412, -0.56690901]), 'effectorPosition': array([ 0.1725501 , -0.37051579])}
episode index:3030
target Thresh 1.9957980784024476
current state at start:  [ 0.51932827 -2.2455728 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.51932827, -2.2455728 ]), 'currentState': array([0.06033847, 3.5376125 ]), 'targetState': array([-0.1415995 , -0.79565029]), 'effectorPosition': array([ 0.10051692, -0.38038017])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9317793574490917
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.51932827, -2.2455728 ]), 'currentState': array([5.86374131, 4.01997591]), 'targetState': array([-0.1415995 , -0.79565029]), 'effectorPosition': array([ 0.01679261, -0.85025008])}
episode index:3031
target Thresh 1.9958064738473993
current state at start:  [ 2.2013263  -2.38796517]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.2013263 , -2.38796517]), 'currentState': array([2.12739282, 3.39522014]), 'targetState': array([-0.0064549 ,  0.11129519]), 'effectorPosition': array([0.1961421 , 0.15972191])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9318018576610148
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.2013263 , -2.38796517]), 'currentState': array([2.12739282, 3.39522014]), 'targetState': array([-0.0064549 ,  0.11129519]), 'effectorPosition': array([0.1961421 , 0.15972191])}
episode index:3032
target Thresh 1.9958148525182406
current state at start:  [ 4.34440138 -2.53200235]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.34440138, -2.53200235]), 'currentState': array([4.66777648, 3.25118296]), 'targetState': array([-0.01010536, -0.0368079 ]), 'effectorPosition': array([-0.10952979, -0.00111534])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9318243430360029
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.34440138, -2.53200235]), 'currentState': array([4.66777648, 3.25118296]), 'targetState': array([-0.01010536, -0.0368079 ]), 'effectorPosition': array([-0.10952979, -0.00111534])}
episode index:3033
target Thresh 1.9958232144484866
current state at start:  [ 3.28304765 -2.28141173]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.28304765, -2.28141173]), 'currentState': array([2.8576898 , 4.50153877]), 'targetState': array([-0.3482737 ,  1.20729502]), 'effectorPosition': array([-0.4851552 ,  1.16019038])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9318468135887267
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.28304765, -2.28141173]), 'currentState': array([2.8576898 , 4.50153877]), 'targetState': array([-0.3482737 ,  1.20729502]), 'effectorPosition': array([-0.4851552 ,  1.16019038])}
episode index:3034
target Thresh 1.9958315596715848
current state at start:  [-0.30417525  2.77551584]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.30417525,  2.77551584]), 'currentState': array([0.18609217, 2.27551584]), 'targetState': array([0.35812003, 1.23247434]), 'effectorPosition': array([0.20515239, 0.81380104])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.9318499876697192
{'reset': False, 'endBeforeDone': False, 'stepCount': 7, 'initial state': array([-0.30417525,  2.77551584]), 'currentState': array([0.50633533, 1.54275804]), 'targetState': array([0.35812003, 1.23247434]), 'effectorPosition': array([0.41425966, 1.37275568])}
episode index:3035
target Thresh 1.995839888220916
current state at start:  [1.04142756 2.21341988]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.04142756, 2.21341988]), 'currentState': array([1.54142756, 2.6982687 ]), 'targetState': array([-0.62179011,  0.23481192]), 'effectorPosition': array([-0.42592084,  0.10922321])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9318724349728582
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.04142756, 2.21341988]), 'currentState': array([1.54142756, 2.6982687 ]), 'targetState': array([-0.62179011,  0.23481192]), 'effectorPosition': array([-0.42592084,  0.10922321])}
episode index:3036
target Thresh 1.9958482001297948
current state at start:  [-2.67510667  2.22533658]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.67510667,  2.22533658]), 'currentState': array([3.2007455 , 2.71375507]), 'targetState': array([-0.08776854, -0.3902478 ]), 'effectorPosition': array([-0.06544882, -0.41950722])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9318948674934466
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.67510667,  2.22533658]), 'currentState': array([3.2007455 , 2.71375507]), 'targetState': array([-0.08776854, -0.3902478 ]), 'effectorPosition': array([-0.06544882, -0.41950722])}
episode index:3037
target Thresh 1.9958564954314684
current state at start:  [ 2.3780433  -2.41801892]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.3780433 , -2.41801892]), 'currentState': array([2.14557911, 3.3775978 ]), 'targetState': array([-0.13019071, -0.02821558]), 'effectorPosition': array([0.18117774, 0.15038288])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9319139936068458
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 2.3780433 , -2.41801892]), 'currentState': array([2.1858665 , 2.92586862]), 'targetState': array([-0.13019071, -0.02821558]), 'effectorPosition': array([-0.18819982, -0.10458246])}
episode index:3038
target Thresh 1.9958647741591182
current state at start:  [-3.08394502  2.7347258 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.08394502,  2.7347258 ]), 'currentState': array([3.61605676, 3.21044242]), 'targetState': array([ 0.23803063, -0.04761999]), 'effectorPosition': array([-0.03353749,  0.06011369])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9319331071331349
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.08394502,  2.7347258 ]), 'currentState': array([4.11605676, 2.7690385 ]), 'targetState': array([ 0.23803063, -0.04761999]), 'effectorPosition': array([ 0.26264414, -0.26118325])}
episode index:3039
target Thresh 1.9958730363458592
current state at start:  [0.45047393 2.69688641]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.45047393, 2.69688641]), 'currentState': array([0.06604171, 2.52841537]), 'targetState': array([0.32867759, 0.61893554]), 'effectorPosition': array([0.14380182, 0.58623681])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9319554975584201
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.45047393, 2.69688641]), 'currentState': array([0.06604171, 2.52841537]), 'targetState': array([0.32867759, 0.61893554]), 'effectorPosition': array([0.14380182, 0.58623681])}
episode index:3040
target Thresh 1.99588128202474
current state at start:  [ 4.12549093 -1.97217625]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.12549093, -1.97217625]), 'currentState': array([4.38353613, 4.01860923]), 'targetState': array([-0.62306078, -0.28233454]), 'effectorPosition': array([-0.84407844, -0.09293057])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9319745848660299
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 4.12549093, -1.97217625]), 'currentState': array([4.56843249, 3.83868355]), 'targetState': array([-0.62306078, -0.28233454]), 'effectorPosition': array([-0.66881661, -0.13877413])}
episode index:3041
target Thresh 1.9958895112287436
current state at start:  [0.62037235 2.17501973]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.62037235, 2.17501973]), 'currentState': array([0.93228507, 2.67501973]), 'targetState': array([-0.49338745,  0.21169499]), 'effectorPosition': array([-0.29750133,  0.35392472])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9319969469354362
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.62037235, 2.17501973]), 'currentState': array([0.93228507, 2.67501973]), 'targetState': array([-0.49338745,  0.21169499]), 'effectorPosition': array([-0.29750133,  0.35392472])}
episode index:3042
target Thresh 1.9958977239907865
current state at start:  [-1.1501231  -2.20796331]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.1501231 , -2.20796331]), 'currentState': array([4.70221618, 3.74556048]), 'targetState': array([0.06819167, 0.14619792]), 'effectorPosition': array([-0.56968308, -0.17112496])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9320095338736764
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-1.1501231 , -2.20796331]), 'currentState': array([4.66473262, 3.10909949]), 'targetState': array([0.06819167, 0.14619792]), 'effectorPosition': array([ 0.03242541, -0.0020749 ])}
episode index:3043
target Thresh 1.9959059203437197
current state at start:  [-0.5379971  -2.19068459]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.5379971 , -2.19068459]), 'currentState': array([5.36532811, 3.62587962]), 'targetState': array([ 0.03278264, -0.07651976]), 'effectorPosition': array([-0.29994805, -0.37418828])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9320189249630738
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([-0.5379971 , -2.19068459]), 'currentState': array([4.75186773, 2.93727435]), 'targetState': array([ 0.03278264, -0.07651976]), 'effectorPosition': array([ 0.20356255, -0.01277612])}
episode index:3044
target Thresh 1.9959141003203291
current state at start:  [0.20105823 2.59634278]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.20105823, 2.59634278]), 'currentState': array([6.21071216, 3.09634278]), 'targetState': array([-0.62219756, -0.20575496]), 'effectorPosition': array([0.00429633, 0.04504157])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.9320220320975362
{'reset': False, 'endBeforeDone': False, 'stepCount': 7, 'initial state': array([0.20105823, 2.59634278]), 'currentState': array([4.51926096, 3.86955976]), 'targetState': array([-0.62219756, -0.20575496]), 'effectorPosition': array([-0.7016323 , -0.12105802])}
episode index:3045
target Thresh 1.9959222639533343
current state at start:  [-1.44946605 -2.51712082]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.44946605, -2.51712082]), 'currentState': array([4.45012566, 4.18685709]), 'targetState': array([-0.58644641, -0.77886492]), 'effectorPosition': array([-0.96467693, -0.25700594])}
done in step count: 35
reward sum = 0.7034476949995692
running average episode reward sum: 0.9319469912777405
{'reset': False, 'endBeforeDone': False, 'stepCount': 36, 'initial state': array([-1.44946605, -2.51712082]), 'currentState': array([3.16864318, 2.01478648]), 'targetState': array([-0.58644641, -0.77886492]), 'effectorPosition': array([-0.54582028, -0.91814372])}
episode index:3046
target Thresh 1.9959304112753897
current state at start:  [0.6230499  2.47825994]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.6230499 , 2.47825994]), 'currentState': array([1.1230499 , 2.97825994]), 'targetState': array([-0.83421873,  0.03524853]), 'effectorPosition': array([-0.14081643,  0.0823957 ])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9319627946937964
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([0.6230499 , 2.47825994]), 'currentState': array([2.10927082, 2.01061099]), 'targetState': array([-0.83421873,  0.03524853]), 'effectorPosition': array([-1.07126954,  0.02894882])}
episode index:3047
target Thresh 1.995938542319085
current state at start:  [ 2.56896773 -2.98816283]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.56896773, -2.98816283]), 'currentState': array([2.11763015, 2.79502248]), 'targetState': array([-0.40978159, -0.48349852]), 'effectorPosition': array([-0.32105765, -0.125839  ])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9319785877401567
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 2.56896773, -2.98816283]), 'currentState': array([2.93147674, 2.53291194]), 'targetState': array([-0.40978159, -0.48349852]), 'effectorPosition': array([-0.29490619, -0.52175107])}
episode index:3048
target Thresh 1.995946657116944
current state at start:  [0.53613359 2.33167431]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.53613359, 2.33167431]), 'currentState': array([0.03613359, 2.76677141]), 'targetState': array([0.62161955, 0.05401624]), 'effectorPosition': array([0.05615575, 0.36837532])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9319879735788775
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([0.53613359, 2.33167431]), 'currentState': array([5.03326311, 2.60418495]), 'targetState': array([0.62161955, 0.05401624]), 'effectorPosition': array([0.53024163, 0.02768798])}
episode index:3049
target Thresh 1.995954755701426
current state at start:  [-2.88316317  2.35619201]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.88316317,  2.35619201]), 'currentState': array([2.95001797, 2.82857578]), 'targetState': array([-0.72011066,  0.09553531]), 'effectorPosition': array([-0.10633362, -0.29304494])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9320037480137698
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-2.88316317,  2.35619201]), 'currentState': array([2.02414234, 2.35069966]), 'targetState': array([-0.72011066,  0.09553531]), 'effectorPosition': array([-0.76914949, -0.04458321])}
episode index:3050
target Thresh 1.9959628381049255
current state at start:  [-2.08965925  2.58729207]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.08965925,  2.58729207]), 'currentState': array([4.69352606, 2.08729207]), 'targetState': array([ 1.25263234, -0.16225158]), 'effectorPosition': array([ 0.85985319, -0.5224753 ])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9320195121081606
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-2.08965925,  2.58729207]), 'currentState': array([5.14817053, 1.81133355]), 'targetState': array([ 1.25263234, -0.16225158]), 'effectorPosition': array([ 1.20200121, -0.28061406])}
episode index:3051
target Thresh 1.9959709043597722
current state at start:  [-0.63980142 -2.2154155 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.63980142, -2.2154155 ]), 'currentState': array([5.14338388, 3.67904959]), 'targetState': array([-0.01072979, -0.29105973]), 'effectorPosition': array([-0.40623462, -0.34197465])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.9320226119237873
{'reset': False, 'endBeforeDone': False, 'stepCount': 7, 'initial state': array([-0.63980142, -2.2154155 ]), 'currentState': array([3.70514732, 2.96445949]), 'targetState': array([-0.01072979, -0.29105973]), 'effectorPosition': array([ 0.08090207, -0.15731834])}
episode index:3052
target Thresh 1.9959789544982307
current state at start:  [-1.35615992  2.79020767]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.35615992,  2.79020767]), 'currentState': array([5.36531291, 3.15984558]), 'targetState': array([0.01283641, 0.76804237]), 'effectorPosition': array([-0.01439649, -0.01122056])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9320351492274481
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-1.35615992,  2.79020767]), 'currentState': array([0.49465687, 2.3993152 ]), 'targetState': array([0.01283641, 0.76804237]), 'effectorPosition': array([-0.0893667 ,  0.71982749])}
episode index:3053
target Thresh 1.995986988552502
current state at start:  [ 2.34401738 -1.97455724]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.34401738, -1.97455724]), 'currentState': array([2.49341018, 3.96596212]), 'targetState': array([0.59431731, 0.87383055]), 'effectorPosition': array([0.18733675, 0.77901539])}
done in step count: 32
reward sum = 0.7249803359578534
running average episode reward sum: 0.9319673513187153
{'reset': False, 'endBeforeDone': False, 'stepCount': 33, 'initial state': array([ 2.34401738, -1.97455724]), 'currentState': array([0.06799663, 1.88282359]), 'targetState': array([0.59431731, 0.87383055]), 'effectorPosition': array([0.62674646, 0.99660002])}
episode index:3054
target Thresh 1.995995006554722
current state at start:  [-0.3922726  -2.37810664]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.3922726 , -2.37810664]), 'currentState': array([5.45287996, 3.42204841]), 'targetState': array([0.35987001, 0.19261419]), 'effectorPosition': array([-0.17795273, -0.21557841])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9319831066865325
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-0.3922726 , -2.37810664]), 'currentState': array([4.94046285, 2.84252757]), 'targetState': array([0.35987001, 0.19261419]), 'effectorPosition': array([0.29703329, 0.02337748])}
episode index:3055
target Thresh 1.996003008536963
current state at start:  [ 2.34753203 -2.31167223]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.34753203, -2.31167223]), 'currentState': array([2.26826417, 3.48026593]), 'targetState': array([-0.18961544,  0.19309261]), 'effectorPosition': array([0.21816544, 0.2569266 ])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9319924695475644
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([ 2.34753203, -2.31167223]), 'currentState': array([1.19025014, 2.82785662]), 'targetState': array([-0.18961544,  0.19309261]), 'effectorPosition': array([-0.26840634,  0.15994875])}
episode index:3056
target Thresh 1.996010994531233
current state at start:  [-2.78176283  2.23458384]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.78176283,  2.23458384]), 'currentState': array([3.98077107, 2.73458384]), 'targetState': array([0.82041165, 0.00252268]), 'effectorPosition': array([ 0.23998478, -0.32525257])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9320050003066264
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-2.78176283,  2.23458384]), 'currentState': array([5.31620879, 2.22762739]), 'targetState': array([0.82041165, 0.00252268]), 'effectorPosition': array([0.87298813, 0.12911641])}
episode index:3057
target Thresh 1.9960189645694755
current state at start:  [ 1.53589742 -2.08723871]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.53589742, -2.08723871]), 'currentState': array([1.49615007, 3.6959466 ]), 'targetState': array([0.05705464, 0.15590881]), 'effectorPosition': array([0.53609683, 0.11008539])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9320239653163364
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.53589742, -2.08723871]), 'currentState': array([1.85080766, 3.1959466 ]), 'targetState': array([0.05705464, 0.15590881]), 'effectorPosition': array([0.05180313, 0.01643351])}
episode index:3058
target Thresh 1.996026918683571
current state at start:  [-1.19328071  2.87267045]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.19328071,  2.87267045]), 'currentState': array([4.61914672, 3.11183108]), 'targetState': array([-0.15431472, -0.06004359]), 'effectorPosition': array([ 0.02958669, -0.00321153])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9320461869687338
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.19328071,  2.87267045]), 'currentState': array([4.61914672, 3.11183108]), 'targetState': array([-0.15431472, -0.06004359]), 'effectorPosition': array([ 0.02958669, -0.00321153])}
episode index:3059
target Thresh 1.996034856905336
current state at start:  [0.78272393 2.97050175]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.78272393, 2.97050175]), 'currentState': array([0.28272393, 2.47050175]), 'targetState': array([0.25075682, 1.10665112]), 'effectorPosition': array([0.03477041, 0.65764998])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9320555169762602
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([0.78272393, 2.97050175]), 'currentState': array([0.39397371, 1.80927342]), 'targetState': array([0.25075682, 1.10665112]), 'effectorPosition': array([0.3322677 , 1.19044193])}
episode index:3060
target Thresh 1.9960427792665234
current state at start:  [ 1.87904604 -2.01383206]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.87904604, -2.01383206]), 'currentState': array([2.2386251 , 3.76935325]), 'targetState': array([0.12604194, 0.69269579]), 'effectorPosition': array([0.34308631, 0.51342201])}
done in step count: 20
reward sum = 0.8179069375972308
running average episode reward sum: 0.9320182257056366
{'reset': False, 'endBeforeDone': False, 'stepCount': 21, 'initial state': array([ 1.87904604, -2.01383206]), 'currentState': array([0.28003358, 2.33921535]), 'targetState': array([0.12604194, 0.69269579]), 'effectorPosition': array([0.09439391, 0.77530062])}
episode index:3061
target Thresh 1.9960506857988225
current state at start:  [-4.12202017  2.95709931]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.12202017,  2.95709931]), 'currentState': array([1.78865893, 3.18212413]), 'targetState': array([0.04238826, 0.13282744]), 'effectorPosition': array([0.03938503, 0.00956008])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9320404274607949
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.12202017,  2.95709931]), 'currentState': array([1.78865893, 3.18212413]), 'targetState': array([0.04238826, 0.13282744]), 'effectorPosition': array([0.03938503, 0.00956008])}
episode index:3062
target Thresh 1.9960585765338597
current state at start:  [ 1.79074623 -2.11336318]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.79074623, -2.11336318]), 'currentState': array([1.37840288, 3.67257729]), 'targetState': array([ 0.23140449, -0.20767703]), 'effectorPosition': array([0.52336733, 0.03832585])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9320529180166353
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 1.79074623, -2.11336318]), 'currentState': array([1.64183039, 3.35119325]), 'targetState': array([ 0.23140449, -0.20767703]), 'effectorPosition': array([0.20599119, 0.03659829])}
episode index:3063
target Thresh 1.9960664515031976
current state at start:  [0.72558701 1.76237023]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.72558701, 1.76237023]), 'currentState': array([1.22558701, 1.84040003]), 'targetState': array([-0.62709645,  1.17206234]), 'effectorPosition': array([-0.6587496 ,  1.01653824])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9320750939572303
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.72558701, 1.76237023]), 'currentState': array([1.22558701, 1.84040003]), 'targetState': array([-0.62709645,  1.17206234]), 'effectorPosition': array([-0.6587496 ,  1.01653824])}
episode index:3064
target Thresh 1.9960743107383363
current state at start:  [-1.24308841  2.28285342]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.24308841,  2.28285342]), 'currentState': array([5.14957978, 2.72289389]), 'targetState': array([0.15772563, 0.366375  ]), 'effectorPosition': array([0.40490518, 0.09388439])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9320907627683374
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.24308841,  2.28285342]), 'currentState': array([5.89540159, 2.69918354]), 'targetState': array([0.15772563, 0.366375  ]), 'effectorPosition': array([0.25101594, 0.35992387])}
episode index:3065
target Thresh 1.9960821542707128
current state at start:  [-1.00502889  2.13596925]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.00502889,  2.13596925]), 'currentState': array([5.76823427, 2.63596925]), 'targetState': array([0.11833055, 0.83995137]), 'effectorPosition': array([0.34744046, 0.35991629])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9321096503212505
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.00502889,  2.13596925]), 'currentState': array([6.26823427, 2.31803295]), 'targetState': array([0.11833055, 0.83995137]), 'effectorPosition': array([0.33131718, 0.72869779])}
episode index:3066
target Thresh 1.996089982131701
current state at start:  [ 3.34889242 -2.20086964]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.34889242, -2.20086964]), 'currentState': array([3.84889242, 3.64588092]), 'targetState': array([-0.21059259,  0.15454133]), 'effectorPosition': array([-0.40858605,  0.28639179])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9321317860726944
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.34889242, -2.20086964]), 'currentState': array([3.84889242, 3.64588092]), 'targetState': array([-0.21059259,  0.15454133]), 'effectorPosition': array([-0.40858605,  0.28639179])}
episode index:3067
target Thresh 1.9960977943526126
current state at start:  [ 1.73282936 -2.75635112]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.73282936, -2.75635112]), 'currentState': array([1.62404312, 4.02683418]), 'targetState': array([ 1.21232943, -0.54731277]), 'effectorPosition': array([0.75344397, 0.40757461])}
done in step count: 18
reward sum = 0.8345137614500875
running average episode reward sum: 0.9320999679421135
{'reset': False, 'endBeforeDone': False, 'stepCount': 19, 'initial state': array([ 1.73282936, -2.75635112]), 'currentState': array([4.8200709 , 1.77886007]), 'targetState': array([ 1.21232943, -0.54731277]), 'effectorPosition': array([ 1.05803903, -0.68368254])}
episode index:3068
target Thresh 1.9961055909646965
current state at start:  [ 1.07345394 -1.96322532]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.07345394, -1.96322532]), 'currentState': array([0.91971446, 3.86355289]), 'targetState': array([ 0.84103505, -0.22220531]), 'effectorPosition': array([ 0.67686635, -0.20206058])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9321220924230706
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.07345394, -1.96322532]), 'currentState': array([0.91971446, 3.86355289]), 'targetState': array([ 0.84103505, -0.22220531]), 'effectorPosition': array([ 0.67686635, -0.20206058])}
episode index:3069
target Thresh 1.996113371999139
current state at start:  [-1.3615863  -2.09444204]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.3615863 , -2.09444204]), 'currentState': array([4.53883615, 3.7359241 ]), 'targetState': array([0.06977919, 0.21916967]), 'effectorPosition': array([-0.58115416, -0.0722063 ])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9321377204059949
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.3615863 , -2.09444204]), 'currentState': array([5.09182438, 2.9043116 ]), 'targetState': array([0.06977919, 0.21916967]), 'effectorPosition': array([0.22872003, 0.06103917])}
episode index:3070
target Thresh 1.9961211374870642
current state at start:  [-0.10702331  1.71067787]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.10702331,  1.71067787]), 'currentState': array([0.39297669, 2.02693761]), 'targetState': array([0.09216502, 1.24869133]), 'effectorPosition': array([0.17307528, 1.04358543])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9321598181850876
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.10702331,  1.71067787]), 'currentState': array([0.39297669, 2.02693761]), 'targetState': array([0.09216502, 1.24869133]), 'effectorPosition': array([0.17307528, 1.04358543])}
episode index:3071
target Thresh 1.9961288874595344
current state at start:  [-1.31648425 -2.4355438 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.31648425, -2.4355438 ]), 'currentState': array([4.6048283 , 4.34764151]), 'targetState': array([ 0.34419753, -0.93981044]), 'effectorPosition': array([-0.99787399, -0.53927797])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9318563807442722
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([-1.31648425, -2.4355438 ]), 'currentState': array([3.88713728, 5.01540789]), 'targetState': array([ 0.34419753, -0.93981044]), 'effectorPosition': array([-1.60142614, -0.1795555 ])}
episode index:3072
target Thresh 1.9961366219475492
current state at start:  [0.77911156 2.90684223]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.77911156, 2.90684223]), 'currentState': array([0.61983443, 3.40684223]), 'targetState': array([-0.02353351, -0.04994188]), 'effectorPosition': array([ 0.18075017, -0.19306779])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9318785556935907
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.77911156, 2.90684223]), 'currentState': array([0.61983443, 3.40684223]), 'targetState': array([-0.02353351, -0.04994188]), 'effectorPosition': array([ 0.18075017, -0.19306779])}
episode index:3073
target Thresh 1.9961443409820465
current state at start:  [-1.05872851 -1.72375328]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.05872851, -1.72375328]), 'currentState': array([4.7244568 , 4.49476384]), 'targetState': array([ 0.54495136, -0.67934388]), 'effectorPosition': array([-0.96687985, -0.79581441])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.931878616458787
{'reset': False, 'endBeforeDone': False, 'stepCount': 8, 'initial state': array([-1.05872851, -1.72375328]), 'currentState': array([4.39348508, 2.05810352]), 'targetState': array([ 0.54495136, -0.67934388]), 'effectorPosition': array([ 0.67232773, -0.78197119])}
episode index:3074
target Thresh 1.9961520445939027
current state at start:  [-3.60283963  2.85311292]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.60283963,  2.85311292]), 'currentState': array([3.12139138, 2.43415527]), 'targetState': array([ 0.62582896, -0.77371539]), 'effectorPosition': array([-0.25304893, -0.64490826])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.931891110892459
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-3.60283963,  2.85311292]), 'currentState': array([4.43932142, 2.23119463]), 'targetState': array([ 0.62582896, -0.77371539]), 'effectorPosition': array([ 0.65623399, -0.58522991])}
episode index:3075
target Thresh 1.9961597328139322
current state at start:  [ 2.06005149 -1.88931817]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.06005149, -1.88931817]), 'currentState': array([1.8421759 , 3.89386713]), 'targetState': array([0.50193541, 0.36338027]), 'effectorPosition': array([0.58595396, 0.44315319])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9319132529240284
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.06005149, -1.88931817]), 'currentState': array([1.8421759 , 3.89386713]), 'targetState': array([0.50193541, 0.36338027]), 'effectorPosition': array([0.58595396, 0.44315319])}
episode index:3076
target Thresh 1.9961674056728878
current state at start:  [-2.14755991 -1.65301438]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.14755991, -1.65301438]), 'currentState': array([3.66271219, 4.88202061]), 'targetState': array([-1.26224881,  0.40633289]), 'effectorPosition': array([-1.5043787 ,  0.27291627])}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9319043055148912
{'reset': False, 'endBeforeDone': False, 'stepCount': 11, 'initial state': array([-2.14755991, -1.65301438]), 'currentState': array([2.20425703, 1.46869994]), 'targetState': array([-1.26224881,  0.40633289]), 'effectorPosition': array([-1.45405413,  0.29927381])}
episode index:3077
target Thresh 1.9961750632014608
current state at start:  [-1.70199073  2.17330605]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.70199073,  2.17330605]), 'currentState': array([5.08119458, 2.57647822]), 'targetState': array([0.93471798, 0.04306947]), 'effectorPosition': array([0.555552  , 0.04803463])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9319231800095257
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.70199073,  2.17330605]), 'currentState': array([5.36306408, 2.10521398]), 'targetState': array([0.93471798, 0.04306947]), 'effectorPosition': array([0.98193482, 0.13085891])}
episode index:3078
target Thresh 1.9961827054302816
current state at start:  [-1.77442892  2.21772023]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.77442892,  2.21772023]), 'currentState': array([4.0766878 , 2.67431717]), 'targetState': array([ 0.0418235 , -0.20754824]), 'effectorPosition': array([ 0.29881174, -0.35371428])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9319420422440142
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.77442892,  2.21772023]), 'currentState': array([3.79754426, 3.03879182]), 'targetState': array([ 0.0418235 , -0.20754824]), 'effectorPosition': array([ 0.05840553, -0.08454289])}
episode index:3079
target Thresh 1.996190332389919
current state at start:  [ 4.21669758 -2.40351657]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.21669758, -2.40351657]), 'currentState': array([4.61196364, 3.37966874]), 'targetState': array([0.15074828, 0.17783732]), 'effectorPosition': array([-0.23747309, -0.00442053])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9319608922302987
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 4.21669758, -2.40351657]), 'currentState': array([4.8629461 , 2.87966874]), 'targetState': array([0.15074828, 0.17783732]), 'effectorPosition': array([0.2611257 , 0.00511746])}
episode index:3080
target Thresh 1.996197944110881
current state at start:  [-2.13715571 -1.68907191]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.13715571, -1.68907191]), 'currentState': array([4.07418575, 4.0941134 ]), 'targetState': array([-0.4307748 , -0.12153937]), 'effectorPosition': array([-0.90492079,  0.14784012])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9319797299803049
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.13715571, -1.68907191]), 'currentState': array([4.51971664, 3.5941134 ]), 'targetState': array([-0.4307748 , -0.12153937]), 'effectorPosition': array([-0.44841652, -0.01506709])}
episode index:3081
target Thresh 1.9962055406236145
current state at start:  [-1.56633295 -2.84456454]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.56633295, -2.84456454]), 'currentState': array([4.76198305, 2.93862076]), 'targetState': array([0.60319698, 0.79537191]), 'effectorPosition': array([ 0.20235091, -0.0105098 ])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9319921632282023
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-1.56633295, -2.84456454]), 'currentState': array([6.24246735, 1.92156543]), 'targetState': array([0.60319698, 0.79537191]), 'effectorPosition': array([0.69406379, 0.91161126])}
episode index:3082
target Thresh 1.9962131219585053
current state at start:  [-3.95734538  2.84609725]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.95734538,  2.84609725]), 'currentState': array([2.15041742, 2.34609725]), 'targetState': array([-0.76295387, -0.17252772]), 'effectorPosition': array([-0.76190849, -0.14011925])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9320142222086667
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.95734538,  2.84609725]), 'currentState': array([2.15041742, 2.34609725]), 'targetState': array([-0.76295387, -0.17252772]), 'effectorPosition': array([-0.76190849, -0.14011925])}
episode index:3083
target Thresh 1.9962206881458788
current state at start:  [-2.29287523  2.59412351]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.29287523,  2.59412351]), 'currentState': array([4.3409116 , 2.09412351]), 'targetState': array([ 0.28964947, -0.96419192]), 'effectorPosition': array([ 0.62550052, -0.78052518])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9320298142248119
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-2.29287523,  2.59412351]), 'currentState': array([3.69822738, 2.19005018]), 'targetState': array([ 0.28964947, -0.96419192]), 'effectorPosition': array([ 0.07399416, -0.91305499])}
episode index:3084
target Thresh 1.9962282392159998
current state at start:  [-0.02069256  2.5834523 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.02069256,  2.5834523 ]), 'currentState': array([0.02654776, 2.09749003]), 'targetState': array([0.39884742, 0.69976814]), 'effectorPosition': array([0.47419972, 0.87737042])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9320518466999416
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.02069256,  2.5834523 ]), 'currentState': array([0.02654776, 2.09749003]), 'targetState': array([0.39884742, 0.69976814]), 'effectorPosition': array([0.47419972, 0.87737042])}
episode index:3085
target Thresh 1.9962357751990727
current state at start:  [1.01112013 1.85889106]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.01112013, 1.85889106]), 'currentState': array([0.86509716, 2.32158976]), 'targetState': array([-0.2592296 ,  0.46479601]), 'effectorPosition': array([-0.35041726,  0.7160793 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9320706244553855
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.01112013, 1.85889106]), 'currentState': array([0.88652905, 2.75672959]), 'targetState': array([-0.2592296 ,  0.46479601]), 'effectorPosition': array([-0.24467722,  0.2939955 ])}
episode index:3086
target Thresh 1.9962432961252414
current state at start:  [ 0.81697225 -1.93512143]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.81697225, -1.93512143]), 'currentState': array([1.23119476, 3.86215864]), 'targetState': array([0.89728966, 0.14462098]), 'effectorPosition': array([0.70492736, 0.01458099])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9320926294361256
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.81697225, -1.93512143]), 'currentState': array([1.23119476, 3.86215864]), 'targetState': array([0.89728966, 0.14462098]), 'effectorPosition': array([0.70492736, 0.01458099])}
episode index:3087
target Thresh 1.9962508020245897
current state at start:  [-0.54582743  1.74629954]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.54582743,  1.74629954]), 'currentState': array([6.16557249, 2.07482667]), 'targetState': array([0.54469774, 1.24830114]), 'effectorPosition': array([0.61621907, 0.80892329])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9321113818229662
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.54582743,  1.74629954]), 'currentState': array([0.29474237, 1.57482667]), 'targetState': array([0.54469774, 1.24830114]), 'effectorPosition': array([0.66252951, 1.2461918 ])}
episode index:3088
target Thresh 1.996258292927141
current state at start:  [ 1.63391661 -2.74616481]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.63391661, -2.74616481]), 'currentState': array([1.84893121, 3.31176903]), 'targetState': array([0.05520821, 0.72528613]), 'effectorPosition': array([0.15888161, 0.06038884])}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9321083495512292
{'reset': False, 'endBeforeDone': False, 'stepCount': 9, 'initial state': array([ 1.63391661, -2.74616481]), 'currentState': array([0.46902885, 2.37155886]), 'targetState': array([0.05520821, 0.72528613]), 'effectorPosition': array([-0.06303134,  0.74850035])}
episode index:3089
target Thresh 1.9962657688628591
current state at start:  [2.00140566 1.78206032]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.00140566, 1.78206032]), 'currentState': array([1.56292766, 2.25065654]), 'targetState': array([-0.44832408,  0.5582197 ]), 'effectorPosition': array([-0.7747148 ,  0.37742326])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9321270847131867
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([2.00140566, 1.78206032]), 'currentState': array([1.14276704, 2.33912025]), 'targetState': array([-0.44832408,  0.5582197 ]), 'effectorPosition': array([-0.52757769,  0.57602067])}
episode index:3090
target Thresh 1.9962732298616475
current state at start:  [1.32030592 2.4768125 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.32030592, 2.4768125 ]), 'currentState': array([1.22681862, 2.9768125 ]), 'targetState': array([-0.03249995,  0.03853236]), 'effectorPosition': array([-0.14985835,  0.06807048])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9321490429517136
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.32030592, 2.4768125 ]), 'currentState': array([1.22681862, 2.9768125 ]), 'targetState': array([-0.03249995,  0.03853236]), 'effectorPosition': array([-0.14985835,  0.06807048])}
episode index:3091
target Thresh 1.9962806759533505
current state at start:  [-2.75634406  2.17233259]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.75634406,  2.17233259]), 'currentState': array([3.06155014, 2.67233259]), 'targetState': array([-0.01180133,  0.03809281]), 'effectorPosition': array([-0.14390946, -0.44213546])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9321677528343295
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.75634406,  2.17233259]), 'currentState': array([2.6109181 , 3.17233259]), 'targetState': array([-0.01180133,  0.03809281]), 'effectorPosition': array([0.01514804, 0.02674708])}
episode index:3092
target Thresh 1.9962881071677523
current state at start:  [ 3.38723789 -2.2148441 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.38723789, -2.2148441 ]), 'currentState': array([2.97758333, 4.48275305]), 'targetState': array([-0.78537559,  0.88028437]), 'effectorPosition': array([-0.60302318,  1.08679207])}
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.932155845463306
{'reset': False, 'endBeforeDone': False, 'stepCount': 12, 'initial state': array([ 3.38723789, -2.2148441 ]), 'currentState': array([1.5627855 , 1.79858529]), 'targetState': array([-0.78537559,  0.88028437]), 'effectorPosition': array([-0.9679351 ,  0.78195481])}
episode index:3093
target Thresh 1.9962955235345778
current state at start:  [-0.14206912  2.39445628]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.14206912,  2.39445628]), 'currentState': array([5.66429193, 2.89445628]), 'targetState': array([ 0.86842097, -0.32793182]), 'effectorPosition': array([0.16666491, 0.18162865])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.9321558162139342
{'reset': False, 'endBeforeDone': False, 'stepCount': 8, 'initial state': array([-0.14206912,  2.39445628]), 'currentState': array([4.7641653 , 1.98835238]), 'targetState': array([ 0.86842097, -0.32793182]), 'effectorPosition': array([ 0.94362364, -0.54636896])}
episode index:3094
target Thresh 1.9963029250834927
current state at start:  [-1.54741051 -1.75163257]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.54741051, -1.75163257]), 'currentState': array([4.31279067, 4.77418684]), 'targetState': array([-0.33087656, -0.76910698]), 'effectorPosition': array([-1.33253424, -0.5898047 ])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9318546350132189
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([-1.54741051, -1.75163257]), 'currentState': array([3.92525448, 4.84871987]), 'targetState': array([-0.33087656, -0.76910698]), 'effectorPosition': array([-1.5039307 , -0.10005198])}
episode index:3095
target Thresh 1.9963103118441028
current state at start:  [0.77501548 2.22787322]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.77501548, 2.22787322]), 'currentState': array([1.21968907, 2.65803631]), 'targetState': array([-1.12239862,  0.14703456]), 'effectorPosition': array([-0.39713296,  0.26756544])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9318702181414447
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([0.77501548, 2.22787322]), 'currentState': array([2.14723209, 1.77131815]), 'targetState': array([-1.12239862,  0.14703456]), 'effectorPosition': array([-1.25808902,  0.13729734])}
episode index:3096
target Thresh 1.9963176838459553
current state at start:  [-1.32534331 -1.7478124 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.32534331, -1.7478124 ]), 'currentState': array([4.46257145, 4.96304115]), 'targetState': array([-1.34099952, -0.29989953]), 'effectorPosition': array([-1.24722681, -0.96979219])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.9318763918036206
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([-1.32534331, -1.7478124 ]), 'currentState': array([4.02512657, 4.85945721]), 'targetState': array([-1.34099952, -0.29989953]), 'effectorPosition': array([-1.49203227, -0.25868317])}
episode index:3097
target Thresh 1.9963250411185385
current state at start:  [-3.96907456  2.42521143]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.96907456,  2.42521143]), 'currentState': array([2.81411075, 2.35128688]), 'targetState': array([-0.47099828, -0.64387679]), 'effectorPosition': array([-0.50918263, -0.57747459])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.931898381347906
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.96907456,  2.42521143]), 'currentState': array([2.81411075, 2.35128688]), 'targetState': array([-0.47099828, -0.64387679]), 'effectorPosition': array([-0.50918263, -0.57747459])}
episode index:3098
target Thresh 1.9963323836912812
current state at start:  [ 1.90045266 -2.34572804]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.90045266, -2.34572804]), 'currentState': array([1.51330601, 3.48677415]), 'targetState': array([1.01270588, 0.0676796 ]), 'effectorPosition': array([0.3411977 , 0.03944635])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9319139352745444
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 1.90045266, -2.34572804]), 'currentState': array([1.25824464, 4.17228964]), 'targetState': array([1.01270588, 0.0676796 ]), 'effectorPosition': array([0.96547686, 0.19852466])}
episode index:3099
target Thresh 1.9963397115935537
current state at start:  [ 2.64043531 -2.52737587]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.64043531, -2.52737587]), 'currentState': array([2.46325991, 3.25580943]), 'targetState': array([-0.11200004,  0.47731656]), 'effectorPosition': array([0.0664416 , 0.09282678])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.9319200888599075
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([ 2.64043531, -2.52737587]), 'currentState': array([0.64629581, 2.81855648]), 'targetState': array([-0.11200004,  0.47731656]), 'effectorPosition': array([-0.14988495,  0.28457437])}
episode index:3100
target Thresh 1.9963470248546678
current state at start:  [-0.51911821 -2.48791927]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.51911821, -2.48791927]), 'currentState': array([5.33419718, 3.58895283]), 'targetState': array([ 0.15999099, -0.22582194]), 'effectorPosition': array([-0.29429506, -0.33197294])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.931923171755922
{'reset': False, 'endBeforeDone': False, 'stepCount': 7, 'initial state': array([-0.51911821, -2.48791927]), 'currentState': array([4.08494187, 2.94159757]), 'targetState': array([ 0.15999099, -0.22582194]), 'effectorPosition': array([ 0.14912272, -0.13276786])}
episode index:3101
target Thresh 1.9963543235038763
current state at start:  [ 1.7477853  -2.33009379]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.7477853 , -2.33009379]), 'currentState': array([1.32633147, 3.45309152]), 'targetState': array([ 0.9351032 , -0.31221107]), 'effectorPosition': array([ 0.30902095, -0.02748707])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9319387026483282
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 1.7477853 , -2.33009379]), 'currentState': array([0.6337861, 4.169174 ]), 'targetState': array([ 0.9351032 , -0.31221107]), 'effectorPosition': array([ 0.89623851, -0.40370144])}
episode index:3102
target Thresh 1.996361607570374
current state at start:  [-3.2325638  2.7493389]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.2325638,  2.7493389]), 'currentState': array([2.55062151, 2.2493389 ]), 'targetState': array([-0.94970028, -0.37132268]), 'effectorPosition': array([-0.74294043, -0.43900035])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9319606366790572
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.2325638,  2.7493389]), 'currentState': array([2.55062151, 2.2493389 ]), 'targetState': array([-0.94970028, -0.37132268]), 'effectorPosition': array([-0.74294043, -0.43900035])}
episode index:3103
target Thresh 1.9963688770832972
current state at start:  [ 0.29260836 -1.78739689]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.29260836, -1.78739689]), 'currentState': array([0.30111511, 3.99578842]), 'targetState': array([ 0.9042638, -0.5819955]), 'effectorPosition': array([ 0.55137223, -0.61833515])}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9319576676254968
{'reset': False, 'endBeforeDone': False, 'stepCount': 9, 'initial state': array([ 0.29260836, -1.78739689]), 'currentState': array([4.58786865, 2.08502647]), 'targetState': array([ 0.9042638, -0.5819955]), 'effectorPosition': array([ 0.80082056, -0.61233735])}
episode index:3104
target Thresh 1.9963761320717237
current state at start:  [-2.01200892  1.98787223]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.01200892,  1.98787223]), 'currentState': array([3.77117639, 2.48787223]), 'targetState': array([-0.07186143, -0.1066761 ]), 'effectorPosition': array([ 0.19143605, -0.6129427 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9319763608082261
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.01200892,  1.98787223]), 'currentState': array([3.28684273, 2.98787223]), 'targetState': array([-0.07186143, -0.1066761 ]), 'effectorPosition': array([ 0.01049439, -0.15321012])}
episode index:3105
target Thresh 1.9963833725646738
current state at start:  [-0.91825078  2.45166675]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.91825078,  2.45166675]), 'currentState': array([4.86493453, 2.76904065]), 'targetState': array([ 0.17271637, -0.13288673]), 'effectorPosition': array([ 0.37019053, -0.01249143])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9319982615291507
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.91825078,  2.45166675]), 'currentState': array([4.86493453, 2.76904065]), 'targetState': array([ 0.17271637, -0.13288673]), 'effectorPosition': array([ 0.37019053, -0.01249143])}
episode index:3106
target Thresh 1.9963905985911095
current state at start:  [1.20461771 2.2887783 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.20461771, 2.2887783 ]), 'currentState': array([0.70461771, 1.95966803]), 'targetState': array([0.05290607, 1.21107347]), 'effectorPosition': array([-0.12637608,  1.10713138])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9320201481524113
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.20461771, 2.2887783 ]), 'currentState': array([0.70461771, 1.95966803]), 'targetState': array([0.05290607, 1.21107347]), 'effectorPosition': array([-0.12637608,  1.10713138])}
episode index:3107
target Thresh 1.9963978101799345
current state at start:  [-0.43746108  2.26297006]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.43746108,  2.26297006]), 'currentState': array([6.11643392, 2.76297006]), 'targetState': array([-0.3159235 ,  0.52590917]), 'effectorPosition': array([0.13119582, 0.35275817])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.932035617860213
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-0.43746108,  2.26297006]), 'currentState': array([0.65678954, 2.63183316]), 'targetState': array([-0.3159235 ,  0.52590917]), 'effectorPosition': array([-0.197254  ,  0.46407658])}
episode index:3108
target Thresh 1.9964050073599955
current state at start:  [ 2.90929023 -2.58055513]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.90929023, -2.58055513]), 'currentState': array([2.40929023, 3.27493108]), 'targetState': array([-0.76823535,  0.5035022 ]), 'effectorPosition': array([0.08228313, 0.10479646])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9320510776164498
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 2.90929023, -2.58055513]), 'currentState': array([1.40929023, 2.4198708 ]), 'targetState': array([-0.76823535,  0.5035022 ]), 'effectorPosition': array([-0.61198666,  0.35232629])}
episode index:3109
target Thresh 1.996412190160081
current state at start:  [ 3.04257011 -1.84343591]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.04257011, -1.84343591]), 'currentState': array([3.18294891, 3.9816934 ]), 'targetState': array([-0.16345875,  0.45158947]), 'effectorPosition': array([-0.36311745,  0.73032192])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9320697107104637
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.04257011, -1.84343591]), 'currentState': array([3.07082616, 3.51258863]), 'targetState': array([-0.16345875,  0.45158947]), 'effectorPosition': array([-0.04222845,  0.36644687])}
episode index:3110
target Thresh 1.9964193586089227
current state at start:  [ 2.70289035 -2.54774911]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.70289035, -2.54774911]), 'currentState': array([2.52061015, 3.2571518 ]), 'targetState': array([ 0.15970831, -0.00406723]), 'effectorPosition': array([0.06166238, 0.09765661])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9320915462261466
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.70289035, -2.54774911]), 'currentState': array([2.52061015, 3.2571518 ]), 'targetState': array([ 0.15970831, -0.00406723]), 'effectorPosition': array([0.06166238, 0.09765661])}
episode index:3111
target Thresh 1.996426512735194
current state at start:  [ 0.43335969 -1.83141095]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.43335969, -1.83141095]), 'currentState': array([0.9000156 , 3.98025346]), 'targetState': array([1.08594063, 0.31909337]), 'effectorPosition': array([ 0.78869036, -0.2026046 ])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9321069731071794
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 0.43335969, -1.83141095]), 'currentState': array([1.24823314, 4.24292956]), 'targetState': array([1.08594063, 0.31909337]), 'effectorPosition': array([1.0194057 , 0.23665058])}
episode index:3112
target Thresh 1.9964336525675113
current state at start:  [-3.8962675   2.39993207]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.8962675 ,  2.39993207]), 'currentState': array([1.88691781, 2.4023616 ]), 'targetState': array([-0.92708546,  0.21085336]), 'effectorPosition': array([-0.72148037,  0.03863176])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9321223900769491
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-3.8962675 ,  2.39993207]), 'currentState': array([1.95469948, 2.16448141]), 'targetState': array([-0.92708546,  0.21085336]), 'effectorPosition': array([-0.93356624,  0.09805825])}
episode index:3113
target Thresh 1.996440778134434
current state at start:  [-1.83958573  2.3931152 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.83958573,  2.3931152 ]), 'currentState': array([4.77257025, 2.28368444]), 'targetState': array([ 0.69424043, -0.44148701]), 'effectorPosition': array([ 0.77591554, -0.29985415])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9321441876395448
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.83958573,  2.3931152 ]), 'currentState': array([4.77257025, 2.28368444]), 'targetState': array([ 0.69424043, -0.44148701]), 'effectorPosition': array([ 0.77591554, -0.29985415])}
episode index:3114
target Thresh 1.9964478894644648
current state at start:  [0.15838665 2.08035858]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.15838665, 2.08035858]), 'currentState': array([0.20010865, 2.58035858]), 'targetState': array([-0.01012137,  0.52585127]), 'effectorPosition': array([0.04454521, 0.5521031 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9321659712069158
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.15838665, 2.08035858]), 'currentState': array([0.20010865, 2.58035858]), 'targetState': array([-0.01012137,  0.52585127]), 'effectorPosition': array([0.04454521, 0.5521031 ])}
episode index:3115
target Thresh 1.9964549865860486
current state at start:  [ 2.78683362 -2.55596481]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.78683362, -2.55596481]), 'currentState': array([2.28683362, 4.2272205 ]), 'targetState': array([0.37033098, 0.85424942]), 'effectorPosition': array([0.31706764, 0.98323614])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9321877407925361
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.78683362, -2.55596481]), 'currentState': array([2.28683362, 4.2272205 ]), 'targetState': array([0.37033098, 0.85424942]), 'effectorPosition': array([0.31706764, 0.98323614])}
episode index:3116
target Thresh 1.9964620695275739
current state at start:  [-0.41088071  2.68340459]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.41088071,  2.68340459]), 'currentState': array([5.3723046 , 3.18340459]), 'targetState': array([ 0.3333197 , -0.45909504]), 'effectorPosition': array([-0.03248784, -0.02631584])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.9321937729738347
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([-0.41088071,  2.68340459]), 'currentState': array([4.37093819, 2.37133691]), 'targetState': array([ 0.3333197 , -0.45909504]), 'effectorPosition': array([ 0.56160173, -0.49913752])}
episode index:3117
target Thresh 1.9964691383173727
current state at start:  [1.20725689 1.99658441]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.20725689, 1.99658441]), 'currentState': array([1.59310919, 2.49658441]), 'targetState': array([-0.72799773,  0.04144233]), 'effectorPosition': array([-0.60553778,  0.18744169])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9322155196791029
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.20725689, 1.99658441]), 'currentState': array([1.59310919, 2.49658441]), 'targetState': array([-0.72799773,  0.04144233]), 'effectorPosition': array([-0.60553778,  0.18744169])}
episode index:3118
target Thresh 1.99647619298372
current state at start:  [-0.79012518  1.92680422]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.79012518,  1.92680422]), 'currentState': array([5.94515087, 1.75908261]), 'targetState': array([1.0373577, 0.7240031]), 'effectorPosition': array([1.09259744, 0.65717528])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9322372524397059
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.79012518,  1.92680422]), 'currentState': array([5.94515087, 1.75908261]), 'targetState': array([1.0373577, 0.7240031]), 'effectorPosition': array([1.09259744, 0.65717528])}
episode index:3119
target Thresh 1.9964832335548346
current state at start:  [-0.9373731   1.85851608]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.9373731 ,  1.85851608]), 'currentState': array([5.79241181, 2.22581066]), 'targetState': array([0.85311726, 0.64362829]), 'effectorPosition': array([0.71846514, 0.51523453])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9322589712690521
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.9373731 ,  1.85851608]), 'currentState': array([5.79241181, 2.22581066]), 'targetState': array([0.85311726, 0.64362829]), 'effectorPosition': array([0.71846514, 0.51523453])}
episode index:3120
target Thresh 1.9964902600588788
current state at start:  [-0.68926434 -2.92289116]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.68926434, -2.92289116]), 'currentState': array([5.09392097, 3.86029415]), 'targetState': array([-0.1552997, -0.3836932]), 'effectorPosition': array([-0.5189705 , -0.47470728])}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.9322529662309921
{'reset': False, 'endBeforeDone': False, 'stepCount': 10, 'initial state': array([-0.68926434, -2.92289116]), 'currentState': array([2.97344017, 2.78997064]), 'targetState': array([-0.1552997, -0.3836932]), 'effectorPosition': array([-0.11796445, -0.32932325])}
episode index:3121
target Thresh 1.9964972725239585
current state at start:  [0.93428691 1.73043488]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.93428691, 1.73043488]), 'currentState': array([0.46417461, 2.19277947]), 'targetState': array([0.26926862, 1.00925867]), 'effectorPosition': array([0.00934799, 0.91357348])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9322651526607707
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([0.93428691, 1.73043488]), 'currentState': array([0.20018941, 2.01349951]), 'targetState': array([0.26926862, 1.00925867]), 'effectorPosition': array([0.38051585, 0.99921992])}
episode index:3122
target Thresh 1.9965042709781236
current state at start:  [-3.53676298  2.94012265]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.53676298,  2.94012265]), 'currentState': array([3.02833176, 2.44012265]), 'targetState': array([-0.34306356, -0.77119629]), 'effectorPosition': array([-0.30752863, -0.6145221 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9322868416928999
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.53676298,  2.94012265]), 'currentState': array([3.02833176, 2.44012265]), 'targetState': array([-0.34306356, -0.77119629]), 'effectorPosition': array([-0.30752863, -0.6145221 ])}
episode index:3123
target Thresh 1.9965112554493678
current state at start:  [ 1.20734881 -2.77359706]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.20734881, -2.77359706]), 'currentState': array([1.68624858, 3.00958825]), 'targetState': array([-0.57015558,  0.87768866]), 'effectorPosition': array([-0.13174734, -0.00652023])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9323021468011928
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 1.20734881, -2.77359706]), 'currentState': array([0.96524198, 2.12020818]), 'targetState': array([-0.57015558,  0.87768866]), 'effectorPosition': array([-0.42920649,  0.87829968])}
episode index:3124
target Thresh 1.9965182259656293
current state at start:  [ 0.03644769 -2.27159487]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.03644769, -2.27159487]), 'currentState': array([0.52705292, 3.51159044]), 'targetState': array([0.1613469 , 0.14529999]), 'effectorPosition': array([ 0.24037565, -0.27850181])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9323174421142165
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 0.03644769, -2.27159487]), 'currentState': array([0.71779768, 3.26119855]), 'targetState': array([0.1613469 , 0.14529999]), 'effectorPosition': array([ 0.0838621 , -0.08518024])}
episode index:3125
target Thresh 1.99652518255479
current state at start:  [-0.02463197 -2.31486499]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.02463197, -2.31486499]), 'currentState': array([0.30203874, 3.47977469]), 'targetState': array([-0.33184747, -0.21052253]), 'effectorPosition': array([ 0.15276812, -0.29990524])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.9323203732425872
{'reset': False, 'endBeforeDone': False, 'stepCount': 7, 'initial state': array([-0.02463197, -2.31486499]), 'currentState': array([2.27553439, 2.52909574]), 'targetState': array([-0.33184747, -0.21052253]), 'effectorPosition': array([-0.55572392, -0.23396753])}
episode index:3126
target Thresh 1.9965321252446764
current state at start:  [0.21894474 2.82619601]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.21894474, 2.82619601]), 'currentState': array([6.00213005, 2.3289372 ]), 'targetState': array([0.46794727, 0.68626133]), 'effectorPosition': array([0.5015711, 0.6109673])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9323420168712272
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.21894474, 2.82619601]), 'currentState': array([6.00213005, 2.3289372 ]), 'targetState': array([0.46794727, 0.68626133]), 'effectorPosition': array([0.5015711, 0.6109673])}
episode index:3127
target Thresh 1.996539054063059
current state at start:  [-1.159661    1.83000985]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.159661  ,  1.83000985]), 'currentState': array([4.90008429, 2.33000985]), 'targetState': array([0.22333487, 0.33415966]), 'effectorPosition': array([ 0.77078989, -0.17082335])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9323510494777261
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([-1.159661  ,  1.83000985]), 'currentState': array([5.4819219 , 2.70556912]), 'targetState': array([0.22333487, 0.33415966]), 'effectorPosition': array([0.36843878, 0.22666359])}
episode index:3128
target Thresh 1.9965459690376535
current state at start:  [-1.46336123 -1.61330228]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.46336123, -1.61330228]), 'currentState': array([4.31982408, 5.16988303]), 'targetState': array([-0.16009457, -1.27801116]), 'effectorPosition': array([-1.3804523 , -0.98881441])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9320530785446876
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([-1.46336123, -1.61330228]), 'currentState': array([4.00499696, 5.07735769]), 'targetState': array([-0.16009457, -1.27801116]), 'effectorPosition': array([-1.59179752, -0.42428857])}
episode index:3129
target Thresh 1.9965528701961193
current state at start:  [ 3.70867305 -2.29521157]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.70867305, -2.29521157]), 'currentState': array([4.11924028, 3.48797374]), 'targetState': array([0.06021139, 0.03266467]), 'effectorPosition': array([-0.31470387,  0.14052232])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9320715919381237
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.70867305, -2.29521157]), 'currentState': array([4.54543161, 3.01281189]), 'targetState': array([0.06021139, 0.03266467]), 'effectorPosition': array([ 0.12526322, -0.02950769])}
episode index:3130
target Thresh 1.9965597575660612
current state at start:  [-1.27560499  2.64732619]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.27560499,  2.64732619]), 'currentState': array([4.52942503, 2.25454904]), 'targetState': array([ 0.2572117 , -0.32818603]), 'effectorPosition': array([ 0.69525929, -0.50319114])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9320900935056937
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.27560499,  2.64732619]), 'currentState': array([4.24473942, 2.75454904]), 'targetState': array([ 0.2572117 , -0.32818603]), 'effectorPosition': array([ 0.30358007, -0.2361803 ])}
episode index:3131
target Thresh 1.996566631175029
current state at start:  [-3.76552084  1.75464636]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.76552084,  1.75464636]), 'currentState': array([2.05063796, 2.25112757]), 'targetState': array([-0.71570948,  0.45815008]), 'effectorPosition': array([-0.86081973, -0.02980409])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.932108583258725
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.76552084,  1.75464636]), 'currentState': array([1.60211996, 2.3520475 ]), 'targetState': array([-0.71570948,  0.45815008]), 'effectorPosition': array([-0.71894976,  0.27344936])}
episode index:3132
target Thresh 1.9965734910505168
current state at start:  [1.20586294 2.12942247]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.20586294, 2.12942247]), 'currentState': array([0.74158437, 2.62942247]), 'targetState': array([0.08152493, 0.4680658 ]), 'effectorPosition': array([-0.23640047,  0.44804998])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9321270612085306
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.20586294, 2.12942247]), 'currentState': array([0.40817941, 2.69887989]), 'targetState': array([0.08152493, 0.4680658 ]), 'effectorPosition': array([-0.08155878,  0.43146546])}
episode index:3133
target Thresh 1.9965803372199642
current state at start:  [0.44421924 2.83680834]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.44421924, 2.83680834]), 'currentState': array([6.22740455, 2.3411503 ]), 'targetState': array([0.58720097, 0.71669664]), 'effectorPosition': array([0.34314956, 0.69962114])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9321487181768751
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.44421924, 2.83680834]), 'currentState': array([6.22740455, 2.3411503 ]), 'targetState': array([0.58720097, 0.71669664]), 'effectorPosition': array([0.34314956, 0.69962114])}
episode index:3134
target Thresh 1.996587169710756
current state at start:  [ 1.01451014 -1.74277814]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.01451014, -1.74277814]), 'currentState': array([1.49128668, 4.52258965]), 'targetState': array([0.88936738, 1.0306716 ]), 'effectorPosition': array([1.04338088, 0.73077539])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9321640136415715
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 1.01451014, -1.74277814]), 'currentState': array([1.67133197, 4.68089941]), 'targetState': array([0.88936738, 1.0306716 ]), 'effectorPosition': array([0.89725089, 1.06394177])}
episode index:3135
target Thresh 1.9965939885502222
current state at start:  [-1.58144359  3.04658032]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.58144359,  3.04658032]), 'currentState': array([4.92694961, 2.55949975]), 'targetState': array([ 0.09631471, -0.04429936]), 'effectorPosition': array([ 0.57223176, -0.04385317])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9321792993515073
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.58144359,  3.04658032]), 'currentState': array([4.56466908, 3.05061468]), 'targetState': array([ 0.09631471, -0.04429936]), 'effectorPosition': array([ 0.08925437, -0.01746257])}
episode index:3136
target Thresh 1.9966007937656378
current state at start:  [1.71405643 1.90671297]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.71405643, 1.90671297]), 'currentState': array([2.20360827, 2.33201735]), 'targetState': array([-0.77344554, -0.43573858]), 'effectorPosition': array([-0.76725885, -0.17805032])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9321977311974264
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.71405643, 1.90671297]), 'currentState': array([2.67992806, 2.08736848]), 'targetState': array([-0.77344554, -0.43573858]), 'effectorPosition': array([-0.84043229, -0.55305391])}
episode index:3137
target Thresh 1.996607585384224
current state at start:  [0.39954528 2.40290702]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.39954528, 2.40290702]), 'currentState': array([6.18273058, 1.90290702]), 'targetState': array([0.76603254, 0.8870292 ]), 'effectorPosition': array([0.76536909, 0.87300168])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9322193380389824
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.39954528, 2.40290702]), 'currentState': array([6.18273058, 1.90290702]), 'targetState': array([0.76603254, 0.8870292 ]), 'effectorPosition': array([0.76536909, 0.87300168])}
episode index:3138
target Thresh 1.9966143634331475
current state at start:  [-2.13023362  2.48979732]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.13023362,  2.48979732]), 'currentState': array([3.65295169, 2.27229708]), 'targetState': array([-0.18207481, -0.56271592]), 'effectorPosition': array([ 0.06454148, -0.83970519])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9322377453858957
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.13023362,  2.48979732]), 'currentState': array([3.16422448, 2.71752869]), 'targetState': array([-0.18207481, -0.56271592]), 'effectorPosition': array([-0.07924156, -0.41336692])}
episode index:3139
target Thresh 1.9966211279395198
current state at start:  [-1.49412401 -2.06531056]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.49412401, -2.06531056]), 'currentState': array([4.53573786, 3.84292037]), 'targetState': array([-0.31511389, -0.16364848]), 'effectorPosition': array([-0.67666693, -0.11895173])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9322561410083842
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.49412401, -2.06531056]), 'currentState': array([4.77280391, 3.39145614]), 'targetState': array([-0.31511389, -0.16364848]), 'effectorPosition': array([-0.24494558, -0.04592697])}
episode index:3140
target Thresh 1.9966278789303997
current state at start:  [-0.61543135 -1.87601722]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.61543135, -1.87601722]), 'currentState': array([5.16775396, 4.08900198]), 'targetState': array([ 0.34653142, -0.8080432 ]), 'effectorPosition': array([-0.54612735, -0.73086802])}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9322472667435006
{'reset': False, 'endBeforeDone': False, 'stepCount': 11, 'initial state': array([-0.61543135, -1.87601722]), 'currentState': array([4.21932641, 2.30195208]), 'targetState': array([ 0.34653142, -0.8080432 ]), 'effectorPosition': array([ 0.49846358, -0.64503736])}
episode index:3141
target Thresh 1.9966346164327906
current state at start:  [ 1.781972 -1.933836]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.781972, -1.933836]), 'currentState': array([2.16944031, 3.84934931]), 'targetState': array([0.42369146, 0.94059769]), 'effectorPosition': array([0.40172781, 0.56477451])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.932265647626141
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.781972, -1.933836]), 'currentState': array([1.95549531, 4.28939609]), 'targetState': array([0.42369146, 0.94059769]), 'effectorPosition': array([0.62398674, 0.88862689])}
episode index:3142
target Thresh 1.9966413404736427
current state at start:  [ 0.28928533 -2.00062179]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.28928533, -2.00062179]), 'currentState': array([0.3788229 , 3.78256352]), 'targetState': array([ 0.05406852, -0.46203727]), 'effectorPosition': array([ 0.40555893, -0.48217299])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9322840168123877
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.28928533, -2.00062179]), 'currentState': array([0.19580765, 3.37648068]), 'targetState': array([ 0.05406852, -0.46203727]), 'effectorPosition': array([ 0.07221533, -0.22294423])}
episode index:3143
target Thresh 1.9966480510798525
current state at start:  [-0.98451348  2.5258756 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.98451348,  2.5258756 ]), 'currentState': array([5.16544761, 2.26708671]), 'targetState': array([0.72367647, 0.11821828]), 'effectorPosition': array([0.84679918, 0.01338534])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9323055549749792
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.98451348,  2.5258756 ]), 'currentState': array([5.16544761, 2.26708671]), 'targetState': array([0.72367647, 0.11821828]), 'effectorPosition': array([0.84679918, 0.01338534])}
episode index:3144
target Thresh 1.996654748278262
current state at start:  [ 0.59293961 -1.72159735]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.59293961, -1.72159735]), 'currentState': array([1.06145173, 4.06158796]), 'targetState': array([1.17249294, 0.0859492 ]), 'effectorPosition': array([ 0.88681116, -0.04379698])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9323238997905674
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.59293961, -1.72159735]), 'currentState': array([1.14086232, 4.20478476]), 'targetState': array([1.17249294, 0.0859492 ]), 'effectorPosition': array([1.00858508, 0.10288953])}
episode index:3145
target Thresh 1.9966614320956602
current state at start:  [ 3.28762102 -1.97072905]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.28762102, -1.97072905]), 'currentState': array([3.6710352 , 3.81245625]), 'targetState': array([-0.63754015,  0.07183691]), 'effectorPosition': array([-0.50101635,  0.42709769])}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9323208549064724
{'reset': False, 'endBeforeDone': False, 'stepCount': 9, 'initial state': array([ 3.28762102, -1.97072905]), 'currentState': array([2.05460739, 2.40713247]), 'targetState': array([-0.63754015,  0.07183691]), 'effectorPosition': array([-0.71318906, -0.08352301])}
episode index:3146
target Thresh 1.9966681025587822
current state at start:  [ 1.40627673 -2.62517183]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.40627673, -2.62517183]), 'currentState': array([1.77347603, 3.15801348]), 'targetState': array([-0.25456482, -0.14609358]), 'effectorPosition': array([0.01605684, 0.00343734])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9323391832017038
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.40627673, -2.62517183]), 'currentState': array([2.16604703, 2.65801348]), 'targetState': array([-0.25456482, -0.14609358]), 'effectorPosition': array([-0.44927678, -0.16576326])}
episode index:3147
target Thresh 1.99667475969431
current state at start:  [ 9.40691483e-04 -2.73481464e+00]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 9.40691483e-04, -2.73481464e+00]), 'currentState': array([5.86605637, 3.62919566]), 'targetState': array([-0.11771068, -0.39109823]), 'effectorPosition': array([-0.08326185, -0.47555299])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9323606764726055
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 9.40691483e-04, -2.73481464e+00]), 'currentState': array([5.86605637, 3.62919566]), 'targetState': array([-0.11771068, -0.39109823]), 'effectorPosition': array([-0.08326185, -0.47555299])}
episode index:3148
target Thresh 1.9966814035288722
current state at start:  [ 2.57646603 -1.69085092]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.57646603, -1.69085092]), 'currentState': array([2.18789673, 4.09233439]), 'targetState': array([0.65877927, 0.46126332]), 'effectorPosition': array([0.42132283, 0.81260562])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9323758366261551
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 2.57646603, -1.69085092]), 'currentState': array([1.54480993, 3.98298118]), 'targetState': array([0.65877927, 0.46126332]), 'effectorPosition': array([0.75398482, 0.31408667])}
episode index:3149
target Thresh 1.996688034089044
current state at start:  [ 0.33588117 -1.78789571]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.33588117, -1.78789571]), 'currentState': array([0.83588117, 3.9952896 ]), 'targetState': array([0.57492129, 0.18759425]), 'effectorPosition': array([ 0.78902688, -0.25106609])}
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.9323612363198344
{'reset': False, 'endBeforeDone': False, 'stepCount': 13, 'initial state': array([ 0.33588117, -1.78789571]), 'currentState': array([5.50921201, 2.70011371]), 'targetState': array([0.57492129, 0.18759425]), 'effectorPosition': array([0.36722608, 0.23854462])}
episode index:3150
target Thresh 1.996694651401348
current state at start:  [-2.31123103  2.18182734]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.31123103,  2.18182734]), 'currentState': array([3.52569874, 2.68182734]), 'targetState': array([-0.22387465,  0.02961802]), 'effectorPosition': array([ 0.07000543, -0.45031758])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9323795285329984
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.31123103,  2.18182734]), 'currentState': array([3.09447856, 3.18182734]), 'targetState': array([-0.22387465,  0.02961802]), 'effectorPosition': array([0.001086  , 0.04021731])}
episode index:3151
target Thresh 1.996701255492253
current state at start:  [ 1.71270251 -2.14731189]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.71270251, -2.14731189]), 'currentState': array([1.73635179, 4.1931764 ]), 'targetState': array([0.79090723, 0.80653497]), 'effectorPosition': array([0.77331219, 0.63999607])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9324009817282608
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.71270251, -2.14731189]), 'currentState': array([1.73635179, 4.1931764 ]), 'targetState': array([0.79090723, 0.80653497]), 'effectorPosition': array([0.77331219, 0.63999607])}
episode index:3152
target Thresh 1.9967078463881756
current state at start:  [ 3.19969674 -2.02725412]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.19969674, -2.02725412]), 'currentState': array([2.79599937, 4.68360378]), 'targetState': array([-0.49273379,  1.02372574]), 'effectorPosition': array([-0.5751805 ,  1.26949003])}
done in step count: 28
reward sum = 0.7547192872036326
running average episode reward sum: 0.932344628510841
{'reset': False, 'endBeforeDone': False, 'stepCount': 29, 'initial state': array([ 3.19969674, -2.02725412]), 'currentState': array([1.19778096, 1.64901125]), 'targetState': array([-0.49273379,  1.02372574]), 'effectorPosition': array([-0.59243505,  1.22178161])}
episode index:3153
target Thresh 1.9967144241154793
current state at start:  [-3.07321652  2.0478912 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.07321652,  2.0478912 ]), 'currentState': array([2.70996878, 2.47104037]), 'targetState': array([-0.23285144, -0.2601796 ]), 'effectorPosition': array([-0.45663196, -0.47384605])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9323629085905775
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.07321652,  2.0478912 ]), 'currentState': array([2.28363577, 2.73326686]), 'targetState': array([-0.23285144, -0.2601796 ]), 'effectorPosition': array([-0.35415523, -0.19748491])}
episode index:3154
target Thresh 1.9967209887004753
current state at start:  [-1.76346697 -1.85212174]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.76346697, -1.85212174]), 'currentState': array([4.06784712, 3.93749384]), 'targetState': array([-0.7055855 ,  0.22001674]), 'effectorPosition': array([-0.75161433,  0.18919192])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9323843466544156
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.76346697, -1.85212174]), 'currentState': array([4.06784712, 3.93749384]), 'targetState': array([-0.7055855 ,  0.22001674]), 'effectorPosition': array([-0.75161433,  0.18919192])}
episode index:3155
target Thresh 1.9967275401694216
current state at start:  [-1.66500414  2.12053998]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.66500414,  2.12053998]), 'currentState': array([4.17839   , 2.49404682]), 'targetState': array([ 0.0335637 , -0.09644503]), 'effectorPosition': array([ 0.41621373, -0.48128253])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9324026025648546
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.66500414,  2.12053998]), 'currentState': array([3.76579604, 2.89279722]), 'targetState': array([ 0.0335637 , -0.09644503]), 'effectorPosition': array([ 0.11892916, -0.21779896])}
episode index:3156
target Thresh 1.9967340785485241
current state at start:  [ 1.69166804 -1.90336691]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.69166804, -1.90336691]), 'currentState': array([1.63314342, 3.87981839]), 'targetState': array([0.57818878, 0.41782066]), 'effectorPosition': array([0.65544836, 0.30176138])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9324240144740833
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.69166804, -1.90336691]), 'currentState': array([1.63314342, 3.87981839]), 'targetState': array([0.57818878, 0.41782066]), 'effectorPosition': array([0.65544836, 0.30176138])}
episode index:3157
target Thresh 1.9967406038639366
current state at start:  [0.67076386 1.75368385]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.67076386, 1.75368385]), 'currentState': array([0.2953643 , 1.68834654]), 'targetState': array([0.34773074, 1.08705999]), 'effectorPosition': array([0.55541557, 1.20704357])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9324454128228883
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.67076386, 1.75368385]), 'currentState': array([0.2953643 , 1.68834654]), 'targetState': array([0.34773074, 1.08705999]), 'effectorPosition': array([0.55541557, 1.20704357])}
episode index:3158
target Thresh 1.99674711614176
current state at start:  [ 0.87365607 -2.43112838]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.87365607, -2.43112838]), 'currentState': array([1.28669367, 3.35205693]), 'targetState': array([-0.08724852, -0.17635661]), 'effectorPosition': array([ 0.20672435, -0.03737636])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9324573955981896
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 0.87365607, -2.43112838]), 'currentState': array([2.32599295, 2.94504657]), 'targetState': array([-0.08724852, -0.17635661]), 'effectorPosition': array([-0.15538947, -0.11983437])}
episode index:3159
target Thresh 1.9967536154080439
current state at start:  [ 4.14307255 -2.99613853]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.14307255, -2.99613853]), 'currentState': array([3.72405836, 3.70590978]), 'targetState': array([-0.9550222 ,  0.08717918]), 'effectorPosition': array([-0.42368701,  0.36136031])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9324663002230003
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([ 4.14307255, -2.99613853]), 'currentState': array([1.95666304, 2.17074423]), 'targetState': array([-0.9550222 ,  0.08717918]), 'effectorPosition': array([-0.9285464 ,  0.09275039])}
episode index:3160
target Thresh 1.996760101688785
current state at start:  [-0.13560006 -2.73291042]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.13560006, -2.73291042]), 'currentState': array([0.34307108, 3.05027488]), 'targetState': array([-0.40132155,  0.34387967]), 'effectorPosition': array([-0.0267511 ,  0.08727841])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9324845013301742
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.13560006, -2.73291042]), 'currentState': array([0.83859328, 2.66972617]), 'targetState': array([-0.40132155,  0.34387967]), 'effectorPosition': array([-0.26499632,  0.38514165])}
episode index:3161
target Thresh 1.9967665750099284
current state at start:  [ 2.13995704 -2.15638366]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.13995704, -2.15638366]), 'currentState': array([2.29105024, 3.62680164]), 'targetState': array([0.06967876, 0.32476599]), 'effectorPosition': array([0.27442915, 0.39437755])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9325058534802912
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.13995704, -2.15638366]), 'currentState': array([2.29105024, 3.62680164]), 'targetState': array([0.06967876, 0.32476599]), 'effectorPosition': array([0.27442915, 0.39437755])}
episode index:3162
target Thresh 1.9967730353973676
current state at start:  [ 3.16037722 -1.86627582]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.16037722, -1.86627582]), 'currentState': array([2.68658312, 4.85832479]), 'targetState': array([-0.6016382 ,  1.25322064]), 'effectorPosition': array([-0.59408046,  1.39208661])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9325271921292067
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.16037722, -1.86627582]), 'currentState': array([2.68658312, 4.85832479]), 'targetState': array([-0.6016382 ,  1.25322064]), 'effectorPosition': array([-0.59408046,  1.39208661])}
episode index:3163
target Thresh 1.9967794828769443
current state at start:  [-3.87884306  1.73937513]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.87884306,  1.73937513]), 'currentState': array([1.94352935, 2.19620668]), 'targetState': array([-0.36706064,  0.78800514]), 'effectorPosition': array([-0.90602582,  0.09086917])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.932542227782769
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-3.87884306,  1.73937513]), 'currentState': array([0.99292923, 2.32817765]), 'targetState': array([-0.36706064,  0.78800514]), 'effectorPosition': array([-0.43769195,  0.659078  ])}
episode index:3164
target Thresh 1.996785917474448
current state at start:  [-3.19562717  2.3023132 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.19562717,  2.3023132 ]), 'currentState': array([2.58755813, 2.8023132 ]), 'targetState': array([0.00190161, 0.00569298]), 'effectorPosition': array([-0.22357542, -0.25303084])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9325603818972135
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.19562717,  2.3023132 ]), 'currentState': array([2.15531982, 3.18905037]), 'targetState': array([0.00190161, 0.00569298]), 'effectorPosition': array([0.03894242, 0.02711641])}
episode index:3165
target Thresh 1.9967923392156173
current state at start:  [ 0.90168253 -2.15094539]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.90168253, -2.15094539]), 'currentState': array([1.40168253, 3.93050436]), 'targetState': array([0.80626278, 0.55907352]), 'effectorPosition': array([0.74917952, 0.17173845])}
done in step count: 69
reward sum = 0.4998370298991989
running average episode reward sum: 0.9324237036432659
{'reset': False, 'endBeforeDone': False, 'stepCount': 70, 'initial state': array([ 0.90168253, -2.15094539]), 'currentState': array([1.43669536, 4.26450935]), 'targetState': array([0.80626278, 0.55907352]), 'effectorPosition': array([0.969075  , 0.44134238])}
episode index:3166
target Thresh 1.9967987481261393
current state at start:  [2.19163828 1.82860833]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.19163828, 1.82860833]), 'currentState': array([2.69163828, 2.12865903]), 'targetState': array([-0.77169047, -0.38100617]), 'effectorPosition': array([-0.79276791, -0.55925909])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9324450412802588
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.19163828, 1.82860833]), 'currentState': array([2.69163828, 2.12865903]), 'targetState': array([-0.77169047, -0.38100617]), 'effectorPosition': array([-0.79276791, -0.55925909])}
episode index:3167
target Thresh 1.9968051442316495
current state at start:  [-0.3197386   2.25604286]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.3197386 ,  2.25604286]), 'currentState': array([5.65719881, 2.70575994]), 'targetState': array([-0.09551681,  0.05797562]), 'effectorPosition': array([0.32310125, 0.2873464 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9324632088808648
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.3197386 ,  2.25604286]), 'currentState': array([5.31505573, 3.11668771]), 'targetState': array([-0.09551681,  0.05797562]), 'effectorPosition': array([0.02069103, 0.01386022])}
episode index:3168
target Thresh 1.9968115275577323
current state at start:  [-0.62921487  2.7360396 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.62921487,  2.7360396 ]), 'currentState': array([5.15397043, 3.13120829]), 'targetState': array([ 0.20853221, -0.2701871 ]), 'effectorPosition': array([0.00941114, 0.00438914])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.932475148228015
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-0.62921487,  2.7360396 ]), 'currentState': array([4.21516067, 2.78809246]), 'targetState': array([ 0.20853221, -0.2701871 ]), 'effectorPosition': array([ 0.27476969, -0.21947235])}
episode index:3169
target Thresh 1.9968178981299212
current state at start:  [1.91755182 2.06664549]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.91755182, 2.06664549]), 'currentState': array([1.79391971, 2.45493113]), 'targetState': array([-0.37073392, -0.08228513]), 'effectorPosition': array([-0.66839234,  0.08073493])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9324901718405615
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([1.91755182, 2.06664549]), 'currentState': array([1.85334449, 2.58146941]), 'targetState': array([-0.37073392, -0.08228513]), 'effectorPosition': array([-0.55282804, -0.00137463])}
episode index:3170
target Thresh 1.9968242559736982
current state at start:  [-3.90023649  2.41047191]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.90023649,  2.41047191]), 'currentState': array([1.88294882, 2.78624236]), 'targetState': array([0.00206329, 0.00157437]), 'effectorPosition': array([-0.35029218, -0.04739239])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9325083080209964
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.90023649,  2.41047191]), 'currentState': array([1.55722559, 2.97413395]), 'targetState': array([0.00206329, 0.00157437]), 'effectorPosition': array([-0.16647197,  0.01624905])}
episode index:3171
target Thresh 1.996830601114495
current state at start:  [ 4.10717866 -2.5055719 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.10717866, -2.5055719 ]), 'currentState': array([4.23326643, 3.27761341]), 'targetState': array([0.12073062, 0.3828322 ]), 'effectorPosition': array([-0.12459099,  0.05431595])}
done in step count: 14
reward sum = 0.8687458127689782
running average episode reward sum: 0.9324882063516231
{'reset': False, 'endBeforeDone': False, 'stepCount': 15, 'initial state': array([ 4.10717866, -2.5055719 ]), 'currentState': array([5.63833291, 2.79359029]), 'targetState': array([0.12073062, 0.3828322 ]), 'effectorPosition': array([0.25288753, 0.23650847])}
episode index:3172
target Thresh 1.9968369335776919
current state at start:  [ 1.49581508 -2.18118097]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.49581508, -2.18118097]), 'currentState': array([0.99581508, 4.22285702]), 'targetState': array([ 1.23843781, -0.28356528]), 'effectorPosition': array([ 1.02874905, -0.03535047])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9325063317199332
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.49581508, -2.18118097]), 'currentState': array([0.63894407, 4.57378157]), 'targetState': array([ 1.23843781, -0.28356528]), 'effectorPosition': array([ 1.28244687, -0.28107296])}
episode index:3173
target Thresh 1.9968432533886191
current state at start:  [-3.15116507  1.81728423]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.15116507,  1.81728423]), 'currentState': array([2.63202024, 2.21560139]), 'targetState': array([-1.08923977, -0.2613956 ]), 'effectorPosition': array([-0.73813233, -0.50306596])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9325244456670914
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.15116507,  1.81728423]), 'currentState': array([2.15800339, 2.02964495]), 'targetState': array([-1.08923977, -0.2613956 ]), 'effectorPosition': array([-1.05502665, -0.03296259])}
episode index:3174
target Thresh 1.9968495605725554
current state at start:  [1.18714335 2.49442636]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.18714335, 2.49442636]), 'currentState': array([1.52615031, 2.9458743 ]), 'targetState': array([-0.03967414, -0.22518518]), 'effectorPosition': array([-0.19342536,  0.02775224])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.932539430093653
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([1.18714335, 2.49442636]), 'currentState': array([2.44588416, 2.87842162]), 'targetState': array([-0.03967414, -0.22518518]), 'effectorPosition': array([-0.19316229, -0.177619  ])}
episode index:3175
target Thresh 1.99685585515473
current state at start:  [-0.8223511  -3.06926794]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.8223511 , -3.06926794]), 'currentState': array([5.18758181, 3.1139772 ]), 'targetState': array([-0.04051793,  0.03272716]), 'effectorPosition': array([0.02472711, 0.0122937 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9325606708272507
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.8223511 , -3.06926794]), 'currentState': array([5.18758181, 3.1139772 ]), 'targetState': array([-0.04051793,  0.03272716]), 'effectorPosition': array([0.02472711, 0.0122937 ])}
episode index:3176
target Thresh 1.996862137160321
current state at start:  [0.72111047 2.51690125]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.72111047, 2.51690125]), 'currentState': array([0.31470753, 3.01690125]), 'targetState': array([0.08787627, 0.03548279]), 'effectorPosition': array([-0.03111424,  0.12066365])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9325818981892818
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.72111047, 2.51690125]), 'currentState': array([0.31470753, 3.01690125]), 'targetState': array([0.08787627, 0.03548279]), 'effectorPosition': array([-0.03111424,  0.12066365])}
episode index:3177
target Thresh 1.9968684066144564
current state at start:  [ 0.31389288 -2.68601337]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.31389288, -2.68601337]), 'currentState': array([0.39472982, 3.26012892]), 'targetState': array([ 0.17849939, -0.22899678]), 'effectorPosition': array([ 0.05195507, -0.1064663 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9326031121923688
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.31389288, -2.68601337]), 'currentState': array([0.39472982, 3.26012892]), 'targetState': array([ 0.17849939, -0.22899678]), 'effectorPosition': array([ 0.05195507, -0.1064663 ])}
episode index:3178
target Thresh 1.996874663542214
current state at start:  [ 3.48949408 -2.40999137]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.48949408, -2.40999137]), 'currentState': array([3.03892737, 4.37319393]), 'targetState': array([0.3940837, 1.3432748]), 'effectorPosition': array([-0.56711268,  1.00644274])}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9325942348607603
{'reset': False, 'endBeforeDone': False, 'stepCount': 11, 'initial state': array([ 3.48949408, -2.40999137]), 'currentState': array([0.65420463, 1.55943174]), 'targetState': array([0.3940837, 1.3432748]), 'effectorPosition': array([0.19406117, 1.40892475])}
episode index:3179
target Thresh 1.9968809079686216
current state at start:  [-0.71612111 -2.33506686]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.71612111, -2.33506686]), 'currentState': array([5.22665849, 3.44811845]), 'targetState': array([-0.0790237 ,  0.01046913]), 'effectorPosition': array([-0.2397892 , -0.18901278])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9326122869881626
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.71612111, -2.33506686]), 'currentState': array([4.89783135, 3.23962355]), 'targetState': array([-0.0790237 ,  0.01046913]), 'effectorPosition': array([-0.09531064, -0.022765  ])}
episode index:3180
target Thresh 1.9968871399186572
current state at start:  [-0.08202204 -1.64703798]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.08202204, -1.64703798]), 'currentState': array([5.98068217, 4.13614733]), 'targetState': array([ 1.19605588, -0.69672095]), 'effectorPosition': array([ 0.18465526, -0.9360287 ])}
done in step count: 88
reward sum = 0.41294967113388814
running average episode reward sum: 0.9324489224437255
{'reset': False, 'endBeforeDone': False, 'stepCount': 89, 'initial state': array([-0.08202204, -1.64703798]), 'currentState': array([5.04845514, 1.74104382]), 'targetState': array([ 1.19605588, -0.69672095]), 'effectorPosition': array([ 1.20431404, -0.45910256])}
episode index:3181
target Thresh 1.996893359417248
current state at start:  [-1.1809396  1.9777571]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.1809396,  1.9777571]), 'currentState': array([4.60653128, 1.4777571 ]), 'targetState': array([ 0.37334991, -0.93082699]), 'effectorPosition': array([ 0.87462503, -1.19199042])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9324670088917318
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.1809396,  1.9777571]), 'currentState': array([4.11946451, 1.90834752]), 'targetState': array([ 0.37334991, -0.93082699]), 'effectorPosition': array([ 0.40878037, -1.08191666])}
episode index:3182
target Thresh 1.9968995664892726
current state at start:  [-1.64620988 -2.29428821]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.64620988, -2.29428821]), 'currentState': array([4.15049406, 3.88648458]), 'targetState': array([-0.73169418,  0.42081159]), 'effectorPosition': array([-0.71476807,  0.13705569])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9324850839753347
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.64620988, -2.29428821]), 'currentState': array([3.77413409, 4.06214695]), 'targetState': array([-0.73169418,  0.42081159]), 'effectorPosition': array([-0.78882795,  0.40864695])}
episode index:3183
target Thresh 1.9969057611595589
current state at start:  [-1.57079865 -2.00527645]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.57079865, -2.00527645]), 'currentState': array([4.29205497, 4.58538511]), 'targetState': array([-1.0014413 , -0.97891525]), 'effectorPosition': array([-1.26197837, -0.39253684])}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.9324791267402556
{'reset': False, 'endBeforeDone': False, 'stepCount': 10, 'initial state': array([-1.57079865, -2.00527645]), 'currentState': array([4.52040017, 4.96388012]), 'targetState': array([-1.0014413 , -0.97891525]), 'effectorPosition': array([-1.1890418 , -1.04109391])}
episode index:3184
target Thresh 1.9969119434528855
current state at start:  [-0.06497479  1.69110901]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.06497479,  1.69110901]), 'currentState': array([5.89955696, 2.19110901]), 'targetState': array([0.21365167, 0.02198146]), 'effectorPosition': array([0.692832  , 0.59783324])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9324940783488145
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-0.06497479,  1.69110901]), 'currentState': array([5.17643606, 2.90336267]), 'targetState': array([0.21365167, 0.02198146]), 'effectorPosition': array([0.22366807, 0.08036301])}
episode index:3185
target Thresh 1.996918113393982
current state at start:  [ 1.15816379 -3.01899407]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.15816379, -3.01899407]), 'currentState': array([0.71118323, 3.75740373]), 'targetState': array([ 0.93628347, -0.11963213]), 'effectorPosition': array([ 0.51619613, -0.31769658])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.9324968988356481
{'reset': False, 'endBeforeDone': False, 'stepCount': 7, 'initial state': array([ 1.15816379, -3.01899407]), 'currentState': array([4.97735855, 2.33916741]), 'targetState': array([ 0.93628347, -0.11963213]), 'effectorPosition': array([ 0.77383194, -0.10608643])}
episode index:3186
target Thresh 1.9969242710075281
current state at start:  [-2.14672853  1.77642234]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.14672853,  1.77642234]), 'currentState': array([3.68042295, 2.17582222]), 'targetState': array([ 0.19924539, -0.98024025]), 'effectorPosition': array([ 0.05192758, -0.92721992])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9325180796016238
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.14672853,  1.77642234]), 'currentState': array([3.68042295, 2.17582222]), 'targetState': array([ 0.19924539, -0.98024025]), 'effectorPosition': array([ 0.05192758, -0.92721992])}
episode index:3187
target Thresh 1.9969304163181538
current state at start:  [0.33898336 2.30336417]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.33898336, 2.30336417]), 'currentState': array([0.13063317, 2.69754015]), 'targetState': array([-0.03720723,  0.36710947]), 'effectorPosition': array([0.04019471, 0.43857514])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9325392470797914
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.33898336, 2.30336417]), 'currentState': array([0.13063317, 2.69754015]), 'targetState': array([-0.03720723,  0.36710947]), 'effectorPosition': array([0.04019471, 0.43857514])}
episode index:3188
target Thresh 1.996936549350441
current state at start:  [-3.22880228  1.90780933]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.22880228,  1.90780933]), 'currentState': array([2.64356195, 2.20519412]), 'targetState': array([ 0.11979978, -0.49111566]), 'effectorPosition': array([-0.74258015, -0.51302002])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9325541610819614
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-3.22880228,  1.90780933]), 'currentState': array([3.0789489 , 2.75848612]), 'targetState': array([ 0.11979978, -0.49111566]), 'effectorPosition': array([-0.09575108, -0.36853219])}
episode index:3189
target Thresh 1.9969426701289212
current state at start:  [ 3.14698869 -1.95218495]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.14698869, -1.95218495]), 'currentState': array([2.64698869, 4.61490834]), 'targetState': array([0.01482301, 1.09639335]), 'effectorPosition': array([-0.32206477,  1.3044622 ])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9325690657336599
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 3.14698869, -1.95218495]), 'currentState': array([2.5057358 , 4.10650696]), 'targetState': array([0.01482301, 1.09639335]), 'effectorPosition': array([0.14178422, 0.91701832])}
episode index:3190
target Thresh 1.9969487786780782
current state at start:  [-2.33119194  2.48719605]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.33119194,  2.48719605]), 'currentState': array([4.38969948, 2.08244022]), 'targetState': array([ 0.83237493, -0.57542339]), 'effectorPosition': array([ 0.66508278, -0.76055396])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.932590197333242
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.33119194,  2.48719605]), 'currentState': array([4.38969948, 2.08244022]), 'targetState': array([ 0.83237493, -0.57542339]), 'effectorPosition': array([ 0.66508278, -0.76055396])}
episode index:3191
target Thresh 1.9969548750223456
current state at start:  [ 3.28365527 -2.22170879]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.28365527, -2.22170879]), 'currentState': array([3.64645107, 3.64270525]), 'targetState': array([0.16212795, 0.35363954]), 'effectorPosition': array([-0.33997469,  0.36099859])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.9325900329067301
{'reset': False, 'endBeforeDone': False, 'stepCount': 8, 'initial state': array([ 3.28365527, -2.22170879]), 'currentState': array([5.81535016, 2.71893598]), 'targetState': array([0.16212795, 0.35363954]), 'effectorPosition': array([0.26351686, 0.3264261 ])}
episode index:3192
target Thresh 1.996960959186109
current state at start:  [ 3.94417827 -2.2736876 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.94417827, -2.2736876 ]), 'currentState': array([3.96134029, 3.58305622]), 'targetState': array([-0.38891414,  0.33181714]), 'effectorPosition': array([-0.37774219,  0.22148641])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9326111447035021
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.94417827, -2.2736876 ]), 'currentState': array([3.96134029, 3.58305622]), 'targetState': array([-0.38891414,  0.33181714]), 'effectorPosition': array([-0.37774219,  0.22148641])}
episode index:3193
target Thresh 1.9969670311937053
current state at start:  [ 4.12665139 -2.58558957]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.12665139, -2.58558957]), 'currentState': array([4.53085114, 3.3076213 ]), 'targetState': array([-0.44825105, -0.00577162]), 'effectorPosition': array([-0.16503378,  0.01631252])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9326291124102324
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 4.12665139, -2.58558957]), 'currentState': array([4.36476119, 3.38284908]), 'targetState': array([-0.44825105, -0.00577162]), 'effectorPosition': array([-0.23449758,  0.0541644 ])}
episode index:3194
target Thresh 1.9969730910694221
current state at start:  [-0.15845808 -1.95275149]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.15845808, -1.95275149]), 'currentState': array([5.71353323, 3.85005575]), 'targetState': array([ 0.65117973, -0.76794613]), 'effectorPosition': array([-0.14829253, -0.67770477])}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.9326231306058734
{'reset': False, 'endBeforeDone': False, 'stepCount': 10, 'initial state': array([-0.15845808, -1.95275149]), 'currentState': array([4.32765731, 2.2291569 ]), 'targetState': array([ 0.65117973, -0.76794613]), 'effectorPosition': array([ 0.58748617, -0.65667207])}
episode index:3195
target Thresh 1.9969791388374993
current state at start:  [-0.36288725 -1.58191001]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.36288725, -1.58191001]), 'currentState': array([5.46113147, 4.21180058]), 'targetState': array([-0.20939911, -0.89720144]), 'effectorPosition': array([-0.28864934, -0.97816047])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9326442122295888
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.36288725, -1.58191001]), 'currentState': array([5.46113147, 4.21180058]), 'targetState': array([-0.20939911, -0.89720144]), 'effectorPosition': array([-0.28864934, -0.97816047])}
episode index:3196
target Thresh 1.9969851745221279
current state at start:  [-1.91685806 -2.01553522]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.91685806, -2.01553522]), 'currentState': array([4.53344686, 3.80133919]), 'targetState': array([-0.09084382,  0.05864265]), 'effectorPosition': array([-0.64048123, -0.09740936])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9326621527324884
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.91685806, -2.01553522]), 'currentState': array([4.8565927 , 3.31037636]), 'targetState': array([-0.09084382,  0.05864265]), 'effectorPosition': array([-0.16419784, -0.03820267])}
episode index:3197
target Thresh 1.9969911981474504
current state at start:  [ 1.42717444 -1.93796217]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.42717444, -1.93796217]), 'currentState': array([0.95920767, 3.850871  ]), 'targetState': array([ 0.95058749, -0.11762601]), 'effectorPosition': array([ 0.67170326, -0.17649526])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9326800820155614
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.42717444, -1.93796217]), 'currentState': array([0.89022955, 4.24389292]), 'targetState': array([ 0.95058749, -0.11762601]), 'effectorPosition': array([ 1.0385763 , -0.13516451])}
episode index:3198
target Thresh 1.9969972097375615
current state at start:  [-2.76642067  2.00865933]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.76642067,  2.00865933]), 'currentState': array([3.01676463, 2.42263999]), 'targetState': array([-0.84159601, -0.62085022]), 'effectorPosition': array([-0.32757629, -0.62265716])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9326949053722305
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-2.76642067,  2.00865933]), 'currentState': array([2.95576143, 2.09554078]), 'targetState': array([-0.84159601, -0.62085022]), 'effectorPosition': array([-0.65032068, -0.75835302])}
episode index:3199
target Thresh 1.9970032093165075
current state at start:  [ 4.289903   -2.65849071]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.289903  , -2.65849071]), 'currentState': array([3.79038911, 4.10221918]), 'targetState': array([-0.76236621,  0.97526034]), 'effectorPosition': array([-0.83542864,  0.39502624])}
done in step count: 26
reward sum = 0.7700431458051551
running average episode reward sum: 0.9326440766973658
{'reset': False, 'endBeforeDone': False, 'stepCount': 27, 'initial state': array([ 4.289903  , -2.65849071]), 'currentState': array([1.38365333, 1.86732488]), 'targetState': array([-0.76236621,  0.97526034]), 'effectorPosition': array([-0.80797082,  0.87337225])}
episode index:3200
target Thresh 1.9970091969082868
current state at start:  [-2.66703132  2.95296025]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.66703132,  2.95296025]), 'currentState': array([4.07900176, 2.54493167]), 'targetState': array([ 0.50016285, -0.54593582]), 'effectorPosition': array([ 0.35062657, -0.47183502])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.932665118847726
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.66703132,  2.95296025]), 'currentState': array([4.07900176, 2.54493167]), 'targetState': array([ 0.50016285, -0.54593582]), 'effectorPosition': array([ 0.35062657, -0.47183502])}
episode index:3201
target Thresh 1.99701517253685
current state at start:  [ 4.08955453 -2.76598751]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.08955453, -2.76598751]), 'currentState': array([4.55050988, 3.09510214]), 'targetState': array([ 0.54881075, -0.37732838]), 'effectorPosition': array([ 0.04569204, -0.00855668])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9326799329892477
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 4.08955453, -2.76598751]), 'currentState': array([4.49302299, 2.21119366]), 'targetState': array([ 0.54881075, -0.37732838]), 'effectorPosition': array([ 0.69505706, -0.56733367])}
episode index:3202
target Thresh 1.997021136226099
current state at start:  [-3.88955032  2.51845764]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.88955032,  2.51845764]), 'currentState': array([2.8735642 , 2.94941893]), 'targetState': array([ 0.42141639, -0.69255491]), 'effectorPosition': array([-0.06833218, -0.17929846])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9326916779368002
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-3.88955032,  2.51845764]), 'currentState': array([3.963023  , 2.46828913]), 'targetState': array([ 0.42141639, -0.69255491]), 'effectorPosition': array([ 0.30787455, -0.58453517])}
episode index:3203
target Thresh 1.997027087999889
current state at start:  [ 2.61253113 -1.83838631]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.61253113, -1.83838631]), 'currentState': array([2.35061029, 3.944799  ]), 'targetState': array([0.02922278, 0.49471954]), 'effectorPosition': array([0.29677814, 0.72326804])}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.9326856934079446
{'reset': False, 'endBeforeDone': False, 'stepCount': 10, 'initial state': array([ 2.61253113, -1.83838631]), 'currentState': array([0.38455168, 2.44856451]), 'targetState': array([0.02922278, 0.49471954]), 'effectorPosition': array([-0.02583052,  0.67875097])}
episode index:3204
target Thresh 1.9970330278820272
current state at start:  [-1.39004591  2.63429306]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.39004591,  2.63429306]), 'currentState': array([4.3931394 , 2.13429306]), 'targetState': array([ 0.71510654, -1.02496026]), 'effectorPosition': array([ 0.65646551, -0.70764531])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9327004872633556
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.39004591,  2.63429306]), 'currentState': array([4.23441006, 1.88905543]), 'targetState': array([ 0.71510654, -1.02496026]), 'effectorPosition': array([ 0.52728633, -1.046968  ])}
episode index:3205
target Thresh 1.997038955896273
current state at start:  [-0.09765818  2.0148898 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.09765818,  2.0148898 ]), 'currentState': array([0.33606676, 1.53268226]), 'targetState': array([0.67794144, 1.14040609]), 'effectorPosition': array([0.65049534, 1.28571595])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9327214790015766
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.09765818,  2.0148898 ]), 'currentState': array([0.33606676, 1.53268226]), 'targetState': array([0.67794144, 1.14040609]), 'effectorPosition': array([0.65049534, 1.28571595])}
episode index:3206
target Thresh 1.9970448720663383
current state at start:  [-1.40143068  2.10049293]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.40143068,  2.10049293]), 'currentState': array([4.38175463, 1.62139533]), 'targetState': array([ 0.90661252, -0.95343885]), 'effectorPosition': array([ 0.63640258, -1.22222622])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9327362524724212
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.40143068,  2.10049293]), 'currentState': array([4.59666493, 1.50277067]), 'targetState': array([ 0.90661252, -0.95343885]), 'effectorPosition': array([ 0.86769954, -1.17602887])}
episode index:3207
target Thresh 1.997050776415888
current state at start:  [0.78623511 2.49798262]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.78623511, 2.49798262]), 'currentState': array([0.83097466, 2.89713087]), 'targetState': array([-0.18602816,  0.35545334]), 'effectorPosition': array([-0.15871951,  0.18512874])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9327572199747678
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.78623511, 2.49798262]), 'currentState': array([0.83097466, 2.89713087]), 'targetState': array([-0.18602816,  0.35545334]), 'effectorPosition': array([-0.15871951,  0.18512874])}
episode index:3208
target Thresh 1.9970566689685394
current state at start:  [-0.08081713  2.78446156]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.08081713,  2.78446156]), 'currentState': array([6.00492794, 2.28446156]), 'targetState': array([0.69960325, 1.20497117]), 'effectorPosition': array([0.53975531, 0.63201763])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9327750581735914
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.08081713,  2.78446156]), 'currentState': array([0.22174264, 1.78446156]), 'targetState': array([0.69960325, 1.20497117]), 'effectorPosition': array([0.55373542, 1.12662801])}
episode index:3209
target Thresh 1.9970625497478627
current state at start:  [-3.73304756  1.9697521 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.73304756,  1.9697521 ]), 'currentState': array([2.06356092, 2.45611116]), 'targetState': array([-0.23060036,  0.17912994]), 'effectorPosition': array([-0.66458959, -0.1004591 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9327928852582724
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.73304756,  1.9697521 ]), 'currentState': array([1.6061724 , 2.82492583]), 'targetState': array([-0.23060036,  0.17912994]), 'effectorPosition': array([-0.31296459,  0.0386764 ])}
episode index:3210
target Thresh 1.997068418777381
current state at start:  [ 3.02995143 -1.84224502]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.02995143, -1.84224502]), 'currentState': array([3.51352514, 3.94094029]), 'targetState': array([0.30475917, 0.15423468]), 'effectorPosition': array([-0.5426541 ,  0.55783282])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9328015439704311
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([ 3.02995143, -1.84224502]), 'currentState': array([5.14797128, 2.70056535]), 'targetState': array([0.30475917, 0.15423468]), 'effectorPosition': array([0.42738337, 0.09336068])}
episode index:3211
target Thresh 1.9970742760805706
current state at start:  [-2.09864486  1.97387509]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.09864486,  1.97387509]), 'currentState': array([4.34186443, 2.00953553]), 'targetState': array([ 0.48901857, -0.99968714]), 'effectorPosition': array([ 0.63556985, -0.86397577])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9328224650339522
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.09864486,  1.97387509]), 'currentState': array([4.34186443, 2.00953553]), 'targetState': array([ 0.48901857, -0.99968714]), 'effectorPosition': array([ 0.63556985, -0.86397577])}
episode index:3212
target Thresh 1.9970801216808607
current state at start:  [-1.09098754 -2.02141223]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.09098754, -2.02141223]), 'currentState': array([4.87145388, 3.79803755]), 'targetState': array([ 0.08474783, -0.01398564]), 'effectorPosition': array([-0.56968018, -0.30187852])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.932837179486167
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.09098754, -2.02141223]), 'currentState': array([5.01132204, 2.86265212]), 'targetState': array([ 0.08474783, -0.01398564]), 'effectorPosition': array([0.27450956, 0.04414891])}
episode index:3213
target Thresh 1.9970859556016336
current state at start:  [-0.73673648  2.29041551]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.73673648,  2.29041551]), 'currentState': array([6.04644883, 1.85135211]), 'targetState': array([1.01657662, 0.50603282]), 'effectorPosition': array([0.92830327, 0.7645087 ])}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.932831168306328
{'reset': False, 'endBeforeDone': False, 'stepCount': 10, 'initial state': array([-0.73673648,  2.29041551]), 'currentState': array([5.85658577, 1.71368811]), 'targetState': array([1.01657662, 0.50603282]), 'effectorPosition': array([1.19029515, 0.54624668])}
episode index:3214
target Thresh 1.997091777866225
current state at start:  [-3.40911194  2.54213688]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.40911194,  2.54213688]), 'currentState': array([2.45215008, 3.04213688]), 'targetState': array([ 0.01167206, -0.08627788]), 'effectorPosition': array([-0.06697327, -0.07347028])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9328520606334488
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.40911194,  2.54213688]), 'currentState': array([2.45215008, 3.04213688]), 'targetState': array([ 0.01167206, -0.08627788]), 'effectorPosition': array([-0.06697327, -0.07347028])}
episode index:3215
target Thresh 1.997097588497924
current state at start:  [ 2.52323333 -1.61397299]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.52323333, -1.61397299]), 'currentState': array([2.63654256, 4.31033496]), 'targetState': array([-0.4370098 ,  1.14111448]), 'effectorPosition': array([-0.08742715,  1.09988077])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9328606874833761
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([ 2.52323333, -1.61397299]), 'currentState': array([2.63475421, 4.48770488]), 'targetState': array([-0.4370098 ,  1.14111448]), 'effectorPosition': array([-0.20628012,  1.22957378])}
episode index:3216
target Thresh 1.997103387519973
current state at start:  [-1.8943363   1.77430077]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.8943363 ,  1.77430077]), 'currentState': array([3.99855344, 2.26957328]), 'targetState': array([ 0.05992491, -0.31991884]), 'effectorPosition': array([ 0.34514893, -0.77091418])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9328784491596325
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.8943363 ,  1.77430077]), 'currentState': array([3.65044265, 2.76472734]), 'targetState': array([ 0.05992491, -0.31991884]), 'effectorPosition': array([ 0.11799732, -0.35557145])}
episode index:3217
target Thresh 1.9971091749555683
current state at start:  [-2.43586803  1.94403766]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.43586803,  1.94403766]), 'currentState': array([3.63776198, 2.44403766]), 'targetState': array([ 0.38420662, -0.13745056]), 'effectorPosition': array([ 0.10037771, -0.67608748])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9328961997969352
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.43586803,  1.94403766]), 'currentState': array([4.01762113, 2.94403766]), 'targetState': array([ 0.38420662, -0.13745056]), 'effectorPosition': array([ 0.13832456, -0.14059703])}
episode index:3218
target Thresh 1.9971149508278596
current state at start:  [ 2.24782577 -2.20187096]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.24782577, -2.20187096]), 'currentState': array([1.8659516 , 4.58131435]), 'targetState': array([1.02902642, 0.90972308]), 'effectorPosition': array([0.69568054, 1.12010237])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.93291086391629
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 2.24782577, -2.20187096]), 'currentState': array([1.59431744, 4.60059961]), 'targetState': array([1.02902642, 0.90972308]), 'effectorPosition': array([0.97258794, 0.91156971])}
episode index:3219
target Thresh 1.9971207151599504
current state at start:  [ 3.61173677 -2.44837173]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.61173677, -2.44837173]), 'currentState': array([3.75787195, 3.37667088]), 'targetState': array([0.34615594, 0.62781905]), 'effectorPosition': array([-0.15707202,  0.17417271])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.932913525185074
{'reset': False, 'endBeforeDone': False, 'stepCount': 7, 'initial state': array([ 3.61173677, -2.44837173]), 'currentState': array([6.20463809, 2.29168344]), 'targetState': array([0.34615594, 0.62781905]), 'effectorPosition': array([0.39784613, 0.72222972])}
episode index:3220
target Thresh 1.997126467974898
current state at start:  [-1.21447669  2.00815161]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.21447669,  2.00815161]), 'currentState': array([4.60611161, 2.37556981]), 'targetState': array([ 0.39033997, -0.26627096]), 'effectorPosition': array([ 0.65973273, -0.35129115])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9329312483998566
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.21447669,  2.00815161]), 'currentState': array([4.52499644, 2.77670821]), 'targetState': array([ 0.39033997, -0.26627096]), 'effectorPosition': array([ 0.33832934, -0.13116118])}
episode index:3221
target Thresh 1.9971322092957136
current state at start:  [ 1.62332501 -2.04143196]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.62332501, -2.04143196]), 'currentState': array([1.61244405, 3.74175335]), 'targetState': array([0.2637264 , 0.05448963]), 'effectorPosition': array([0.5570093 , 0.19811839])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9329489606132644
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.62332501, -2.04143196]), 'currentState': array([1.87607763, 3.24175335]), 'targetState': array([0.2637264 , 0.05448963]), 'effectorPosition': array([0.09386348, 0.03483429])}
episode index:3222
target Thresh 1.9971379391453625
current state at start:  [ 0.14819022 -1.72946146]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.14819022, -1.72946146]), 'currentState': array([0.64819022, 4.05372384]), 'targetState': array([ 0.63957786, -0.01013904]), 'effectorPosition': array([ 0.78670302, -0.39620046])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9329635901631828
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 0.14819022, -1.72946146]), 'currentState': array([1.03888256, 3.90080133]), 'targetState': array([ 0.63957786, -0.01013904]), 'effectorPosition': array([ 0.73252646, -0.11244152])}
episode index:3223
target Thresh 1.9971436575467643
current state at start:  [-1.07789588  2.72605968]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.07789588,  2.72605968]), 'currentState': array([4.72065521, 2.28190497]), 'targetState': array([ 0.89231874, -0.78633504]), 'effectorPosition': array([ 0.76048392, -0.34105127])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9329812813573009
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.07789588,  2.72605968]), 'currentState': array([4.80358808, 1.82685527]), 'targetState': array([ 0.89231874, -0.78633504]), 'effectorPosition': array([ 1.03138212, -0.65552343])}
episode index:3224
target Thresh 1.9971493645227925
current state at start:  [-1.65960904 -2.67453662]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.65960904, -2.67453662]), 'currentState': array([4.83176182, 3.13943937]), 'targetState': array([-0.0547561 , -0.04414256]), 'effectorPosition': array([0.00213823, 0.00025413])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9330020623553296
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.65960904, -2.67453662]), 'currentState': array([4.83176182, 3.13943937]), 'targetState': array([-0.0547561 , -0.04414256]), 'effectorPosition': array([0.00213823, 0.00025413])}
episode index:3225
target Thresh 1.9971550600962749
current state at start:  [0.97195857 2.68496885]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.97195857, 2.68496885]), 'currentState': array([1.29807004, 3.00373884]), 'targetState': array([-0.26463518,  0.22566986]), 'effectorPosition': array([-0.12978333,  0.0461507 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9330228304699125
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.97195857, 2.68496885]), 'currentState': array([1.29807004, 3.00373884]), 'targetState': array([-0.26463518,  0.22566986]), 'effectorPosition': array([-0.12978333,  0.0461507 ])}
episode index:3226
target Thresh 1.997160744289994
current state at start:  [1.45490909 2.89077001]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.45490909, 2.89077001]), 'currentState': array([0.9706522, 3.1811825]), 'targetState': array([0.68646764, 0.54337316]), 'effectorPosition': array([ 0.03310569, -0.02170633])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.9330283982478581
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([1.45490909, 2.89077001]), 'currentState': array([5.93604866, 1.99685669]), 'targetState': array([0.68646764, 0.54337316]), 'effectorPosition': array([0.86150889, 0.65668049])}
episode index:3227
target Thresh 1.997166417126686
current state at start:  [-1.57643587 -1.78789635]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.57643587, -1.78789635]), 'currentState': array([4.29615986, 4.42230329]), 'targetState': array([-1.01261712, -0.19739707]), 'effectorPosition': array([-1.16507326, -0.26558542])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9330491453363811
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.57643587, -1.78789635]), 'currentState': array([4.29615986, 4.42230329]), 'targetState': array([-1.01261712, -0.19739707]), 'effectorPosition': array([-1.16507326, -0.26558542])}
episode index:3228
target Thresh 1.9971720786290432
current state at start:  [ 2.65913736 -2.8617251 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.65913736, -2.8617251 ]), 'currentState': array([2.54823143, 2.93580767]), 'targetState': array([-0.03136397, -0.00671203]), 'effectorPosition': array([-0.131747  , -0.15761013])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9330698795744311
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.65913736, -2.8617251 ]), 'currentState': array([2.54823143, 2.93580767]), 'targetState': array([-0.03136397, -0.00671203]), 'effectorPosition': array([-0.131747  , -0.15761013])}
episode index:3229
target Thresh 1.9971777288197112
current state at start:  [-4.08947684  2.15333278]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.08947684,  2.15333278]), 'currentState': array([1.76156663, 2.60489607]), 'targetState': array([-0.22819958,  0.07239072]), 'effectorPosition': array([-0.52868351,  0.04109668])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9330875049987114
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-4.08947684,  2.15333278]), 'currentState': array([1.50375583, 2.69474346]), 'targetState': array([-0.22819958,  0.07239072]), 'effectorPosition': array([-0.42457796,  0.12691458])}
episode index:3230
target Thresh 1.9971833677212905
current state at start:  [1.18539229 1.84295354]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.18539229, 1.84295354]), 'currentState': array([1.14183471, 1.78698591]), 'targetState': array([-0.76501971,  1.13265431]), 'effectorPosition': array([-0.56152258,  1.12056836])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9331082145298167
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.18539229, 1.84295354]), 'currentState': array([1.14183471, 1.78698591]), 'targetState': array([-0.76501971,  1.13265431]), 'effectorPosition': array([-0.56152258,  1.12056836])}
episode index:3231
target Thresh 1.997188995356337
current state at start:  [ 3.93990521 -3.02794666]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.93990521, -3.02794666]), 'currentState': array([4.43990521, 2.80868852]), 'targetState': array([0.3973407 , 0.04572624]), 'effectorPosition': array([ 0.29995669, -0.14082401])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9331289112456181
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.93990521, -3.02794666]), 'currentState': array([4.43990521, 2.80868852]), 'targetState': array([0.3973407 , 0.04572624]), 'effectorPosition': array([ 0.29995669, -0.14082401])}
episode index:3232
target Thresh 1.9971946117473611
current state at start:  [1.21002554 2.28045915]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.21002554, 2.28045915]), 'currentState': array([1.71002554, 1.94720944]), 'targetState': array([-1.06443942,  0.45804667]), 'effectorPosition': array([-1.00875601,  0.4972295 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9331495951580073
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.21002554, 2.28045915]), 'currentState': array([1.71002554, 1.94720944]), 'targetState': array([-1.06443942,  0.45804667]), 'effectorPosition': array([-1.00875601,  0.4972295 ])}
episode index:3233
target Thresh 1.9972002169168286
current state at start:  [-1.56857781 -2.66787967]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.56857781, -2.66787967]), 'currentState': array([4.35105278, 3.78984483]), 'targetState': array([-1.04291749, -0.64386513]), 'effectorPosition': array([-0.63652009,  0.02369592])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.933149259892933
{'reset': False, 'endBeforeDone': False, 'stepCount': 8, 'initial state': array([-1.56857781, -2.66787967]), 'currentState': array([4.48167432, 4.39494958]), 'targetState': array([-1.04291749, -0.64386513]), 'effectorPosition': array([-1.08216123, -0.45239058])}
episode index:3234
target Thresh 1.99720581088716
current state at start:  [0.67687508 1.89803424]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.67687508, 1.89803424]), 'currentState': array([0.21612146, 2.39803424]), 'targetState': array([0.81989713, 0.35809608]), 'effectorPosition': array([0.11263658, 0.7177632 ])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9331637732592721
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([0.67687508, 1.89803424]), 'currentState': array([5.64661148, 2.09477172]), 'targetState': array([0.81989713, 0.35809608]), 'effectorPosition': array([0.91649779, 0.39922367])}
episode index:3235
target Thresh 1.9972113936807312
current state at start:  [ 1.61785794 -1.72036062]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.61785794, -1.72036062]), 'currentState': array([1.94830568, 4.06282468]), 'targetState': array([0.02420319, 0.40918979]), 'effectorPosition': array([0.5946144 , 0.66087422])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9331813369881783
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.61785794, -1.72036062]), 'currentState': array([2.31333972, 3.56985103]), 'targetState': array([0.02420319, 0.40918979]), 'effectorPosition': array([0.24489917, 0.34733786])}
episode index:3236
target Thresh 1.9972169653198732
current state at start:  [-2.68036401  1.69185544]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.68036401,  1.69185544]), 'currentState': array([3.41287854, 2.17533366]), 'targetState': array([ 0.31756074, -0.43302071]), 'effectorPosition': array([-0.19535619, -0.9083353 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9331988898652286
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.68036401,  1.69185544]), 'currentState': array([3.58220853, 2.61498959]), 'targetState': array([ 0.31756074, -0.43302071]), 'effectorPosition': array([ 0.09181621, -0.51237787])}
episode index:3237
target Thresh 1.997222525826873
current state at start:  [-3.38656353  2.27230596]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.38656353,  2.27230596]), 'currentState': array([2.43636231, 2.73993601]), 'targetState': array([0.12919834, 0.04701567]), 'effectorPosition': array([-0.31401458, -0.24610086])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.933216431900477
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.38656353,  2.27230596]), 'currentState': array([2.03817658, 3.19338789]), 'targetState': array([0.12919834, 0.04701567]), 'effectorPosition': array([0.04561539, 0.02452311])}
episode index:3238
target Thresh 1.9972280752239724
current state at start:  [ 1.27061895 -1.7998201 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.27061895, -1.7998201 ]), 'currentState': array([1.50830979, 3.986927  ]), 'targetState': array([0.83321062, 0.2924798 ]), 'effectorPosition': array([0.76774699, 0.2891405 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9332370504766114
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.27061895, -1.7998201 ]), 'currentState': array([1.50830979, 3.986927  ]), 'targetState': array([0.83321062, 0.2924798 ]), 'effectorPosition': array([0.76774699, 0.2891405 ])}
episode index:3239
target Thresh 1.997233613533369
current state at start:  [-1.71765309 -1.73600776]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.71765309, -1.73600776]), 'currentState': array([4.36812245, 4.31570049]), 'targetState': array([-0.55764944, -0.62594055]), 'effectorPosition': array([-1.0753306 , -0.26633041])}
done in step count: 17
reward sum = 0.8429431933839268
running average episode reward sum: 0.9332091820022003
{'reset': False, 'endBeforeDone': False, 'stepCount': 18, 'initial state': array([-1.71765309, -1.73600776]), 'currentState': array([2.91074689, 2.23917466]), 'targetState': array([-0.55764944, -0.62594055]), 'effectorPosition': array([-0.54976747, -0.67699895])}
episode index:3240
target Thresh 1.9972391407772159
current state at start:  [-1.22155823  1.62157243]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.22155823,  1.62157243]), 'currentState': array([4.62063326, 2.02181976]), 'targetState': array([ 0.80702978, -0.67079133]), 'effectorPosition': array([ 0.84452751, -0.6442046 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9332297900916781
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.22155823,  1.62157243]), 'currentState': array([4.62063326, 2.02181976]), 'targetState': array([ 0.80702978, -0.67079133]), 'effectorPosition': array([ 0.84452751, -0.6442046 ])}
episode index:3241
target Thresh 1.9972446569776223
current state at start:  [-3.62199901  2.62060896]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.62199901,  2.62060896]), 'currentState': array([2.20519909, 3.0434835 ]), 'targetState': array([-0.04105477,  0.00051785]), 'effectorPosition': array([-0.08174313, -0.05418255])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9332503854679608
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.62199901,  2.62060896]), 'currentState': array([2.20519909, 3.0434835 ]), 'targetState': array([-0.04105477,  0.00051785]), 'effectorPosition': array([-0.08174313, -0.05418255])}
episode index:3242
target Thresh 1.997250162156653
current state at start:  [1.22979988 2.1079615 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.22979988, 2.1079615 ]), 'currentState': array([1.02658683, 2.5810225 ]), 'targetState': array([ 0.26668393, -0.10658399]), 'effectorPosition': array([-0.37562326,  0.40620554])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9332648318492535
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([1.22979988, 2.1079615 ]), 'currentState': array([0.28652313, 3.44553181]), 'targetState': array([ 0.26668393, -0.10658399]), 'effectorPosition': array([ 0.12854891, -0.27412628])}
episode index:3243
target Thresh 1.9972556563363286
current state at start:  [-3.27207843  1.60210545]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.27207843,  1.60210545]), 'currentState': array([2.5590719 , 1.94828654]), 'targetState': array([-0.17359662, -0.55855189]), 'effectorPosition': array([-1.03867562, -0.42892406])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9332792693240226
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-3.27207843,  1.60210545]), 'currentState': array([3.0747782 , 2.62371446]), 'targetState': array([-0.17359662, -0.55855189]), 'effectorPosition': array([-0.16388698, -0.48517836])}
episode index:3244
target Thresh 1.997261139538626
current state at start:  [1.77302904 1.61612419]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.77302904, 1.61612419]), 'currentState': array([2.12858457, 2.0914676 ]), 'targetState': array([-0.27003924,  0.00155105]), 'effectorPosition': array([-1.00199742, -0.0328028 ])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.9332847271916885
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([1.77302904, 1.61612419]), 'currentState': array([1.72559864, 2.62012431]), 'targetState': array([-0.27003924,  0.00155105]), 'effectorPosition': array([-0.51268986,  0.05451426])}
episode index:3245
target Thresh 1.9972666117854778
current state at start:  [-1.13574402 -1.99910209]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.13574402, -1.99910209]), 'currentState': array([4.679484  , 4.54841874]), 'targetState': array([-0.79154872, -0.93371803]), 'effectorPosition': array([-1.01358164, -0.8038528 ])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9329972087914447
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([-1.13574402, -1.99910209]), 'currentState': array([4.10145582, 5.12303356]), 'targetState': array([-0.79154872, -0.93371803]), 'effectorPosition': array([-1.55364128, -0.62016094])}
episode index:3246
target Thresh 1.9972720730987732
current state at start:  [-2.94513162  2.56316532]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.94513162,  2.56316532]), 'currentState': array([3.72650112, 2.08541501]), 'targetState': array([-0.2904238 , -1.34745659]), 'effectorPosition': array([ 0.05723015, -1.00614054])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9330147643169169
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.94513162,  2.56316532]), 'currentState': array([3.57744446, 1.74724031]), 'targetState': array([-0.2904238 , -1.34745659]), 'effectorPosition': array([-0.33176306, -1.2405134 ])}
episode index:3247
target Thresh 1.9972775235003573
current state at start:  [-0.67940933  2.39763274]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.67940933,  2.39763274]), 'currentState': array([5.12336093, 2.89763274]), 'targetState': array([-0.04719672, -0.00704702]), 'effectorPosition': array([0.23326383, 0.06935291])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9330323090323365
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.67940933,  2.39763274]), 'currentState': array([4.75969901, 3.09371137]), 'targetState': array([-0.04719672, -0.00704702]), 'effectorPosition': array([0.04786364, 0.00111875])}
episode index:3248
target Thresh 1.9972829630120317
current state at start:  [-3.66920253  2.29260643]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.66920253,  2.29260643]), 'currentState': array([3.11398278, 2.43623908]), 'targetState': array([-0.14226887, -1.26004789]), 'effectorPosition': array([-0.25642397, -0.64146862])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.933049842947685
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.66920253,  2.29260643]), 'currentState': array([3.61398278, 1.97322311]), 'targetState': array([-0.14226887, -1.26004789]), 'effectorPosition': array([-0.12305716, -1.09615333])}
episode index:3249
target Thresh 1.9972883916555546
current state at start:  [-3.24575611  2.4499048 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.24575611,  2.4499048 ]), 'currentState': array([3.5374292 , 2.03889095]), 'targetState': array([-0.14474245, -0.97770325]), 'effectorPosition': array([-0.16227279, -1.03503341])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9330704429960088
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.24575611,  2.4499048 ]), 'currentState': array([3.5374292 , 2.03889095]), 'targetState': array([-0.14474245, -0.97770325]), 'effectorPosition': array([-0.16227279, -1.03503341])}
episode index:3250
target Thresh 1.9972938094526405
current state at start:  [-2.58382155  2.47355674]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.58382155,  2.47355674]), 'currentState': array([3.55957527, 2.95700629]), 'targetState': array([ 0.15045211, -0.26150892]), 'effectorPosition': array([ 0.05897682, -0.17463456])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9330910303712792
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.58382155,  2.47355674]), 'currentState': array([3.55957527, 2.95700629]), 'targetState': array([ 0.15045211, -0.26150892]), 'effectorPosition': array([ 0.05897682, -0.17463456])}
episode index:3251
target Thresh 1.9972992164249606
current state at start:  [ 3.72796126 -2.87555219]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.72796126, -2.87555219]), 'currentState': array([4.22796126, 2.90763312]), 'targetState': array([ 0.22954492, -0.26980051]), 'effectorPosition': array([ 0.19246934, -0.13207343])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9331116050851872
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.72796126, -2.87555219]), 'currentState': array([4.22796126, 2.90763312]), 'targetState': array([ 0.22954492, -0.26980051]), 'effectorPosition': array([ 0.19246934, -0.13207343])}
episode index:3252
target Thresh 1.9973046125941427
current state at start:  [-0.53492939  2.6889375 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.53492939,  2.6889375 ]), 'currentState': array([6.01721558, 3.15631668]), 'targetState': array([-0.4794532 ,  0.31787322]), 'effectorPosition': array([-0.00376541, -0.01423428])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9331230368081859
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-0.53492939,  2.6889375 ]), 'currentState': array([1.20251539, 2.56220853]), 'targetState': array([-0.4794532 ,  0.31787322]), 'effectorPosition': array([-0.45204293,  0.34936683])}
episode index:3253
target Thresh 1.9973099979817717
current state at start:  [ 0.15367154 -2.3986063 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.15367154, -2.3986063 ]), 'currentState': array([6.23473889, 3.39774085]), 'targetState': array([-0.41123609, -0.48822716]), 'effectorPosition': array([ 0.02031928, -0.25463908])}
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.9331059495267449
{'reset': False, 'endBeforeDone': False, 'stepCount': 14, 'initial state': array([ 0.15367154, -2.3986063 ]), 'currentState': array([2.97098462, 2.2660663 ]), 'targetState': array([-0.41123609, -0.48822716]), 'effectorPosition': array([-0.48456128, -0.69571175])}
episode index:3254
target Thresh 1.9973153726093889
current state at start:  [-0.4288554   2.05359052]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.4288554 ,  2.05359052]), 'currentState': array([5.4482051 , 2.51895777]), 'targetState': array([0.2189612 , 0.00248867]), 'effectorPosition': array([0.5582526 , 0.25231861])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9331234284977044
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.4288554 ,  2.05359052]), 'currentState': array([5.009703  , 2.74100658]), 'targetState': array([0.2189612 , 0.00248867]), 'effectorPosition': array([0.39604171, 0.03854538])}
episode index:3255
target Thresh 1.997320736498493
current state at start:  [ 1.93516297 -2.18410789]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.93516297, -2.18410789]), 'currentState': array([1.81854806, 3.59907742]), 'targetState': array([-0.25277298,  0.19948067]), 'effectorPosition': array([0.40298897, 0.20800793])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9331318660227357
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([ 1.93516297, -2.18410789]), 'currentState': array([1.07160854, 2.87213266]), 'targetState': array([-0.25277298,  0.19948067]), 'effectorPosition': array([-0.21645124,  0.15912033])}
episode index:3256
target Thresh 1.9973260896705396
current state at start:  [-1.44694053  2.19574319]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.44694053,  2.19574319]), 'currentState': array([5.254696  , 2.38850408]), 'targetState': array([0.97514826, 0.0011701 ]), 'effectorPosition': array([0.7253376 , 0.12134741])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.933149326303355
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.44694053,  2.19574319]), 'currentState': array([5.12039229, 1.95241715]), 'targetState': array([0.97514826, 0.0011701 ]), 'effectorPosition': array([ 1.10088959, -0.20782622])}
episode index:3257
target Thresh 1.9973314321469413
current state at start:  [0.07170481 1.64833131]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.07170481, 1.64833131]), 'currentState': array([6.06371645, 2.11454889]), 'targetState': array([0.08669517, 0.2180667 ]), 'effectorPosition': array([0.65738331, 0.73016795])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.933163737191537
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([0.07170481, 1.64833131]), 'currentState': array([5.52336322, 2.82320433]), 'targetState': array([0.08669517, 0.2180667 ]), 'effectorPosition': array([0.25205261, 0.19232043])}
episode index:3258
target Thresh 1.997336763949068
current state at start:  [ 0.70133017 -2.21513895]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.70133017, -2.21513895]), 'currentState': array([1.16511356, 3.85438077]), 'targetState': array([1.14946471, 0.08037368]), 'effectorPosition': array([ 0.69694689, -0.03437946])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9331811769776088
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.70133017, -2.21513895]), 'currentState': array([0.9056867 , 4.35438077]), 'targetState': array([1.14946471, 0.08037368]), 'effectorPosition': array([ 1.13785207, -0.06688652])}
episode index:3259
target Thresh 1.997342085098247
current state at start:  [-0.45477    -2.67528311]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.45477   , -2.67528311]), 'currentState': array([5.76142772, 3.16940981]), 'targetState': array([-0.43253326,  0.1031979 ]), 'effectorPosition': array([-0.01352701, -0.02430564])}
done in step count: 20
reward sum = 0.8179069375972308
running average episode reward sum: 0.93314581678148
{'reset': False, 'endBeforeDone': False, 'stepCount': 21, 'initial state': array([-0.45477   , -2.67528311]), 'currentState': array([1.71026717, 2.65715472]), 'targetState': array([-0.43253326,  0.1031979 ]), 'effectorPosition': array([-0.47718483,  0.04920312])}
episode index:3260
target Thresh 1.9973473956157628
current state at start:  [0.61324939 1.78861569]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.61324939, 1.78861569]), 'currentState': array([0.96394888, 2.26449009]), 'targetState': array([-0.33388866,  0.55831932]), 'effectorPosition': array([-0.42595059,  0.73471275])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9331663179109552
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.61324939, 1.78861569]), 'currentState': array([0.96394888, 2.26449009]), 'targetState': array([-0.33388866,  0.55831932]), 'effectorPosition': array([-0.42595059,  0.73471275])}
episode index:3261
target Thresh 1.9973526955228575
current state at start:  [ 3.82319628 -1.59620135]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.82319628, -1.59620135]), 'currentState': array([4.1494992 , 4.24787913]), 'targetState': array([-0.7487203 , -0.15237036]), 'effectorPosition': array([-1.05067875,  0.01024081])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9331837408668376
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.82319628, -1.59620135]), 'currentState': array([4.58002549, 3.83513163]), 'targetState': array([-0.7487203 , -0.15237036]), 'effectorPosition': array([-0.66415909, -0.14462261])}
episode index:3262
target Thresh 1.9973579848407308
current state at start:  [-0.02576588  2.60456849]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.02576588,  2.60456849]), 'currentState': array([5.84729366, 3.10232337]), 'targetState': array([0.0094475 , 0.05714066]), 'effectorPosition': array([0.01727482, 0.03526272])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.933204217808037
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.02576588,  2.60456849]), 'currentState': array([5.84729366, 3.10232337]), 'targetState': array([0.0094475 , 0.05714066]), 'effectorPosition': array([0.01727482, 0.03526272])}
episode index:3263
target Thresh 1.99736326359054
current state at start:  [ 3.83511033 -1.95403858]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.83511033, -1.95403858]), 'currentState': array([3.40304833, 4.50064368]), 'targetState': array([-0.9567455,  0.6450053]), 'effectorPosition': array([-1.01570464,  0.74027766])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9332246822020909
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.83511033, -1.95403858]), 'currentState': array([3.40304833, 4.50064368]), 'targetState': array([-0.9567455,  0.6450053]), 'effectorPosition': array([-1.01570464,  0.74027766])}
episode index:3264
target Thresh 1.9973685317934
current state at start:  [ 0.04722149 -2.5622038 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.04722149, -2.5622038 ]), 'currentState': array([5.86244712, 3.2229012 ]), 'targetState': array([ 0.72227465, -0.08552508]), 'effectorPosition': array([-0.03015703, -0.07548504])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.933239039114127
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 0.04722149, -2.5622038 ]), 'currentState': array([5.00678284, 2.36079595]), 'targetState': array([ 0.72227465, -0.08552508]), 'effectorPosition': array([ 0.7576088 , -0.07295814])}
episode index:3265
target Thresh 1.9973737894703836
current state at start:  [-1.38390156 -1.76262352]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.38390156, -1.76262352]), 'currentState': array([4.48058156, 4.88687804]), 'targetState': array([-0.48233635, -1.03956863]), 'effectorPosition': array([-1.22809473, -0.91596578])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.932953295378942
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([-1.38390156, -1.76262352]), 'currentState': array([4.29660084, 5.02217029]), 'targetState': array([-0.48233635, -1.03956863]), 'effectorPosition': array([-1.39829758, -0.80898987])}
episode index:3266
target Thresh 1.9973790366425217
current state at start:  [1.62741391 2.6297773 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.62741391, 2.6297773 ]), 'currentState': array([1.31133179, 2.96907471]), 'targetState': array([ 0.00967896, -0.00791441]), 'effectorPosition': array([-0.16210894,  0.05838997])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9329738177862335
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.62741391, 2.6297773 ]), 'currentState': array([1.31133179, 2.96907471]), 'targetState': array([ 0.00967896, -0.00791441]), 'effectorPosition': array([-0.16210894,  0.05838997])}
episode index:3267
target Thresh 1.9973842733308027
current state at start:  [-0.1070864   1.58270816]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.1070864 ,  1.58270816]), 'currentState': array([5.87950217, 1.56007065]), 'targetState': array([0.93278946, 0.52553326]), 'effectorPosition': array([1.32226933, 0.52254643])}
done in step count: 34
reward sum = 0.7105532272722921
running average episode reward sum: 0.9329057576300174
{'reset': False, 'endBeforeDone': False, 'stepCount': 35, 'initial state': array([-0.1070864 ,  1.58270816]), 'currentState': array([1.56503563, 4.16473874]), 'targetState': array([0.93278946, 0.52553326]), 'effectorPosition': array([0.85649738, 0.47439131])}
episode index:3268
target Thresh 1.9973894995561738
current state at start:  [ 0.35786693 -1.61496817]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.35786693, -1.61496817]), 'currentState': array([6.14335563, 4.24372391]), 'targetState': array([ 0.45006133, -1.1220411 ]), 'effectorPosition': array([ 0.41860672, -0.95988386])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.932926282023523
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.35786693, -1.61496817]), 'currentState': array([6.14335563, 4.24372391]), 'targetState': array([ 0.45006133, -1.1220411 ]), 'effectorPosition': array([ 0.41860672, -0.95988386])}
episode index:3269
target Thresh 1.9973947153395395
current state at start:  [-1.69390317 -2.70549165]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.69390317, -2.70549165]), 'currentState': array([4.48844746, 3.42169407]), 'targetState': array([-0.48771553,  0.25400028]), 'effectorPosition': array([-0.27820482,  0.02339373])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9329437357599072
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.69390317, -2.70549165]), 'currentState': array([4.33875862, 3.54606627]), 'targetState': array([-0.48771553,  0.25400028]), 'effectorPosition': array([-0.3958361 ,  0.06851597])}
episode index:3270
target Thresh 1.997399920701763
current state at start:  [0.96645819 1.90998881]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.96645819, 1.90998881]), 'currentState': array([1.28961437, 2.39632832]), 'targetState': array([-0.38683603,  0.29728911]), 'effectorPosition': array([-0.57797268,  0.44286595])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9329642359935484
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.96645819, 1.90998881]), 'currentState': array([1.28961437, 2.39632832]), 'targetState': array([-0.38683603,  0.29728911]), 'effectorPosition': array([-0.57797268,  0.44286595])}
episode index:3271
target Thresh 1.9974051156636659
current state at start:  [ 4.2616239  -2.52176186]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.2616239 , -2.52176186]), 'currentState': array([4.66547329, 3.26142345]), 'targetState': array([-0.08153938, -0.10936058]), 'effectorPosition': array([-0.11974899, -0.00155679])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9329847236964843
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.2616239 , -2.52176186]), 'currentState': array([4.66547329, 3.26142345]), 'targetState': array([-0.08153938, -0.10936058]), 'effectorPosition': array([-0.11974899, -0.00155679])}
episode index:3272
target Thresh 1.997410300246028
current state at start:  [-0.97734646 -1.97472955]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.97734646, -1.97472955]), 'currentState': array([4.82017004, 3.88057312]), 'targetState': array([ 0.04882317, -0.26232001]), 'effectorPosition': array([-0.64156663, -0.33178456])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9329931597754038
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([-0.97734646, -1.97472955]), 'currentState': array([4.12037319, 2.78713166]), 'targetState': array([ 0.04882317, -0.26232001]), 'effectorPosition': array([ 0.25332617, -0.24527217])}
episode index:3273
target Thresh 1.9974154744695878
current state at start:  [0.08741104 1.75231137]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.08741104, 1.75231137]), 'currentState': array([0.58741104, 2.16802131]), 'targetState': array([-0.00492753,  0.90195242]), 'effectorPosition': array([-0.09398376,  0.93084214])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9330136261285572
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.08741104, 1.75231137]), 'currentState': array([0.58741104, 2.16802131]), 'targetState': array([-0.00492753,  0.90195242]), 'effectorPosition': array([-0.09398376,  0.93084214])}
episode index:3274
target Thresh 1.9974206383550417
current state at start:  [1.18800813 2.44970738]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.18800813, 2.44970738]), 'currentState': array([0.75922093, 2.06277906]), 'targetState': array([0.20683666, 0.9830683 ]), 'effectorPosition': array([-0.22399097,  1.00253641])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9330250109755409
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([1.18800813, 2.44970738]), 'currentState': array([0.36518786, 1.88774059]), 'targetState': array([0.20683666, 0.9830683 ]), 'effectorPosition': array([0.30360722, 1.13335506])}
episode index:3275
target Thresh 1.9974257919230458
current state at start:  [1.39965405 2.36715359]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.39965405, 2.36715359]), 'currentState': array([0.89965405, 2.44968185]), 'targetState': array([0.07756556, 0.82145995]), 'effectorPosition': array([-0.35661794,  0.57685962])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9330424026083322
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.39965405, 2.36715359]), 'currentState': array([0.41846298, 2.09600073]), 'targetState': array([0.07756556, 0.82145995]), 'effectorPosition': array([0.10399895, 0.99317897])}
episode index:3276
target Thresh 1.997430935194214
current state at start:  [0.60897438 2.32035726]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.60897438, 2.32035726]), 'currentState': array([1.10897438, 1.93093761]), 'targetState': array([-0.62006023,  1.07417229]), 'effectorPosition': array([-0.54925504,  0.9967477 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9330628351983205
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.60897438, 2.32035726]), 'currentState': array([1.10897438, 1.93093761]), 'targetState': array([-0.62006023,  1.07417229]), 'effectorPosition': array([-0.54925504,  0.9967477 ])}
episode index:3277
target Thresh 1.99743606818912
current state at start:  [-2.43710761  2.23355823]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.43710761,  2.23355823]), 'currentState': array([3.42122831, 1.74010518]), 'targetState': array([-0.22787462, -1.19659979]), 'effectorPosition': array([-0.52714119, -1.17691118])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9330771845469483
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-2.43710761,  2.23355823]), 'currentState': array([3.42736556, 1.90725634]), 'targetState': array([-0.22787462, -1.19659979]), 'effectorPosition': array([-0.37659303, -1.09447812])}
episode index:3278
target Thresh 1.9974411909282948
current state at start:  [-3.91077268  2.00514214]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.91077268,  2.00514214]), 'currentState': array([1.87241263, 2.48821344]), 'targetState': array([-0.15721708,  0.11154629]), 'effectorPosition': array([-0.64161724,  0.01609084])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9330945443564795
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.91077268,  2.00514214]), 'currentState': array([1.37241263, 2.83977889]), 'targetState': array([-0.15721708,  0.11154629]), 'effectorPosition': array([-0.28251383,  0.10289853])}
episode index:3279
target Thresh 1.99744630343223
current state at start:  [ 2.2041711  -2.25294861]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.2041711 , -2.25294861]), 'currentState': array([2.06089362, 3.57726146]), 'targetState': array([0.05177026, 0.01315949]), 'effectorPosition': array([0.32836986, 0.28106447])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.933111893580761
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 2.2041711 , -2.25294861]), 'currentState': array([1.97929649, 3.1074988 ]), 'targetState': array([0.05177026, 0.01315949]), 'effectorPosition': array([-0.03151331, -0.01300727])}
episode index:3280
target Thresh 1.9974514057213757
current state at start:  [-0.58290429  1.80547946]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.58290429,  1.80547946]), 'currentState': array([6.08811032, 2.24566018]), 'targetState': array([0.30486932, 0.6660474 ]), 'effectorPosition': array([0.51944125, 0.6932523 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9331322800807363
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.58290429,  1.80547946]), 'currentState': array([6.08811032, 2.24566018]), 'targetState': array([0.30486932, 0.6660474 ]), 'effectorPosition': array([0.51944125, 0.6932523 ])}
episode index:3281
target Thresh 1.9974564978161409
current state at start:  [-2.16674355 -1.78596023]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.16674355, -1.78596023]), 'currentState': array([4.49565059, 4.27124381]), 'targetState': array([-0.54747284, -0.76004597]), 'effectorPosition': array([-1.00633356, -0.36516053])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9328479618966776
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([-2.16674355, -1.78596023]), 'currentState': array([4.52649692, 4.18637225]), 'targetState': array([-0.54747284, -0.76004597]), 'effectorPosition': array([-0.94193958, -0.32949163])}
episode index:3282
target Thresh 1.9974615797368938
current state at start:  [-3.63369059  2.33102372]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.63369059,  2.33102372]), 'currentState': array([2.14949471, 2.64133325]), 'targetState': array([-0.3255029 , -0.30372095]), 'effectorPosition': array([-0.46857615, -0.15974998])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9328684163706659
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.63369059,  2.33102372]), 'currentState': array([2.14949471, 2.64133325]), 'targetState': array([-0.3255029 , -0.30372095]), 'effectorPosition': array([-0.46857615, -0.15974998])}
episode index:3283
target Thresh 1.9974666515039625
current state at start:  [-4.30735723  2.78022278]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.30735723,  2.78022278]), 'currentState': array([1.58958867, 3.20359922]), 'targetState': array([ 0.49835845, -0.16134251]), 'effectorPosition': array([0.06191979, 0.00308589])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9328858133206138
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-4.30735723,  2.78022278]), 'currentState': array([1.28859934, 3.57835299]), 'targetState': array([ 0.49835845, -0.16134251]), 'effectorPosition': array([ 0.43241508, -0.02763288])}
episode index:3284
target Thresh 1.9974717131376336
current state at start:  [0.4732937  2.01633781]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.4732937 , 2.01633781]), 'currentState': array([6.25842084, 2.41664323]), 'targetState': array([0.69284622, 0.3327447 ]), 'effectorPosition': array([0.26780952, 0.65666746])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9329001859801814
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([0.4732937 , 2.01633781]), 'currentState': array([5.76494107, 2.24335081]), 'targetState': array([0.69284622, 0.3327447 ]), 'effectorPosition': array([0.71499167, 0.49276209])}
episode index:3285
target Thresh 1.997476764658154
current state at start:  [ 3.02934405 -1.93549383]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.02934405, -1.93549383]), 'currentState': array([3.15757861, 3.86794627]), 'targetState': array([0.02723886, 0.03647645]), 'effectorPosition': array([-0.26298323,  0.66002849])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9329175626734315
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.02934405, -1.93549383]), 'currentState': array([3.4352129 , 3.36794627]), 'targetState': array([0.02723886, 0.03647645]), 'effectorPosition': array([-0.08937022,  0.20743803])}
episode index:3286
target Thresh 1.9974818060857296
current state at start:  [-3.8117042   2.04906442]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.8117042 ,  2.04906442]), 'currentState': array([2.00583901, 1.82066185]), 'targetState': array([-1.3467453 , -0.21731518]), 'effectorPosition': array([-1.19592623,  0.27425013])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9329349287937011
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.8117042 ,  2.04906442]), 'currentState': array([2.50583901, 1.59579711]), 'targetState': array([-1.3467453 , -0.21731518]), 'effectorPosition': array([-1.3781088 , -0.22543242])}
episode index:3287
target Thresh 1.9974868374405264
current state at start:  [-1.88011763 -1.79698853]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.88011763, -1.79698853]), 'currentState': array([4.21359767, 3.98619678]), 'targetState': array([-0.20052723,  0.02326104]), 'effectorPosition': array([-0.81732595,  0.06263886])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9329522843506373
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.88011763, -1.79698853]), 'currentState': array([4.60806714, 3.48619678]), 'targetState': array([-0.20052723,  0.02326104]), 'effectorPosition': array([-0.34210953, -0.02329257])}
episode index:3288
target Thresh 1.9974918587426693
current state at start:  [-2.06202042 -1.86853024]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.06202042, -1.86853024]), 'currentState': array([3.80810458, 4.63748693]), 'targetState': array([-1.15025183,  0.11343905]), 'effectorPosition': array([-1.34368095,  0.21179574])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9329726697916982
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.06202042, -1.86853024]), 'currentState': array([3.80810458, 4.63748693]), 'targetState': array([-1.15025183,  0.11343905]), 'effectorPosition': array([-1.34368095,  0.21179574])}
episode index:3289
target Thresh 1.997496870012244
current state at start:  [-3.08212883  1.90276688]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.08212883,  1.90276688]), 'currentState': array([2.71904099, 2.40276688]), 'targetState': array([-0.35414532, -0.05950463]), 'effectorPosition': array([-0.51396919, -0.50726328])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9329900033267159
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.08212883,  1.90276688]), 'currentState': array([2.21904099, 2.77256852]), 'targetState': array([-0.35414532, -0.05950463]), 'effectorPosition': array([-0.32818162, -0.16412568])}
episode index:3290
target Thresh 1.9975018712692953
current state at start:  [ 0.14297979 -2.01773723]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.14297979, -2.01773723]), 'currentState': array([5.9261651 , 4.58552103]), 'targetState': array([ 0.02968501, -1.16195736]), 'effectorPosition': array([ 0.47171791, -1.23467665])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9330073263278319
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.14297979, -2.01773723]), 'currentState': array([5.44172179, 4.53603642]), 'targetState': array([ 0.02968501, -1.16195736]), 'effectorPosition': array([-0.18459069, -1.2708448 ])}
episode index:3291
target Thresh 1.9975068625338284
current state at start:  [-2.05144707 -2.15120616]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.05144707, -2.15120616]), 'currentState': array([3.73349017, 4.41477491]), 'targetState': array([-1.05836407,  0.68154004]), 'effectorPosition': array([-1.11993765,  0.39907348])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.933024638804646
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.05144707, -2.15120616]), 'currentState': array([3.23349017, 4.61846834]), 'targetState': array([-1.05836407,  0.68154004]), 'effectorPosition': array([-0.99375728,  0.90822973])}
episode index:3292
target Thresh 1.9975118438258084
current state at start:  [ 0.22710951 -1.71435972]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.22710951, -1.71435972]), 'currentState': array([0.31620034, 4.10102673]), 'targetState': array([ 0.36765949, -0.57767084]), 'effectorPosition': array([ 0.65952905, -0.64579753])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.933041940766746
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.22710951, -1.71435972]), 'currentState': array([0.25248054, 3.78294461]), 'targetState': array([ 0.36765949, -0.57767084]), 'effectorPosition': array([ 0.34186646, -0.52967163])}
episode index:3293
target Thresh 1.9975168151651603
current state at start:  [-1.35363243  2.01362587]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.35363243,  2.01362587]), 'currentState': array([5.3675971 , 2.26926206]), 'targetState': array([ 1.25809408, -0.06562722]), 'effectorPosition': array([0.82474484, 0.18360023])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.933059232223708
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.35363243,  2.01362587]), 'currentState': array([5.27383455, 1.83553867]), 'targetState': array([ 1.25809408, -0.06562722]), 'effectorPosition': array([ 1.21009432, -0.11113303])}
episode index:3294
target Thresh 1.9975217765717697
current state at start:  [-2.82169681  1.80473745]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.82169681,  1.80473745]), 'currentState': array([3.46284426, 2.29641902]), 'targetState': array([ 0.37986976, -0.44738966]), 'effectorPosition': array([-0.08297723, -0.8160343 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9330765131850969
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.82169681,  1.80473745]), 'currentState': array([3.86121563, 2.75217527]), 'targetState': array([ 0.37986976, -0.44738966]), 'effectorPosition': array([ 0.19392142, -0.33486366])}
episode index:3295
target Thresh 1.9975267280654818
current state at start:  [ 2.36408529 -2.07648772]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.36408529, -2.07648772]), 'currentState': array([2.30469457, 3.92031331]), 'targetState': array([0.200821  , 0.84904177]), 'effectorPosition': array([0.32853874, 0.68442451])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.933096817641048
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.36408529, -2.07648772]), 'currentState': array([2.30469457, 3.92031331]), 'targetState': array([0.200821  , 0.84904177]), 'effectorPosition': array([0.32853874, 0.68442451])}
episode index:3296
target Thresh 1.997531669666103
current state at start:  [ 0.6211844  -2.10290728]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.6211844 , -2.10290728]), 'currentState': array([0.48071092, 4.45084934]), 'targetState': array([ 1.16817331, -0.45150934]), 'effectorPosition': array([ 1.10408722, -0.51366833])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.933117109780071
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.6211844 , -2.10290728]), 'currentState': array([0.48071092, 4.45084934]), 'targetState': array([ 1.16817331, -0.45150934]), 'effectorPosition': array([ 1.10408722, -0.51366833])}
episode index:3297
target Thresh 1.9975366013933997
current state at start:  [-0.69478795  1.90827628]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.69478795,  1.90827628]), 'currentState': array([5.2382147 , 2.38340856]), 'targetState': array([0.29846864, 0.27001434]), 'effectorPosition': array([0.7322005 , 0.10821625])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9331343574726786
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.69478795,  1.90827628]), 'currentState': array([5.33751725, 2.74982982]), 'targetState': array([0.29846864, 0.27001434]), 'effectorPosition': array([0.35394826, 0.16200558])}
episode index:3298
target Thresh 1.9975415232670986
current state at start:  [-1.5160821   1.98341022]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.5160821 ,  1.98341022]), 'currentState': array([4.26710321, 1.53176973]), 'targetState': array([ 0.3089423 , -1.36504343]), 'effectorPosition': array([ 0.45427952, -1.36808753])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9331546259305529
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.5160821 ,  1.98341022]), 'currentState': array([4.26710321, 1.53176973]), 'targetState': array([ 0.3089423 , -1.36504343]), 'effectorPosition': array([ 0.45427952, -1.36808753])}
episode index:3299
target Thresh 1.9975464353068872
current state at start:  [-0.71064937  1.69416843]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.71064937,  1.69416843]), 'currentState': array([5.07253594, 1.42008785]), 'targetState': array([ 1.20294185, -0.68998033]), 'effectorPosition': array([ 1.33055958, -0.72793436])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9331748821045133
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.71064937,  1.69416843]), 'currentState': array([5.07253594, 1.42008785]), 'targetState': array([ 1.20294185, -0.68998033]), 'effectorPosition': array([ 1.33055958, -0.72793436])}
episode index:3300
target Thresh 1.9975513375324139
current state at start:  [-3.62440951  1.92203849]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.62440951,  1.92203849]), 'currentState': array([3.09476744, 2.03983262]), 'targetState': array([-0.6488608 , -0.97489828]), 'effectorPosition': array([-0.58912553, -0.86537702])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9331951260057236
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.62440951,  1.92203849]), 'currentState': array([3.09476744, 2.03983262]), 'targetState': array([-0.6488608 , -0.97489828]), 'effectorPosition': array([-0.58912553, -0.86537702])}
episode index:3301
target Thresh 1.9975562299632872
current state at start:  [ 2.19301814 -1.96842433]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.19301814, -1.96842433]), 'currentState': array([2.32809388, 3.89450779]), 'targetState': array([-0.01379495,  0.36734575]), 'effectorPosition': array([0.31120527, 0.66614855])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9332123291777389
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 2.19301814, -1.96842433]), 'currentState': array([2.31442027, 3.45753094]), 'targetState': array([-0.01379495,  0.36734575]), 'effectorPosition': array([0.19518174, 0.24676621])}
episode index:3302
target Thresh 1.9975611126190773
current state at start:  [ 1.99806337 -2.49695691]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.99806337, -2.49695691]), 'currentState': array([2.19445964, 4.2749382 ]), 'targetState': array([-0.37688781,  1.12040734]), 'effectorPosition': array([0.39869974, 0.99688273])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9329297944126229
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([ 1.99806337, -2.49695691]), 'currentState': array([2.6615084 , 3.94390191]), 'targetState': array([-0.37688781,  1.12040734]), 'effectorPosition': array([0.06157714, 0.77853174])}
episode index:3303
target Thresh 1.9975659855193146
current state at start:  [-1.38994311  1.80807716]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.38994311,  1.80807716]), 'currentState': array([5.29287626, 2.10734254]), 'targetState': array([ 1.15812089, -0.37638951]), 'effectorPosition': array([0.98678214, 0.06260852])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.9329352605916447
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([-1.38994311,  1.80807716]), 'currentState': array([4.89012115, 1.76742372]), 'targetState': array([ 1.15812089, -0.37638951]), 'effectorPosition': array([ 1.10753993, -0.61857065])}
episode index:3304
target Thresh 1.9975708486834909
current state at start:  [ 2.81982632 -2.23292873]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.81982632, -2.23292873]), 'currentState': array([2.54161104, 3.55025658]), 'targetState': array([0.03864038, 0.45406509]), 'effectorPosition': array([0.15640853, 0.37447459])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9329555524946426
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.81982632, -2.23292873]), 'currentState': array([2.54161104, 3.55025658]), 'targetState': array([0.03864038, 0.45406509]), 'effectorPosition': array([0.15640853, 0.37447459])}
episode index:3305
target Thresh 1.9975757021310585
current state at start:  [-3.21081042  2.39937187]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.21081042,  2.39937187]), 'currentState': array([2.57237488, 2.89830489]), 'targetState': array([0.35215095, 0.23024903]), 'effectorPosition': array([-0.15464129, -0.18703914])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9329728073184493
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.21081042,  2.39937187]), 'currentState': array([2.07237488, 3.39830489]), 'targetState': array([0.35215095, 0.23024903]), 'effectorPosition': array([0.20687129, 0.1508122 ])}
episode index:3306
target Thresh 1.9975805458814313
current state at start:  [-3.55254418  1.84301302]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.55254418,  1.84301302]), 'currentState': array([2.23064112, 2.32045266]), 'targetState': array([-0.39117082, -0.36406681]), 'effectorPosition': array([-0.77359096, -0.19693273])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9329900517069227
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.55254418,  1.84301302]), 'currentState': array([2.6018067 , 2.57908097]), 'targetState': array([-0.39117082, -0.36406681]), 'effectorPosition': array([-0.40627146, -0.37829482])}
episode index:3307
target Thresh 1.9975853799539847
current state at start:  [-0.52117218  1.71683516]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.52117218,  1.71683516]), 'currentState': array([6.13315086, 2.21683516]), 'targetState': array([0.25567445, 0.99646454]), 'effectorPosition': array([0.51285069, 0.73001896])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9330072856695264
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.52117218,  1.71683516]), 'currentState': array([0.23426582, 1.86205806]), 'targetState': array([0.25567445, 0.99646454]), 'effectorPosition': array([0.47101559, 1.09718832])}
episode index:3308
target Thresh 1.9975902043680545
current state at start:  [-1.45994232 -2.01287597]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.45994232, -2.01287597]), 'currentState': array([4.32324299, 4.70111836]), 'targetState': array([-1.07534182, -0.24606344]), 'effectorPosition': array([-1.30029708, -0.53543137])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9330215173752775
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.45994232, -2.01287597]), 'currentState': array([4.19486859, 4.39347474]), 'targetState': array([-1.07534182, -0.24606344]), 'effectorPosition': array([-1.16484027, -0.12678994])}
episode index:3309
target Thresh 1.9975950191429386
current state at start:  [ 1.69803951 -1.69073539]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.69803951, -1.69073539]), 'currentState': array([1.9368841, 4.2111703]), 'targetState': array([0.68511614, 0.90064494]), 'effectorPosition': array([0.63291851, 0.7990149 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9330417525664029
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.69803951, -1.69073539]), 'currentState': array([1.9368841, 4.2111703]), 'targetState': array([0.68511614, 0.90064494]), 'effectorPosition': array([0.63291851, 0.7990149 ])}
episode index:3310
target Thresh 1.9975998242978958
current state at start:  [2.1970079  1.80199755]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.1970079 , 1.80199755]), 'currentState': array([2.66691789, 2.15355954]), 'targetState': array([-0.7273544 , -0.80950116]), 'effectorPosition': array([-0.78156331, -0.53711494])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9330589552989409
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([2.1970079 , 1.80199755]), 'currentState': array([3.11610124, 2.01108358]), 'targetState': array([-0.7273544 , -0.80950116]), 'effectorPosition': array([-0.59667203, -0.88970996])}
episode index:3311
target Thresh 1.9976046198521473
current state at start:  [-1.88558869 -2.19447858]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.88558869, -2.19447858]), 'currentState': array([4.24158122, 3.97710765]), 'targetState': array([-0.73987061,  0.1302693 ]), 'effectorPosition': array([-0.81028211,  0.04302605])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9330791669670269
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.88558869, -2.19447858]), 'currentState': array([4.24158122, 3.97710765]), 'targetState': array([-0.73987061,  0.1302693 ]), 'effectorPosition': array([-0.81028211,  0.04302605])}
episode index:3312
target Thresh 1.997609405824875
current state at start:  [-1.25299754  2.18158279]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.25299754,  2.18158279]), 'currentState': array([4.53018777, 1.73392738]), 'targetState': array([ 0.16928128, -0.87469599]), 'effectorPosition': array([ 0.81862339, -1.00251622])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9330963480213682
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.25299754,  2.18158279]), 'currentState': array([4.03018777, 2.13037039]), 'targetState': array([ 0.16928128, -0.87469599]), 'effectorPosition': array([ 0.36198761, -0.89850677])}
episode index:3313
target Thresh 1.997614182235223
current state at start:  [2.11274059 2.03979945]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.11274059, 2.03979945]), 'currentState': array([1.61626236, 1.91736841]), 'targetState': array([-0.93295449,  0.93847166]), 'effectorPosition': array([-0.96958264,  0.61689389])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9331105313804445
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([2.11274059, 2.03979945]), 'currentState': array([1.52530618, 1.84169428]), 'targetState': array([-0.93295449,  0.93847166]), 'effectorPosition': array([-0.92922858,  0.77546163])}
episode index:3314
target Thresh 1.9976189491022964
current state at start:  [ 1.42559767 -2.19756632]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.42559767, -2.19756632]), 'currentState': array([1.03203732, 3.58561898]), 'targetState': array([ 0.047251  , -0.46364002]), 'effectorPosition': array([ 0.41848014, -0.13717016])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.9331102160913123
{'reset': False, 'endBeforeDone': False, 'stepCount': 8, 'initial state': array([ 1.42559767, -2.19756632]), 'currentState': array([3.4688262 , 2.63136437]), 'targetState': array([ 0.047251  , -0.46364002]), 'effectorPosition': array([ 0.03636797, -0.50339973])}
episode index:3315
target Thresh 1.9976237064451632
current state at start:  [-2.10881545  2.38539547]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.10881545,  2.38539547]), 'currentState': array([3.7000276 , 1.88539547]), 'targetState': array([ 0.03081145, -1.37267769]), 'effectorPosition': array([-0.08180353, -1.17236409])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.933130387919994
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.10881545,  2.38539547]), 'currentState': array([3.7000276 , 1.88539547]), 'targetState': array([ 0.03081145, -1.37267769]), 'effectorPosition': array([-0.08180353, -1.17236409])}
episode index:3316
target Thresh 1.9976284542828524
current state at start:  [-2.22884286  2.08873358]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.22884286,  2.08873358]), 'currentState': array([3.5637145 , 2.55132535]), 'targetState': array([-0.00115155, -0.03156984]), 'effectorPosition': array([ 0.07367515, -0.57705122])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9331475328135966
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.22884286,  2.08873358]), 'currentState': array([3.15543863, 3.03301805]), 'targetState': array([-0.00115155, -0.03156984]), 'effectorPosition': array([-0.00438755, -0.10843255])}
episode index:3317
target Thresh 1.9976331926343558
current state at start:  [ 3.91942962 -2.03762605]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.91942962, -2.03762605]), 'currentState': array([3.41942962, 4.64878075]), 'targetState': array([-1.23726815,  0.6353814 ]), 'effectorPosition': array([-1.17424481,  0.70286445])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.933167681236498
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.91942962, -2.03762605]), 'currentState': array([3.41942962, 4.64878075]), 'targetState': array([-1.23726815,  0.6353814 ]), 'effectorPosition': array([-1.17424481,  0.70286445])}
episode index:3318
target Thresh 1.9976379215186266
current state at start:  [ 0.3031974 -2.8352389]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.3031974, -2.8352389]), 'currentState': array([6.26862829, 3.82668499]), 'targetState': array([-0.20520695, -0.44211041]), 'effectorPosition': array([ 0.21640492, -0.63596199])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9331848045624284
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.3031974, -2.8352389]), 'currentState': array([5.9433686 , 3.46646926]), 'targetState': array([-0.20520695, -0.44211041]), 'effectorPosition': array([-0.05707262, -0.31837475])}
episode index:3319
target Thresh 1.9976426409545802
current state at start:  [-1.62807479  3.06686564]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.62807479,  3.06686564]), 'currentState': array([4.38747296, 3.56686564]), 'targetState': array([-0.56449461,  0.57822396]), 'effectorPosition': array([-0.4194178 ,  0.04729092])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9331989356453916
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.62807479,  3.06686564]), 'currentState': array([3.59733573, 3.98144615]), 'targetState': array([-0.56449461,  0.57822396]), 'effectorPosition': array([-0.62619505,  0.52224127])}
episode index:3320
target Thresh 1.9976473509610946
current state at start:  [-1.85864584 -2.08476671]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.85864584, -2.08476671]), 'currentState': array([4.70819517, 4.65812395]), 'targetState': array([-1.03255288, -0.84338629]), 'effectorPosition': array([-1.00248556, -0.94156566])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9332190503892502
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.85864584, -2.08476671]), 'currentState': array([4.70819517, 4.65812395]), 'targetState': array([-1.03255288, -0.84338629]), 'effectorPosition': array([-1.00248556, -0.94156566])}
episode index:3321
target Thresh 1.9976520515570095
current state at start:  [-1.69580938  2.09571599]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.69580938,  2.09571599]), 'currentState': array([4.2979955 , 2.58536106]), 'targetState': array([ 0.48857523, -0.5125998 ]), 'effectorPosition': array([ 0.42260409, -0.35057689])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9332391530230886
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.69580938,  2.09571599]), 'currentState': array([4.2979955 , 2.58536106]), 'targetState': array([ 0.48857523, -0.5125998 ]), 'effectorPosition': array([ 0.42260409, -0.35057689])}
episode index:3322
target Thresh 1.9976567427611276
current state at start:  [-3.74033238  2.35536329]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.74033238,  2.35536329]), 'currentState': array([2.07002895, 2.85536329]), 'targetState': array([-0.09787894,  0.48121382]), 'effectorPosition': array([-0.26735572, -0.09945024])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.9332444948518207
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([-3.74033238,  2.35536329]), 'currentState': array([0.59884743, 2.70885475]), 'targetState': array([-0.09787894,  0.48121382]), 'effectorPosition': array([-0.16024965,  0.39834415])}
episode index:3323
target Thresh 1.9976614245922137
current state at start:  [ 3.01176135 -2.25726954]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.01176135, -2.25726954]), 'currentState': array([2.5223002 , 4.46053996]), 'targetState': array([-0.5900609 ,  1.15805795]), 'effectorPosition': array([-0.04922487,  1.22441283])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9329637353768352
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([ 3.01176135, -2.25726954]), 'currentState': array([2.15655603, 4.11466357]), 'targetState': array([-0.5900609 ,  1.15805795]), 'effectorPosition': array([0.44709581, 0.82132692])}
episode index:3324
target Thresh 1.997666097068995
current state at start:  [1.67890826 2.45809946]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.67890826, 2.45809946]), 'currentState': array([2.15541911, 2.06777147]), 'targetState': array([-0.97906429, -0.27619601]), 'effectorPosition': array([-1.02180331, -0.0487895 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9329838966594286
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.67890826, 2.45809946]), 'currentState': array([2.15541911, 2.06777147]), 'targetState': array([-0.97906429, -0.27619601]), 'effectorPosition': array([-1.02180331, -0.0487895 ])}
episode index:3325
target Thresh 1.9976707602101615
current state at start:  [-1.83804665  2.09070656]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.83804665,  2.09070656]), 'currentState': array([4.78560498, 2.56984303]), 'targetState': array([ 0.701012  , -0.33564065]), 'effectorPosition': array([ 0.55128877, -0.11903627])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9329980626556225
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.83804665,  2.09070656]), 'currentState': array([4.58445864, 2.26911786]), 'targetState': array([ 0.701012  , -0.33564065]), 'effectorPosition': array([ 0.71410814, -0.45186671])}
episode index:3326
target Thresh 1.9976754140343658
current state at start:  [-1.50979496  2.6155986 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.50979496,  2.6155986 ]), 'currentState': array([4.27339035, 2.1338581 ]), 'targetState': array([-0.36485381, -0.90333231]), 'effectorPosition': array([ 0.56728077, -0.7814326 ])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9330122201360387
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.50979496,  2.6155986 ]), 'currentState': array([3.27339035, 2.26405565]), 'targetState': array([-0.36485381, -0.90333231]), 'effectorPosition': array([-0.25674078, -0.80993154])}
episode index:3327
target Thresh 1.997680058560223
current state at start:  [-0.93788236  2.4135979 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.93788236,  2.4135979 ]), 'currentState': array([4.89170314, 2.73700132]), 'targetState': array([ 0.08769979, -0.05618649]), 'effectorPosition': array([ 0.40173131, -0.00923402])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9330263691083537
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-0.93788236,  2.4135979 ]), 'currentState': array([4.47193187, 2.99674137]), 'targetState': array([ 0.08769979, -0.05618649]), 'effectorPosition': array([ 0.13769833, -0.04454665])}
episode index:3328
target Thresh 1.9976846938063113
current state at start:  [-0.34332388  1.88809115]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.34332388,  1.88809115]), 'currentState': array([5.95768175, 2.04876533]), 'targetState': array([0.643706  , 0.48651231]), 'effectorPosition': array([0.79561437, 0.6686137 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.933046487351337
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.34332388,  1.88809115]), 'currentState': array([5.95768175, 2.04876533]), 'targetState': array([0.643706  , 0.48651231]), 'effectorPosition': array([0.79561437, 0.6686137 ])}
episode index:3329
target Thresh 1.9976893197911718
current state at start:  [-0.42138176 -1.62472261]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.42138176, -1.62472261]), 'currentState': array([5.53232349, 4.1584627 ]), 'targetState': array([ 0.81502428, -0.78652515]), 'effectorPosition': array([-0.23372679, -0.94515126])}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9330433937198285
{'reset': False, 'endBeforeDone': False, 'stepCount': 9, 'initial state': array([-0.42138176, -1.62472261]), 'currentState': array([4.4263389 , 1.94337074]), 'targetState': array([ 0.81502428, -0.78652515]), 'effectorPosition': array([ 0.71409408, -0.87294947])}
episode index:3330
target Thresh 1.9976939365333084
current state at start:  [1.29710306 2.25319149]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.29710306, 2.25319149]), 'currentState': array([0.79710306, 2.16321293]), 'targetState': array([0.25329785, 1.1334604 ]), 'effectorPosition': array([-0.28483241,  0.89562023])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9330604926709782
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.29710306, 2.25319149]), 'currentState': array([0.29710306, 1.76582707]), 'targetState': array([0.25329785, 1.1334604 ]), 'effectorPosition': array([0.48368104, 1.17407805])}
episode index:3331
target Thresh 1.997698544051188
current state at start:  [ 3.5888742  -1.63932969]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.5888742 , -1.63932969]), 'currentState': array([3.677448  , 4.16784967]), 'targetState': array([-0.40399142,  0.08522959]), 'effectorPosition': array([-0.85114837,  0.48938561])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9330775813586519
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.5888742 , -1.63932969]), 'currentState': array([4.07351601, 3.66784967]), 'targetState': array([-0.40399142,  0.08522959]), 'effectorPosition': array([-0.48391301,  0.19089722])}
episode index:3332
target Thresh 1.997703142363241
current state at start:  [-2.99876409  2.12183606]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.99876409,  2.12183606]), 'currentState': array([3.72372449, 1.94317098]), 'targetState': array([-0.25222078, -1.09074416]), 'effectorPosition': array([-0.01926386, -1.12781744])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9330976600921177
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.99876409,  2.12183606]), 'currentState': array([3.72372449, 1.94317098]), 'targetState': array([-0.25222078, -1.09074416]), 'effectorPosition': array([-0.01926386, -1.12781744])}
episode index:3333
target Thresh 1.9977077314878602
current state at start:  [1.18557002 2.0345583 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.18557002, 2.0345583 ]), 'currentState': array([0.68557002, 2.41704253]), 'targetState': array([0.31060175, 0.82169489]), 'effectorPosition': array([-0.22518209,  0.67208458])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9331147273806323
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.18557002, 2.0345583 ]), 'currentState': array([0.18557002, 2.01232631]), 'targetState': array([0.31060175, 0.82169489]), 'effectorPosition': array([0.39603223, 0.99423943])}
episode index:3334
target Thresh 1.9977123114434021
current state at start:  [1.9100997  2.22212394]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.9100997 , 2.22212394]), 'currentState': array([2.36699586, 2.64663084]), 'targetState': array([-0.46816461, -0.67734494]), 'effectorPosition': array([-0.41800069, -0.25554203])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9331317844338914
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.9100997 , 2.22212394]), 'currentState': array([2.80221544, 2.35953446]), 'targetState': array([-0.46816461, -0.67734494]), 'effectorPosition': array([-0.50857219, -0.56782501])}
episode index:3335
target Thresh 1.997716882248187
current state at start:  [-1.64079596 -1.83565869]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.64079596, -1.83565869]), 'currentState': array([4.31616904, 4.93121199]), 'targetState': array([-0.87181452, -0.91514809]), 'effectorPosition': array([-1.37024028, -0.74605848])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9328520686711714
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([-1.64079596, -1.83565869]), 'currentState': array([3.93271319, 5.21958546]), 'targetState': array([-0.87181452, -0.91514809]), 'effectorPosition': array([-1.66615552, -0.44202142])}
episode index:3336
target Thresh 1.9977214439204978
current state at start:  [-3.30567641  2.2697881 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.30567641,  2.2697881 ]), 'currentState': array([2.47750889, 2.7697881 ]), 'targetState': array([-0.02345827, -0.03990716]), 'effectorPosition': array([-0.27771993, -0.24397766])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9328691942124746
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.30567641,  2.2697881 ]), 'currentState': array([2.07514124, 3.13967402]), 'targetState': array([-0.02345827, -0.03990716]), 'effectorPosition': array([-0.00168063, -0.00092554])}
episode index:3337
target Thresh 1.9977259964785812
current state at start:  [0.53286617 2.20887945]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.53286617, 2.20887945]), 'currentState': array([0.03286617, 2.08955519]), 'targetState': array([0.69154217, 0.54062536]), 'effectorPosition': array([0.47538804, 0.88453427])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9328863094928183
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.53286617, 2.20887945]), 'currentState': array([5.85076967, 1.9871607 ]), 'targetState': array([0.69154217, 0.54062536]), 'effectorPosition': array([0.92400667, 0.58080586])}
episode index:3338
target Thresh 1.9977305399406473
current state at start:  [-3.50734137  2.36606803]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.50734137,  2.36606803]), 'currentState': array([3.22805148, 2.16444058]), 'targetState': array([-0.33498168, -0.76163869]), 'effectorPosition': array([-0.36739159, -0.86385905])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9329064094300771
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.50734137,  2.36606803]), 'currentState': array([3.22805148, 2.16444058]), 'targetState': array([-0.33498168, -0.76163869]), 'effectorPosition': array([-0.36739159, -0.86385905])}
episode index:3339
target Thresh 1.9977350743248705
current state at start:  [-0.58813698  2.24100775]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.58813698,  2.24100775]), 'currentState': array([5.21139174, 2.74100775]), 'targetState': array([0.00066765, 0.02454749]), 'effectorPosition': array([0.38029109, 0.11710064])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9329235033194693
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.58813698,  2.24100775]), 'currentState': array([4.83996889, 3.08841482]), 'targetState': array([0.00066765, 0.02454749]), 'effectorPosition': array([0.05290064, 0.00536073])}
episode index:3340
target Thresh 1.9977395996493876
current state at start:  [0.39247396 2.14976389]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.39247396, 2.14976389]), 'currentState': array([0.25841371, 2.4685531 ]), 'targetState': array([0.19632962, 0.62721253]), 'effectorPosition': array([0.05152945, 0.65839476])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9329435800918968
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.39247396, 2.14976389]), 'currentState': array([0.25841371, 2.4685531 ]), 'targetState': array([0.19632962, 0.62721253]), 'effectorPosition': array([0.05152945, 0.65839476])}
episode index:3341
target Thresh 1.9977441159323006
current state at start:  [0.37108082 2.09494558]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.37108082, 2.09494558]), 'currentState': array([0.13908686, 2.59494558]), 'targetState': array([-0.00576601,  0.0891427 ]), 'effectorPosition': array([0.07225239, 0.53500942])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.932960652629272
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.37108082, 2.09494558]), 'currentState': array([6.04653772, 3.09494558]), 'targetState': array([-0.00576601,  0.0891427 ]), 'effectorPosition': array([0.01198967, 0.04507553])}
episode index:3342
target Thresh 1.9977486231916741
current state at start:  [-2.12356492  2.68774558]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.12356492,  2.68774558]), 'currentState': array([4.64102421, 2.23839868]), 'targetState': array([ 0.67207673, -0.48916981]), 'effectorPosition': array([ 0.75614998, -0.43592139])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9329807062779022
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.12356492,  2.68774558]), 'currentState': array([4.64102421, 2.23839868]), 'targetState': array([ 0.67207673, -0.48916981]), 'effectorPosition': array([ 0.75614998, -0.43592139])}
episode index:3343
target Thresh 1.9977531214455375
current state at start:  [-1.82312671 -2.20340824]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.82312671, -2.20340824]), 'currentState': array([4.41784135, 3.63768214]), 'targetState': array([-0.35606212,  0.22603628]), 'effectorPosition': array([-0.49048721,  0.02282553])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9330007479327234
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.82312671, -2.20340824]), 'currentState': array([4.41784135, 3.63768214]), 'targetState': array([-0.35606212,  0.22603628]), 'effectorPosition': array([-0.49048721,  0.02282553])}
episode index:3344
target Thresh 1.9977576107118837
current state at start:  [-0.22513414  1.61819307]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.22513414,  1.61819307]), 'currentState': array([6.07644544, 2.11819307]), 'targetState': array([0.1633081, 0.6264996]), 'effectorPosition': array([0.64459903, 0.73726511])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9330177880678705
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.22513414,  1.61819307]), 'currentState': array([0.06653306, 2.5477791 ]), 'targetState': array([0.1633081, 0.6264996]), 'effectorPosition': array([0.13360881, 0.56966905])}
episode index:3345
target Thresh 1.9977620910086697
current state at start:  [-1.89588848 -1.86774828]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.89588848, -1.86774828]), 'currentState': array([4.2106389 , 3.92667617]), 'targetState': array([-0.3223756 ,  0.06012842]), 'effectorPosition': array([-0.76051836,  0.0833867 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9330348180176409
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.89588848, -1.86774828]), 'currentState': array([4.60702314, 3.53362746]), 'targetState': array([-0.3223756 ,  0.06012842]), 'effectorPosition': array([-0.38792969, -0.03526308])}
episode index:3346
target Thresh 1.9977665623538168
current state at start:  [ 3.34159272 -1.92284509]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.34159272, -1.92284509]), 'currentState': array([3.78899076, 3.92540742]), 'targetState': array([0.07085748, 0.01523676]), 'effectorPosition': array([-0.6585251,  0.387161 ])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9330488799184424
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 3.34159272, -1.92284509]), 'currentState': array([4.67612445, 2.94180401]), 'targetState': array([0.07085748, 0.01523676]), 'effectorPosition': array([ 0.1976105 , -0.02707394])}
episode index:3347
target Thresh 1.9977710247652103
current state at start:  [-1.07559976 -1.82490187]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.07559976, -1.82490187]), 'currentState': array([4.77220059, 4.81173117]), 'targetState': array([-0.41128434, -0.72882006]), 'effectorPosition': array([-0.92758579, -1.15669457])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9327701914835803
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([-1.07559976, -1.82490187]), 'currentState': array([4.41547465, 4.4797401 ]), 'targetState': array([-0.41128434, -0.72882006]), 'effectorPosition': array([-1.15559875, -0.45108739])}
episode index:3348
target Thresh 1.9977754782607
current state at start:  [0.81366692 1.76983647]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.81366692, 1.76983647]), 'currentState': array([0.47055275, 2.25432755]), 'targetState': array([-0.07420278,  0.52519925]), 'effectorPosition': array([-0.02310676,  0.85813537])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9327872801095929
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.81366692, 1.76983647]), 'currentState': array([0.51158645, 2.63526591]), 'targetState': array([-0.07420278,  0.52519925]), 'effectorPosition': array([-0.12801723,  0.48430152])}
episode index:3349
target Thresh 1.9977799228580997
current state at start:  [-2.0488482   2.37450816]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.0488482 ,  2.37450816]), 'currentState': array([3.79010709, 2.83097132]), 'targetState': array([ 0.028654  , -0.27000319]), 'effectorPosition': array([ 0.14647323, -0.27250304])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9328073436080676
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.0488482 ,  2.37450816]), 'currentState': array([3.79010709, 2.83097132]), 'targetState': array([ 0.028654  , -0.27000319]), 'effectorPosition': array([ 0.14647323, -0.27250304])}
episode index:3350
target Thresh 1.9977843585751878
current state at start:  [ 2.36221606 -1.8163056 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.36221606, -1.8163056 ]), 'currentState': array([1.90610683, 3.97505061]), 'targetState': array([0.37205482, 0.55434164]), 'effectorPosition': array([0.59120702, 0.55302285])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9328273951319088
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.36221606, -1.8163056 ]), 'currentState': array([1.90610683, 3.97505061]), 'targetState': array([0.37205482, 0.55434164]), 'effectorPosition': array([0.59120702, 0.55302285])}
episode index:3351
target Thresh 1.9977887854297072
current state at start:  [-1.79138097 -2.24438548]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.79138097, -2.24438548]), 'currentState': array([4.52565879, 4.40502426]), 'targetState': array([-1.17959916, -0.32543174]), 'effectorPosition': array([-1.06604522, -0.50838152])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9328474346918337
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.79138097, -2.24438548]), 'currentState': array([4.52565879, 4.40502426]), 'targetState': array([-1.17959916, -0.32543174]), 'effectorPosition': array([-1.06604522, -0.50838152])}
episode index:3352
target Thresh 1.9977932034393655
current state at start:  [-1.44057773 -2.01136327]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.44057773, -2.01136327]), 'currentState': array([4.41695463, 3.77182204]), 'targetState': array([ 0.0075922 , -0.02991032]), 'effectorPosition': array([-0.619731  , -0.01219809])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.932864479894729
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.44057773, -2.01136327]), 'currentState': array([4.72782641, 3.27182204]), 'targetState': array([ 0.0075922 , -0.02991032]), 'effectorPosition': array([-0.1297154 , -0.01047151])}
episode index:3353
target Thresh 1.9977976126218346
current state at start:  [ 2.58524404 -1.57568762]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.58524404, -1.57568762]), 'currentState': array([2.79103884, 4.20749769]), 'targetState': array([-0.704993  ,  0.85007992]), 'effectorPosition': array([-0.18431974,  0.99930057])}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.9328587114891204
{'reset': False, 'endBeforeDone': False, 'stepCount': 10, 'initial state': array([ 2.58524404, -1.57568762]), 'currentState': array([1.37605344, 2.06516319]), 'targetState': array([-0.704993  ,  0.85007992]), 'effectorPosition': array([-0.76193325,  0.6859365 ])}
episode index:3354
target Thresh 1.9978020129947511
current state at start:  [ 3.93089786 -1.90776908]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.93089786, -1.90776908]), 'currentState': array([3.48050207, 4.0838917 ]), 'targetState': array([-0.34195549,  1.17859586]), 'effectorPosition': array([-0.65756053,  0.6259029 ])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9328669789402413
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([ 3.93089786, -1.90776908]), 'currentState': array([2.53138241, 4.6435047 ]), 'targetState': array([-0.34195549,  1.17859586]), 'effectorPosition': array([-0.19143887,  1.35118153])}
episode index:3355
target Thresh 1.997806404575717
current state at start:  [-1.26002675  1.75941946]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.26002675,  1.75941946]), 'currentState': array([4.52315856, 2.01769089]), 'targetState': array([ 0.49386865, -0.71037023]), 'effectorPosition': array([ 0.77888474, -0.72732678])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9328840030823925
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.26002675,  1.75941946]), 'currentState': array([4.11670391, 2.26395713]), 'targetState': array([ 0.49386865, -0.71037023]), 'effectorPosition': array([ 0.43417704, -0.73044287])}
episode index:3356
target Thresh 1.997810787382298
current state at start:  [-1.69844193  2.2394208 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.69844193,  2.2394208 ]), 'currentState': array([4.08474338, 2.72241917]), 'targetState': array([ 0.02405094, -0.03497448]), 'effectorPosition': array([ 0.2785954 , -0.30908462])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9329010170820701
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.69844193,  2.2394208 ]), 'currentState': array([3.86746986, 3.21059519]), 'targetState': array([ 0.02405094, -0.03497448]), 'effectorPosition': array([-0.04754682,  0.04998761])}
episode index:3357
target Thresh 1.9978151614320256
current state at start:  [-2.68701172  2.02604399]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.68701172,  2.02604399]), 'currentState': array([3.27706787, 2.48513709]), 'targetState': array([ 0.22466968, -0.26405262]), 'effectorPosition': array([-0.12350561, -0.63279185])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.932918020948335
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.68701172,  2.02604399]), 'currentState': array([3.47975916, 2.87188904]), 'targetState': array([ 0.22466968, -0.26405262]), 'effectorPosition': array([ 0.0542928 , -0.26334858])}
episode index:3358
target Thresh 1.997819526742396
current state at start:  [0.8411644  2.08471768]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.8411644 , 2.08471768]), 'currentState': array([0.3411644 , 1.82487907]), 'targetState': array([-0.01541854,  1.06544042]), 'effectorPosition': array([0.38165231, 1.16259456])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.9329234011296246
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([0.8411644 , 2.08471768]), 'currentState': array([0.63106888, 2.20216187]), 'targetState': array([-0.01541854,  1.06544042]), 'effectorPosition': array([-0.14543468,  0.89350632])}
episode index:3359
target Thresh 1.9978238833308706
current state at start:  [-0.30117347  2.8011067 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.30117347,  2.8011067 ]), 'currentState': array([5.48201184, 3.27435887]), 'targetState': array([-0.01664201, -0.04994284]), 'effectorPosition': array([-0.08894531, -0.09843639])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.932943364403098
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.30117347,  2.8011067 ]), 'currentState': array([5.48201184, 3.27435887]), 'targetState': array([-0.01664201, -0.04994284]), 'effectorPosition': array([-0.08894531, -0.09843639])}
episode index:3360
target Thresh 1.9978282312148756
current state at start:  [-3.81661093  1.92208312]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.81661093,  1.92208312]), 'currentState': array([1.96657437, 2.42208312]), 'targetState': array([-0.10494048,  0.25913349]), 'effectorPosition': array([-0.70363263, -0.02535813])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9329573949403182
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-3.81661093,  1.92208312]), 'currentState': array([1.13645971, 2.83760933]), 'targetState': array([-0.10494048,  0.25913349]), 'effectorPosition': array([-0.25223759,  0.16754904])}
episode index:3361
target Thresh 1.9978325704118025
current state at start:  [ 3.32915982 -1.98485512]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.32915982, -1.98485512]), 'currentState': array([3.27705866, 4.17604396]), 'targetState': array([-1.00449347,  0.60215268]), 'effectorPosition': array([-0.60061069,  0.78566627])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.9329571296080655
{'reset': False, 'endBeforeDone': False, 'stepCount': 8, 'initial state': array([ 3.32915982, -1.98485512]), 'currentState': array([1.43583992, 1.99900405]), 'targetState': array([-1.00449347,  0.60215268]), 'effectorPosition': array([-0.82276198,  0.70184094])}
episode index:3362
target Thresh 1.9978369009390082
current state at start:  [-2.14370873  1.99495818]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.14370873,  1.99495818]), 'currentState': array([3.6907352 , 2.49495818]), 'targetState': array([ 0.05987195, -0.07337865]), 'effectorPosition': array([ 0.14227904, -0.6192936 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9329740915082713
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.14370873,  1.99495818]), 'currentState': array([3.43271215, 2.99495818]), 'targetState': array([ 0.05987195, -0.07337865]), 'effectorPosition': array([ 0.03165703, -0.14304196])}
episode index:3363
target Thresh 1.9978412228138147
current state at start:  [-0.03319779  2.26310676]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.03319779,  2.26310676]), 'currentState': array([0.07088376, 2.76310676]), 'targetState': array([-0.2210737 ,  0.17220282]), 'effectorPosition': array([0.04442648, 0.37359861])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9329881003990239
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-0.03319779,  2.26310676]), 'currentState': array([0.39684174, 2.8965814 ]), 'targetState': array([-0.2210737 ,  0.17220282]), 'effectorPosition': array([-0.06620959,  0.23525964])}
episode index:3364
target Thresh 1.9978455360535097
current state at start:  [-2.48472701  1.70761105]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.48472701,  1.70761105]), 'currentState': array([4.01842278, 2.15972533]), 'targetState': array([ 0.20038168, -1.09803209]), 'effectorPosition': array([ 0.35489758, -0.87355948])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9330050430140613
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.48472701,  1.70761105]), 'currentState': array([4.05336258, 1.70182168]), 'targetState': array([ 0.20038168, -1.09803209]), 'effectorPosition': array([ 0.25146845, -1.29439641])}
episode index:3365
target Thresh 1.997849840675346
current state at start:  [-2.6284882   2.13588509]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.6284882 ,  2.13588509]), 'currentState': array([4.08952464, 2.56758482]), 'targetState': array([ 0.80997732, -0.18481694]), 'effectorPosition': array([ 0.34753714, -0.44693961])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.933016122621009
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-2.6284882 ,  2.13588509]), 'currentState': array([5.03051494, 2.05760076]), 'targetState': array([ 0.80997732, -0.18481694]), 'effectorPosition': array([ 1.00594852, -0.22904087])}
episode index:3366
target Thresh 1.9978541366965419
current state at start:  [-1.66284848  1.96943154]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.66284848,  1.96943154]), 'currentState': array([4.26342135, 2.42108937]), 'targetState': array([ 0.43752809, -0.29471494]), 'effectorPosition': array([ 0.48650834, -0.51025688])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9330360168524848
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.66284848,  1.96943154]), 'currentState': array([4.26342135, 2.42108937]), 'targetState': array([ 0.43752809, -0.29471494]), 'effectorPosition': array([ 0.48650834, -0.51025688])}
episode index:3367
target Thresh 1.997858424134282
current state at start:  [-0.73847605 -2.26419656]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.73847605, -2.26419656]), 'currentState': array([5.14936366, 3.60833253]), 'targetState': array([ 0.07904113, -0.231606  ]), 'effectorPosition': array([-0.36243015, -0.28734015])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.9330413476223921
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([-0.73847605, -2.26419656]), 'currentState': array([3.87421125, 2.94122398]), 'targetState': array([ 0.07904113, -0.231606  ]), 'effectorPosition': array([ 0.11824189, -0.16134535])}
episode index:3368
target Thresh 1.9978627030057157
current state at start:  [-1.56120529  2.16312161]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.56120529,  2.16312161]), 'currentState': array([4.22198002, 2.66312161]), 'targetState': array([-0.11454994,  0.13398244]), 'effectorPosition': array([ 0.35326538, -0.31591728])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9330582543164786
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.56120529,  2.16312161]), 'currentState': array([3.74329654, 3.16312161]), 'targetState': array([-0.11454994,  0.13398244]), 'effectorPosition': array([-0.01237652,  0.01761533])}
episode index:3369
target Thresh 1.9978669733279586
current state at start:  [-1.85080446  2.75919747]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.85080446,  2.75919747]), 'currentState': array([3.93238085, 2.33485403]), 'targetState': array([ 0.05100934, -0.82031887]), 'effectorPosition': array([ 0.2965876 , -0.72685757])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9330751509769187
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.85080446,  2.75919747]), 'currentState': array([3.50987565, 2.14520179]), 'targetState': array([ 0.05100934, -0.82031887]), 'effectorPosition': array([-0.12380606, -0.9476289 ])}
episode index:3370
target Thresh 1.997871235118092
current state at start:  [ 0.88908053 -2.15650562]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.88908053, -2.15650562]), 'currentState': array([1.15795112, 3.72284904]), 'targetState': array([ 0.12543874, -0.06622923]), 'effectorPosition': array([ 0.56883333, -0.06986933])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9330920376126419
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.88908053, -2.15650562]), 'currentState': array([1.4966234 , 3.29988334]), 'targetState': array([ 0.12543874, -0.06622923]), 'effectorPosition': array([0.15812353, 0.00078626])}
episode index:3371
target Thresh 1.9978754883931629
current state at start:  [-0.19484819  2.03949729]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.19484819,  2.03949729]), 'currentState': array([0.17895507, 1.65176725]), 'targetState': array([0.7607577 , 1.18546606]), 'effectorPosition': array([0.7270212 , 1.14441043])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.933111879831618
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.19484819,  2.03949729]), 'currentState': array([0.17895507, 1.65176725]), 'targetState': array([0.7607577 , 1.18546606]), 'effectorPosition': array([0.7270212 , 1.14441043])}
episode index:3372
target Thresh 1.9978797331701847
current state at start:  [-1.92689343 -1.95061615]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.92689343, -1.95061615]), 'currentState': array([4.05847229, 4.62603075]), 'targetState': array([-1.12835877, -0.10054951]), 'effectorPosition': array([-1.34658293, -0.11921647])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.93313171028527
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.92689343, -1.95061615]), 'currentState': array([4.05847229, 4.62603075]), 'targetState': array([-1.12835877, -0.10054951]), 'effectorPosition': array([-1.34658293, -0.11921647])}
episode index:3373
target Thresh 1.9978839694661363
current state at start:  [ 2.70855625 -2.08327577]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.70855625, -2.08327577]), 'currentState': array([2.20855625, 3.76003423]), 'targetState': array([0.55267936, 0.07120757]), 'effectorPosition': array([0.35552464, 0.4940003 ])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9331456309401944
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 2.70855625, -2.08327577]), 'currentState': array([1.44005289, 3.68830496]), 'targetState': array([0.55267936, 0.07120757]), 'effectorPosition': array([0.53444764, 0.07673999])}
episode index:3374
target Thresh 1.997888197297963
current state at start:  [0.29089871 2.33131307]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.29089871, 2.33131307]), 'currentState': array([6.14346931, 2.83131307]), 'targetState': array([ 0.01096027, -0.21525982]), 'effectorPosition': array([0.08980656, 0.29569967])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9331624766791751
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.29089871, 2.33131307]), 'currentState': array([5.64346931, 3.33131307]), 'targetState': array([ 0.01096027, -0.21525982]), 'effectorPosition': array([-0.09818369, -0.16200606])}
episode index:3375
target Thresh 1.9978924166825758
current state at start:  [-0.49840911 -2.213281  ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.49840911, -2.213281  ]), 'currentState': array([5.2847762 , 4.04978141]), 'targetState': array([-0.45461326, -0.80432415]), 'effectorPosition': array([-0.4542926 , -0.75051235])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9331822745237606
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.49840911, -2.213281  ]), 'currentState': array([5.2847762 , 4.04978141]), 'targetState': array([-0.45461326, -0.80432415]), 'effectorPosition': array([-0.4542926 , -0.75051235])}
episode index:3376
target Thresh 1.9978966276368528
current state at start:  [-2.23152429 -1.72381393]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.23152429, -1.72381393]), 'currentState': array([4.40387937, 5.007272  ]), 'targetState': array([-0.60579145, -1.06041931]), 'effectorPosition': array([-1.30354611, -0.93916101])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9329059398259448
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([-2.23152429, -1.72381393]), 'currentState': array([4.00983194, 5.48238558]), 'targetState': array([-0.60579145, -1.06041931]), 'effectorPosition': array([-1.64389813, -0.83058084])}
episode index:3377
target Thresh 1.9979008301776375
current state at start:  [1.70007565 2.68142712]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.70007565, 2.68142712]), 'currentState': array([2.20007565, 2.73739924]), 'targetState': array([-0.35069902, -0.48826575]), 'effectorPosition': array([-0.36537217, -0.16632306])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9329228415607507
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.70007565, 2.68142712]), 'currentState': array([2.70007565, 2.53535668]), 'targetState': array([-0.35069902, -0.48826575]), 'effectorPosition': array([-0.40458556, -0.4389915 ])}
episode index:3378
target Thresh 1.99790502432174
current state at start:  [ 2.29371522 -2.17211693]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.29371522, -2.17211693]), 'currentState': array([2.54376052, 3.64553482]), 'targetState': array([0.07834961, 0.22235065]), 'effectorPosition': array([0.16903783, 0.46909985])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9329397332915701
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 2.29371522, -2.17211693]), 'currentState': array([2.64882125, 3.17479886]), 'targetState': array([0.07834961, 0.22235065]), 'effectorPosition': array([0.01522026, 0.02951092])}
episode index:3379
target Thresh 1.997909210085937
current state at start:  [2.02039734 2.13205674]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.02039734, 2.13205674]), 'currentState': array([2.35680453, 2.23654086]), 'targetState': array([-0.70415357, -0.12384759]), 'effectorPosition': array([-0.82630064, -0.28624739])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9329595736071643
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.02039734, 2.13205674]), 'currentState': array([2.35680453, 2.23654086]), 'targetState': array([-0.70415357, -0.12384759]), 'effectorPosition': array([-0.82630064, -0.28624739])}
episode index:3380
target Thresh 1.9979133874869717
current state at start:  [-2.14699207  2.53936652]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.14699207,  2.53936652]), 'currentState': array([3.63619323, 2.14385257]), 'targetState': array([-0.55005711, -0.7721578 ]), 'effectorPosition': array([-0.0040853 , -0.95685848])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9329735163538053
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-2.14699207,  2.53936652]), 'currentState': array([3.04520237, 2.13982991]), 'targetState': array([-0.55005711, -0.7721578 ]), 'effectorPosition': array([-0.54011667, -0.79412697])}
episode index:3381
target Thresh 1.9979175565415535
current state at start:  [ 3.43484159 -2.14024847]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.43484159, -2.14024847]), 'currentState': array([3.91697558, 3.74836783]), 'targetState': array([-0.03979507, -0.03292726]), 'effectorPosition': array([-0.52663159,  0.28227092])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9329903781171541
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.43484159, -2.14024847]), 'currentState': array([4.39674597, 3.32652764]), 'targetState': array([-0.03979507, -0.03292726]), 'effectorPosition': array([-0.18009162,  0.04087289])}
episode index:3382
target Thresh 1.9979217172663588
current state at start:  [-2.04751263  2.85209948]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.04751263,  2.85209948]), 'currentState': array([4.72841194, 2.62966376]), 'targetState': array([1.02507674, 0.7194794 ]), 'effectorPosition': array([ 0.49185092, -0.12033363])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9330014063825645
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-2.04751263,  2.85209948]), 'currentState': array([6.21045208, 1.72316651]), 'targetState': array([1.02507674, 0.7194794 ]), 'effectorPosition': array([0.9178033 , 0.92416153])}
episode index:3383
target Thresh 1.9979258696780302
current state at start:  [ 0.90737531 -1.70016474]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.90737531, -1.70016474]), 'currentState': array([0.42305142, 4.14895359]), 'targetState': array([ 0.9328309 , -0.76905873]), 'effectorPosition': array([ 0.77191712, -0.57961757])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9330212050213402
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.90737531, -1.70016474]), 'currentState': array([0.42305142, 4.14895359]), 'targetState': array([ 0.9328309 , -0.76905873]), 'effectorPosition': array([ 0.77191712, -0.57961757])}
episode index:3384
target Thresh 1.9979300137931777
current state at start:  [-1.89287987  2.3548816 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.89287987,  2.3548816 ]), 'currentState': array([3.95861504, 2.8548816 ]), 'targetState': array([ 0.04774185, -0.02981822]), 'effectorPosition': array([ 0.17825439, -0.22330926])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9330409919622498
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.89287987,  2.3548816 ]), 'currentState': array([3.95861504, 2.8548816 ]), 'targetState': array([ 0.04774185, -0.02981822]), 'effectorPosition': array([ 0.17825439, -0.22330926])}
episode index:3385
target Thresh 1.9979341496283773
current state at start:  [ 3.00488595 -1.83944779]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.00488595, -1.83944779]), 'currentState': array([2.63699488, 4.02007005]), 'targetState': array([0.13073668, 0.63099154]), 'effectorPosition': array([0.0555484 , 0.84868517])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9330607672156572
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.00488595, -1.83944779]), 'currentState': array([2.63699488, 4.02007005]), 'targetState': array([0.13073668, 0.63099154]), 'effectorPosition': array([0.0555484 , 0.84868517])}
episode index:3386
target Thresh 1.997938277200173
current state at start:  [ 0.82008657 -2.88823517]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.82008657, -2.88823517]), 'currentState': array([0.6297673 , 3.67538412]), 'targetState': array([-0.41875201, -1.09255151]), 'effectorPosition': array([ 0.41209026, -0.32926174])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.933071761674702
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 0.82008657, -2.88823517]), 'currentState': array([5.52831996, 4.33231515]), 'targetState': array([-0.41875201, -1.09255151]), 'effectorPosition': array([-0.17814468, -1.10737817])}
episode index:3387
target Thresh 1.9979423965250747
current state at start:  [ 3.47122695 -1.89434988]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.47122695, -1.89434988]), 'currentState': array([3.97122695, 3.91486972]), 'targetState': array([-0.33688282,  0.11385344]), 'effectorPosition': array([-0.7072551 ,  0.26179984])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9330885645785759
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.47122695, -1.89434988]), 'currentState': array([4.47122695, 3.46191943]), 'targetState': array([-0.33688282,  0.11385344]), 'effectorPosition': array([-0.31791327,  0.02580701])}
episode index:3388
target Thresh 1.9979465076195597
current state at start:  [ 0.77588778 -2.43423847]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.77588778, -2.43423847]), 'currentState': array([0.61062201, 3.89323478]), 'targetState': array([ 0.33410653, -0.72069514]), 'effectorPosition': array([ 0.61226742, -0.40495866])}
done in step count: 14
reward sum = 0.8687458127689782
running average episode reward sum: 0.9330695788152801
{'reset': False, 'endBeforeDone': False, 'stepCount': 15, 'initial state': array([ 0.77588778, -2.43423847]), 'currentState': array([0.26774103, 4.03236392]), 'targetState': array([ 0.33410653, -0.72069514]), 'effectorPosition': array([ 0.56366796, -0.65165437])}
episode index:3389
target Thresh 1.9979506105000724
current state at start:  [1.22343588 2.94834116]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.22343588, 2.94834116]), 'currentState': array([1.7032491, 2.6169183]), 'targetState': array([-0.81164766, -0.66888822]), 'effectorPosition': array([-0.51430806,  0.06717879])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9330834520958656
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([1.22343588, 2.94834116]), 'currentState': array([2.7032491 , 2.03562418]), 'targetState': array([-0.81164766, -0.66888822]), 'effectorPosition': array([-0.87897477, -0.5752091 ])}
episode index:3390
target Thresh 1.9979547051830244
current state at start:  [ 1.83614375 -1.88836207]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.83614375, -1.88836207]), 'currentState': array([1.81244528, 3.94191344]), 'targetState': array([-0.25345903,  0.29980992]), 'effectorPosition': array([0.62409568, 0.46642413])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.9330887327204024
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([ 1.83614375, -1.88836207]), 'currentState': array([1.00553604, 2.90461694]), 'targetState': array([-0.25345903,  0.29980992]), 'effectorPosition': array([-0.1832765 ,  0.14934825])}
episode index:3391
target Thresh 1.9979587916847945
current state at start:  [1.23784201 1.95961164]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.23784201, 1.95961164]), 'currentState': array([1.73784201, 2.34034727]), 'targetState': array([-1.24732964,  0.20721296]), 'effectorPosition': array([-0.75880291,  0.18053413])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9331055108062748
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.23784201, 1.95961164]), 'currentState': array([2.23784201, 1.84618346]), 'targetState': array([-1.24732964,  0.20721296]), 'effectorPosition': array([-1.20648926, -0.02333772])}
episode index:3392
target Thresh 1.9979628700217285
current state at start:  [-0.21944561 -1.90301661]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.21944561, -1.90301661]), 'currentState': array([6.11778038, 3.88016869]), 'targetState': array([-0.38849544, -0.14905869]), 'effectorPosition': array([ 0.14616625, -0.70695084])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.9331052042448545
{'reset': False, 'endBeforeDone': False, 'stepCount': 8, 'initial state': array([-0.21944561, -1.90301661]), 'currentState': array([5.46287027, 3.55310955]), 'targetState': array([-0.38849544, -0.14905869]), 'effectorPosition': array([-0.23560839, -0.33385392])}
episode index:3393
target Thresh 1.9979669402101399
current state at start:  [-3.89417517  1.87710166]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.89417517,  1.87710166]), 'currentState': array([1.88901014, 2.2472777 ]), 'targetState': array([-0.52334979,  0.16244298]), 'effectorPosition': array([-0.85762908,  0.11120282])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.933119050678489
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-3.89417517,  1.87710166]), 'currentState': array([1.7781258 , 2.71538432]), 'targetState': array([-0.52334979,  0.16244298]), 'effectorPosition': array([-0.42298267,  0.00244262])}
episode index:3394
target Thresh 1.9979710022663093
current state at start:  [-0.59461666 -2.25778162]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.59461666, -2.25778162]), 'currentState': array([5.28904682, 3.68451805]), 'targetState': array([-0.06770743, -0.47058146]), 'effectorPosition': array([-0.3546935 , -0.40223202])}
done in step count: 25
reward sum = 0.7778213593991467
running average episode reward sum: 0.9330733076177292
{'reset': False, 'endBeforeDone': False, 'stepCount': 26, 'initial state': array([-0.59461666, -2.25778162]), 'currentState': array([3.45669291, 2.49863223]), 'targetState': array([-0.06770743, -0.47058146]), 'effectorPosition': array([-0.00403174, -0.63192971])}
episode index:3395
target Thresh 1.9979750562064853
current state at start:  [-1.32062626 -1.99789859]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.32062626, -1.99789859]), 'currentState': array([4.46255905, 3.83981451]), 'targetState': array([-0.49054119, -0.06518429]), 'effectorPosition': array([-0.68075616, -0.06780909])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9330930151243201
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.32062626, -1.99789859]), 'currentState': array([4.46255905, 3.83981451]), 'targetState': array([-0.49054119, -0.06518429]), 'effectorPosition': array([-0.68075616, -0.06780909])}
episode index:3396
target Thresh 1.9979791020468833
current state at start:  [0.42977367 2.46140732]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.42977367, 2.46140732]), 'currentState': array([0.38399151, 2.84845881]), 'targetState': array([-0.11573948,  0.31210185]), 'effectorPosition': array([-0.06869857,  0.28389157])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9331127110280221
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.42977367, 2.46140732]), 'currentState': array([0.38399151, 2.84845881]), 'targetState': array([-0.11573948,  0.31210185]), 'effectorPosition': array([-0.06869857,  0.28389157])}
episode index:3397
target Thresh 1.997983139803687
current state at start:  [-3.55043696  2.39570459]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.55043696,  2.39570459]), 'currentState': array([2.23274835, 2.82291528]), 'targetState': array([ 0.30990357, -0.01042099]), 'effectorPosition': array([-0.27808528, -0.15286365])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9331294524314864
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.55043696,  2.39570459]), 'currentState': array([1.73274835, 3.23191022]), 'targetState': array([ 0.30990357, -0.01042099]), 'effectorPosition': array([0.08835736, 0.01856599])}
episode index:3398
target Thresh 1.9979871694930469
current state at start:  [-1.93500085  1.70936003]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.93500085,  1.70936003]), 'currentState': array([3.84818446, 2.1601795 ]), 'targetState': array([ 0.19624007, -0.47517411]), 'effectorPosition': array([ 0.20189465, -0.92062034])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.933146183984169
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.93500085,  1.70936003]), 'currentState': array([3.44484301, 2.62253508]), 'targetState': array([ 0.19624007, -0.47517411]), 'effectorPosition': array([ 0.02243296, -0.51275982])}
episode index:3399
target Thresh 1.9979911911310821
current state at start:  [-1.21422804  2.05739103]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.21422804,  2.05739103]), 'currentState': array([5.53093772, 1.95686838]), 'targetState': array([1.26554635, 0.12947939]), 'effectorPosition': array([1.08820212, 0.25042194])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9331658468712325
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.21422804,  2.05739103]), 'currentState': array([5.53093772, 1.95686838]), 'targetState': array([1.26554635, 0.12947939]), 'effectorPosition': array([1.08820212, 0.25042194])}
episode index:3400
target Thresh 1.9979952047338794
current state at start:  [-4.37349634  2.56309993]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.37349634,  2.56309993]), 'currentState': array([2.4063962 , 3.06309993]), 'targetState': array([ 0.34696465, -0.7901594 ]), 'effectorPosition': array([-0.05487728, -0.05609304])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9331767651755927
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-4.37349634,  2.56309993]), 'currentState': array([3.90495675, 2.25534406]), 'targetState': array([ 0.34696465, -0.7901594 ]), 'effectorPosition': array([ 0.26994488, -0.81393142])}
episode index:3401
target Thresh 1.9979992103174928
current state at start:  [0.1657976  2.73084851]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.1657976 , 2.73084851]), 'currentState': array([0.61906241, 3.23084851]), 'targetState': array([-0.95223728, -0.27921324]), 'effectorPosition': array([ 0.05496586, -0.07028567])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9331848249183393
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([0.1657976 , 2.73084851]), 'currentState': array([2.59209509, 1.92711369]), 'targetState': array([-0.95223728, -0.27921324]), 'effectorPosition': array([-1.04476794, -0.45913984])}
episode index:3402
target Thresh 1.9980032078979448
current state at start:  [-1.3895073  -2.32071103]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.3895073 , -2.32071103]), 'currentState': array([4.50071975, 4.4118328 ]), 'targetState': array([-1.10503175, -0.71459716]), 'effectorPosition': array([-1.08174812, -0.48756334])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9332044591161299
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.3895073 , -2.32071103]), 'currentState': array([4.50071975, 4.4118328 ]), 'targetState': array([-1.10503175, -0.71459716]), 'effectorPosition': array([-1.08174812, -0.48756334])}
episode index:3403
target Thresh 1.9980071974912257
current state at start:  [0.95142389 1.84991296]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.95142389, 1.84991296]), 'currentState': array([0.47745765, 2.34991296]), 'targetState': array([0.53573873, 0.48739692]), 'effectorPosition': array([-0.06287105,  0.76859934])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.933215356454815
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([0.95142389, 1.84991296]), 'currentState': array([5.99626268, 2.23707323]), 'targetState': array([0.53573873, 0.48739692]), 'effectorPosition': array([0.58879859, 0.64590195])}
episode index:3404
target Thresh 1.998011179113294
current state at start:  [-3.04443394  2.05940252]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.04443394,  2.05940252]), 'currentState': array([2.82869004, 2.51954296]), 'targetState': array([ 0.01883954, -0.04518055]), 'effectorPosition': array([-0.3575873 , -0.49674915])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9332320332957974
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.04443394,  2.05940252]), 'currentState': array([2.41865434, 2.94988974]), 'targetState': array([ 0.01883954, -0.04518055]), 'effectorPosition': array([-0.13979012, -0.13075289])}
episode index:3405
target Thresh 1.9980151527800762
current state at start:  [1.71739619 2.43255437]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.71739619, 2.43255437]), 'currentState': array([2.21739619, 2.05384725]), 'targetState': array([-1.16116189, -0.60820014]), 'effectorPosition': array([-1.02945173, -0.10612623])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9332487003441544
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.71739619, 2.43255437]), 'currentState': array([2.71739619, 1.80632979]), 'targetState': array([-1.16116189, -0.60820014]), 'effectorPosition': array([-1.09891554, -0.57066727])}
episode index:3406
target Thresh 1.9980191185074667
current state at start:  [-0.82493159  1.83187937]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.82493159,  1.83187937]), 'currentState': array([5.12202508, 2.09012949]), 'targetState': array([ 0.98542932, -0.18240254]), 'effectorPosition': array([ 0.99693549, -0.11626251])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9332682927420575
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.82493159,  1.83187937]), 'currentState': array([5.12202508, 2.09012949]), 'targetState': array([ 0.98542932, -0.18240254]), 'effectorPosition': array([ 0.99693549, -0.11626251])}
episode index:3407
target Thresh 1.9980230763113287
current state at start:  [-2.05684091  1.8267704 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.05684091,  1.8267704 ]), 'currentState': array([3.7940565 , 2.26120994]), 'targetState': array([ 0.1765517 , -0.87837886]), 'effectorPosition': array([ 0.17954844, -0.83309669])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9332878736420746
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.05684091,  1.8267704 ]), 'currentState': array([3.7940565 , 2.26120994]), 'targetState': array([ 0.1765517 , -0.87837886]), 'effectorPosition': array([ 0.17954844, -0.83309669])}
episode index:3408
target Thresh 1.998027026207493
current state at start:  [-2.19601923  2.09905163]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.19601923,  2.09905163]), 'currentState': array([3.65808628, 2.26896635]), 'targetState': array([-0.03335089, -0.87049793]), 'effectorPosition': array([ 0.06769609, -0.84248639])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9333074430543238
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.19601923,  2.09905163]), 'currentState': array([3.65808628, 2.26896635]), 'targetState': array([-0.03335089, -0.87049793]), 'effectorPosition': array([ 0.06769609, -0.84248639])}
episode index:3409
target Thresh 1.9980309682117599
current state at start:  [-1.51659766  2.18636456]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.51659766,  2.18636456]), 'currentState': array([5.26658765, 1.86138728]), 'targetState': array([ 1.2277889 , -0.30680618]), 'effectorPosition': array([ 1.1901507 , -0.10249096])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.933327000988912
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.51659766,  2.18636456]), 'currentState': array([5.26658765, 1.86138728]), 'targetState': array([ 1.2277889 , -0.30680618]), 'effectorPosition': array([ 1.1901507 , -0.10249096])}
episode index:3410
target Thresh 1.998034902339897
current state at start:  [1.02136631 2.81858336]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.02136631, 2.81858336]), 'currentState': array([0.57084725, 2.31858336]), 'targetState': array([0.65464787, 1.05698087]), 'effectorPosition': array([-0.12693179,  0.78984336])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9333436157643477
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.02136631, 2.81858336]), 'currentState': array([0.11120195, 1.81858336]), 'targetState': array([0.65464787, 1.05698087]), 'effectorPosition': array([0.64249558, 1.04722541])}
episode index:3411
target Thresh 1.9980388286076405
current state at start:  [-1.55262469  2.10379432]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.55262469,  2.10379432]), 'currentState': array([4.30054583, 2.56555511]), 'targetState': array([0.01008829, 0.06904924]), 'effectorPosition': array([ 0.43456222, -0.36592415])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.933360220800759
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.55262469,  2.10379432]), 'currentState': array([3.97132404, 3.06089033]), 'targetState': array([0.01008829, 0.06904924]), 'effectorPosition': array([ 0.0572764 , -0.05682205])}
episode index:3412
target Thresh 1.998042747030696
current state at start:  [ 4.20215075 -2.429861  ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.20215075, -2.429861  ]), 'currentState': array([4.68401226, 4.06778348]), 'targetState': array([-0.9639084 , -0.87577857]), 'effectorPosition': array([-0.81033918, -0.37627666])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9333768161067065
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 4.20215075, -2.429861  ]), 'currentState': array([4.75378215, 4.51372076]), 'targetState': array([-0.9639084 , -0.87577857]), 'effectorPosition': array([-0.9462764 , -0.84251595])}
episode index:3413
target Thresh 1.998046657624737
current state at start:  [-0.77442304  1.86302924]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.77442304,  1.86302924]), 'currentState': array([5.00876226, 1.66202657]), 'targetState': array([ 0.88116872, -0.61825769]), 'effectorPosition': array([ 1.21787105, -0.57843117])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9333934016907408
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.77442304,  1.86302924]), 'currentState': array([4.54940286, 2.08552177]), 'targetState': array([ 0.88116872, -0.61825769]), 'effectorPosition': array([ 0.77650941, -0.64221598])}
episode index:3414
target Thresh 1.9980505604054062
current state at start:  [ 2.78221698 -2.18166154]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.78221698, -2.18166154]), 'currentState': array([2.58163647, 3.60152376]), 'targetState': array([-0.01347716,  0.36819883]), 'effectorPosition': array([0.14772328, 0.43129071])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9334129058190891
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.78221698, -2.18166154]), 'currentState': array([2.58163647, 3.60152376]), 'targetState': array([-0.01347716,  0.36819883]), 'effectorPosition': array([0.14772328, 0.43129071])}
episode index:3415
target Thresh 1.998054455388314
current state at start:  [1.51369024 1.86480748]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.51369024, 1.86480748]), 'currentState': array([1.11912561, 2.0662906 ]), 'targetState': array([-0.93823653,  0.90286273]), 'effectorPosition': array([-0.56257059,  0.85590961])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9334294711276899
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.51369024, 1.86480748]), 'currentState': array([1.51956157, 1.81774485]), 'targetState': array([-0.93823653,  0.90286273]), 'effectorPosition': array([-0.92969677,  0.80422107])}
episode index:3416
target Thresh 1.998058342589041
current state at start:  [-2.670538    2.06961871]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.670538  ,  2.06961871]), 'currentState': array([4.04488475, 2.07309027]), 'targetState': array([ 0.12314147, -1.10611463]), 'effectorPosition': array([ 0.36735598, -0.94982882])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9334460267404707
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.670538  ,  2.06961871]), 'currentState': array([3.84891718, 1.86100606]), 'targetState': array([ 0.12314147, -1.10611463]), 'effectorPosition': array([ 0.08003306, -1.19217798])}
episode index:3417
target Thresh 1.9980622220231357
current state at start:  [0.37511378 2.69344118]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.37511378, 2.69344118]), 'currentState': array([0.85983809, 2.27084883]), 'targetState': array([-0.45004595,  0.77418781]), 'effectorPosition': array([-0.34738037,  0.76864243])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9334654983534783
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.37511378, 2.69344118]), 'currentState': array([0.85983809, 2.27084883]), 'targetState': array([-0.45004595,  0.77418781]), 'effectorPosition': array([-0.34738037,  0.76864243])}
episode index:3418
target Thresh 1.9980660937061159
current state at start:  [ 0.01830779 -2.56649451]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.01830779, -2.56649451]), 'currentState': array([5.86746215, 4.14064105]), 'targetState': array([ 0.6791036 , -0.69826341]), 'effectorPosition': array([ 0.08018879, -0.95465394])}
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.9334543467757962
{'reset': False, 'endBeforeDone': False, 'stepCount': 12, 'initial state': array([ 0.01830779, -2.56649451]), 'currentState': array([4.36746199, 2.27596991]), 'targetState': array([ 0.6791036 , -0.69826341]), 'effectorPosition': array([ 0.59768196, -0.58859513])}
episode index:3419
target Thresh 1.9980699576534682
current state at start:  [-0.30246593  2.45652194]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.30246593,  2.45652194]), 'currentState': array([5.61013173, 2.91173445]), 'targetState': array([ 0.03351881, -0.00534169]), 'effectorPosition': array([0.16259533, 0.16175703])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9334738045691366
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.30246593,  2.45652194]), 'currentState': array([5.61013173, 2.91173445]), 'targetState': array([ 0.03351881, -0.00534169]), 'effectorPosition': array([0.16259533, 0.16175703])}
episode index:3420
target Thresh 1.9980738138806486
current state at start:  [-1.24601823  2.25493581]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.24601823,  2.25493581]), 'currentState': array([4.67333502, 2.70833887]), 'targetState': array([0.00362301, 0.14099944]), 'effectorPosition': array([ 0.41589856, -0.10871672])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9334903278650825
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.24601823,  2.25493581]), 'currentState': array([4.52415048, 3.16709469]), 'targetState': array([0.00362301, 0.14099944]), 'effectorPosition': array([-0.02510968,  0.00445223])}
episode index:3421
target Thresh 1.998077662403082
current state at start:  [ 1.57143459 -1.76461246]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.57143459, -1.76461246]), 'currentState': array([1.20161334, 4.02236534]), 'targetState': array([ 0.09541376, -0.18336665]), 'effectorPosition': array([0.85041762, 0.06065513])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9335039484589267
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 1.57143459, -1.76461246]), 'currentState': array([1.61596405, 3.06737934]), 'targetState': array([ 0.09541376, -0.18336665]), 'effectorPosition': array([-0.07419388, -0.00059809])}
episode index:3422
target Thresh 1.9980815032361625
current state at start:  [0.0919627  2.57990452]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.0919627 , 2.57990452]), 'currentState': array([0.04152924, 3.07990452]), 'targetState': array([-0.48402041, -0.35525358]), 'effectorPosition': array([-0.00065903,  0.06167483])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.9335035281841526
{'reset': False, 'endBeforeDone': False, 'stepCount': 8, 'initial state': array([0.0919627 , 2.57990452]), 'currentState': array([4.7445404 , 3.82263632]), 'targetState': array([-0.48402041, -0.35525358]), 'effectorPosition': array([-0.62210759, -0.24320784])}
episode index:3423
target Thresh 1.9980853363952535
current state at start:  [ 0.81866572 -2.34436517]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.81866572, -2.34436517]), 'currentState': array([1.10771153, 3.93907642]), 'targetState': array([ 0.46835581, -0.4873461 ]), 'effectorPosition': array([ 0.77491162, -0.04992899])}
done in step count: 120
reward sum = 0.2993803913123313
running average episode reward sum: 0.9333183286698793
{'reset': False, 'endBeforeDone': False, 'stepCount': 121, 'initial state': array([ 0.81866572, -2.34436517]), 'currentState': array([0.69107862, 3.9002124 ]), 'targetState': array([ 0.46835581, -0.4873461 ]), 'effectorPosition': array([ 0.64975679, -0.3553079 ])}
episode index:3424
target Thresh 1.9980891618956873
current state at start:  [ 3.80197109 -2.30557974]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.80197109, -2.30557974]), 'currentState': array([3.30197109, 3.54947149]), 'targetState': array([-0.12360954,  0.91158689]), 'effectorPosition': array([-0.14432679,  0.37847223])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9333348780629683
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.80197109, -2.30557974]), 'currentState': array([2.80197109, 3.99678283]), 'targetState': array([-0.12360954,  0.91158689]), 'effectorPosition': array([-0.07286828,  0.82615992])}
episode index:3425
target Thresh 1.9980929797527662
current state at start:  [-0.7540324   2.02760286]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.7540324 ,  2.02760286]), 'currentState': array([6.00520251, 1.70435203]), 'targetState': array([0.90562087, 0.82828433]), 'effectorPosition': array([1.10553647, 0.71517208])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9333543366508075
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.7540324 ,  2.02760286]), 'currentState': array([6.00520251, 1.70435203]), 'targetState': array([0.90562087, 0.82828433]), 'effectorPosition': array([1.10553647, 0.71517208])}
episode index:3426
target Thresh 1.9980967899817617
current state at start:  [-1.41601959  1.96719744]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.41601959,  1.96719744]), 'currentState': array([4.53623662, 2.4383363 ]), 'targetState': array([ 0.68797971, -0.08396542]), 'effectorPosition': array([ 0.59511922, -0.34691849])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9333708658785136
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.41601959,  1.96719744]), 'currentState': array([4.92322114, 2.68131896]), 'targetState': array([ 0.68797971, -0.08396542]), 'effectorPosition': array([ 0.45613652, -0.00880667])}
episode index:3427
target Thresh 1.9981005925979145
current state at start:  [ 3.37461153 -1.70709641]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.37461153, -1.70709641]), 'currentState': array([3.80956788, 4.10385704]), 'targetState': array([-0.62891988,  0.2088844 ]), 'effectorPosition': array([-0.84448569,  0.37883612])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9333873854625631
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.37461153, -1.70709641]), 'currentState': array([4.16310123, 3.75790613]), 'targetState': array([-0.62891988,  0.2088844 ]), 'effectorPosition': array([-0.58905544,  0.14485802])}
episode index:3428
target Thresh 1.998104387616435
current state at start:  [-0.11190257  2.11340492]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.11190257,  2.11340492]), 'currentState': array([5.74574348, 2.60109218]), 'targetState': array([0.24405384, 0.06449752]), 'effectorPosition': array([0.38587895, 0.36904594])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9334038954113928
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.11190257,  2.11340492]), 'currentState': array([5.40313491, 2.88674381]), 'targetState': array([0.24405384, 0.06449752]), 'effectorPosition': array([0.21488853, 0.13572065])}
episode index:3429
target Thresh 1.9981081750525036
current state at start:  [-1.59032182  1.85100642]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.59032182,  1.85100642]), 'currentState': array([4.24021541, 2.3082684 ]), 'targetState': array([ 0.6274039 , -0.72756144]), 'effectorPosition': array([ 0.51019118, -0.62838447])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9334233111853253
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.59032182,  1.85100642]), 'currentState': array([4.24021541, 2.3082684 ]), 'targetState': array([ 0.6274039 , -0.72756144]), 'effectorPosition': array([ 0.51019118, -0.62838447])}
episode index:3430
target Thresh 1.99811195492127
current state at start:  [ 2.06336971 -2.72182996]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.06336971, -2.72182996]), 'currentState': array([2.01543817, 3.09116435]), 'targetState': array([-0.01081985,  0.24302901]), 'effectorPosition': array([-0.04605241, -0.02053414])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9334340589815406
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 2.06336971, -2.72182996]), 'currentState': array([0.89013064, 2.98053133]), 'targetState': array([-0.01081985,  0.24302901]), 'effectorPosition': array([-0.11648422,  0.11097814])}
episode index:3431
target Thresh 1.9981157272378534
current state at start:  [ 3.49900909 -2.8059436 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.49900909, -2.8059436 ]), 'currentState': array([3.85080298, 2.97724171]), 'targetState': array([-0.1651325 , -0.14370333]), 'effectorPosition': array([ 0.09632381, -0.13293687])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9334505408990867
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.49900909, -2.8059436 ]), 'currentState': array([3.5647923 , 3.01604294]), 'targetState': array([-0.1651325 , -0.14370333]), 'effectorPosition': array([ 0.04424876, -0.11740564])}
episode index:3432
target Thresh 1.9981194920173433
current state at start:  [-0.28835068 -2.17541924]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.28835068, -2.17541924]), 'currentState': array([5.90179398, 3.60776607]), 'targetState': array([ 0.14954913, -0.49793909]), 'effectorPosition': array([-0.06826049, -0.45689274])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9334699261187491
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.28835068, -2.17541924]), 'currentState': array([5.90179398, 3.60776607]), 'targetState': array([ 0.14954913, -0.49793909]), 'effectorPosition': array([-0.06826049, -0.45689274])}
episode index:3433
target Thresh 1.9981232492747987
current state at start:  [ 4.28578296 -2.33436857]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.28578296, -2.33436857]), 'currentState': array([4.47472771, 3.44881673]), 'targetState': array([0.15309924, 0.14777804]), 'effectorPosition': array([-0.304937  ,  0.02569024])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9334863879923312
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 4.28578296, -2.33436857]), 'currentState': array([4.77540072, 2.94881673]), 'targetState': array([0.15309924, 0.14777804]), 'effectorPosition': array([ 0.19237036, -0.00642298])}
episode index:3434
target Thresh 1.9981269990252488
current state at start:  [-2.03908624  1.9944638 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.03908624,  1.9944638 ]), 'currentState': array([4.55965196, 2.29718399]), 'targetState': array([ 0.77923235, -0.62151849]), 'effectorPosition': array([ 0.68778151, -0.44565644])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9335057514892767
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.03908624,  1.9944638 ]), 'currentState': array([4.55965196, 2.29718399]), 'targetState': array([ 0.77923235, -0.62151849]), 'effectorPosition': array([ 0.68778151, -0.44565644])}
episode index:3435
target Thresh 1.9981307412836924
current state at start:  [ 1.08108591 -2.29361406]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.08108591, -2.29361406]), 'currentState': array([0.95494234, 3.48957124]), 'targetState': array([-0.08374787, -0.05339021]), 'effectorPosition': array([ 0.31297262, -0.14805498])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9335221933543845
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.08108591, -2.29361406]), 'currentState': array([1.39606934, 3.0501728 ]), 'targetState': array([-0.08374787, -0.05339021]), 'effectorPosition': array([-0.08917661,  0.01998254])}
episode index:3436
target Thresh 1.9981344760650988
current state at start:  [-0.19909013  2.66022773]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.19909013,  2.66022773]), 'currentState': array([0.30090987, 2.4105805 ]), 'targetState': array([-0.45199252,  1.15605204]), 'effectorPosition': array([0.0461441 , 0.71335308])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9335386256519247
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.19909013,  2.66022773]), 'currentState': array([0.7922376 , 1.99214124]), 'targetState': array([-0.45199252,  1.15605204]), 'effectorPosition': array([-0.23462062,  1.06159171])}
episode index:3437
target Thresh 1.9981382033844068
current state at start:  [ 3.25006305 -2.72000068]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.25006305, -2.72000068]), 'currentState': array([2.7838447 , 4.06165651]), 'targetState': array([-0.00972133,  0.74243855]), 'effectorPosition': array([-0.09066512,  0.88331259])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9335579570580759
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.25006305, -2.72000068]), 'currentState': array([2.7838447 , 4.06165651]), 'targetState': array([-0.00972133,  0.74243855]), 'effectorPosition': array([-0.09066512,  0.88331259])}
episode index:3438
target Thresh 1.9981419232565258
current state at start:  [-3.25630218  1.80847991]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.25630218,  1.80847991]), 'currentState': array([2.52688313, 2.20872063]), 'targetState': array([ 0.12081446, -0.40834764]), 'effectorPosition': array([-0.79372831, -0.4230093 ])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9335658192427057
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([-3.25630218,  1.80847991]), 'currentState': array([3.5452604 , 2.62126234]), 'targetState': array([ 0.12081446, -0.40834764]), 'effectorPosition': array([ 0.07357612, -0.50919205])}
episode index:3439
target Thresh 1.9981456356963354
current state at start:  [ 1.60902404 -2.02558933]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.60902404, -2.02558933]), 'currentState': array([1.20363068, 3.84631084]), 'targetState': array([ 0.10233109, -0.38109491]), 'effectorPosition': array([ 0.69015018, -0.01021949])}
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.9335495271507744
{'reset': False, 'endBeforeDone': False, 'stepCount': 14, 'initial state': array([ 1.60902404, -2.02558933]), 'currentState': array([3.58513856, 2.81779639]), 'targetState': array([ 0.10233109, -0.38109491]), 'effectorPosition': array([ 0.08960294, -0.3096813 ])}
episode index:3440
target Thresh 1.9981493407186854
current state at start:  [0.0284243  2.40221701]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.0284243 , 2.40221701]), 'currentState': array([6.12591834, 2.90221701]), 'targetState': array([-0.28340585, -0.06207584]), 'effectorPosition': array([0.06529579, 0.2297043 ])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.933560207032451
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([0.0284243 , 2.40221701]), 'currentState': array([5.32871879, 3.42707599]), 'targetState': array([-0.28340585, -0.06207584]), 'effectorPosition': array([-0.20640853, -0.19581682])}
episode index:3441
target Thresh 1.9981530383383959
current state at start:  [-2.22479734  2.25670061]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.22479734,  2.25670061]), 'currentState': array([3.62641726, 2.62737886]), 'targetState': array([-0.20862139, -0.6323665 ]), 'effectorPosition': array([ 0.11481146, -0.49543814])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9335766044156489
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.22479734,  2.25670061]), 'currentState': array([3.28672687, 2.25500611]), 'targetState': array([-0.20862139, -0.6323665 ]), 'effectorPosition': array([-0.25199801, -0.81998493])}
episode index:3442
target Thresh 1.998156728570257
current state at start:  [-1.03332284 -2.78770096]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.03332284, -2.78770096]), 'currentState': array([4.82745969, 3.85581833]), 'targetState': array([-0.54878423, -0.24898745]), 'effectorPosition': array([-0.6226394 , -0.31799186])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9335958967175905
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.03332284, -2.78770096]), 'currentState': array([4.82745969, 3.85581833]), 'targetState': array([-0.54878423, -0.24898745]), 'effectorPosition': array([-0.6226394 , -0.31799186])}
episode index:3443
target Thresh 1.9981604114290303
current state at start:  [-0.91454813 -2.84255904]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.91454813, -2.84255904]), 'currentState': array([4.97005606, 3.703389  ]), 'targetState': array([ 0.02052158, -0.32071558]), 'effectorPosition': array([-0.47595432, -0.28437367])}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.9335900666800659
{'reset': False, 'endBeforeDone': False, 'stepCount': 10, 'initial state': array([-0.91454813, -2.84255904]), 'currentState': array([3.93800373, 3.00558095]), 'targetState': array([ 0.02052158, -0.32071558]), 'effectorPosition': array([ 0.09047055, -0.10141874])}
episode index:3444
target Thresh 1.9981640869294466
current state at start:  [-0.05465886 -1.76813245]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.05465886, -1.76813245]), 'currentState': array([0.3902191 , 4.01505286]), 'targetState': array([ 0.05254043, -0.02508809]), 'effectorPosition': array([ 0.62251392, -0.57281804])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9336035673863998
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-0.05465886, -1.76813245]), 'currentState': array([1.26915142, 3.14220128]), 'targetState': array([ 0.05254043, -0.02508809]), 'effectorPosition': array([ 0.0005812 , -0.00018064])}
episode index:3445
target Thresh 1.9981677550862083
current state at start:  [ 2.27828111 -2.84951678]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.27828111, -2.84951678]), 'currentState': array([1.78183557, 3.90305296]), 'targetState': array([0.79456535, 0.28323103]), 'effectorPosition': array([0.61681993, 0.41457783])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9336228350685281
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.27828111, -2.84951678]), 'currentState': array([1.78183557, 3.90305296]), 'targetState': array([0.79456535, 0.28323103]), 'effectorPosition': array([0.61681993, 0.41457783])}
episode index:3446
target Thresh 1.9981714159139878
current state at start:  [ 3.1948448  -2.05011552]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.1948448 , -2.05011552]), 'currentState': array([3.45984946, 3.76653839]), 'targetState': array([-0.14284726, -0.01391955]), 'effectorPosition': array([-0.36258356,  0.49653139])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9336391904978669
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.1948448 , -2.05011552]), 'currentState': array([3.89263858, 3.29601974]), 'targetState': array([-0.14284726, -0.01391955]), 'effectorPosition': array([-0.113662  ,  0.10431356])}
episode index:3447
target Thresh 1.9981750694274285
current state at start:  [ 3.31923647 -1.8184578 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.31923647, -1.8184578 ]), 'currentState': array([3.67059146, 4.00058232]), 'targetState': array([ 0.06282203, -0.00117395]), 'effectorPosition': array([-0.68152142,  0.47866788])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9336526652105996
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 3.31923647, -1.8184578 ]), 'currentState': array([4.58669896, 3.11510255]), 'targetState': array([ 0.06282203, -0.00117395]), 'effectorPosition': array([ 0.02623408, -0.00366847])}
episode index:3448
target Thresh 1.9981787156411446
current state at start:  [-3.39222406  2.42834116]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.39222406,  2.42834116]), 'currentState': array([2.40223469, 2.82822437]), 'targetState': array([-0.79343291,  0.32913881]), 'effectorPosition': array([-0.24369693, -0.19496285])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9336604771400833
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([-3.39222406,  2.42834116]), 'currentState': array([1.57190479, 2.09213451]), 'targetState': array([-0.79343291,  0.32913881]), 'effectorPosition': array([-0.86770936,  0.50099748])}
episode index:3449
target Thresh 1.9981823545697206
current state at start:  [-2.05844351  2.4525716 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.05844351,  2.4525716 ]), 'currentState': array([4.66211084, 2.61982769]), 'targetState': array([ 0.84280635, -0.05114109]), 'effectorPosition': array([ 0.49109406, -0.15793963])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9336768074365643
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.05844351,  2.4525716 ]), 'currentState': array([5.12956221, 2.2580522 ]), 'targetState': array([ 0.84280635, -0.05114109]), 'effectorPosition': array([ 0.85482217, -0.0210303 ])}
episode index:3450
target Thresh 1.9981859862277127
current state at start:  [ 4.02484314 -2.31544212]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.02484314, -2.31544212]), 'currentState': array([4.44995315, 3.56080094]), 'targetState': array([ 0.03708735, -0.31637178]), 'effectorPosition': array([-0.41556481,  0.02197544])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9336846078429867
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([ 4.02484314, -2.31544212]), 'currentState': array([4.11398577, 2.98992649]), 'targetState': array([ 0.03708735, -0.31637178]), 'effectorPosition': array([ 0.11836565, -0.0945946 ])}
episode index:3451
target Thresh 1.9981896106296473
current state at start:  [-2.15547498  2.10601561]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.15547498,  2.10601561]), 'currentState': array([3.80404474, 2.60601561]), 'targetState': array([ 0.16421744, -0.01066965]), 'effectorPosition': array([ 0.20347571, -0.48851721])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9337009216877598
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.15547498,  2.10601561]), 'currentState': array([3.96373178, 3.09261878]), 'targetState': array([ 0.16421744, -0.01066965]), 'effectorPosition': array([ 0.035048 , -0.0341994])}
episode index:3452
target Thresh 1.9981932277900218
current state at start:  [1.76433121 1.92746086]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.76433121, 1.92746086]), 'currentState': array([1.32047617, 1.82623389]), 'targetState': array([-0.40354197,  1.27970887]), 'effectorPosition': array([-0.75227275,  0.96371579])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.9337031745773379
{'reset': False, 'endBeforeDone': False, 'stepCount': 7, 'initial state': array([1.76433121, 1.92746086]), 'currentState': array([0.84232309, 1.97851961]), 'targetState': array([-0.40354197,  1.27970887]), 'effectorPosition': array([-0.28326808,  1.06147004])}
episode index:3453
target Thresh 1.9981968377233053
current state at start:  [-1.4714721   1.57230836]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.4714721 ,  1.57230836]), 'currentState': array([5.3117132 , 2.07230836]), 'targetState': array([ 1.15731638, -0.31768965]), 'effectorPosition': array([1.01693529, 0.06586937])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9337194736003321
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.4714721 ,  1.57230836]), 'currentState': array([5.17128858, 1.89262863]), 'targetState': array([ 1.15731638, -0.31768965]), 'effectorPosition': array([ 1.15336043, -0.19274092])}
episode index:3454
target Thresh 1.998200440443937
current state at start:  [ 3.00812179 -2.77205654]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.00812179, -2.77205654]), 'currentState': array([3.19372409, 3.10420878]), 'targetState': array([-0.02566042, -0.13047001]), 'effectorPosition': array([ 0.00124979, -0.0373608 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9337386575442973
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.00812179, -2.77205654]), 'currentState': array([3.19372409, 3.10420878]), 'targetState': array([-0.02566042, -0.13047001]), 'effectorPosition': array([ 0.00124979, -0.0373608 ])}
episode index:3455
target Thresh 1.9982040359663282
current state at start:  [ 1.16987279 -2.64500185]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.16987279, -2.64500185]), 'currentState': array([1.61050188, 3.55978748]), 'targetState': array([ 0.41623861, -0.00408215]), 'effectorPosition': array([0.40237064, 0.10222919])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9337578303864431
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.16987279, -2.64500185]), 'currentState': array([1.61050188, 3.55978748]), 'targetState': array([ 0.41623861, -0.00408215]), 'effectorPosition': array([0.40237064, 0.10222919])}
episode index:3456
target Thresh 1.998207624304861
current state at start:  [-0.49316973  2.39788421]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.49316973,  2.39788421]), 'currentState': array([0.00683027, 2.48860971]), 'targetState': array([0.04203128, 1.0109508 ]), 'effectorPosition': array([0.20157042, 0.60894936])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9337740994548878
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.49316973,  2.39788421]), 'currentState': array([0.50683027, 2.00266809]), 'targetState': array([0.04203128, 1.0109508 ]), 'effectorPosition': array([0.06749561, 1.07624414])}
episode index:3457
target Thresh 1.9982112054738885
current state at start:  [-0.58863861  2.74825249]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.58863861,  2.74825249]), 'currentState': array([5.26729303, 3.07953118]), 'targetState': array([ 0.34686807, -0.4326539 ]), 'effectorPosition': array([0.05372967, 0.03104051])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9337846618899789
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-0.58863861,  2.74825249]), 'currentState': array([4.27818319, 2.59359425]), 'targetState': array([ 0.34686807, -0.4326539 ]), 'effectorPosition': array([ 0.41103311, -0.35201383])}
episode index:3458
target Thresh 1.9982147794877354
current state at start:  [-2.72072029  3.04371616]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.72072029,  3.04371616]), 'currentState': array([4.0374289 , 2.98039442]), 'targetState': array([ 0.25144623, -0.00378286]), 'effectorPosition': array([ 0.1172073 , -0.11041332])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9338038048035696
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.72072029,  3.04371616]), 'currentState': array([4.0374289 , 2.98039442]), 'targetState': array([ 0.25144623, -0.00378286]), 'effectorPosition': array([ 0.1172073 , -0.11041332])}
episode index:3459
target Thresh 1.9982183463606982
current state at start:  [-1.77609538  1.84732573]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.77609538,  1.84732573]), 'currentState': array([4.08895052, 2.34732573]), 'targetState': array([ 0.35960029, -0.38883448]), 'effectorPosition': array([ 0.40447424, -0.65938214])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9338200464784817
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.77609538,  1.84732573]), 'currentState': array([4.18315723, 2.81513186]), 'targetState': array([ 0.35960029, -0.38883448]), 'effectorPosition': array([ 0.25015486, -0.20749941])}
episode index:3460
target Thresh 1.9982219061070439
current state at start:  [ 4.09939198 -2.109742  ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.09939198, -2.109742  ]), 'currentState': array([4.37173777, 3.67344331]), 'targetState': array([-0.08014994, -0.03127521]), 'effectorPosition': array([-0.52413757,  0.03923971])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9338362787678551
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 4.09939198, -2.109742  ]), 'currentState': array([4.73393746, 3.22244932]), 'targetState': array([-0.08014994, -0.03127521]), 'effectorPosition': array([-0.08067944, -0.00500667])}
episode index:3461
target Thresh 1.9982254587410115
current state at start:  [-1.45732662  2.12764101]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.45732662,  2.12764101]), 'currentState': array([4.82861436, 2.62764101]), 'targetState': array([0.22442032, 0.44176882]), 'effectorPosition': array([ 0.50328698, -0.07130939])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9338496420611054
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.45732662,  2.12764101]), 'currentState': array([5.68288747, 2.62737246]), 'targetState': array([0.22442032, 0.44176882]), 'effectorPosition': array([0.38455721, 0.33281027])}
episode index:3462
target Thresh 1.9982290042768118
current state at start:  [1.31948997 1.63436038]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.31948997, 1.63436038]), 'currentState': array([1.09805714, 2.06854931]), 'targetState': array([-0.76299813,  0.85667925]), 'effectorPosition': array([-0.54436041,  0.86531322])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.933868744099205
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.31948997, 1.63436038]), 'currentState': array([1.09805714, 2.06854931]), 'targetState': array([-0.76299813,  0.85667925]), 'effectorPosition': array([-0.54436041,  0.86531322])}
episode index:3463
target Thresh 1.998232542728627
current state at start:  [-1.16544325 -2.4508208 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.16544325, -2.4508208 ]), 'currentState': array([5.10275996, 4.3323645 ]), 'targetState': array([ 0.29387546, -1.32297463]), 'effectorPosition': array([-0.61941496, -0.93511428])}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.9338628689558401
{'reset': False, 'endBeforeDone': False, 'stepCount': 10, 'initial state': array([-1.16544325, -2.4508208 ]), 'currentState': array([3.9887493 , 1.69626409]), 'targetState': array([ 0.29387546, -1.32297463]), 'effectorPosition': array([ 0.16424982, -1.31253356])}
episode index:3464
target Thresh 1.9982360741106107
current state at start:  [-2.65879684  1.88371925]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.65879684,  1.88371925]), 'currentState': array([3.12837647, 2.38371925]), 'targetState': array([-0.20763705, -0.3053027 ]), 'effectorPosition': array([-0.28276093, -0.68370125])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9338790701480606
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.65879684,  1.88371925]), 'currentState': array([2.68407102, 2.8497449 ]), 'targetState': array([-0.20763705, -0.3053027 ]), 'effectorPosition': array([-0.16503144, -0.23945121])}
episode index:3465
target Thresh 1.9982395984368884
current state at start:  [-0.30820208 -1.66565827]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.30820208, -1.66565827]), 'currentState': array([5.87311742, 4.35513654]), 'targetState': array([ 0.85031907, -1.09849725]), 'effectorPosition': array([ 0.22288478, -1.11844509])}
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.9338679504666153
{'reset': False, 'endBeforeDone': False, 'stepCount': 12, 'initial state': array([-0.30820208, -1.66565827]), 'currentState': array([4.50542887, 1.61507917]), 'targetState': array([ 0.85031907, -1.09849725]), 'effectorPosition': array([ 0.78131138, -1.14062079])}
episode index:3466
target Thresh 1.9982431157215574
current state at start:  [-1.95970734  1.81415313]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.95970734,  1.81415313]), 'currentState': array([4.76370056, 1.86700288]), 'targetState': array([ 1.01970682, -0.88651756]), 'effectorPosition': array([ 0.99150991, -0.65811849])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9338870251852578
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.95970734,  1.81415313]), 'currentState': array([4.76370056, 1.86700288]), 'targetState': array([ 1.01970682, -0.88651756]), 'effectorPosition': array([ 0.99150991, -0.65811849])}
episode index:3467
target Thresh 1.998246625978687
current state at start:  [ 3.70066417 -1.74792918]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.70066417, -1.74792918]), 'currentState': array([3.2037448 , 4.71680496]), 'targetState': array([-1.15734934,  0.65725963]), 'effectorPosition': array([-1.06458816,  0.93567302])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.933903205397142
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.70066417, -1.74792918]), 'currentState': array([3.49764037, 4.43150021]), 'targetState': array([-1.15734934,  0.65725963]), 'effectorPosition': array([-1.01237001,  0.64860433])}
episode index:3468
target Thresh 1.9982501292223183
current state at start:  [-3.52347564  2.13195364]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.52347564,  2.13195364]), 'currentState': array([3.16409434, 1.873951  ]), 'targetState': array([-1.07800228, -0.80524822]), 'effectorPosition': array([-0.67981613, -0.96994073])}
done in step count: 27
reward sum = 0.7623427143471035
running average episode reward sum: 0.9338537500811864
{'reset': False, 'endBeforeDone': False, 'stepCount': 28, 'initial state': array([-3.52347564,  2.13195364]), 'currentState': array([2.74391586, 1.87339074]), 'targetState': array([-1.07800228, -0.80524822]), 'effectorPosition': array([-1.01690238, -0.6082056 ])}
episode index:3469
target Thresh 1.9982536254664642
current state at start:  [-2.0630518   2.11679395]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.0630518 ,  2.11679395]), 'currentState': array([4.40376725, 2.29021548]), 'targetState': array([ 0.56516184, -0.74696073]), 'effectorPosition': array([ 0.6130569 , -0.55341258])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9338728124010478
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.0630518 ,  2.11679395]), 'currentState': array([4.40376725, 2.29021548]), 'targetState': array([ 0.56516184, -0.74696073]), 'effectorPosition': array([ 0.6130569 , -0.55341258])}
episode index:3470
target Thresh 1.9982571147251096
current state at start:  [ 2.36286806 -2.25146784]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.36286806, -2.25146784]), 'currentState': array([2.79198404, 3.7792608 ]), 'targetState': array([0.04652375, 0.7952146 ]), 'effectorPosition': array([0.0192901 , 0.62662238])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9338918637371465
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.36286806, -2.25146784]), 'currentState': array([2.79198404, 3.7792608 ]), 'targetState': array([0.04652375, 0.7952146 ]), 'effectorPosition': array([0.0192901 , 0.62662238])}
episode index:3471
target Thresh 1.9982605970122114
current state at start:  [-0.46611252 -2.59400045]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.46611252, -2.59400045]), 'currentState': array([5.68638199, 3.1903991 ]), 'targetState': array([0.19252501, 0.13770152]), 'effectorPosition': array([-0.02643344, -0.04102279])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9339080239146416
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.46611252, -2.59400045]), 'currentState': array([5.5973426 , 2.69688343]), 'targetState': array([0.19252501, 0.13770152]), 'effectorPosition': array([0.34772505, 0.27132214])}
episode index:3472
target Thresh 1.9982640723416991
current state at start:  [-2.02998908 -1.81122673]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.02998908, -1.81122673]), 'currentState': array([3.82226526, 4.33804103]), 'targetState': array([-1.1586881 ,  0.25287481]), 'effectorPosition': array([-1.07870604,  0.32413245])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9339270541409834
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.02998908, -1.81122673]), 'currentState': array([3.82226526, 4.33804103]), 'targetState': array([-1.1586881 ,  0.25287481]), 'effectorPosition': array([-1.07870604,  0.32413245])}
episode index:3473
target Thresh 1.9982675407274737
current state at start:  [-0.93222725 -2.60664317]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.93222725, -2.60664317]), 'currentState': array([4.99825582, 3.57286979]), 'targetState': array([ 0.63022969, -0.43165331]), 'effectorPosition': array([-0.37524559, -0.20573169])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9339375239008738
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-0.93222725, -2.60664317]), 'currentState': array([4.77350247, 2.22108001]), 'targetState': array([ 0.63022969, -0.43165331]), 'effectorPosition': array([ 0.81852587, -0.34524045])}
episode index:3474
target Thresh 1.9982710021834091
current state at start:  [-0.90483398 -1.68625163]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.90483398, -1.68625163]), 'currentState': array([4.91144505, 4.58803358]), 'targetState': array([-1.1345487 , -0.68578384]), 'effectorPosition': array([-0.79946707, -1.05488489])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9339479876350031
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-0.90483398, -1.68625163]), 'currentState': array([4.46893009, 4.86771244]), 'targetState': array([-1.1345487 , -0.68578384]), 'effectorPosition': array([-1.23717953, -0.88248861])}
episode index:3475
target Thresh 1.9982744567233508
current state at start:  [ 0.47980645 -1.91730357]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.47980645, -1.91730357]), 'currentState': array([0.27245604, 4.57487894]), 'targetState': array([ 1.09871352, -0.76948233]), 'effectorPosition': array([ 1.09764969, -0.72181091])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9339669899400562
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.47980645, -1.91730357]), 'currentState': array([0.27245604, 4.57487894]), 'targetState': array([ 1.09871352, -0.76948233]), 'effectorPosition': array([ 1.09764969, -0.72181091])}
episode index:3476
target Thresh 1.9982779043611172
current state at start:  [ 2.56374464 -2.5610088 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.56374464, -2.5610088 ]), 'currentState': array([2.49948056, 3.22217651]), 'targetState': array([-0.04817032, -0.00600567]), 'effectorPosition': array([0.04560971, 0.06640783])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9339859813148219
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.56374464, -2.5610088 ]), 'currentState': array([2.49948056, 3.22217651]), 'targetState': array([-0.04817032, -0.00600567]), 'effectorPosition': array([0.04560971, 0.06640783])}
episode index:3477
target Thresh 1.9982813451104986
current state at start:  [0.52057386 1.83648658]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.52057386, 1.83648658]), 'currentState': array([0.47102631, 1.61755939]), 'targetState': array([0.26265047, 1.26370675]), 'effectorPosition': array([0.39614251, 1.32271655])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9340049617687279
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.52057386, 1.83648658]), 'currentState': array([0.47102631, 1.61755939]), 'targetState': array([0.26265047, 1.26370675]), 'effectorPosition': array([0.39614251, 1.32271655])}
episode index:3478
target Thresh 1.9982847789852582
current state at start:  [ 0.02393242 -2.58507157]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.02393242, -2.58507157]), 'currentState': array([0.26902333, 3.19811374]), 'targetState': array([-0.16599922, -0.24265269]), 'effectorPosition': array([ 0.0165542 , -0.05403463])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.9340044042482158
{'reset': False, 'endBeforeDone': False, 'stepCount': 8, 'initial state': array([ 0.02393242, -2.58507157]), 'currentState': array([2.34521945, 2.78155735]), 'targetState': array([-0.16599922, -0.24265269]), 'effectorPosition': array([-0.29667419, -0.20053841])}
episode index:3479
target Thresh 1.9982882059991314
current state at start:  [ 1.77589227 -2.2760235 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.77589227, -2.2760235 ]), 'currentState': array([1.3858145 , 3.52285571]), 'targetState': array([ 0.39834248, -0.32557157]), 'effectorPosition': array([0.37895199, 0.00214099])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9340148337297537
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 1.77589227, -2.2760235 ]), 'currentState': array([1.10648875, 3.60119539]), 'targetState': array([ 0.39834248, -0.32557157]), 'effectorPosition': array([ 0.44309897, -0.10585708])}
episode index:3480
target Thresh 1.9982916261658263
current state at start:  [-2.03844041  2.75416286]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.03844041,  2.75416286]), 'currentState': array([3.77182829, 3.25416286]), 'targetState': array([-0.45111814,  0.04595163]), 'effectorPosition': array([-0.07131496,  0.08702214])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9340224698045224
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([-2.03844041,  2.75416286]), 'currentState': array([1.88522208, 2.65686159]), 'targetState': array([-0.45111814,  0.04595163]), 'effectorPosition': array([-0.47875368, -0.03455893])}
episode index:3481
target Thresh 1.9982950394990238
current state at start:  [-1.11935678  1.74018289]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.11935678,  1.74018289]), 'currentState': array([5.59007726, 2.24018289]), 'targetState': array([0.93877105, 0.53352586]), 'effectorPosition': array([0.79298316, 0.36078748])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9340414179751702
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.11935678,  1.74018289]), 'currentState': array([5.59007726, 2.24018289]), 'targetState': array([0.93877105, 0.53352586]), 'effectorPosition': array([0.79298316, 0.36078748])}
episode index:3482
target Thresh 1.998298446012377
current state at start:  [ 1.29911294 -1.97913395]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.29911294, -1.97913395]), 'currentState': array([1.70866948, 4.74941664]), 'targetState': array([0.60409689, 0.88635196]), 'effectorPosition': array([0.84730704, 1.164521  ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9340574841773018
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.29911294, -1.97913395]), 'currentState': array([2.07042017, 4.31116496]), 'targetState': array([0.60409689, 0.88635196]), 'effectorPosition': array([0.51606725, 0.97600395])}
episode index:3483
target Thresh 1.9983018457195119
current state at start:  [ 4.09492721 -2.93249868]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.09492721, -2.93249868]), 'currentState': array([3.6552472 , 3.68459644]), 'targetState': array([0.14112013, 1.05483695]), 'effectorPosition': array([-0.37917015,  0.3793535 ])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9340651014350007
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([ 4.09492721, -2.93249868]), 'currentState': array([2.56532408, 4.24365193]), 'targetState': array([0.14112013, 1.05483695]), 'effectorPosition': array([0.02642562, 1.04679599])}
episode index:3484
target Thresh 1.9983052386340272
current state at start:  [-2.36383055  2.47459609]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.36383055,  2.47459609]), 'currentState': array([3.41935475, 2.97459609]), 'targetState': array([-0.42551683, -0.22825167]), 'effectorPosition': array([ 0.03220028, -0.16366503])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.934078310875048
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-2.36383055,  2.47459609]), 'currentState': array([2.49149855, 2.64715033]), 'targetState': array([-0.42551683, -0.22825167]), 'effectorPosition': array([-0.38255857, -0.30525721])}
episode index:3485
target Thresh 1.998308624769495
current state at start:  [ 1.4203002  -1.57269415]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.4203002 , -1.57269415]), 'currentState': array([1.79636438, 4.94635564]), 'targetState': array([1.02897309, 0.96754551]), 'effectorPosition': array([0.6725989 , 1.41819835])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9340943526676828
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.4203002 , -1.57269415]), 'currentState': array([1.39258463, 5.0702606 ]), 'targetState': array([1.02897309, 0.96754551]), 'effectorPosition': array([1.16117439, 1.16285727])}
episode index:3486
target Thresh 1.9983120041394595
current state at start:  [0.37337345 2.98535286]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.37337345, 2.98535286]), 'currentState': array([6.17853767, 2.48535286]), 'targetState': array([0.55178852, 0.976472  ]), 'effectorPosition': array([0.27030508, 0.58510768])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9341047354171329
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([0.37337345, 2.98535286]), 'currentState': array([0.24074426, 1.84631355]), 'targetState': array([0.55178852, 0.976472  ]), 'effectorPosition': array([0.47752847, 1.10809619])}
episode index:3487
target Thresh 1.9983153767574384
current state at start:  [-0.6654258  -1.79843916]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.6654258 , -1.79843916]), 'currentState': array([5.32639173, 4.04277127]), 'targetState': array([-0.04695423, -0.72081487]), 'effectorPosition': array([-0.42231018, -0.76176212])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9338369301604192
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([-0.6654258 , -1.79843916]), 'currentState': array([4.48947741, 4.21613502]), 'targetState': array([-0.04695423, -0.72081487]), 'effectorPosition': array([-0.97342579, -0.31650084])}
episode index:3488
target Thresh 1.9983187426369222
current state at start:  [-3.57293229  2.61482365]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.57293229,  2.61482365]), 'currentState': array([2.25637318, 2.87827854]), 'targetState': array([-0.21146714, -0.04769612]), 'effectorPosition': array([-0.22329415, -0.13810999])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9338558934937066
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.57293229,  2.61482365]), 'currentState': array([2.25637318, 2.87827854]), 'targetState': array([-0.21146714, -0.04769612]), 'effectorPosition': array([-0.22329415, -0.13810999])}
episode index:3489
target Thresh 1.9983221017913742
current state at start:  [-3.75692011  1.75787629]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.75692011,  1.75787629]), 'currentState': array([3.02626519, 1.75814005]), 'targetState': array([-1.19777559, -0.71897975]), 'effectorPosition': array([-0.92140313, -0.88233597])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.933866335644568
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-3.75692011,  1.75787629]), 'currentState': array([2.64880587, 1.73309712]), 'targetState': array([-1.19777559, -0.71897975]), 'effectorPosition': array([-1.20552066, -0.47280183])}
episode index:3490
target Thresh 1.998325454234231
current state at start:  [-1.4256366 -2.4545101]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.4256366, -2.4545101]), 'currentState': array([4.48244148, 3.59839418]), 'targetState': array([-0.74253956,  0.38757552]), 'effectorPosition': array([-0.45283968,  0.00070042])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9338824151817652
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.4256366, -2.4545101]), 'currentState': array([4.12779584, 3.95206117]), 'targetState': array([-0.74253956,  0.38757552]), 'effectorPosition': array([-0.77581972,  0.14066175])}
episode index:3491
target Thresh 1.9983287999789028
current state at start:  [-2.16647034 -1.71896246]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.16647034, -1.71896246]), 'currentState': array([3.63505644, 4.15064872]), 'targetState': array([-0.56044635,  0.55775088]), 'effectorPosition': array([-0.81247399,  0.52399079])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9338984855096053
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.16647034, -1.71896246]), 'currentState': array([3.22772036, 3.91327938]), 'targetState': array([-0.56044635,  0.55775088]), 'effectorPosition': array([-0.34220107,  0.67039354])}
episode index:3492
target Thresh 1.998332139038772
current state at start:  [ 1.77908833 -2.50326072]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.77908833, -2.50326072]), 'currentState': array([1.57162186, 3.32425209]), 'targetState': array([-0.17068082,  0.17620302]), 'effectorPosition': array([0.18163161, 0.01678585])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9339145466359982
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.77908833, -2.50326072]), 'currentState': array([1.78737462, 2.91745763]), 'targetState': array([-0.17068082,  0.17620302]), 'effectorPosition': array([-0.22244578, -0.02333299])}
episode index:3493
target Thresh 1.9983354714271953
current state at start:  [-1.98380694 -2.11853578]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.98380694, -2.11853578]), 'currentState': array([4.71975521, 4.50282819]), 'targetState': array([-0.65505357, -0.71362621]), 'effectorPosition': array([-0.97226206, -0.7991532 ])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9336472556953468
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([-1.98380694, -2.11853578]), 'currentState': array([4.34263106, 4.73566231]), 'targetState': array([-0.65505357, -0.71362621]), 'effectorPosition': array([-1.30196205, -0.59282144])}
episode index:3494
target Thresh 1.998338797157502
current state at start:  [ 1.72409755 -2.62453799]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.72409755, -2.62453799]), 'currentState': array([1.5843799 , 4.11797141]), 'targetState': array([0.61934217, 0.74405416]), 'effectorPosition': array([0.82242215, 0.45118639])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9336633795134597
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.72409755, -2.62453799]), 'currentState': array([1.93547912, 4.36552859]), 'targetState': array([0.61934217, 0.74405416]), 'effectorPosition': array([0.64318821, 0.9520584 ])}
episode index:3495
target Thresh 1.998342116242995
current state at start:  [ 4.38465922 -2.55043202]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.38465922, -2.55043202]), 'currentState': array([4.04113467, 3.82455278]), 'targetState': array([-0.68024166,  0.37975292]), 'effectorPosition': array([-0.63367421,  0.21688935])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9336823545193197
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.38465922, -2.55043202]), 'currentState': array([4.04113467, 3.82455278]), 'targetState': array([-0.68024166,  0.37975292]), 'effectorPosition': array([-0.63367421,  0.21688935])}
episode index:3496
target Thresh 1.998345428696951
current state at start:  [2.22901366 1.64571185]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.22901366, 1.64571185]), 'currentState': array([1.72901366, 2.08098669]), 'targetState': array([-0.35722648,  0.28337972]), 'effectorPosition': array([-0.94236753,  0.36777261])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9336984590790796
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([2.22901366, 1.64571185]), 'currentState': array([1.22901366, 2.4966094 ]), 'targetState': array([-0.35722648,  0.28337972]), 'effectorPosition': array([-0.49907993,  0.39076791])}
episode index:3497
target Thresh 1.9983487345326194
current state at start:  [-0.98100373  2.49372575]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.98100373,  2.49372575]), 'currentState': array([4.80218157, 2.93695647]), 'targetState': array([-0.20603392,  0.11307415]), 'effectorPosition': array([ 0.20426329, -0.00255863])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9337145544309723
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.98100373,  2.49372575]), 'currentState': array([4.52189452, 3.31551555]), 'targetState': array([-0.20603392,  0.11307415]), 'effectorPosition': array([-0.17277363,  0.01795196])}
episode index:3498
target Thresh 1.998352033763224
current state at start:  [-3.99332943  2.32788643]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.99332943,  2.32788643]), 'currentState': array([2.77050052, 1.9590005 ]), 'targetState': array([-1.08209504, -0.39134676]), 'effectorPosition': array([-0.91482066, -0.63722015])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9337306405828925
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.99332943,  2.32788643]), 'currentState': array([2.2908643 , 2.01996207]), 'targetState': array([-1.08209504, -0.39134676]), 'effectorPosition': array([-1.0502929 , -0.16869045])}
episode index:3499
target Thresh 1.9983553264019611
current state at start:  [-3.58888017  2.0366844 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.58888017,  2.0366844 ]), 'currentState': array([2.20787071, 2.5366844 ]), 'targetState': array([0.03923978, 0.28340459]), 'effectorPosition': array([-0.56268568, -0.19564323])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9337410886855831
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-3.58888017,  2.0366844 ]), 'currentState': array([0.89425831, 2.99432583]), 'targetState': array([0.03923978, 0.28340459]), 'effectorPosition': array([-0.10763896,  0.10031054])}
episode index:3500
target Thresh 1.9983586124620019
current state at start:  [1.89711236 2.18362434]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.89711236, 2.18362434]), 'currentState': array([2.39077612, 2.64318679]), 'targetState': array([-0.17366248, -0.77767059]), 'effectorPosition': array([-0.41507184, -0.26650315])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9337543303054959
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([1.89711236, 2.18362434]), 'currentState': array([3.33152147, 2.07414423]), 'targetState': array([-0.17366248, -0.77767059]), 'effectorPosition': array([-0.34295675, -0.95794512])}
episode index:3501
target Thresh 1.9983618919564903
current state at start:  [ 3.14470231 -1.92719039]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.14470231, -1.92719039]), 'currentState': array([2.70453867, 4.31643502]), 'targetState': array([-0.47327042,  0.88982856]), 'effectorPosition': array([-0.16604454,  1.09592526])}
done in step count: 159
reward sum = 0.2023000271287771
running average episode reward sum: 0.9335454627146401
{'reset': False, 'endBeforeDone': False, 'stepCount': 160, 'initial state': array([ 3.14470231, -1.92719039]), 'currentState': array([2.93714272, 4.08413383]), 'targetState': array([-0.47327042,  0.88982856]), 'effectorPosition': array([-0.23941855,  0.87590571])}
episode index:3502
target Thresh 1.998365164898544
current state at start:  [ 3.26651067 -2.1325538 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.26651067, -2.1325538 ]), 'currentState': array([3.7579135 , 3.65063151]), 'targetState': array([-0.39566289, -0.18823848]), 'effectorPosition': array([-0.38515872,  0.32438578])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.9335504426139224
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([ 3.26651067, -2.1325538 ]), 'currentState': array([2.7356121 , 2.78500998]), 'targetState': array([-0.39566289, -0.18823848]), 'effectorPosition': array([-0.19564783, -0.2958573 ])}
episode index:3503
target Thresh 1.9983684313012555
current state at start:  [-2.88204437  2.92505566]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.88204437,  2.92505566]), 'currentState': array([3.90114094, 2.44813031]), 'targetState': array([ 0.16228053, -1.00530832]), 'effectorPosition': array([ 0.27266999, -0.6225561 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9335665526474229
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.88204437,  2.92505566]), 'currentState': array([3.98034141, 1.96865997]), 'targetState': array([ 0.16228053, -1.00530832]), 'effectorPosition': array([ 0.27628426, -1.07180573])}
episode index:3504
target Thresh 1.99837169117769
current state at start:  [ 0.13316163 -2.01210452]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.13316163, -2.01210452]), 'currentState': array([0.63316163, 3.78378492]), 'targetState': array([0.13556176, 0.07165264]), 'effectorPosition': array([ 0.51499768, -0.36497692])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9335826534883223
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.13316163, -2.01210452]), 'currentState': array([1.13316163, 3.339995  ]), 'targetState': array([0.13556176, 0.07165264]), 'effectorPosition': array([ 0.18684135, -0.06576355])}
episode index:3505
target Thresh 1.998374944540887
current state at start:  [-1.92459952  1.6790067 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.92459952,  1.6790067 ]), 'currentState': array([3.88891776, 2.1790067 ]), 'targetState': array([-0.09119713, -0.31188704]), 'effectorPosition': array([ 0.24341115, -0.8932814 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9335987451444864
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.92459952,  1.6790067 ]), 'currentState': array([3.4316218, 2.6790067]), 'targetState': array([-0.09119713, -0.31188704]), 'effectorPosition': array([ 0.02691344, -0.4576819 ])}
episode index:3506
target Thresh 1.9983781914038599
current state at start:  [-1.34063824 -1.74753253]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.34063824, -1.74753253]), 'currentState': array([4.56445734, 5.03565278]), 'targetState': array([-0.17492793, -1.11224035]), 'effectorPosition': array([-1.13206133, -1.16351327])}
done in step count: 128
reward sum = 0.2762516676992083
running average episode reward sum: 0.933411306570935
{'reset': False, 'endBeforeDone': False, 'stepCount': 129, 'initial state': array([-1.34063824, -1.74753253]), 'currentState': array([3.45877977, 2.07464547]), 'targetState': array([-0.17492793, -1.11224035]), 'effectorPosition': array([-0.21826411, -0.99335842])}
episode index:3507
target Thresh 1.9983814317795965
current state at start:  [-1.29773511  2.084855  ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.29773511,  2.084855  ]), 'currentState': array([5.07053159, 2.37222097]), 'targetState': array([ 0.95403162, -0.05830638]), 'effectorPosition': array([ 0.75027154, -0.01991931])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.933430288524592
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.29773511,  2.084855  ]), 'currentState': array([5.07053159, 2.37222097]), 'targetState': array([ 0.95403162, -0.05830638]), 'effectorPosition': array([ 0.75027154, -0.01991931])}
episode index:3508
target Thresh 1.9983846656810578
current state at start:  [-0.35184677 -2.67732319]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.35184677, -2.67732319]), 'currentState': array([5.89231574, 3.10586211]), 'targetState': array([-0.05208082,  0.33590015]), 'effectorPosition': array([0.0142003 , 0.03278547])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9334435885278624
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-0.35184677, -2.67732319]), 'currentState': array([5.76638603, 2.94322246]), 'targetState': array([-0.05208082,  0.33590015]), 'effectorPosition': array([0.11442298, 0.16164542])}
episode index:3509
target Thresh 1.9983878931211798
current state at start:  [0.12439132 2.94892791]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.12439132, 2.94892791]), 'currentState': array([0.345568  , 3.39599404]), 'targetState': array([-0.82213959, -0.28592383]), 'effectorPosition': array([ 0.11553031, -0.22588605])}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.9334379115076218
{'reset': False, 'endBeforeDone': False, 'stepCount': 10, 'initial state': array([0.12439132, 2.94892791]), 'currentState': array([2.48304482, 2.07324858]), 'targetState': array([-0.82213959, -0.28592383]), 'effectorPosition': array([-0.94634419, -0.3758728 ])}
episode index:3510
target Thresh 1.998391114112872
current state at start:  [ 2.63182439 -2.43734992]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.63182439, -2.43734992]), 'currentState': array([2.25402131, 3.34583539]), 'targetState': array([-0.5867661 ,  0.44474837]), 'effectorPosition': array([0.144178  , 0.14416306])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9334512017635297
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 2.63182439, -2.43734992]), 'currentState': array([1.48653995, 2.40417996]), 'targetState': array([-0.5867661 ,  0.44474837]), 'effectorPosition': array([-0.64812677,  0.31545261])}
episode index:3511
target Thresh 1.9983943286690187
current state at start:  [ 3.86208402 -2.57909852]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.86208402, -2.57909852]), 'currentState': array([4.25187974, 3.25677491]), 'targetState': array([0.37825522, 0.31496937]), 'effectorPosition': array([-0.10589998,  0.04513851])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9334644844509546
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 3.86208402, -2.57909852]), 'currentState': array([5.17109533, 2.70828301]), 'targetState': array([0.37825522, 0.31496937]), 'effectorPosition': array([0.41739458, 0.10305146])}
episode index:3512
target Thresh 1.9983975368024778
current state at start:  [-0.81394344 -1.93022919]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.81394344, -1.93022919]), 'currentState': array([5.04214795, 4.13334559]), 'targetState': array([-0.98579406, -0.75505509]), 'effectorPosition': array([-0.64527422, -0.69940985])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9334805776805445
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.81394344, -1.93022919]), 'currentState': array([4.60731096, 4.63334559]), 'targetState': array([-0.98579406, -0.75505509]), 'effectorPosition': array([-1.08798224, -0.81140152])}
episode index:3513
target Thresh 1.9984007385260818
current state at start:  [-0.06844347 -2.2259936 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.06844347, -2.2259936 ]), 'currentState': array([0.07296676, 3.64851202]), 'targetState': array([ 0.88425141, -0.4106417 ]), 'effectorPosition': array([ 0.16081406, -0.47502665])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.9334828541665207
{'reset': False, 'endBeforeDone': False, 'stepCount': 7, 'initial state': array([-0.06844347, -2.2259936 ]), 'currentState': array([4.78127469, 2.08017958]), 'targetState': array([ 0.88425141, -0.4106417 ]), 'effectorPosition': array([ 0.90624129, -0.45105315])}
episode index:3514
target Thresh 1.998403933852638
current state at start:  [-3.45124732  2.56772564]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.45124732,  2.56772564]), 'currentState': array([3.33193799, 2.15239499]), 'targetState': array([-0.10128009, -1.26890402]), 'effectorPosition': array([-0.28440942, -0.90575403])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9334989330131304
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.45124732,  2.56772564]), 'currentState': array([3.83193799, 1.72986941]), 'targetState': array([-0.10128009, -1.26890402]), 'effectorPosition': array([-0.02012971, -1.29722345])}
episode index:3515
target Thresh 1.9984071227949276
current state at start:  [-1.2208517   2.31634399]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.2208517 ,  2.31634399]), 'currentState': array([5.56233361, 2.11213386]), 'targetState': array([0.97473637, 0.77976928]), 'effectorPosition': array([0.92979543, 0.32390581])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9335150027136385
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.2208517 ,  2.31634399]), 'currentState': array([6.06233361, 1.80727154]), 'targetState': array([0.97473637, 0.77976928]), 'effectorPosition': array([0.96008836, 0.78081724])}
episode index:3516
target Thresh 1.998410305365706
current state at start:  [-1.5666811  -2.04908918]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.5666811 , -2.04908918]), 'currentState': array([4.78787498, 4.73409613]), 'targetState': array([-0.66153717, -0.9434735 ]), 'effectorPosition': array([-0.91986614, -1.09419248])}
done in step count: 20
reward sum = 0.8179069375972308
running average episode reward sum: 0.9334821314980809
{'reset': False, 'endBeforeDone': False, 'stepCount': 21, 'initial state': array([-1.5666811 , -2.04908918]), 'currentState': array([3.20786669, 1.88104911]), 'targetState': array([-0.66153717, -0.9434735 ]), 'effectorPosition': array([-0.63011186, -0.99617284])}
episode index:3517
target Thresh 1.998413481577704
current state at start:  [ 0.12982083 -1.72645895]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.12982083, -1.72645895]), 'currentState': array([0.61077399, 4.09228903]), 'targetState': array([0.43569669, 0.00833328]), 'effectorPosition': array([ 0.80987855, -0.42645483])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9334981968387579
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.12982083, -1.72645895]), 'currentState': array([1.08159486, 3.7570396 ]), 'targetState': array([0.43569669, 0.00833328]), 'effectorPosition': array([ 0.59583157, -0.10933323])}
episode index:3518
target Thresh 1.998416651443626
current state at start:  [-0.64470952 -1.97065056]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.64470952, -1.97065056]), 'currentState': array([5.57288119, 3.93881926]), 'targetState': array([ 0.77368615, -0.4423091 ]), 'effectorPosition': array([-0.23806101, -0.73887745])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.9335004650833052
{'reset': False, 'endBeforeDone': False, 'stepCount': 7, 'initial state': array([-0.64470952, -1.97065056]), 'currentState': array([4.55042788, 2.05697534]), 'targetState': array([ 0.77368615, -0.4423091 ]), 'effectorPosition': array([ 0.78664621, -0.66834541])}
episode index:3519
target Thresh 1.9984198149761516
current state at start:  [-3.72569971  2.79990947]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.72569971,  2.79990947]), 'currentState': array([2.0574856 , 2.34412575]), 'targetState': array([-0.87737955,  0.12865385]), 'effectorPosition': array([-0.77350126, -0.06820992])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9335193569966338
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.72569971,  2.79990947]), 'currentState': array([2.0574856 , 2.34412575]), 'targetState': array([-0.87737955,  0.12865385]), 'effectorPosition': array([-0.77350126, -0.06820992])}
episode index:3520
target Thresh 1.9984229721879352
current state at start:  [-1.5046966   2.34191327]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.5046966 ,  2.34191327]), 'currentState': array([5.04381249, 2.03154905]), 'targetState': array([ 1.0738468 , -0.33585936]), 'effectorPosition': array([ 1.02768715, -0.23369678])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9335382381789693
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.5046966 ,  2.34191327]), 'currentState': array([5.04381249, 2.03154905]), 'targetState': array([ 1.0738468 , -0.33585936]), 'effectorPosition': array([ 1.02768715, -0.23369678])}
episode index:3521
target Thresh 1.9984261230916054
current state at start:  [-1.03011217  2.449712  ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.03011217,  2.449712  ]), 'currentState': array([4.75307313, 2.949712  ]), 'targetState': array([-0.1632711 , -0.04941577]), 'effectorPosition': array([ 0.19129402, -0.01058095])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9335542693435976
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.03011217,  2.449712  ]), 'currentState': array([4.3871725 , 3.18824771]), 'targetState': array([-0.1632711 , -0.04941577]), 'effectorPosition': array([-0.04454112,  0.01387042])}
episode index:3522
target Thresh 1.9984292676997657
current state at start:  [-2.08211973 -1.60416434]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.08211973, -1.60416434]), 'currentState': array([3.70106558, 4.46325265]), 'targetState': array([-1.15162329,  0.46589773]), 'effectorPosition': array([-1.15291414,  0.42149127])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9335731298972895
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.08211973, -1.60416434]), 'currentState': array([3.70106558, 4.46325265]), 'targetState': array([-1.15162329,  0.46589773]), 'effectorPosition': array([-1.15291414,  0.42149127])}
episode index:3523
target Thresh 1.998432406024995
current state at start:  [ 1.50640982 -2.34425751]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.50640982, -2.34425751]), 'currentState': array([1.31477139, 4.43892779]), 'targetState': array([1.04969825, 0.37885626]), 'effectorPosition': array([1.11630381, 0.46231435])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9335919797469213
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.50640982, -2.34425751]), 'currentState': array([1.31477139, 4.43892779]), 'targetState': array([1.04969825, 0.37885626]), 'effectorPosition': array([1.11630381, 0.46231435])}
episode index:3524
target Thresh 1.998435538079846
current state at start:  [ 3.15776984 -2.5322991 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.15776984, -2.5322991 ]), 'currentState': array([3.15657786, 3.29392892]), 'targetState': array([0.77039429, 0.47521102]), 'effectorPosition': array([-0.01385333,  0.15155719])}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9335889025028592
{'reset': False, 'endBeforeDone': False, 'stepCount': 9, 'initial state': array([ 3.15776984, -2.5322991 ]), 'currentState': array([5.59606632, 2.27948203]), 'targetState': array([0.77039429, 0.47521102]), 'effectorPosition': array([0.75151164, 0.36545488])}
episode index:3525
target Thresh 1.9984386638768474
current state at start:  [-0.86346128  2.77768838]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.86346128,  2.77768838]), 'currentState': array([4.93716238, 3.27768838]), 'targetState': array([-0.43609752, -0.37008595]), 'effectorPosition': array([-0.13020205, -0.03925434])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9336020933983491
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-0.86346128,  2.77768838]), 'currentState': array([4.93295718, 3.6783305 ]), 'targetState': array([-0.43609752, -0.37008595]), 'effectorPosition': array([-0.46818218, -0.249084  ])}
episode index:3526
target Thresh 1.9984417834285022
current state at start:  [ 4.12897223 -2.20462801]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.12897223, -2.20462801]), 'currentState': array([4.4366684 , 3.65466421]), 'targetState': array([-0.07770856, -0.01871382]), 'effectorPosition': array([-0.50736906,  0.00973497])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9336180837319474
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 4.12897223, -2.20462801]), 'currentState': array([4.73447967, 3.24447964]), 'targetState': array([-0.07770856, -0.01871382]), 'effectorPosition': array([-0.10256369, -0.00755556])}
episode index:3527
target Thresh 1.9984448967472885
current state at start:  [-2.86445772  1.83772524]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.86445772,  1.83772524]), 'currentState': array([2.91872759, 1.95312619]), 'targetState': array([-1.30155673, -0.50264685]), 'effectorPosition': array([-0.81647839, -0.76628767])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.933620312208611
{'reset': False, 'endBeforeDone': False, 'stepCount': 7, 'initial state': array([-2.86445772,  1.83772524]), 'currentState': array([2.82586236, 1.6399195 ]), 'targetState': array([-1.30155673, -0.50264685]), 'effectorPosition': array([-1.194685 , -0.6592355])}
episode index:3528
target Thresh 1.99844800384566
current state at start:  [-1.96439912  2.02318801]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.96439912,  2.02318801]), 'currentState': array([4.5649586 , 2.51255338]), 'targetState': array([ 0.72309694, -0.44299747]), 'effectorPosition': array([ 0.55386839, -0.27575989])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9336391219812921
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.96439912,  2.02318801]), 'currentState': array([4.5649586 , 2.51255338]), 'targetState': array([ 0.72309694, -0.44299747]), 'effectorPosition': array([ 0.55386839, -0.27575989])}
episode index:3529
target Thresh 1.9984511047360447
current state at start:  [ 3.80583913 -2.17604888]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.80583913, -2.17604888]), 'currentState': array([3.3474618 , 4.44628381]), 'targetState': array([-0.99396543,  0.71433962]), 'effectorPosition': array([-0.91868408,  0.79376833])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9336579210968781
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.80583913, -2.17604888]), 'currentState': array([3.3474618 , 4.44628381]), 'targetState': array([-0.99396543,  0.71433962]), 'effectorPosition': array([-0.91868408,  0.79376833])}
episode index:3530
target Thresh 1.9984541994308462
current state at start:  [ 3.58339171 -2.39085325]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.58339171, -2.39085325]), 'currentState': array([4.08339171, 3.45513133]), 'targetState': array([8.29225274e-05, 1.52106727e-04]), 'effectorPosition': array([-0.27808176,  0.14203634])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9336738775055167
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.58339171, -2.39085325]), 'currentState': array([4.54780496, 3.00094531]), 'targetState': array([8.29225274e-05, 1.52106727e-04]), 'effectorPosition': array([ 0.13667187, -0.03270915])}
episode index:3531
target Thresh 1.9984572879424434
current state at start:  [-3.29763165  2.33831874]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.29763165,  2.33831874]), 'currentState': array([3.48555365, 2.10704041]), 'targetState': array([-0.10223792, -0.76756281]), 'effectorPosition': array([-0.1705568 , -0.97421178])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9336926561358945
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.29763165,  2.33831874]), 'currentState': array([3.48555365, 2.10704041]), 'targetState': array([-0.10223792, -0.76756281]), 'effectorPosition': array([-0.1705568 , -0.97421178])}
episode index:3532
target Thresh 1.9984603702831902
current state at start:  [-3.04404694  2.6918135 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.04404694,  2.6918135 ]), 'currentState': array([3.08295745, 2.55637035]), 'targetState': array([-0.17558011, -0.36003865]), 'effectorPosition': array([-0.19849534, -0.54168347])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9337114241358561
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.04404694,  2.6918135 ]), 'currentState': array([3.08295745, 2.55637035]), 'targetState': array([-0.17558011, -0.36003865]), 'effectorPosition': array([-0.19849534, -0.54168347])}
episode index:3533
target Thresh 1.9984634464654163
current state at start:  [ 1.74311673 -2.59780346]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.74311673, -2.59780346]), 'currentState': array([1.52797282, 3.21421137]), 'targetState': array([ 0.27488964, -0.60108544]), 'effectorPosition': array([ 0.07260122, -0.00047294])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.9337163133904582
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([ 1.74311673, -2.59780346]), 'currentState': array([3.90992657, 2.55398678]), 'targetState': array([ 0.27488964, -0.60108544]), 'effectorPosition': array([ 0.2646436 , -0.51519237])}
episode index:3534
target Thresh 1.9984665165014261
current state at start:  [-0.90044091  2.39400174]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.90044091,  2.39400174]), 'currentState': array([5.8455181 , 1.95893624]), 'targetState': array([0.76949972, 1.16311731]), 'effectorPosition': array([0.95524988, 0.57494607])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9337322352254255
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.90044091,  2.39400174]), 'currentState': array([0.0033338 , 1.69123968]), 'targetState': array([0.76949972, 1.16311731]), 'effectorPosition': array([0.87653312, 0.99568317])}
episode index:3535
target Thresh 1.9984695804035
current state at start:  [1.81475264 1.86094927]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.81475264, 1.86094927]), 'currentState': array([1.31475264, 2.29459309]), 'targetState': array([-0.25634194,  0.85910032]), 'effectorPosition': array([-0.63932843,  0.51651765])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9337453482810745
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([1.81475264, 1.86094927]), 'currentState': array([0.54980478, 2.2171449 ]), 'targetState': array([-0.25634194,  0.85910032]), 'effectorPosition': array([-0.07801178,  0.88846108])}
episode index:3536
target Thresh 1.9984726381838933
current state at start:  [ 0.03772334 -1.89949447]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.03772334, -1.89949447]), 'currentState': array([0.53772334, 3.92904022]), 'targetState': array([-0.00042039,  0.00705756]), 'effectorPosition': array([ 0.61571395, -0.45780349])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9337584539219338
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 0.03772334, -1.89949447]), 'currentState': array([1.53772334, 3.07926011]), 'targetState': array([-0.00042039,  0.00705756]), 'effectorPosition': array([-0.0621939,  0.0040008])}
episode index:3537
target Thresh 1.9984756898548373
current state at start:  [ 0.7989672 -2.7458709]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.7989672, -2.7458709]), 'currentState': array([0.4309939, 4.0373144]), 'targetState': array([ 1.20585214, -0.32978716]), 'effectorPosition': array([ 0.66688662, -0.55258589])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9337743503453588
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.7989672, -2.7458709]), 'currentState': array([0.73561294, 4.21566744]), 'targetState': array([ 1.20585214, -0.32978716]), 'effectorPosition': array([ 0.97804524, -0.30055916])}
episode index:3538
target Thresh 1.9984787354285387
current state at start:  [0.48907817 2.60909538]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.48907817, 2.60909538]), 'currentState': array([0.22502435, 3.10909538]), 'targetState': array([ 0.18355231, -0.31097135]), 'effectorPosition': array([-0.00673517,  0.03179021])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.933790237785216
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.48907817, 2.60909538]), 'currentState': array([6.09232698, 3.55108871]), 'targetState': array([ 0.18355231, -0.31097135]), 'effectorPosition': array([ 0.00564794, -0.40660169])}
episode index:3539
target Thresh 1.99848177491718
current state at start:  [-0.10139408 -1.72387334]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.10139408, -1.72387334]), 'currentState': array([0.37634758, 4.06941173]), 'targetState': array([ 0.18969228, -0.13689709]), 'effectorPosition': array([ 0.66653149, -0.59713827])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9338061162491184
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.10139408, -1.72387334]), 'currentState': array([0.87634758, 3.61339683]), 'targetState': array([ 0.18969228, -0.13689709]), 'effectorPosition': array([ 0.41915226, -0.20691032])}
episode index:3540
target Thresh 1.9984848083329185
current state at start:  [-3.31830621  1.87665705]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.31830621,  1.87665705]), 'currentState': array([3.4648791 , 1.87708017]), 'targetState': array([ 0.02654326, -1.25022991]), 'effectorPosition': array([-0.359399  , -1.12596506])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9338219857446707
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.31830621,  1.87665705]), 'currentState': array([3.9648791 , 1.83017818]), 'targetState': array([ 0.02654326, -1.25022991]), 'effectorPosition': array([ 0.20339765, -1.20235733])}
episode index:3541
target Thresh 1.9984878356878888
current state at start:  [ 0.55503537 -1.7355907 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.55503537, -1.7355907 ]), 'currentState': array([0.40296379, 4.04759461]), 'targetState': array([ 0.29693305, -0.30627771]), 'effectorPosition': array([ 0.66105362, -0.57377129])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9338378462794689
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.55503537, -1.7355907 ]), 'currentState': array([0.84607143, 3.57109249]), 'targetState': array([ 0.29693305, -0.30627771]), 'effectorPosition': array([ 0.37197432, -0.20805486])}
episode index:3542
target Thresh 1.9984908569941995
current state at start:  [ 0.34881932 -1.71821572]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.34881932, -1.71821572]), 'currentState': array([6.14344255, 4.43061798]), 'targetState': array([ 0.57569917, -1.21773551]), 'effectorPosition': array([ 0.58110967, -1.05175903])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9338565203279364
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.34881932, -1.71821572]), 'currentState': array([6.14344255, 4.43061798]), 'targetState': array([ 0.57569917, -1.21773551]), 'effectorPosition': array([ 0.58110967, -1.05175903])}
episode index:3543
target Thresh 1.9984938722639363
current state at start:  [1.7480551  2.75291117]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.7480551 , 2.75291117]), 'currentState': array([2.2480551 , 2.64731048]), 'targetState': array([-0.36257262, -0.80016046]), 'effectorPosition': array([-0.44470187, -0.20401298])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9338695687138484
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([1.7480551 , 2.75291117]), 'currentState': array([3.2480551 , 2.18416341]), 'targetState': array([-0.36257262, -0.80016046]), 'effectorPosition': array([-0.33508172, -0.85817957])}
episode index:3544
target Thresh 1.9984968815091602
current state at start:  [ 3.1740831  -1.62331433]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.1740831 , -1.62331433]), 'currentState': array([2.94040012, 4.54355289]), 'targetState': array([-0.7468007 ,  0.85448362]), 'effectorPosition': array([-0.61818685,  1.13215494])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9338826097381887
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 3.1740831 , -1.62331433]), 'currentState': array([3.08788054, 4.47521393]), 'targetState': array([-0.7468007 ,  0.85448362]), 'effectorPosition': array([-0.71175563,  1.0116761 ])}
episode index:3545
target Thresh 1.998499884741908
current state at start:  [-1.5783564   1.65311673]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.5783564 ,  1.65311673]), 'currentState': array([4.25468116, 2.15311673]), 'targetState': array([ 0.15239283, -0.80485851]), 'effectorPosition': array([ 0.55035287, -0.77277742])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9338984352853578
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.5783564 ,  1.65311673]), 'currentState': array([3.84212127, 2.34911328]), 'targetState': array([ 0.15239283, -0.80485851]), 'effectorPosition': array([ 0.23127397, -0.73644315])}
episode index:3546
target Thresh 1.9985028819741928
current state at start:  [-1.49004669 -2.76941154]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.49004669, -2.76941154]), 'currentState': array([4.8287204 , 3.07873801]), 'targetState': array([ 0.60276996, -0.23625054]), 'effectorPosition': array([0.06261792, 0.00532933])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.933911460818122
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.49004669, -2.76941154]), 'currentState': array([4.697161  , 2.29996422]), 'targetState': array([ 0.60276996, -0.23625054]), 'effectorPosition': array([ 0.74056044, -0.34506747])}
episode index:3547
target Thresh 1.9985058732180034
current state at start:  [ 2.17184166 -2.17515169]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.17184166, -2.17515169]), 'currentState': array([2.51315854, 3.64677068]), 'targetState': array([-0.31501902,  0.76925058]), 'effectorPosition': array([0.18346453, 0.46493452])}
done in step count: 23
reward sum = 0.7936142836436554
running average episode reward sum: 0.9338719182089974
{'reset': False, 'endBeforeDone': False, 'stepCount': 24, 'initial state': array([ 2.17184166, -2.17515169]), 'currentState': array([2.79163435, 4.08779573]), 'targetState': array([-0.31501902,  0.76925058]), 'effectorPosition': array([-0.11193686,  0.90439781])}
episode index:3548
target Thresh 1.998508858485305
current state at start:  [ 2.88593148 -2.73984582]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.88593148, -2.73984582]), 'currentState': array([3.3578624 , 3.04333949]), 'targetState': array([ 0.71583528, -0.29724606]), 'effectorPosition': array([ 0.01633941, -0.09684495])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9338794482433144
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([ 2.88593148, -2.73984582]), 'currentState': array([4.90556293, 2.16323015]), 'targetState': array([ 0.71583528, -0.29724606]), 'effectorPosition': array([ 0.89893332, -0.27414489])}
episode index:3549
target Thresh 1.9985118377880386
current state at start:  [-2.17203172 -1.72841097]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.17203172, -1.72841097]), 'currentState': array([4.53385673, 4.513502  ]), 'targetState': array([-0.5860905 , -0.75230746]), 'effectorPosition': array([-1.10720415, -0.61558284])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9336163836100064
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([-2.17203172, -1.72841097]), 'currentState': array([4.25789183, 4.80883835]), 'targetState': array([-0.5860905 , -0.75230746]), 'effectorPosition': array([-1.37559333, -0.5480354 ])}
episode index:3550
target Thresh 1.9985148111381215
current state at start:  [ 1.28710974 -2.03676293]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.28710974, -2.03676293]), 'currentState': array([1.00397331, 3.74642237]), 'targetState': array([ 0.5940141 , -0.15966188]), 'effectorPosition': array([ 0.57495218, -0.15566671])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9336350779542446
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.28710974, -2.03676293]), 'currentState': array([1.00397331, 3.74642237]), 'targetState': array([ 0.5940141 , -0.15966188]), 'effectorPosition': array([ 0.57495218, -0.15566671])}
episode index:3551
target Thresh 1.9985177785474466
current state at start:  [-1.16073607 -2.51692945]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.16073607, -2.51692945]), 'currentState': array([4.6724143 , 3.79015166]), 'targetState': array([-1.07552877,  0.58264851]), 'effectorPosition': array([-0.61167057, -0.17874292])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9336481592949107
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.16073607, -2.51692945]), 'currentState': array([3.69694918, 4.41249362]), 'targetState': array([-1.07552877,  0.58264851]), 'effectorPosition': array([-1.10240415,  0.44030059])}
episode index:3552
target Thresh 1.9985207400278842
current state at start:  [-4.02997957  1.99552517]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.02997957,  1.99552517]), 'currentState': array([2.70763995, 2.44670044]), 'targetState': array([-0.22415098, -0.64391826]), 'effectorPosition': array([-0.47960669, -0.48345835])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.933664019649739
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-4.02997957,  1.99552517]), 'currentState': array([3.16845061, 2.43766198]), 'targetState': array([-0.22415098, -0.64391826]), 'effectorPosition': array([-0.22022931, -0.65336889])}
episode index:3553
target Thresh 1.9985236955912797
current state at start:  [ 2.25203999 -1.88759899]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.25203999, -1.88759899]), 'currentState': array([2.31000418, 3.98646829]), 'targetState': array([0.32316258, 0.72438806]), 'effectorPosition': array([0.326209  , 0.75228924])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9336826848102202
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.25203999, -1.88759899]), 'currentState': array([2.31000418, 3.98646829]), 'targetState': array([0.32316258, 0.72438806]), 'effectorPosition': array([0.326209  , 0.75228924])}
episode index:3554
target Thresh 1.998526645249456
current state at start:  [-0.57635844 -1.78367118]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.57635844, -1.78367118]), 'currentState': array([5.90591991, 4.15930548]), 'targetState': array([ 1.03052264, -0.69041049]), 'effectorPosition': array([ 0.127847  , -0.96593382])}
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.9336718987538063
{'reset': False, 'endBeforeDone': False, 'stepCount': 12, 'initial state': array([-0.57635844, -1.78367118]), 'currentState': array([4.91968086, 1.86713249]), 'targetState': array([ 1.03052264, -0.69041049]), 'effectorPosition': array([ 1.08164792, -0.49598558])}
episode index:3555
target Thresh 1.998529589014211
current state at start:  [ 3.72551233 -2.14952252]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.72551233, -2.14952252]), 'currentState': array([4.22551233, 3.79354989]), 'targetState': array([-0.67021747, -0.1645184 ]), 'effectorPosition': array([-0.63219959,  0.10260664])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9336877390522443
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.72551233, -2.14952252]), 'currentState': array([4.72551233, 3.70703117]), 'targetState': array([-0.67021747, -0.1645184 ]), 'effectorPosition': array([-0.53369746, -0.16266397])}
episode index:3556
target Thresh 1.9985325268973202
current state at start:  [-4.12575547  2.39761127]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.12575547,  2.39761127]), 'currentState': array([1.73200968, 2.10692303]), 'targetState': array([-0.76114807,  0.82956786]), 'effectorPosition': array([-0.92706901,  0.34485228])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9337035704441329
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-4.12575547,  2.39761127]), 'currentState': array([1.34612131, 1.86157702]), 'targetState': array([-0.76114807,  0.82956786]), 'effectorPosition': array([-0.77502626,  0.90880903])}
episode index:3557
target Thresh 1.9985354589105349
current state at start:  [ 1.10130305 -2.22852681]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.10130305, -2.22852681]), 'currentState': array([1.19299986, 3.57363301]), 'targetState': array([-0.00891571, -0.00956701]), 'effectorPosition': array([ 0.42309052, -0.06904945])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9337193929369816
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.10130305, -2.22852681]), 'currentState': array([1.69299986, 3.08887556]), 'targetState': array([-0.00891571, -0.00956701]), 'effectorPosition': array([-0.05246907, -0.00504435])}
episode index:3558
target Thresh 1.9985383850655833
current state at start:  [ 0.66701325 -2.31137981]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.66701325, -2.31137981]), 'currentState': array([0.29100522, 3.49294193]), 'targetState': array([-0.13408302, -0.92519289]), 'effectorPosition': array([ 0.1572685 , -0.31216699])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9337296709945998
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 0.66701325, -2.31137981]), 'currentState': array([5.71997502, 4.11506671]), 'targetState': array([-0.13408302, -0.92519289]), 'effectorPosition': array([-0.07147016, -0.93275461])}
episode index:3559
target Thresh 1.9985413053741703
current state at start:  [1.79797983 2.04118428]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.79797983, 2.04118428]), 'currentState': array([1.36911666, 2.4856115 ]), 'targetState': array([-0.23743833,  0.57128423]), 'effectorPosition': array([-0.55599908,  0.32552308])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.933742696367916
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([1.79797983, 2.04118428]), 'currentState': array([0.88407024, 2.51613126]), 'targetState': array([-0.23743833,  0.57128423]), 'effectorPosition': array([-0.3327379 ,  0.51758994])}
episode index:3560
target Thresh 1.9985442198479766
current state at start:  [-1.6197623   2.09530223]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.6197623 ,  2.09530223]), 'currentState': array([4.21993561, 2.59530223]), 'targetState': array([ 0.07720996, -0.50112233]), 'effectorPosition': array([ 0.38897847, -0.37387237])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9337584945436059
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.6197623 ,  2.09530223]), 'currentState': array([3.89158146, 2.44985452]), 'targetState': array([ 0.07720996, -0.50112233]), 'effectorPosition': array([ 0.26660741, -0.62341284])}
episode index:3561
target Thresh 1.9985471284986605
current state at start:  [ 1.88560128 -2.78584239]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.88560128, -2.78584239]), 'currentState': array([1.78459883, 3.08772889]), 'targetState': array([0.26690555, 0.03639933]), 'effectorPosition': array([-0.05291962, -0.01000587])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9337742838488996
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.88560128, -2.78584239]), 'currentState': array([1.54360562, 3.44886422]), 'targetState': array([0.26690555, 0.03639933]), 'effectorPosition': array([0.30362072, 0.03859727])}
episode index:3562
target Thresh 1.9985500313378564
current state at start:  [-1.47324353 -2.25903983]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.47324353, -2.25903983]), 'currentState': array([4.53294785, 3.61732003]), 'targetState': array([0.13328376, 0.02167291]), 'effectorPosition': array([-0.47045   , -0.02751621])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9337900642912659
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.47324353, -2.25903983]), 'currentState': array([4.77924092, 3.17681437]), 'targetState': array([0.13328376, 0.02167291]), 'effectorPosition': array([-0.03509435, -0.00297124])}
episode index:3563
target Thresh 1.9985529283771755
current state at start:  [1.56426831 1.85697498]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.56426831, 1.85697498]), 'currentState': array([2.06426831, 1.78542505]), 'targetState': array([-1.40827415, -0.01748399]), 'effectorPosition': array([-1.23328502,  0.2303013 ])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9338030581003873
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([1.56426831, 1.85697498]), 'currentState': array([2.15126415, 1.84319122]), 'targetState': array([-1.40827415, -0.01748399]), 'effectorPosition': array([-1.20624493,  0.08303952])}
episode index:3564
target Thresh 1.9985558196282065
current state at start:  [-0.0509483  2.3956474]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.0509483,  2.3956474]), 'currentState': array([5.98478913, 2.86418959]), 'targetState': array([0.06233695, 0.00466717]), 'effectorPosition': array([0.11705184, 0.2505177 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9338188216184516
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.0509483,  2.3956474]), 'currentState': array([5.70306372, 2.96189349]), 'targetState': array([0.06233695, 0.00466717]), 'effectorPosition': array([0.11143652, 0.14066587])}
episode index:3565
target Thresh 1.998558705102514
current state at start:  [-0.83179284 -2.62829141]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.83179284, -2.62829141]), 'currentState': array([5.17747125, 3.1548939 ]), 'targetState': array([0.15138305, 0.05234935]), 'effectorPosition': array([-0.01184843, -0.00604445])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9338373805579866
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.83179284, -2.62829141]), 'currentState': array([5.17747125, 3.1548939 ]), 'targetState': array([0.15138305, 0.05234935]), 'effectorPosition': array([-0.01184843, -0.00604445])}
episode index:3566
target Thresh 1.9985615848116398
current state at start:  [0.74901463 2.46318442]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.74901463, 2.46318442]), 'currentState': array([0.638029  , 2.42857911]), 'targetState': array([-0.1025956 ,  0.53218604]), 'effectorPosition': array([-0.1939187 ,  0.67052765])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9338559290916121
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.74901463, 2.46318442]), 'currentState': array([0.638029  , 2.42857911]), 'targetState': array([-0.1025956 ,  0.53218604]), 'effectorPosition': array([-0.1939187 ,  0.67052765])}
episode index:3567
target Thresh 1.9985644587671032
current state at start:  [-1.12240121  2.2019379 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.12240121,  2.2019379 ]), 'currentState': array([4.82542822, 2.03904422]), 'targetState': array([ 0.48750713, -0.51477485]), 'effectorPosition': array([ 0.94855524, -0.44451774])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9338716645374944
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.12240121,  2.2019379 ]), 'currentState': array([4.45914892, 2.31656756]), 'targetState': array([ 0.48750713, -0.51477485]), 'effectorPosition': array([ 0.63059681, -0.49524802])}
episode index:3568
target Thresh 1.9985673269803996
current state at start:  [-2.46640521  2.40031231]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.46640521,  2.40031231]), 'currentState': array([3.42703608, 2.85371095]), 'targetState': array([-0.14858327,  0.25642072]), 'effectorPosition': array([ 0.04046014, -0.28402123])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9338873911655309
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.46640521,  2.40031231]), 'currentState': array([3.02632878, 3.29956061]), 'targetState': array([-0.14858327,  0.25642072]), 'effectorPosition': array([0.00572385, 0.15769992])}
episode index:3569
target Thresh 1.998570189463002
current state at start:  [-0.19419041  2.24419214]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.19419041,  2.24419214]), 'currentState': array([0.20794615, 1.74419214]), 'targetState': array([0.64119786, 0.91012108]), 'effectorPosition': array([0.60629063, 1.13461677])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9339059101035798
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.19419041,  2.24419214]), 'currentState': array([0.20794615, 1.74419214]), 'targetState': array([0.64119786, 0.91012108]), 'effectorPosition': array([0.60629063, 1.13461677])}
episode index:3570
target Thresh 1.9985730462263605
current state at start:  [ 2.76300493 -2.1892911 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.76300493, -2.1892911 ]), 'currentState': array([2.55534415, 3.59389421]), 'targetState': array([-0.74398187, -0.04312992]), 'effectorPosition': array([0.1580205 , 0.41969308])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9339188460010586
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 2.76300493, -2.1892911 ]), 'currentState': array([1.74426751, 2.59389421]), 'targetState': array([-0.74398187, -0.04312992]), 'effectorPosition': array([-0.53815585,  0.05420119])}
episode index:3571
target Thresh 1.9985758972819017
current state at start:  [-2.32858346  2.17448716]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.32858346,  2.17448716]), 'currentState': array([3.54968642, 2.53327672]), 'targetState': array([ 0.1670431 , -0.57162608]), 'effectorPosition': array([ 0.06214342, -0.59574742])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9339373457642162
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.32858346,  2.17448716]), 'currentState': array([3.54968642, 2.53327672]), 'targetState': array([ 0.1670431 , -0.57162608]), 'effectorPosition': array([ 0.06214342, -0.59574742])}
episode index:3572
target Thresh 1.9985787426410304
current state at start:  [ 1.56656908 -2.56590882]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.56656908, -2.56590882]), 'currentState': array([1.08429535, 3.21727649]), 'targetState': array([ 0.6483684 , -0.61608043]), 'effectorPosition': array([ 0.0681771 , -0.03282061])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9339502656226645
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 1.56656908, -2.56590882]), 'currentState': array([0.5893792 , 4.11417386]), 'targetState': array([ 0.6483684 , -0.61608043]), 'effectorPosition': array([ 0.82245011, -0.44411589])}
episode index:3573
target Thresh 1.9985815823151276
current state at start:  [ 2.88925693 -2.33019324]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.88925693, -2.33019324]), 'currentState': array([2.87448984, 4.42666413]), 'targetState': array([-0.90733395,  1.06767797]), 'effectorPosition': array([-0.43944384,  1.11498123])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9339659482567935
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 2.88925693, -2.33019324]), 'currentState': array([3.08102677, 4.75592445]), 'targetState': array([-0.90733395,  1.06767797]), 'effectorPosition': array([-0.98113686,  1.06038384])}
episode index:3574
target Thresh 1.9985844163155524
current state at start:  [0.08173009 2.66547712]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.08173009, 2.66547712]), 'currentState': array([5.8649154 , 2.20112699]), 'targetState': array([1.00877555, 0.58544408]), 'effectorPosition': array([0.7033181 , 0.57141914])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.933981622117421
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.08173009, 2.66547712]), 'currentState': array([6.08357236, 1.78445211]), 'targetState': array([1.00877555, 0.58544408]), 'effectorPosition': array([0.96610103, 0.80161142])}
episode index:3575
target Thresh 1.9985872446536403
current state at start:  [1.71121994 1.95437461]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.71121994, 1.95437461]), 'currentState': array([1.87686826, 1.69952535]), 'targetState': array([-1.07358006,  0.48025612]), 'effectorPosition': array([-1.20826937,  0.53229462])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9340000836324888
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.71121994, 1.95437461]), 'currentState': array([1.87686826, 1.69952535]), 'targetState': array([-1.07358006,  0.48025612]), 'effectorPosition': array([-1.20826937,  0.53229462])}
episode index:3576
target Thresh 1.998590067340705
current state at start:  [ 3.90045459 -2.67066488]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.90045459, -2.67066488]), 'currentState': array([3.40045459, 3.95783445]), 'targetState': array([-1.27021563,  0.08516765]), 'effectorPosition': array([-0.49104093,  0.62365892])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.9340048334133855
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([ 3.90045459, -2.67066488]), 'currentState': array([2.07766624, 1.89422422]), 'targetState': array([-1.27021563,  0.08516765]), 'effectorPosition': array([-1.16009906,  0.13613594])}
episode index:3577
target Thresh 1.9985928843880374
current state at start:  [-3.98766569  2.37002887]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.98766569,  2.37002887]), 'currentState': array([1.79551962, 2.03636886]), 'targetState': array([-1.2926832 ,  0.42316546]), 'effectorPosition': array([-0.9938943,  0.3380905])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.934020483264304
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.98766569,  2.37002887]), 'currentState': array([2.0713208 , 1.67909522]), 'targetState': array([-1.2926832 ,  0.42316546]), 'effectorPosition': array([-1.30020725,  0.30542835])}
episode index:3578
target Thresh 1.9985956958069053
current state at start:  [ 2.9742937  -1.99964088]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.9742937 , -1.99964088]), 'currentState': array([2.4742937 , 4.78354443]), 'targetState': array([0.15842328, 1.31367206]), 'effectorPosition': array([-0.22404074,  1.4463736 ])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9340333582340542
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 2.9742937 , -1.99964088]), 'currentState': array([2.42091613, 4.66686101]), 'targetState': array([0.15842328, 1.31367206]), 'effectorPosition': array([-0.05795407,  1.38044081])}
episode index:3579
target Thresh 1.9985985016085546
current state at start:  [-1.23660349 -2.39956898]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.23660349, -2.39956898]), 'currentState': array([4.95002032, 4.38361633]), 'targetState': array([-0.3331559 , -0.97949024]), 'effectorPosition': array([-0.76044832, -0.8808831 ])}
done in step count: 88
reward sum = 0.41294967113388814
running average episode reward sum: 0.9338878041315123
{'reset': False, 'endBeforeDone': False, 'stepCount': 89, 'initial state': array([-1.23660349, -2.39956898]), 'currentState': array([3.25240413, 2.00502124]), 'targetState': array([-0.3331559 , -0.97949024]), 'effectorPosition': array([-0.47541748, -0.96569326])}
episode index:3580
target Thresh 1.9986013018042084
current state at start:  [-3.69467175  1.91251473]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.69467175,  1.91251473]), 'currentState': array([2.58081591, 1.83620154]), 'targetState': array([-1.27235498, -0.49076033]), 'effectorPosition': array([-1.13793757, -0.42484992])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9339062660683647
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.69467175,  1.91251473]), 'currentState': array([2.58081591, 1.83620154]), 'targetState': array([-1.27235498, -0.49076033]), 'effectorPosition': array([-1.13793757, -0.42484992])}
episode index:3581
target Thresh 1.9986040964050675
current state at start:  [-0.03111969 -2.06560303]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.03111969, -2.06560303]), 'currentState': array([5.97080346, 3.73534995]), 'targetState': array([-0.36086562, -0.7836688 ]), 'effectorPosition': array([-0.00907015, -0.58500335])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9339219259605845
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.03111969, -2.06560303]), 'currentState': array([5.52026262, 3.97580197]), 'targetState': array([-0.36086562, -0.7836688 ]), 'effectorPosition': array([-0.27464077, -0.76226323])}
episode index:3582
target Thresh 1.9986068854223105
current state at start:  [2.09792691 1.86685564]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.09792691, 1.86685564]), 'currentState': array([2.51842248, 1.91984271]), 'targetState': array([-0.96006485, -0.21881083]), 'effectorPosition': array([-1.08273594, -0.37905038])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9339403680688846
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.09792691, 1.86685564]), 'currentState': array([2.51842248, 1.91984271]), 'targetState': array([-0.96006485, -0.21881083]), 'effectorPosition': array([-1.08273594, -0.37905038])}
episode index:3583
target Thresh 1.9986096688670933
current state at start:  [0.68445164 2.09906262]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.68445164, 2.09906262]), 'currentState': array([0.48214283, 2.5927563 ]), 'targetState': array([0.18267903, 0.1959809 ]), 'effectorPosition': array([-0.11177344,  0.53032288])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9339560097072582
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.68445164, 2.09906262]), 'currentState': array([0.1294893 , 3.07517496]), 'targetState': array([0.18267903, 0.1959809 ]), 'effectorPosition': array([-0.00638368,  0.06609794])}
episode index:3584
target Thresh 1.9986124467505497
current state at start:  [ 3.1750001  -1.61640996]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.1750001 , -1.61640996]), 'currentState': array([3.10116251, 4.26922241]), 'targetState': array([0.00439769, 0.19239923]), 'effectorPosition': array([-0.53421636,  0.92574743])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9339688811131976
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 3.1750001 , -1.61640996]), 'currentState': array([3.23381584, 3.31924683]), 'targetState': array([0.00439769, 0.19239923]), 'effectorPosition': array([-0.03194686,  0.17452073])}
episode index:3585
target Thresh 1.9986152190837911
current state at start:  [-1.4184036   1.74713212]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.4184036 ,  1.74713212]), 'currentState': array([4.36478171, 2.24713212]), 'targetState': array([ 0.25580153, -0.46349799]), 'effectorPosition': array([ 0.60580443, -0.61735059])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9339845060766351
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.4184036 ,  1.74713212]), 'currentState': array([3.86478171, 2.73248955]), 'targetState': array([ 0.25580153, -0.46349799]), 'effectorPosition': array([ 0.20138007, -0.35283159])}
episode index:3586
target Thresh 1.9986179858779072
current state at start:  [-3.76936713  1.98794839]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.76936713,  1.98794839]), 'currentState': array([2.97524411, 2.3755804 ]), 'targetState': array([-0.29673279, -1.24342362]), 'effectorPosition': array([-0.3902561 , -0.63744666])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9340001223280773
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.76936713,  1.98794839]), 'currentState': array([3.44329677, 1.92886776]), 'targetState': array([-0.29673279, -1.24342362]), 'effectorPosition': array([-0.34189198, -1.08727761])}
episode index:3587
target Thresh 1.998620747143965
current state at start:  [ 0.42085021 -1.67996289]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.42085021, -1.67996289]), 'currentState': array([6.20577362, 4.435134  ]), 'targetState': array([ 0.66809575, -1.20136346]), 'effectorPosition': array([ 0.64972741, -1.0150967 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.934018516942813
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.42085021, -1.67996289]), 'currentState': array([6.20577362, 4.435134  ]), 'targetState': array([ 0.66809575, -1.20136346]), 'effectorPosition': array([ 0.64972741, -1.0150967 ])}
episode index:3588
target Thresh 1.9986235028930095
current state at start:  [0.86393053 1.58088626]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.86393053, 1.58088626]), 'currentState': array([1.31721187, 1.9654182 ]), 'targetState': array([-0.50639485,  1.12345974]), 'effectorPosition': array([-0.73919531,  0.82744908])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9340313565870196
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([0.86393053, 1.58088626]), 'currentState': array([1.05212228, 1.69872129]), 'targetState': array([-0.50639485,  1.12345974]), 'effectorPosition': array([-0.428895 ,  1.2493584])}
episode index:3589
target Thresh 1.9986262531360637
current state at start:  [-0.36715275 -2.33236393]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.36715275, -2.33236393]), 'currentState': array([6.05031533, 3.45082138]), 'targetState': array([-0.19200315, -0.23498886]), 'effectorPosition': array([-0.02407799, -0.30705555])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9340497322537085
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.36715275, -2.33236393]), 'currentState': array([6.05031533, 3.45082138]), 'targetState': array([-0.19200315, -0.23498886]), 'effectorPosition': array([-0.02407799, -0.30705555])}
episode index:3590
target Thresh 1.9986289978841285
current state at start:  [ 3.55950985 -1.71308907]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.55950985, -1.71308907]), 'currentState': array([3.07945228, 4.18590875]), 'targetState': array([-0.52411459,  0.75404302]), 'effectorPosition': array([-0.44285561,  0.89380772])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9340680976861079
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.55950985, -1.71308907]), 'currentState': array([3.07945228, 4.18590875]), 'targetState': array([-0.52411459,  0.75404302]), 'effectorPosition': array([-0.44285561,  0.89380772])}
episode index:3591
target Thresh 1.998631737148183
current state at start:  [-1.57010112 -2.03767556]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.57010112, -2.03767556]), 'currentState': array([4.86674483, 4.73637876]), 'targetState': array([-0.57783292, -1.07297608]), 'effectorPosition': array([-0.83039489, -1.16551246])}
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.9340548228459158
{'reset': False, 'endBeforeDone': False, 'stepCount': 13, 'initial state': array([-1.57010112, -2.03767556]), 'currentState': array([3.37007279, 1.62213606]), 'targetState': array([-0.57783292, -1.07297608]), 'effectorPosition': array([-0.69782923, -1.18760263])}
episode index:3592
target Thresh 1.9986344709391843
current state at start:  [1.81018873 2.16753428]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.81018873, 2.16753428]), 'currentState': array([1.31018873, 1.79422529]), 'targetState': array([-0.52465356,  0.98414487]), 'effectorPosition': array([-0.74164127,  1.00340367])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.934073176638611
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.81018873, 2.16753428]), 'currentState': array([1.31018873, 1.79422529]), 'targetState': array([-0.52465356,  0.98414487]), 'effectorPosition': array([-0.74164127,  1.00340367])}
episode index:3593
target Thresh 1.9986371992680678
current state at start:  [1.43580129 2.38707527]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.43580129, 2.38707527]), 'currentState': array([1.76363831, 2.85112747]), 'targetState': array([-0.15727955, -0.06178898]), 'effectorPosition': array([-0.28911718, -0.0137751 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9340915202177322
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.43580129, 2.38707527]), 'currentState': array([1.76363831, 2.85112747]), 'targetState': array([-0.15727955, -0.06178898]), 'effectorPosition': array([-0.28911718, -0.0137751 ])}
episode index:3594
target Thresh 1.9986399221457463
current state at start:  [0.98567177 2.20368154]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.98567177, 2.20368154]), 'currentState': array([0.48567177, 2.68324367]), 'targetState': array([0.13211009, 0.43420777]), 'effectorPosition': array([-0.11526519,  0.43948316])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9341098535918023
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.98567177, 2.20368154]), 'currentState': array([0.48567177, 2.68324367]), 'targetState': array([0.13211009, 0.43420777]), 'effectorPosition': array([-0.11526519,  0.43948316])}
episode index:3595
target Thresh 1.9986426395831116
current state at start:  [-3.22155787  2.26896463]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.22155787,  2.26896463]), 'currentState': array([2.56162744, 2.76896463]), 'targetState': array([0.06753269, 0.05204241]), 'effectorPosition': array([-0.25690995, -0.26692637])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9341253959017045
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.22155787,  2.26896463]), 'currentState': array([2.06162744, 3.24177109]), 'targetState': array([0.06753269, 0.05204241]), 'effectorPosition': array([0.08584057, 0.05156283])}
episode index:3596
target Thresh 1.9986453515910334
current state at start:  [-1.46763161 -2.20036232]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.46763161, -2.20036232]), 'currentState': array([4.3278997 , 3.82329364]), 'targetState': array([-0.77750392,  0.24908554]), 'effectorPosition': array([-0.66794105,  0.02916666])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9341437096643117
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.46763161, -2.20036232]), 'currentState': array([4.3278997 , 3.82329364]), 'targetState': array([-0.77750392,  0.24908554]), 'effectorPosition': array([-0.66794105,  0.02916666])}
episode index:3597
target Thresh 1.9986480581803598
current state at start:  [ 1.86896979 -2.48688907]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.86896979, -2.48688907]), 'currentState': array([1.36896979, 4.29629623]), 'targetState': array([1.01615026, 0.36688396]), 'effectorPosition': array([1.01554479, 0.40036162])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9341620132469509
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.86896979, -2.48688907]), 'currentState': array([1.36896979, 4.29629623]), 'targetState': array([1.01615026, 0.36688396]), 'effectorPosition': array([1.01554479, 0.40036162])}
episode index:3598
target Thresh 1.9986507593619172
current state at start:  [-1.79025672 -2.12639967]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.79025672, -2.12639967]), 'currentState': array([4.93314877, 4.65678564]), 'targetState': array([-0.7799302 , -1.01463512]), 'effectorPosition': array([-0.76742161, -1.14013801])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9341803066581076
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.79025672, -2.12639967]), 'currentState': array([4.93314877, 4.65678564]), 'targetState': array([-0.7799302 , -1.01463512]), 'effectorPosition': array([-0.76742161, -1.14013801])}
episode index:3599
target Thresh 1.9986534551465103
current state at start:  [-0.4111911   2.73027696]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.4111911 ,  2.73027696]), 'currentState': array([5.59298919, 3.04459848]), 'targetState': array([0.09569657, 0.1192004 ]), 'effectorPosition': array([0.06528274, 0.07168445])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9341985899062581
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.4111911 ,  2.73027696]), 'currentState': array([5.59298919, 3.04459848]), 'targetState': array([0.09569657, 0.1192004 ]), 'effectorPosition': array([0.06528274, 0.07168445])}
episode index:3600
target Thresh 1.9986561455449219
current state at start:  [-4.15027029  2.99060226]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.15027029,  2.99060226]), 'currentState': array([1.63291501, 3.45088763]), 'targetState': array([0.25354458, 0.33629328]), 'effectorPosition': array([0.30085432, 0.06625604])}
done in step count: 106
reward sum = 0.3446121833475176
running average episode reward sum: 0.9340348613845811
{'reset': False, 'endBeforeDone': False, 'stepCount': 107, 'initial state': array([-4.15027029,  2.99060226]), 'currentState': array([6.17197086, 2.4848867 ]), 'targetState': array([0.25354458, 0.33629328]), 'effectorPosition': array([0.27446525, 0.58365544])}
episode index:3601
target Thresh 1.998658830567914
current state at start:  [-2.4975529  2.2344933]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.4975529,  2.2344933]), 'currentState': array([3.31965432, 1.98941135]), 'targetState': array([-0.67041686, -0.74096589]), 'effectorPosition': array([-0.42229235, -1.00432976])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9340503986246187
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.4975529,  2.2344933]), 'currentState': array([2.87827841, 2.0585156 ]), 'targetState': array([-0.67041686, -0.74096589]), 'effectorPosition': array([-0.7430063 , -0.71464469])}
episode index:3602
target Thresh 1.9986615102262268
current state at start:  [1.28633166 2.15701158]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.28633166, 2.15701158]), 'currentState': array([1.78633166, 2.63339035]), 'targetState': array([-0.63273167, -0.09368094]), 'effectorPosition': array([-0.50237722,  0.0193842 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9340687027049338
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.28633166, 2.15701158]), 'currentState': array([1.78633166, 2.63339035]), 'targetState': array([-0.63273167, -0.09368094]), 'effectorPosition': array([-0.50237722,  0.0193842 ])}
episode index:3603
target Thresh 1.9986641845305786
current state at start:  [-1.08078545  2.20377832]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.08078545,  2.20377832]), 'currentState': array([5.70239985, 1.72277727]), 'targetState': array([1.3085363 , 0.29074924]), 'effectorPosition': array([1.25181579, 0.3607827 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9340869966276018
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.08078545,  2.20377832]), 'currentState': array([5.70239985, 1.72277727]), 'targetState': array([1.3085363 , 0.29074924]), 'effectorPosition': array([1.25181579, 0.3607827 ])}
episode index:3604
target Thresh 1.9986668534916667
current state at start:  [ 4.05607779 -2.75497304]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.05607779, -2.75497304]), 'currentState': array([4.19215776, 3.02821227]), 'targetState': array([0.22572201, 0.52452796]), 'effectorPosition': array([ 0.0949784 , -0.06180978])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.934086435837388
{'reset': False, 'endBeforeDone': False, 'stepCount': 8, 'initial state': array([ 4.05607779, -2.75497304]), 'currentState': array([6.03777055, 2.46833847]), 'targetState': array([0.22572201, 0.52452796]), 'effectorPosition': array([0.36315803, 0.55183586])}
episode index:3605
target Thresh 1.998669517120167
current state at start:  [ 3.04532383 -2.29029051]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.04532383, -2.29029051]), 'currentState': array([2.58770684, 4.07820025]), 'targetState': array([0.67019689, 1.18355152]), 'effectorPosition': array([0.07716461, 0.89944274])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.934099196115858
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 3.04532383, -2.29029051]), 'currentState': array([1.94075028, 4.70235985]), 'targetState': array([0.67019689, 1.18355152]), 'effectorPosition': array([0.5743508 , 1.28454787])}
episode index:3606
target Thresh 1.998672175426734
current state at start:  [-0.51454577  2.59966554]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.51454577,  2.59966554]), 'currentState': array([5.41991616, 3.05997579]), 'targetState': array([-0.476723  , -0.17963191]), 'effectorPosition': array([0.06412122, 0.05045873])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9341146939821968
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.51454577,  2.59966554]), 'currentState': array([5.0477416 , 3.46153145]), 'targetState': array([-0.476723  , -0.17963191]), 'effectorPosition': array([-0.28028816, -0.15142394])}
episode index:3607
target Thresh 1.9986748284220008
current state at start:  [ 0.83329722 -2.38120259]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.83329722, -2.38120259]), 'currentState': array([1.33329722, 3.40198272]), 'targetState': array([-0.00506033, -0.00931027]), 'effectorPosition': array([ 0.25816164, -0.02780861])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9341301832577006
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.83329722, -2.38120259]), 'currentState': array([1.74300271, 2.90198272]), 'targetState': array([-0.00506033, -0.00931027]), 'effectorPosition': array([-0.23870903, -0.01252015])}
episode index:3608
target Thresh 1.9986774761165798
current state at start:  [ 1.54632951 -2.6356192 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.54632951, -2.6356192 ]), 'currentState': array([1.83117245, 3.14756611]), 'targetState': array([-0.4776545 ,  0.69251702]), 'effectorPosition': array([0.00576748, 0.00155506])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9341429208073659
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 1.54632951, -2.6356192 ]), 'currentState': array([1.16921219, 2.1649861 ]), 'targetState': array([-0.4776545 ,  0.69251702]), 'effectorPosition': array([-0.59063186,  0.72902594])}
episode index:3609
target Thresh 1.9986801185210612
current state at start:  [ 4.17068878 -2.46049199]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.17068878, -2.46049199]), 'currentState': array([4.56110678, 3.32269332]), 'targetState': array([0.09529512, 0.21719467]), 'effectorPosition': array([-0.18051985,  0.01097681])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9341556513002172
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 4.17068878, -2.46049199]), 'currentState': array([5.24534235, 2.94614021]), 'targetState': array([0.09529512, 0.21719467]), 'effectorPosition': array([0.17694928, 0.08227485])}
episode index:3610
target Thresh 1.9986827556460152
current state at start:  [-2.70584279  2.15862003]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.70584279,  2.15862003]), 'currentState': array([3.24182041, 2.19613661]), 'targetState': array([-0.45330436, -0.81792745]), 'effectorPosition': array([-0.33142089, -0.84818265])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.934173885680915
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.70584279,  2.15862003]), 'currentState': array([3.24182041, 2.19613661]), 'targetState': array([-0.45330436, -0.81792745]), 'effectorPosition': array([-0.33142089, -0.84818265])}
episode index:3611
target Thresh 1.9986853875019899
current state at start:  [ 1.56073974 -2.38962212]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.56073974, -2.38962212]), 'currentState': array([1.42054886, 4.30903363]), 'targetState': array([1.00821172, 0.35067058]), 'effectorPosition': array([1.00031866, 0.46297875])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9341921099650565
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.56073974, -2.38962212]), 'currentState': array([1.42054886, 4.30903363]), 'targetState': array([1.00821172, 0.35067058]), 'effectorPosition': array([1.00031866, 0.46297875])}
episode index:3612
target Thresh 1.998688014099513
current state at start:  [ 2.50026981 -2.5933929 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.50026981, -2.5933929 ]), 'currentState': array([2.43456109, 3.18979241]), 'targetState': array([ 0.38212363, -0.31975533]), 'effectorPosition': array([0.03041447, 0.03738618])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9342021035687197
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 2.50026981, -2.5933929 ]), 'currentState': array([3.93023176, 2.56337387]), 'targetState': array([ 0.38212363, -0.31975533]), 'effectorPosition': array([ 0.27313183, -0.50052379])}
episode index:3613
target Thresh 1.9986906354490905
current state at start:  [-1.74399433 -2.13364487]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.74399433, -2.13364487]), 'currentState': array([5.03919098, 4.59668315]), 'targetState': array([-0.70273957, -1.21713229]), 'effectorPosition': array([-0.65678589, -1.15660566])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9342203099595419
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.74399433, -2.13364487]), 'currentState': array([5.03919098, 4.59668315]), 'targetState': array([-0.70273957, -1.21713229]), 'effectorPosition': array([-0.65678589, -1.15660566])}
episode index:3614
target Thresh 1.9986932515612081
current state at start:  [ 1.34891377 -1.80342829]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.34891377, -1.80342829]), 'currentState': array([1.02985902, 3.97975701]), 'targetState': array([0.20274062, 0.08643907]), 'effectorPosition': array([ 0.80780968, -0.09892588])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.934235740025943
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.34891377, -1.80342829]), 'currentState': array([1.51986844, 3.47975701]), 'targetState': array([0.20274062, 0.08643907]), 'effectorPosition': array([0.33420888, 0.039673  ])}
episode index:3615
target Thresh 1.9986958624463302
current state at start:  [ 2.32957338 -2.83161554]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.32957338, -2.83161554]), 'currentState': array([1.89233403, 2.95156977]), 'targetState': array([-0.53037084,  0.11850359]), 'effectorPosition': array([-0.1848898, -0.0426138])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9342511615580154
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 2.32957338, -2.83161554]), 'currentState': array([2.00432929, 2.45156977]), 'targetState': array([-0.53037084,  0.11850359]), 'effectorPosition': array([-0.67376641, -0.0597991 ])}
episode index:3616
target Thresh 1.9986984681149005
current state at start:  [0.83997025 2.37457205]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.83997025, 2.37457205]), 'currentState': array([1.18296458, 2.68553502]), 'targetState': array([-0.3428171 ,  0.39500276]), 'effectorPosition': array([-0.36905141,  0.26116964])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.934269339284983
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.83997025, 2.37457205]), 'currentState': array([1.18296458, 2.68553502]), 'targetState': array([-0.3428171 ,  0.39500276]), 'effectorPosition': array([-0.36905141,  0.26116964])}
episode index:3617
target Thresh 1.9987010685773414
current state at start:  [-4.57028768  2.87524815]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.57028768,  2.87524815]), 'currentState': array([1.25841221, 3.13678018]), 'targetState': array([0.14121434, 0.11104035]), 'effectorPosition': array([-0.00457599,  0.00149002])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.934287506963456
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.57028768,  2.87524815]), 'currentState': array([1.25841221, 3.13678018]), 'targetState': array([0.14121434, 0.11104035]), 'effectorPosition': array([-0.00457599,  0.00149002])}
episode index:3618
target Thresh 1.998703663844055
current state at start:  [ 4.03305985 -1.8235548 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.03305985, -1.8235548 ]), 'currentState': array([4.49274178, 4.07839961]), 'targetState': array([-0.70637219, -0.44001616]), 'effectorPosition': array([-0.87513202, -0.22229887])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9343029014075113
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 4.03305985, -1.8235548 ]), 'currentState': array([4.81905056, 4.15792138]), 'targetState': array([-0.70637219, -0.44001616]), 'effectorPosition': array([-0.79493978, -0.56132812])}
episode index:3619
target Thresh 1.9987062539254221
current state at start:  [ 3.68027844 -1.83020671]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.68027844, -1.83020671]), 'currentState': array([4.0552192 , 3.96560482]), 'targetState': array([-0.77009644,  0.22086598]), 'effectorPosition': array([-0.77694797,  0.19438975])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9343210497772882
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.68027844, -1.83020671]), 'currentState': array([4.0552192 , 3.96560482]), 'targetState': array([-0.77009644,  0.22086598]), 'effectorPosition': array([-0.77694797,  0.19438975])}
episode index:3620
target Thresh 1.9987088388318033
current state at start:  [ 0.21488851 -2.641769  ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.21488851, -2.641769  ]), 'currentState': array([0.39459906, 3.14141631]), 'targetState': array([-0.23664282, -0.39949799]), 'effectorPosition': array([-6.77781538e-05,  1.62796052e-04])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.9343230268829562
{'reset': False, 'endBeforeDone': False, 'stepCount': 7, 'initial state': array([ 0.21488851, -2.641769  ]), 'currentState': array([2.66329356, 2.71074969]), 'targetState': array([-0.23664282, -0.39949799]), 'effectorPosition': array([-0.27335621, -0.32870708])}
episode index:3621
target Thresh 1.998711418573538
current state at start:  [ 3.7670315  -2.26730874]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.7670315 , -2.26730874]), 'currentState': array([4.2670315 , 3.88832448]), 'targetState': array([-0.77344619, -0.40787951]), 'effectorPosition': array([-0.7276134 ,  0.05247272])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9343383987695152
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.7670315 , -2.26730874]), 'currentState': array([4.7670315, 4.0417906]), 'targetState': array([-0.77344619, -0.40787951]), 'effectorPosition': array([-0.76160625, -0.42076848])}
episode index:3622
target Thresh 1.9987139931609452
current state at start:  [-1.25500053  2.55683272]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.25500053,  2.55683272]), 'currentState': array([4.61032588, 2.61734661]), 'targetState': array([ 0.19282774, -0.34616618]), 'effectorPosition': array([ 0.48427244, -0.18459963])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9343537621703516
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.25500053,  2.55683272]), 'currentState': array([4.26813955, 2.58284857]), 'targetState': array([ 0.19282774, -0.34616618]), 'effectorPosition': array([ 0.41330433, -0.36515257])}
episode index:3623
target Thresh 1.9987165626043235
current state at start:  [ 2.74834544 -1.9438208 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.74834544, -1.9438208 ]), 'currentState': array([2.44502426, 3.83936451]), 'targetState': array([0.132688  , 0.62493862]), 'effectorPosition': array([0.2329509 , 0.64279272])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9343718764743885
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.74834544, -1.9438208 ]), 'currentState': array([2.44502426, 3.83936451]), 'targetState': array([0.132688  , 0.62493862]), 'effectorPosition': array([0.2329509 , 0.64279272])}
episode index:3624
target Thresh 1.9987191269139506
current state at start:  [-1.95258674  2.57658824]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.95258674,  2.57658824]), 'currentState': array([4.21179595, 3.053346  ]), 'targetState': array([0.02059356, 0.39393225]), 'effectorPosition': array([ 0.0754506 , -0.04571242])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.9343764607980921
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([-1.95258674,  2.57658824]), 'currentState': array([5.94285526, 2.91102477]), 'targetState': array([0.02059356, 0.39393225]), 'effectorPosition': array([0.10122846, 0.20658957])}
episode index:3625
target Thresh 1.9987216861000834
current state at start:  [1.94025525 1.99371206]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.94025525, 1.99371206]), 'currentState': array([2.43331283, 1.70991626]), 'targetState': array([-1.19886876, -0.34176767]), 'effectorPosition': array([-1.29840659, -0.19182574])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9343945588508229
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.94025525, 1.99371206]), 'currentState': array([2.43331283, 1.70991626]), 'targetState': array([-1.19886876, -0.34176767]), 'effectorPosition': array([-1.29840659, -0.19182574])}
episode index:3626
target Thresh 1.998724240172959
current state at start:  [-1.58409695 -1.78555187]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.58409695, -1.78555187]), 'currentState': array([4.83339714, 4.96622438]), 'targetState': array([-0.70068446, -1.18470849]), 'effectorPosition': array([-0.80985186, -1.3588144 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9344126469239272
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.58409695, -1.78555187]), 'currentState': array([4.83339714, 4.96622438]), 'targetState': array([-0.70068446, -1.18470849]), 'effectorPosition': array([-0.80985186, -1.3588144 ])}
episode index:3627
target Thresh 1.9987267891427936
current state at start:  [ 0.4641034  -2.06158181]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.4641034 , -2.06158181]), 'currentState': array([0.9524844, 3.7698754]), 'targetState': array([0.09429521, 0.43260485]), 'effectorPosition': array([ 0.5896311 , -0.18509216])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.9344145949676088
{'reset': False, 'endBeforeDone': False, 'stepCount': 7, 'initial state': array([ 0.4641034 , -2.06158181]), 'currentState': array([0.12283248, 2.54209546]), 'targetState': array([0.09429521, 0.43260485]), 'effectorPosition': array([0.10393542, 0.58134207])}
episode index:3628
target Thresh 1.998729333019783
current state at start:  [-1.64960024 -2.02810137]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.64960024, -2.02810137]), 'currentState': array([5.13358507, 4.69643723]), 'targetState': array([-0.36314554, -1.35590239]), 'effectorPosition': array([-0.5101538 , -1.30684389])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9344326675509741
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.64960024, -2.02810137]), 'currentState': array([5.13358507, 4.69643723]), 'targetState': array([-0.36314554, -1.35590239]), 'effectorPosition': array([-0.5101538 , -1.30684389])}
episode index:3629
target Thresh 1.998731871814103
current state at start:  [ 3.45182503 -2.0001317 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.45182503, -2.0001317 ]), 'currentState': array([3.95182503, 3.8008866 ]), 'targetState': array([-0.4555186 , -0.18100736]), 'effectorPosition': array([-0.58823311,  0.2704292 ])}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.934426905727264
{'reset': False, 'endBeforeDone': False, 'stepCount': 10, 'initial state': array([ 3.45182503, -2.0001317 ]), 'currentState': array([2.45803107, 2.63499907]), 'targetState': array([-0.4555186 , -0.18100736]), 'effectorPosition': array([-0.40381248, -0.29686821])}
episode index:3630
target Thresh 1.9987344055359084
current state at start:  [ 0.81559843 -2.44306667]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.81559843, -2.44306667]), 'currentState': array([1.29137481, 3.49641829]), 'targetState': array([0.24094606, 0.29733397]), 'effectorPosition': array([ 0.35113233, -0.03594331])}
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.934413674652075
{'reset': False, 'endBeforeDone': False, 'stepCount': 13, 'initial state': array([ 0.81559843, -2.44306667]), 'currentState': array([5.70676018, 2.63614942]), 'targetState': array([0.24094606, 0.29733397]), 'effectorPosition': array([0.36873669, 0.33780668])}
episode index:3631
target Thresh 1.9987369341953343
current state at start:  [-3.84444508  2.99752364]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.84444508,  2.99752364]), 'currentState': array([2.48250945, 3.09833784]), 'targetState': array([ 0.01889263, -0.02384309]), 'effectorPosition': array([-0.02722009, -0.0336118 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9344317325610364
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.84444508,  2.99752364]), 'currentState': array([2.48250945, 3.09833784]), 'targetState': array([ 0.01889263, -0.02384309]), 'effectorPosition': array([-0.02722009, -0.0336118 ])}
episode index:3632
target Thresh 1.998739457802495
current state at start:  [-2.06933719 -1.91096999]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.06933719, -1.91096999]), 'currentState': array([4.71384811, 4.72757722]), 'targetState': array([-0.94481341, -0.91189432]), 'effectorPosition': array([-0.9984023 , -1.01664554])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9344497805289524
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.06933719, -1.91096999]), 'currentState': array([4.71384811, 4.72757722]), 'targetState': array([-0.94481341, -0.91189432]), 'effectorPosition': array([-0.9984023 , -1.01664554])}
episode index:3633
target Thresh 1.9987419763674856
current state at start:  [-0.62991912  2.87318924]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.62991912,  2.87318924]), 'currentState': array([5.21802675, 3.05778943]), 'targetState': array([ 0.2464873 , -0.60002918]), 'effectorPosition': array([0.07493064, 0.03747361])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9344596454765229
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-0.62991912,  2.87318924]), 'currentState': array([3.91495001, 2.44601145]), 'targetState': array([ 0.2464873 , -0.60002918]), 'effectorPosition': array([ 0.2814075 , -0.62084383])}
episode index:3634
target Thresh 1.99874448990038
current state at start:  [-3.18474346  1.94708147]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.18474346,  1.94708147]), 'currentState': array([2.63282889, 2.44708147]), 'targetState': array([ 0.03743404, -0.12817845]), 'effectorPosition': array([-0.51404391, -0.44612284])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9344722012824442
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-3.18474346,  1.94708147]), 'currentState': array([2.34448208, 3.23115586]), 'targetState': array([ 0.03743404, -0.12817845]), 'effectorPosition': array([0.06118176, 0.06536819])}
episode index:3635
target Thresh 1.9987469984112323
current state at start:  [-2.60186849  2.8327697 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.60186849,  2.8327697 ]), 'currentState': array([3.18131681, 2.3655553 ]), 'targetState': array([-0.34214208, -0.60703381]), 'effectorPosition': array([-0.2582616 , -0.71127446])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9344902232292862
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.60186849,  2.8327697 ]), 'currentState': array([3.18131681, 2.3655553 ]), 'targetState': array([-0.34214208, -0.60703381]), 'effectorPosition': array([-0.2582616 , -0.71127446])}
episode index:3636
target Thresh 1.9987495019100763
current state at start:  [1.82752284 1.61888395]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.82752284, 1.61888395]), 'currentState': array([1.32752284, 2.11888395]), 'targetState': array([-0.38387175,  0.56522106]), 'effectorPosition': array([-0.71302174,  0.67043877])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9345054857469575
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.82752284, 1.61888395]), 'currentState': array([0.82752284, 2.59035269]), 'targetState': array([-0.38387175,  0.56522106]), 'effectorPosition': array([-0.28537438,  0.46347594])}
episode index:3637
target Thresh 1.9987520004069266
current state at start:  [ 2.05601213 -1.74944466]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.05601213, -1.74944466]), 'currentState': array([2.23735106, 4.05051298]), 'targetState': array([0.11217554, 0.46767822]), 'effectorPosition': array([0.38170722, 0.79063519])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9345207398740198
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 2.05601213, -1.74944466]), 'currentState': array([2.5183996 , 3.58879737]), 'targetState': array([0.11217554, 0.46767822]), 'effectorPosition': array([0.17253495, 0.40854966])}
episode index:3638
target Thresh 1.9987544939117767
current state at start:  [-1.35100091  1.78964933]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.35100091,  1.78964933]), 'currentState': array([4.43530351, 2.28964933]), 'targetState': array([0.15383084, 0.21908299]), 'effectorPosition': array([ 0.63044393, -0.53431883])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.9345226523251127
{'reset': False, 'endBeforeDone': False, 'stepCount': 7, 'initial state': array([-1.35100091,  1.78964933]), 'currentState': array([5.11755353, 2.82303184]), 'targetState': array([0.15383084, 0.21908299]), 'effectorPosition': array([0.30767448, 0.07721469])}
episode index:3639
target Thresh 1.9987569824346008
current state at start:  [-1.12820476 -2.36245296]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.12820476, -2.36245296]), 'currentState': array([5.13463673, 4.42073234]), 'targetState': array([-0.22298553, -1.2247961 ]), 'effectorPosition': array([-0.58167328, -1.04239034])}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9345194166223937
{'reset': False, 'endBeforeDone': False, 'stepCount': 9, 'initial state': array([-1.12820476, -2.36245296]), 'currentState': array([3.72810954, 1.73232721]), 'targetState': array([-0.22298553, -1.2247961 ]), 'effectorPosition': array([-0.15266447, -1.28648158])}
episode index:3640
target Thresh 1.998759465985353
current state at start:  [-0.1059194  -1.69067356]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.1059194 , -1.69067356]), 'currentState': array([0.37104627, 4.09251175]), 'targetState': array([-0.15233138, -0.34792534]), 'effectorPosition': array([ 0.68567739, -0.60661028])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.9345213283864086
{'reset': False, 'endBeforeDone': False, 'stepCount': 7, 'initial state': array([-0.1059194 , -1.69067356]), 'currentState': array([2.86611932, 2.77513114]), 'targetState': array([-0.15233138, -0.34792534]), 'effectorPosition': array([-0.16135778, -0.3267438 ])}
episode index:3641
target Thresh 1.9987619445739675
current state at start:  [-3.81567882  2.6748773 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.81567882,  2.6748773 ]), 'currentState': array([2.01336085, 3.10180969]), 'targetState': array([0.40321946, 0.49313719]), 'effectorPosition': array([-0.0362795 , -0.01631788])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9345311520194711
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-3.81567882,  2.6748773 ]), 'currentState': array([1.91299949, 3.73529307]), 'targetState': array([0.40321946, 0.49313719]), 'effectorPosition': array([0.46957199, 0.34892648])}
episode index:3642
target Thresh 1.9987644182103586
current state at start:  [1.23044358 2.2556295 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.23044358, 2.2556295 ]), 'currentState': array([1.15095226, 2.7556295 ]), 'targetState': array([0.02530092, 0.0704692 ]), 'effectorPosition': array([-0.31377183,  0.22062337])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9345463781649502
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.23044358, 2.2556295 ]), 'currentState': array([1.02175816, 3.22880094]), 'targetState': array([0.02530092, 0.0704692 ]), 'effectorPosition': array([ 0.07627997, -0.04221176])}
episode index:3643
target Thresh 1.9987668869044208
current state at start:  [ 0.11177278 -2.39156496]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.11177278, -2.39156496]), 'currentState': array([0.14555851, 4.14857591]), 'targetState': array([ 0.40251817, -0.90822683]), 'effectorPosition': array([ 0.58325896, -0.76875422])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9345643401907008
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.11177278, -2.39156496]), 'currentState': array([0.14555851, 4.14857591]), 'targetState': array([ 0.40251817, -0.90822683]), 'effectorPosition': array([ 0.58325896, -0.76875422])}
episode index:3644
target Thresh 1.9987693506660291
current state at start:  [ 2.63481777 -2.90251889]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.63481777, -2.90251889]), 'currentState': array([2.5021769 , 2.89197497]), 'targetState': array([0.0490565 , 0.06437377]), 'effectorPosition': array([-0.17228171, -0.1797363 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9345795488765194
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 2.63481777, -2.90251889]), 'currentState': array([2.09047013, 3.2192383 ]), 'targetState': array([0.0490565 , 0.06437377]), 'effectorPosition': array([0.06583106, 0.04113501])}
episode index:3645
target Thresh 1.9987718095050386
current state at start:  [-0.61268744  2.06679853]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.61268744,  2.06679853]), 'currentState': array([5.17049787, 2.5242718 ]), 'targetState': array([-0.00060453, -0.00064455]), 'effectorPosition': array([0.60079296, 0.09046208])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.934594749219669
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.61268744,  2.06679853]), 'currentState': array([4.67049787, 2.90802251]), 'targetState': array([-0.00060453, -0.00064455]), 'effectorPosition': array([ 0.23011197, -0.03682285])}
episode index:3646
target Thresh 1.9987742634312842
current state at start:  [-0.53546428 -1.68978816]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.53546428, -1.68978816]), 'currentState': array([6.01555271, 4.09339715]), 'targetState': array([ 0.9832211 , -0.82277094]), 'effectorPosition': array([ 0.18945695, -0.89648055])}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.9345889698114606
{'reset': False, 'endBeforeDone': False, 'stepCount': 10, 'initial state': array([-0.53546428, -1.68978816]), 'currentState': array([4.70849337, 1.90885271]), 'targetState': array([ 0.9832211 , -0.82277094]), 'effectorPosition': array([ 0.94079029, -0.67201593])}
episode index:3647
target Thresh 1.998776712454582
current state at start:  [-0.17780929  2.0475842 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.17780929,  2.0475842 ]), 'currentState': array([5.60537602, 1.93088093]), 'targetState': array([1.08720837, 0.23327787]), 'effectorPosition': array([1.0913543 , 0.32286062])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9346069004666657
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.17780929,  2.0475842 ]), 'currentState': array([5.60537602, 1.93088093]), 'targetState': array([1.08720837, 0.23327787]), 'effectorPosition': array([1.0913543 , 0.32286062])}
episode index:3648
target Thresh 1.998779156584728
current state at start:  [ 0.53976852 -1.92443828]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.53976852, -1.92443828]), 'currentState': array([0.82521299, 4.233886  ]), 'targetState': array([ 0.88133806, -0.52171919]), 'effectorPosition': array([ 1.01820593, -0.20580347])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9346220808173188
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.53976852, -1.92443828]), 'currentState': array([0.56548327, 4.2613477 ]), 'targetState': array([ 0.88133806, -0.52171919]), 'effectorPosition': array([ 0.9585221 , -0.45763474])}
episode index:3649
target Thresh 1.9987815958314987
current state at start:  [ 1.03467889 -2.60778326]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.03467889, -2.60778326]), 'currentState': array([1.43539311, 4.04981565]), 'targetState': array([0.60654614, 0.64249597]), 'effectorPosition': array([0.83314667, 0.27490211])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9346372528499716
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.03467889, -2.60778326]), 'currentState': array([1.84301881, 4.28229478]), 'targetState': array([0.60654614, 0.64249597]), 'effectorPosition': array([0.71869138, 0.80595896])}
episode index:3650
target Thresh 1.9987840302046511
current state at start:  [-2.09326929 -1.61520659]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.09326929, -1.61520659]), 'currentState': array([4.5445143 , 4.52446343]), 'targetState': array([-1.14392041, -0.53725712]), 'effectorPosition': array([-1.10445532, -0.63760153])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9346551555470819
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.09326929, -1.61520659]), 'currentState': array([4.5445143 , 4.52446343]), 'targetState': array([-1.14392041, -0.53725712]), 'effectorPosition': array([-1.10445532, -0.63760153])}
episode index:3651
target Thresh 1.9987864597139227
current state at start:  [0.6513947  1.92065164]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.6513947 , 1.92065164]), 'currentState': array([0.24600867, 2.34994563]), 'targetState': array([0.2354714 , 0.63363217]), 'effectorPosition': array([0.11509599, 0.76249861])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9346730484398675
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.6513947 , 1.92065164]), 'currentState': array([0.24600867, 2.34994563]), 'targetState': array([0.2354714 , 0.63363217]), 'effectorPosition': array([0.11509599, 0.76249861])}
episode index:3652
target Thresh 1.9987888843690316
current state at start:  [-3.0456003   1.99309035]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.0456003 ,  1.99309035]), 'currentState': array([2.78857332, 2.49309035]), 'targetState': array([ 0.0687791, -0.0147658]), 'effectorPosition': array([-0.39931184, -0.49655964])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9346881940603329
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.0456003 ,  1.99309035]), 'currentState': array([2.32775462, 2.96887748]), 'targetState': array([ 0.0687791, -0.0147658]), 'effectorPosition': array([-0.13514532, -0.10720164])}
episode index:3653
target Thresh 1.998791304179676
current state at start:  [-1.50455123 -2.66032071]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.50455123, -2.66032071]), 'currentState': array([4.64451073, 3.15092247]), 'targetState': array([-0.20846288,  0.6438761 ]), 'effectorPosition': array([-0.00931115,  0.00058937])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.934690052833004
{'reset': False, 'endBeforeDone': False, 'stepCount': 7, 'initial state': array([-1.50455123, -2.66032071]), 'currentState': array([0.36138529, 2.44267618]), 'targetState': array([-0.20846288,  0.6438761 ]), 'effectorPosition': array([-0.00816719,  0.68472897])}
episode index:3654
target Thresh 1.998793719155536
current state at start:  [-0.48961027 -2.06351726]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.48961027, -2.06351726]), 'currentState': array([5.47569172, 3.75447424]), 'targetState': array([-0.7254461 , -0.80679634]), 'effectorPosition': array([-0.28981115, -0.52917086])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9347051855134874
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.48961027, -2.06351726]), 'currentState': array([5.02936988, 4.20299165]), 'targetState': array([-0.7254461 , -0.80679634]), 'effectorPosition': array([-0.66984571, -0.75894951])}
episode index:3655
target Thresh 1.9987961293062708
current state at start:  [-0.23315364  2.00140203]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.23315364,  2.00140203]), 'currentState': array([5.57587618, 2.50140203]), 'targetState': array([0.4677468 , 0.00129117]), 'effectorPosition': array([0.53866758, 0.32538198])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9347203099156992
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.23315364,  2.00140203]), 'currentState': array([5.18960327, 2.71389502]), 'targetState': array([0.4677468 , 0.00129117]), 'effectorPosition': array([0.40981005, 0.11049644])}
episode index:3656
target Thresh 1.9987985346415211
current state at start:  [-3.66221186  2.3894036 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.66221186,  2.3894036 ]), 'currentState': array([2.61027248, 2.66492494]), 'targetState': array([-0.28380087, -0.36518285]), 'effectorPosition': array([-0.32857537, -0.33908801])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9347381605282462
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.66221186,  2.3894036 ]), 'currentState': array([2.61027248, 2.66492494]), 'targetState': array([-0.28380087, -0.36518285]), 'effectorPosition': array([-0.32857537, -0.33908801])}
episode index:3657
target Thresh 1.9988009351709086
current state at start:  [-1.57603034 -2.12099829]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.57603034, -2.12099829]), 'currentState': array([4.512287  , 3.92386014]), 'targetState': array([-0.00231723, -0.44465869]), 'effectorPosition': array([-0.74860329, -0.14477237])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.9347426033629569
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([-1.57603034, -2.12099829]), 'currentState': array([3.72944467, 2.82058103]), 'targetState': array([-0.00231723, -0.44465869]), 'effectorPosition': array([ 0.13247504, -0.29088992])}
episode index:3658
target Thresh 1.9988033309040352
current state at start:  [-2.78558995  2.75334885]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.78558995,  2.75334885]), 'currentState': array([3.26066363, 2.27374007]), 'targetState': array([-0.23895882, -0.61359674]), 'effectorPosition': array([-0.26040059, -0.79953658])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9347604381256345
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.78558995,  2.75334885]), 'currentState': array([3.26066363, 2.27374007]), 'targetState': array([-0.23895882, -0.61359674]), 'effectorPosition': array([-0.26040059, -0.79953658])}
episode index:3659
target Thresh 1.9988057218504836
current state at start:  [0.05713913 1.75961575]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.05713913, 1.75961575]), 'currentState': array([6.03990317, 1.67832693]), 'targetState': array([0.75574149, 0.7856023 ]), 'effectorPosition': array([1.10588753, 0.7499105 ])}
done in step count: 21
reward sum = 0.8097278682212584
running average episode reward sum: 0.934726276221289
{'reset': False, 'endBeforeDone': False, 'stepCount': 22, 'initial state': array([0.05713913, 1.75961575]), 'currentState': array([0.00654895, 2.04131719]), 'targetState': array([0.75574149, 0.7856023 ]), 'effectorPosition': array([0.54080042, 0.89489311])}
episode index:3660
target Thresh 1.998808108019818
current state at start:  [-1.48667184 -2.20764078]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.48667184, -2.20764078]), 'currentState': array([4.38040936, 3.97302321]), 'targetState': array([-0.84658302, -0.078832  ]), 'effectorPosition': array([-0.80485881, -0.06755334])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9347441057006057
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.48667184, -2.20764078]), 'currentState': array([4.38040936, 3.97302321]), 'targetState': array([-0.84658302, -0.078832  ]), 'effectorPosition': array([-0.80485881, -0.06755334])}
episode index:3661
target Thresh 1.9988104894215828
current state at start:  [1.58788445 2.89249162]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.58788445, 2.89249162]), 'currentState': array([1.08788445, 3.37682883]), 'targetState': array([0.61747843, 0.3704551 ]), 'effectorPosition': array([ 0.21920878, -0.08383832])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.9347459451445436
{'reset': False, 'endBeforeDone': False, 'stepCount': 7, 'initial state': array([1.58788445, 2.89249162]), 'currentState': array([5.68819851, 2.24802903]), 'targetState': array([0.61747843, 0.3704551 ]), 'effectorPosition': array([0.74600269, 0.43612189])}
episode index:3662
target Thresh 1.9988128660653035
current state at start:  [-3.22324311  2.17580558]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.22324311,  2.17580558]), 'currentState': array([2.55994219, 1.90581814]), 'targetState': array([-0.96002651, -0.59692827]), 'effectorPosition': array([-1.07969303, -0.42033726])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9347637595193334
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.22324311,  2.17580558]), 'currentState': array([2.55994219, 1.90581814]), 'targetState': array([-0.96002651, -0.59692827]), 'effectorPosition': array([-1.07969303, -0.42033726])}
episode index:3663
target Thresh 1.998815237960487
current state at start:  [-3.97818103  2.35753828]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.97818103,  2.35753828]), 'currentState': array([1.80500428, 2.85753828]), 'targetState': array([0.07437966, 0.45141199]), 'effectorPosition': array([-0.28189842, -0.02605946])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9347734580019974
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-3.97818103,  2.35753828]), 'currentState': array([0.40761188, 2.63865976]), 'targetState': array([0.07437966, 0.45141199]), 'effectorPosition': array([-0.07739026,  0.49159473])}
episode index:3664
target Thresh 1.998817605116621
current state at start:  [-1.69928207 -2.0188753 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.69928207, -2.0188753 ]), 'currentState': array([4.17148475, 3.77876011]), 'targetState': array([-0.22544036,  0.06480585]), 'effectorPosition': array([-0.61102597,  0.13812684])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9347885266355576
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.69928207, -2.0188753 ]), 'currentState': array([4.52431123, 3.27876011]), 'targetState': array([-0.22544036,  0.06480585]), 'effectorPosition': array([-0.13608259,  0.0163389 ])}
episode index:3665
target Thresh 1.9988199675431737
current state at start:  [-0.68283464 -1.68123992]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.68283464, -1.68123992]), 'currentState': array([5.10035066, 4.11506303]), 'targetState': array([-0.83305252, -0.54580587]), 'effectorPosition': array([-0.59986087, -0.71784399])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9348035870483683
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.68283464, -1.68123992]), 'currentState': array([4.62323894, 4.30049804]), 'targetState': array([-0.83305252, -0.54580587]), 'effectorPosition': array([-0.96611501, -0.51568994])}
episode index:3666
target Thresh 1.9988223252495951
current state at start:  [1.59868912 1.8743706 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.59868912, 1.8743706 ]), 'currentState': array([1.17756884, 2.3743706 ]), 'targetState': array([-0.00036843,  0.00192076]), 'effectorPosition': array([-0.53381097,  0.52474985])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9348159394925875
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([1.59868912, 1.8743706 ]), 'currentState': array([1.22407048, 3.29126492]), 'targetState': array([-0.00036843,  0.00192076]), 'effectorPosition': array([ 0.14403953, -0.04015731])}
episode index:3667
target Thresh 1.9988246782453158
current state at start:  [0.56701229 2.27207255]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.56701229, 2.27207255]), 'currentState': array([0.96380354, 2.19797061]), 'targetState': array([-0.87070429,  0.93451001]), 'effectorPosition': array([-0.42939634,  0.80118691])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9348309842200976
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.56701229, 2.27207255]), 'currentState': array([1.37879212, 1.73931219]), 'targetState': array([-0.87070429,  0.93451001]), 'effectorPosition': array([-0.8088975 ,  1.00510994])}
episode index:3668
target Thresh 1.998827026539748
current state at start:  [-1.82240651 -1.97366436]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.82240651, -1.97366436]), 'currentState': array([4.85199117, 4.6908349 ]), 'targetState': array([-0.2642016 , -0.98772214]), 'effectorPosition': array([-0.85389123, -1.10804555])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9345761924555241
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([-1.82240651, -1.97366436]), 'currentState': array([3.5180504 , 5.13030762]), 'targetState': array([-0.2642016 , -0.98772214]), 'effectorPosition': array([-1.64339946,  0.33310122])}
episode index:3669
target Thresh 1.9988293701422848
current state at start:  [ 4.05453116 -1.99632375]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.05453116, -1.99632375]), 'currentState': array([3.63584262, 4.56833007]), 'targetState': array([-1.21981736,  0.2358506 ]), 'effectorPosition': array([-1.22340203,  0.46493567])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9345940191060812
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.05453116, -1.99632375]), 'currentState': array([3.63584262, 4.56833007]), 'targetState': array([-1.21981736,  0.2358506 ]), 'effectorPosition': array([-1.22340203,  0.46493567])}
episode index:3670
target Thresh 1.9988317090623005
current state at start:  [-0.19925275  1.69024379]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.19925275,  1.69024379]), 'currentState': array([5.58393256, 2.15683673]), 'targetState': array([0.785787  , 0.11382824]), 'effectorPosition': array([0.87829402, 0.34995235])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9346091119910972
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.19925275,  1.69024379]), 'currentState': array([5.34930011, 2.43382035]), 'targetState': array([0.785787  , 0.11382824]), 'effectorPosition': array([0.66551691, 0.19355381])}
episode index:3671
target Thresh 1.998834043309151
current state at start:  [-3.17712757  1.75328133]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.17712757,  1.75328133]), 'currentState': array([2.60605774, 2.22710344]), 'targetState': array([-0.823973  , -0.48753585]), 'effectorPosition': array([-0.73951696, -0.48241476])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9346269199671345
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.17712757,  1.75328133]), 'currentState': array([2.60605774, 2.22710344]), 'targetState': array([-0.823973  , -0.48753585]), 'effectorPosition': array([-0.73951696, -0.48241476])}
episode index:3672
target Thresh 1.9988363728921732
current state at start:  [-2.86430196  2.31337923]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.86430196,  2.31337923]), 'currentState': array([2.96029415, 2.81337923]), 'targetState': array([-0.22108343,  0.06883234]), 'effectorPosition': array([-0.11062772, -0.30744428])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9346419956763728
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.86430196,  2.31337923]), 'currentState': array([2.56270417, 3.16654015]), 'targetState': array([-0.22108343,  0.06883234]), 'effectorPosition': array([0.01338673, 0.0210509 ])}
episode index:3673
target Thresh 1.9988386978206854
current state at start:  [-3.66188753  2.66858413]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.66188753,  2.66858413]), 'currentState': array([3.10983148, 2.30133178]), 'targetState': array([ 0.34015714, -0.94867923]), 'effectorPosition': array([-0.35621594, -0.73387541])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9346543685681322
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-3.66188753,  2.66858413]), 'currentState': array([4.04653227, 1.99422525]), 'targetState': array([ 0.34015714, -0.94867923]), 'effectorPosition': array([ 0.35302496, -1.02644798])}
episode index:3674
target Thresh 1.9988410181039873
current state at start:  [1.82140887 2.15033628]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.82140887, 2.15033628]), 'currentState': array([1.32140887, 2.5907938 ]), 'targetState': array([-0.01597337,  0.00694761]), 'effectorPosition': array([-0.47067547,  0.27249074])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.934669428603896
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.82140887, 2.15033628]), 'currentState': array([1.11044018, 3.02674593]), 'targetState': array([-0.01597337,  0.00694761]), 'effectorPosition': array([-0.09973782,  0.05681237])}
episode index:3675
target Thresh 1.99884333375136
current state at start:  [ 1.64302201 -2.18478304]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.64302201, -2.18478304]), 'currentState': array([1.35358594, 3.59840226]), 'targetState': array([-0.1283435 ,  0.27803521]), 'effectorPosition': array([0.45281972, 0.00506927])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9346791210879537
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 1.64302201, -2.18478304]), 'currentState': array([1.14395138, 2.7000781 ]), 'targetState': array([-0.1283435 ,  0.27803521]), 'effectorPosition': array([-0.34926917,  0.26419692])}
episode index:3676
target Thresh 1.9988456447720662
current state at start:  [ 2.92070396 -2.38432916]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.92070396, -2.38432916]), 'currentState': array([2.73786972, 3.39885615]), 'targetState': array([-0.17604412, -0.16446366]), 'effectorPosition': array([0.06968914, 0.24690829])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9346941662005215
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 2.92070396, -2.38432916]), 'currentState': array([2.34968261, 2.89885615]), 'targetState': array([-0.17604412, -0.16446366]), 'effectorPosition': array([-0.19165741, -0.14798551])}
episode index:3677
target Thresh 1.99884795117535
current state at start:  [-1.64487936  2.54574593]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.64487936,  2.54574593]), 'currentState': array([4.16767804, 2.04574593]), 'targetState': array([ 0.13715252, -0.73888257]), 'effectorPosition': array([ 0.47939678, -0.92498188])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9347092031319514
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.64487936,  2.54574593]), 'currentState': array([3.74803229, 2.30629267]), 'targetState': array([ 0.13715252, -0.73888257]), 'effectorPosition': array([ 0.15224314, -0.79681333])}
episode index:3678
target Thresh 1.998850252970437
current state at start:  [-3.28146563  2.00574536]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.28146563,  2.00574536]), 'currentState': array([2.50195631, 2.37597144]), 'targetState': array([-0.94857084,  0.03230653]), 'effectorPosition': array([-0.63752912, -0.389426  ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9347242318889146
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.28146563,  2.00574536]), 'currentState': array([2.00195631, 2.18940023]), 'targetState': array([-0.94857084,  0.03230653]), 'effectorPosition': array([-0.91570075,  0.04117586])}
episode index:3679
target Thresh 1.9988525501665342
current state at start:  [ 0.55739483 -2.44673404]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.55739483, -2.44673404]), 'currentState': array([0.05739483, 3.45331049]), 'targetState': array([-0.29024683, -1.32844858]), 'effectorPosition': array([ 0.06570552, -0.30342468])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.934736562260684
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 0.55739483, -2.44673404]), 'currentState': array([5.52358386, 4.40409726]), 'targetState': array([-0.29024683, -1.32844858]), 'effectorPosition': array([-0.15107649, -1.17060378])}
episode index:3680
target Thresh 1.9988548427728308
current state at start:  [ 2.4851235  -2.45714451]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.4851235 , -2.45714451]), 'currentState': array([2.04255439, 3.39053165]), 'targetState': array([0.64220821, 0.10465733]), 'effectorPosition': array([0.20545555, 0.1394248 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9347515754195374
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 2.4851235 , -2.45714451]), 'currentState': array([1.59189369, 3.71066615]), 'targetState': array([0.64220821, 0.10465733]), 'effectorPosition': array([0.53540719, 0.16893185])}
episode index:3681
target Thresh 1.9988571307984966
current state at start:  [0.17373016 1.88146598]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.17373016, 1.88146598]), 'currentState': array([0.5911906 , 2.38146598]), 'targetState': array([-0.24697996,  1.09918459]), 'effectorPosition': array([-0.15548652,  0.72548361])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9347665804234973
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.17373016, 1.88146598]), 'currentState': array([0.62888981, 1.98806036]), 'targetState': array([-0.24697996,  1.09918459]), 'effectorPosition': array([-0.056822  ,  1.08915093])}
episode index:3682
target Thresh 1.9988594142526843
current state at start:  [-1.51308554 -2.55537845]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.51308554, -2.55537845]), 'currentState': array([4.27009976, 4.08581465]), 'targetState': array([-1.07813761,  0.21213304]), 'effectorPosition': array([-0.90913033, -0.02711992])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9347815772792063
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.51308554, -2.55537845]), 'currentState': array([3.87826175, 4.33984303]), 'targetState': array([-1.07813761,  0.21213304]), 'effectorPosition': array([-1.09684051,  0.26261199])}
episode index:3683
target Thresh 1.9988616931445276
current state at start:  [-0.38151485 -2.65378375]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.38151485, -2.65378375]), 'currentState': array([5.93075681, 3.15037765]), 'targetState': array([-0.03417468, -0.01853632]), 'effectorPosition': array([-0.00299613, -0.00825826])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9347992804341251
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.38151485, -2.65378375]), 'currentState': array([5.93075681, 3.15037765]), 'targetState': array([-0.03417468, -0.01853632]), 'effectorPosition': array([-0.00299613, -0.00825826])}
episode index:3684
target Thresh 1.9988639674831417
current state at start:  [-0.60512468  1.75148755]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.60512468,  1.75148755]), 'currentState': array([5.24000008, 2.15311199]), 'targetState': array([ 0.84504987, -0.10069222]), 'effectorPosition': array([0.94819785, 0.03165384])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9348169739808186
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.60512468,  1.75148755]), 'currentState': array([5.24000008, 2.15311199]), 'targetState': array([ 0.84504987, -0.10069222]), 'effectorPosition': array([0.94819785, 0.03165384])}
episode index:3685
target Thresh 1.9988662372776245
current state at start:  [ 1.4456477  -1.65610475]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.4456477 , -1.65610475]), 'currentState': array([1.06598498, 4.16737288]), 'targetState': array([0.52645714, 0.22250048]), 'effectorPosition': array([0.98136304, 0.00792837])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.93483194495912
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.4456477 , -1.65610475]), 'currentState': array([1.4701163 , 3.74198547]), 'targetState': array([0.52645714, 0.22250048]), 'effectorPosition': array([0.57968349, 0.11721582])}
episode index:3686
target Thresh 1.9988685025370545
current state at start:  [ 1.96163001 -1.62273923]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.96163001, -1.62273923]), 'currentState': array([2.29656302, 4.19726756]), 'targetState': array([-0.26327446,  0.51164795]), 'effectorPosition': array([0.31418708, 0.95708173])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.9348337481065141
{'reset': False, 'endBeforeDone': False, 'stepCount': 7, 'initial state': array([ 1.96163001, -1.62273923]), 'currentState': array([0.73017468, 2.77836808]), 'targetState': array([-0.26327446,  0.51164795]), 'effectorPosition': array([-0.188368  ,  0.30822954])}
episode index:3687
target Thresh 1.9988707632704934
current state at start:  [-3.97871737  2.60901019]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.97871737,  2.60901019]), 'currentState': array([1.80446794, 3.06249449]), 'targetState': array([-0.14849393,  0.06633239]), 'effectorPosition': array([-0.07759226, -0.0152545 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9348514179145112
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.97871737,  2.60901019]), 'currentState': array([1.80446794, 3.06249449]), 'targetState': array([-0.14849393,  0.06633239]), 'effectorPosition': array([-0.07759226, -0.0152545 ])}
episode index:3688
target Thresh 1.998873019486984
current state at start:  [-2.78306004  2.50973323]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.78306004,  2.50973323]), 'currentState': array([3.84374945, 2.43535196]), 'targetState': array([ 0.16154809, -0.58669015]), 'effectorPosition': array([ 0.2365407 , -0.64994968])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9348690781427805
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.78306004,  2.50973323]), 'currentState': array([3.84374945, 2.43535196]), 'targetState': array([ 0.16154809, -0.58669015]), 'effectorPosition': array([ 0.2365407 , -0.64994968])}
episode index:3689
target Thresh 1.9988752711955509
current state at start:  [-2.33643301  3.03043545]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.33643301,  3.03043545]), 'currentState': array([3.48579781, 3.53043545]), 'targetState': array([-0.34197768,  0.71673406]), 'effectorPosition': array([-0.19820561,  0.33168923])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.93488401877201
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.33643301,  3.03043545]), 'currentState': array([3.10159426, 4.03043545]), 'targetState': array([-0.34197768,  0.71673406]), 'effectorPosition': array([-0.33834929,  0.79050496])}
episode index:3690
target Thresh 1.998877518405201
current state at start:  [-2.20329939  2.42862033]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.20329939,  2.42862033]), 'currentState': array([3.64472058, 1.94366022]), 'targetState': array([-0.16585711, -1.14645288]), 'effectorPosition': array([-0.10789979, -1.12240348])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9349016605984062
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.20329939,  2.42862033]), 'currentState': array([3.64472058, 1.94366022]), 'targetState': array([-0.16585711, -1.14645288]), 'effectorPosition': array([-0.10789979, -1.12240348])}
episode index:3691
target Thresh 1.9988797611249234
current state at start:  [ 1.14414651 -2.6569811 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.14414651, -2.6569811 ]), 'currentState': array([1.29490101, 3.14857907]), 'targetState': array([-0.10933061, -0.16788316]), 'effectorPosition': array([ 0.0067288 , -0.00187966])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9349192928680166
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.14414651, -2.6569811 ]), 'currentState': array([1.29490101, 3.14857907]), 'targetState': array([-0.10933061, -0.16788316]), 'effectorPosition': array([ 0.0067288 , -0.00187966])}
episode index:3692
target Thresh 1.9988819993636886
current state at start:  [ 0.97956469 -2.23334433]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.97956469, -2.23334433]), 'currentState': array([0.54931697, 4.23922739]), 'targetState': array([ 0.92303949, -0.80306335]), 'effectorPosition': array([ 0.92896313, -0.47499677])}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9349159961990644
{'reset': False, 'endBeforeDone': False, 'stepCount': 9, 'initial state': array([ 0.97956469, -2.23334433]), 'currentState': array([0.40591405, 4.42933871]), 'targetState': array([ 0.92303949, -0.80306335]), 'effectorPosition': array([ 1.04129676, -0.59760303])}
episode index:3693
target Thresh 1.99888423313045
current state at start:  [-0.20332397  3.00743704]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.20332397,  3.00743704]), 'currentState': array([5.87425214, 3.29781057]), 'targetState': array([-0.31836838, -0.03287501]), 'effectorPosition': array([-0.05069154, -0.1475968 ])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9349282279272185
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-0.20332397,  3.00743704]), 'currentState': array([5.47928785, 3.32002585]), 'targetState': array([-0.31836838, -0.03287501]), 'effectorPosition': array([-0.11678583, -0.13459231])}
episode index:3694
target Thresh 1.9988864624341423
current state at start:  [1.00156367 2.76889108]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.00156367, 2.76889108]), 'currentState': array([1.47667542, 2.509337  ]), 'targetState': array([-0.5629867 ,  0.20049662]), 'effectorPosition': array([-0.57018317,  0.24798803])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9349458386909729
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.00156367, 2.76889108]), 'currentState': array([1.47667542, 2.509337  ]), 'targetState': array([-0.5629867 ,  0.20049662]), 'effectorPosition': array([-0.57018317,  0.24798803])}
episode index:3695
target Thresh 1.9988886872836829
current state at start:  [-1.1606034   1.89035386]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.1606034 ,  1.89035386]), 'currentState': array([4.88783045, 2.29614723]), 'targetState': array([ 0.85535907, -0.05918701]), 'effectorPosition': array([ 0.79553194, -0.20083038])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9349634399250933
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.1606034 ,  1.89035386]), 'currentState': array([4.88783045, 2.29614723]), 'targetState': array([ 0.85535907, -0.05918701]), 'effectorPosition': array([ 0.79553194, -0.20083038])}
episode index:3696
target Thresh 1.998890907687971
current state at start:  [-0.11655209 -2.65465775]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.11655209, -2.65465775]), 'currentState': array([0.28996935, 3.12852756]), 'targetState': array([-0.33053137,  0.46822562]), 'effectorPosition': array([-0.00365372,  0.01254371])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9349783267414511
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.11655209, -2.65465775]), 'currentState': array([0.74101034, 2.62852756]), 'targetState': array([-0.33053137,  0.46822562]), 'effectorPosition': array([-0.23634585,  0.44905727])}
episode index:3697
target Thresh 1.9988931236558884
current state at start:  [0.3629392  1.91526835]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.3629392 , 1.91526835]), 'currentState': array([0.20596883, 2.41067063]), 'targetState': array([-0.00205711,  0.26967678]), 'effectorPosition': array([0.1135159 , 0.70568811])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9349932055065291
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.3629392 , 1.91526835]), 'currentState': array([0.01520722, 2.84644582]), 'targetState': array([-0.00205711,  0.26967678]), 'effectorPosition': array([0.03881225, 0.29150425])}
episode index:3698
target Thresh 1.998895335196299
current state at start:  [0.01622043 2.61758092]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.01622043, 2.61758092]), 'currentState': array([0.44448785, 3.07439437]), 'targetState': array([-0.55072099,  0.32356536]), 'effectorPosition': array([-0.02683557,  0.06159352])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9350080762268571
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.01622043, 2.61758092]), 'currentState': array([0.94448785, 2.6479783 ]), 'targetState': array([-0.55072099,  0.32356536]), 'effectorPosition': array([-0.31390892,  0.37444493])}
episode index:3699
target Thresh 1.998897542318049
current state at start:  [-3.56030587  1.86568277]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.56030587,  1.86568277]), 'currentState': array([3.20637607, 2.01874967]), 'targetState': array([-0.49396208, -1.01748546]), 'effectorPosition': array([-0.50733838, -0.93614333])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9350256416116607
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.56030587,  1.86568277]), 'currentState': array([3.20637607, 2.01874967]), 'targetState': array([-0.49396208, -1.01748546]), 'effectorPosition': array([-0.50733838, -0.93614333])}
episode index:3700
target Thresh 1.9988997450299668
current state at start:  [-4.27848157  2.59859443]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.27848157,  2.59859443]), 'currentState': array([2.30124611, 2.94067258]), 'targetState': array([ 1.72441363e-04, -3.01483998e-01]), 'effectorPosition': array([-0.16207722, -0.11817034])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.935043197504227
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.27848157,  2.59859443]), 'currentState': array([2.30124611, 2.94067258]), 'targetState': array([ 1.72441363e-04, -3.01483998e-01]), 'effectorPosition': array([-0.16207722, -0.11817034])}
episode index:3701
target Thresh 1.9989019433408632
current state at start:  [-3.67038084  2.09681061]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.67038084,  2.09681061]), 'currentState': array([3.11280446, 2.21441291]), 'targetState': array([-0.57492115, -0.77773397]), 'effectorPosition': array([-0.4227673 , -0.78808823])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9350607439122486
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.67038084,  2.09681061]), 'currentState': array([3.11280446, 2.21441291]), 'targetState': array([-0.57492115, -0.77773397]), 'effectorPosition': array([-0.4227673 , -0.78808823])}
episode index:3702
target Thresh 1.9989041372595315
current state at start:  [-3.45231719  2.41146575]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.45231719,  2.41146575]), 'currentState': array([3.33086812, 2.1800231 ]), 'targetState': array([ 0.42405576, -1.25797996]), 'effectorPosition': array([-0.26582902, -0.88592771])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9350729068223453
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-3.45231719,  2.41146575]), 'currentState': array([4.28955027, 1.69711786]), 'targetState': array([ 0.42405576, -1.25797996]), 'effectorPosition': array([ 0.54600914, -1.2041189 ])}
episode index:3703
target Thresh 1.9989063267947473
current state at start:  [ 3.74965736 -2.8908781 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.74965736, -2.8908781 ]), 'currentState': array([3.24965736, 3.86497627]), 'targetState': array([-1.02120587,  0.2201173 ]), 'effectorPosition': array([-0.3203604 ,  0.63105354])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9350797975089483
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([ 3.74965736, -2.8908781 ]), 'currentState': array([2.09217041, 2.0631903 ]), 'targetState': array([-1.02120587,  0.2201173 ]), 'effectorPosition': array([-1.02673817,  0.0183057 ])}
episode index:3704
target Thresh 1.998908511955269
current state at start:  [-0.73284094  2.10056248]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.73284094,  2.10056248]), 'currentState': array([5.7002839 , 2.33600257]), 'targetState': array([0.83061489, 0.29212817]), 'effectorPosition': array([0.65357239, 0.4329799 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9350973198308082
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.73284094,  2.10056248]), 'currentState': array([5.7002839 , 2.33600257]), 'targetState': array([0.83061489, 0.29212817]), 'effectorPosition': array([0.65357239, 0.4329799 ])}
episode index:3705
target Thresh 1.998910692749837
current state at start:  [-0.38182106 -2.09953161]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.38182106, -2.09953161]), 'currentState': array([5.43177836, 4.31610669]), 'targetState': array([-0.36034249, -1.33294262]), 'effectorPosition': array([-0.28932798, -1.06972262])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9351121343694399
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.38182106, -2.09953161]), 'currentState': array([5.09115784, 4.81610669]), 'targetState': array([-0.36034249, -1.33294262]), 'effectorPosition': array([-0.51606707, -1.3931039 ])}
episode index:3706
target Thresh 1.9989128691871745
current state at start:  [-0.27761756  1.76190184]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.27761756,  1.76190184]), 'currentState': array([0.07571901, 1.86605891]), 'targetState': array([0.87078757, 0.93889559]), 'effectorPosition': array([0.63460426, 1.00761862])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9351296385144711
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.27761756,  1.76190184]), 'currentState': array([0.07571901, 1.86605891]), 'targetState': array([0.87078757, 0.93889559]), 'effectorPosition': array([0.63460426, 1.00761862])}
episode index:3707
target Thresh 1.9989150412759873
current state at start:  [0.66473002 1.65133702]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.66473002, 1.65133702]), 'currentState': array([1.09087921, 2.15133702]), 'targetState': array([-0.69466704,  0.79566631]), 'effectorPosition': array([-0.53323606,  0.78657933])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9351471332182159
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.66473002, 1.65133702]), 'currentState': array([1.09087921, 2.15133702]), 'targetState': array([-0.69466704,  0.79566631]), 'effectorPosition': array([-0.53323606,  0.78657933])}
episode index:3708
target Thresh 1.9989172090249636
current state at start:  [-2.36188389  2.29660453]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.36188389,  2.29660453]), 'currentState': array([3.42130142, 2.79660453]), 'targetState': array([0.02092152, 0.04746901]), 'effectorPosition': array([ 0.03673418, -0.34130875])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9351619223437972
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.36188389,  2.29660453]), 'currentState': array([3.13196358, 3.29660453]), 'targetState': array([0.02092152, 0.04746901]), 'effectorPosition': array([-0.01050312,  0.15450013])}
episode index:3709
target Thresh 1.9989193724427747
current state at start:  [ 3.62261184 -1.97451109]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.62261184, -1.97451109]), 'currentState': array([3.91125731, 3.85377943]), 'targetState': array([-0.06177445, -0.16987084]), 'effectorPosition': array([-0.62931641,  0.30015256])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9351687778930307
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([ 3.62261184, -1.97451109]), 'currentState': array([3.85250549, 3.12777881]), 'targetState': array([-0.06177445, -0.16987084]), 'effectorPosition': array([ 0.0089413 , -0.01052959])}
episode index:3710
target Thresh 1.9989215315380742
current state at start:  [2.0010303  1.77817269]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.0010303 , 1.77817269]), 'currentState': array([2.43134455, 1.47839063]), 'targetState': array([-1.35376561, -0.2544381 ]), 'effectorPosition': array([-1.47740262, -0.04277863])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9351862479070719
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.0010303 , 1.77817269]), 'currentState': array([2.43134455, 1.47839063]), 'targetState': array([-1.35376561, -0.2544381 ]), 'effectorPosition': array([-1.47740262, -0.04277863])}
episode index:3711
target Thresh 1.9989236863194983
current state at start:  [0.85686483 2.20271105]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.85686483, 2.20271105]), 'currentState': array([0.573644  , 2.65548715]), 'targetState': array([-0.0451643 ,  0.26398411]), 'effectorPosition': array([-0.15624198,  0.45526961])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9352037085083901
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.85686483, 2.20271105]), 'currentState': array([0.573644  , 2.65548715]), 'targetState': array([-0.0451643 ,  0.26398411]), 'effectorPosition': array([-0.15624198,  0.45526961])}
episode index:3712
target Thresh 1.9989258367956664
current state at start:  [ 0.88674855 -1.60832745]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.88674855, -1.60832745]), 'currentState': array([0.38674855, 4.17485785]), 'targetState': array([ 0.52472638, -0.68496875]), 'effectorPosition': array([ 0.77592845, -0.61147471])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9352105472645148
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([ 0.88674855, -1.60832745]), 'currentState': array([0.42425717, 4.07330282]), 'targetState': array([ 0.52472638, -0.68496875]), 'effectorPosition': array([ 0.69816441, -0.56536894])}
episode index:3713
target Thresh 1.9989279829751803
current state at start:  [-2.02536357 -1.65989935]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.02536357, -1.65989935]), 'currentState': array([3.75782174, 4.58055722]), 'targetState': array([-1.37333695,  0.33707492]), 'effectorPosition': array([-1.2817388 ,  0.30699379])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9352279919206095
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.02536357, -1.65989935]), 'currentState': array([3.75782174, 4.58055722]), 'targetState': array([-1.37333695,  0.33707492]), 'effectorPosition': array([-1.2817388 ,  0.30699379])}
episode index:3714
target Thresh 1.9989301248666245
current state at start:  [ 0.23396876 -2.33107426]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.23396876, -2.33107426]), 'currentState': array([0.04742343, 3.45211105]), 'targetState': array([1.4100997 , 0.07087019]), 'effectorPosition': array([ 0.06225584, -0.30294159])}
done in step count: 35
reward sum = 0.7034476949995692
running average episode reward sum: 0.9351656015311288
{'reset': False, 'endBeforeDone': False, 'stepCount': 36, 'initial state': array([ 0.23396876, -2.33107426]), 'currentState': array([5.56838729, 1.78385251]), 'targetState': array([1.4100997 , 0.07087019]), 'effectorPosition': array([1.23617906, 0.22128127])}
episode index:3715
target Thresh 1.9989322624785668
current state at start:  [-0.18278426  2.44182442]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.18278426,  2.44182442]), 'currentState': array([0.27717432, 1.97612257]), 'targetState': array([0.40529732, 0.90697649]), 'effectorPosition': array([0.33109706, 1.04963687])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9351830488934724
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.18278426,  2.44182442]), 'currentState': array([0.27717432, 1.97612257]), 'targetState': array([0.40529732, 0.90697649]), 'effectorPosition': array([0.33109706, 1.04963687])}
episode index:3716
target Thresh 1.9989343958195576
current state at start:  [ 4.03146166 -2.9340062 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.03146166, -2.9340062 ]), 'currentState': array([4.48855388, 2.91497671]), 'targetState': array([ 0.01309292, -0.00315689]), 'effectorPosition': array([ 0.21340096, -0.07480252])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9352004868679428
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.03146166, -2.9340062 ]), 'currentState': array([4.48855388, 2.91497671]), 'targetState': array([ 0.01309292, -0.00315689]), 'effectorPosition': array([ 0.21340096, -0.07480252])}
episode index:3717
target Thresh 1.9989365248981301
current state at start:  [-3.00362526  1.81677114]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.00362526,  1.81677114]), 'currentState': array([2.83578633, 2.29376974]), 'targetState': array([-0.43443254, -0.70312352]), 'effectorPosition': array([-0.54843239, -0.61317824])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.935217915462115
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.00362526,  1.81677114]), 'currentState': array([2.83578633, 2.29376974]), 'targetState': array([-0.43443254, -0.70312352]), 'effectorPosition': array([-0.54843239, -0.61317824])}
episode index:3718
target Thresh 1.9989386497228008
current state at start:  [ 3.89436715 -1.71096296]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.89436715, -1.71096296]), 'currentState': array([3.41986185, 4.63907623]), 'targetState': array([-0.99340906,  0.7862136 ]), 'effectorPosition': array([-1.16505683,  0.70437801])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9352353346835556
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.89436715, -1.71096296]), 'currentState': array([3.41986185, 4.63907623]), 'targetState': array([-0.99340906,  0.7862136 ]), 'effectorPosition': array([-1.16505683,  0.70437801])}
episode index:3719
target Thresh 1.9989407703020692
current state at start:  [ 4.12102675 -2.1610948 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.12102675, -2.1610948 ]), 'currentState': array([3.74585759, 3.79187678]), 'targetState': array([-0.58759298,  0.43589461]), 'effectorPosition': array([-0.51191783,  0.38225189])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9352527445398235
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.12102675, -2.1610948 ]), 'currentState': array([3.74585759, 3.79187678]), 'targetState': array([-0.58759298,  0.43589461]), 'effectorPosition': array([-0.51191783,  0.38225189])}
episode index:3720
target Thresh 1.9989428866444172
current state at start:  [ 0.41041037 -1.75838503]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.41041037, -1.75838503]), 'currentState': array([0.19206166, 4.33982441]), 'targetState': array([ 0.71827959, -1.0256061 ]), 'effectorPosition': array([ 0.80208845, -0.79287048])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9352701450384691
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.41041037, -1.75838503]), 'currentState': array([0.19206166, 4.33982441]), 'targetState': array([ 0.71827959, -1.0256061 ]), 'effectorPosition': array([ 0.80208845, -0.79287048])}
episode index:3721
target Thresh 1.9989449987583106
current state at start:  [ 3.42474071 -2.1811669 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.42474071, -2.1811669 ]), 'currentState': array([3.87800462, 3.65002852]), 'targetState': array([-0.69285945, -0.28843798]), 'effectorPosition': array([-0.42067568,  0.27571351])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.9352743685486414
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([ 3.42474071, -2.1811669 ]), 'currentState': array([2.58696805, 2.25661958]), 'targetState': array([-0.69285945, -0.28843798]), 'effectorPosition': array([-0.71927561, -0.46478158])}
episode index:3722
target Thresh 1.9989471066521973
current state at start:  [-2.07548653 -2.06611117]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.07548653, -2.06611117]), 'currentState': array([3.72854148, 4.154729  ]), 'targetState': array([-0.75310039,  0.85947367]), 'effectorPosition': array([-0.86191902,  0.44574802])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9352890678855877
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.07548653, -2.06611117]), 'currentState': array([3.22854148, 4.46787455]), 'targetState': array([-0.75310039,  0.85947367]), 'effectorPosition': array([-0.83930789,  0.90077289])}
episode index:3723
target Thresh 1.9989492103345095
current state at start:  [-0.2192314  2.7764298]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.2192314,  2.7764298]), 'currentState': array([5.5659428 , 2.29089257]), 'targetState': array([0.9734767 , 0.35237671]), 'effectorPosition': array([0.75076738, 0.34268686])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9353064446127936
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.2192314,  2.7764298]), 'currentState': array([5.5659428 , 2.29089257]), 'targetState': array([0.9734767 , 0.35237671]), 'effectorPosition': array([0.75076738, 0.34268686])}
episode index:3724
target Thresh 1.9989513098136613
current state at start:  [ 1.11065198 -2.66104144]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.11065198, -2.66104144]), 'currentState': array([1.38672502, 3.21225122]), 'targetState': array([ 0.24856131, -0.09018598]), 'effectorPosition': array([ 0.06986384, -0.01046901])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.935323812010213
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.11065198, -2.66104144]), 'currentState': array([1.38672502, 3.21225122]), 'targetState': array([ 0.24856131, -0.09018598]), 'effectorPosition': array([ 0.06986384, -0.01046901])}
episode index:3725
target Thresh 1.9989534050980513
current state at start:  [-2.13208969  2.13913683]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.13208969,  2.13913683]), 'currentState': array([4.59851973, 2.39345927]), 'targetState': array([ 0.98924353, -0.27504118]), 'effectorPosition': array([ 0.64552431, -0.34260542])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9353384862420943
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.13208969,  2.13913683]), 'currentState': array([5.05319079, 2.07759029]), 'targetState': array([ 0.98924353, -0.27504118]), 'effectorPosition': array([ 0.99603038, -0.19279548])}
episode index:3726
target Thresh 1.99895549619606
current state at start:  [-0.28647526 -2.29742124]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.28647526, -2.29742124]), 'currentState': array([0.17482681, 3.48576407]), 'targetState': array([-0.07853164,  0.10864422]), 'effectorPosition': array([ 0.11644017, -0.32207294])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9353531525994212
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.28647526, -2.29742124]), 'currentState': array([0.62456078, 2.98576407]), 'targetState': array([-0.07853164,  0.10864422]), 'effectorPosition': array([-0.08092172,  0.13298544])}
episode index:3727
target Thresh 1.9989575831160524
current state at start:  [ 2.9936776  -2.76093322]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.9936776 , -2.76093322]), 'currentState': array([2.4936776 , 3.02225209]), 'targetState': array([-1.01281389, -0.27565169]), 'effectorPosition': array([-0.07752542, -0.0906371 ])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9353651555091317
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 2.9936776 , -2.76093322]), 'currentState': array([2.44820975, 2.02225209]), 'targetState': array([-1.01281389, -0.27565169]), 'effectorPosition': array([-1.00866235, -0.3317355 ])}
episode index:3728
target Thresh 1.9989596658663757
current state at start:  [-2.72232246  2.85140508]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.72232246,  2.85140508]), 'currentState': array([3.06086285, 3.34583497]), 'targetState': array([-0.77596015,  0.35674532]), 'effectorPosition': array([-0.0043611 ,  0.20384085])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9353745236626557
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-2.72232246,  2.85140508]), 'currentState': array([1.56086285, 2.15929654]), 'targetState': array([-0.77596015,  0.35674532]), 'effectorPosition': array([-0.82731394,  0.45312617])}
episode index:3729
target Thresh 1.9989617444553611
current state at start:  [-1.64557468  1.87806276]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.64557468,  1.87806276]), 'currentState': array([4.13761063, 2.3274037 ]), 'targetState': array([ 0.02852486, -0.64749834]), 'effectorPosition': array([ 0.43986583, -0.65848408])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.935389168562478
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.64557468,  1.87806276]), 'currentState': array([3.63761063, 2.46806727]), 'targetState': array([ 0.02852486, -0.64749834]), 'effectorPosition': array([ 0.1048022 , -0.65250389])}
episode index:3730
target Thresh 1.9989638188913228
current state at start:  [ 4.34261738 -2.42865785]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.34261738, -2.42865785]), 'currentState': array([4.55863495, 3.39427196]), 'targetState': array([-0.19052956, -0.03867582]), 'effectorPosition': array([-0.25191295,  0.00690777])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9354064858584945
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.34261738, -2.42865785]), 'currentState': array([4.55863495, 3.39427196]), 'targetState': array([-0.19052956, -0.03867582]), 'effectorPosition': array([-0.25191295,  0.00690777])}
episode index:3731
target Thresh 1.998965889182559
current state at start:  [ 3.61322186 -1.97930815]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.61322186, -1.97930815]), 'currentState': array([3.11322186, 4.01618118]), 'targetState': array([-0.32023015,  0.93875917]), 'effectorPosition': array([-0.33677761,  0.77714579])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9354237938740737
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.61322186, -1.97930815]), 'currentState': array([3.11322186, 4.01618118]), 'targetState': array([-0.32023015,  0.93875917]), 'effectorPosition': array([-0.33677761,  0.77714579])}
episode index:3732
target Thresh 1.9989679553373503
current state at start:  [-3.50053948  2.15113373]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.50053948,  2.15113373]), 'currentState': array([2.28264583, 2.5523972 ]), 'targetState': array([-0.29688001, -0.38402075]), 'effectorPosition': array([-0.5308885 , -0.23533241])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9354384138060655
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.50053948,  2.15113373]), 'currentState': array([2.6973348 , 2.66445894]), 'targetState': array([-0.29688001, -0.38402075]), 'effectorPosition': array([-0.29821744, -0.366656  ])}
episode index:3733
target Thresh 1.9989700173639617
current state at start:  [-1.09618639 -2.68440961]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.09618639, -2.68440961]), 'currentState': array([4.86437191, 3.13792346]), 'targetState': array([0.00358387, 0.00585835]), 'effectorPosition': array([0.00362791, 0.00054886])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9354557040005471
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.09618639, -2.68440961]), 'currentState': array([4.86437191, 3.13792346]), 'targetState': array([0.00358387, 0.00585835]), 'effectorPosition': array([0.00362791, 0.00054886])}
episode index:3734
target Thresh 1.998972075270641
current state at start:  [ 4.6201693  -3.11175347]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.6201693 , -3.11175347]), 'currentState': array([4.91703822, 2.76346269]), 'targetState': array([0.07699833, 0.21235504]), 'effectorPosition': array([0.37583559, 0.00585759])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9354703075603862
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 4.6201693 , -3.11175347]), 'currentState': array([5.01086701, 3.04808104]), 'targetState': array([0.07699833, 0.21235504]), 'effectorPosition': array([0.09053159, 0.02328266])}
episode index:3735
target Thresh 1.9989741290656202
current state at start:  [ 1.70735865 -2.48142152]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.70735865, -2.48142152]), 'currentState': array([1.60265203, 3.31598226]), 'targetState': array([-0.00533496,  0.00853621]), 'effectorPosition': array([0.17293592, 0.02068593])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9354875799620028
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.70735865, -2.48142152]), 'currentState': array([1.60265203, 3.31598226]), 'targetState': array([-0.00533496,  0.00853621]), 'effectorPosition': array([0.17293592, 0.02068593])}
episode index:3736
target Thresh 1.9989761787571143
current state at start:  [-0.23227551  2.46471113]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.23227551,  2.46471113]), 'currentState': array([0.26772449, 2.10185856]), 'targetState': array([-0.14642978,  1.35838006]), 'effectorPosition': array([0.24786508, 0.96211423])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.935502167176356
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.23227551,  2.46471113]), 'currentState': array([0.76772449, 1.74210319]), 'targetState': array([-0.14642978,  1.35838006]), 'effectorPosition': array([-0.08749356,  1.28506981])}
episode index:3737
target Thresh 1.9989782243533218
current state at start:  [-0.04064067  2.504973  ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.04064067,  2.504973  ]), 'currentState': array([5.86720794, 2.99448708]), 'targetState': array([ 0.09307961, -0.03436988]), 'effectorPosition': array([0.06910835, 0.12971156])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9355194218132804
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.04064067,  2.504973  ]), 'currentState': array([5.86720794, 2.99448708]), 'targetState': array([ 0.09307961, -0.03436988]), 'effectorPosition': array([0.06910835, 0.12971156])}
episode index:3738
target Thresh 1.9989802658624256
current state at start:  [-1.65461843 -2.60214485]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.65461843, -2.60214485]), 'currentState': array([4.27604763, 3.61812199]), 'targetState': array([-0.65235168,  0.49395405]), 'effectorPosition': array([-0.46280362,  0.0928886 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9355339927087569
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.65461843, -2.60214485]), 'currentState': array([3.86135696, 3.97021593]), 'targetState': array([-0.65235168,  0.49395405]), 'effectorPosition': array([-0.72955425,  0.34054148])}
episode index:3739
target Thresh 1.9989823032925915
current state at start:  [-4.03046252  2.16717954]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.03046252,  2.16717954]), 'currentState': array([2.73786937, 2.18321952]), 'targetState': array([-0.78500128, -0.63742487]), 'effectorPosition': array([-0.7124165, -0.5854561])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9355512296091022
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.03046252,  2.16717954]), 'currentState': array([2.73786937, 2.18321952]), 'targetState': array([-0.78500128, -0.63742487]), 'effectorPosition': array([-0.7124165, -0.5854561])}
episode index:3740
target Thresh 1.9989843366519693
current state at start:  [-3.31133086  2.69979454]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.31133086,  2.69979454]), 'currentState': array([2.47243884, 2.77915765]), 'targetState': array([-0.48429102,  0.01991341]), 'effectorPosition': array([-0.27089075, -0.23779335])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9355657842122539
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.31133086,  2.69979454]), 'currentState': array([2.0524162 , 2.49435259]), 'targetState': array([-0.48429102,  0.01991341]), 'effectorPosition': array([-0.62807946, -0.10007056])}
episode index:3741
target Thresh 1.9989863659486922
current state at start:  [ 2.56223014 -2.19875678]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.56223014, -2.19875678]), 'currentState': array([2.84932494, 3.6594056 ]), 'targetState': array([-0.03112225,  0.70146658]), 'effectorPosition': array([0.01707936, 0.51176233])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9355830034040732
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.56223014, -2.19875678]), 'currentState': array([2.84932494, 3.6594056 ]), 'targetState': array([-0.03112225,  0.70146658]), 'effectorPosition': array([0.01707936, 0.51176233])}
episode index:3742
target Thresh 1.9989883911908775
current state at start:  [-1.93165751  2.89040323]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.93165751,  2.89040323]), 'currentState': array([3.8515278 , 3.36002766]), 'targetState': array([-0.53517721,  0.20369613]), 'effectorPosition': array([-0.15926444,  0.14885991])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.9355871196334337
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([-1.93165751,  2.89040323]), 'currentState': array([1.70976891, 2.32930245]), 'targetState': array([-0.53517721,  0.20369613]), 'effectorPosition': array([-0.76210866,  0.20860168])}
episode index:3743
target Thresh 1.9989904123866262
current state at start:  [ 2.19681467 -2.68910359]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.19681467, -2.68910359]), 'currentState': array([1.95905381, 3.09408172]), 'targetState': array([ 0.69804009, -0.50727531]), 'effectorPosition': array([-0.04438536, -0.0169353 ])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.935588693626427
{'reset': False, 'endBeforeDone': False, 'stepCount': 7, 'initial state': array([ 2.19681467, -2.68910359]), 'currentState': array([4.49917587, 2.21920442]), 'targetState': array([ 0.69804009, -0.50727531]), 'effectorPosition': array([ 0.69518652, -0.55576885])}
episode index:3744
target Thresh 1.9989924295440231
current state at start:  [-0.12021023 -2.49270081]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.12021023, -2.49270081]), 'currentState': array([5.81581596, 3.99437852]), 'targetState': array([-0.39194151, -0.98962771]), 'effectorPosition': array([-0.03388534, -0.82648445])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9356032226801984
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.12021023, -2.49270081]), 'currentState': array([5.59485874, 4.03339756]), 'targetState': array([-0.39194151, -0.98962771]), 'effectorPosition': array([-0.20705948, -0.83732279])}
episode index:3745
target Thresh 1.998994442671137
current state at start:  [-2.68010242  2.02731631]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.68010242,  2.02731631]), 'currentState': array([3.14142525, 2.39333138]), 'targetState': array([-0.78877637, -0.48410686]), 'effectorPosition': array([-0.26724094, -0.68032079])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9356177439768666
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.68010242,  2.02731631]), 'currentState': array([2.71759677, 1.98453576]), 'targetState': array([-0.78877637, -0.48410686]), 'effectorPosition': array([-0.92170857, -0.58854161])}
episode index:3746
target Thresh 1.9989964517760201
current state at start:  [ 2.73437076 -1.87029209]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.73437076, -1.87029209]), 'currentState': array([2.24668201, 3.91289322]), 'targetState': array([0.32283864, 0.63243494]), 'effectorPosition': array([0.36678147, 0.65685764])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9356349263243507
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.73437076, -1.87029209]), 'currentState': array([2.24668201, 3.91289322]), 'targetState': array([0.32283864, 0.63243494]), 'effectorPosition': array([0.36678147, 0.65685764])}
episode index:3747
target Thresh 1.998998456866709
current state at start:  [ 2.12821002 -2.49476851]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.12821002, -2.49476851]), 'currentState': array([1.62821002, 4.26094514]), 'targetState': array([1.05733591, 0.88919664]), 'effectorPosition': array([0.86598718, 0.61443945])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9356467900046271
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 2.12821002, -2.49476851]), 'currentState': array([1.35174826, 5.00822132]), 'targetState': array([1.05733591, 0.88919664]), 'effectorPosition': array([1.21435407, 1.0528136 ])}
episode index:3748
target Thresh 1.9990004579512242
current state at start:  [1.314522   2.22676361]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.314522  , 2.22676361]), 'currentState': array([1.814522  , 2.72071454]), 'targetState': array([-0.15191603, -0.35847926]), 'effectorPosition': array([-0.41754715, -0.01390387])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9356612880601073
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.314522  , 2.22676361]), 'currentState': array([2.29492808, 2.78876073]), 'targetState': array([-0.15191603, -0.35847926]), 'effectorPosition': array([-0.29965832, -0.18278161])}
episode index:3749
target Thresh 1.9990024550375696
current state at start:  [-2.73438578  1.8945491 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.73438578,  1.8945491 ]), 'currentState': array([4.04879953, 2.34660801]), 'targetState': array([ 0.50088116, -0.66641919]), 'effectorPosition': array([ 0.37776116, -0.67579957])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.935678445049958
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.73438578,  1.8945491 ]), 'currentState': array([4.04879953, 2.34660801]), 'targetState': array([ 0.50088116, -0.66641919]), 'effectorPosition': array([ 0.37776116, -0.67579957])}
episode index:3750
target Thresh 1.999004448133734
current state at start:  [0.32062469 2.33229238]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.32062469, 2.33229238]), 'currentState': array([0.14231757, 2.77439985]), 'targetState': array([-0.0027842 ,  0.26661695]), 'effectorPosition': array([0.015068  , 0.36482237])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9356955928918534
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.32062469, 2.33229238]), 'currentState': array([0.14231757, 2.77439985]), 'targetState': array([-0.0027842 ,  0.26661695]), 'effectorPosition': array([0.015068  , 0.36482237])}
episode index:3751
target Thresh 1.9990064372476894
current state at start:  [1.22802861 2.60252202]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.22802861, 2.60252202]), 'currentState': array([0.90495502, 3.06286717]), 'targetState': array([-0.02473397,  0.11822913]), 'effectorPosition': array([-0.05993235,  0.05101583])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9357127315931083
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.22802861, 2.60252202]), 'currentState': array([0.90495502, 3.06286717]), 'targetState': array([-0.02473397,  0.11822913]), 'effectorPosition': array([-0.05993235,  0.05101583])}
episode index:3752
target Thresh 1.9990084223873927
current state at start:  [-0.19786607 -2.5988704 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.19786607, -2.5988704 ]), 'currentState': array([5.83829091, 4.18431491]), 'targetState': array([-0.1218122 , -1.25817942]), 'effectorPosition': array([ 0.07609596, -0.99321096])}
done in step count: 155
reward sum = 0.21059844619672852
running average episode reward sum: 0.935519522351063
{'reset': False, 'endBeforeDone': False, 'stepCount': 156, 'initial state': array([-0.19786607, -2.5988704 ]), 'currentState': array([5.68265472, 4.48473141]), 'targetState': array([-0.1218122 , -1.25817942]), 'effectorPosition': array([ 0.08832852, -1.24129197])}
episode index:3753
target Thresh 1.999010403560784
current state at start:  [ 1.55655122 -2.20551425]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.55655122, -2.20551425]), 'currentState': array([1.81350261, 3.6942918 ]), 'targetState': array([0.08125831, 0.83207674]), 'effectorPosition': array([0.473817  , 0.27069585])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9355313978112785
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 1.55655122, -2.20551425]), 'currentState': array([2.55814088, 3.95615906]), 'targetState': array([0.08125831, 0.83207674]), 'effectorPosition': array([0.13884567, 0.7799706 ])}
episode index:3754
target Thresh 1.9990123807757885
current state at start:  [ 1.32004139 -2.80305324]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.32004139, -2.80305324]), 'currentState': array([1.05592933, 2.98013207]), 'targetState': array([-0.14953919, -1.01881257]), 'effectorPosition': array([-0.13351413,  0.09048156])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.9355329820327404
{'reset': False, 'endBeforeDone': False, 'stepCount': 7, 'initial state': array([ 1.32004139, -2.80305324]), 'currentState': array([3.42182287, 2.04231834]), 'targetState': array([-0.14953919, -1.01881257]), 'effectorPosition': array([-0.278072  , -1.00707025])}
episode index:3755
target Thresh 1.9990143540403145
current state at start:  [ 0.84566661 -1.84991545]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.84566661, -1.84991545]), 'currentState': array([0.87392171, 4.04991126]), 'targetState': array([ 0.99698636, -0.13670783]), 'effectorPosition': array([ 0.85169607, -0.210877  ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9355501457755432
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.84566661, -1.84991545]), 'currentState': array([0.87392171, 4.04991126]), 'targetState': array([ 0.99698636, -0.13670783]), 'effectorPosition': array([ 0.85169607, -0.210877  ])}
episode index:3756
target Thresh 1.9990163233622555
current state at start:  [0.42464571 2.93200273]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.42464571, 2.93200273]), 'currentState': array([0.89011695, 2.50557375]), 'targetState': array([-0.6551258 ,  0.36796402]), 'effectorPosition': array([-0.33856927,  0.52577283])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.935564638683242
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.42464571, 2.93200273]), 'currentState': array([1.2968985 , 2.46396103]), 'targetState': array([-0.6551258 ,  0.36796402]), 'effectorPosition': array([-0.54381819,  0.38228557])}
episode index:3757
target Thresh 1.9990182887494887
current state at start:  [ 2.49356358 -1.85281456]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.49356358, -1.85281456]), 'currentState': array([1.99356358, 3.93037075]), 'targetState': array([0.57337521, 0.28146426]), 'effectorPosition': array([0.52587479, 0.56038394])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9355738814616659
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 2.49356358, -1.85281456]), 'currentState': array([1.50374352, 3.76525361]), 'targetState': array([0.57337521, 0.28146426]), 'effectorPosition': array([0.59531196, 0.14870086])}
episode index:3758
target Thresh 1.9990202502098755
current state at start:  [ 0.21220609 -2.58219852]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.21220609, -2.58219852]), 'currentState': array([0.13832056, 3.20897926]), 'targetState': array([-0.42497413, -0.33970937]), 'effectorPosition': array([ 0.01153217, -0.06637956])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.9355729480928032
{'reset': False, 'endBeforeDone': False, 'stepCount': 8, 'initial state': array([ 0.21220609, -2.58219852]), 'currentState': array([5.47069216, 3.56035639]), 'targetState': array([-0.42497413, -0.33970937]), 'effectorPosition': array([-0.23579422, -0.34236882])}
episode index:3759
target Thresh 1.9990222077512618
current state at start:  [-0.3208908  -1.89584251]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.3208908 , -1.89584251]), 'currentState': array([0.04594962, 3.88734279]), 'targetState': array([ 0.9347692 , -0.37169295]), 'effectorPosition': array([ 0.29630763, -0.66561516])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9355796031624594
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([-0.3208908 , -1.89584251]), 'currentState': array([4.9808087 , 2.19974986]), 'targetState': array([ 0.9347692 , -0.37169295]), 'effectorPosition': array([ 0.8888735 , -0.18249981])}
episode index:3760
target Thresh 1.9990241613814779
current state at start:  [ 3.39395183 -1.77074015]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.39395183, -1.77074015]), 'currentState': array([3.80863479, 4.10068861]), 'targetState': array([-1.14107195,  0.02994104]), 'effectorPosition': array([-0.84096855,  0.3798042 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9355940728239422
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.39395183, -1.77074015]), 'currentState': array([4.2074449 , 4.26924439]), 'targetState': array([-1.14107195,  0.02994104]), 'effectorPosition': array([-1.06699523, -0.0628993 ])}
episode index:3761
target Thresh 1.9990261111083383
current state at start:  [1.10139233 2.24891069]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.10139233, 2.24891069]), 'currentState': array([1.57222221, 2.73086863]), 'targetState': array([-4.90940204e-01, -3.17688608e-04]), 'effectorPosition': array([-0.39939142,  0.08259862])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9356111929534415
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.10139233, 2.24891069]), 'currentState': array([1.57222221, 2.73086863]), 'targetState': array([-4.90940204e-01, -3.17688608e-04]), 'effectorPosition': array([-0.39939142,  0.08259862])}
episode index:3762
target Thresh 1.9990280569396417
current state at start:  [-3.05413513  2.30598943]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.05413513,  2.30598943]), 'currentState': array([3.02973859, 2.8007767 ]), 'targetState': array([ 0.33368323, -0.08052802]), 'effectorPosition': array([-0.09446832, -0.32574722])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9356178325540384
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([-3.05413513,  2.30598943]), 'currentState': array([4.79909791, 2.70833717]), 'targetState': array([ 0.33368323, -0.08052802]), 'effectorPosition': array([ 0.42625201, -0.05569185])}
episode index:3763
target Thresh 1.9990299988831715
current state at start:  [1.40536656 2.58170985]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.40536656, 2.58170985]), 'currentState': array([1.54013412, 2.13692312]), 'targetState': array([-0.9574711 ,  0.99242757]), 'effectorPosition': array([-0.82937427,  0.4892893 ])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9356296503456023
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([1.40536656, 2.58170985]), 'currentState': array([1.63444631, 1.59460632]), 'targetState': array([-0.9574711 ,  0.99242757]), 'effectorPosition': array([-1.05978483,  0.9106265 ])}
episode index:3764
target Thresh 1.9990319369466956
current state at start:  [-1.37441629 -2.4669596 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.37441629, -2.4669596 ]), 'currentState': array([4.95261573, 3.58664105]), 'targetState': array([-0.32247138, -0.2188745 ]), 'effectorPosition': array([-0.3949632 , -0.19703911])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9356467473840231
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.37441629, -2.4669596 ]), 'currentState': array([4.95261573, 3.58664105]), 'targetState': array([-0.32247138, -0.2188745 ]), 'effectorPosition': array([-0.3949632 , -0.19703911])}
episode index:3765
target Thresh 1.9990338711379663
current state at start:  [ 3.55205319 -1.5743359 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.55205319, -1.5743359 ]), 'currentState': array([4.05205319, 4.35893   ]), 'targetState': array([-1.20542844, -0.2347339 ]), 'effectorPosition': array([-1.14202545,  0.05905772])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9356585512216801
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 3.55205319, -1.5743359 ]), 'currentState': array([4.3122122 , 4.50763563]), 'targetState': array([-1.20542844, -0.2347339 ]), 'effectorPosition': array([-1.212123  , -0.35228753])}
episode index:3766
target Thresh 1.99903580146472
current state at start:  [-1.49522358  3.07507359]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.49522358,  3.07507359]), 'currentState': array([5.02976715, 2.57507359]), 'targetState': array([ 0.42796533, -0.11342165]), 'effectorPosition': array([0.55864822, 0.01906771])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9356756315107106
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.49522358,  3.07507359]), 'currentState': array([5.02976715, 2.57507359]), 'targetState': array([ 0.42796533, -0.11342165]), 'effectorPosition': array([0.55864822, 0.01906771])}
episode index:3767
target Thresh 1.9990377279346785
current state at start:  [ 2.65024619 -2.62987226]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.65024619, -2.62987226]), 'currentState': array([2.54848293, 3.16082246]), 'targetState': array([-0.16364528,  0.33017113]), 'effectorPosition': array([0.01059438, 0.01604784])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9356822451992693
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([ 2.65024619, -2.62987226]), 'currentState': array([0.76759291, 2.91119077]), 'targetState': array([-0.16364528,  0.33017113]), 'effectorPosition': array([-0.13956524,  0.18268046])}
episode index:3768
target Thresh 1.9990396505555474
current state at start:  [-4.5031325   2.86193337]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.5031325 ,  2.86193337]), 'currentState': array([1.2800528 , 3.29962145]), 'targetState': array([ 0.35645244, -0.07827563]), 'effectorPosition': array([ 0.15433914, -0.03317532])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9356993101381923
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.5031325 ,  2.86193337]), 'currentState': array([1.2800528 , 3.29962145]), 'targetState': array([ 0.35645244, -0.07827563]), 'effectorPosition': array([ 0.15433914, -0.03317532])}
episode index:3769
target Thresh 1.9990415693350172
current state at start:  [ 1.37037989 -1.72101511]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.37037989, -1.72101511]), 'currentState': array([1.41347  , 4.8530782]), 'targetState': array([1.12247591, 0.67892909]), 'effectorPosition': array([1.15653973, 0.97101338])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9357084877747605
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 1.37037989, -1.72101511]), 'currentState': array([1.27300638, 4.78569445]), 'targetState': array([1.12247591, 0.67892909]), 'effectorPosition': array([1.26831714, 0.73338346])}
episode index:3770
target Thresh 1.9990434842807632
current state at start:  [1.15638232 2.59280052]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.15638232, 2.59280052]), 'currentState': array([1.65638232, 3.06783511]), 'targetState': array([ 0.13795531, -0.62309434]), 'effectorPosition': array([-0.07365337, -0.00359029])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9357150874889544
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([1.15638232, 2.59280052]), 'currentState': array([3.64532762, 2.41296392]), 'targetState': array([ 0.13795531, -0.62309434]), 'effectorPosition': array([ 0.099032  , -0.70570274])}
episode index:3771
target Thresh 1.9990453954004448
current state at start:  [0.00750267 2.36319804]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.00750267, 2.36319804]), 'currentState': array([0.50750267, 2.5618169 ]), 'targetState': array([-0.3080935 ,  0.99452404]), 'effectorPosition': array([-0.12342851,  0.55820638])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9357294790352191
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.00750267, 2.36319804]), 'currentState': array([0.97443824, 2.08241236]), 'targetState': array([-0.3080935 ,  0.99452404]), 'effectorPosition': array([-0.43477861,  0.91202718])}
episode index:3772
target Thresh 1.999047302701707
current state at start:  [-0.04369809  2.34735426]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.04369809,  2.34735426]), 'currentState': array([0.45630191, 2.71889496]), 'targetState': array([-0.54452315,  1.17367724]), 'effectorPosition': array([-0.1017473 ,  0.40703351])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.935738641378438
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-0.04369809,  2.34735426]), 'currentState': array([1.20153682, 1.75214059]), 'targetState': array([-0.54452315,  1.17367724]), 'effectorPosition': array([-0.62147088,  1.11940611])}
episode index:3773
target Thresh 1.9990492061921785
current state at start:  [-1.64685164 -2.19466663]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.64685164, -2.19466663]), 'currentState': array([4.92361941, 4.41661852]), 'targetState': array([-0.32113216, -0.77749838]), 'effectorPosition': array([-0.78676548, -0.89333432])}
done in step count: 108
reward sum = 0.337754400898902
running average episode reward sum: 0.9355801929840344
{'reset': False, 'endBeforeDone': False, 'stepCount': 109, 'initial state': array([-1.64685164, -2.19466663]), 'currentState': array([3.25324815, 2.19621521]), 'targetState': array([-0.32113216, -0.77749838]), 'effectorPosition': array([-0.32164845, -0.85186174])}
episode index:3774
target Thresh 1.9990511058794738
current state at start:  [0.0432211  1.72910663]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.0432211 , 1.72910663]), 'currentState': array([0.11249062, 2.22910663]), 'targetState': array([-0.0776388 ,  0.38088991]), 'effectorPosition': array([0.29696959, 0.82960642])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9355946088269524
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.0432211 , 1.72910663]), 'currentState': array([0.11965656, 2.72910663]), 'targetState': array([-0.0776388 ,  0.38088991]), 'effectorPosition': array([0.03541874, 0.40803363])}
episode index:3775
target Thresh 1.9990530017711912
current state at start:  [-0.49340816  1.63763105]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.49340816,  1.63763105]), 'currentState': array([5.97097268, 2.09325521]), 'targetState': array([0.89119999, 0.53606935]), 'effectorPosition': array([0.74295552, 0.6708145 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9356116653394453
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.49340816,  1.63763105]), 'currentState': array([5.97097268, 2.09325521]), 'targetState': array([0.89119999, 0.53606935]), 'effectorPosition': array([0.74295552, 0.6708145 ])}
episode index:3776
target Thresh 1.9990548938749142
current state at start:  [0.91827384 1.88624634]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.91827384, 1.88624634]), 'currentState': array([0.56886772, 2.38624634]), 'targetState': array([0.32208114, 0.29157656]), 'effectorPosition': array([-0.14015174,  0.72407813])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9356208491717621
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([0.91827384, 1.88624634]), 'currentState': array([5.6954395 , 2.68968587]), 'targetState': array([0.32208114, 0.29157656]), 'effectorPosition': array([0.32567288, 0.3077418 ])}
episode index:3777
target Thresh 1.9990567821982117
current state at start:  [ 1.49702371 -1.99902308]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.49702371, -1.99902308]), 'currentState': array([1.01245631, 4.16675568]), 'targetState': array([ 1.18284833, -0.19120926]), 'effectorPosition': array([ 0.97983054, -0.0448669 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9356352428061793
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.49702371, -1.99902308]), 'currentState': array([0.68409745, 4.63816112]), 'targetState': array([ 1.18284833, -0.19120926]), 'effectorPosition': array([ 1.34775032, -0.18774892])}
episode index:3778
target Thresh 1.9990586667486367
current state at start:  [-2.7160969   1.80053325]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.7160969 ,  1.80053325]), 'currentState': array([3.07266022, 2.30025982]), 'targetState': array([-0.33982833, -0.24470552]), 'effectorPosition': array([-0.3840888 , -0.72078866])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9356496288229016
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.7160969 ,  1.80053325]), 'currentState': array([2.57266022, 2.62880622]), 'targetState': array([-0.33982833, -0.24470552]), 'effectorPosition': array([-0.37266488, -0.3440337 ])}
episode index:3779
target Thresh 1.9990605475337273
current state at start:  [ 3.05319217 -2.70946843]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.05319217, -2.70946843]), 'currentState': array([2.75099919, 3.8569433 ]), 'targetState': array([0.15512414, 0.52986981]), 'effectorPosition': array([0.02304496, 0.69981592])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9356666527306204
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.05319217, -2.70946843]), 'currentState': array([2.75099919, 3.8569433 ]), 'targetState': array([0.15512414, 0.52986981]), 'effectorPosition': array([0.02304496, 0.69981592])}
episode index:3780
target Thresh 1.999062424561007
current state at start:  [-2.34997754  2.39700762]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.34997754,  2.39700762]), 'currentState': array([3.43320777, 2.88861812]), 'targetState': array([ 0.03064217, -0.02461068]), 'effectorPosition': array([ 0.04147277, -0.24886856])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9356836676333629
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.34997754,  2.39700762]), 'currentState': array([3.43320777, 2.88861812]), 'targetState': array([ 0.03064217, -0.02461068]), 'effectorPosition': array([ 0.04147277, -0.24886856])}
episode index:3781
target Thresh 1.9990642978379836
current state at start:  [-0.77317043 -2.05111433]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.77317043, -2.05111433]), 'currentState': array([5.6863008 , 3.73224425]), 'targetState': array([-0.21742839, -0.16532298]), 'effectorPosition': array([-0.17288983, -0.55583554])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9356980294346232
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.77317043, -2.05111433]), 'currentState': array([5.67026956, 3.3000583 ]), 'targetState': array([-0.21742839, -0.16532298]), 'effectorPosition': array([-0.08052836, -0.13628662])}
episode index:3782
target Thresh 1.9990661673721501
current state at start:  [ 0.6383383  -2.51285822]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.6383383 , -2.51285822]), 'currentState': array([0.98343262, 3.34362894]), 'targetState': array([-0.40957514,  0.27245259]), 'effectorPosition': array([ 0.17830592, -0.0942709 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9357123836430729
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.6383383 , -2.51285822]), 'currentState': array([1.34236691, 2.88443538]), 'targetState': array([-0.40957514,  0.27245259]), 'effectorPosition': array([-0.24027929,  0.08962197])}
episode index:3783
target Thresh 1.9990680331709851
current state at start:  [-1.74153893 -2.64902239]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.74153893, -2.64902239]), 'currentState': array([4.726824  , 3.27822999]), 'targetState': array([-0.31838151, -0.10294672]), 'effectorPosition': array([-0.13606384, -0.01128556])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9357293729708628
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.74153893, -2.64902239]), 'currentState': array([4.726824  , 3.27822999]), 'targetState': array([-0.31838151, -0.10294672]), 'effectorPosition': array([-0.13606384, -0.01128556])}
episode index:3784
target Thresh 1.9990698952419514
current state at start:  [0.95150151 2.41919323]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.95150151, 2.41919323]), 'currentState': array([1.33354114, 2.91919323]), 'targetState': array([ 0.09321073, -0.14101667]), 'effectorPosition': array([-0.208603  ,  0.07578099])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9357437113135388
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.95150151, 2.41919323]), 'currentState': array([1.51503249, 3.3570015 ]), 'targetState': array([ 0.09321073, -0.14101667]), 'effectorPosition': array([0.21470268, 0.01116182])}
episode index:3785
target Thresh 1.9990717535924976
current state at start:  [0.45060552 1.95833627]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.45060552, 1.95833627]), 'currentState': array([6.23379083, 1.82371078]), 'targetState': array([0.75332266, 0.85935478]), 'effectorPosition': array([0.79666244, 0.9299868 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9357606833919029
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.45060552, 1.95833627]), 'currentState': array([6.23379083, 1.82371078]), 'targetState': array([0.75332266, 0.85935478]), 'effectorPosition': array([0.79666244, 0.9299868 ])}
episode index:3786
target Thresh 1.9990736082300569
current state at start:  [-2.99923698  2.39570402]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.99923698,  2.39570402]), 'currentState': array([2.82311996, 2.89570402]), 'targetState': array([-0.05883926, -0.02359471]), 'effectorPosition': array([-0.10478437, -0.22175987])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9357776465069302
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.99923698,  2.39570402]), 'currentState': array([2.82311996, 2.89570402]), 'targetState': array([-0.05883926, -0.02359471]), 'effectorPosition': array([-0.10478437, -0.22175987])}
episode index:3787
target Thresh 1.9990754591620479
current state at start:  [-2.72314989  2.35941507]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.72314989,  2.35941507]), 'currentState': array([3.90734691, 2.06459869]), 'targetState': array([ 0.11887554, -0.82683879]), 'effectorPosition': array([ 0.23109486, -0.99931992])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9357946006657192
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.72314989,  2.35941507]), 'currentState': array([3.90734691, 2.06459869]), 'targetState': array([ 0.11887554, -0.82683879]), 'effectorPosition': array([ 0.23109486, -0.99931992])}
episode index:3788
target Thresh 1.9990773063958742
current state at start:  [-1.23458762  2.26909322]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.23458762,  2.26909322]), 'currentState': array([4.61644518, 2.76909322]), 'targetState': array([ 0.27648811, -0.18661534]), 'effectorPosition': array([ 0.3557011 , -0.10312868])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9358115458753614
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.23458762,  2.26909322]), 'currentState': array([4.61644518, 2.76909322]), 'targetState': array([ 0.27648811, -0.18661534]), 'effectorPosition': array([ 0.3557011 , -0.10312868])}
episode index:3789
target Thresh 1.9990791499389249
current state at start:  [0.48094327 1.69931119]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.48094327, 1.69931119]), 'currentState': array([0.16075594, 2.18433033]), 'targetState': array([0.37969311, 1.01549295]), 'effectorPosition': array([0.28789795, 0.87498213])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9358284821429405
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.48094327, 1.69931119]), 'currentState': array([0.16075594, 2.18433033]), 'targetState': array([0.37969311, 1.01549295]), 'effectorPosition': array([0.28789795, 0.87498213])}
episode index:3790
target Thresh 1.999080989798574
current state at start:  [ 2.31359958 -1.87459776]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.31359958, -1.87459776]), 'currentState': array([1.88416242, 3.92867354]), 'targetState': array([0.79938872, 0.69900056]), 'effectorPosition': array([0.58314747, 0.4981036 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9358427716491016
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 2.31359958, -1.87459776]), 'currentState': array([1.62653481, 4.42424247]), 'targetState': array([0.79938872, 0.69900056]), 'effectorPosition': array([0.91740497, 0.76812554])}
episode index:3791
target Thresh 1.9990828259821811
current state at start:  [ 3.92895762 -1.63093079]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.92895762, -1.63093079]), 'currentState': array([3.48597095, 4.18047144]), 'targetState': array([-0.39046961,  0.216907  ]), 'effectorPosition': array([-0.75484368,  0.64485446])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9358570536186034
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.92895762, -1.63093079]), 'currentState': array([3.68846754, 3.74854642]), 'targetState': array([-0.39046961,  0.216907  ]), 'effectorPosition': array([-0.44916401,  0.39430076])}
episode index:3792
target Thresh 1.9990846584970912
current state at start:  [-3.33017041  1.72930563]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.33017041,  1.72930563]), 'currentState': array([2.4530149 , 2.21998385]), 'targetState': array([-0.01445794, -0.41824753]), 'effectorPosition': array([-0.81153059, -0.36378467])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9358661340157511
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-3.33017041,  1.72930563]), 'currentState': array([2.80602061, 2.67101741]), 'targetState': array([-0.01445794, -0.41824753]), 'effectorPosition': array([-0.2519383, -0.392316 ])}
episode index:3793
target Thresh 1.9990864873506338
current state at start:  [-0.1183738   1.85234126]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.1183738 ,  1.85234126]), 'currentState': array([5.66481151, 1.84556928]), 'targetState': array([1.09739219, 0.46468045]), 'effectorPosition': array([1.15170189, 0.36183686])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9358830380394686
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.1183738 ,  1.85234126]), 'currentState': array([5.66481151, 1.84556928]), 'targetState': array([1.09739219, 0.46468045]), 'effectorPosition': array([1.15170189, 0.36183686])}
episode index:3794
target Thresh 1.9990883125501246
current state at start:  [ 1.74449839 -1.65694318]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.74449839, -1.65694318]), 'currentState': array([1.24449839, 4.41287839]), 'targetState': array([1.34777228, 0.21866818]), 'effectorPosition': array([1.1310283 , 0.36148272])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9358972981084964
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.74449839, -1.65694318]), 'currentState': array([0.82149883, 4.86313685]), 'targetState': array([1.34777228, 0.21866818]), 'effectorPosition': array([1.50727827, 0.16872271])}
episode index:3795
target Thresh 1.9990901341028644
current state at start:  [ 2.61107797 -2.06908304]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.61107797, -2.06908304]), 'currentState': array([2.82299717, 4.33691576]), 'targetState': array([-0.18001352,  1.03540405]), 'effectorPosition': array([-0.31000641,  1.08188279])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9359141850162656
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.61107797, -2.06908304]), 'currentState': array([2.82299717, 4.33691576]), 'targetState': array([-0.18001352,  1.03540405]), 'effectorPosition': array([-0.31000641,  1.08188279])}
episode index:3796
target Thresh 1.9990919520161394
current state at start:  [-1.58637766  2.19441515]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.58637766,  2.19441515]), 'currentState': array([5.16280523, 1.9313316 ]), 'targetState': array([ 1.27911429, -0.00529635]), 'effectorPosition': array([ 1.12414925, -0.17532305])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9359310630291662
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.58637766,  2.19441515]), 'currentState': array([5.16280523, 1.9313316 ]), 'targetState': array([ 1.27911429, -0.00529635]), 'effectorPosition': array([ 1.12414925, -0.17532305])}
episode index:3797
target Thresh 1.9990937662972212
current state at start:  [ 2.03070337 -2.36365822]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.03070337, -2.36365822]), 'currentState': array([1.55613903, 3.59764043]), 'targetState': array([0.95341429, 0.0645659 ]), 'effectorPosition': array([0.44185386, 0.09573405])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.935945299189506
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 2.03070337, -2.36365822]), 'currentState': array([1.09508509, 4.09764043]), 'targetState': array([0.95341429, 0.0645659 ]), 'effectorPosition': array([0.92004849, 0.00212775])}
episode index:3798
target Thresh 1.9990955769533671
current state at start:  [1.28574428 2.7487013 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.28574428, 2.7487013 ]), 'currentState': array([0.80423993, 3.2487013 ]), 'targetState': array([0.36433017, 0.00446055]), 'effectorPosition': array([ 0.08097843, -0.07002708])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.9359442778809294
{'reset': False, 'endBeforeDone': False, 'stepCount': 8, 'initial state': array([1.28574428, 2.7487013 ]), 'currentState': array([5.52821385, 2.7680127 ]), 'targetState': array([0.36433017, 0.00446055]), 'effectorPosition': array([0.30032162, 0.2185253 ])}
episode index:3799
target Thresh 1.9990973839918196
current state at start:  [ 0.21699063 -2.86481167]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.21699063, -2.86481167]), 'currentState': array([6.13169841, 3.86990964]), 'targetState': array([ 0.83052278, -0.55931347]), 'effectorPosition': array([ 0.15035216, -0.69627784])}
done in step count: 17
reward sum = 0.8429431933839268
running average episode reward sum: 0.935919803911325
{'reset': False, 'endBeforeDone': False, 'stepCount': 18, 'initial state': array([ 0.21699063, -2.86481167]), 'currentState': array([4.57762806, 1.98987205]), 'targetState': array([ 0.83052278, -0.55931347]), 'effectorPosition': array([ 0.82550067, -0.71043366])}
episode index:3800
target Thresh 1.999099187419807
current state at start:  [-1.41051393  2.26467379]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.41051393,  2.26467379]), 'currentState': array([4.37267138, 2.61431708]), 'targetState': array([ 0.05800915, -0.33407713]), 'effectorPosition': array([ 0.42916575, -0.29572697])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.935934031797694
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.41051393,  2.26467379]), 'currentState': array([3.87267138, 2.82931268]), 'targetState': array([ 0.05800915, -0.33407713]), 'effectorPosition': array([ 0.1691235 , -0.26100978])}
episode index:3801
target Thresh 1.9991009872445427
current state at start:  [-1.42657733  2.10993069]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.42657733,  2.10993069]), 'currentState': array([4.35660798, 2.57459178]), 'targetState': array([0.22294516, 0.12283925]), 'effectorPosition': array([ 0.44896129, -0.33377018])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9359482521996408
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.42657733,  2.10993069]), 'currentState': array([4.24246547, 3.0600436 ]), 'targetState': array([0.22294516, 0.12283925]), 'effectorPosition': array([ 0.07112397, -0.03984902])}
episode index:3802
target Thresh 1.999102783473226
current state at start:  [ 3.32252956 -1.70693505]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.32252956, -1.70693505]), 'currentState': array([2.82252956, 4.65767603]), 'targetState': array([-0.45978109,  1.10093926]), 'effectorPosition': array([-0.58439637,  1.24463231])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9359650946260938
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.32252956, -1.70693505]), 'currentState': array([2.82252956, 4.65767603]), 'targetState': array([-0.45978109,  1.10093926]), 'effectorPosition': array([-0.58439637,  1.24463231])}
episode index:3803
target Thresh 1.9991045761130424
current state at start:  [-2.64863349  3.10791903]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.64863349,  3.10791903]), 'currentState': array([3.95865041, 2.64203506]), 'targetState': array([ 0.08868335, -0.63749669]), 'effectorPosition': array([ 0.26564936, -0.41694276])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9359792993856557
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.64863349,  3.10791903]), 'currentState': array([3.62940919, 2.3163472 ]), 'targetState': array([ 0.08868335, -0.63749669]), 'effectorPosition': array([ 0.06025062, -0.79976032])}
episode index:3804
target Thresh 1.9991063651711618
current state at start:  [0.19427937 1.93952793]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.19427937, 1.93952793]), 'currentState': array([0.48930176, 2.34209117]), 'targetState': array([-0.04529697,  1.00917362]), 'effectorPosition': array([-0.06961137,  0.77525853])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9359961247997461
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.19427937, 1.93952793]), 'currentState': array([0.48930176, 2.34209117]), 'targetState': array([-0.04529697,  1.00917362]), 'effectorPosition': array([-0.06961137,  0.77525853])}
episode index:3805
target Thresh 1.9991081506547406
current state at start:  [ 1.89780962 -1.81654445]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.89780962, -1.81654445]), 'currentState': array([1.58024692, 4.01908907]), 'targetState': array([0.72659216, 0.54242838]), 'effectorPosition': array([0.76569609, 0.36817386])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9360129413723158
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.89780962, -1.81654445]), 'currentState': array([1.58024692, 4.01908907]), 'targetState': array([0.72659216, 0.54242838]), 'effectorPosition': array([0.76569609, 0.36817386])}
episode index:3806
target Thresh 1.999109932570921
current state at start:  [-0.21144724 -1.85578152]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.21144724, -1.85578152]), 'currentState': array([0.22793812, 4.05885635]), 'targetState': array([ 0.92889858, -0.95424059]), 'effectorPosition': array([ 0.56127205, -0.68482399])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9360245218973036
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-0.21144724, -1.85578152]), 'currentState': array([0.07091147, 4.55517477]), 'targetState': array([ 0.92889858, -0.95424059]), 'effectorPosition': array([ 0.91129118, -0.92542618])}
episode index:3807
target Thresh 1.9991117109268306
current state at start:  [-1.12685543 -1.58301014]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.12685543, -1.58301014]), 'currentState': array([5.37689899, 5.09396416]), 'targetState': array([ 0.16550311, -0.7821619 ]), 'effectorPosition': array([ 0.11571046, -1.65268773])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9360360963400827
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.12685543, -1.58301014]), 'currentState': array([6.03964176, 4.09808874]), 'targetState': array([ 0.16550311, -0.7821619 ]), 'effectorPosition': array([ 0.21405556, -0.89521313])}
episode index:3808
target Thresh 1.9991134857295825
current state at start:  [1.24942356 2.8526696 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.24942356, 2.8526696 ]), 'currentState': array([0.74942356, 3.28646195]), 'targetState': array([0.54933734, 0.12115789]), 'effectorPosition': array([ 0.10601129, -0.09854969])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9360425442039996
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([1.24942356, 2.8526696 ]), 'currentState': array([5.31265771, 2.62402533]), 'targetState': array([0.54933734, 0.12115789]), 'effectorPosition': array([0.48225708, 0.17139834])}
episode index:3809
target Thresh 1.9991152569862762
current state at start:  [ 1.55981954 -2.06525148]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.55981954, -2.06525148]), 'currentState': array([1.12114465, 3.76235633]), 'targetState': array([ 0.83626634, -0.10949965]), 'effectorPosition': array([ 0.60493008, -0.08479747])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9360593309378044
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.55981954, -2.06525148]), 'currentState': array([1.12114465, 3.76235633]), 'targetState': array([ 0.83626634, -0.10949965]), 'effectorPosition': array([ 0.60493008, -0.08479747])}
episode index:3810
target Thresh 1.9991170247039967
current state at start:  [-3.4782704   1.91682018]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.4782704 ,  1.91682018]), 'currentState': array([2.36032064, 2.38712175]), 'targetState': array([-0.02314039, -0.05850704]), 'effectorPosition': array([-0.67497215, -0.29520255])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9360708871354066
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-3.4782704 ,  1.91682018]), 'currentState': array([1.82244198, 3.06984497]), 'targetState': array([-0.02314039, -0.05850704]), 'effectorPosition': array([-0.07006892, -0.01535798])}
episode index:3811
target Thresh 1.9991187888898148
current state at start:  [-0.76156806  1.77770508]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.76156806,  1.77770508]), 'currentState': array([5.06385309, 2.0791894 ]), 'targetState': array([ 1.19907708, -0.23294068]), 'effectorPosition': array([ 0.99681848, -0.18112029])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9360876576267142
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.76156806,  1.77770508]), 'currentState': array([5.06385309, 2.0791894 ]), 'targetState': array([ 1.19907708, -0.23294068]), 'effectorPosition': array([ 0.99681848, -0.18112029])}
episode index:3812
target Thresh 1.9991205495507873
current state at start:  [0.06214995 2.30351503]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.06214995, 2.30351503]), 'currentState': array([5.91936709, 2.31121354]), 'targetState': array([0.45213473, 0.47335321]), 'effectorPosition': array([0.56678501, 0.57407565])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9361044193215408
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.06214995, 2.30351503]), 'currentState': array([5.91936709, 2.31121354]), 'targetState': array([0.45213473, 0.47335321]), 'effectorPosition': array([0.56678501, 0.57407565])}
episode index:3813
target Thresh 1.999122306693957
current state at start:  [-3.50061743  2.02205667]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.50061743,  2.02205667]), 'currentState': array([2.28256788, 2.44850409]), 'targetState': array([-0.57310343, -0.03442156]), 'effectorPosition': array([-0.63449432, -0.24261955])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9361211722268051
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.50061743,  2.02205667]), 'currentState': array([2.28256788, 2.44850409]), 'targetState': array([-0.57310343, -0.03442156]), 'effectorPosition': array([-0.63449432, -0.24261955])}
episode index:3814
target Thresh 1.999124060326352
current state at start:  [-1.19927831  2.40991807]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.19927831,  2.40991807]), 'currentState': array([5.40290861, 2.86419839]), 'targetState': array([0.06912841, 0.7619055 ]), 'effectorPosition': array([0.23546415, 0.1449554 ])}
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.9361081351886633
{'reset': False, 'endBeforeDone': False, 'stepCount': 13, 'initial state': array([-1.19927831,  2.40991807]), 'currentState': array([6.20852469, 2.48224038]), 'targetState': array([0.06912841, 0.7619055 ]), 'effectorPosition': array([0.25472186, 0.59526329])}
episode index:3815
target Thresh 1.9991258104549874
current state at start:  [-0.95914433  2.65394197]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.95914433,  2.65394197]), 'currentState': array([4.82404098, 3.1345898 ]), 'targetState': array([-0.40592205, -0.28104054]), 'effectorPosition': array([0.00696193, 0.00075589])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.9361120350614913
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([-0.95914433,  2.65394197]), 'currentState': array([2.43077755, 2.44394372]), 'targetState': array([-0.40592205, -0.28104054]), 'effectorPosition': array([-0.59621005, -0.33440132])}
episode index:3816
target Thresh 1.9991275570868632
current state at start:  [-3.73503881  2.22372169]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.73503881,  2.22372169]), 'currentState': array([2.91454686, 2.2432342 ]), 'targetState': array([-0.80567084, -0.51084357]), 'effectorPosition': array([-0.5435239, -0.6773417])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9361235592859971
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-3.73503881,  2.22372169]), 'currentState': array([2.77081336, 2.22869361]), 'targetState': array([-0.80567084, -0.51084357]), 'effectorPosition': array([-0.64885588, -0.59672213])}
episode index:3817
target Thresh 1.9991293002289663
current state at start:  [-1.02622961  2.41112662]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.02622961,  2.41112662]), 'currentState': array([4.80463355, 2.56199277]), 'targetState': array([-0.25212079, -0.75539773]), 'effectorPosition': array([ 0.56040456, -0.11217406])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.936132510422905
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-1.02622961,  2.41112662]), 'currentState': array([3.34089457, 2.2133444 ]), 'targetState': array([-0.25212079, -0.75539773]), 'effectorPosition': array([-0.23432839, -0.86406922])}
episode index:3818
target Thresh 1.9991310398882693
current state at start:  [-1.06343806  2.50753757]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.06343806,  2.50753757]), 'currentState': array([5.70983094, 2.04257491]), 'targetState': array([1.38834847, 0.26804232]), 'effectorPosition': array([0.94148732, 0.45239256])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9361440232507597
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.06343806,  2.50753757]), 'currentState': array([5.63718265, 1.84813242]), 'targetState': array([1.38834847, 0.26804232]), 'effectorPosition': array([1.15886848, 0.33080935])}
episode index:3819
target Thresh 1.9991327760717306
current state at start:  [ 3.37416706 -2.28854343]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.37416706, -2.28854343]), 'currentState': array([2.93956307, 3.51919363]), 'targetState': array([0.2689862 , 0.44147599]), 'effectorPosition': array([0.00496555, 0.37532882])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9361581216739925
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.37416706, -2.28854343]), 'currentState': array([2.62556157, 3.69943904]), 'targetState': array([0.2689862 , 0.44147599]), 'effectorPosition': array([0.12934145, 0.53523505])}
episode index:3820
target Thresh 1.9991345087862948
current state at start:  [ 3.65778142 -2.39822348]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.65778142, -2.39822348]), 'currentState': array([3.67188001, 3.44771789]), 'targetState': array([-0.01564371,  0.22987331]), 'effectorPosition': array([-0.1925319 ,  0.23646262])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9361748298337218
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.65778142, -2.39822348]), 'currentState': array([3.67188001, 3.44771789]), 'targetState': array([-0.01564371,  0.22987331]), 'effectorPosition': array([-0.1925319 ,  0.23646262])}
episode index:3821
target Thresh 1.9991362380388933
current state at start:  [-1.57658972 -1.62484757]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.57658972, -1.62484757]), 'currentState': array([4.31026103, 4.34332907]), 'targetState': array([-0.07191861, -0.14187371]), 'effectorPosition': array([-1.10846068, -0.22324272])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9361837581880301
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-1.57658972, -1.62484757]), 'currentState': array([4.53406663, 3.08710542]), 'targetState': array([-0.07191861, -0.14187371]), 'effectorPosition': array([ 0.05333344, -0.01112063])}
episode index:3822
target Thresh 1.9991379638364426
current state at start:  [-0.89401796  2.43444882]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.89401796,  2.43444882]), 'currentState': array([5.80561967, 2.19009918]), 'targetState': array([0.66029502, 0.40228161]), 'effectorPosition': array([0.74685331, 0.53035354])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9362004509010335
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.89401796,  2.43444882]), 'currentState': array([5.80561967, 2.19009918]), 'targetState': array([0.66029502, 0.40228161]), 'effectorPosition': array([0.74685331, 0.53035354])}
episode index:3823
target Thresh 1.9991396861858464
current state at start:  [1.17585241 2.42667697]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.17585241, 2.42667697]), 'currentState': array([1.37420612, 2.92667697]), 'targetState': array([ 0.02320734, -0.06541211]), 'effectorPosition': array([-0.2046636 ,  0.06421878])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.936214519820777
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.17585241, 2.42667697]), 'currentState': array([1.39262749, 3.25850873]), 'targetState': array([ 0.02320734, -0.06541211]), 'effectorPosition': array([ 0.11601323, -0.01395476])}
episode index:3824
target Thresh 1.9991414050939935
current state at start:  [ 1.05042517 -1.92416759]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.05042517, -1.92416759]), 'currentState': array([1.49492311, 4.5259838 ]), 'targetState': array([0.48726023, 0.97114498]), 'effectorPosition': array([1.04160218, 0.7378413 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9362285813842224
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.05042517, -1.92416759]), 'currentState': array([1.93439403, 4.52845845]), 'targetState': array([0.48726023, 0.97114498]), 'effectorPosition': array([0.6282642, 1.1133255])}
episode index:3825
target Thresh 1.99914312056776
current state at start:  [-2.11298589  2.70057876]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.11298589,  2.70057876]), 'currentState': array([4.40960763, 2.33829944]), 'targetState': array([ 0.30722496, -0.49450519]), 'effectorPosition': array([ 0.59577011, -0.50633676])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9362426355971382
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.11298589,  2.70057876]), 'currentState': array([4.07941926, 2.65051784]), 'targetState': array([ 0.30722496, -0.49450519]), 'effectorPosition': array([ 0.31031344, -0.37423595])}
episode index:3826
target Thresh 1.9991448326140075
current state at start:  [ 2.53697077 -2.09091156]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.53697077, -2.09091156]), 'currentState': array([2.26118848, 3.71186624]), 'targetState': array([-0.03487218,  0.01180786]), 'effectorPosition': array([0.31545415, 0.46581334])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9362566824652863
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 2.53697077, -2.09091156]), 'currentState': array([1.99444062, 3.2297215 ]), 'targetState': array([-0.03487218,  0.01180786]), 'effectorPosition': array([0.07863867, 0.03971935])}
episode index:3827
target Thresh 1.9991465412395844
current state at start:  [-3.87198667  2.45403955]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.87198667,  2.45403955]), 'currentState': array([2.91119864, 2.00551695]), 'targetState': array([-1.11083073, -0.67251179]), 'effectorPosition': array([-0.77066867, -0.7508367 ])}
done in step count: 21
reward sum = 0.8097278682212584
running average episode reward sum: 0.9362236289610427
{'reset': False, 'endBeforeDone': False, 'stepCount': 22, 'initial state': array([-3.87198667,  2.45403955]), 'currentState': array([2.68915706, 1.75344897]), 'targetState': array([-1.11083073, -0.67251179]), 'effectorPosition': array([-1.16590728, -0.5266714 ])}
episode index:3828
target Thresh 1.999148246451325
current state at start:  [ 2.01054819 -1.68420662]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.01054819, -1.68420662]), 'currentState': array([2.51054819, 4.34146823]), 'targetState': array([0.02196369, 1.19762965]), 'effectorPosition': array([0.03511944, 1.12863599])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.93624028510391
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.01054819, -1.68420662]), 'currentState': array([2.51054819, 4.34146823]), 'targetState': array([0.02196369, 1.19762965]), 'effectorPosition': array([0.03511944, 1.12863599])}
episode index:3829
target Thresh 1.9991499482560504
current state at start:  [0.35185369 3.00228855]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.35185369, 3.00228855]), 'currentState': array([0.65772023, 2.95216862]), 'targetState': array([-0.24153272,  0.11664222]), 'effectorPosition': array([-0.10095068,  0.15994769])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9362569325490526
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.35185369, 3.00228855]), 'currentState': array([0.65772023, 2.95216862]), 'targetState': array([-0.24153272,  0.11664222]), 'effectorPosition': array([-0.10095068,  0.15994769])}
episode index:3830
target Thresh 1.9991516466605677
current state at start:  [-0.37867251 -2.23392545]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.37867251, -2.23392545]), 'currentState': array([5.95332783, 3.61284842]), 'targetState': array([ 0.98026978, -0.34433141]), 'effectorPosition': array([-0.04393139, -0.46483577])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9362632857407652
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([-0.37867251, -2.23392545]), 'currentState': array([5.04644544, 2.04976921]), 'targetState': array([ 0.98026978, -0.34433141]), 'effectorPosition': array([ 1.01517909, -0.21834752])}
episode index:3831
target Thresh 1.9991533416716705
current state at start:  [-2.69514793  2.54215163]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.69514793,  2.54215163]), 'currentState': array([3.2658532, 2.1041601]), 'targetState': array([-0.18012566, -0.83103918]), 'effectorPosition': array([-0.38105123, -0.91538759])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9362799184950081
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.69514793,  2.54215163]), 'currentState': array([3.2658532, 2.1041601]), 'targetState': array([-0.18012566, -0.83103918]), 'effectorPosition': array([-0.38105123, -0.91538759])}
episode index:3832
target Thresh 1.9991550332961388
current state at start:  [-0.76613038 -1.76664706]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.76613038, -1.76664706]), 'currentState': array([5.93538756, 4.80399378]), 'targetState': array([-0.10955489, -1.21926406]), 'effectorPosition': array([ 0.68672598, -1.30818993])}
done in step count: 115
reward sum = 0.31480917318095203
running average episode reward sum: 0.9361177815930217
{'reset': False, 'endBeforeDone': False, 'stepCount': 116, 'initial state': array([-0.76613038, -1.76664706]), 'currentState': array([5.77270687, 4.25542752]), 'targetState': array([-0.10955489, -1.21926406]), 'effectorPosition': array([ 0.04907506, -1.05600421])}
episode index:3833
target Thresh 1.999156721540739
current state at start:  [-1.60204128  2.02114427]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.60204128,  2.02114427]), 'currentState': array([4.21492273, 2.52114427]), 'targetState': array([ 0.29011085, -0.10248734]), 'effectorPosition': array([ 0.4219895 , -0.44123595])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9361318353797736
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.60204128,  2.02114427]), 'currentState': array([4.03462972, 3.00880432]), 'targetState': array([ 0.29011085, -0.10248734]), 'effectorPosition': array([ 0.09761552, -0.08987801])}
episode index:3834
target Thresh 1.9991584064122245
current state at start:  [ 0.28229761 -2.28832109]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.28229761, -2.28832109]), 'currentState': array([0.76589304, 3.53289177]), 'targetState': array([ 0.02815843, -0.0069814 ]), 'effectorPosition': array([ 0.31885141, -0.22249727])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9361458818373016
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.28229761, -2.28832109]), 'currentState': array([1.1211462 , 3.13665314]), 'targetState': array([ 0.02815843, -0.0069814 ]), 'effectorPosition': array([-0.0044432 ,  0.00215794])}
episode index:3835
target Thresh 1.9991600879173343
current state at start:  [-1.89644074 -2.13753233]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.89644074, -2.13753233]), 'currentState': array([4.297936  , 4.03879664]), 'targetState': array([-1.15150848, -0.02730125]), 'effectorPosition': array([-0.86690684, -0.02961552])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9361599209713377
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.89644074, -2.13753233]), 'currentState': array([4.31143248, 4.14760334]), 'targetState': array([-1.15150848, -0.02730125]), 'effectorPosition': array([-0.9591058 , -0.09821682])}
episode index:3836
target Thresh 1.999161766062795
current state at start:  [ 3.71464448 -2.59256794]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.71464448, -2.59256794]), 'currentState': array([4.20100745, 3.1981831 ]), 'targetState': array([ 0.56548597, -0.58242525]), 'effectorPosition': array([-0.05010786,  0.02628358])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.936171372646873
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 3.71464448, -2.59256794]), 'currentState': array([4.5175529 , 2.29516764]), 'targetState': array([ 0.56548597, -0.58242525]), 'effectorPosition': array([ 0.66943622, -0.47594714])}
episode index:3837
target Thresh 1.9991634408553185
current state at start:  [-2.03928095  2.0975356 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.03928095,  2.0975356 ]), 'currentState': array([3.83078826, 2.5975356 ]), 'targetState': array([-0.14104514, -0.39564924]), 'effectorPosition': array([ 0.21772808, -0.49128706])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.936185397823359
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.03928095,  2.0975356 ]), 'currentState': array([3.37611869, 2.89415913]), 'targetState': array([-0.14104514, -0.39564924]), 'effectorPosition': array([ 0.02729211, -0.24528915])}
episode index:3838
target Thresh 1.9991651123016045
current state at start:  [-3.60067093  2.50937541]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.60067093,  2.50937541]), 'currentState': array([3.17935488, 2.77063121]), 'targetState': array([ 0.52682076, -0.74487471]), 'effectorPosition': array([-0.05428627, -0.36482121])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9361968368966012
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-3.60067093,  2.50937541]), 'currentState': array([4.17935488, 1.99471413]), 'targetState': array([ 0.52682076, -0.74487471]), 'effectorPosition': array([ 0.48590387, -0.97016916])}
episode index:3839
target Thresh 1.9991667804083384
current state at start:  [2.0415184  1.75548566]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.0415184 , 1.75548566]), 'currentState': array([2.43026502, 1.70283818]), 'targetState': array([-1.05734113, -0.01586533]), 'effectorPosition': array([-1.30492219, -0.18401382])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9362108481369926
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([2.0415184 , 1.75548566]), 'currentState': array([1.98679463, 2.07384365]), 'targetState': array([-1.05734113, -0.01586533]), 'effectorPosition': array([-1.01068247,  0.11969028])}
episode index:3840
target Thresh 1.999168445182193
current state at start:  [-0.27898564 -2.68933588]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.27898564, -2.68933588]), 'currentState': array([0.15176634, 3.09630752]), 'targetState': array([-0.16931363,  0.01451623]), 'effectorPosition': array([-0.00583065,  0.0449043 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9362274555704378
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.27898564, -2.68933588]), 'currentState': array([0.15176634, 3.09630752]), 'targetState': array([-0.16931363,  0.01451623]), 'effectorPosition': array([-0.00583065,  0.0449043 ])}
episode index:3841
target Thresh 1.999170106629827
current state at start:  [-0.21544622  2.10069005]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.21544622,  2.10069005]), 'currentState': array([5.64388157, 2.51291324]), 'targetState': array([0.8041413 , 0.01037567]), 'effectorPosition': array([0.5043048 , 0.35786453])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9362414515476448
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.21544622,  2.10069005]), 'currentState': array([5.32122193, 2.1581427 ]), 'targetState': array([0.8041413 , 0.01037567]), 'effectorPosition': array([0.93782662, 0.11033181])}
episode index:3842
target Thresh 1.9991717647578868
current state at start:  [ 3.52805759 -1.91340966]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.52805759, -1.91340966]), 'currentState': array([3.0645125 , 4.46467223]), 'targetState': array([-0.95666615,  0.83939582]), 'effectorPosition': array([-0.67791448,  1.0247194 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.936255440240971
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.52805759, -1.91340966]), 'currentState': array([3.38125814, 4.4190504 ]), 'targetState': array([-0.95666615,  0.83939582]), 'effectorPosition': array([-0.9177701 ,  0.76118226])}
episode index:3843
target Thresh 1.9991734195730042
current state at start:  [-0.40139459 -2.64340469]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.40139459, -2.64340469]), 'currentState': array([6.09869226, 3.17132507]), 'targetState': array([ 0.1588806 , -0.18409637]), 'effectorPosition': array([-0.00501908, -0.02930461])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9362720231129166
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.40139459, -2.64340469]), 'currentState': array([6.09869226, 3.17132507]), 'targetState': array([ 0.1588806 , -0.18409637]), 'effectorPosition': array([-0.00501908, -0.02930461])}
episode index:3844
target Thresh 1.999175071081799
current state at start:  [-3.84744486  3.00253217]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.84744486,  3.00253217]), 'currentState': array([2.27974432, 2.50253217]), 'targetState': array([-0.6939468 , -0.80339851]), 'effectorPosition': array([-0.58120498, -0.23851167])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.936285996578947
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.84744486,  3.00253217]), 'currentState': array([2.77685835, 2.105918  ]), 'targetState': array([-0.6939468 , -0.80339851]), 'effectorPosition': array([-0.76465445, -0.62881807])}
episode index:3845
target Thresh 1.999176719290877
current state at start:  [-0.08937172 -2.85245305]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.08937172, -2.85245305]), 'currentState': array([0.31984385, 2.93073226]), 'targetState': array([-0.4373769 ,  0.56281416]), 'effectorPosition': array([-0.04478265,  0.20565049])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9362999627784844
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.08937172, -2.85245305]), 'currentState': array([0.69477572, 2.4353701 ]), 'targetState': array([-0.4373769 ,  0.56281416]), 'effectorPosition': array([-0.23173718,  0.65165975])}
episode index:3846
target Thresh 1.9991783642068308
current state at start:  [-1.24075975 -2.82763852]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.24075975, -2.82763852]), 'currentState': array([4.89913467, 3.32690496]), 'targetState': array([-0.66538549, -0.04544202]), 'effectorPosition': array([-0.17787124, -0.05103247])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.9363013093307646
{'reset': False, 'endBeforeDone': False, 'stepCount': 7, 'initial state': array([-1.24075975, -2.82763852]), 'currentState': array([4.40916738, 3.58633173]), 'targetState': array([-0.66538549, -0.04544202]), 'effectorPosition': array([-0.43964196,  0.03562362])}
episode index:3847
target Thresh 1.9991800058362406
current state at start:  [-1.109872   -2.48003052]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.109872  , -2.48003052]), 'currentState': array([5.28625632, 3.30315479]), 'targetState': array([0.26911978, 0.34312051]), 'effectorPosition': array([-0.12802177, -0.09826506])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9363152642919572
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.109872  , -2.48003052]), 'currentState': array([5.4879267 , 2.80315479]), 'targetState': array([0.26911978, 0.34312051]), 'effectorPosition': array([0.27678637, 0.19193846])}
episode index:3848
target Thresh 1.9991816441856725
current state at start:  [0.60066519 2.77558123]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.60066519, 2.77558123]), 'currentState': array([0.10066519, 2.27558123]), 'targetState': array([0.31331457, 0.78345549]), 'effectorPosition': array([0.273795  , 0.79328198])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9363318100793586
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.60066519, 2.77558123]), 'currentState': array([0.10066519, 2.27558123]), 'targetState': array([0.31331457, 0.78345549]), 'effectorPosition': array([0.273795  , 0.79328198])}
episode index:3849
target Thresh 1.9991832792616802
current state at start:  [-0.25220266 -2.1801849 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.25220266, -2.1801849 ]), 'currentState': array([0.1962676 , 3.78128714]), 'targetState': array([ 0.57309584, -0.71813843]), 'effectorPosition': array([ 0.31033708, -0.54693194])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9363431784403771
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-0.25220266, -2.1801849 ]), 'currentState': array([0.30611202, 4.16197658]), 'targetState': array([ 0.57309584, -0.71813843]), 'effectorPosition': array([ 0.71163489, -0.6689531 ])}
episode index:3850
target Thresh 1.9991849110708038
current state at start:  [-1.8140011  -1.89793325]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.8140011 , -1.89793325]), 'currentState': array([4.56690221, 3.97143954]), 'targetState': array([-0.99245924, -0.20545527]), 'effectorPosition': array([-0.77715142, -0.21461173])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9363597083862507
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.8140011 , -1.89793325]), 'currentState': array([4.56690221, 3.97143954]), 'targetState': array([-0.99245924, -0.20545527]), 'effectorPosition': array([-0.77715142, -0.21461173])}
episode index:3851
target Thresh 1.9991865396195705
current state at start:  [1.45508096 1.87942378]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.45508096, 1.87942378]), 'currentState': array([1.06148264, 2.34810264]), 'targetState': array([-0.0569257 ,  0.20650246]), 'effectorPosition': array([-0.47672623,  0.60828309])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9363736336956
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.45508096, 1.87942378]), 'currentState': array([0.80928741, 2.84810264]), 'targetState': array([-0.0569257 ,  0.20650246]), 'effectorPosition': array([-0.17988532,  0.230567  ])}
episode index:3852
target Thresh 1.9991881649144947
current state at start:  [-4.08548639  2.17535244]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.08548639,  2.17535244]), 'currentState': array([2.69769892, 2.26768446]), 'targetState': array([-0.66791338, -0.86272448]), 'effectorPosition': array([-0.65278216, -0.53870816])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9363875517766549
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-4.08548639,  2.17535244]), 'currentState': array([3.19769892, 2.05753614]), 'targetState': array([-0.66791338, -0.86272448]), 'effectorPosition': array([-0.48185144, -0.91231877])}
episode index:3853
target Thresh 1.9991897869620774
current state at start:  [-3.69896772  1.63291426]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.69896772,  1.63291426]), 'currentState': array([2.13936661, 2.07490964]), 'targetState': array([-1.08062843,  0.24227566]), 'effectorPosition': array([-1.01619626, -0.03581417])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9364014626350418
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.69896772,  1.63291426]), 'currentState': array([1.73347158, 1.99103423]), 'targetState': array([-1.08062843,  0.24227566]), 'effectorPosition': array([-0.99682134,  0.43633918])}
episode index:3854
target Thresh 1.999191405768807
current state at start:  [-0.8371606   1.87089786]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.8371606 ,  1.87089786]), 'currentState': array([5.00514071, 2.28251857]), 'targetState': array([ 0.2701872 , -0.73096195]), 'effectorPosition': array([ 0.82512016, -0.11357353])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9364127981829964
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-0.8371606 ,  1.87089786]), 'currentState': array([4.08842247, 2.40211086]), 'targetState': array([ 0.2701872 , -0.73096195]), 'effectorPosition': array([ 0.39432147, -0.60570192])}
episode index:3855
target Thresh 1.9991930213411584
current state at start:  [-0.57418013  2.10569634]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.57418013,  2.10569634]), 'currentState': array([5.86614374, 2.14396097]), 'targetState': array([0.9785223 , 0.47539902]), 'effectorPosition': array([0.75880167, 0.58278016])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9364292886398992
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.57418013,  2.10569634]), 'currentState': array([5.86614374, 2.14396097]), 'targetState': array([0.9785223 , 0.47539902]), 'effectorPosition': array([0.75880167, 0.58278016])}
episode index:3856
target Thresh 1.9991946336855944
current state at start:  [-2.0948455   2.27935061]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.0948455 ,  2.27935061]), 'currentState': array([3.68833981, 1.88290867]), 'targetState': array([-0.17479035, -0.93162362]), 'effectorPosition': array([-0.09712227, -1.1732127 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9364431778572598
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.0948455 ,  2.27935061]), 'currentState': array([3.21925203, 2.22418305]), 'targetState': array([-0.17479035, -0.93162362]), 'effectorPosition': array([-0.32933723, -0.82205772])}
episode index:3857
target Thresh 1.9991962428085637
current state at start:  [ 0.38941526 -2.40144422]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.38941526, -2.40144422]), 'currentState': array([0.23480389, 3.40475414]), 'targetState': array([-0.20136414, -0.36649523]), 'effectorPosition': array([ 0.09400379, -0.24498674])}
done in step count: 55
reward sum = 0.5753547499769285
running average episode reward sum: 0.9363495831377471
{'reset': False, 'endBeforeDone': False, 'stepCount': 56, 'initial state': array([ 0.38941526, -2.40144422]), 'currentState': array([2.70004741, 2.69236848]), 'targetState': array([-0.20136414, -0.36649523]), 'effectorPosition': array([-0.27527846, -0.35021878])}
episode index:3858
target Thresh 1.9991978487165034
current state at start:  [-3.54554706  2.64060998]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.54554706,  2.64060998]), 'currentState': array([3.23763824, 2.46166414]), 'targetState': array([ 0.58680796, -1.0175333 ]), 'effectorPosition': array([-0.16106275, -0.64716571])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9363609203797431
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-3.54554706,  2.64060998]), 'currentState': array([4.23763824, 1.73532966]), 'targetState': array([ 0.58680796, -1.0175333 ]), 'effectorPosition': array([ 0.49515046, -1.19467237])}
episode index:3859
target Thresh 1.9991994514158369
current state at start:  [ 2.96360284 -2.48444077]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.96360284, -2.48444077]), 'currentState': array([2.59782129, 3.29874454]), 'targetState': array([-0.79997212,  0.2049971 ]), 'effectorPosition': array([0.07042541, 0.14030748])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9363722517475204
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 2.96360284, -2.48444077]), 'currentState': array([1.78175211, 2.29874454]), 'targetState': array([-0.79997212,  0.2049971 ]), 'effectorPosition': array([-0.80006735,  0.17092002])}
episode index:3860
target Thresh 1.9992010509129747
current state at start:  [-1.36064683  1.91146658]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.36064683,  1.91146658]), 'currentState': array([4.47920408, 2.14851199]), 'targetState': array([ 0.47644109, -0.70667982]), 'effectorPosition': array([ 0.71015665, -0.63518032])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9363887313507974
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.36064683,  1.91146658]), 'currentState': array([4.47920408, 2.14851199]), 'targetState': array([ 0.47644109, -0.70667982]), 'effectorPosition': array([ 0.71015665, -0.63518032])}
episode index:3861
target Thresh 1.9992026472143154
current state at start:  [ 4.66241771 -3.0694437 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.66241771, -3.0694437 ]), 'currentState': array([4.26518929, 3.71374161]), 'targetState': array([-0.89444084,  0.42390165]), 'effectorPosition': array([-0.5570667 ,  0.09054238])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9364026130878893
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 4.66241771, -3.0694437 ]), 'currentState': array([3.9059791 , 4.11544884]), 'targetState': array([-0.89444084,  0.42390165]), 'effectorPosition': array([-0.88847205,  0.29391933])}
episode index:3862
target Thresh 1.9992042403262438
current state at start:  [-1.51414    -2.10906496]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.51414   , -2.10906496]), 'currentState': array([4.99444317, 4.33947865]), 'targetState': array([ 0.00251584, -0.60654482]), 'effectorPosition': array([-0.71754617, -0.86975453])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9364113877156169
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-1.51414   , -2.10906496]), 'currentState': array([0.0286359 , 3.73043833]), 'targetState': array([ 0.00251584, -0.60654482]), 'effectorPosition': array([ 0.18425086, -0.55035164])}
episode index:3863
target Thresh 1.9992058302551325
current state at start:  [-3.92784399  2.06056106]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.92784399,  2.06056106]), 'currentState': array([1.85967484, 2.56056106]), 'targetState': array([-0.06947109,  0.08401308]), 'effectorPosition': array([-0.57289212,  0.00093799])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9364252564040964
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.92784399,  2.06056106]), 'currentState': array([1.40512481, 2.98502251]), 'targetState': array([-0.06947109,  0.08401308]), 'effectorPosition': array([-0.15177894,  0.03777995])}
episode index:3864
target Thresh 1.999207417007341
current state at start:  [ 3.276473   -2.23717977]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.276473  , -2.23717977]), 'currentState': array([2.82157434, 4.25789691]), 'targetState': array([0.15630819, 1.00580009]), 'effectorPosition': array([-0.24986346,  1.02934748])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9364391179160227
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.276473  , -2.23717977]), 'currentState': array([2.35708962, 4.31911832]), 'targetState': array([0.15630819, 1.00580009]), 'effectorPosition': array([0.21601622, 1.08945588])}
episode index:3865
target Thresh 1.9992090005892167
current state at start:  [1.29377855 1.57120238]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.29377855, 1.57120238]), 'currentState': array([1.71367006, 2.07120238]), 'targetState': array([-0.25500951,  0.24563478]), 'effectorPosition': array([-0.94252092,  0.38998797])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9364529722569652
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.29377855, 1.57120238]), 'currentState': array([1.21367006, 2.57120238]), 'targetState': array([-0.25500951,  0.24563478]), 'effectorPosition': array([-0.45054951,  0.33708237])}
episode index:3866
target Thresh 1.9992105810070935
current state at start:  [0.69692676 2.08525354]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.69692676, 2.08525354]), 'currentState': array([0.95146124, 2.57893968]), 'targetState': array([-0.42276461,  0.60004418]), 'effectorPosition': array([-0.34486761,  0.43517871])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9364694054164541
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.69692676, 2.08525354]), 'currentState': array([0.95146124, 2.57893968]), 'targetState': array([-0.42276461,  0.60004418]), 'effectorPosition': array([-0.34486761,  0.43517871])}
episode index:3867
target Thresh 1.9992121582672935
current state at start:  [0.12888124 2.69819325]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.12888124, 2.69819325]), 'currentState': array([0.24399707, 3.19819325]), 'targetState': array([-0.27955395, -0.41158089]), 'effectorPosition': array([ 0.01522041, -0.05450791])}
done in step count: 55
reward sum = 0.5753547499769285
running average episode reward sum: 0.9363760458881605
{'reset': False, 'endBeforeDone': False, 'stepCount': 56, 'initial state': array([0.12888124, 2.69819325]), 'currentState': array([5.94140859, 3.63855848]), 'targetState': array([-0.27955395, -0.41158089]), 'effectorPosition': array([-0.04582165, -0.48972851])}
episode index:3868
target Thresh 1.9992137323761252
current state at start:  [ 3.38939199 -2.59463157]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.38939199, -2.59463157]), 'currentState': array([2.88939199, 3.20831679]), 'targetState': array([0.69077028, 0.61437268]), 'effectorPosition': array([0.01448286, 0.0651207 ])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9363873469876984
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 3.38939199, -2.59463157]), 'currentState': array([1.88939199, 4.13769217]), 'targetState': array([0.69077028, 0.61437268]), 'effectorPosition': array([0.65415174, 0.69636544])}
episode index:3869
target Thresh 1.9992153033398856
current state at start:  [ 3.8462726  -1.90944395]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.8462726 , -1.90944395]), 'currentState': array([3.3462726, 3.9142684]), 'targetState': array([-0.24947872,  0.97379684]), 'effectorPosition': array([-0.4199094 ,  0.62576773])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9364012003864095
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.8462726 , -1.90944395]), 'currentState': array([2.8462726 , 4.38764259]), 'targetState': array([-0.24947872,  0.97379684]), 'effectorPosition': array([-0.3756198 ,  1.10488591])}
episode index:3870
target Thresh 1.9992168711648584
current state at start:  [-2.46802148  2.23412056]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.46802148,  2.23412056]), 'currentState': array([4.23386973, 2.49622123]), 'targetState': array([ 0.88954812, -0.21116685]), 'effectorPosition': array([ 0.44132348, -0.45550057])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9364099572450025
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-2.46802148,  2.23412056]), 'currentState': array([5.04766591, 2.20466898]), 'targetState': array([ 0.88954812, -0.21116685]), 'effectorPosition': array([ 0.89503152, -0.11991455])}
episode index:3871
target Thresh 1.9992184358573146
current state at start:  [-0.88832334  2.10102922]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.88832334,  2.10102922]), 'currentState': array([5.82235304, 2.40313905]), 'targetState': array([0.66446973, 0.94042607]), 'effectorPosition': array([0.53265944, 0.48708637])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9364237976486066
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.88832334,  2.10102922]), 'currentState': array([6.2369614 , 1.90899897]), 'targetState': array([0.66446973, 0.94042607]), 'effectorPosition': array([0.7110841 , 0.91146873])}
episode index:3872
target Thresh 1.9992199974235132
current state at start:  [-4.24669245  2.72140123]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.24669245,  2.72140123]), 'currentState': array([1.64266995, 3.0537238 ]), 'targetState': array([-0.00360202, -0.00974172]), 'effectorPosition': array([-0.08780631, -0.00245388])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9364402128828827
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.24669245,  2.72140123]), 'currentState': array([1.64266995, 3.0537238 ]), 'targetState': array([-0.00360202, -0.00974172]), 'effectorPosition': array([-0.08780631, -0.00245388])}
episode index:3873
target Thresh 1.9992215558697004
current state at start:  [-2.06345637 -1.67064717]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.06345637, -1.67064717]), 'currentState': array([4.45113962, 4.99592811]), 'targetState': array([-0.33760444, -0.95656304]), 'effectorPosition': array([-1.25803931, -0.98835597])}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.9364342957519072
{'reset': False, 'endBeforeDone': False, 'stepCount': 10, 'initial state': array([-2.06345637, -1.67064717]), 'currentState': array([3.12339817, 2.10361782]), 'targetState': array([-0.33760444, -0.95656304]), 'effectorPosition': array([-0.50762428, -0.85228289])}
episode index:3874
target Thresh 1.9992231112021102
current state at start:  [-0.95925153 -2.64747732]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.95925153, -2.64747732]), 'currentState': array([5.54570692, 3.37849553]), 'targetState': array([-0.16636798, -0.34596748]), 'effectorPosition': array([-0.13714   , -0.19249312])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9364506998046163
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.95925153, -2.64747732]), 'currentState': array([5.54570692, 3.37849553]), 'targetState': array([-0.16636798, -0.34596748]), 'effectorPosition': array([-0.13714   , -0.19249312])}
episode index:3875
target Thresh 1.9992246634269637
current state at start:  [ 2.33629647 -1.67970111]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.33629647, -1.67970111]), 'currentState': array([2.83629647, 4.1069503 ]), 'targetState': array([-0.26780405,  1.03271012]), 'effectorPosition': array([-0.16380342,  0.91374108])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.936467095392902
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.33629647, -1.67970111]), 'currentState': array([2.83629647, 4.1069503 ]), 'targetState': array([-0.26780405,  1.03271012]), 'effectorPosition': array([-0.16380342,  0.91374108])}
episode index:3876
target Thresh 1.99922621255047
current state at start:  [-0.01631812 -2.58979799]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.01631812, -2.58979799]), 'currentState': array([0.47108739, 3.19338732]), 'targetState': array([-0.10786396, -0.06670138]), 'effectorPosition': array([ 0.02469175, -0.04552367])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9364834825233139
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.01631812, -2.58979799]), 'currentState': array([0.47108739, 3.19338732]), 'targetState': array([-0.10786396, -0.06670138]), 'effectorPosition': array([ 0.02469175, -0.04552367])}
episode index:3877
target Thresh 1.9992277585788254
current state at start:  [-0.12439276  2.14627696]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.12439276,  2.14627696]), 'currentState': array([0.37560724, 1.70415205]), 'targetState': array([0.27344754, 1.34905412]), 'effectorPosition': array([0.44301312, 1.24008779])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9364998612023951
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.12439276,  2.14627696]), 'currentState': array([0.37560724, 1.70415205]), 'targetState': array([0.27344754, 1.34905412]), 'effectorPosition': array([0.44301312, 1.24008779])}
episode index:3878
target Thresh 1.9992293015182139
current state at start:  [ 3.92867502 -1.98173242]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.92867502, -1.98173242]), 'currentState': array([3.73363135, 3.87325291]), 'targetState': array([-0.77429102,  0.31962523]), 'effectorPosition': array([-0.58521417,  0.41157256])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9365162314366816
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.92867502, -1.98173242]), 'currentState': array([3.73363135, 3.87325291]), 'targetState': array([-0.77429102,  0.31962523]), 'effectorPosition': array([-0.58521417,  0.41157256])}
episode index:3879
target Thresh 1.9992308413748077
current state at start:  [-2.28061101  2.01661702]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.28061101,  2.01661702]), 'currentState': array([3.51874873, 2.27424934]), 'targetState': array([-0.67877336, -0.64757551]), 'effectorPosition': array([-0.04747102, -0.83906901])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9365300159131155
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.28061101,  2.01661702]), 'currentState': array([3.04254294, 2.05789786]), 'targetState': array([-0.67877336, -0.64757551]), 'effectorPosition': array([-0.61671278, -0.82676015])}
episode index:3880
target Thresh 1.9992323781547658
current state at start:  [ 0.72037889 -2.5515264 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.72037889, -2.5515264 ]), 'currentState': array([0.90667428, 3.23165891]), 'targetState': array([-0.13660228,  0.03857564]), 'effectorPosition': array([ 0.07332584, -0.05224719])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9365463699414811
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.72037889, -2.5515264 ]), 'currentState': array([0.90667428, 3.23165891]), 'targetState': array([-0.13660228,  0.03857564]), 'effectorPosition': array([ 0.07332584, -0.05224719])}
episode index:3881
target Thresh 1.9992339118642355
current state at start:  [0.74732771 2.67355149]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.74732771, 2.67355149]), 'currentState': array([0.59325749, 3.15083068]), 'targetState': array([ 0.32963579, -0.13947744]), 'effectorPosition': array([ 0.00519996, -0.00763551])}
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.9365311650607644
{'reset': False, 'endBeforeDone': False, 'stepCount': 14, 'initial state': array([0.74732771, 2.67355149]), 'currentState': array([5.19356473, 2.76572118]), 'targetState': array([ 0.32963579, -0.13947744]), 'effectorPosition': array([0.35771197, 0.10800925])}
episode index:3882
target Thresh 1.9992354425093517
current state at start:  [0.46421615 2.73253275]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.46421615, 2.73253275]), 'currentState': array([0.49195396, 3.23253275]), 'targetState': array([-0.05600644,  0.01852422]), 'effectorPosition': array([ 0.04653845, -0.07809338])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9365475103697881
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.46421615, 2.73253275]), 'currentState': array([0.49195396, 3.23253275]), 'targetState': array([-0.05600644,  0.01852422]), 'effectorPosition': array([ 0.04653845, -0.07809338])}
episode index:3883
target Thresh 1.999236970096237
current state at start:  [-1.09740357  1.6224367 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.09740357,  1.6224367 ]), 'currentState': array([4.86944961, 2.1224367 ]), 'targetState': array([0.82540517, 0.21333424]), 'effectorPosition': array([ 0.91562367, -0.33684321])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9365587236781379
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.09740357,  1.6224367 ]), 'currentState': array([5.50310544, 2.17110636]), 'targetState': array([0.82540517, 0.21333424]), 'effectorPosition': array([0.88966049, 0.28054868])}
episode index:3884
target Thresh 1.9992384946310016
current state at start:  [-3.35027097  1.70040093]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.35027097,  1.70040093]), 'currentState': array([2.47659879, 2.15707765]), 'targetState': array([-0.11552859, -0.50377557]), 'effectorPosition': array([-0.86555186, -0.37984946])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9365699312138707
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-3.35027097,  1.70040093]), 'currentState': array([2.90371412, 2.65821056]), 'targetState': array([-0.11552859, -0.50377557]), 'effectorPosition': array([-0.22086617, -0.42469046])}
episode index:3885
target Thresh 1.9992400161197437
current state at start:  [-0.15268256 -2.0606329 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.15268256, -2.0606329 ]), 'currentState': array([0.27008878, 3.75624969]), 'targetState': array([0.04893174, 0.02679632]), 'effectorPosition': array([ 0.33026101, -0.50693699])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9365836805882366
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.15268256, -2.0606329 ]), 'currentState': array([0.74784718, 3.27444701]), 'targetState': array([0.04893174, 0.02679632]), 'effectorPosition': array([ 0.09654434, -0.09112369])}
episode index:3886
target Thresh 1.9992415345685493
current state at start:  [-1.7434712  -2.05960535]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.7434712 , -2.05960535]), 'currentState': array([4.97642068, 4.38102634]), 'targetState': array([-0.15274674, -0.87022566]), 'effectorPosition': array([-0.73675948, -0.89806558])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9365948759366832
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.7434712 , -2.05960535]), 'currentState': array([5.92461453, 3.90337106]), 'targetState': array([-0.15274674, -0.87022566]), 'effectorPosition': array([ 0.0165922 , -0.74330702])}
episode index:3887
target Thresh 1.9992430499834921
current state at start:  [ 0.94337998 -1.87170408]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.94337998, -1.87170408]), 'currentState': array([0.47990245, 3.91148123]), 'targetState': array([ 0.27867649, -0.74526098]), 'effectorPosition': array([ 0.5715193 , -0.48722605])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9366086118225019
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.94337998, -1.87170408]), 'currentState': array([0.22038982, 3.82740493]), 'targetState': array([ 0.27867649, -0.74526098]), 'effectorPosition': array([ 0.35907253, -0.56855708])}
episode index:3888
target Thresh 1.9992445623706339
current state at start:  [ 1.82489556 -2.36574464]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.82489556, -2.36574464]), 'currentState': array([1.89468224, 3.41744067]), 'targetState': array([0.27997016, 0.2038232 ]), 'effectorPosition': array([0.24617003, 0.12252005])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9366249119994567
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.82489556, -2.36574464]), 'currentState': array([1.89468224, 3.41744067]), 'targetState': array([0.27997016, 0.2038232 ]), 'effectorPosition': array([0.24617003, 0.12252005])}
episode index:3889
target Thresh 1.999246071736024
current state at start:  [1.48610785 2.09763111]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.48610785, 2.09763111]), 'currentState': array([1.98610785, 1.64154653]), 'targetState': array([-1.22359503,  0.08059024]), 'effectorPosition': array([-1.28765445,  0.4478433 ])}
done in step count: 21
reward sum = 0.8097278682212584
running average episode reward sum: 0.9365922906514418
{'reset': False, 'endBeforeDone': False, 'stepCount': 22, 'initial state': array([1.48610785, 2.09763111]), 'currentState': array([2.31860667, 1.510187  ]), 'targetState': array([-1.22359503,  0.08059024]), 'effectorPosition': array([-1.45305963,  0.09880369])}
episode index:3890
target Thresh 1.9992475780857002
current state at start:  [1.47491529 2.28111391]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.47491529, 2.28111391]), 'currentState': array([1.2246468, 1.8326685]), 'targetState': array([-0.99835647,  0.96419584]), 'effectorPosition': array([-0.65717252,  1.02486369])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9366060166111818
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.47491529, 2.28111391]), 'currentState': array([1.59944864, 1.47549225]), 'targetState': array([-0.99835647,  0.96419584]), 'effectorPosition': array([-1.02642799,  1.06619197])}
episode index:3891
target Thresh 1.9992490814256876
current state at start:  [-0.2567085   2.95329498]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.2567085 ,  2.95329498]), 'currentState': array([6.1130789 , 3.45329498]), 'targetState': array([-0.76547923, -0.00801808]), 'effectorPosition': array([-0.00442528, -0.31041046])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.9366072689577362
{'reset': False, 'endBeforeDone': False, 'stepCount': 7, 'initial state': array([-0.2567085 ,  2.95329498]), 'currentState': array([1.73587433, 2.4439262 ]), 'targetState': array([-0.76547923, -0.00801808]), 'effectorPosition': array([-0.67209425,  0.1249099 ])}
episode index:3892
target Thresh 1.9992505817619999
current state at start:  [ 2.55477355 -1.80393456]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.55477355, -1.80393456]), 'currentState': array([2.05477355, 4.30873986]), 'targetState': array([0.41107425, 1.14453202]), 'effectorPosition': array([0.53147214, 0.96539305])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9366235527314434
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.55477355, -1.80393456]), 'currentState': array([2.05477355, 4.30873986]), 'targetState': array([0.41107425, 1.14453202]), 'effectorPosition': array([0.53147214, 0.96539305])}
episode index:3893
target Thresh 1.999252079100638
current state at start:  [-2.16596399  2.398496  ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.16596399,  2.398496  ]), 'currentState': array([3.70025139, 2.898496  ]), 'targetState': array([0.16254859, 0.09560523]), 'effectorPosition': array([ 0.10265528, -0.21969848])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9366347177153337
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-2.16596399,  2.398496  ]), 'currentState': array([4.36108538, 2.91205937]), 'targetState': array([0.16254859, 0.09560523]), 'effectorPosition': array([ 0.20460169, -0.10292119])}
episode index:3894
target Thresh 1.9992535734475918
current state at start:  [-1.17676794  1.77157196]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.17676794,  1.77157196]), 'currentState': array([5.17673677, 2.23830244]), 'targetState': array([ 1.18724349, -0.24632951]), 'effectorPosition': array([0.87282213, 0.01108778])}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.9366287825496773
{'reset': False, 'endBeforeDone': False, 'stepCount': 10, 'initial state': array([-1.17676794,  1.77157196]), 'currentState': array([5.17705131, 2.05363695]), 'targetState': array([ 1.18724349, -0.24632951]), 'effectorPosition': array([ 1.03183337, -0.08201245])}
episode index:3895
target Thresh 1.9992550648088383
current state at start:  [ 2.09663708 -3.05840902]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.09663708, -3.05840902]), 'currentState': array([1.73165576, 2.89020019]), 'targetState': array([0.01607008, 0.11328861]), 'effectorPosition': array([-0.25057602, -0.00881469])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9366424815274622
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 2.09663708, -3.05840902]), 'currentState': array([1.25267942, 3.10168538]), 'targetState': array([0.01607008, 0.11328861]), 'effectorPosition': array([-0.03764588,  0.01323507])}
episode index:3896
target Thresh 1.999256553190343
current state at start:  [ 3.88506304 -2.51952331]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.88506304, -2.51952331]), 'currentState': array([3.38506304, 3.94920607]), 'targetState': array([-0.19349589,  1.15002359]), 'effectorPosition': array([-0.47387657,  0.62688988])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9366511180474706
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 3.88506304, -2.51952331]), 'currentState': array([2.62037622, 4.35986085]), 'targetState': array([-0.19349589,  1.15002359]), 'effectorPosition': array([-0.10047595,  1.13989537])}
episode index:3897
target Thresh 1.9992580385980594
current state at start:  [-2.34261264 -1.58813558]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.34261264, -1.58813558]), 'currentState': array([3.8003064 , 4.21566634]), 'targetState': array([-0.94155567,  0.01460364]), 'effectorPosition': array([-0.95206377,  0.37480789])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9366648042665451
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.34261264, -1.58813558]), 'currentState': array([4.19931515, 3.91747426]), 'targetState': array([-0.94155567,  0.01460364]), 'effectorPosition': array([-0.75065055,  0.09442453])}
episode index:3898
target Thresh 1.9992595210379291
current state at start:  [-2.29914387 -1.59572843]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.29914387, -1.59572843]), 'currentState': array([3.96642483, 4.25221741]), 'targetState': array([-0.67830403, -0.18662505]), 'effectorPosition': array([-1.03531247,  0.19981096])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9366784834652455
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.29914387, -1.59572843]), 'currentState': array([4.34742743, 3.8421025 ]), 'targetState': array([-0.67830403, -0.18662505]), 'effectorPosition': array([-0.68620031,  0.01009242])}
episode index:3899
target Thresh 1.9992610005158822
current state at start:  [-0.44636774 -1.90020942]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.44636774, -1.90020942]), 'currentState': array([6.08642196, 3.92944656]), 'targetState': array([-0.18332955, -0.32279294]), 'effectorPosition': array([ 0.15037102, -0.75276304])}
done in step count: 44
reward sum = 0.6426116020847181
running average episode reward sum: 0.936603081700789
{'reset': False, 'endBeforeDone': False, 'stepCount': 45, 'initial state': array([-0.44636774, -1.90020942]), 'currentState': array([2.47587181, 2.60220576]), 'targetState': array([-0.18332955, -0.32279294]), 'effectorPosition': array([-0.42887934, -0.31625153])}
episode index:3900
target Thresh 1.9992624770378364
current state at start:  [ 0.72506116 -1.73736371]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.72506116, -1.73736371]), 'currentState': array([1.03466336, 4.05735384]), 'targetState': array([0.70746793, 0.29588459]), 'effectorPosition': array([ 0.88139055, -0.06911203])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.936616769708556
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.72506116, -1.73736371]), 'currentState': array([1.36807132, 3.92186661]), 'targetState': array([0.70746793, 0.29588459]), 'effectorPosition': array([0.74731136, 0.1417182 ])}
episode index:3901
target Thresh 1.9992639506096976
current state at start:  [0.48415779 2.43026198]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.48415779, 2.43026198]), 'currentState': array([0.56925415, 2.90843368]), 'targetState': array([-0.04950478, -0.1189588 ]), 'effectorPosition': array([-0.10174646,  0.20920069])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9366304507004297
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.48415779, 2.43026198]), 'currentState': array([0.6415173 , 3.39354793]), 'targetState': array([-0.04950478, -0.1189588 ]), 'effectorPosition': array([ 0.17447891, -0.18084097])}
episode index:3902
target Thresh 1.9992654212373604
current state at start:  [-3.16428507  1.90825757]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.16428507,  1.90825757]), 'currentState': array([2.61890024, 2.21262851]), 'targetState': array([-0.94309407, -0.02432767]), 'effectorPosition': array([-0.74762012, -0.49369638])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9366441246818028
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.16428507,  1.90825757]), 'currentState': array([2.13001656, 2.08064371]), 'targetState': array([-0.94309407, -0.02432767]), 'effectorPosition': array([-1.01146729, -0.02908341])}
episode index:3903
target Thresh 1.9992668889267071
current state at start:  [-2.77542017  2.09567965]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.77542017,  2.09567965]), 'currentState': array([3.01312801, 2.56541086]), 'targetState': array([ 0.17595636, -0.07191567]), 'effectorPosition': array([-0.22991914, -0.51965292])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9366577916580625
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.77542017,  2.09567965]), 'currentState': array([2.60356569, 3.03694017]), 'targetState': array([ 0.17595636, -0.07191567]), 'effectorPosition': array([-0.0582287 , -0.08689977])}
episode index:3904
target Thresh 1.9992683536836084
current state at start:  [ 1.67587624 -2.6596227 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.67587624, -2.6596227 ]), 'currentState': array([1.45481152, 3.12356261]), 'targetState': array([-0.04533697,  0.25969796]), 'effectorPosition': array([-0.01788913,  0.00224786])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9366689164233231
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 1.67587624, -2.6596227 ]), 'currentState': array([0.85455469, 3.08663977]), 'targetState': array([-0.04533697,  0.25969796]), 'effectorPosition': array([-0.04043784,  0.03720001])}
episode index:3905
target Thresh 1.9992698155139237
current state at start:  [-3.01378674  2.66660963]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.01378674,  2.66660963]), 'currentState': array([3.02724581, 3.13381966]), 'targetState': array([ 0.16233078, -0.02920509]), 'effectorPosition': array([-0.00091689, -0.00771871])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9366851302184016
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.01378674,  2.66660963]), 'currentState': array([3.02724581, 3.13381966]), 'targetState': array([ 0.16233078, -0.02920509]), 'effectorPosition': array([-0.00091689, -0.00771871])}
episode index:3906
target Thresh 1.9992712744235
current state at start:  [ 3.35293851 -1.6558    ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.35293851, -1.6558    ]), 'currentState': array([2.85293851, 4.33971491]), 'targetState': array([-0.19907512,  1.16810169]), 'effectorPosition': array([-0.34446226,  1.07383949])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9367013357136106
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.35293851, -1.6558    ]), 'currentState': array([2.85293851, 4.33971491]), 'targetState': array([-0.19907512,  1.16810169]), 'effectorPosition': array([-0.34446226,  1.07383949])}
episode index:3907
target Thresh 1.999272730418173
current state at start:  [ 2.28184889 -2.12439788]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.28184889, -2.12439788]), 'currentState': array([2.48688136, 3.65878743]), 'targetState': array([-0.050972  ,  0.06033337]), 'effectorPosition': array([0.19733573, 0.47184675])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9367149740616879
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 2.28184889, -2.12439788]), 'currentState': array([2.46976384, 3.15878743]), 'targetState': array([-0.050972  ,  0.06033337]), 'effectorPosition': array([0.01058611, 0.01354943])}
episode index:3908
target Thresh 1.9992741835037666
current state at start:  [-2.56111408  1.88704921]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.56111408,  1.88704921]), 'currentState': array([3.26525229, 2.16351725]), 'targetState': array([-0.64545631, -0.65409289]), 'effectorPosition': array([-0.33570465, -0.87753212])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9367260728148059
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-2.56111408,  1.88704921]), 'currentState': array([2.88510999, 2.14780636]), 'targetState': array([-0.64545631, -0.65409289]), 'effectorPosition': array([-0.65222113, -0.69538954])}
episode index:3909
target Thresh 1.9992756336860935
current state at start:  [ 1.08354918 -1.79197587]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.08354918, -1.79197587]), 'currentState': array([1.48778213, 4.51457499]), 'targetState': array([0.91026848, 0.69416608]), 'effectorPosition': array([1.04374512, 0.71940481])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9367422554048789
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.08354918, -1.79197587]), 'currentState': array([1.48778213, 4.51457499]), 'targetState': array([0.91026848, 0.69416608]), 'effectorPosition': array([1.04374512, 0.71940481])}
episode index:3910
target Thresh 1.999277080970954
current state at start:  [-3.0721042   2.94855525]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.0721042 ,  2.94855525]), 'currentState': array([2.71108111, 3.44855525]), 'targetState': array([0.91404322, 0.52735233]), 'effectorPosition': array([0.08362515, 0.29410085])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9367533415067953
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-3.0721042 ,  2.94855525]), 'currentState': array([1.71108111, 4.15216693]), 'targetState': array([0.91404322, 0.52735233]), 'effectorPosition': array([0.77328942, 0.58247304])}
episode index:3911
target Thresh 1.9992785253641374
current state at start:  [-2.60173078  1.65878812]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.60173078,  1.65878812]), 'currentState': array([3.18145452, 2.15878812]), 'targetState': array([ 0.08176992, -0.42956793]), 'effectorPosition': array([-0.41179651, -0.84914146])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9367644219409705
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-2.60173078,  1.65878812]), 'currentState': array([3.3590264 , 2.67808487]), 'targetState': array([ 0.08176992, -0.42956793]), 'effectorPosition': array([-0.00657802, -0.45932266])}
episode index:3912
target Thresh 1.9992799668714214
current state at start:  [-0.07600368  2.05619754]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.07600368,  2.05619754]), 'currentState': array([5.70718163, 2.55006973]), 'targetState': array([0.65388313, 0.16622456]), 'effectorPosition': array([0.44621817, 0.37510599])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9367780267398611
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.07600368,  2.05619754]), 'currentState': array([5.50011395, 2.37579655]), 'targetState': array([0.65388313, 0.16622456]), 'effectorPosition': array([0.68682305, 0.2943    ])}
episode index:3913
target Thresh 1.9992814054985717
current state at start:  [ 3.30853734 -1.77308585]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.30853734, -1.77308585]), 'currentState': array([3.54614553, 4.07846918]), 'targetState': array([-0.41673404,  0.02949698]), 'effectorPosition': array([-0.6919174 ,  0.58020276])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9367916245868871
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.30853734, -1.77308585]), 'currentState': array([3.92194337, 3.65656953]), 'targetState': array([-0.41673404,  0.02949698]), 'effectorPosition': array([-0.43866881,  0.2587691 ])}
episode index:3914
target Thresh 1.9992828412513433
current state at start:  [ 3.19239541 -2.46291246]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.19239541, -2.46291246]), 'currentState': array([3.27104752, 3.32027284]), 'targetState': array([-0.30310273, -0.28417325]), 'effectorPosition': array([-0.03873158,  0.17418847])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9368052154873758
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.19239541, -2.46291246]), 'currentState': array([2.8742915 , 2.82027284]), 'targetState': array([-0.30310273, -0.28417325]), 'effectorPosition': array([-0.13278012, -0.2910852 ])}
episode index:3915
target Thresh 1.9992842741354788
current state at start:  [-0.79014787 -1.75051173]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.79014787, -1.75051173]), 'currentState': array([5.46852668, 4.03267358]), 'targetState': array([-0.76770253, -0.95111156]), 'effectorPosition': array([-0.31096446, -0.80383935])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9365659904578847
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([-0.79014787, -1.75051173]), 'currentState': array([5.59505016, 3.78515216]), 'targetState': array([-0.76770253, -0.95111156]), 'effectorPosition': array([-0.22657495, -0.59053693])}
episode index:3916
target Thresh 1.99928570415671
current state at start:  [-1.67149479  2.32984344]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.67149479,  2.32984344]), 'currentState': array([4.11169052, 2.60070914]), 'targetState': array([-0.25593284, -0.66443364]), 'effectorPosition': array([ 0.34407418, -0.40878448])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9365771045782681
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.67149479,  2.32984344]), 'currentState': array([3.11169052, 2.32293715]), 'targetState': array([-0.25593284, -0.66443364]), 'effectorPosition': array([-0.33848689, -0.72043001])}
episode index:3917
target Thresh 1.9992871313207567
current state at start:  [-1.32043515 -2.28635437]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.32043515, -2.28635437]), 'currentState': array([5.35203757, 3.49683094]), 'targetState': array([-0.12718231,  0.4384188 ]), 'effectorPosition': array([-0.24178382, -0.2577078 ])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9365857114938939
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-1.32043515, -2.28635437]), 'currentState': array([6.24803684, 2.84233963]), 'targetState': array([-0.12718231,  0.4384188 ]), 'effectorPosition': array([0.05477544, 0.29306264])}
episode index:3918
target Thresh 1.999288555633328
current state at start:  [ 2.5342715  -2.31128722]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.5342715 , -2.31128722]), 'currentState': array([2.52374989, 3.47869242]), 'targetState': array([0.01066881, 0.02656344]), 'effectorPosition': array([0.14571985, 0.30220845])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9365993410648319
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 2.5342715 , -2.31128722]), 'currentState': array([2.49667088, 3.03874544]), 'targetState': array([0.01066881, 0.02656344]), 'effectorPosition': array([-0.065939  , -0.07886873])}
episode index:3919
target Thresh 1.9992899771001207
current state at start:  [ 0.23071414 -2.01112245]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.23071414, -2.01112245]), 'currentState': array([0.73071414, 3.81099393]), 'targetState': array([0.49650887, 0.16731807]), 'effectorPosition': array([ 0.57484457, -0.31806772])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9366104381717032
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 0.23071414, -2.01112245]), 'currentState': array([1.28367206, 3.54559522]), 'targetState': array([0.49650887, 0.16731807]), 'effectorPosition': array([ 0.39980777, -0.03411527])}
episode index:3920
target Thresh 1.9992913957268208
current state at start:  [ 2.72431228 -1.93568609]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.72431228, -1.93568609]), 'currentState': array([3.14567328, 4.63777062]), 'targetState': array([-0.6069493 ,  1.16575946]), 'effectorPosition': array([-0.92951242,  0.99343263])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9366240544843347
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 2.72431228, -1.93568609]), 'currentState': array([2.65517706, 4.84474169]), 'targetState': array([-0.6069493 ,  1.16575946]), 'effectorPosition': array([-0.53730257,  1.40543204])}
episode index:3921
target Thresh 1.999292811519103
current state at start:  [ 1.99104747 -1.81059425]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.99104747, -1.81059425]), 'currentState': array([2.23096188, 3.99343292]), 'targetState': array([0.00625107, 0.12502198]), 'effectorPosition': array([0.3850247 , 0.73113407])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9366351396310751
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 1.99104747, -1.81059425]), 'currentState': array([2.51366917, 3.08112911]), 'targetState': array([0.00625107, 0.12502198]), 'effectorPosition': array([-0.0369774 , -0.04782675])}
episode index:3922
target Thresh 1.9992942244826304
current state at start:  [-1.76598311  2.29410429]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.76598311,  2.29410429]), 'currentState': array([4.08391744, 2.79410429]), 'targetState': array([-0.16040178, -0.1729853 ]), 'effectorPosition': array([ 0.24033114, -0.24855377])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9366462191264534
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.76598311,  2.29410429]), 'currentState': array([3.64380435, 3.03320427]), 'targetState': array([-0.16040178, -0.1729853 ]), 'effectorPosition': array([ 0.04692865, -0.09764346])}
episode index:3923
target Thresh 1.9992956346230546
current state at start:  [-0.12700524 -2.60743445]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.12700524, -2.60743445]), 'currentState': array([0.23773496, 3.29561052]), 'targetState': array([-0.07518555, -0.34271628]), 'effectorPosition': array([ 0.04763265, -0.14630714])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9366623643305496
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.12700524, -2.60743445]), 'currentState': array([0.23773496, 3.29561052]), 'targetState': array([-0.07518555, -0.34271628]), 'effectorPosition': array([ 0.04763265, -0.14630714])}
episode index:3924
target Thresh 1.9992970419460163
current state at start:  [0.16901532 2.58579465]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.16901532, 2.58579465]), 'currentState': array([6.01826385, 3.08579465]), 'targetState': array([ 0.07292176, -0.16033559]), 'effectorPosition': array([0.01610421, 0.05341595])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9366785013077903
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.16901532, 2.58579465]), 'currentState': array([6.01826385, 3.08579465]), 'targetState': array([ 0.07292176, -0.16033559]), 'effectorPosition': array([0.01610421, 0.05341595])}
episode index:3925
target Thresh 1.999298446457145
current state at start:  [-0.59324161  2.76152468]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.59324161,  2.76152468]), 'currentState': array([5.53924927, 2.5930712 ]), 'targetState': array([0.39941176, 0.12525287]), 'effectorPosition': array([0.46105003, 0.28432386])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9366946300644617
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.59324161,  2.76152468]), 'currentState': array([5.53924927, 2.5930712 ]), 'targetState': array([0.39941176, 0.12525287]), 'effectorPosition': array([0.46105003, 0.28432386])}
episode index:3926
target Thresh 1.9992998481620585
current state at start:  [ 1.85666388 -2.20247097]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.85666388, -2.20247097]), 'currentState': array([1.65532952, 3.61411225]), 'targetState': array([ 0.05806351, -0.10693442]), 'effectorPosition': array([0.4442543 , 0.14761225])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9367082041337094
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.85666388, -2.20247097]), 'currentState': array([1.42857991, 3.12016525]), 'targetState': array([ 0.05806351, -0.10693442]), 'effectorPosition': array([-0.02117692,  0.00326407])}
episode index:3927
target Thresh 1.9993012470663638
current state at start:  [-0.64906923  2.1371482 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.64906923,  2.1371482 ]), 'currentState': array([6.11015775, 2.43188777]), 'targetState': array([0.42014226, 1.22710429]), 'effectorPosition': array([0.35002527, 0.60031149])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9367217712915163
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.64906923,  2.1371482 ]), 'currentState': array([0.3053302 , 1.93188777]), 'targetState': array([0.42014226, 1.22710429]), 'effectorPosition': array([0.33557052, 1.08664687])}
episode index:3928
target Thresh 1.9993026431756564
current state at start:  [-0.75880235  2.13692691]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.75880235,  2.13692691]), 'currentState': array([5.02508912, 2.49565133]), 'targetState': array([ 0.29177884, -0.59998919]), 'effectorPosition': array([ 0.63473657, -0.00651931])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9367328118180394
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-0.75880235,  2.13692691]), 'currentState': array([4.092668  , 2.53453621]), 'targetState': array([ 0.29177884, -0.59998919]), 'effectorPosition': array([ 0.36059876, -0.47676732])}
episode index:3929
target Thresh 1.9993040364955208
current state at start:  [1.50257482 2.98322575]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.50257482, 2.98322575]), 'currentState': array([1.34492963, 2.48322575]), 'targetState': array([-0.4977356 ,  0.65881535]), 'effectorPosition': array([-0.54947828,  0.34071793])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9367438467259738
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([1.50257482, 2.98322575]), 'currentState': array([0.92758355, 2.33086413]), 'targetState': array([-0.4977356 ,  0.65881535]), 'effectorPosition': array([-0.3934109,  0.6835837])}
episode index:3930
target Thresh 1.9993054270315302
current state at start:  [-3.73200243  1.83540846]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.73200243,  1.83540846]), 'currentState': array([2.05118288, 2.25195975]), 'targetState': array([-0.29437305,  0.18873556]), 'effectorPosition': array([-0.86004004, -0.03060462])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9367573944627516
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.73200243,  1.83540846]), 'currentState': array([1.55118288, 2.58817113]), 'targetState': array([-0.29437305,  0.18873556]), 'effectorPosition': array([-0.52257251,  0.15954833])}
episode index:3931
target Thresh 1.999306814789247
current state at start:  [-3.84501242  2.31629954]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.84501242,  2.31629954]), 'currentState': array([2.90468485, 2.1578945 ]), 'targetState': array([-0.38442783, -1.14391846]), 'effectorPosition': array([-0.62899172, -0.70460949])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9367709353085139
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.84501242,  2.31629954]), 'currentState': array([3.35224409, 1.79479275]), 'targetState': array([-0.38442783, -1.14391846]), 'effectorPosition': array([-0.55680388, -1.11611536])}
episode index:3932
target Thresh 1.999308199774222
current state at start:  [ 0.22779994 -2.72445793]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.22779994, -2.72445793]), 'currentState': array([6.03518548, 3.91126489]), 'targetState': array([-0.11005788, -1.21165433]), 'effectorPosition': array([ 0.10241835, -0.74379626])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9367844692685167
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.22779994, -2.72445793]), 'currentState': array([5.7635883, 4.1788938]), 'targetState': array([-0.11005788, -1.21165433]), 'effectorPosition': array([-9.38311684e-04, -9.91416807e-01])}
episode index:3933
target Thresh 1.9993095819919948
current state at start:  [ 1.1506551  -2.71875121]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.1506551 , -2.71875121]), 'currentState': array([0.6506551, 3.0644341]), 'targetState': array([-0.36638259, -0.51717148]), 'effectorPosition': array([-0.04432182,  0.0631353 ])}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.936778554875587
{'reset': False, 'endBeforeDone': False, 'stepCount': 10, 'initial state': array([ 1.1506551 , -2.71875121]), 'currentState': array([5.7252215 , 3.72188942]), 'targetState': array([-0.36638259, -0.51717148]), 'effectorPosition': array([-0.15141568, -0.55179103])}
episode index:3934
target Thresh 1.999310961448095
current state at start:  [ 0.72695534 -2.69363396]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.72695534, -2.69363396]), 'currentState': array([1.19973411, 3.31467446]), 'targetState': array([0.24052972, 0.37538429]), 'effectorPosition': array([ 0.16591596, -0.0485231 ])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9367870734131029
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 0.72695534, -2.69363396]), 'currentState': array([0.07951288, 2.7228805 ]), 'targetState': array([0.24052972, 0.37538429]), 'effectorPosition': array([0.05381912, 0.41216122])}
episode index:3935
target Thresh 1.99931233814804
current state at start:  [-1.60962113 -2.53617502]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.60962113, -2.53617502]), 'currentState': array([4.26826091, 4.05663674]), 'targetState': array([-1.13575487,  0.38167949]), 'effectorPosition': array([-0.88337349, -0.01183259])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9368005929574592
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.60962113, -2.53617502]), 'currentState': array([3.88392116, 4.242763  ]), 'targetState': array([-1.13575487,  0.38167949]), 'effectorPosition': array([-1.00623155,  0.28704092])}
episode index:3936
target Thresh 1.9993137120973365
current state at start:  [-0.47670966 -1.86833428]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.47670966, -1.86833428]), 'currentState': array([5.94919255, 3.92780413]), 'targetState': array([-0.47368729, -0.67102074]), 'effectorPosition': array([ 0.04526116, -0.76478005])}
done in step count: 134
reward sum = 0.26008546137772603
running average episode reward sum: 0.936628706970266
{'reset': False, 'endBeforeDone': False, 'stepCount': 135, 'initial state': array([-0.47670966, -1.86833428]), 'currentState': array([5.59899501, 3.85971192]), 'targetState': array([-0.47368729, -0.67102074]), 'effectorPosition': array([-0.2244934 , -0.66596821])}
episode index:3937
target Thresh 1.9993150833014808
current state at start:  [-0.0429787   2.80624376]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.0429787 ,  2.80624376]), 'currentState': array([0.27325857, 3.23121227]), 'targetState': array([-0.72845476,  0.32121637]), 'effectorPosition': array([ 0.02801758, -0.08509593])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9366372570700704
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-0.0429787 ,  2.80624376]), 'currentState': array([1.61982543, 2.11804183]), 'targetState': array([-0.72845476,  0.32121637]), 'effectorPosition': array([-0.87644286,  0.43723446])}
episode index:3938
target Thresh 1.9993164517659572
current state at start:  [-3.64902878  2.08634835]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.64902878,  2.08634835]), 'currentState': array([2.13415653, 2.55997151]), 'targetState': array([-0.0555929 , -0.06502085]), 'effectorPosition': array([-0.55229007, -0.15436784])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.93665080435185
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.64902878,  2.08634835]), 'currentState': array([1.67638708, 2.96635818]), 'targetState': array([-0.0555929 , -0.06502085]), 'effectorPosition': array([-0.17498208, -0.00314538])}
episode index:3939
target Thresh 1.9993178174962396
current state at start:  [ 3.49378544 -2.201917  ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.49378544, -2.201917  ]), 'currentState': array([3.40070386, 3.6334846 ]), 'targetState': array([ 0.15100409, -0.25998875]), 'effectorPosition': array([-0.23561338,  0.42615088])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9366618320664816
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 3.49378544, -2.201917  ]), 'currentState': array([4.10212193, 2.77801874]), 'targetState': array([ 0.15100409, -0.25998875]), 'effectorPosition': array([ 0.25396459, -0.25736799])}
episode index:3940
target Thresh 1.9993191804977912
current state at start:  [-2.52429977  1.9912714 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.52429977,  1.9912714 ]), 'currentState': array([3.27714413, 2.3076021 ]), 'targetState': array([-0.72468775, -0.49256786]), 'effectorPosition': array([-0.22498013, -0.7781598 ])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9366728541847089
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-2.52429977,  1.9912714 ]), 'currentState': array([2.38835928, 2.20980876]), 'targetState': array([-0.72468775, -0.49256786]), 'effectorPosition': array([-0.8434538 , -0.30948286])}
episode index:3941
target Thresh 1.999320540776064
current state at start:  [-1.79742664  2.23130188]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.79742664,  2.23130188]), 'currentState': array([4.02812437, 2.06064353]), 'targetState': array([-0.10085322, -0.95093768]), 'effectorPosition': array([ 0.34905704, -0.96807905])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9366863821263159
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.79742664,  2.23130188]), 'currentState': array([3.58908969, 2.10830725]), 'targetState': array([-0.10085322, -0.95093768]), 'effectorPosition': array([-0.06825649, -0.98556687])}
episode index:3942
target Thresh 1.9993218983364989
current state at start:  [-1.57161535  2.28061134]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.57161535,  2.28061134]), 'currentState': array([5.21156996, 1.96244413]), 'targetState': array([1.38165798, 0.20229174]), 'effectorPosition': array([ 1.10747441, -0.10038181])}
done in step count: 20
reward sum = 0.8179069375972308
running average episode reward sum: 0.9366562579963315
{'reset': False, 'endBeforeDone': False, 'stepCount': 21, 'initial state': array([-1.57161535,  2.28061134]), 'currentState': array([5.61249671, 1.85604059]), 'targetState': array([1.38165798, 0.20229174]), 'effectorPosition': array([1.15936478, 0.30510589])}
episode index:3943
target Thresh 1.9993232531845262
current state at start:  [-0.50035211  2.07038942]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.50035211,  2.07038942]), 'currentState': array([5.28283319, 2.53954116]), 'targetState': array([-0.06648362, -0.17271362]), 'effectorPosition': array([0.571608  , 0.15783935])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9366647881033303
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-0.50035211,  2.07038942]), 'currentState': array([4.0355635 , 3.16293244]), 'targetState': array([-0.06648362, -0.17271362]), 'effectorPosition': array([-0.01677709,  0.01318706])}
episode index:3944
target Thresh 1.9993246053255656
current state at start:  [-0.1451023  -1.88316343]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.1451023 , -1.88316343]), 'currentState': array([6.00942138, 3.90002187]), 'targetState': array([-0.28607962, -0.29410316]), 'effectorPosition': array([ 0.07792917, -0.73626933])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9366733138858137
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-0.1451023 , -1.88316343]), 'currentState': array([5.8289512 , 3.53027081]), 'targetState': array([-0.28607962, -0.29410316]), 'effectorPosition': array([-0.09925463, -0.37326521])}
episode index:3945
target Thresh 1.999325954765025
current state at start:  [-2.51940401  2.27717667]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.51940401,  2.27717667]), 'currentState': array([3.48649811, 2.63141846]), 'targetState': array([ 0.1799259 , -0.41471107]), 'effectorPosition': array([ 0.04526676, -0.50262512])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9366893622097149
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.51940401,  2.27717667]), 'currentState': array([3.48649811, 2.63141846]), 'targetState': array([ 0.1799259 , -0.41471107]), 'effectorPosition': array([ 0.04526676, -0.50262512])}
episode index:3946
target Thresh 1.9993273015083028
current state at start:  [2.1957246  1.59284526]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.1957246 , 1.59284526]), 'currentState': array([1.89205067, 2.04055131]), 'targetState': array([-0.44090204, -0.33659958]), 'effectorPosition': array([-1.01888496,  0.23777677])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9367028688319065
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([2.1957246 , 1.59284526]), 'currentState': array([2.39205067, 2.41147402]), 'targetState': array([-0.44090204, -0.33659958]), 'effectorPosition': array([-0.64099139, -0.31454645])}
episode index:3947
target Thresh 1.9993286455607857
current state at start:  [-1.38063671  2.43198456]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.38063671,  2.43198456]), 'currentState': array([4.42625372, 2.82385327]), 'targetState': array([ 0.25111393, -0.2495118 ]), 'effectorPosition': array([ 0.28558937, -0.13620021])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9367189015399024
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.38063671,  2.43198456]), 'currentState': array([4.42625372, 2.82385327]), 'targetState': array([ 0.25111393, -0.2495118 ]), 'effectorPosition': array([ 0.28558937, -0.13620021])}
episode index:3948
target Thresh 1.99932998692785
current state at start:  [-2.32962447  2.68421401]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.32962447,  2.68421401]), 'currentState': array([3.46703781, 2.18561883]), 'targetState': array([-0.24121594, -0.92990033]), 'effectorPosition': array([-0.13979256, -0.90930246])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9367349261280159
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.32962447,  2.68421401]), 'currentState': array([3.46703781, 2.18561883]), 'targetState': array([-0.24121594, -0.92990033]), 'effectorPosition': array([-0.13979256, -0.90930246])}
episode index:3949
target Thresh 1.999331325614861
current state at start:  [-1.32302313 -2.7079027 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.32302313, -2.7079027 ]), 'currentState': array([5.35485097, 3.34517816]), 'targetState': array([-0.56996474, -0.16517268]), 'effectorPosition': array([-0.14949758, -0.13767562])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9364977780454519
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([-1.32302313, -2.7079027 ]), 'currentState': array([5.79276073, 3.4636307 ]), 'targetState': array([-0.56996474, -0.16517268]), 'effectorPosition': array([-0.10372349, -0.30340855])}
episode index:3950
target Thresh 1.9993326616271736
current state at start:  [0.31863251 2.27663259]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.31863251, 2.27663259]), 'currentState': array([0.16636595, 2.69876573]), 'targetState': array([-0.12834075,  0.46006995]), 'effectorPosition': array([0.02416563, 0.4385523 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9365138504883662
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.31863251, 2.27663259]), 'currentState': array([0.16636595, 2.69876573]), 'targetState': array([-0.12834075,  0.46006995]), 'effectorPosition': array([0.02416563, 0.4385523 ])}
episode index:3951
target Thresh 1.9993339949701319
current state at start:  [-2.78187078  2.38385869]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.78187078,  2.38385869]), 'currentState': array([4.00131452, 2.64494271]), 'targetState': array([ 0.73792015, -0.31006674]), 'effectorPosition': array([ 0.28216203, -0.4025135 ])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9365223993622305
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-2.78187078,  2.38385869]), 'currentState': array([4.94491524, 2.09953837]), 'targetState': array([ 0.73792015, -0.31006674]), 'effectorPosition': array([ 0.9543982 , -0.28324716])}
episode index:3952
target Thresh 1.9993353256490691
current state at start:  [0.04007321 1.78097076]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.04007321, 1.78097076]), 'currentState': array([6.06809756, 2.16267777]), 'targetState': array([0.50205799, 0.7453881 ]), 'effectorPosition': array([0.60901668, 0.71641599])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9365384574448609
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.04007321, 1.78097076]), 'currentState': array([6.06809756, 2.16267777]), 'targetState': array([0.50205799, 0.7453881 ]), 'effectorPosition': array([0.60901668, 0.71641599])}
episode index:3953
target Thresh 1.999336653669308
current state at start:  [-0.22357718 -2.4404962 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.22357718, -2.4404962 ]), 'currentState': array([0.23243858, 3.37864397]), 'targetState': array([-0.04064629, -0.30517954]), 'effectorPosition': array([ 0.08130837, -0.22208023])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9365545074050416
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.22357718, -2.4404962 ]), 'currentState': array([0.23243858, 3.37864397]), 'targetState': array([-0.04064629, -0.30517954]), 'effectorPosition': array([ 0.08130837, -0.22208023])}
episode index:3954
target Thresh 1.9993379790361607
current state at start:  [-3.34239885  2.11944672]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.34239885,  2.11944672]), 'currentState': array([2.49090896, 1.90152809]), 'targetState': array([-0.78240961, -0.53673104]), 'effectorPosition': array([-1.11019078, -0.34352   ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9365680208039279
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.34239885,  2.11944672]), 'currentState': array([2.8887573 , 2.07026821]), 'targetState': array([-0.78240961, -0.53673104]), 'effectorPosition': array([-0.72406339, -0.7195889 ])}
episode index:3955
target Thresh 1.9993393017549288
current state at start:  [-2.27203492  2.85214432]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.27203492,  2.85214432]), 'currentState': array([3.53666862, 3.28821524]), 'targetState': array([-0.12686137, -0.23576816]), 'effectorPosition': array([-0.06613317,  0.13071381])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9365815273709642
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.27203492,  2.85214432]), 'currentState': array([3.40006983, 2.91786479]), 'targetState': array([-0.12686137, -0.23576816]), 'effectorPosition': array([ 0.03261596, -0.22086629])}
episode index:3956
target Thresh 1.9993406218309029
current state at start:  [-0.27369632 -2.64525807]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.27369632, -2.64525807]), 'currentState': array([5.76726487, 3.1893399 ]), 'targetState': array([-0.84016187, -0.12324204]), 'effectorPosition': array([-0.02255513, -0.04207889])}
done in step count: 199
reward sum = 0.0
running average episode reward sum: 0.9363448375738019
{'reset': False, 'endBeforeDone': False, 'stepCount': 200, 'initial state': array([-0.27369632, -2.64525807]), 'currentState': array([4.89501531, 3.71664555]), 'targetState': array([-0.84016187, -0.12324204]), 'effectorPosition': array([-0.50562456, -0.25693722])}
episode index:3957
target Thresh 1.9993419392693637
current state at start:  [-4.12383781  2.5071699 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.12383781,  2.5071699 ]), 'currentState': array([2.5958549 , 2.66120988]), 'targetState': array([-0.37623084, -0.19467989]), 'effectorPosition': array([-0.33660376, -0.33624649])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.936360920232323
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.12383781,  2.5071699 ]), 'currentState': array([2.5958549 , 2.66120988]), 'targetState': array([-0.37623084, -0.19467989]), 'effectorPosition': array([-0.33660376, -0.33624649])}
episode index:3958
target Thresh 1.9993432540755804
current state at start:  [-0.5625106  -2.64496716]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.5625106 , -2.64496716]), 'currentState': array([6.1117077 , 3.13821815]), 'targetState': array([0.50377619, 0.47291188]), 'effectorPosition': array([0.00058143, 0.00332403])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9363744688758611
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.5625106 , -2.64496716]), 'currentState': array([5.93651675, 2.63821815]), 'targetState': array([0.50377619, 0.47291188]), 'effectorPosition': array([0.28055905, 0.41154238])}
episode index:3959
target Thresh 1.9993445662548126
current state at start:  [0.17452161 2.16502329]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.17452161, 2.16502329]), 'currentState': array([5.95770692, 2.62297742]), 'targetState': array([0.2593165 , 0.41116917]), 'effectorPosition': array([0.28308891, 0.42760712])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9363905359291753
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.17452161, 2.16502329]), 'currentState': array([5.95770692, 2.62297742]), 'targetState': array([0.2593165 , 0.41116917]), 'effectorPosition': array([0.28308891, 0.42760712])}
episode index:3960
target Thresh 1.9993458758123088
current state at start:  [ 0.48298303 -2.16504804]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.48298303, -2.16504804]), 'currentState': array([6.26616834, 3.65769186]), 'targetState': array([-0.16382103, -0.845329  ]), 'effectorPosition': array([ 0.12183303, -0.49563607])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9364040702548685
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.48298303, -2.16504804]), 'currentState': array([5.77029334, 3.92503964]), 'targetState': array([-0.16382103, -0.845329  ]), 'effectorPosition': array([-0.09229364, -0.75796546])}
episode index:3961
target Thresh 1.9993471827533076
current state at start:  [ 3.55413338 -1.58405917]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.55413338, -1.58405917]), 'currentState': array([3.05413338, 4.26926886]), 'targetState': array([-0.35749336, -0.15748234]), 'effectorPosition': array([-0.49014471,  0.94986184])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9364101762467273
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([ 3.55413338, -1.58405917]), 'currentState': array([2.37007802, 2.52525999]), 'targetState': array([-0.35749336, -0.15748234]), 'effectorPosition': array([-0.53492528, -0.28608964])}
episode index:3962
target Thresh 1.9993484870830365
current state at start:  [1.58952498 2.37753926]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.58952498, 2.37753926]), 'currentState': array([1.08952498, 2.79660274]), 'targetState': array([0.20834834, 0.84331092]), 'effectorPosition': array([-0.27249655,  0.20877716])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9364187275522416
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([1.58952498, 2.37753926]), 'currentState': array([0.04454464, 2.21427019]), 'targetState': array([0.20834834, 0.84331092]), 'effectorPosition': array([0.36400034, 0.81703571])}
episode index:3963
target Thresh 1.9993497888067129
current state at start:  [1.22649872 1.62408812]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.22649872, 1.62408812]), 'currentState': array([0.72954875, 1.97968812]), 'targetState': array([0.37404197, 1.1321304 ]), 'effectorPosition': array([-0.16250592,  1.08554428])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9364322445230913
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.22649872, 1.62408812]), 'currentState': array([0.22954875, 1.70497317]), 'targetState': array([0.37404197, 1.1321304 ]), 'effectorPosition': array([0.61801061, 1.16211603])}
episode index:3964
target Thresh 1.9993510879295435
current state at start:  [-0.21168533 -2.30431724]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.21168533, -2.30431724]), 'currentState': array([0.24410012, 4.19134635]), 'targetState': array([ 0.92459356, -0.38396777]), 'effectorPosition': array([ 0.69693926, -0.72021268])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9364457546757966
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.21168533, -2.30431724]), 'currentState': array([0.72231993, 4.24389924]), 'targetState': array([ 0.92459356, -0.38396777]), 'effectorPosition': array([ 1.00138723, -0.30683068])}
episode index:3965
target Thresh 1.9993523844567251
current state at start:  [ 1.4645164  -2.77336109]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.4645164 , -2.77336109]), 'currentState': array([1.4754571 , 3.00982422]), 'targetState': array([0.01369494, 0.19252258]), 'effectorPosition': array([-0.12996554,  0.02113695])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9364617794476887
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.4645164 , -2.77336109]), 'currentState': array([1.4754571 , 3.00982422]), 'targetState': array([0.01369494, 0.19252258]), 'effectorPosition': array([-0.12996554,  0.02113695])}
episode index:3966
target Thresh 1.9993536783934436
current state at start:  [2.06609541 1.90707138]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.06609541, 1.90707138]), 'currentState': array([2.44843638, 1.50023094]), 'targetState': array([-1.31702119,  0.1481833 ]), 'effectorPosition': array([-1.46084735, -0.08329879])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.936475275343971
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([2.06609541, 1.90707138]), 'currentState': array([1.94843638, 1.81131503]), 'targetState': array([-1.31702119,  0.1481833 ]), 'effectorPosition': array([-1.18367474,  0.35000178])}
episode index:3967
target Thresh 1.999354969744875
current state at start:  [ 0.1824946  -2.56368743]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.1824946 , -2.56368743]), 'currentState': array([0.59778174, 3.21949788]), 'targetState': array([-0.23279706,  0.23727097]), 'effectorPosition': array([ 0.04630862, -0.06262321])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9364887644378863
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.1824946 , -2.56368743]), 'currentState': array([0.90467536, 2.71949788]), 'targetState': array([-0.23279706,  0.23727097]), 'effectorPosition': array([-0.26785946,  0.32215799])}
episode index:3968
target Thresh 1.9993562585161841
current state at start:  [-0.27469806 -2.78885759]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.27469806, -2.78885759]), 'currentState': array([0.11924584, 2.99432772]), 'targetState': array([0.67090559, 0.08948388]), 'effectorPosition': array([-0.00670886,  0.14697886])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9364948383218777
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([-0.27469806, -2.78885759]), 'currentState': array([5.24487805, 2.50592408]), 'targetState': array([0.67090559, 0.08948388]), 'effectorPosition': array([0.61067589, 0.13313562])}
episode index:3969
target Thresh 1.9993575447125267
current state at start:  [ 1.95158867 -2.2788946 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.95158867, -2.2788946 ]), 'currentState': array([2.11434262, 3.50576712]), 'targetState': array([ 0.11521294, -0.12204977]), 'effectorPosition': array([0.27092838, 0.24033639])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9365083156925774
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.95158867, -2.2788946 ]), 'currentState': array([2.13917748, 3.03829376]), 'targetState': array([ 0.11521294, -0.12204977]), 'effectorPosition': array([-0.08977211, -0.05101122])}
episode index:3970
target Thresh 1.9993588283390473
current state at start:  [1.63167736 2.29966949]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.63167736, 2.29966949]), 'currentState': array([1.21574983, 2.79966949]), 'targetState': array([-0.07817801,  0.0855215 ]), 'effectorPosition': array([-0.29426304,  0.17083945])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9365243045327455
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.63167736, 2.29966949]), 'currentState': array([1.21574983, 2.79966949]), 'targetState': array([-0.07817801,  0.0855215 ]), 'effectorPosition': array([-0.29426304,  0.17083945])}
episode index:3971
target Thresh 1.9993601094008804
current state at start:  [ 1.50385122 -2.09504957]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.50385122, -2.09504957]), 'currentState': array([1.6800666 , 4.56171926]), 'targetState': array([0.9175994 , 0.53658085]), 'effectorPosition': array([0.89009021, 0.95264832])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9365377676987745
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 1.50385122, -2.09504957]), 'currentState': array([1.35152839, 4.32732961]), 'targetState': array([0.9175994 , 0.53658085]), 'effectorPosition': array([1.04039966, 0.40784829])}
episode index:3972
target Thresh 1.9993613879031502
current state at start:  [-0.64727527  1.57422151]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.64727527,  1.57422151]), 'currentState': array([5.16117186, 1.95784186]), 'targetState': array([ 1.10432531, -0.2420891 ]), 'effectorPosition': array([ 1.10443261, -0.15912357])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9365537410771538
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.64727527,  1.57422151]), 'currentState': array([5.16117186, 1.95784186]), 'targetState': array([ 1.10432531, -0.2420891 ]), 'effectorPosition': array([ 1.10443261, -0.15912357])}
episode index:3973
target Thresh 1.9993626638509707
current state at start:  [ 3.48877137 -1.98247507]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.48877137, -1.98247507]), 'currentState': array([3.1403135 , 4.28697136]), 'targetState': array([-0.88541039,  0.67320019]), 'effectorPosition': array([-0.58613317,  0.91161696])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9365671900602748
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.48877137, -1.98247507]), 'currentState': array([3.51787304, 4.19955556]), 'targetState': array([-0.88541039,  0.67320019]), 'effectorPosition': array([-0.79390884,  0.62322747])}
episode index:3974
target Thresh 1.9993639372494458
current state at start:  [-1.03402266  2.45045474]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.03402266,  2.45045474]), 'currentState': array([4.74916265, 2.16538819]), 'targetState': array([ 0.58351665, -0.58815977]), 'effectorPosition': array([ 0.84398764, -0.40907633])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9365806322766118
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.03402266,  2.45045474]), 'currentState': array([4.24916265, 2.31628929]), 'targetState': array([ 0.58351665, -0.58815977]), 'effectorPosition': array([ 0.51358982, -0.61608222])}
episode index:3975
target Thresh 1.9993652081036692
current state at start:  [-0.35082045  2.27498989]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.35082045,  2.27498989]), 'currentState': array([5.44163014, 2.77498989]), 'targetState': array([-0.14287593,  0.03439662]), 'effectorPosition': array([0.31156171, 0.18928389])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9365940677312705
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.35082045,  2.27498989]), 'currentState': array([4.95078919, 3.27498989]), 'targetState': array([-0.14287593,  0.03439662]), 'effectorPosition': array([-0.12714227, -0.04004115])}
episode index:3976
target Thresh 1.999366476418724
current state at start:  [1.70249387 1.9736857 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.70249387, 1.9736857 ]), 'currentState': array([2.17932745, 2.23124196]), 'targetState': array([-0.7744795 ,  0.15065254]), 'effectorPosition': array([-0.8689209 , -0.13430858])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9366074964293516
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.70249387, 1.9736857 ]), 'currentState': array([1.73429539, 2.30425634]), 'targetState': array([-0.7744795 ,  0.15065254]), 'effectorPosition': array([-0.78676072,  0.20523075])}
episode index:3977
target Thresh 1.9993677421996836
current state at start:  [0.56910453 2.42940956]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.56910453, 2.42940956]), 'currentState': array([0.66514464, 2.91502857]), 'targetState': array([-0.02636582, -0.01940328]), 'effectorPosition': array([-0.11852782,  0.19251815])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9366234322019938
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.56910453, 2.42940956]), 'currentState': array([0.66514464, 2.91502857]), 'targetState': array([-0.02636582, -0.01940328]), 'effectorPosition': array([-0.11852782,  0.19251815])}
episode index:3978
target Thresh 1.9993690054516113
current state at start:  [-3.89514629  2.64412398]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.89514629,  2.64412398]), 'currentState': array([1.88803902, 3.14412398]), 'targetState': array([0.40201142, 0.52584858]), 'effectorPosition': array([0.00240401, 0.00079269])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9366294569765095
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([-3.89514629,  2.64412398]), 'currentState': array([1.87216617, 3.81597662]), 'targetState': array([0.40201142, 0.52584858]), 'effectorPosition': array([0.53129608, 0.39438681])}
episode index:3979
target Thresh 1.9993702661795598
current state at start:  [1.36003166 2.77787462]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.36003166, 2.77787462]), 'currentState': array([1.53757515, 3.21573877]), 'targetState': array([ 0.01229092, -0.00238119]), 'effectorPosition': array([0.07412858, 0.00028554])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9366453792235003
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.36003166, 2.77787462]), 'currentState': array([1.53757515, 3.21573877]), 'targetState': array([ 0.01229092, -0.00238119]), 'effectorPosition': array([0.07412858, 0.00028554])}
episode index:3980
target Thresh 1.9993715243885724
current state at start:  [-1.64234594 -1.71879207]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.64234594, -1.71879207]), 'currentState': array([4.95732075, 4.06439324]), 'targetState': array([-0.06059235, -0.03972245]), 'effectorPosition': array([-0.67737338, -0.57791526])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9366562947273377
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.64234594, -1.71879207]), 'currentState': array([5.7856614 , 3.13201516]), 'targetState': array([-0.06059235, -0.03972245]), 'effectorPosition': array([0.0046111 , 0.00839437])}
episode index:3981
target Thresh 1.9993727800836816
current state at start:  [ 0.01916271 -2.32613525]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.01916271, -2.32613525]), 'currentState': array([5.81490517, 3.45705006]), 'targetState': array([-0.37671776, -0.55076519]), 'effectorPosition': array([-0.09599944, -0.29912367])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9366696909365975
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.01916271, -2.32613525]), 'currentState': array([5.41600952, 3.77195016]), 'targetState': array([-0.37671776, -0.55076519]), 'effectorPosition': array([-0.32510676, -0.52789386])}
episode index:3982
target Thresh 1.9993740332699101
current state at start:  [-1.54198837 -2.40216086]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.54198837, -2.40216086]), 'currentState': array([5.22899465, 4.25847819]), 'targetState': array([-0.180405  , -1.02007923]), 'effectorPosition': array([-0.50410371, -0.93215457])}
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.9366593139753426
{'reset': False, 'endBeforeDone': False, 'stepCount': 12, 'initial state': array([-1.54198837, -2.40216086]), 'currentState': array([5.79858948, 3.97254825]), 'targetState': array([-0.180405  , -1.02007923]), 'effectorPosition': array([-0.05575141, -0.80532677])}
episode index:3983
target Thresh 1.9993752839522712
current state at start:  [-0.68310143 -1.69933352]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.68310143, -1.69933352]), 'currentState': array([6.10008388, 4.24818173]), 'targetState': array([ 0.55565876, -0.63190851]), 'effectorPosition': array([ 0.38024201, -0.97978969])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9366727027017544
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.68310143, -1.69933352]), 'currentState': array([0.31689857, 3.88967433]), 'targetState': array([ 0.55565876, -0.63190851]), 'effectorPosition': array([ 0.46568497, -0.56315829])}
episode index:3984
target Thresh 1.999376532135767
current state at start:  [ 2.54184079 -2.736929  ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.54184079, -2.736929  ]), 'currentState': array([2.58888298, 4.04625631]), 'targetState': array([-0.25826918,  1.22543095]), 'effectorPosition': array([0.08759582, 0.86972804])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9366787060411015
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([ 2.54184079, -2.736929  ]), 'currentState': array([2.83366188, 4.36220722]), 'targetState': array([-0.25826918,  1.22543095]), 'effectorPosition': array([-0.34133808,  1.09423545])}
episode index:3985
target Thresh 1.9993777778253905
current state at start:  [-1.00842521 -1.97584264]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.00842521, -1.97584264]), 'currentState': array([5.7747601 , 4.76512872]), 'targetState': array([ 0.38722013, -1.05376298]), 'effectorPosition': array([ 0.43343426, -1.38476183])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9366895994916682
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-1.00842521, -1.97584264]), 'currentState': array([5.98979241, 4.20783991]), 'targetState': array([ 0.38722013, -1.05376298]), 'effectorPosition': array([ 0.24134743, -0.98738337])}
episode index:3986
target Thresh 1.9993790210261246
current state at start:  [ 0.24905603 -1.64055358]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.24905603, -1.64055358]), 'currentState': array([0.19583609, 4.66911198]), 'targetState': array([ 1.0020945 , -0.83021202]), 'effectorPosition': array([ 1.13285332, -0.7937987 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9367054786992198
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.24905603, -1.64055358]), 'currentState': array([0.19583609, 4.66911198]), 'targetState': array([ 1.0020945 , -0.83021202]), 'effectorPosition': array([ 1.13285332, -0.7937987 ])}
episode index:3987
target Thresh 1.9993802617429421
current state at start:  [-0.15696434 -1.93018908]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.15696434, -1.93018908]), 'currentState': array([0.31588342, 4.63612416]), 'targetState': array([ 0.76044863, -1.02255375]), 'effectorPosition': array([ 1.18785445, -0.66077226])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9367188424207095
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.15696434, -1.93018908]), 'currentState': array([6.09906873, 4.46407589]), 'targetState': array([ 0.76044863, -1.02255375]), 'effectorPosition': array([ 0.56402031, -1.09102833])}
episode index:3988
target Thresh 1.9993814999808055
current state at start:  [-2.00907869 -2.02336419]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.00907869, -2.02336419]), 'currentState': array([4.43113943, 3.76202745]), 'targetState': array([-0.1701672 ,  0.08345548]), 'effectorPosition': array([-0.61027518, -0.01768331])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9367321994419125
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.00907869, -2.02336419]), 'currentState': array([4.83980533, 3.27614007]), 'targetState': array([-0.1701672 ,  0.08345548]), 'effectorPosition': array([-0.13190595, -0.02601024])}
episode index:3989
target Thresh 1.999382735744668
current state at start:  [-4.16333966  2.23933442]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.16333966,  2.23933442]), 'currentState': array([1.63488724, 2.67105766]), 'targetState': array([0.07152314, 0.25823234]), 'effectorPosition': array([-0.45939265,  0.07941444])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9367430685648594
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-4.16333966,  2.23933442]), 'currentState': array([0.75366851, 2.8896481 ]), 'targetState': array([0.07152314, 0.25823234]), 'effectorPosition': array([-0.1475714 ,  0.20338064])}
episode index:3990
target Thresh 1.999383969039473
current state at start:  [ 3.09880674 -2.31181722]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.09880674, -2.31181722]), 'currentState': array([2.59880674, 3.53623126]), 'targetState': array([0.36042941, 0.66148271]), 'effectorPosition': array([0.13277323, 0.36891751])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9367564128222975
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.09880674, -2.31181722]), 'currentState': array([2.12210471, 4.03429095]), 'targetState': array([0.36042941, 0.66148271]), 'effectorPosition': array([0.46817075, 0.7253897 ])}
episode index:3991
target Thresh 1.999385199870153
current state at start:  [-0.02082287  1.79482205]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.02082287,  1.79482205]), 'currentState': array([5.76236244, 2.23214645]), 'targetState': array([0.87484003, 0.19565066]), 'effectorPosition': array([0.72734483, 0.49254821])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9367697503942357
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.02082287,  1.79482205]), 'currentState': array([5.33360126, 2.29102165]), 'targetState': array([0.87484003, 0.19565066]), 'effectorPosition': array([0.80937447, 0.16063891])}
episode index:3992
target Thresh 1.9993864282416318
current state at start:  [-3.92406131  2.86291098]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.92406131,  2.86291098]), 'currentState': array([2.55503827, 2.46362173]), 'targetState': array([-1.02747929, -0.91330554]), 'effectorPosition': array([-0.53134746, -0.39996988])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9367806019468543
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-3.92406131,  2.86291098]), 'currentState': array([2.95390264, 1.68791651]), 'targetState': array([-1.02747929, -0.91330554]), 'effectorPosition': array([-1.05294915, -0.81092101])}
episode index:3993
target Thresh 1.9993876541588227
current state at start:  [-3.21844688  2.07316846]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.21844688,  2.07316846]), 'currentState': array([2.56473843, 2.22807458]), 'targetState': array([-0.53214503, -0.5179376 ]), 'effectorPosition': array([-0.75784511, -0.45137783])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9367964305392562
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.21844688,  2.07316846]), 'currentState': array([2.56473843, 2.22807458]), 'targetState': array([-0.53214503, -0.5179376 ]), 'effectorPosition': array([-0.75784511, -0.45137783])}
episode index:3994
target Thresh 1.9993888776266293
current state at start:  [-3.91375029  2.18423983]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.91375029,  2.18423983]), 'currentState': array([1.86943501, 2.67210337]), 'targetState': array([-0.07551666,  0.12586355]), 'effectorPosition': array([-0.46424005, -0.0297026 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9368097480785454
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.91375029,  2.18423983]), 'currentState': array([1.36943501, 3.04135143]), 'targetState': array([-0.07551666,  0.12586355]), 'effectorPosition': array([-0.09704747,  0.02493354])}
episode index:3995
target Thresh 1.9993900986499458
current state at start:  [ 2.54906256 -2.70643523]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.54906256, -2.70643523]), 'currentState': array([2.25931663, 3.14443079]), 'targetState': array([ 1.01897286, -0.23516374]), 'effectorPosition': array([0.00218901, 0.00180645])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9368181287722195
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 2.54906256, -2.70643523]), 'currentState': array([0.82244835, 4.42179177]), 'targetState': array([ 1.01897286, -0.23516374]), 'effectorPosition': array([ 1.18755871, -0.12905583])}
episode index:3996
target Thresh 1.999391317233656
current state at start:  [1.24990543 1.73381834]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.24990543, 1.73381834]), 'currentState': array([1.66446241, 2.23381834]), 'targetState': array([-1.19720189,  0.31885118]), 'effectorPosition': array([-0.82064286,  0.30909946])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9368314342191115
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.24990543, 1.73381834]), 'currentState': array([2.11487838, 1.80581398]), 'targetState': array([-1.19720189,  0.31885118]), 'effectorPosition': array([-1.22917932,  0.15296371])}
episode index:3997
target Thresh 1.9993925333826343
current state at start:  [-1.10040413  1.97843946]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.10040413,  1.97843946]), 'currentState': array([4.68278118, 2.47843946]), 'targetState': array([ 0.16701572, -0.15114443]), 'effectorPosition': array([ 0.60906068, -0.23007612])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9368447330099521
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.10040413,  1.97843946]), 'currentState': array([4.19205333, 2.97843946]), 'targetState': array([ 0.16701572, -0.15114443]), 'effectorPosition': array([ 0.13433063, -0.09227812])}
episode index:3998
target Thresh 1.9993937471017453
current state at start:  [0.4771444  2.14923512]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.4771444 , 2.14923512]), 'currentState': array([6.26032971, 2.64923512]), 'targetState': array([0.64829068, 0.29409628]), 'effectorPosition': array([0.1295511 , 0.46986672])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9368580251497345
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.4771444 , 2.14923512]), 'currentState': array([5.81095673, 2.37617974]), 'targetState': array([0.64829068, 0.29409628]), 'effectorPosition': array([0.56353076, 0.49014325])}
episode index:3999
target Thresh 1.9993949583958441
current state at start:  [-0.69454564 -1.89376407]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.69454564, -1.89376407]), 'currentState': array([6.08533367, 4.45716728]), 'targetState': array([ 0.46616284, -0.80087789]), 'effectorPosition': array([ 0.54276027, -1.09566939])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9368713106434471
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.69454564, -1.89376407]), 'currentState': array([0.28764834, 4.03867711]), 'targetState': array([ 0.46616284, -0.80087789]), 'effectorPosition': array([ 0.58236908, -0.64270052])}

Process finished with exit code 0
