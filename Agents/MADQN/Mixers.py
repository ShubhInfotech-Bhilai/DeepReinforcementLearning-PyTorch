from Agents.DQN.DQN import DQNAgent
from Agents.Core.ReplayMemory import ReplayMemory, Transition
import random
import torch
import torch.optim
import numpy as np
import simplejson as json
import os
import math
import pickle
from copy import deepcopy


class GroupReplayMemory(object):

    def __init__(self, capacity, numAgents):
        self.capacity = capacity
        self.numAgents = numAgents
        self.memory = [ []  for _ in range(self.numAgents)]
        self.position = 0

    def push(self, transitions):
        """Saves a transition"""


        if len(self.memory[0]) < self.capacity:
            for n in range(self.numAgents):
                self.memory[n].append(transitions[n])
        else:
            # write on the earlier experience
            for n in range(self.numAgents):
                self.memory[n][self.position] = transitions[n]
            self.position = (self.position + 1) % self.capacity

    def sample(self, batch_size):
        index = random.sample(range(0, len(self.memory[0])), batch_size)
        return [[self.memory[n][i] for i in index ] for n in range(self.numAgents)]

    def fetch_all(self):
        return self.memory

    def clear(self):
        for n in range(self.numAgents):
            self.memory[n].clear()
        self.position = 0

    def __len__(self):
        return len(self.memory[0])

    def __repr__(self):
        return str(self.memory)


class QMixer(torch.nn.Module):
    def __init__(self, config):
        super(QMixer, self).__init__()

        self.config = config
        self.numAgents = config['numAgents']
        self.state_dim = int(np.prod(args.state_shape))

        self.embed_dim = self.config['mixing_embed_dim']

        self.hyper_w_1 = torch.nn.Linear(self.state_dim, self.embed_dim * self.n_agents)
        self.hyper_w_final = torch.nn.Linear(self.state_dim, self.embed_dim)

        # State dependent bias for hidden layer
        self.hyper_b_1 = torch.nn.Linear(self.state_dim, self.embed_dim)

        # V(s) instead of a bias for the last layers
        self.V = torch.nn.Sequential(torch.nn.Linear(self.state_dim, self.embed_dim),
                               torch.nn.ReLU(),
                               torch.nn.Linear(self.embed_dim, 1))

    def forward(self, agent_qs, states):
        batchSize = agent_qs.size(0)
        states = states.reshape(-1, self.state_dim)
        agent_qs = agent_qs.view(-1, 1, self.numAgents)
        # First layer
        # weight and bias are generated by hyper net
        # weight and bias will have first dimensional equaling the sample batch size
        w1 = torch.abs(self.hyper_w_1(states))
        b1 = self.hyper_b_1(states)
        w1 = w1.view(-1, self.numAgents, self.embed_dim)
        b1 = b1.view(-1, 1, self.embed_dim)
        hidden = torch.elu(torch.bmm(agent_qs, w1) + b1)
        # Second layer
        # weight and bias are generated by hyper net
        w_final = torch.abs(self.hyper_w_final(states))
        w_final = w_final.view(-1, self.embed_dim, 1)
        # State-dependent bias
        # v will the size of batchSize, 1, 1
        v = self.V(states).view(-1, 1, 1)
        # Compute final output
        # bmm is batch matrix multiplication
        y = torch.bmm(hidden, w_final) + v
        # Reshape and return
        q_tot = y.view(batchSize, -1, 1)
        return q_tot



class VDNMixer(torch.nn.Module):
    def __init__(self):
        super(VDNMixer, self).__init__()

    def forward(self, QValues):
        return torch.sum(QValues, dim=1, keepdim=True)

