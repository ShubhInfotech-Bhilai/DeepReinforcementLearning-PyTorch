/home/yangyutu/anaconda3/bin/python /home/yangyutu/Dropbox/pythonScripts/DeepReinforcementLearning-PyTorch/Env/CustomEnv/MultiStageMaze/DQNBenchmarkFreeMaze/DQNMultiStageFreeMaze.py
episode index:0
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 102
reward sum = 0.3587482976818919
running average episode reward sum: 0.3587482976818919
{'currentState': array([4., 5.])}
episode index:1
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [4. 4.]
finish  [4. 5.] 1 1
done in step count: 20
reward sum = 0.8179069375972308
running average episode reward sum: 0.5883276176395613
{'currentState': array([4., 5.])}
episode index:2
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.7060451282267075
{'currentState': array([4., 5.])}
episode index:3
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.7556293649222318
{'currentState': array([4., 5.])}
episode index:4
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.7927995218179854
{'currentState': array([4., 5.])}
episode index:5
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 24
reward sum = 0.7856781408072188
running average episode reward sum: 0.7916126249828577
{'currentState': array([4., 5.])}
episode index:6
start: 1
at step 0:
{'currentState': array([0., 5.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.8157531085567351
{'currentState': array([4., 5.])}
episode index:7
start: 1
at step 0:
{'currentState': array([0., 5.])}
not finish  [0. 5.] 1
done in step count: 400
reward sum = 0.0
running average episode reward sum: 0.7137839699871432
{'currentState': array([0., 5.])}
episode index:8
start: 1
at step 0:
{'currentState': array([0., 5.])}
not finish  [0. 1.] 1
done in step count: 400
reward sum = 0.0
running average episode reward sum: 0.6344746399885718
{'currentState': array([0., 1.])}
episode index:9
start: 0
at step 0:
{'currentState': array([0., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 228
reward sum = 0.10111704470857531
running average episode reward sum: 0.581138880460572
{'currentState': array([4., 5.])}
episode index:10
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 29
reward sum = 0.7471720943315961
running average episode reward sum: 0.5962328089943015
{'currentState': array([4., 5.])}
episode index:11
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.6265964090781097
{'currentState': array([4., 5.])}
episode index:12
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 41
reward sum = 0.6622820409839835
running average episode reward sum: 0.6293414576862537
{'currentState': array([4., 5.])}
episode index:13
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.6483412288700011
{'currentState': array([4., 5.])}
episode index:14
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.6685178169386676
{'currentState': array([4., 5.])}
episode index:15
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.6844069967817459
{'currentState': array([4., 5.])}
episode index:16
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.6984268613491679
{'currentState': array([4., 5.])}
episode index:17
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.7108889631868762
{'currentState': array([4., 5.])}
episode index:18
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.7240314393349354
{'currentState': array([4., 5.])}
episode index:19
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.7358596678681886
{'currentState': array([4., 5.])}
episode index:20
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.745651119369751
{'currentState': array([4., 5.])}
episode index:21
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.7537008273269404
{'currentState': array([4., 5.])}
episode index:22
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.7626962700518561
{'currentState': array([4., 5.])}
episode index:23
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.7709420925496954
{'currentState': array([4., 5.])}
episode index:24
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.7785282492477076
{'currentState': array([4., 5.])}
episode index:25
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.7855308554304881
{'currentState': array([4., 5.])}
episode index:26
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.7916589737441737
{'currentState': array([4., 5.])}
episode index:27
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.7976924393247389
{'currentState': array([4., 5.])}
episode index:28
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 20
reward sum = 0.8179069375972308
running average episode reward sum: 0.7983894909893077
{'currentState': array([4., 5.])}
episode index:29
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 16
reward sum = 0.8514577710948755
running average episode reward sum: 0.8001584336594932
{'currentState': array([4., 5.])}
episode index:30
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.8035204866062452
{'currentState': array([4., 5.])}
episode index:31
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.8075375135218934
{'currentState': array([4., 5.])}
episode index:32
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 16
reward sum = 0.8514577710948755
running average episode reward sum: 0.8088684304180443
{'currentState': array([4., 5.])}
episode index:33
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.8122177323006877
{'currentState': array([4., 5.])}
episode index:34
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.815375645504323
{'currentState': array([4., 5.])}
episode index:35
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.8183581190855339
{'currentState': array([4., 5.])}
episode index:36
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.8222023864075465
{'currentState': array([4., 5.])}
episode index:37
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.8243650097917902
{'currentState': array([4., 5.])}
episode index:38
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.8268875658081012
{'currentState': array([4., 5.])}
episode index:39
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.828374998455802
{'currentState': array([4., 5.])}
episode index:40
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.8306766983575609
{'currentState': array([4., 5.])}
episode index:41
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.8333148757633572
{'currentState': array([4., 5.])}
episode index:42
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.8353946389881144
{'currentState': array([4., 5.])}
episode index:43
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.8382401246929301
{'currentState': array([4., 5.])}
episode index:44
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 14
reward sum = 0.8687458127689782
running average episode reward sum: 0.8389180288723977
{'currentState': array([4., 5.])}
episode index:45
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.8407403476888221
{'currentState': array([4., 5.])}
episode index:46
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.8424851210236965
{'currentState': array([4., 5.])}
episode index:47
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.8449457645440362
{'currentState': array([4., 5.])}
episode index:48
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.8473059736349744
{'currentState': array([4., 5.])}
episode index:49
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.8491894571502949
{'currentState': array([4., 5.])}
episode index:50
start: 1
at step 0:
{'currentState': array([0., 3.])}
finish  [4. 5.] 1 1
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.8508144746161125
{'currentState': array([4., 5.])}
episode index:51
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.8521977480740319
{'currentState': array([4., 5.])}
episode index:52
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.8542429982990503
{'currentState': array([4., 5.])}
episode index:53
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.8562124985157346
{'currentState': array([4., 5.])}
episode index:54
start: 1
at step 0:
{'currentState': array([0., 5.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.8581103805427213
{'currentState': array([4., 5.])}
episode index:55
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.8599404810687441
{'currentState': array([4., 5.])}
episode index:56
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.8617063675412223
{'currentState': array([4., 5.])}
episode index:57
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.8627587524875447
{'currentState': array([4., 5.])}
episode index:58
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.8644170110894508
{'currentState': array([4., 5.])}
episode index:59
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.865389139145092
{'currentState': array([4., 5.])}
episode index:60
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.8663293941497284
{'currentState': array([4., 5.])}
episode index:61
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.8678498234376362
{'currentState': array([4., 5.])}
episode index:62
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.868721170596212
{'currentState': array([4., 5.])}
episode index:63
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.8695652881560825
{'currentState': array([4., 5.])}
episode index:64
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.8703834328679569
{'currentState': array([4., 5.])}
episode index:65
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.8711767853158351
{'currentState': array([4., 5.])}
episode index:66
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.8723680280708226
{'currentState': array([4., 5.])}
episode index:67
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.8731088613996034
{'currentState': array([4., 5.])}
episode index:68
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.8738282212985645
{'currentState': array([4., 5.])}
episode index:69
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.8745270280575553
{'currentState': array([4., 5.])}
episode index:70
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.8752061501191097
{'currentState': array([4., 5.])}
episode index:71
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.8758664076789544
{'currentState': array([4., 5.])}
episode index:72
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.8770270871628043
{'currentState': array([4., 5.])}
episode index:73
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.877644892666387
{'currentState': array([4., 5.])}
episode index:74
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.8787509075641685
{'currentState': array([4., 5.])}
episode index:75
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.8798278168067453
{'currentState': array([4., 5.])}
episode index:76
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.8808767543806837
{'currentState': array([4., 5.])}
episode index:77
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.8818987961193929
{'currentState': array([4., 5.])}
episode index:78
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.8828949633837044
{'currentState': array([4., 5.])}
episode index:79
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.8833930850217572
{'currentState': array([4., 5.])}
episode index:80
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.8843462075523528
{'currentState': array([4., 5.])}
episode index:81
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.8852760831919583
{'currentState': array([4., 5.])}
episode index:82
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.885727512242994
{'currentState': array([4., 5.])}
episode index:83
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.8863912341139226
{'currentState': array([4., 5.])}
episode index:84
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.8866028910656271
{'currentState': array([4., 5.])}
episode index:85
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.8874632761695151
{'currentState': array([4., 5.])}
episode index:86
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.8883038823054977
{'currentState': array([4., 5.])}
episode index:87
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.8884865890407625
{'currentState': array([4., 5.])}
episode index:88
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.8886651900066955
{'currentState': array([4., 5.])}
episode index:89
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.8890438511669313
{'currentState': array([4., 5.])}
episode index:90
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 14
reward sum = 0.8687458127689782
running average episode reward sum: 0.8888207957999208
{'currentState': array([4., 5.])}
episode index:91
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.8896009611716609
{'currentState': array([4., 5.])}
episode index:92
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.890364348793471
{'currentState': array([4., 5.])}
episode index:93
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.8911114941254554
{'currentState': array([4., 5.])}
episode index:94
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 17
reward sum = 0.8429431933839268
running average episode reward sum: 0.8906044593808078
{'currentState': array([4., 5.])}
episode index:95
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.8909392534958819
{'currentState': array([4., 5.])}
episode index:96
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 38
reward sum = 0.682554595010387
running average episode reward sum: 0.8887909580475778
{'currentState': array([4., 5.])}
episode index:97
start: 1
at step 0:
{'currentState': array([0., 5.])}
finish  [4. 5.] 1 1
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.8894256426583168
{'currentState': array([4., 5.])}
episode index:98
start: 1
at step 0:
{'currentState': array([0., 5.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.8901445352577277
{'currentState': array([4., 5.])}
episode index:99
start: 0
at step 0:
{'currentState': array([0., 0.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.8902869106552385
{'currentState': array([4., 5.])}
episode index:100
start: 1
at step 0:
{'currentState': array([0., 5.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.8909830403517213
{'currentState': array([4., 5.])}
episode index:101
start: 0
at step 0:
{'currentState': array([0., 0.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.8912039639510538
{'currentState': array([4., 5.])}
episode index:102
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 21
reward sum = 0.8097278682212584
running average episode reward sum: 0.8904129338954248
{'currentState': array([4., 5.])}
episode index:103
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.8909954061646995
{'currentState': array([4., 5.])}
episode index:104
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.8916582690583691
{'currentState': array([4., 5.])}
episode index:105
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.8923086251049882
{'currentState': array([4., 5.])}
episode index:106
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.8925930743509969
{'currentState': array([4., 5.])}
episode index:107
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.8928722560183758
{'currentState': array([4., 5.])}
episode index:108
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.8931463150863533
{'currentState': array([4., 5.])}
episode index:109
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.8934153912621857
{'currentState': array([4., 5.])}
episode index:110
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.8935141902148579
{'currentState': array([4., 5.])}
episode index:111
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.8937751768596174
{'currentState': array([4., 5.])}
episode index:112
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.8943665116661694
{'currentState': array([4., 5.])}
episode index:113
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.8946154430939042
{'currentState': array([4., 5.])}
episode index:114
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.8951891871539571
{'currentState': array([4., 5.])}
episode index:115
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.8951132878829414
{'currentState': array([4., 5.])}
episode index:116
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.8956729692685573
{'currentState': array([4., 5.])}
episode index:117
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.8962231645289933
{'currentState': array([4., 5.])}
episode index:118
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.8961404897994735
{'currentState': array([4., 5.])}
episode index:119
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.8963621915047105
{'currentState': array([4., 5.])}
episode index:120
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.8968930495088039
{'currentState': array([4., 5.])}
episode index:121
start: 1
at step 0:
{'currentState': array([0., 5.])}
finish  [4. 5.] 1 1
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.8968803052854425
{'currentState': array([4., 5.])}
episode index:122
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.8970905848719667
{'currentState': array([4., 5.])}
episode index:123
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.8975252579770314
{'currentState': array([4., 5.])}
episode index:124
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 14
reward sum = 0.8687458127689782
running average episode reward sum: 0.8972950224153671
{'currentState': array([4., 5.])}
episode index:125
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.8971380859120622
{'currentState': array([4., 5.])}
episode index:126
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.8971951251962885
{'currentState': array([4., 5.])}
episode index:127
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.8973947312059106
{'currentState': array([4., 5.])}
episode index:128
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.8975912425487169
{'currentState': array([4., 5.])}
episode index:129
start: 1
at step 0:
{'currentState': array([0., 5.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.8980758946060344
{'currentState': array([4., 5.])}
episode index:130
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.8985531473953015
{'currentState': array([4., 5.])}
episode index:131
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.898736416691003
{'currentState': array([4., 5.])}
episode index:132
start: 1
at step 0:
{'currentState': array([0., 5.])}
finish  [4. 5.] 1 1
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.8990577981399503
{'currentState': array([4., 5.])}
episode index:133
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.8992345660226964
{'currentState': array([4., 5.])}
episode index:134
start: 1
at step 0:
{'currentState': array([0., 5.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.8996890952373431
{'currentState': array([4., 5.])}
episode index:135
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9001369401988333
{'currentState': array([4., 5.])}
episode index:136
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9001679265843076
{'currentState': array([4., 5.])}
episode index:137
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9001984638917314
{'currentState': array([4., 5.])}
episode index:138
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9006329786119348
{'currentState': array([4., 5.])}
episode index:139
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9010612859789925
{'currentState': array([4., 5.])}
episode index:140
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.9010206971015438
{'currentState': array([4., 5.])}
episode index:141
start: 0
at step 0:
{'currentState': array([0., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 14
reward sum = 0.8687458127689782
running average episode reward sum: 0.9007934091837088
{'currentState': array([4., 5.])}
episode index:142
start: 0
at step 0:
{'currentState': array([0., 0.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 27
reward sum = 0.7623427143471035
running average episode reward sum: 0.8998252225065297
{'currentState': array([4., 5.])}
episode index:143
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 14
reward sum = 0.8687458127689782
running average episode reward sum: 0.8996093932722413
{'currentState': array([4., 5.])}
episode index:144
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.8995181896753026
{'currentState': array([4., 5.])}
episode index:145
start: 1
at step 0:
{'currentState': array([0., 5.])}
finish  [4. 5.] 1 1
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.8998056003583553
{'currentState': array([4., 5.])}
episode index:146
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.8999616486173321
{'currentState': array([4., 5.])}
episode index:147
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9001155881160524
{'currentState': array([4., 5.])}
episode index:148
start: 1
at step 0:
{'currentState': array([0., 5.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9005214969877566
{'currentState': array([4., 5.])}
episode index:149
start: 1
at step 0:
{'currentState': array([0., 5.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9009219937411715
{'currentState': array([4., 5.])}
episode index:150
start: 1
at step 0:
{'currentState': array([0., 5.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.901317185901826
{'currentState': array([4., 5.])}
episode index:151
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9014581563526556
{'currentState': array([4., 5.])}
episode index:152
start: 1
at step 0:
{'currentState': array([0., 5.])}
finish  [4. 5.] 1 1
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.901536973941747
{'currentState': array([4., 5.])}
episode index:153
start: 1
at step 0:
{'currentState': array([0., 5.])}
finish  [4. 5.] 1 1
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.9018580978116059
{'currentState': array([4., 5.])}
episode index:154
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.902237052083789
{'currentState': array([4., 5.])}
episode index:155
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9023685113295848
{'currentState': array([4., 5.])}
episode index:156
start: 0
at step 0:
{'currentState': array([0., 0.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.9022667047078431
{'currentState': array([4., 5.])}
episode index:157
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.9025148910666605
{'currentState': array([4., 5.])}
episode index:158
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.902880181122845
{'currentState': array([4., 5.])}
episode index:159
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9030043343310018
{'currentState': array([4., 5.])}
episode index:160
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9030128917265161
{'currentState': array([4., 5.])}
episode index:161
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9031346929777594
{'currentState': array([4., 5.])}
episode index:162
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9031423456282567
{'currentState': array([4., 5.])}
episode index:163
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9034926728500355
{'currentState': array([4., 5.])}
episode index:164
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9036093517686895
{'currentState': array([4., 5.])}
episode index:165
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9037246249172391
{'currentState': array([4., 5.])}
episode index:166
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9040651721333035
{'currentState': array([4., 5.])}
episode index:167
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9041763597660096
{'currentState': array([4., 5.])}
episode index:168
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9042862315687429
{'currentState': array([4., 5.])}
episode index:169
start: 1
at step 0:
{'currentState': array([0., 5.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9046174655595149
{'currentState': array([4., 5.])}
episode index:170
start: 1
at step 0:
{'currentState': array([0., 5.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9049448254685236
{'currentState': array([4., 5.])}
episode index:171
start: 1
at step 0:
{'currentState': array([0., 5.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9052683788669623
{'currentState': array([4., 5.])}
episode index:172
start: 1
at step 0:
{'currentState': array([0., 5.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.905588191763685
{'currentState': array([4., 5.])}
episode index:173
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9055812600581973
{'currentState': array([4., 5.])}
episode index:174
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9056793368260243
{'currentState': array([4., 5.])}
episode index:175
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 14
reward sum = 0.8687458127689782
running average episode reward sum: 0.9054694872575184
{'currentState': array([4., 5.])}
episode index:176
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9055670872980293
{'currentState': array([4., 5.])}
episode index:177
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9056635907088715
{'currentState': array([4., 5.])}
episode index:178
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9059704757328442
{'currentState': array([4., 5.])}
episode index:179
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9059616512843773
{'currentState': array([4., 5.])}
episode index:180
start: 1
at step 0:
{'currentState': array([0., 5.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9062634985700989
{'currentState': array([4., 5.])}
episode index:181
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9065620288526808
{'currentState': array([4., 5.])}
episode index:182
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9068572965092234
{'currentState': array([4., 5.])}
episode index:183
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9069436410631294
{'currentState': array([4., 5.])}
episode index:184
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9069297947601331
{'currentState': array([4., 5.])}
episode index:185
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9070148211024331
{'currentState': array([4., 5.])}
episode index:186
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9073013515243452
{'currentState': array([4., 5.])}
episode index:187
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9073834969653217
{'currentState': array([4., 5.])}
episode index:188
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9076650446533359
{'currentState': array([4., 5.])}
episode index:189
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9079436286814762
{'currentState': array([4., 5.])}
episode index:190
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9080211211722953
{'currentState': array([4., 5.])}
episode index:191
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9080978064496684
{'currentState': array([4., 5.])}
episode index:192
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9081736970609547
{'currentState': array([4., 5.])}
episode index:193
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9084439151688879
{'currentState': array([4., 5.])}
episode index:194
start: 1
at step 0:
{'currentState': array([0., 5.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9087113618090474
{'currentState': array([4., 5.])}
episode index:195
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9087829604448581
{'currentState': array([4., 5.])}
episode index:196
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 36
reward sum = 0.6964132180495735
running average episode reward sum: 0.9077049414479277
{'currentState': array([4., 5.])}
episode index:197
start: 0
at step 0:
{'currentState': array([0., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.9075524974153572
{'currentState': array([4., 5.])}
episode index:198
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9076288401139128
{'currentState': array([4., 5.])}
episode index:199
start: 0
at step 0:
{'currentState': array([0., 0.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 22
reward sum = 0.8016305895390459
running average episode reward sum: 0.9070988488610385
{'currentState': array([4., 5.])}
episode index:200
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9070853325732164
{'currentState': array([4., 5.])}
episode index:201
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.9071171737361393
{'currentState': array([4., 5.])}
episode index:202
start: 1
at step 0:
{'currentState': array([0., 5.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.907380616279311
{'currentState': array([4., 5.])}
episode index:203
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9074559303878827
{'currentState': array([4., 5.])}
episode index:204
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.9076219021879467
{'currentState': array([4., 5.])}
episode index:205
start: 0
at step 0:
{'currentState': array([0., 0.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.9076505203689937
{'currentState': array([4., 5.])}
episode index:206
start: 1
at step 0:
{'currentState': array([0., 5.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9079062956812208
{'currentState': array([4., 5.])}
episode index:207
start: 0
at step 0:
{'currentState': array([0., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 20
reward sum = 0.8179069375972308
running average episode reward sum: 0.9074736064596631
{'currentState': array([4., 5.])}
episode index:208
start: 1
at step 0:
{'currentState': array([0., 5.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.907727780639282
{'currentState': array([4., 5.])}
episode index:209
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.9077553495290169
{'currentState': array([4., 5.])}
episode index:210
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9078263890783009
{'currentState': array([4., 5.])}
episode index:211
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9078967584431576
{'currentState': array([4., 5.])}
episode index:212
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9079664670628045
{'currentState': array([4., 5.])}
episode index:213
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9080355242000248
{'currentState': array([4., 5.])}
episode index:214
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9081039389452709
{'currentState': array([4., 5.])}
episode index:215
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9083469577927464
{'currentState': array([4., 5.])}
episode index:216
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9084133068094984
{'currentState': array([4., 5.])}
episode index:217
start: 1
at step 0:
{'currentState': array([0., 4.])}
finish  [4. 5.] 1 1
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.908608612970464
{'currentState': array([4., 5.])}
episode index:218
start: 1
at step 0:
{'currentState': array([0., 5.])}
finish  [4. 5.] 1 1
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.9088021355135214
{'currentState': array([4., 5.])}
episode index:219
start: 1
at step 0:
{'currentState': array([0., 5.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9090375622157326
{'currentState': array([4., 5.])}
episode index:220
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 14
reward sum = 0.8687458127689782
running average episode reward sum: 0.9088552466073763
{'currentState': array([4., 5.])}
episode index:221
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9089178116876491
{'currentState': array([4., 5.])}
episode index:222
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 23
reward sum = 0.7936142836436554
running average episode reward sum: 0.9084007555080795
{'currentState': array([4., 5.])}
episode index:223
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 23
reward sum = 0.7936142836436554
running average episode reward sum: 0.907888315901542
{'currentState': array([4., 5.])}
episode index:224
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 14
reward sum = 0.8687458127689782
running average episode reward sum: 0.9077143492209528
{'currentState': array([4., 5.])}
episode index:225
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9076996046447929
{'currentState': array([4., 5.])}
episode index:226
start: 1
at step 0:
{'currentState': array([0., 5.])}
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.907765882573353
{'currentState': array([4., 5.])}
episode index:227
start: 1
at step 0:
{'currentState': array([0., 5.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9079975936585576
{'currentState': array([4., 5.])}
episode index:228
start: 0
at step 0:
{'currentState': array([0., 0.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 31
reward sum = 0.7323033696543975
running average episode reward sum: 0.9072303699729499
{'currentState': array([4., 5.])}
episode index:229
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9074623944948066
{'currentState': array([4., 5.])}
episode index:230
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9075285516373742
{'currentState': array([4., 5.])}
episode index:231
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9075941384597473
{'currentState': array([4., 5.])}
episode index:232
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.9077395719831004
{'currentState': array([4., 5.])}
episode index:233
start: 1
at step 0:
{'currentState': array([0., 5.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9079654541968477
{'currentState': array([4., 5.])}
episode index:234
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.908189414008776
{'currentState': array([4., 5.])}
episode index:235
start: 1
at step 0:
{'currentState': array([0., 5.])}
finish  [4. 5.] 1 1
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.9083304764468787
{'currentState': array([4., 5.])}
episode index:236
start: 1
at step 0:
{'currentState': array([0., 5.])}
finish  [4. 5.] 1 1
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.9082378789585632
{'currentState': array([4., 5.])}
episode index:237
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.908298831964737
{'currentState': array([4., 5.])}
episode index:238
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9083592749039137
{'currentState': array([4., 5.])}
episode index:239
start: 0
at step 0:
{'currentState': array([0., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 17
reward sum = 0.8429431933839268
running average episode reward sum: 0.9080867078975803
{'currentState': array([4., 5.])}
episode index:240
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9081475294184531
{'currentState': array([4., 5.])}
episode index:241
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9082078482821287
{'currentState': array([4., 5.])}
episode index:242
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9084234374250005
{'currentState': array([4., 5.])}
episode index:243
start: 1
at step 0:
{'currentState': array([0., 5.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9086372594437505
{'currentState': array([4., 5.])}
episode index:244
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9086948408110329
{'currentState': array([4., 5.])}
episode index:245
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9086773092427312
{'currentState': array([4., 5.])}
episode index:246
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9086599196304481
{'currentState': array([4., 5.])}
episode index:247
start: 1
at step 0:
{'currentState': array([0., 5.])}
finish  [4. 5.] 1 1
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.9087922592666197
{'currentState': array([4., 5.])}
episode index:248
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 16
reward sum = 0.8514577710948755
running average episode reward sum: 0.9085620002779782
{'currentState': array([4., 5.])}
episode index:249
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9087701363168662
{'currentState': array([4., 5.])}
episode index:250
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9088258118471892
{'currentState': array([4., 5.])}
episode index:251
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.9087722897932667
{'currentState': array([4., 5.])}
episode index:252
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.9089391584102894
{'currentState': array([4., 5.])}
episode index:253
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9089935109142959
{'currentState': array([4., 5.])}
episode index:254
start: 1
at step 0:
{'currentState': array([0., 3.])}
finish  [4. 5.] 1 1
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.9091209094965967
{'currentState': array([4., 5.])}
episode index:255
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9093219841079381
{'currentState': array([4., 5.])}
episode index:256
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.909447113155771
{'currentState': array([4., 5.])}
episode index:257
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 15
reward sum = 0.8600583546412884
running average episode reward sum: 0.9092556838592033
{'currentState': array([4., 5.])}
episode index:258
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.909453909056658
{'currentState': array([4., 5.])}
episode index:259
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9095050274619322
{'currentState': array([4., 5.])}
episode index:260
start: 1
at step 0:
{'currentState': array([0., 5.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9097007783528825
{'currentState': array([4., 5.])}
episode index:261
start: 1
at step 0:
{'currentState': array([0., 5.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9098950349622227
{'currentState': array([4., 5.])}
episode index:262
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9099438929830048
{'currentState': array([4., 5.])}
episode index:263
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9101357570626146
{'currentState': array([4., 5.])}
episode index:264
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9101833379583328
{'currentState': array([4., 5.])}
episode index:265
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9103728592817977
{'currentState': array([4., 5.])}
episode index:266
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9104191957430192
{'currentState': array([4., 5.])}
episode index:267
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9104651864097539
{'currentState': array([4., 5.])}
episode index:268
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9105108351384461
{'currentState': array([4., 5.])}
episode index:269
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9106963357860814
{'currentState': array([4., 5.])}
episode index:270
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9107407946740588
{'currentState': array([4., 5.])}
episode index:271
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.9107510022211528
{'currentState': array([4., 5.])}
episode index:272
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9109335846672291
{'currentState': array([4., 5.])}
episode index:273
start: 1
at step 0:
{'currentState': array([0., 5.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.911114834394721
{'currentState': array([4., 5.])}
episode index:274
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9111571247948417
{'currentState': array([4., 5.])}
episode index:275
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9111991087427876
{'currentState': array([4., 5.])}
episode index:276
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9111744985127012
{'currentState': array([4., 5.])}
episode index:277
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 14
reward sum = 0.8687458127689782
running average episode reward sum: 0.9110218773409612
{'currentState': array([4., 5.])}
episode index:278
start: 1
at step 0:
{'currentState': array([0., 5.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9111995624042551
{'currentState': array([4., 5.])}
episode index:279
start: 1
at step 0:
{'currentState': array([0., 5.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9113759782885257
{'currentState': array([4., 5.])}
episode index:280
start: 1
at step 0:
{'currentState': array([0., 5.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9115511385437266
{'currentState': array([4., 5.])}
episode index:281
start: 1
at step 0:
{'currentState': array([0., 5.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9117250565276142
{'currentState': array([4., 5.])}
episode index:282
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.911897745409142
{'currentState': array([4., 5.])}
episode index:283
start: 1
at step 0:
{'currentState': array([0., 5.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.912069218171786
{'currentState': array([4., 5.])}
episode index:284
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.912074298976389
{'currentState': array([4., 5.])}
episode index:285
start: 1
at step 0:
{'currentState': array([0., 5.])}
finish  [4. 5.] 1 1
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.9121771166352163
{'currentState': array([4., 5.])}
episode index:286
start: 1
at step 0:
{'currentState': array([0., 5.])}
finish  [4. 5.] 1 1
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.9121817860806812
{'currentState': array([4., 5.])}
episode index:287
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9122184628457758
{'currentState': array([4., 5.])}
episode index:288
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.912160053819523
{'currentState': array([4., 5.])}
episode index:289
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9121965525802417
{'currentState': array([4., 5.])}
episode index:290
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9122328004903713
{'currentState': array([4., 5.])}
episode index:291
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9122688001271437
{'currentState': array([4., 5.])}
episode index:292
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9122418829765692
{'currentState': array([4., 5.])}
episode index:293
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9122776068250432
{'currentState': array([4., 5.])}
episode index:294
start: 0
at step 0:
{'currentState': array([0., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.9121898348416232
{'currentState': array([4., 5.])}
episode index:295
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9122254931510364
{'currentState': array([4., 5.])}
episode index:296
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9123883568441306
{'currentState': array([4., 5.])}
episode index:297
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9123614901265624
{'currentState': array([4., 5.])}
episode index:298
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9123962165623529
{'currentState': array([4., 5.])}
episode index:299
start: 1
at step 0:
{'currentState': array([0., 4.])}
finish  [4. 5.] 1 1
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.9125248626734784
{'currentState': array([4., 5.])}
episode index:300
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9124978102227652
{'currentState': array([4., 5.])}
episode index:301
start: 1
at step 0:
{'currentState': array([0., 5.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9126570757849415
{'currentState': array([4., 5.])}
episode index:302
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.912629765551357
{'currentState': array([4., 5.])}
episode index:303
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9126630383437141
{'currentState': array([4., 5.])}
episode index:304
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9126960929538263
{'currentState': array([4., 5.])}
episode index:305
start: 1
at step 0:
{'currentState': array([0., 4.])}
finish  [4. 5.] 1 1
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.9128212366039772
{'currentState': array([4., 5.])}
episode index:306
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9128535605708304
{'currentState': array([4., 5.])}
episode index:307
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9128260557475771
{'currentState': array([4., 5.])}
episode index:308
start: 0
at step 0:
{'currentState': array([0., 0.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 56
reward sum = 0.5696012024771592
running average episode reward sum: 0.9117152957046307
{'currentState': array([4., 5.])}
episode index:309
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 20
reward sum = 0.8179069375972308
running average episode reward sum: 0.9114126880978327
{'currentState': array([4., 5.])}
episode index:310
start: 1
at step 0:
{'currentState': array([0., 5.])}
finish  [4. 5.] 1 1
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.9115093680377142
{'currentState': array([4., 5.])}
episode index:311
start: 0
at step 0:
{'currentState': array([0., 0.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 32
reward sum = 0.7249803359578534
running average episode reward sum: 0.9109115185759199
{'currentState': array([4., 5.])}
episode index:312
start: 0
at step 0:
{'currentState': array([0., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 15
reward sum = 0.8600583546412884
running average episode reward sum: 0.9107490484036048
{'currentState': array([4., 5.])}
episode index:313
start: 0
at step 0:
{'currentState': array([0., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.910728771418271
{'currentState': array([4., 5.])}
episode index:314
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.9108565850007526
{'currentState': array([4., 5.])}
episode index:315
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9110139882444213
{'currentState': array([4., 5.])}
episode index:316
start: 1
at step 0:
{'currentState': array([0., 5.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9111703984076881
{'currentState': array([4., 5.])}
episode index:317
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9112067955649844
{'currentState': array([4., 5.])}
episode index:318
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9111854014566579
{'currentState': array([4., 5.])}
episode index:319
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.9111078998012188
{'currentState': array([4., 5.])}
episode index:320
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.9110032677862585
{'currentState': array([4., 5.])}
episode index:321
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.910926813140078
{'currentState': array([4., 5.])}
episode index:322
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9110805877433595
{'currentState': array([4., 5.])}
episode index:323
start: 1
at step 0:
{'currentState': array([0., 5.])}
finish  [4. 5.] 1 1
done in step count: 17
reward sum = 0.8429431933839268
running average episode reward sum: 0.9108702871434846
{'currentState': array([4., 5.])}
episode index:324
start: 1
at step 0:
{'currentState': array([0., 5.])}
finish  [4. 5.] 1 1
done in step count: 25
reward sum = 0.7778213593991467
running average episode reward sum: 0.9104609058273482
{'currentState': array([4., 5.])}
episode index:325
start: 1
at step 0:
{'currentState': array([0., 5.])}
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9104422591070459
{'currentState': array([4., 5.])}
episode index:326
start: 1
at step 0:
{'currentState': array([0., 5.])}
finish  [4. 5.] 1 1
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.9105083847608684
{'currentState': array([4., 5.])}
episode index:327
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9104897069872341
{'currentState': array([4., 5.])}
episode index:328
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 14
reward sum = 0.8687458127689782
running average episode reward sum: 0.9103628258497924
{'currentState': array([4., 5.])}
episode index:329
start: 1
at step 0:
{'currentState': array([0., 5.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9105150476199447
{'currentState': array([4., 5.])}
episode index:330
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9104965190017842
{'currentState': array([4., 5.])}
episode index:331
start: 0
at step 0:
{'currentState': array([0., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 24
reward sum = 0.7856781408072188
running average episode reward sum: 0.9101205600313186
{'currentState': array([4., 5.])}
episode index:332
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 18
reward sum = 0.8345137614500875
running average episode reward sum: 0.9098935125881316
{'currentState': array([4., 5.])}
episode index:333
start: 1
at step 0:
{'currentState': array([0., 5.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9100453164725983
{'currentState': array([4., 5.])}
episode index:334
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9100832250635098
{'currentState': array([4., 5.])}
episode index:335
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9101209080080468
{'currentState': array([4., 5.])}
episode index:336
start: 1
at step 0:
{'currentState': array([0., 5.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9102706857587648
{'currentState': array([4., 5.])}
episode index:337
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.9102802909709685
{'currentState': array([4., 5.])}
episode index:338
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 16
reward sum = 0.8514577710948755
running average episode reward sum: 0.910106773213222
{'currentState': array([4., 5.])}
episode index:339
start: 1
at step 0:
{'currentState': array([0., 5.])}
finish  [4. 5.] 1 1
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.9101713572564389
{'currentState': array([4., 5.])}
episode index:340
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9103192301383849
{'currentState': array([4., 5.])}
episode index:341
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 18
reward sum = 0.8345137614500875
running average episode reward sum: 0.9100975767211676
{'currentState': array([4., 5.])}
episode index:342
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9102448024741672
{'currentState': array([4., 5.])}
episode index:343
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9102811393693816
{'currentState': array([4., 5.])}
episode index:344
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.910237826658916
{'currentState': array([4., 5.])}
episode index:345
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9102739736755894
{'currentState': array([4., 5.])}
episode index:346
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9104189939531814
{'currentState': array([4., 5.])}
episode index:347
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9105631807809021
{'currentState': array([4., 5.])}
episode index:348
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9105980848314668
{'currentState': array([4., 5.])}
episode index:349
start: 1
at step 0:
{'currentState': array([0., 5.])}
finish  [4. 5.] 1 1
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.9107134904459482
{'currentState': array([4., 5.])}
episode index:350
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9107477673803698
{'currentState': array([4., 5.])}
episode index:351
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9107818495594823
{'currentState': array([4., 5.])}
episode index:352
start: 1
at step 0:
{'currentState': array([0., 5.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9109229661612968
{'currentState': array([4., 5.])}
episode index:353
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9110632854941745
{'currentState': array([4., 5.])}
episode index:354
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.9111489668009543
{'currentState': array([4., 5.])}
episode index:355
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9111815390695694
{'currentState': array([4., 5.])}
episode index:356
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9113199549545287
{'currentState': array([4., 5.])}
episode index:357
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.911351867634622
{'currentState': array([4., 5.])}
episode index:358
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9113836025281966
{'currentState': array([4., 5.])}
episode index:359
start: 1
at step 0:
{'currentState': array([0., 5.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9115203036600629
{'currentState': array([4., 5.])}
episode index:360
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.9114506764247611
{'currentState': array([4., 5.])}
episode index:361
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9114818753695212
{'currentState': array([4., 5.])}
episode index:362
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9116171760158862
{'currentState': array([4., 5.])}
episode index:363
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9116477461214139
{'currentState': array([4., 5.])}
episode index:364
start: 1
at step 0:
{'currentState': array([0., 5.])}
finish  [4. 5.] 1 1
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.9115785327668788
{'currentState': array([4., 5.])}
episode index:365
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.911609041405297
{'currentState': array([4., 5.])}
episode index:366
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9116393837841053
{'currentState': array([4., 5.])}
episode index:367
start: 1
at step 0:
{'currentState': array([0., 4.])}
finish  [4. 5.] 1 1
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.9115466708471891
{'currentState': array([4., 5.])}
episode index:368
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9115272545983046
{'currentState': array([4., 5.])}
episode index:369
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 16
reward sum = 0.8514577710948755
running average episode reward sum: 0.91136490464289
{'currentState': array([4., 5.])}
episode index:370
start: 1
at step 0:
{'currentState': array([0., 5.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.911497603040079
{'currentState': array([4., 5.])}
episode index:371
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.9114300956978103
{'currentState': array([4., 5.])}
episode index:372
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9115619078004972
{'currentState': array([4., 5.])}
episode index:373
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 20
reward sum = 0.8179069375972308
running average episode reward sum: 0.911311493441665
{'currentState': array([4., 5.])}
episode index:374
start: 1
at step 0:
{'currentState': array([0., 5.])}
finish  [4. 5.] 1 1
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.9112450224503968
{'currentState': array([4., 5.])}
episode index:375
start: 1
at step 0:
{'currentState': array([0., 5.])}
finish  [4. 5.] 1 1
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.911325435022074
{'currentState': array([4., 5.])}
episode index:376
start: 0
at step 0:
{'currentState': array([0., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.9112357681466812
{'currentState': array([4., 5.])}
episode index:377
start: 1
at step 0:
{'currentState': array([0., 5.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9113663507970867
{'currentState': array([4., 5.])}
episode index:378
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 14
reward sum = 0.8687458127689782
running average episode reward sum: 0.9112538955516299
{'currentState': array([4., 5.])}
episode index:379
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9112841344960413
{'currentState': array([4., 5.])}
episode index:380
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9113142147058363
{'currentState': array([4., 5.])}
episode index:381
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9114432246411613
{'currentState': array([4., 5.])}
episode index:382
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9115715608953621
{'currentState': array([4., 5.])}
episode index:383
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9116006575972698
{'currentState': array([4., 5.])}
episode index:384
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9116296031474793
{'currentState': array([4., 5.])}
episode index:385
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9116583987207447
{'currentState': array([4., 5.])}
episode index:386
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9116395968506881
{'currentState': array([4., 5.])}
episode index:387
start: 1
at step 0:
{'currentState': array([0., 5.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9117657731732379
{'currentState': array([4., 5.])}
episode index:388
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9117939966211934
{'currentState': array([4., 5.])}
episode index:389
start: 1
at step 0:
{'currentState': array([0., 5.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9119191299888314
{'currentState': array([4., 5.])}
episode index:390
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9119468168544046
{'currentState': array([4., 5.])}
episode index:391
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9119275190435739
{'currentState': array([4., 5.])}
episode index:392
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9120513574429542
{'currentState': array([4., 5.])}
episode index:393
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.9119862140781654
{'currentState': array([4., 5.])}
episode index:394
start: 1
at step 0:
{'currentState': array([0., 5.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9121092768526511
{'currentState': array([4., 5.])}
episode index:395
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 15
reward sum = 0.8600583546412884
running average episode reward sum: 0.911977835129895
{'currentState': array([4., 5.])}
episode index:396
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9120049556822831
{'currentState': array([4., 5.])}
episode index:397
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9120319399504883
{'currentState': array([4., 5.])}
episode index:398
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9120587889592037
{'currentState': array([4., 5.])}
episode index:399
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.9121088053565731
{'currentState': array([4., 5.])}
episode index:400
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9122297210788759
{'currentState': array([4., 5.])}
episode index:401
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9123500352304211
{'currentState': array([4., 5.])}
episode index:402
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9123758284294223
{'currentState': array([4., 5.])}
episode index:403
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9123560419110545
{'currentState': array([4., 5.])}
episode index:404
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9123363531038885
{'currentState': array([4., 5.])}
episode index:405
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9123167612859203
{'currentState': array([4., 5.])}
episode index:406
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 15
reward sum = 0.8600583546412884
running average episode reward sum: 0.9121883622523954
{'currentState': array([4., 5.])}
episode index:407
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.9121470629680972
{'currentState': array([4., 5.])}
episode index:408
start: 1
at step 0:
{'currentState': array([0., 5.])}
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9121729740474611
{'currentState': array([4., 5.])}
episode index:409
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.9122676498422233
{'currentState': array([4., 5.])}
episode index:410
start: 0
at step 0:
{'currentState': array([0., 0.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 15
reward sum = 0.8600583546412884
running average episode reward sum: 0.9121406199268927
{'currentState': array([4., 5.])}
episode index:411
start: 0
at step 0:
{'currentState': array([0., 0.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 34
reward sum = 0.7105532272722921
running average episode reward sum: 0.911651330138896
{'currentState': array([4., 5.])}
episode index:412
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.911769840259625
{'currentState': array([4., 5.])}
episode index:413
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9117963495692104
{'currentState': array([4., 5.])}
episode index:414
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9118227311230869
{'currentState': array([4., 5.])}
episode index:415
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9119399745819255
{'currentState': array([4., 5.])}
episode index:416
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9119658851810767
{'currentState': array([4., 5.])}
episode index:417
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.9120364934686842
{'currentState': array([4., 5.])}
episode index:418
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9120620500342194
{'currentState': array([4., 5.])}
episode index:419
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.912177607081757
{'currentState': array([4., 5.])}
episode index:420
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9122926151646982
{'currentState': array([4., 5.])}
episode index:421
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.9122312224077112
{'currentState': array([4., 5.])}
episode index:422
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9123455599670309
{'currentState': array([4., 5.])}
episode index:423
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9124593581982409
{'currentState': array([4., 5.])}
episode index:424
start: 0
at step 0:
{'currentState': array([0., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 17
reward sum = 0.8429431933839268
running average episode reward sum: 0.9122957907516189
{'currentState': array([4., 5.])}
episode index:425
start: 1
at step 0:
{'currentState': array([0., 3.])}
finish  [4. 5.] 1 1
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.9123642986357724
{'currentState': array([4., 5.])}
episode index:426
start: 1
at step 0:
{'currentState': array([0., 5.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9124772534633233
{'currentState': array([4., 5.])}
episode index:427
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9125896804645772
{'currentState': array([4., 5.])}
episode index:428
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9127015833306272
{'currentState': array([4., 5.])}
episode index:429
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9127249394029465
{'currentState': array([4., 5.])}
episode index:430
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9127055824089927
{'currentState': array([4., 5.])}
episode index:431
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9127288210942217
{'currentState': array([4., 5.])}
episode index:432
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.9127952213905421
{'currentState': array([4., 5.])}
episode index:433
start: 1
at step 0:
{'currentState': array([0., 4.])}
finish  [4. 5.] 1 1
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.912883227907845
{'currentState': array([4., 5.])}
episode index:434
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.9128846854241113
{'currentState': array([4., 5.])}
episode index:435
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9128651840240761
{'currentState': array([4., 5.])}
episode index:436
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9129744078821447
{'currentState': array([4., 5.])}
episode index:437
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9129967144724319
{'currentState': array([4., 5.])}
episode index:438
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9131051411137248
{'currentState': array([4., 5.])}
episode index:439
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9132130749066482
{'currentState': array([4., 5.])}
episode index:440
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.913320519203912
{'currentState': array([4., 5.])}
episode index:441
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9134274773278851
{'currentState': array([4., 5.])}
episode index:442
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9134070588124922
{'currentState': array([4., 5.])}
episode index:443
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9135133402340857
{'currentState': array([4., 5.])}
episode index:444
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.9135761869962585
{'currentState': array([4., 5.])}
episode index:445
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.913576054844885
{'currentState': array([4., 5.])}
episode index:446
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9136812449011604
{'currentState': array([4., 5.])}
episode index:447
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9137859653589704
{'currentState': array([4., 5.])}
episode index:448
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9138902193559437
{'currentState': array([4., 5.])}
episode index:449
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9139940100018195
{'currentState': array([4., 5.])}
episode index:450
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9140973403787557
{'currentState': array([4., 5.])}
episode index:451
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9141164716930237
{'currentState': array([4., 5.])}
episode index:452
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 15
reward sum = 0.8600583546412884
running average episode reward sum: 0.913997138101298
{'currentState': array([4., 5.])}
episode index:453
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9140164058465109
{'currentState': array([4., 5.])}
episode index:454
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9140355888983382
{'currentState': array([4., 5.])}
episode index:455
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9141376950849647
{'currentState': array([4., 5.])}
episode index:456
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9142393544173828
{'currentState': array([4., 5.])}
episode index:457
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.914340569822585
{'currentState': array([4., 5.])}
episode index:458
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.9143996974469388
{'currentState': array([4., 5.])}
episode index:459
start: 0
at step 0:
{'currentState': array([0., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 19
reward sum = 0.8261686238355866
running average episode reward sum: 0.9142078907651751
{'currentState': array([4., 5.])}
episode index:460
start: 0
at step 0:
{'currentState': array([0., 0.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 14
reward sum = 0.8687458127689782
running average episode reward sum: 0.9141092745439252
{'currentState': array([4., 5.])}
episode index:461
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9141279659289555
{'currentState': array([4., 5.])}
episode index:462
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9141465765736617
{'currentState': array([4., 5.])}
episode index:463
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.9140676421909576
{'currentState': array([4., 5.])}
episode index:464
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.9141063469344329
{'currentState': array([4., 5.])}
episode index:465
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.9140468587901877
{'currentState': array([4., 5.])}
episode index:466
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9140654837059001
{'currentState': array([4., 5.])}
episode index:467
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9141649079073834
{'currentState': array([4., 5.])}
episode index:468
start: 0
at step 0:
{'currentState': array([0., 0.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 16
reward sum = 0.8514577710948755
running average episode reward sum: 0.9140312039909387
{'currentState': array([4., 5.])}
episode index:469
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.914049743332294
{'currentState': array([4., 5.])}
episode index:470
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9140682039503315
{'currentState': array([4., 5.])}
episode index:471
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 16
reward sum = 0.8514577710948755
running average episode reward sum: 0.9139355547281801
{'currentState': array([4., 5.])}
episode index:472
start: 1
at step 0:
{'currentState': array([0., 5.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9140342026251608
{'currentState': array([4., 5.])}
episode index:473
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9141324342862892
{'currentState': array([4., 5.])}
episode index:474
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 15
reward sum = 0.8600583546412884
running average episode reward sum: 0.9140185941186155
{'currentState': array([4., 5.])}
episode index:475
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9140369262621225
{'currentState': array([4., 5.])}
episode index:476
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9140551815412961
{'currentState': array([4., 5.])}
episode index:477
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9141525472912098
{'currentState': array([4., 5.])}
episode index:478
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9142495065035454
{'currentState': array([4., 5.])}
episode index:479
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9142672048117213
{'currentState': array([4., 5.])}
episode index:480
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.9143237805800981
{'currentState': array([4., 5.])}
episode index:481
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9143031546349295
{'currentState': array([4., 5.])}
episode index:482
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9143206319429895
{'currentState': array([4., 5.])}
episode index:483
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9144162422282314
{'currentState': array([4., 5.])}
episode index:484
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9144334142946224
{'currentState': array([4., 5.])}
episode index:485
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9144505156940738
{'currentState': array([4., 5.])}
episode index:486
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9144675468619051
{'currentState': array([4., 5.])}
episode index:487
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9144845082298683
{'currentState': array([4., 5.])}
episode index:488
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9145788057795005
{'currentState': array([4., 5.])}
episode index:489
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9145954708583748
{'currentState': array([4., 5.])}
episode index:490
start: 1
at step 0:
{'currentState': array([0., 5.])}
finish  [4. 5.] 1 1
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.9146502258044902
{'currentState': array([4., 5.])}
episode index:491
start: 1
at step 0:
{'currentState': array([0., 4.])}
finish  [4. 5.] 1 1
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.9147240872355785
{'currentState': array([4., 5.])}
episode index:492
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9147403562156847
{'currentState': array([4., 5.])}
episode index:493
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9147565593294747
{'currentState': array([4., 5.])}
episode index:494
start: 1
at step 0:
{'currentState': array([1., 4.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9148491642803243
{'currentState': array([4., 5.])}
episode index:495
start: 0
at step 0:
{'currentState': array([0., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 22
reward sum = 0.8016305895390459
running average episode reward sum: 0.9146209010247975
{'currentState': array([4., 5.])}
episode index:496
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9146372466855685
{'currentState': array([4., 5.])}
episode index:497
start: 1
at step 0:
{'currentState': array([0., 5.])}
finish  [4. 5.] 1 1
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9147295333588906
{'currentState': array([4., 5.])}
episode index:498
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9147455958059227
{'currentState': array([4., 5.])}
episode index:499
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9147615940031668
{'currentState': array([4., 5.])}
episode index:500
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9147408764003837
{'currentState': array([4., 5.])}
episode index:501
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9147568202609964
{'currentState': array([4., 5.])}
episode index:502
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9147727007265369
{'currentState': array([4., 5.])}
episode index:503
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9147885181743571
{'currentState': array([4., 5.])}
episode index:504
start: 0
at step 0:
{'currentState': array([0., 0.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.9147860008066527
{'currentState': array([4., 5.])}
episode index:505
start: 0
at step 0:
{'currentState': array([0., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.9147834933890183
{'currentState': array([4., 5.])}
episode index:506
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9147991959551701
{'currentState': array([4., 5.])}
episode index:507
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.9147432622460381
{'currentState': array([4., 5.])}
episode index:508
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.914758982152093
{'currentState': array([4., 5.])}
episode index:509
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9147746404114573
{'currentState': array([4., 5.])}
episode index:510
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9147902373860493
{'currentState': array([4., 5.])}
episode index:511
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 15
reward sum = 0.8600583546412884
running average episode reward sum: 0.9146833391775634
{'currentState': array([4., 5.])}
episode index:512
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9146990533203516
{'currentState': array([4., 5.])}
episode index:513
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9146789813781113
{'currentState': array([4., 5.])}
episode index:514
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9146946429568488
{'currentState': array([4., 5.])}
episode index:515
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9147102438317928
{'currentState': array([4., 5.])}
episode index:516
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9147257843551896
{'currentState': array([4., 5.])}
episode index:517
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9147412648765655
{'currentState': array([4., 5.])}
episode index:518
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9147566857427532
{'currentState': array([4., 5.])}
episode index:519
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.914772047297917
{'currentState': array([4., 5.])}
episode index:520
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9147873498835791
{'currentState': array([4., 5.])}
episode index:521
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9148025938386449
{'currentState': array([4., 5.])}
episode index:522
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9148177794994276
{'currentState': array([4., 5.])}
episode index:523
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9148329071996728
{'currentState': array([4., 5.])}
episode index:524
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9148479772705838
{'currentState': array([4., 5.])}
episode index:525
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9148280801179949
{'currentState': array([4., 5.])}
episode index:526
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.9148255927695426
{'currentState': array([4., 5.])}
episode index:527
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.914840591068138
{'currentState': array([4., 5.])}
episode index:528
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.914855532662391
{'currentState': array([4., 5.])}
episode index:529
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9148704178732693
{'currentState': array([4., 5.])}
episode index:530
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9148852470193233
{'currentState': array([4., 5.])}
episode index:531
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9149000204167079
{'currentState': array([4., 5.])}
episode index:532
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.9148633191668805
{'currentState': array([4., 5.])}
episode index:533
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9148436913688317
{'currentState': array([4., 5.])}
episode index:534
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9148584595988487
{'currentState': array([4., 5.])}
episode index:535
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9148731727235299
{'currentState': array([4., 5.])}
episode index:536
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9148878310507261
{'currentState': array([4., 5.])}
episode index:537
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9149024348859998
{'currentState': array([4., 5.])}
episode index:538
start: 0
at step 0:
{'currentState': array([0., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.914866137704873
{'currentState': array([4., 5.])}
episode index:539
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9148807276247306
{'currentState': array([4., 5.])}
episode index:540
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.9148782073287212
{'currentState': array([4., 5.])}
episode index:541
start: 0
at step 0:
{'currentState': array([0., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.9148421557547912
{'currentState': array([4., 5.])}
episode index:542
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 20
reward sum = 0.8179069375972308
running average episode reward sum: 0.9146636378576318
{'currentState': array([4., 5.])}
episode index:543
start: 0
at step 0:
{'currentState': array([0., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 18
reward sum = 0.8345137614500875
running average episode reward sum: 0.9145163035260003
{'currentState': array([4., 5.])}
episode index:544
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.914531401490958
{'currentState': array([4., 5.])}
episode index:545
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9145128129809175
{'currentState': array([4., 5.])}
episode index:546
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9145278621243307
{'currentState': array([4., 5.])}
episode index:547
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [4. 4.]
finish  [4. 5.] 1 1
done in step count: 18
reward sum = 0.8345137614500875
running average episode reward sum: 0.9143818509917134
{'currentState': array([4., 5.])}
episode index:548
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9143970838577175
{'currentState': array([4., 5.])}
episode index:549
start: 0
at step 0:
{'currentState': array([0., 0.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 24
reward sum = 0.7856781408072188
running average episode reward sum: 0.9141630494158074
{'currentState': array([4., 5.])}
episode index:550
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9141786240891506
{'currentState': array([4., 5.])}
episode index:551
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.914194142332518
{'currentState': array([4., 5.])}
episode index:552
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9142096044520395
{'currentState': array([4., 5.])}
episode index:553
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.9142083547102192
{'currentState': array([4., 5.])}
episode index:554
start: 0
at step 0:
{'currentState': array([0., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.9141743545292255
{'currentState': array([4., 5.])}
episode index:555
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9141897688096189
{'currentState': array([4., 5.])}
episode index:556
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9142051277425064
{'currentState': array([4., 5.])}
episode index:557
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9142204316254552
{'currentState': array([4., 5.])}
episode index:558
start: 0
at step 0:
{'currentState': array([0., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 16
reward sum = 0.8514577710948755
running average episode reward sum: 0.9141081549518764
{'currentState': array([4., 5.])}
episode index:559
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9141235773437979
{'currentState': array([4., 5.])}
episode index:560
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9141062128120063
{'currentState': array([4., 5.])}
episode index:561
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9141215837757357
{'currentState': array([4., 5.])}
episode index:562
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9141369001356864
{'currentState': array([4., 5.])}
episode index:563
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9141196043464543
{'currentState': array([4., 5.])}
episode index:564
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9141348699926163
{'currentState': array([4., 5.])}
episode index:565
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9141500816965655
{'currentState': array([4., 5.])}
episode index:566
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9141652397437109
{'currentState': array([4., 5.])}
episode index:567
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9141803444174507
{'currentState': array([4., 5.])}
episode index:568
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9141953959991914
{'currentState': array([4., 5.])}
episode index:569
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9142103947683646
{'currentState': array([4., 5.])}
episode index:570
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9142253410024445
{'currentState': array([4., 5.])}
episode index:571
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9142402349769645
{'currentState': array([4., 5.])}
episode index:572
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9142550769655352
{'currentState': array([4., 5.])}
episode index:573
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.9142065226009891
{'currentState': array([4., 5.])}
episode index:574
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9142213715954708
{'currentState': array([4., 5.])}
episode index:575
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9142361690309438
{'currentState': array([4., 5.])}
episode index:576
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9142190908783925
{'currentState': array([4., 5.])}
episode index:577
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9142338410575439
{'currentState': array([4., 5.])}
episode index:578
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9142168259175634
{'currentState': array([4., 5.])}
episode index:579
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9141998694504794
{'currentState': array([4., 5.])}
episode index:580
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9142145765502684
{'currentState': array([4., 5.])}
episode index:581
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9142292331101957
{'currentState': array([4., 5.])}
episode index:582
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.914243839390329
{'currentState': array([4., 5.])}
episode index:583
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.914226952807484
{'currentState': array([4., 5.])}
episode index:584
start: 0
at step 0:
{'currentState': array([0., 0.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.9141946644338963
{'currentState': array([4., 5.])}
episode index:585
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9142092549287667
{'currentState': array([4., 5.])}
episode index:586
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9142237957115591
{'currentState': array([4., 5.])}
episode index:587
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9142382870359067
{'currentState': array([4., 5.])}
episode index:588
start: 0
at step 0:
{'currentState': array([0., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.9142061986950286
{'currentState': array([4., 5.])}
episode index:589
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9141895476379334
{'currentState': array([4., 5.])}
episode index:590
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.914204023351622
{'currentState': array([4., 5.])}
episode index:591
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9142184501608726
{'currentState': array([4., 5.])}
episode index:592
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.914171513266362
{'currentState': array([4., 5.])}
episode index:593
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9141859462312805
{'currentState': array([4., 5.])}
episode index:594
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.9141542694380493
{'currentState': array([4., 5.])}
episode index:595
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9141378731386713
{'currentState': array([4., 5.])}
episode index:596
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9141522899247505
{'currentState': array([4., 5.])}
episode index:597
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.9141512279808692
{'currentState': array([4., 5.])}
episode index:598
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9141655743355387
{'currentState': array([4., 5.])}
episode index:599
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 14
reward sum = 0.8687458127689782
running average episode reward sum: 0.9140898747329279
{'currentState': array([4., 5.])}
episode index:600
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 14
reward sum = 0.8687458127689782
running average episode reward sum: 0.9140144270424722
{'currentState': array([4., 5.])}
episode index:601
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9140289291477636
{'currentState': array([4., 5.])}
episode index:602
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9140433831532033
{'currentState': array([4., 5.])}
episode index:603
start: 0
at step 0:
{'currentState': array([0., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.9140425120676577
{'currentState': array([4., 5.])}
episode index:604
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9140568958401541
{'currentState': array([4., 5.])}
episode index:605
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9140712321414541
{'currentState': array([4., 5.])}
episode index:606
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9140855212061765
{'currentState': array([4., 5.])}
episode index:607
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9140997632673965
{'currentState': array([4., 5.])}
episode index:608
start: 0
at step 0:
{'currentState': array([0., 0.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.9140988067554363
{'currentState': array([4., 5.])}
episode index:609
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9141129803417847
{'currentState': array([4., 5.])}
episode index:610
start: 0
at step 0:
{'currentState': array([0., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.9141120053289237
{'currentState': array([4., 5.])}
episode index:611
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9141261110300658
{'currentState': array([4., 5.])}
episode index:612
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9141401707093446
{'currentState': array([4., 5.])}
episode index:613
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9141541845916225
{'currentState': array([4., 5.])}
episode index:614
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9141681529002994
{'currentState': array([4., 5.])}
episode index:615
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 25
reward sum = 0.7778213593991467
running average episode reward sum: 0.9139468107030572
{'currentState': array([4., 5.])}
episode index:616
start: 0
at step 0:
{'currentState': array([0., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9139313087003113
{'currentState': array([4., 5.])}
episode index:617
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9139455698422654
{'currentState': array([4., 5.])}
episode index:618
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9139597849062163
{'currentState': array([4., 5.])}
episode index:619
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9139739541151223
{'currentState': array([4., 5.])}
episode index:620
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9139880776905053
{'currentState': array([4., 5.])}
episode index:621
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9140021558524626
{'currentState': array([4., 5.])}
episode index:622
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9140161888196784
{'currentState': array([4., 5.])}
episode index:623
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9140301768094352
{'currentState': array([4., 5.])}
episode index:624
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9140441200376248
{'currentState': array([4., 5.])}
episode index:625
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9140580187187595
{'currentState': array([4., 5.])}
episode index:626
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.914071873065983
{'currentState': array([4., 5.])}
episode index:627
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9140856832910818
{'currentState': array([4., 5.])}
episode index:628
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9140994496044949
{'currentState': array([4., 5.])}
episode index:629
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 14
reward sum = 0.8687458127689782
running average episode reward sum: 0.914027459704756
{'currentState': array([4., 5.])}
episode index:630
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 16
reward sum = 0.8514577710948755
running average episode reward sum: 0.9139283001348512
{'currentState': array([4., 5.])}
episode index:631
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9139422501258212
{'currentState': array([4., 5.])}
episode index:632
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9139271471635511
{'currentState': array([4., 5.])}
episode index:633
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9139410549668072
{'currentState': array([4., 5.])}
episode index:634
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9139260014550623
{'currentState': array([4., 5.])}
episode index:635
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9139398673245165
{'currentState': array([4., 5.])}
episode index:636
start: 0
at step 0:
{'currentState': array([0., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.9139106654201746
{'currentState': array([4., 5.])}
episode index:637
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9139245118606256
{'currentState': array([4., 5.])}
episode index:638
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9139383149632349
{'currentState': array([4., 5.])}
episode index:639
start: 0
at step 0:
{'currentState': array([0., 0.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 29
reward sum = 0.7471720943315961
running average episode reward sum: 0.913677742743498
{'currentState': array([4., 5.])}
episode index:640
start: 0
at step 0:
{'currentState': array([0., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 19
reward sum = 0.8261686238355866
running average episode reward sum: 0.9135412230572142
{'currentState': array([4., 5.])}
episode index:641
start: 0
at step 0:
{'currentState': array([0., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.9135411857120841
{'currentState': array([4., 5.])}
episode index:642
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9135554991004446
{'currentState': array([4., 5.])}
episode index:643
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9135697680372886
{'currentState': array([4., 5.])}
episode index:644
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9135839927293671
{'currentState': array([4., 5.])}
episode index:645
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9135981733821512
{'currentState': array([4., 5.])}
episode index:646
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9136123101998418
{'currentState': array([4., 5.])}
episode index:647
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9135980660097321
{'currentState': array([4., 5.])}
episode index:648
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.913612159427942
{'currentState': array([4., 5.])}
episode index:649
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9136262094817882
{'currentState': array([4., 5.])}
episode index:650
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9136402163711064
{'currentState': array([4., 5.])}
episode index:651
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.91362601676779
{'currentState': array([4., 5.])}
episode index:652
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9136399810521088
{'currentState': array([4., 5.])}
episode index:653
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.913653902632194
{'currentState': array([4., 5.])}
episode index:654
start: 0
at step 0:
{'currentState': array([0., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 18
reward sum = 0.8345137614500875
running average episode reward sum: 0.913533077989168
{'currentState': array([4., 5.])}
episode index:655
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 14
reward sum = 0.8687458127689782
running average episode reward sum: 0.9134648047190154
{'currentState': array([4., 5.])}
episode index:656
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [4. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9134789293608858
{'currentState': array([4., 5.])}
episode index:657
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 14
reward sum = 0.8687458127689782
running average episode reward sum: 0.9134109459010198
{'currentState': array([4., 5.])}
episode index:658
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 27
reward sum = 0.7623427143471035
running average episode reward sum: 0.913181707309891
{'currentState': array([4., 5.])}
episode index:659
start: 0
at step 0:
{'currentState': array([0., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 16
reward sum = 0.8514577710948755
running average episode reward sum: 0.9130881861944137
{'currentState': array([4., 5.])}
episode index:660
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9131027951327397
{'currentState': array([4., 5.])}
episode index:661
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9131173599353004
{'currentState': array([4., 5.])}
episode index:662
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9131318808018052
{'currentState': array([4., 5.])}
episode index:663
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9131463579307602
{'currentState': array([4., 5.])}
episode index:664
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9131607915194777
{'currentState': array([4., 5.])}
episode index:665
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.9131340309530201
{'currentState': array([4., 5.])}
episode index:666
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [4. 4.]
finish  [4. 5.] 1 1
done in step count: 14
reward sum = 0.8687458127689782
running average episode reward sum: 0.9130674819002704
{'currentState': array([4., 5.])}
episode index:667
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9130544797941456
{'currentState': array([4., 5.])}
episode index:668
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.913068964419906
{'currentState': array([4., 5.])}
episode index:669
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9130834058079778
{'currentState': array([4., 5.])}
episode index:670
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9130978041516736
{'currentState': array([4., 5.])}
episode index:671
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9131121596431562
{'currentState': array([4., 5.])}
episode index:672
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.9131127615567379
{'currentState': array([4., 5.])}
episode index:673
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.9130599548229728
{'currentState': array([4., 5.])}
episode index:674
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9130743025853505
{'currentState': array([4., 5.])}
episode index:675
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 18
reward sum = 0.8345137614500875
running average episode reward sum: 0.912958088767103
{'currentState': array([4., 5.])}
episode index:676
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.9129589147031689
{'currentState': array([4., 5.])}
episode index:677
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 16
reward sum = 0.8514577710948755
running average episode reward sum: 0.9128682050518292
{'currentState': array([4., 5.])}
episode index:678
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 20
reward sum = 0.8179069375972308
running average episode reward sum: 0.9127283504605854
{'currentState': array([4., 5.])}
episode index:679
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 18
reward sum = 0.8345137614500875
running average episode reward sum: 0.9126133290061582
{'currentState': array([4., 5.])}
episode index:680
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 16
reward sum = 0.8514577710948755
running average episode reward sum: 0.9125235264247906
{'currentState': array([4., 5.])}
episode index:681
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9125385134746486
{'currentState': array([4., 5.])}
episode index:682
start: 0
at step 0:
{'currentState': array([0., 0.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 14
reward sum = 0.8687458127689782
running average episode reward sum: 0.9124743953184179
{'currentState': array([4., 5.])}
episode index:683
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9124894103755955
{'currentState': array([4., 5.])}
episode index:684
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9124775748495126
{'currentState': array([4., 5.])}
episode index:685
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9124925414961284
{'currentState': array([4., 5.])}
episode index:686
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9125074645717205
{'currentState': array([4., 5.])}
episode index:687
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [4. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9124956544124722
{'currentState': array([4., 5.])}
episode index:688
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 20
reward sum = 0.8179069375972308
running average episode reward sum: 0.9123583703532339
{'currentState': array([4., 5.])}
episode index:689
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 19
reward sum = 0.8261686238355866
running average episode reward sum: 0.9122334576771213
{'currentState': array([4., 5.])}
episode index:690
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.9122090073103797
{'currentState': array([4., 5.])}
episode index:691
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9122242322917634
{'currentState': array([4., 5.])}
episode index:692
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 16
reward sum = 0.8514577710948755
running average episode reward sum: 0.9121365462005702
{'currentState': array([4., 5.])}
episode index:693
start: 0
at step 0:
{'currentState': array([0., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.9121385356836871
{'currentState': array([4., 5.])}
episode index:694
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9121537963437507
{'currentState': array([4., 5.])}
episode index:695
start: 0
at step 0:
{'currentState': array([0., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.9121557553252736
{'currentState': array([4., 5.])}
episode index:696
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9121709474904137
{'currentState': array([4., 5.])}
episode index:697
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9121860961249947
{'currentState': array([4., 5.])}
episode index:698
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.912201201415843
{'currentState': array([4., 5.])}
episode index:699
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9121900312352615
{'currentState': array([4., 5.])}
episode index:700
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9122050878161355
{'currentState': array([4., 5.])}
episode index:701
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9122201015007677
{'currentState': array([4., 5.])}
episode index:702
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9122350724722146
{'currentState': array([4., 5.])}
episode index:703
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9122500009124926
{'currentState': array([4., 5.])}
episode index:704
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9122648870025855
{'currentState': array([4., 5.])}
episode index:705
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9122797309224514
{'currentState': array([4., 5.])}
episode index:706
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9122945328510306
{'currentState': array([4., 5.])}
episode index:707
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9122833570631178
{'currentState': array([4., 5.])}
episode index:708
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.9122468288750403
{'currentState': array([4., 5.])}
episode index:709
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9122616146011711
{'currentState': array([4., 5.])}
episode index:710
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9122763587359486
{'currentState': array([4., 5.])}
episode index:711
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.912291061454617
{'currentState': array([4., 5.])}
episode index:712
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.9122547273876627
{'currentState': array([4., 5.])}
episode index:713
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9122694192182512
{'currentState': array([4., 5.])}
episode index:714
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9122840699528103
{'currentState': array([4., 5.])}
episode index:715
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9122986797635297
{'currentState': array([4., 5.])}
episode index:716
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9123132488216391
{'currentState': array([4., 5.])}
episode index:717
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9123277772974139
{'currentState': array([4., 5.])}
episode index:718
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9123422653601823
{'currentState': array([4., 5.])}
episode index:719
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.912356713178332
{'currentState': array([4., 5.])}
episode index:720
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9123711209193162
{'currentState': array([4., 5.])}
episode index:721
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9123600557587753
{'currentState': array([4., 5.])}
episode index:722
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9123744190211116
{'currentState': array([4., 5.])}
episode index:723
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9123887426059276
{'currentState': array([4., 5.])}
episode index:724
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 14
reward sum = 0.8687458127689782
running average episode reward sum: 0.912328545461325
{'currentState': array([4., 5.])}
episode index:725
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 27
reward sum = 0.7623427143471035
running average episode reward sum: 0.9121219534074487
{'currentState': array([4., 5.])}
episode index:726
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9121113070822787
{'currentState': array([4., 5.])}
episode index:727
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9121259133835776
{'currentState': array([4., 5.])}
episode index:728
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9121404796127194
{'currentState': array([4., 5.])}
episode index:729
start: 0
at step 0:
{'currentState': array([0., 0.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 14
reward sum = 0.8687458127689782
running average episode reward sum: 0.9120810348636185
{'currentState': array([4., 5.])}
episode index:730
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9120956226332003
{'currentState': array([4., 5.])}
episode index:731
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9120850849998337
{'currentState': array([4., 5.])}
episode index:732
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9120996274410725
{'currentState': array([4., 5.])}
episode index:733
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.912114130257131
{'currentState': array([4., 5.])}
episode index:734
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9121285936097443
{'currentState': array([4., 5.])}
episode index:735
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9121180684486017
{'currentState': array([4., 5.])}
episode index:736
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9121324872084108
{'currentState': array([4., 5.])}
episode index:737
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9121468668929901
{'currentState': array([4., 5.])}
episode index:738
start: 0
at step 0:
{'currentState': array([0., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.9121241218150006
{'currentState': array([4., 5.])}
episode index:739
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 106
reward sum = 0.3446121833475176
running average episode reward sum: 0.9113572137900445
{'currentState': array([4., 5.])}
episode index:740
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 15
reward sum = 0.8600583546412884
running average episode reward sum: 0.911287984560424
{'currentState': array([4., 5.])}
episode index:741
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9113034248702185
{'currentState': array([4., 5.])}
episode index:742
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.9112698871136182
{'currentState': array([4., 5.])}
episode index:743
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9112853102417289
{'currentState': array([4., 5.])}
episode index:744
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9113006919654687
{'currentState': array([4., 5.])}
episode index:745
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.9112792945958886
{'currentState': array([4., 5.])}
episode index:746
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 14
reward sum = 0.8687458127689782
running average episode reward sum: 0.9112223555305247
{'currentState': array([4., 5.])}
episode index:747
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9112377597269116
{'currentState': array([4., 5.])}
episode index:748
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9112531227905979
{'currentState': array([4., 5.])}
episode index:749
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9112684448861142
{'currentState': array([4., 5.])}
episode index:750
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9112837261771154
{'currentState': array([4., 5.])}
episode index:751
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [4. 4.]
finish  [4. 5.] 1 1
done in step count: 23
reward sum = 0.7936142836436554
running average episode reward sum: 0.9111272508545976
{'currentState': array([4., 5.])}
episode index:752
start: 0
at step 0:
{'currentState': array([0., 0.])}
job passage [4. 4.]
finish  [4. 5.] 1 1
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.9111304248209044
{'currentState': array([4., 5.])}
episode index:753
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 20
reward sum = 0.8179069375972308
running average episode reward sum: 0.9110067862436848
{'currentState': array([4., 5.])}
episode index:754
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.91101011135791
{'currentState': array([4., 5.])}
episode index:755
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 19
reward sum = 0.8261686238355866
running average episode reward sum: 0.9108978871680656
{'currentState': array([4., 5.])}
episode index:756
start: 0
at step 0:
{'currentState': array([0., 0.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 26
reward sum = 0.7700431458051551
running average episode reward sum: 0.9107118174965162
{'currentState': array([4., 5.])}
episode index:757
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9107276920043412
{'currentState': array([4., 5.])}
episode index:758
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9107435246821062
{'currentState': array([4., 5.])}
episode index:759
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9107593156949296
{'currentState': array([4., 5.])}
episode index:760
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.9107272862021849
{'currentState': array([4., 5.])}
episode index:761
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9107430570791215
{'currentState': array([4., 5.])}
episode index:762
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9107587866169312
{'currentState': array([4., 5.])}
episode index:763
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9107744749779404
{'currentState': array([4., 5.])}
episode index:764
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9107901223236267
{'currentState': array([4., 5.])}
episode index:765
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [4. 4.]
finish  [4. 5.] 1 1
done in step count: 19
reward sum = 0.8261686238355866
running average episode reward sum: 0.9106796503934856
{'currentState': array([4., 5.])}
episode index:766
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9106953805682372
{'currentState': array([4., 5.])}
episode index:767
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.910711069778992
{'currentState': array([4., 5.])}
episode index:768
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.910679436231446
{'currentState': array([4., 5.])}
episode index:769
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.910695105397935
{'currentState': array([4., 5.])}
episode index:770
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9106869172910749
{'currentState': array([4., 5.])}
episode index:771
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9107025361733765
{'currentState': array([4., 5.])}
episode index:772
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9107181146445984
{'currentState': array([4., 5.])}
episode index:773
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9107336528613728
{'currentState': array([4., 5.])}
episode index:774
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9107491509795231
{'currentState': array([4., 5.])}
episode index:775
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9107646091540701
{'currentState': array([4., 5.])}
episode index:776
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9107800275392359
{'currentState': array([4., 5.])}
episode index:777
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9107954062884502
{'currentState': array([4., 5.])}
episode index:778
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9107871735140219
{'currentState': array([4., 5.])}
episode index:779
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9107789618492717
{'currentState': array([4., 5.])}
episode index:780
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9107707712131122
{'currentState': array([4., 5.])}
episode index:781
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9107860831353819
{'currentState': array([4., 5.])}
episode index:782
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9108013559467388
{'currentState': array([4., 5.])}
episode index:783
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9108165897968424
{'currentState': array([4., 5.])}
episode index:784
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.910831784834589
{'currentState': array([4., 5.])}
episode index:785
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9108469412081175
{'currentState': array([4., 5.])}
episode index:786
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9108620590648135
{'currentState': array([4., 5.])}
episode index:787
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.910877138551315
{'currentState': array([4., 5.])}
episode index:788
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.910892179813516
{'currentState': array([4., 5.])}
episode index:789
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9109071829965723
{'currentState': array([4., 5.])}
episode index:790
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9109221482449052
{'currentState': array([4., 5.])}
episode index:791
start: 0
at step 0:
{'currentState': array([0., 0.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.9109254248853582
{'currentState': array([4., 5.])}
episode index:792
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9109403293866729
{'currentState': array([4., 5.])}
episode index:793
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9109551963451632
{'currentState': array([4., 5.])}
episode index:794
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9109700259025
{'currentState': array([4., 5.])}
episode index:795
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9109848181996425
{'currentState': array([4., 5.])}
episode index:796
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9109995733768423
{'currentState': array([4., 5.])}
episode index:797
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9109912807723711
{'currentState': array([4., 5.])}
episode index:798
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9110059909271341
{'currentState': array([4., 5.])}
episode index:799
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9110206643065101
{'currentState': array([4., 5.])}
episode index:800
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9110353010482347
{'currentState': array([4., 5.])}
episode index:801
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9110499012893565
{'currentState': array([4., 5.])}
episode index:802
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9110644651662414
{'currentState': array([4., 5.])}
episode index:803
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9110789928145768
{'currentState': array([4., 5.])}
episode index:804
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9110706736620231
{'currentState': array([4., 5.])}
episode index:805
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.911085157558755
{'currentState': array([4., 5.])}
episode index:806
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.911099605559832
{'currentState': array([4., 5.])}
episode index:807
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9110912917843976
{'currentState': array([4., 5.])}
episode index:808
start: 0
at step 0:
{'currentState': array([0., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.9110718195501261
{'currentState': array([4., 5.])}
episode index:809
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9110635606062479
{'currentState': array([4., 5.])}
episode index:810
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9110779639771748
{'currentState': array([4., 5.])}
episode index:811
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9110697178084946
{'currentState': array([4., 5.])}
episode index:812
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.911061491925592
{'currentState': array([4., 5.])}
episode index:813
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.9110202874183112
{'currentState': array([4., 5.])}
episode index:814
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 22
reward sum = 0.8016305895390459
running average episode reward sum: 0.9108860669301159
{'currentState': array([4., 5.])}
episode index:815
start: 0
at step 0:
{'currentState': array([0., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.9108451783958864
{'currentState': array([4., 5.])}
episode index:816
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9108597432869906
{'currentState': array([4., 5.])}
episode index:817
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.910874272567114
{'currentState': array([4., 5.])}
episode index:818
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9108887663666998
{'currentState': array([4., 5.])}
episode index:819
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.910903224815555
{'currentState': array([4., 5.])}
episode index:820
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9109176480428539
{'currentState': array([4., 5.])}
episode index:821
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9109320361771422
{'currentState': array([4., 5.])}
episode index:822
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9109240775365975
{'currentState': array([4., 5.])}
episode index:823
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9109384229454462
{'currentState': array([4., 5.])}
episode index:824
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9109527335775462
{'currentState': array([4., 5.])}
episode index:825
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9109670095592053
{'currentState': array([4., 5.])}
episode index:826
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9109812510161203
{'currentState': array([4., 5.])}
episode index:827
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.910995458073381
{'currentState': array([4., 5.])}
episode index:828
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9110096308554733
{'currentState': array([4., 5.])}
episode index:829
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9110237694862835
{'currentState': array([4., 5.])}
episode index:830
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9110378740891014
{'currentState': array([4., 5.])}
episode index:831
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.911051944786624
{'currentState': array([4., 5.])}
episode index:832
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.9110116915791958
{'currentState': array([4., 5.])}
episode index:833
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 16
reward sum = 0.8514577710948755
running average episode reward sum: 0.9109402840006774
{'currentState': array([4., 5.])}
episode index:834
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 72
reward sum = 0.48499137027416284
running average episode reward sum: 0.9104301655411248
{'currentState': array([4., 5.])}
episode index:835
start: 0
at step 0:
{'currentState': array([0., 0.])}
job passage [4. 4.]
finish  [4. 5.] 1 1
done in step count: 22
reward sum = 0.8016305895390459
running average episode reward sum: 0.9103000225076294
{'currentState': array([4., 5.])}
episode index:836
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 17
reward sum = 0.8429431933839268
running average episode reward sum: 0.9102195483987601
{'currentState': array([4., 5.])}
episode index:837
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9102344948737352
{'currentState': array([4., 5.])}
episode index:838
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9102494057194493
{'currentState': array([4., 5.])}
episode index:839
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9102642810631499
{'currentState': array([4., 5.])}
episode index:840
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.910279121031479
{'currentState': array([4., 5.])}
episode index:841
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9102939257504772
{'currentState': array([4., 5.])}
episode index:842
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9103086953455869
{'currentState': array([4., 5.])}
episode index:843
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.910323429941656
{'currentState': array([4., 5.])}
episode index:844
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9103381296629416
{'currentState': array([4., 5.])}
episode index:845
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9103527946331129
{'currentState': array([4., 5.])}
episode index:846
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9103674249752556
{'currentState': array([4., 5.])}
episode index:847
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9103820208118742
{'currentState': array([4., 5.])}
episode index:848
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9103965822648967
{'currentState': array([4., 5.])}
episode index:849
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9104111094556768
{'currentState': array([4., 5.])}
episode index:850
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9104256025049979
{'currentState': array([4., 5.])}
episode index:851
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9104400615330764
{'currentState': array([4., 5.])}
episode index:852
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9104544866595652
{'currentState': array([4., 5.])}
episode index:853
start: 0
at step 0:
{'currentState': array([0., 0.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 14
reward sum = 0.8687458127689782
running average episode reward sum: 0.910405647462972
{'currentState': array([4., 5.])}
episode index:854
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.9104092867612419
{'currentState': array([4., 5.])}
episode index:855
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.910423697284217
{'currentState': array([4., 5.])}
episode index:856
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9104380741770335
{'currentState': array([4., 5.])}
episode index:857
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9104310159029446
{'currentState': array([4., 5.])}
episode index:858
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9104453508022752
{'currentState': array([4., 5.])}
episode index:859
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9104596523646307
{'currentState': array([4., 5.])}
episode index:860
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9104739207061676
{'currentState': array([4., 5.])}
episode index:861
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9104881559425038
{'currentState': array([4., 5.])}
episode index:862
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9105023581887209
{'currentState': array([4., 5.])}
episode index:863
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.910495274527633
{'currentState': array([4., 5.])}
episode index:864
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9104882072449523
{'currentState': array([4., 5.])}
episode index:865
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9105023602324616
{'currentState': array([4., 5.])}
episode index:866
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9105164805717874
{'currentState': array([4., 5.])}
episode index:867
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9105305683757691
{'currentState': array([4., 5.])}
episode index:868
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9105446237567267
{'currentState': array([4., 5.])}
episode index:869
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9105586468264637
{'currentState': array([4., 5.])}
episode index:870
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9105726376962702
{'currentState': array([4., 5.])}
episode index:871
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9105865964769257
{'currentState': array([4., 5.])}
episode index:872
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9105794893503872
{'currentState': array([4., 5.])}
episode index:873
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9105723984872962
{'currentState': array([4., 5.])}
episode index:874
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.910586309682657
{'currentState': array([4., 5.])}
episode index:875
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9106001891172977
{'currentState': array([4., 5.])}
episode index:876
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9105930989073678
{'currentState': array([4., 5.])}
episode index:877
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9106069389933822
{'currentState': array([4., 5.])}
episode index:878
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9106207475888708
{'currentState': array([4., 5.])}
episode index:879
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.910634524801188
{'currentState': array([4., 5.])}
episode index:880
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9106482707372001
{'currentState': array([4., 5.])}
episode index:881
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9106619855032894
{'currentState': array([4., 5.])}
episode index:882
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9106756692053558
{'currentState': array([4., 5.])}
episode index:883
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9106893219488202
{'currentState': array([4., 5.])}
episode index:884
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9107029438386272
{'currentState': array([4., 5.])}
episode index:885
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9106958096751624
{'currentState': array([4., 5.])}
episode index:886
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9107093935362139
{'currentState': array([4., 5.])}
episode index:887
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9107229468029839
{'currentState': array([4., 5.])}
episode index:888
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.910736469578715
{'currentState': array([4., 5.])}
episode index:889
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9107499619661861
{'currentState': array([4., 5.])}
episode index:890
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9107634240677144
{'currentState': array([4., 5.])}
episode index:891
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9107768559851586
{'currentState': array([4., 5.])}
episode index:892
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.910790257819921
{'currentState': array([4., 5.])}
episode index:893
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.91080362967295
{'currentState': array([4., 5.])}
episode index:894
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9108169716447433
{'currentState': array([4., 5.])}
episode index:895
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [4. 4.]
finish  [4. 5.] 1 1
done in step count: 15
reward sum = 0.8600583546412884
running average episode reward sum: 0.910760321402552
{'currentState': array([4., 5.])}
episode index:896
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.910773681907597
{'currentState': array([4., 5.])}
episode index:897
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9107870126565061
{'currentState': array([4., 5.])}
episode index:898
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.9107900496251681
{'currentState': array([4., 5.])}
episode index:899
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9108033325638378
{'currentState': array([4., 5.])}
episode index:900
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9107962057519011
{'currentState': array([4., 5.])}
episode index:901
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9108094524134045
{'currentState': array([4., 5.])}
episode index:902
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9108226697356797
{'currentState': array([4., 5.])}
episode index:903
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9108358578160914
{'currentState': array([4., 5.])}
episode index:904
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9108490167515741
{'currentState': array([4., 5.])}
episode index:905
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9108418788467808
{'currentState': array([4., 5.])}
episode index:906
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9108550021274656
{'currentState': array([4., 5.])}
episode index:907
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9108680965022459
{'currentState': array([4., 5.])}
episode index:908
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9108609611650694
{'currentState': array([4., 5.])}
episode index:909
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.910874020212611
{'currentState': array([4., 5.])}
episode index:910
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9108870505904544
{'currentState': array([4., 5.])}
episode index:911
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9109000523929078
{'currentState': array([4., 5.])}
episode index:912
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9109130257138662
{'currentState': array([4., 5.])}
episode index:913
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9109259706468138
{'currentState': array([4., 5.])}
episode index:914
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9109388872848259
{'currentState': array([4., 5.])}
episode index:915
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9109517757205716
{'currentState': array([4., 5.])}
episode index:916
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9109646360463158
{'currentState': array([4., 5.])}
episode index:917
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.910977468353921
{'currentState': array([4., 5.])}
episode index:918
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9109902727348503
{'currentState': array([4., 5.])}
episode index:919
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9110030492801688
{'currentState': array([4., 5.])}
episode index:920
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9110157980805464
{'currentState': array([4., 5.])}
episode index:921
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.9110185111493134
{'currentState': array([4., 5.])}
episode index:922
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.911031215573234
{'currentState': array([4., 5.])}
episode index:923
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9110438924984013
{'currentState': array([4., 5.])}
episode index:924
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9110565420140009
{'currentState': array([4., 5.])}
episode index:925
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9110493341662631
{'currentState': array([4., 5.])}
episode index:926
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9110421418694373
{'currentState': array([4., 5.])}
episode index:927
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9110547523786598
{'currentState': array([4., 5.])}
episode index:928
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9110673357393158
{'currentState': array([4., 5.])}
episode index:929
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9110798920389809
{'currentState': array([4., 5.])}
episode index:930
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9110726978209034
{'currentState': array([4., 5.])}
episode index:931
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9110852214224131
{'currentState': array([4., 5.])}
episode index:932
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9110780369139312
{'currentState': array([4., 5.])}
episode index:933
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9110905279819334
{'currentState': array([4., 5.])}
episode index:934
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.9110641048201518
{'currentState': array([4., 5.])}
episode index:935
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9110765840825532
{'currentState': array([4., 5.])}
episode index:936
start: 0
at step 0:
{'currentState': array([0., 0.])}
job passage [4. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9110694394624105
{'currentState': array([4., 5.])}
episode index:937
start: 0
at step 0:
{'currentState': array([0., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.9110720490658447
{'currentState': array([4., 5.])}
episode index:938
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9110844799980726
{'currentState': array([4., 5.])}
episode index:939
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9110968844815087
{'currentState': array([4., 5.])}
episode index:940
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9111092626004741
{'currentState': array([4., 5.])}
episode index:941
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9111216144389321
{'currentState': array([4., 5.])}
episode index:942
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9111339400804899
{'currentState': array([4., 5.])}
episode index:943
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9111462396084004
{'currentState': array([4., 5.])}
episode index:944
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9111585131055638
{'currentState': array([4., 5.])}
episode index:945
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9111513498517618
{'currentState': array([4., 5.])}
episode index:946
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9111635920318845
{'currentState': array([4., 5.])}
episode index:947
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9111758083846229
{'currentState': array([4., 5.])}
episode index:948
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.911168649550718
{'currentState': array([4., 5.])}
episode index:949
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.911180834861115
{'currentState': array([4., 5.])}
episode index:950
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9111929945452021
{'currentState': array([4., 5.])}
episode index:951
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.911185840217958
{'currentState': array([4., 5.])}
episode index:952
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 20
reward sum = 0.8179069375972308
running average episode reward sum: 0.9110879609917033
{'currentState': array([4., 5.])}
episode index:953
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.911062066768144
{'currentState': array([4., 5.])}
episode index:954
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.9110456020430033
{'currentState': array([4., 5.])}
episode index:955
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 22
reward sum = 0.8016305895390459
running average episode reward sum: 0.9109311511931037
{'currentState': array([4., 5.])}
episode index:956
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9109434955434014
{'currentState': array([4., 5.])}
episode index:957
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9109558141226128
{'currentState': array([4., 5.])}
episode index:958
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9109681070113567
{'currentState': array([4., 5.])}
episode index:959
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9109803742899155
{'currentState': array([4., 5.])}
episode index:960
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9109926160382381
{'currentState': array([4., 5.])}
episode index:961
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9110048323359405
{'currentState': array([4., 5.])}
episode index:962
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9110170232623082
{'currentState': array([4., 5.])}
episode index:963
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9110291888962974
{'currentState': array([4., 5.])}
episode index:964
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9110413293165374
{'currentState': array([4., 5.])}
episode index:965
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9110534446013319
{'currentState': array([4., 5.])}
episode index:966
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9110655348286603
{'currentState': array([4., 5.])}
episode index:967
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9110776000761802
{'currentState': array([4., 5.])}
episode index:968
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9110706903495884
{'currentState': array([4., 5.])}
episode index:969
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9110827254053393
{'currentState': array([4., 5.])}
episode index:970
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9110758246325313
{'currentState': array([4., 5.])}
episode index:971
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9110878296426089
{'currentState': array([4., 5.])}
episode index:972
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9110998099764068
{'currentState': array([4., 5.])}
episode index:973
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9111117657099299
{'currentState': array([4., 5.])}
episode index:974
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.911104863463057
{'currentState': array([4., 5.])}
episode index:975
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [1. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9111167895193735
{'currentState': array([4., 5.])}
episode index:976
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9111098962598949
{'currentState': array([4., 5.])}
episode index:977
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9111217927815392
{'currentState': array([4., 5.])}
episode index:978
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9111336649997683
{'currentState': array([4., 5.])}
episode index:979
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9111267756222265
{'currentState': array([4., 5.])}
episode index:980
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9111386185567889
{'currentState': array([4., 5.])}
episode index:981
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9111504373713216
{'currentState': array([4., 5.])}
episode index:982
start: 0
at step 0:
{'currentState': array([0., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9111435519569142
{'currentState': array([4., 5.])}
episode index:983
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9111553417358482
{'currentState': array([4., 5.])}
episode index:984
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9111484653229274
{'currentState': array([4., 5.])}
episode index:985
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9111602262043725
{'currentState': array([4., 5.])}
episode index:986
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9111719632542444
{'currentState': array([4., 5.])}
episode index:987
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [0. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9111836765449061
{'currentState': array([4., 5.])}
episode index:988
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9111953661484279
{'currentState': array([4., 5.])}
episode index:989
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9112070321365889
{'currentState': array([4., 5.])}
episode index:990
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9112186745808789
{'currentState': array([4., 5.])}
episode index:991
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.911230293552499
{'currentState': array([4., 5.])}
episode index:992
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9112418891223635
{'currentState': array([4., 5.])}
episode index:993
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9112349879009213
{'currentState': array([4., 5.])}
episode index:994
start: 0
at step 0:
{'currentState': array([0., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.9112372816291451
{'currentState': array([4., 5.])}
episode index:995
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9112488352564532
{'currentState': array([4., 5.])}
episode index:996
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9112603657069762
{'currentState': array([4., 5.])}
episode index:997
start: 0
at step 0:
{'currentState': array([1., 0.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9112718730503839
{'currentState': array([4., 5.])}
episode index:998
start: 0
at step 0:
{'currentState': array([0., 0.])}
job passage [3. 4.]
finish  [4. 5.] 1 1
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.9112741206724393
{'currentState': array([4., 5.])}
episode index:999
start: 0
at step 0:
{'currentState': array([0., 1.])}
job passage [2. 4.]
finish  [4. 5.] 1 1
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9112672286267757
{'currentState': array([4., 5.])}
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]
start: 0
finish  [4. 5.] 1 1
finish step: 7
[4. 5.]

Process finished with exit code 0
