TTPG barely work.


/home/yangyutu/anaconda3/bin/python /home/yangyutu/Dropbox/pythonScripts/DeepReinforcementLearning-PyTorch/Env/CustomEnv/TwoArmRobot/DDPGSolver/DDPG_TwoArmRobot.py
episode index:0
target Thresh 0.19999999999999996
current state at start:  [-1.58534054 -2.78765448]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.58534054, -2.78765448]), 'currentState': array([4.56830448, 3.33108981]), 'targetState': array([-0.3604058 ,  0.03839912]), 'effectorPosition': array([-0.18898352,  0.00933125])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 1.0
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.58534054, -2.78765448]), 'currentState': array([4.56830448, 3.33108981]), 'targetState': array([-0.3604058 ,  0.03839912]), 'effectorPosition': array([-0.18898352,  0.00933125])}
episode index:1
target Thresh 0.2035964023988004
current state at start:  [ 2.33772353 -1.87225941]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.33772353, -1.87225941]), 'currentState': array([2.55563689, 4.07941893]), 'targetState': array([0.19382502, 1.23333276]), 'effectorPosition': array([0.10554574, 0.89765027])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 1.0
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.33772353, -1.87225941]), 'currentState': array([2.55563689, 4.07941893]), 'targetState': array([0.19382502, 1.23333276]), 'effectorPosition': array([0.10554574, 0.89765027])}
episode index:2
target Thresh 0.20718561918081524
current state at start:  [-3.12156106  2.05144517]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.12156106,  2.05144517]), 'currentState': array([3.53954526, 1.55144517]), 'targetState': array([-0.50871615, -0.96410962]), 'effectorPosition': array([-0.55223503, -1.31671423])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 1.0
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.12156106,  2.05144517]), 'currentState': array([3.53954526, 1.55144517]), 'targetState': array([-0.50871615, -0.96410962]), 'effectorPosition': array([-0.55223503, -1.31671423])}
episode index:3
target Thresh 0.2107676647029164
current state at start:  [1.59278017 1.92791471]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.59278017, 1.92791471]), 'currentState': array([2.09278017, 1.42791471]), 'targetState': array([-1.00961371,  0.65151071]), 'effectorPosition': array([-1.42759804,  0.49674515])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 1.0
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.59278017, 1.92791471]), 'currentState': array([2.09278017, 1.42791471]), 'targetState': array([-1.00961371,  0.65151071]), 'effectorPosition': array([-1.42759804,  0.49674515])}
episode index:4
target Thresh 0.21434255329329077
current state at start:  [-3.30366087  2.99209283]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.30366087,  2.99209283]), 'currentState': array([3.43487093, 2.49209283]), 'targetState': array([ 0.03200125, -0.04326916]), 'effectorPosition': array([-0.02008011, -0.63782756])}
done in step count: 76
reward sum = 0.46588077516979337
running average episode reward sum: 0.8931761550339588
{'reset': False, 'endBeforeDone': False, 'stepCount': 77, 'initial state': array([-3.30366087,  2.99209283]), 'currentState': array([4.8565804 , 3.56997506]), 'targetState': array([ 0.03200125, -0.04326916]), 'effectorPosition': array([-0.39810488, -0.14911315])}
episode index:5
target Thresh 0.2179102992514974
current state at start:  [-0.83331682 -3.03733924]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.83331682, -3.03733924]), 'currentState': array([5.94986848, 2.82948358]), 'targetState': array([-0.00982486,  0.01482018]), 'effectorPosition': array([0.1461187 , 0.27435962])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9109801291949656
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.83331682, -3.03733924]), 'currentState': array([5.94986848, 2.82948358]), 'targetState': array([-0.00982486,  0.01482018]), 'effectorPosition': array([0.1461187 , 0.27435962])}
episode index:6
target Thresh 0.22147091684852493
current state at start:  [-0.058167   -2.66342111]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.058167  , -2.66342111]), 'currentState': array([0.441833  , 3.20584692]), 'targetState': array([ 0.08820848, -0.46419178]), 'effectorPosition': array([ 0.02932147, -0.05716155])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9236972535956848
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.058167  , -2.66342111]), 'currentState': array([0.441833  , 3.20584692]), 'targetState': array([ 0.08820848, -0.46419178]), 'effectorPosition': array([ 0.02932147, -0.05716155])}
episode index:7
target Thresh 0.22502442032684855
current state at start:  [ 3.81862066 -1.67125291]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.81862066, -1.67125291]), 'currentState': array([4.31862066, 4.14980977]), 'targetState': array([-1.38641064,  0.14595061]), 'effectorPosition': array([-0.96017929, -0.10637848])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9332350968962242
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.81862066, -1.67125291]), 'currentState': array([4.31862066, 4.14980977]), 'targetState': array([-1.38641064,  0.14595061]), 'effectorPosition': array([-0.96017929, -0.10637848])}
episode index:8
target Thresh 0.22857082390048666
current state at start:  [0.07025427 2.48668451]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.07025427, 2.48668451]), 'currentState': array([0.49212059, 2.10746164]), 'targetState': array([0.1389546 , 0.53176713]), 'effectorPosition': array([0.02465955, 0.9883552 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9406534194633104
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.07025427, 2.48668451]), 'currentState': array([0.49212059, 2.10746164]), 'targetState': array([0.1389546 , 0.53176713]), 'effectorPosition': array([0.02465955, 0.9883552 ])}
episode index:9
target Thresh 0.23211014175505862
current state at start:  [-0.71826859  2.37651924]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.71826859,  2.37651924]), 'currentState': array([5.7995551 , 2.03288749]), 'targetState': array([0.77603519, 0.33556952]), 'effectorPosition': array([0.90685011, 0.53477194])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9465880775169794
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.71826859,  2.37651924]), 'currentState': array([5.7995551 , 2.03288749]), 'targetState': array([0.77603519, 0.33556952]), 'effectorPosition': array([0.90685011, 0.53477194])}
episode index:10
target Thresh 0.23564238804784043
current state at start:  [0.06858762 2.40395616]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.06858762, 2.40395616]), 'currentState': array([0.56858762, 2.25455849]), 'targetState': array([0.20324543, 0.76776982]), 'effectorPosition': array([-0.10706064,  0.85153401])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9514437068336176
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.06858762, 2.40395616]), 'currentState': array([0.56858762, 2.25455849]), 'targetState': array([0.20324543, 0.76776982]), 'effectorPosition': array([-0.10706064,  0.85153401])}
episode index:11
target Thresh 0.23916757690782187
current state at start:  [-1.03556494  2.97422317]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.03556494,  2.97422317]), 'currentState': array([5.70407357, 2.9407995 ]), 'targetState': array([0.03323314, 0.03562052]), 'effectorPosition': array([0.12596869, 0.15593108])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9554900645974828
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.03556494,  2.97422317]), 'currentState': array([5.70407357, 2.9407995 ]), 'targetState': array([0.03323314, 0.03562052]), 'effectorPosition': array([0.12596869, 0.15593108])}
episode index:12
target Thresh 0.24268572243576325
current state at start:  [-0.38309925  1.643575  ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.38309925,  1.643575  ]), 'currentState': array([6.12883026, 1.71010194]), 'targetState': array([1.24404464, 0.48895352]), 'effectorPosition': array([1.00315975, 0.84614392])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9589139057822919
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.38309925,  1.643575  ]), 'currentState': array([6.12883026, 1.71010194]), 'targetState': array([1.24404464, 0.48895352]), 'effectorPosition': array([1.00315975, 0.84614392])}
episode index:13
target Thresh 0.24619683870425102
current state at start:  [-0.56056168 -3.05240458]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.56056168, -3.05240458]), 'currentState': array([5.77106072, 3.01304057]), 'targetState': array([0.0392413 , 0.02680715]), 'effectorPosition': array([0.0700139, 0.1077077])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9618486267978424
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.56056168, -3.05240458]), 'currentState': array([5.77106072, 3.01304057]), 'targetState': array([0.0392413 , 0.02680715]), 'effectorPosition': array([0.0700139, 0.1077077])}
episode index:14
target Thresh 0.24970093975775565
current state at start:  [1.18654112 2.63504959]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.18654112, 2.63504959]), 'currentState': array([1.25013903, 2.66342429]), 'targetState': array([-0.32408113,  0.1746679 ]), 'effectorPosition': array([-0.40134701,  0.2514798 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9643920516779863
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.18654112, 2.63504959]), 'currentState': array([1.25013903, 2.66342429]), 'targetState': array([-0.32408113,  0.1746679 ]), 'effectorPosition': array([-0.40134701,  0.2514798 ])}
episode index:15
target Thresh 0.2531980396126854
current state at start:  [-0.92779616 -2.49891414]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.92779616, -2.49891414]), 'currentState': array([5.12775694, 3.62375744]), 'targetState': array([-0.36048712, -0.4897823 ]), 'effectorPosition': array([-0.37826423, -0.29142716])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9666175484481121
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.92779616, -2.49891414]), 'currentState': array([5.12775694, 3.62375744]), 'targetState': array([-0.36048712, -0.4897823 ]), 'effectorPosition': array([-0.37826423, -0.29142716])}
episode index:16
target Thresh 0.25668815225744424
current state at start:  [ 2.54217436 -2.2700596 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.54217436, -2.2700596 ]), 'currentState': array([2.3613008 , 3.93313517]), 'targetState': array([0.22818176, 0.77563334]), 'effectorPosition': array([0.28922846, 0.7147373 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9685812220688114
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.54217436, -2.2700596 ]), 'currentState': array([2.3613008 , 3.93313517]), 'targetState': array([0.22818176, 0.77563334]), 'effectorPosition': array([0.28922846, 0.7147373 ])}
episode index:17
target Thresh 0.2601712916524881
current state at start:  [ 1.56783315 -2.66142797]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.56783315, -2.66142797]), 'currentState': array([1.56551551, 3.61690259]), 'targetState': array([0.47945798, 0.03851147]), 'effectorPosition': array([0.45819304, 0.10843095])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9703267097316552
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.56783315, -2.66142797]), 'currentState': array([1.56551551, 3.61690259]), 'targetState': array([0.47945798, 0.03851147]), 'effectorPosition': array([0.45819304, 0.10843095])}
episode index:18
target Thresh 0.2636474717303785
current state at start:  [-0.84481218 -1.84540815]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.84481218, -1.84540815]), 'currentState': array([5.43677447, 4.37385913]), 'targetState': array([-0.225829  , -1.05870697]), 'effectorPosition': array([-0.26380139, -1.12525879])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9718884618510417
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.84481218, -1.84540815]), 'currentState': array([5.43677447, 4.37385913]), 'targetState': array([-0.225829  , -1.05870697]), 'effectorPosition': array([-0.26380139, -1.12525879])}
episode index:19
target Thresh 0.26711670639584084
current state at start:  [-0.05163186  2.67058236]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.05163186,  2.67058236]), 'currentState': array([6.23708278, 2.60446905]), 'targetState': array([0.19500688, 0.574811  ]), 'effectorPosition': array([0.16424716, 0.50463342])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9732940387584896
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.05163186,  2.67058236]), 'currentState': array([6.23708278, 2.60446905]), 'targetState': array([0.19500688, 0.574811  ]), 'effectorPosition': array([0.16424716, 0.50463342])}
episode index:20
target Thresh 0.27057900952581826
current state at start:  [-1.1851982  -3.02757732]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.1851982 , -3.02757732]), 'currentState': array([5.02619874, 3.23939671]), 'targetState': array([-0.00685238, -0.06691332]), 'effectorPosition': array([-0.0914043 , -0.03468812])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9745657511985616
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.1851982 , -3.02757732]), 'currentState': array([5.02619874, 3.23939671]), 'targetState': array([-0.00685238, -0.06691332]), 'effectorPosition': array([-0.0914043 , -0.03468812])}
episode index:21
target Thresh 0.27403439496952786
current state at start:  [ 3.44598425 -2.33268411]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.44598425, -2.33268411]), 'currentState': array([3.56111569, 3.57006949]), 'targetState': array([-0.47846634,  0.72521468]), 'effectorPosition': array([-0.25179884,  0.34263396])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9757218534168088
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.44598425, -2.33268411]), 'currentState': array([3.56111569, 3.57006949]), 'targetState': array([-0.47846634,  0.72521468]), 'effectorPosition': array([-0.25179884,  0.34263396])}
episode index:22
target Thresh 0.277482876548516
current state at start:  [1.06436571 2.91681209]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.06436571, 2.91681209]), 'currentState': array([0.93224607, 2.78704198]), 'targetState': array([-0.30853803,  0.2128214 ]), 'effectorPosition': array([-0.24169143,  0.25686593])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9767774250073823
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.06436571, 2.91681209]), 'currentState': array([0.93224607, 2.78704198]), 'targetState': array([-0.30853803,  0.2128214 ]), 'effectorPosition': array([-0.24169143,  0.25686593])}
episode index:23
target Thresh 0.28092446805671356
current state at start:  [-1.66494859 -2.10415537]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.66494859, -2.10415537]), 'currentState': array([4.23085099, 3.97005709]), 'targetState': array([-0.81659133, -0.47854928]), 'effectorPosition': array([-0.8031518 ,  0.05413852])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.9753067051904497
{'reset': False, 'endBeforeDone': False, 'stepCount': 7, 'initial state': array([-1.66494859, -2.10415537]), 'currentState': array([2.97262219, 1.85145819]), 'targetState': array([-0.81659133, -0.47854928]), 'effectorPosition': array([-0.87429911, -0.82560144])}
episode index:24
target Thresh 0.2843591832604915
current state at start:  [0.94191224 2.44342976]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.94191224, 2.44342976]), 'currentState': array([1.02041225, 2.35469498]), 'targetState': array([-0.46324493,  0.55237375]), 'effectorPosition': array([-0.44984451,  0.62092558])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9762944369828317
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.94191224, 2.44342976]), 'currentState': array([1.02041225, 2.35469498]), 'targetState': array([-0.46324493,  0.55237375]), 'effectorPosition': array([-0.44984451,  0.62092558])}
episode index:25
target Thresh 0.2877870358987147
current state at start:  [-3.55476493  1.6773899 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.55476493,  1.6773899 ]), 'currentState': array([2.66271514, 1.17991517]), 'targetState': array([-1.26465342, -0.42277039]), 'effectorPosition': array([-1.651686  , -0.18422774])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9772061894065689
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.55476493,  1.6773899 ]), 'currentState': array([2.66271514, 1.17991517]), 'targetState': array([-1.26465342, -0.42277039]), 'effectorPosition': array([-1.651686  , -0.18422774])}
episode index:26
target Thresh 0.29120803968279874
current state at start:  [-2.88860535  3.00049627]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.88860535,  3.00049627]), 'currentState': array([3.50028923, 2.58741916]), 'targetState': array([ 0.05676868, -0.20801372]), 'effectorPosition': array([ 0.04459995, -0.54528846])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.978050404613733
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.88860535,  3.00049627]), 'currentState': array([3.50028923, 2.58741916]), 'targetState': array([ 0.05676868, -0.20801372]), 'effectorPosition': array([ 0.04459995, -0.54528846])}
episode index:27
target Thresh 0.2946222082967629
current state at start:  [ 1.68999665 -2.94103743]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.68999665, -2.94103743]), 'currentState': array([1.85604955, 3.07727772]), 'targetState': array([0.10478208, 0.05075921]), 'effectorPosition': array([-0.06225525, -0.01610183])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9788343187346712
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.68999665, -2.94103743]), 'currentState': array([1.85604955, 3.07727772]), 'targetState': array([0.10478208, 0.05075921]), 'effectorPosition': array([-0.06225525, -0.01610183])}
episode index:28
target Thresh 0.2980295553972867
current state at start:  [1.52219796 1.81962523]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.52219796, 1.81962523]), 'currentState': array([1.91618382, 1.6715564 ]), 'targetState': array([-0.9599944,  0.7444128]), 'effectorPosition': array([-1.24067741,  0.50945093])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9795641698127859
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.52219796, 1.81962523]), 'currentState': array([1.91618382, 1.6715564 ]), 'targetState': array([-0.9599944,  0.7444128]), 'effectorPosition': array([-1.24067741,  0.50945093])}
episode index:29
target Thresh 0.3014300946137627
current state at start:  [-1.58047965 -2.54081179]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.58047965, -2.54081179]), 'currentState': array([4.8269085 , 3.77643778]), 'targetState': array([-0.59463997, -0.09713664]), 'effectorPosition': array([-0.56690437, -0.261328  ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9802453641523597
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.58047965, -2.54081179]), 'currentState': array([4.8269085 , 3.77643778]), 'targetState': array([-0.59463997, -0.09713664]), 'effectorPosition': array([-0.56690437, -0.261328  ])}
episode index:30
target Thresh 0.30482383954835224
current state at start:  [-3.35249566  2.57318092]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.35249566,  2.57318092]), 'currentState': array([2.95131405, 2.67135725]), 'targetState': array([-0.23770185, -0.47111689]), 'effectorPosition': array([-0.1922746 , -0.42439035])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9808826104700256
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.35249566,  2.57318092]), 'currentState': array([2.95131405, 2.67135725]), 'targetState': array([-0.23770185, -0.47111689]), 'effectorPosition': array([-0.1922746 , -0.42439035])}
episode index:31
target Thresh 0.30821080377604004
current state at start:  [-2.79536865  2.90455417]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.79536865,  2.90455417]), 'currentState': array([3.37731484, 2.88533433]), 'targetState': array([ 0.19115402, -0.17342612]), 'effectorPosition': array([ 0.02744321, -0.25407996])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9814800288928373
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.79536865,  2.90455417]), 'currentState': array([3.37731484, 2.88533433]), 'targetState': array([ 0.19115402, -0.17342612]), 'effectorPosition': array([ 0.02744321, -0.25407996])}
episode index:32
target Thresh 0.31159100084468694
current state at start:  [-0.3998032   2.90279709]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.3998032 ,  2.90279709]), 'currentState': array([5.63304912, 2.97366666]), 'targetState': array([0.014116  , 0.05487274]), 'effectorPosition': array([0.11236462, 0.12452762])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9820412401385089
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.3998032 ,  2.90279709]), 'currentState': array([5.63304912, 2.97366666]), 'targetState': array([0.014116  , 0.05487274]), 'effectorPosition': array([0.11236462, 0.12452762])}
episode index:33
target Thresh 0.3149644442750861
current state at start:  [ 0.32546977 -2.74421273]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.32546977, -2.74421273]), 'currentState': array([0.01481609, 3.57181463]), 'targetState': array([ 0.1575097 , -0.28729734]), 'effectorPosition': array([ 0.09729596, -0.41567669])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9825694389579646
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.32546977, -2.74421273]), 'currentState': array([0.01481609, 3.57181463]), 'targetState': array([ 0.1575097 , -0.28729734]), 'effectorPosition': array([ 0.09729596, -0.41567669])}
episode index:34
target Thresh 0.31833114756101555
current state at start:  [-0.78535054  3.00558787]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.78535054,  3.00558787]), 'currentState': array([5.13164451, 2.8991451 ]), 'targetState': array([0.08367116, 0.00551775]), 'effectorPosition': array([0.23119236, 0.07101789])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9830674549877371
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.78535054,  3.00558787]), 'currentState': array([5.13164451, 2.8991451 ]), 'targetState': array([0.08367116, 0.00551775]), 'effectorPosition': array([0.23119236, 0.07101789])}
episode index:35
target Thresh 0.321691124169293
current state at start:  [-1.55399594  3.02605175]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.55399594,  3.02605175]), 'currentState': array([4.45574003, 2.99171227]), 'targetState': array([-0.02464414,  0.0011255 ]), 'effectorPosition': array([ 0.14158322, -0.0487473 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9835378034602998
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.55399594,  3.02605175]), 'currentState': array([4.45574003, 2.99171227]), 'targetState': array([-0.02464414,  0.0011255 ]), 'effectorPosition': array([ 0.14158322, -0.0487473 ])}
episode index:36
target Thresh 0.32504438753982967
current state at start:  [0.43967378 2.74040095]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.43967378, 2.74040095]), 'currentState': array([0.73448145, 2.45210062]), 'targetState': array([0.0484241 , 0.54077565]), 'effectorPosition': array([-0.25680976,  0.62522815])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9839827276911026
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.43967378, 2.74040095]), 'currentState': array([0.73448145, 2.45210062]), 'targetState': array([0.0484241 , 0.54077565]), 'effectorPosition': array([-0.25680976,  0.62522815])}
episode index:37
target Thresh 0.32839095108568306
current state at start:  [1.46055741 2.96464387]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.46055741, 2.96464387]), 'currentState': array([1.67718754, 2.57290489]), 'targetState': array([-0.14373591,  0.02662629]), 'effectorPosition': array([-0.55219538,  0.0993152 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9844042348571262
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.46055741, 2.96464387]), 'currentState': array([1.67718754, 2.57290489]), 'targetState': array([-0.14373591,  0.02662629]), 'effectorPosition': array([-0.55219538,  0.0993152 ])}
episode index:38
target Thresh 0.33173082819311195
current state at start:  [-2.85101308  2.3876334 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.85101308,  2.3876334 ]), 'currentState': array([3.4292406, 1.8876334]), 'targetState': array([ 0.06988686, -0.84247335]), 'effectorPosition': array([-0.39057538, -1.10649249])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9848041262710461
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.85101308,  2.3876334 ]), 'currentState': array([3.4292406, 1.8876334]), 'targetState': array([ 0.06988686, -0.84247335]), 'effectorPosition': array([-0.39057538, -1.10649249])}
episode index:39
target Thresh 0.33506403222162917
current state at start:  [-2.1482677  -1.73469586]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.1482677 , -1.73469586]), 'currentState': array([4.32658051, 4.04848945]), 'targetState': array([-1.31799122, -0.12869724]), 'effectorPosition': array([-0.87413262, -0.05921661])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9851840231142699
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.1482677 , -1.73469586]), 'currentState': array([4.32658051, 4.04848945]), 'targetState': array([-1.31799122, -0.12869724]), 'effectorPosition': array([-0.87413262, -0.05921661])}
episode index:40
target Thresh 0.3383905765040556
current state at start:  [ 0.86945703 -2.40837652]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.86945703, -2.40837652]), 'currentState': array([1.36945703, 3.67353598]), 'targetState': array([ 0.59590995, -0.2294046 ]), 'effectorPosition': array([0.52459616, 0.03395319])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9855453884041657
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.86945703, -2.40837652]), 'currentState': array([1.36945703, 3.67353598]), 'targetState': array([ 0.59590995, -0.2294046 ]), 'effectorPosition': array([0.52459616, 0.03395319])}
episode index:41
target Thresh 0.3417104743465722
current state at start:  [-1.36029089  2.86253363]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.36029089,  2.86253363]), 'currentState': array([5.31184247, 2.55386096]), 'targetState': array([0.2563752 , 0.18675706]), 'effectorPosition': array([0.55246981, 0.17428723])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9858895458231142
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.36029089,  2.86253363]), 'currentState': array([5.31184247, 2.55386096]), 'targetState': array([0.2563752 , 0.18675706]), 'effectorPosition': array([0.55246981, 0.17428723])}
episode index:42
target Thresh 0.3450237390287756
current state at start:  [ 1.51558961 -2.14731402]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.51558961, -2.14731402]), 'currentState': array([2.01558961, 3.80993623]), 'targetState': array([0.88020086, 0.37754755]), 'effectorPosition': array([0.46681783, 0.46084997])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9862176959202511
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.51558961, -2.14731402]), 'currentState': array([2.01558961, 3.80993623]), 'targetState': array([0.88020086, 0.37754755]), 'effectorPosition': array([0.46681783, 0.46084997])}
episode index:43
target Thresh 0.3483303838037284
current state at start:  [-3.59899437  1.80903925]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.59899437,  1.80903925]), 'currentState': array([3.18419094, 1.41342913]), 'targetState': array([-1.24799734, -0.54087825]), 'effectorPosition': array([-1.11360996, -1.03600668])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9865309301038817
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.59899437,  1.80903925]), 'currentState': array([3.18419094, 1.41342913]), 'targetState': array([-1.24799734, -0.54087825]), 'effectorPosition': array([-1.11360996, -1.03600668])}
episode index:44
target Thresh 0.35163042189801375
current state at start:  [ 1.55572676 -2.46278612]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.55572676, -2.46278612]), 'currentState': array([2.05572676, 3.80432847]), 'targetState': array([0.54264137, 0.3694093 ]), 'effectorPosition': array([0.44566133, 0.47409089])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9868302427682399
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.55572676, -2.46278612]), 'currentState': array([2.05572676, 3.80432847]), 'targetState': array([0.54264137, 0.3694093 ]), 'effectorPosition': array([0.44566133, 0.47409089])}
episode index:45
target Thresh 0.3549238665117893
current state at start:  [-4.05723262  2.08713808]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.05723262,  2.08713808]), 'currentState': array([2.58323759, 1.83988017]), 'targetState': array([-0.91711307, -0.00312538]), 'effectorPosition': array([-1.13338153, -0.42866022])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9871165418384955
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.05723262,  2.08713808]), 'currentState': array([2.58323759, 1.83988017]), 'targetState': array([-0.91711307, -0.00312538]), 'effectorPosition': array([-1.13338153, -0.42866022])}
episode index:46
target Thresh 0.35821073081883736
current state at start:  [0.43550548 2.17923456]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.43550548, 2.17923456]), 'currentState': array([0.91569805, 1.90729585]), 'targetState': array([0.15163045, 0.79098544]), 'effectorPosition': array([-0.34043809,  1.1062242 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9873906579695914
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.43550548, 2.17923456]), 'currentState': array([0.91569805, 1.90729585]), 'targetState': array([0.15163045, 0.79098544]), 'effectorPosition': array([-0.34043809,  1.1062242 ])}
episode index:47
target Thresh 0.36149102796661947
current state at start:  [ 1.15607013 -2.18261589]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.15607013, -2.18261589]), 'currentState': array([1.13630319, 3.60056941]), 'targetState': array([0.8714706, 0.1961027]), 'effectorPosition': array([ 0.44543187, -0.09261677])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9876533525952249
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.15607013, -2.18261589]), 'currentState': array([1.13630319, 3.60056941]), 'targetState': array([0.8714706, 0.1961027]), 'effectorPosition': array([ 0.44543187, -0.09261677])}
episode index:48
target Thresh 0.3647647710763289
current state at start:  [ 1.78810192 -2.45574732]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.78810192, -2.45574732]), 'currentState': array([1.81928683, 3.39825891]), 'targetState': array([0.58957756, 0.46896816]), 'effectorPosition': array([0.23800352, 0.09418615])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9879053249912407
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.78810192, -2.45574732]), 'currentState': array([1.81928683, 3.39825891]), 'targetState': array([0.58957756, 0.46896816]), 'effectorPosition': array([0.23800352, 0.09418615])}
episode index:49
target Thresh 0.36803197324294223
current state at start:  [-0.391876   -2.19371552]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.391876  , -2.19371552]), 'currentState': array([5.58106924, 3.58946979]), 'targetState': array([-0.05796729, -0.83409278]), 'effectorPosition': array([-0.20437772, -0.39432582])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.988147218491416
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.391876  , -2.19371552]), 'currentState': array([5.58106924, 3.58946979]), 'targetState': array([-0.05796729, -0.83409278]), 'effectorPosition': array([-0.20437772, -0.39432582])}
episode index:50
target Thresh 0.3712926475352729
current state at start:  [ 3.67287475 -2.90498299]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.67287475, -2.90498299]), 'currentState': array([3.71192846, 2.87820231]), 'targetState': array([-0.13255335,  0.1333737 ]), 'effectorPosition': array([ 0.11154122, -0.23776645])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9883796259719764
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.67287475, -2.90498299]), 'currentState': array([3.71192846, 2.87820231]), 'targetState': array([-0.13255335,  0.1333737 ]), 'effectorPosition': array([ 0.11154122, -0.23776645])}
episode index:51
target Thresh 0.37454680699602183
current state at start:  [-3.66196334  2.47517562]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.66196334,  2.47517562]), 'currentState': array([2.79562489, 2.07793117]), 'targetState': array([-0.38686139, -0.31356651]), 'effectorPosition': array([-0.78027744, -0.64793342])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9886030947032846
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.66196334,  2.47517562]), 'currentState': array([2.79562489, 2.07793117]), 'targetState': array([-0.38686139, -0.31356651]), 'effectorPosition': array([-0.78027744, -0.64793342])}
episode index:52
target Thresh 0.3777944646418312
current state at start:  [-4.45342794  3.09783628]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.45342794,  3.09783628]), 'currentState': array([1.94578678, 2.75245305]), 'targetState': array([ 0.00021528, -0.00164953]), 'effectorPosition': array([-0.38041232, -0.06938878])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9888181306522792
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.45342794,  3.09783628]), 'currentState': array([1.94578678, 2.75245305]), 'targetState': array([ 0.00021528, -0.00164953]), 'effectorPosition': array([-0.38041232, -0.06938878])}
episode index:53
target Thresh 0.3810356334633367
current state at start:  [1.04975973 2.2119138 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.04975973, 2.2119138 ]), 'currentState': array([1.22919629, 1.71997038]), 'targetState': array([-0.62909425,  0.60614538]), 'effectorPosition': array([-0.64654807,  1.13346053])}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.9874236698528599
{'reset': False, 'endBeforeDone': False, 'stepCount': 10, 'initial state': array([1.04975973, 2.2119138 ]), 'currentState': array([3.40586902, 4.01893003]), 'targetState': array([-0.62909425,  0.60614538]), 'effectorPosition': array([-0.54915411,  0.64809538])}
episode index:54
target Thresh 0.3842703264252172
current state at start:  [1.67336577 1.86245737]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.67336577, 1.86245737]), 'currentState': array([2.17336577, 1.36245737]), 'targetState': array([-0.96969689,  0.75412063]), 'effectorPosition': array([-1.49005367,  0.43978425])}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.9860799167188741
{'reset': False, 'endBeforeDone': False, 'stepCount': 10, 'initial state': array([1.67336577, 1.86245737]), 'currentState': array([3.83002743, 4.01984675]), 'targetState': array([-0.96969689,  0.75412063]), 'effectorPosition': array([-0.76813395,  0.36466233])}
episode index:55
target Thresh 0.3874985564662492
current state at start:  [-1.82937566 -2.60619618]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.82937566, -2.60619618]), 'currentState': array([4.0429866 , 3.84586637]), 'targetState': array([-0.60730586,  0.05619248]), 'effectorPosition': array([-0.65538172,  0.21519942])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9863284896346085
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.82937566, -2.60619618]), 'currentState': array([4.0429866 , 3.84586637]), 'targetState': array([-0.60730586,  0.05619248]), 'effectorPosition': array([-0.65538172,  0.21519942])}
episode index:56
target Thresh 0.390720336499357
current state at start:  [ 2.39901088 -2.96176471]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.39901088, -2.96176471]), 'currentState': array([2.36970966, 3.66082876]), 'targetState': array([-0.04027045,  0.01553592]), 'effectorPosition': array([0.2516556 , 0.44751813])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9865683406936504
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.39901088, -2.96176471]), 'currentState': array([2.36970966, 3.66082876]), 'targetState': array([-0.04027045,  0.01553592]), 'effectorPosition': array([0.2516556 , 0.44751813])}
episode index:57
target Thresh 0.3939356794116651
current state at start:  [-1.07828568 -2.11153136]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.07828568, -2.11153136]), 'currentState': array([4.78294333, 4.34157794]), 'targetState': array([-0.63797713, -0.93377396]), 'effectorPosition': array([-0.88476477, -0.70174665])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9867999210265185
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.07828568, -2.11153136]), 'currentState': array([4.78294333, 4.34157794]), 'targetState': array([-0.63797713, -0.93377396]), 'effectorPosition': array([-0.88476477, -0.70174665])}
episode index:58
target Thresh 0.39714459806454916
current state at start:  [-0.11213334  2.63733457]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.11213334,  2.63733457]), 'currentState': array([5.67105197, 2.61874409]), 'targetState': array([0.32075117, 0.53356261]), 'effectorPosition': array([0.3962752 , 0.33191179])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9870236511786115
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.11213334,  2.63733457]), 'currentState': array([5.67105197, 2.61874409]), 'targetState': array([0.32075117, 0.53356261]), 'effectorPosition': array([0.3962752 , 0.33191179])}
episode index:59
target Thresh 0.40034710529368867
current state at start:  [-1.32165915  2.78834665]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.32165915,  2.78834665]), 'currentState': array([4.46152616, 2.86109144]), 'targetState': array([ 0.41756232, -0.16305293]), 'effectorPosition': array([ 0.25846991, -0.10658189])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.987239923658968
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.32165915,  2.78834665]), 'currentState': array([4.46152616, 2.86109144]), 'targetState': array([ 0.41756232, -0.16305293]), 'effectorPosition': array([ 0.25846991, -0.10658189])}
episode index:60
target Thresh 0.4035432139091164
current state at start:  [-2.43617049  2.63179951]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.43617049,  2.63179951]), 'currentState': array([3.98285571, 2.60210999]), 'targetState': array([ 0.01785199, -0.56361653]), 'effectorPosition': array([ 0.28828707, -0.44826496])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9874491052383291
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.43617049,  2.63179951]), 'currentState': array([3.98285571, 2.60210999]), 'targetState': array([ 0.01785199, -0.56361653]), 'effectorPosition': array([ 0.28828707, -0.44826496])}
episode index:61
target Thresh 0.4067329366952712
current state at start:  [-2.04739458  2.92590481]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.04739458,  2.92590481]), 'currentState': array([4.14857449, 2.99984438]), 'targetState': array([-0.01992171, -0.02171992]), 'effectorPosition': array([ 0.11404817, -0.08397601])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9876515390248076
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.04739458,  2.92590481]), 'currentState': array([4.14857449, 2.99984438]), 'targetState': array([-0.01992171, -0.02171992]), 'effectorPosition': array([ 0.11404817, -0.08397601])}
episode index:62
target Thresh 0.4099162864110484
current state at start:  [-1.09963744  2.18675344]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.09963744,  2.18675344]), 'currentState': array([4.75546939, 1.86393427]), 'targetState': array([1.11102414, 0.04400058]), 'effectorPosition': array([ 0.98707614, -0.66915263])}
done in step count: 38
reward sum = 0.682554595010387
running average episode reward sum: 0.9828087303896581
{'reset': False, 'endBeforeDone': False, 'stepCount': 39, 'initial state': array([-1.09963744,  2.18675344]), 'currentState': array([0.66568984, 4.63856445]), 'targetState': array([1.11102414, 0.04400058]), 'effectorPosition': array([ 1.34440094, -0.21229962])}
episode index:63
target Thresh 0.4130932757898511
current state at start:  [ 2.33599955 -1.92936131]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.33599955, -1.92936131]), 'currentState': array([2.83599955, 3.85382399]), 'targetState': array([0.24142801, 1.07375239]), 'effectorPosition': array([-0.03521301,  0.69638279])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9830773439773197
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.33599955, -1.92936131]), 'currentState': array([2.83599955, 3.85382399]), 'targetState': array([0.24142801, 1.07375239]), 'effectorPosition': array([-0.03521301,  0.69638279])}
episode index:64
target Thresh 0.4162639175396412
current state at start:  [1.96754987 1.67668283]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.96754987, 1.67668283]), 'currentState': array([2.23467935, 1.17668283]), 'targetState': array([-1.08247483,  0.47606233]), 'effectorPosition': array([-1.58001212,  0.52109624])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9833376925315148
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.96754987, 1.67668283]), 'currentState': array([2.23467935, 1.17668283]), 'targetState': array([-1.08247483,  0.47606233]), 'effectorPosition': array([-1.58001212,  0.52109624])}
episode index:65
target Thresh 0.41942822434298965
current state at start:  [ 0.16522525 -2.91420628]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.16522525, -2.91420628]), 'currentState': array([0.36281815, 2.86897903]), 'targetState': array([ 0.1614627 , -0.11666914]), 'effectorPosition': array([-0.06103398,  0.26482809])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9835901517355827
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.16522525, -2.91420628]), 'currentState': array([0.36281815, 2.86897903]), 'targetState': array([ 0.1614627 , -0.11666914]), 'effectorPosition': array([-0.06103398,  0.26482809])}
episode index:66
target Thresh 0.42258620885712816
current state at start:  [0.98636708 1.69492682]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.98636708, 1.69492682]), 'currentState': array([1.19135773, 1.19492682]), 'targetState': array([-0.23799367,  1.15218791]), 'effectorPosition': array([-0.35766132,  1.61438574])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9838350748440069
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.98636708, 1.69492682]), 'currentState': array([1.19135773, 1.19492682]), 'targetState': array([-0.23799367,  1.15218791]), 'effectorPosition': array([-0.35766132,  1.61438574])}
episode index:67
target Thresh 0.4257378837139987
current state at start:  [1.24993334 2.2355053 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.24993334, 2.2355053 ]), 'currentState': array([1.74329208, 1.7355053 ]), 'targetState': array([-0.44122921,  0.41601373]), 'effectorPosition': array([-1.11532476,  0.65430893])}
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.9822716329051092
{'reset': False, 'endBeforeDone': False, 'stepCount': 14, 'initial state': array([1.24993334, 2.2355053 ]), 'currentState': array([1.95212225, 3.04776307]), 'targetState': array([-0.44122921,  0.41601373]), 'effectorPosition': array([-0.08859926, -0.03078479])}
episode index:68
target Thresh 0.4288832615203053
current state at start:  [ 1.97406521 -2.9135252 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.97406521, -2.9135252 ]), 'currentState': array([2.47406521, 2.88122504]), 'targetState': array([0.13871694, 0.02374743]), 'effectorPosition': array([-0.18583467, -0.18131371])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9825285657615569
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.97406521, -2.9135252 ]), 'currentState': array([2.47406521, 2.88122504]), 'targetState': array([0.13871694, 0.02374743]), 'effectorPosition': array([-0.18583467, -0.18131371])}
episode index:69
target Thresh 0.432022354857563
current state at start:  [0.68275408 2.5911921 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.68275408, 2.5911921 ]), 'currentState': array([1.09156052, 2.0911921 ]), 'targetState': array([-0.36805585,  0.70733054]), 'effectorPosition': array([-0.53805184,  0.8461992 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9827781576792489
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.68275408, 2.5911921 ]), 'currentState': array([1.09156052, 2.0911921 ]), 'targetState': array([-0.36805585,  0.70733054]), 'effectorPosition': array([-0.53805184,  0.8461992 ])}
episode index:70
target Thresh 0.4351551762821495
current state at start:  [0.22653808 2.7745799 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.22653808, 2.7745799 ]), 'currentState': array([0.72653808, 2.2745799 ]), 'targetState': array([-0.20851362,  0.47121362]), 'effectorPosition': array([-0.24267106,  0.80429904])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9830207188386961
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.22653808, 2.7745799 ]), 'currentState': array([0.72653808, 2.2745799 ]), 'targetState': array([-0.20851362,  0.47121362]), 'effectorPosition': array([-0.24267106,  0.80429904])}
episode index:71
target Thresh 0.4382817383253548
current state at start:  [-3.34933813  2.77511984]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.34933813,  2.77511984]), 'currentState': array([3.43384717, 2.27511984]), 'targetState': array([-0.15947708, -0.26648267]), 'effectorPosition': array([-0.11797959, -0.8312905 ])}
done in step count: 30
reward sum = 0.7397003733882802
running average episode reward sum: 0.9796412695963291
{'reset': False, 'endBeforeDone': False, 'stepCount': 31, 'initial state': array([-3.34933813,  2.77511984]), 'currentState': array([3.70031216, 3.27583158]), 'targetState': array([-0.15947708, -0.26648267]), 'effectorPosition': array([-0.07857511,  0.10871522])}
episode index:72
target Thresh 0.4414020534934311
current state at start:  [ 1.24532024 -2.46828806]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.24532024, -2.46828806]), 'currentState': array([1.74532024, 3.4806628 ]), 'targetState': array([ 0.51004412, -0.02661893]), 'effectorPosition': array([0.31767148, 0.11382498])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9799201563141876
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.24532024, -2.46828806]), 'currentState': array([1.74532024, 3.4806628 ]), 'targetState': array([ 0.51004412, -0.02661893]), 'effectorPosition': array([0.31767148, 0.11382498])}
episode index:73
target Thresh 0.4445161342676429
current state at start:  [ 4.27560581 -2.97366237]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.27560581, -2.97366237]), 'currentState': array([4.77560581, 2.80952294]), 'targetState': array([-0.2729869 ,  0.09616683]), 'effectorPosition': array([ 0.32880044, -0.03392625])}
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.9787771576377624
{'reset': False, 'endBeforeDone': False, 'stepCount': 12, 'initial state': array([ 4.27560581, -2.97366237]), 'currentState': array([3.76688162, 3.95530938]), 'targetState': array([-0.2729869 ,  0.09616683]), 'effectorPosition': array([-0.67938455,  0.40599658])}
episode index:74
target Thresh 0.447623993104318
current state at start:  [-2.73874689  2.3701398 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.73874689,  2.3701398 ]), 'currentState': array([3.66066068, 1.90355524]), 'targetState': array([ 0.02207177, -0.72704117]), 'effectorPosition': array([-0.11579699, -1.15468064])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9790601288692589
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.73874689,  2.3701398 ]), 'currentState': array([3.66066068, 1.90355524]), 'targetState': array([ 0.02207177, -0.72704117]), 'effectorPosition': array([-0.11579699, -1.15468064])}
episode index:75
target Thresh 0.450725642434896
current state at start:  [-1.19380115  2.42012161]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.19380115,  2.42012161]), 'currentState': array([5.45038788, 2.08297854]), 'targetState': array([ 0.48334977, -0.13383891]), 'effectorPosition': array([0.98795929, 0.20922532])}
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.9777240880025445
{'reset': False, 'endBeforeDone': False, 'stepCount': 14, 'initial state': array([-1.19380115,  2.42012161]), 'currentState': array([4.35358485, 2.78464139]), 'targetState': array([ 0.48334977, -0.13383891]), 'effectorPosition': array([ 0.30503285, -0.18171965])}
episode index:76
target Thresh 0.45382109466597775
current state at start:  [ 1.39525854 -2.47468255]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.39525854, -2.47468255]), 'currentState': array([1.73094177, 3.30850276]), 'targetState': array([0.56011504, 0.25659671]), 'effectorPosition': array([0.16179426, 0.04021173])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.978013385560953
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.39525854, -2.47468255]), 'currentState': array([1.73094177, 3.30850276]), 'targetState': array([0.56011504, 0.25659671]), 'effectorPosition': array([0.16179426, 0.04021173])}
episode index:77
target Thresh 0.4569103621793764
current state at start:  [ 3.39123431 -2.95273212]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.39123431, -2.95273212]), 'currentState': array([3.89123431, 2.83045319]), 'targetState': array([-0.04834905,  0.07350857]), 'effectorPosition': array([ 0.17345554, -0.25679268])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9782952652332485
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.39123431, -2.95273212]), 'currentState': array([3.89123431, 2.83045319]), 'targetState': array([-0.04834905,  0.07350857]), 'effectorPosition': array([ 0.17345554, -0.25679268])}
episode index:78
target Thresh 0.4599934573321667
current state at start:  [ 2.4665829  -2.24707357]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.4665829 , -2.24707357]), 'currentState': array([2.9665829 , 3.53611174]), 'targetState': array([0.39625197, 0.87099187]), 'effectorPosition': array([-0.00872043,  0.39186849])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9785700087113086
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.4665829 , -2.24707357]), 'currentState': array([2.9665829 , 3.53611174]), 'targetState': array([0.39625197, 0.87099187]), 'effectorPosition': array([-0.00872043,  0.39186849])}
episode index:79
target Thresh 0.463070392456733
current state at start:  [ 0.54152459 -2.20445659]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.54152459, -2.20445659]), 'currentState': array([1.04152459, 3.57872871]), 'targetState': array([ 0.7722875 , -0.32099981]), 'effectorPosition': array([ 0.41289948, -0.13258351])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9788378836024172
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.54152459, -2.20445659]), 'currentState': array([1.04152459, 3.57872871]), 'targetState': array([ 0.7722875 , -0.32099981]), 'effectorPosition': array([ 0.41289948, -0.13258351])}
episode index:80
target Thresh 0.4661411798608195
current state at start:  [-4.34000266  2.41054914]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.34000266,  2.41054914]), 'currentState': array([2.44318264, 1.91054914]), 'targetState': array([-0.68716171,  0.15206723]), 'effectorPosition': array([-1.11688271, -0.29336823])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9790991442986837
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.34000266,  2.41054914]), 'currentState': array([2.44318264, 1.91054914]), 'targetState': array([-0.68716171,  0.15206723]), 'effectorPosition': array([-1.11688271, -0.29336823])}
episode index:81
target Thresh 0.4692058318275807
current state at start:  [ 4.43020922 -2.79242787]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.43020922, -2.79242787]), 'currentState': array([4.75725684, 2.99075744]), 'targetState': array([-0.14400922, -0.02635709]), 'effectorPosition': array([ 0.15062195, -0.00460289])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.979354032782846
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.43020922, -2.79242787]), 'currentState': array([4.75725684, 2.99075744]), 'targetState': array([-0.14400922, -0.02635709]), 'effectorPosition': array([ 0.15062195, -0.00460289])}
episode index:82
target Thresh 0.4722643606156278
current state at start:  [0.66566286 2.66536238]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.66566286, 2.66536238]), 'currentState': array([1.0121176 , 2.20162119]), 'targetState': array([-0.29480046,  0.36554111]), 'effectorPosition': array([-0.46733232,  0.77587264])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9796027793758239
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.66566286, 2.66536238]), 'currentState': array([1.0121176 , 2.20162119]), 'targetState': array([-0.29480046,  0.36554111]), 'effectorPosition': array([-0.46733232,  0.77587264])}
episode index:83
target Thresh 0.4753167784590806
current state at start:  [ 0.05717449 -1.57281072]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.05717449, -1.57281072]), 'currentState': array([0.23498182, 4.41318696]), 'targetState': array([ 1.15269038, -0.77630455]), 'effectorPosition': array([ 0.9083425 , -0.76511328])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9798456034308736
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.05717449, -1.57281072]), 'currentState': array([0.23498182, 4.41318696]), 'targetState': array([ 1.15269038, -0.77630455]), 'effectorPosition': array([ 0.9083425 , -0.76511328])}
episode index:84
target Thresh 0.4783630975676143
current state at start:  [ 1.66685644 -2.61849871]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.66685644, -2.61849871]), 'currentState': array([1.79456467, 3.16468659]), 'targetState': array([0.41492932, 0.15965154]), 'effectorPosition': array([0.02245699, 0.00538422])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9800827139787456
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.66685644, -2.61849871]), 'currentState': array([1.79456467, 3.16468659]), 'targetState': array([0.41492932, 0.15965154]), 'effectorPosition': array([0.02245699, 0.00538422])}
episode index:85
target Thresh 0.48140333012650927
current state at start:  [-1.63403723 -2.37151321]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.63403723, -2.37151321]), 'currentState': array([4.87363252, 3.49695475]), 'targetState': array([-0.78152472, -0.15783845]), 'effectorPosition': array([-0.33338585, -0.11752763])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.98031431032783
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.63403723, -2.37151321]), 'currentState': array([4.87363252, 3.49695475]), 'targetState': array([-0.78152472, -0.15783845]), 'effectorPosition': array([-0.33338585, -0.11752763])}
episode index:86
target Thresh 0.4844374882967002
current state at start:  [-3.24100464  2.89950418]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.24100464,  2.89950418]), 'currentState': array([3.35841123, 2.44774761]), 'targetState': array([ 0.03008527, -0.45899464]), 'effectorPosition': array([-0.08822267, -0.67426341])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9805405826229124
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.24100464,  2.89950418]), 'currentState': array([3.35841123, 2.44774761]), 'targetState': array([ 0.03008527, -0.45899464]), 'effectorPosition': array([-0.08822267, -0.67426341])}
episode index:87
target Thresh 0.48746558421482344
current state at start:  [-2.80254733  2.21751024]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.80254733,  2.21751024]), 'currentState': array([3.52094413, 1.89302541]), 'targetState': array([-0.06510629, -0.89576621]), 'effectorPosition': array([-0.28347922, -1.13414114])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9807617123658339
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.80254733,  2.21751024]), 'currentState': array([3.52094413, 1.89302541]), 'targetState': array([-0.06510629, -0.89576621]), 'effectorPosition': array([-0.28347922, -1.13414114])}
episode index:88
target Thresh 0.4904876299932668
current state at start:  [-1.02818704 -2.83048302]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.02818704, -2.83048302]), 'currentState': array([5.26751262, 3.11208827]), 'targetState': array([-0.36111463,  0.04570697]), 'effectorPosition': array([0.02529961, 0.01517811])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9809778729010492
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.02818704, -2.83048302]), 'currentState': array([5.26751262, 3.11208827]), 'targetState': array([-0.36111463,  0.04570697]), 'effectorPosition': array([0.02529961, 0.01517811])}
episode index:89
target Thresh 0.4935036377202173
current state at start:  [-2.94539737  2.74544552]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.94539737,  2.74544552]), 'currentState': array([3.4584101 , 2.38115874]), 'targetState': array([-0.00807445, -0.15291573]), 'effectorPosition': array([-0.04702638, -0.74075265])}
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.9799268395545501
{'reset': False, 'endBeforeDone': False, 'stepCount': 13, 'initial state': array([-2.94539737,  2.74544552]), 'currentState': array([1.47888661, 3.47134344]), 'targetState': array([-0.00807445, -0.15291573]), 'effectorPosition': array([0.32738539, 0.02393038])}
episode index:90
target Thresh 0.4965136194597104
current state at start:  [-0.99180054 -1.59481526]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.99180054, -1.59481526]), 'currentState': array([5.79138476, 4.18837005]), 'targetState': array([-0.24248319, -1.16477754]), 'effectorPosition': array([ 0.03157141, -0.99913743])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9801474237352693
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.99180054, -1.59481526]), 'currentState': array([5.79138476, 4.18837005]), 'targetState': array([-0.24248319, -1.16477754]), 'effectorPosition': array([ 0.03157141, -0.99913743])}
episode index:91
target Thresh 0.4995175872516764
current state at start:  [1.94904817 1.99063953]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.94904817, 1.99063953]), 'currentState': array([2.44904817, 1.49063953]), 'targetState': array([-1.15028571,  0.40259013]), 'effectorPosition': array([-1.46769583, -0.07753006])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9803632126077121
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.94904817, 1.99063953]), 'currentState': array([2.44904817, 1.49063953]), 'targetState': array([-1.15028571,  0.40259013]), 'effectorPosition': array([-1.46769583, -0.07753006])}
episode index:92
target Thresh 0.5025155531119907
current state at start:  [-2.07549658  2.02069882]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.07549658,  2.02069882]), 'currentState': array([4.70768873, 1.52069882]), 'targetState': array([ 0.39802596, -1.10281438]), 'effectorPosition': array([ 0.99379875, -1.05475929])}
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.9794489657437444
{'reset': False, 'endBeforeDone': False, 'stepCount': 12, 'initial state': array([-2.07549658,  2.02069882]), 'currentState': array([3.70897803, 2.30388412]), 'targetState': array([ 0.39802596, -1.10281438]), 'effectorPosition': array([ 0.12037562, -0.80447182])}
episode index:93
target Thresh 0.5055075290325213
current state at start:  [-2.5245198   1.95140986]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.5245198 ,  1.95140986]), 'currentState': array([4.23524709, 1.45140986]), 'targetState': array([-0.21504583, -1.09742787]), 'effectorPosition': array([ 0.3680487 , -1.45008493])}
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.9783646259273105
{'reset': False, 'endBeforeDone': False, 'stepCount': 14, 'initial state': array([-2.5245198 ,  1.95140986]), 'currentState': array([3.20528019, 1.95282061]), 'targetState': array([-0.21504583, -1.09742787]), 'effectorPosition': array([-0.56687236, -0.96594852])}
episode index:94
target Thresh 0.5084935269811748
current state at start:  [-0.93358749 -2.42468603]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.93358749, -2.42468603]), 'currentState': array([5.84959782, 3.36040505]), 'targetState': array([-0.49842354, -0.34718298]), 'effectorPosition': array([-0.06955997, -0.20700132])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9785923667070231
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.93358749, -2.42468603]), 'currentState': array([5.84959782, 3.36040505]), 'targetState': array([-0.49842354, -0.34718298]), 'effectorPosition': array([-0.06955997, -0.20700132])}
episode index:95
target Thresh 0.5114735589019479
current state at start:  [-2.33523041  2.73369794]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.33523041,  2.73369794]), 'currentState': array([4.4479549 , 2.36171489]), 'targetState': array([ 0.32219211, -0.27017736]), 'effectorPosition': array([ 0.60321589, -0.46274356])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9788153628871582
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.33523041,  2.73369794]), 'currentState': array([4.4479549 , 2.36171489]), 'targetState': array([ 0.32219211, -0.27017736]), 'effectorPosition': array([ 0.60321589, -0.46274356])}
episode index:96
target Thresh 0.5144476367149717
current state at start:  [-4.07465591  2.46726697]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.07465591,  2.46726697]), 'currentState': array([2.7085294, 1.9804443]), 'targetState': array([-0.64736995, -0.17681538]), 'effectorPosition': array([-0.93109764, -0.58007264])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9790337612079092
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.07465591,  2.46726697]), 'currentState': array([2.7085294, 1.9804443]), 'targetState': array([-0.64736995, -0.17681538]), 'effectorPosition': array([-0.93109764, -0.58007264])}
episode index:97
target Thresh 0.5174157723165616
current state at start:  [ 1.16328287 -2.31177396]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.16328287, -2.31177396]), 'currentState': array([1.57644158, 3.48368594]), 'targetState': array([0.59376203, 0.25701413]), 'effectorPosition': array([0.33512736, 0.05983831])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9792477024200734
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.16328287, -2.31177396]), 'currentState': array([1.57644158, 3.48368594]), 'targetState': array([0.59376203, 0.25701413]), 'effectorPosition': array([0.33512736, 0.05983831])}
episode index:98
target Thresh 0.5203779775792643
current state at start:  [ 2.62653007 -1.98670439]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.62653007, -1.98670439]), 'currentState': array([3.0539722 , 3.79648092]), 'targetState': array([0.09402392, 0.85534766]), 'effectorPosition': array([-0.15279158,  0.62483819])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9794573215875474
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.62653007, -1.98670439]), 'currentState': array([3.0539722 , 3.79648092]), 'targetState': array([0.09402392, 0.85534766]), 'effectorPosition': array([-0.15279158,  0.62483819])}
episode index:99
target Thresh 0.5233342643519041
current state at start:  [0.17426027 2.03947792]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.17426027, 2.03947792]), 'currentState': array([0.63230179, 1.54794747]), 'targetState': array([0.26219182, 0.81737721]), 'effectorPosition': array([0.23425031, 1.4109644 ])}
done in step count: 16
reward sum = 0.8514577710948755
running average episode reward sum: 0.9781773260826206
{'reset': False, 'endBeforeDone': False, 'stepCount': 17, 'initial state': array([0.17426027, 2.03947792]), 'currentState': array([2.11060155, 4.18088011]), 'targetState': array([0.26219182, 0.81737721]), 'effectorPosition': array([0.48599666, 0.86610506])}
episode index:100
target Thresh 0.5262846444596327
current state at start:  [ 1.55044417 -2.23366565]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.55044417, -2.23366565]), 'currentState': array([2.05044417, 3.64928546]), 'targetState': array([0.57003598, 0.24603905]), 'effectorPosition': array([0.37309708, 0.33624628])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9783933921610105
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.55044417, -2.23366565]), 'currentState': array([2.05044417, 3.64928546]), 'targetState': array([0.57003598, 0.24603905]), 'effectorPosition': array([0.37309708, 0.33624628])}
episode index:101
target Thresh 0.5292291297039742
current state at start:  [-0.3592709   1.64821459]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.3592709 ,  1.64821459]), 'currentState': array([0.1407291 , 1.14821459]), 'targetState': array([1.09037288, 0.80454294]), 'effectorPosition': array([1.26824966, 1.10080684])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.978605221649628
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.3592709 ,  1.64821459]), 'currentState': array([0.1407291 , 1.14821459]), 'targetState': array([1.09037288, 0.80454294]), 'effectorPosition': array([1.26824966, 1.10080684])}
episode index:102
target Thresh 0.532167731862873
current state at start:  [0.9988913  1.63246711]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.9988913 , 1.63246711]), 'currentState': array([1.4988913 , 1.13246711]), 'targetState': array([-0.57348573,  1.25856527]), 'effectorPosition': array([-0.80078705,  1.48579762])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9788129379442919
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.9988913 , 1.63246711]), 'currentState': array([1.4988913 , 1.13246711]), 'targetState': array([-0.57348573,  1.25856527]), 'effectorPosition': array([-0.80078705,  1.48579762])}
episode index:103
target Thresh 0.5351004626907427
current state at start:  [-1.56021073 -2.00207231]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.56021073, -2.00207231]), 'currentState': array([5.22297458, 3.84556413]), 'targetState': array([-0.80603355, -0.73454267]), 'effectorPosition': array([-0.44852677, -0.5237064 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9790166596948275
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.56021073, -2.00207231]), 'currentState': array([5.22297458, 3.84556413]), 'targetState': array([-0.80603355, -0.73454267]), 'effectorPosition': array([-0.44852677, -0.5237064 ])}
episode index:104
target Thresh 0.5380273339185098
current state at start:  [-4.51813223  3.04895548]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.51813223,  3.04895548]), 'currentState': array([2.26505307, 2.63808073]), 'targetState': array([-0.20861161, -0.10800141]), 'effectorPosition': array([-0.45022415, -0.21333384])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9792165010310673
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.51813223,  3.04895548]), 'currentState': array([2.26505307, 2.63808073]), 'targetState': array([-0.20861161, -0.10800141]), 'effectorPosition': array([-0.45022415, -0.21333384])}
episode index:105
target Thresh 0.5409483572536633
current state at start:  [-1.06869478  2.60429885]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.06869478,  2.60429885]), 'currentState': array([5.71449053, 2.41104203]), 'targetState': array([ 0.62704821, -0.04881924]), 'effectorPosition': array([0.57437875, 0.42482334])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9794125717760572
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.06869478,  2.60429885]), 'currentState': array([5.71449053, 2.41104203]), 'targetState': array([ 0.62704821, -0.04881924]), 'effectorPosition': array([0.57437875, 0.42482334])}
episode index:106
target Thresh 0.5438635443803004
current state at start:  [-0.11604618 -2.8065064 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.11604618, -2.8065064 ]), 'currentState': array([0.38395382, 3.21257421]), 'targetState': array([-0.03255677, -0.33295422]), 'effectorPosition': array([ 0.0289014 , -0.06481493])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.979604977647309
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.11604618, -2.8065064 ]), 'currentState': array([0.38395382, 3.21257421]), 'targetState': array([-0.03255677, -0.33295422]), 'effectorPosition': array([ 0.0289014 , -0.06481493])}
episode index:107
target Thresh 0.5467729069591734
current state at start:  [-4.43198756  2.97031231]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.43198756,  2.97031231]), 'currentState': array([2.26676487, 2.77029539]), 'targetState': array([-0.1839449 ,  0.05500231]), 'effectorPosition': array([-0.32213177, -0.18032254])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9797938204468709
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.43198756,  2.97031231]), 'currentState': array([2.26676487, 2.77029539]), 'targetState': array([-0.1839449 ,  0.05500231]), 'effectorPosition': array([-0.32213177, -0.18032254])}
episode index:108
target Thresh 0.5496764566277366
current state at start:  [-2.44642905  2.91492319]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.44642905,  2.91492319]), 'currentState': array([4.33675626, 2.43967527]), 'targetState': array([-0.0224979 ,  0.08469639]), 'effectorPosition': array([ 0.51393925, -0.45678803])}
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.9790189987387228
{'reset': False, 'endBeforeDone': False, 'stepCount': 12, 'initial state': array([-2.44642905,  2.91492319]), 'currentState': array([3.49523427, 3.91216222]), 'targetState': array([-0.0224979 ,  0.08469639]), 'effectorPosition': array([-0.50622968,  0.55561083])}
episode index:109
target Thresh 0.5525742050001927
current state at start:  [ 0.30811327 -2.06317217]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.30811327, -2.06317217]), 'currentState': array([0.80811327, 3.72001314]), 'targetState': array([ 0.6131403 , -0.81288194]), 'effectorPosition': array([ 0.5076421 , -0.26008664])}
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.9782582646979955
{'reset': False, 'endBeforeDone': False, 'stepCount': 12, 'initial state': array([ 0.30811327, -2.06317217]), 'currentState': array([0.02492796, 4.63155073]), 'targetState': array([ 0.6131403 , -0.81288194]), 'effectorPosition': array([ 0.94380815, -0.97351205])}
episode index:110
target Thresh 0.5554661636675386
current state at start:  [ 3.85325146 -2.36225789]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.85325146, -2.36225789]), 'currentState': array([4.35325146, 3.42092742]), 'targetState': array([-0.45238514,  0.57116347]), 'effectorPosition': array([-0.27174883,  0.06061715])}
done in step count: 25
reward sum = 0.7778213593991467
running average episode reward sum: 0.9764525268124201
{'reset': False, 'endBeforeDone': False, 'stepCount': 26, 'initial state': array([ 3.85325146, -2.36225789]), 'currentState': array([3.06684031, 4.04505881]), 'targetState': array([-0.45238514,  0.57116347]), 'effectorPosition': array([-0.32138302,  0.81174549])}
episode index:111
target Thresh 0.5583523441976135
current state at start:  [-0.68495218 -2.99377758]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.68495218, -2.99377758]), 'currentState': array([6.08549314, 2.78940772]), 'targetState': array([0.10701689, 0.12973242]), 'effectorPosition': array([0.12793371, 0.32617547])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9766627721087379
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.68495218, -2.99377758]), 'currentState': array([6.08549314, 2.78940772]), 'targetState': array([0.10701689, 0.12973242]), 'effectorPosition': array([0.12793371, 0.32617547])}
episode index:112
target Thresh 0.5612327581351428
current state at start:  [-1.13300027  1.66007847]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.13300027,  1.66007847]), 'currentState': array([5.52212908, 1.16007847]), 'targetState': array([ 1.13177235, -0.12440194]), 'effectorPosition': array([ 1.64554926, -0.30116908])}
done in step count: 14
reward sum = 0.8687458127689782
running average episode reward sum: 0.9757077547694479
{'reset': False, 'endBeforeDone': False, 'stepCount': 15, 'initial state': array([-1.13300027,  1.66007847]), 'currentState': array([5.3056861 , 1.28161207]), 'targetState': array([ 1.13177235, -0.12440194]), 'effectorPosition': array([ 1.51321068, -0.52965491])}
episode index:113
target Thresh 0.5641074170017863
current state at start:  [ 3.81073535 -2.15009229]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.81073535, -2.15009229]), 'currentState': array([4.31073535, 3.64019151]), 'targetState': array([-0.74473992,  0.37323112]), 'effectorPosition': array([-0.48773435,  0.07488871])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9759208446398914
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.81073535, -2.15009229]), 'currentState': array([4.31073535, 3.64019151]), 'targetState': array([-0.74473992,  0.37323112]), 'effectorPosition': array([-0.48773435,  0.07488871])}
episode index:114
target Thresh 0.5669763322961832
current state at start:  [-0.83516506 -2.93766361]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.83516506, -2.93766361]), 'currentState': array([5.94802024, 2.87192423]), 'targetState': array([-0.13670782, -0.07782651]), 'effectorPosition': array([0.12175924, 0.23970006])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9761302285995445
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.83516506, -2.93766361]), 'currentState': array([5.94802024, 2.87192423]), 'targetState': array([-0.13670782, -0.07782651]), 'effectorPosition': array([0.12175924, 0.23970006])}
episode index:115
target Thresh 0.5698395154939986
current state at start:  [0.63573596 2.50786828]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.63573596, 2.50786828]), 'currentState': array([1.13573596, 2.20238929]), 'targetState': array([-0.40474565,  0.73010476]), 'effectorPosition': array([-0.55928441,  0.71157474])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9763360024909278
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.63573596, 2.50786828]), 'currentState': array([1.13573596, 2.20238929]), 'targetState': array([-0.40474565,  0.73010476]), 'effectorPosition': array([-0.55928441,  0.71157474])}
episode index:116
target Thresh 0.5726969780479694
current state at start:  [ 1.43779386 -2.86669867]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.43779386, -2.86669867]), 'currentState': array([1.93779386, 3.05212643]), 'targetState': array([0.0218569 , 0.12305368]), 'effectorPosition': array([-0.08483227, -0.02832587])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9765382588798942
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.43779386, -2.86669867]), 'currentState': array([1.93779386, 3.05212643]), 'targetState': array([0.0218569 , 0.12305368]), 'effectorPosition': array([-0.08483227, -0.02832587])}
episode index:117
target Thresh 0.575548731387949
current state at start:  [ 0.47139569 -2.13272568]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.47139569, -2.13272568]), 'currentState': array([0.97139569, 3.99370594]), 'targetState': array([ 1.01566921, -0.73754311]), 'effectorPosition': array([ 0.81417906, -0.14256384])}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9760823812150469
{'reset': False, 'endBeforeDone': False, 'stepCount': 9, 'initial state': array([ 0.47139569, -2.13272568]), 'currentState': array([4.61680057, 2.2122835 ]), 'targetState': array([ 1.01566921, -0.73754311]), 'effectorPosition': array([ 0.7592181 , -0.47624847])}
episode index:118
target Thresh 0.5783947869209551
current state at start:  [1.00672305 2.72715834]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.00672305, 2.72715834]), 'currentState': array([1.45627499, 2.22715834]), 'targetState': array([-0.42564343,  0.13347072]), 'effectorPosition': array([-0.7424897 ,  0.47773571])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9762833696081978
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.00672305, 2.72715834]), 'currentState': array([1.45627499, 2.22715834]), 'targetState': array([-0.42564343,  0.13347072]), 'effectorPosition': array([-0.7424897 ,  0.47773571])}
episode index:119
target Thresh 0.5812351560312132
current state at start:  [-0.90157058  2.65725829]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.90157058,  2.65725829]), 'currentState': array([5.54696889, 2.18842899]), 'targetState': array([ 0.47097028, -0.06450961]), 'effectorPosition': array([0.85932052, 0.32148815])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9764810081947961
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.90157058,  2.65725829]), 'currentState': array([5.54696889, 2.18842899]), 'targetState': array([ 0.47097028, -0.06450961]), 'effectorPosition': array([0.85932052, 0.32148815])}
episode index:120
target Thresh 0.5840698500802037
current state at start:  [ 0.05763638 -2.93980852]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.05763638, -2.93980852]), 'currentState': array([0.31906009, 2.88020722]), 'targetState': array([-0.07346858, -0.18702226]), 'effectorPosition': array([-0.04880661,  0.25603154])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.976675380027897
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.05763638, -2.93980852]), 'currentState': array([0.31906009, 2.88020722]), 'targetState': array([-0.07346858, -0.18702226]), 'effectorPosition': array([-0.04880661,  0.25603154])}
episode index:121
target Thresh 0.5868988804067068
current state at start:  [-3.81729974  2.3890957 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.81729974,  2.3890957 ]), 'currentState': array([2.73186769, 1.92286745]), 'targetState': array([-0.49968269, -0.48537904]), 'effectorPosition': array([-0.97485232, -0.59998141])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9768665654375044
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.81729974,  2.3890957 ]), 'currentState': array([2.73186769, 1.92286745]), 'targetState': array([-0.49968269, -0.48537904]), 'effectorPosition': array([-0.97485232, -0.59998141])}
episode index:122
target Thresh 0.5897222583268475
current state at start:  [1.43580332 2.92941513]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.43580332, 2.92941513]), 'currentState': array([1.93392246, 2.50223481]), 'targetState': array([ 0.07734907, -0.18958685]), 'effectorPosition': array([-0.6279304 , -0.02729901])}
done in step count: 20
reward sum = 0.8179069375972308
running average episode reward sum: 0.975574210739616
{'reset': False, 'endBeforeDone': False, 'stepCount': 21, 'initial state': array([1.43580332, 2.92941513]), 'currentState': array([6.0368925, 3.7391065]), 'targetState': array([ 0.07734907, -0.18958685]), 'effectorPosition': array([ 0.03086961, -0.58785489])}
episode index:123
target Thresh 0.592539995134141
current state at start:  [-3.99184518  2.81689788]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.99184518,  2.81689788]), 'currentState': array([2.30639415, 2.45544095]), 'targetState': array([-0.19989726, -0.24558169]), 'effectorPosition': array([-0.62160455, -0.25734806])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9757711929110707
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.99184518,  2.81689788]), 'currentState': array([2.30639415, 2.45544095]), 'targetState': array([-0.19989726, -0.24558169]), 'effectorPosition': array([-0.62160455, -0.25734806])}
episode index:124
target Thresh 0.5953521020995383
current state at start:  [ 3.65772748 -2.30990631]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.65772748, -2.30990631]), 'currentState': array([3.71340594, 3.707688  ]), 'targetState': array([-0.47143658,  0.38268761]), 'effectorPosition': array([-0.42142721,  0.3666004 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9759650233677821
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.65772748, -2.30990631]), 'currentState': array([3.71340594, 3.707688  ]), 'targetState': array([-0.47143658,  0.38268761]), 'effectorPosition': array([-0.42142721,  0.3666004 ])}
episode index:125
target Thresh 0.5981585904714712
current state at start:  [ 4.01760301 -2.63256908]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.01760301, -2.63256908]), 'currentState': array([4.20983279, 3.31418743]), 'targetState': array([-0.20806244,  0.01319869]), 'effectorPosition': array([-0.15766071,  0.06970065])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9761557771505776
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.01760301, -2.63256908]), 'currentState': array([4.20983279, 3.31418743]), 'targetState': array([-0.20806244,  0.01319869]), 'effectorPosition': array([-0.15766071,  0.06970065])}
episode index:126
target Thresh 0.600959471475897
current state at start:  [-3.27403796  2.36301881]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.27403796,  2.36301881]), 'currentState': array([3.07230229, 2.08242229]), 'targetState': array([-0.60832392, -0.73417103]), 'effectorPosition': array([-0.56954895, -0.83451944])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9763435269367934
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.27403796,  2.36301881]), 'currentState': array([3.07230229, 2.08242229]), 'targetState': array([-0.60832392, -0.73417103]), 'effectorPosition': array([-0.56954895, -0.83451944])}
episode index:127
target Thresh 0.603754756316343
current state at start:  [-1.48521056 -3.04056692]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.48521056, -3.04056692]), 'currentState': array([4.80102623, 2.91697967]), 'targetState': array([-0.12546432, -0.22239301]), 'effectorPosition': array([ 0.22407833, -0.00530475])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9765283431325997
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.48521056, -3.04056692]), 'currentState': array([4.80102623, 2.91697967]), 'targetState': array([-0.12546432, -0.22239301]), 'effectorPosition': array([ 0.22407833, -0.00530475])}
episode index:128
target Thresh 0.6065444561739528
current state at start:  [-0.20186635  2.41378785]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.20186635,  2.41378785]), 'currentState': array([6.26178469, 2.31243608]), 'targetState': array([0.19085723, 0.33697167]), 'effectorPosition': array([0.34020658, 0.73024904])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9767102939610292
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.20186635,  2.41378785]), 'currentState': array([6.26178469, 2.31243608]), 'targetState': array([0.19085723, 0.33697167]), 'effectorPosition': array([0.34020658, 0.73024904])}
episode index:129
target Thresh 0.6093285822075294
current state at start:  [0.39041456 2.74242454]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.39041456, 2.74242454]), 'currentState': array([0.56482747, 2.60029593]), 'targetState': array([0.10417349, 0.39536765]), 'effectorPosition': array([-0.1550422 ,  0.51174152])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9768894455459444
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.39041456, 2.74242454]), 'currentState': array([0.56482747, 2.60029593]), 'targetState': array([0.10417349, 0.39536765]), 'effectorPosition': array([-0.1550422 ,  0.51174152])}
episode index:130
target Thresh 0.6121071455535807
current state at start:  [0.1299307  2.21663814]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.1299307 , 2.21663814]), 'currentState': array([0.23702294, 1.91261905]), 'targetState': array([0.19226089, 0.86223256]), 'effectorPosition': array([0.42498332, 1.07190454])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9770658619921585
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.1299307 , 2.21663814]), 'currentState': array([0.23702294, 1.91261905]), 'targetState': array([0.19226089, 0.86223256]), 'effectorPosition': array([0.42498332, 1.07190454])}
episode index:131
target Thresh 0.6148801573263634
current state at start:  [-2.36105451  1.60232126]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.36105451,  1.60232126]), 'currentState': array([4.00081215, 1.26553589]), 'targetState': array([-0.05947274, -1.14018772]), 'effectorPosition': array([-0.12697045, -1.6077816 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9772396054619149
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.36105451,  1.60232126]), 'currentState': array([4.00081215, 1.26553589]), 'targetState': array([-0.05947274, -1.14018772]), 'effectorPosition': array([-0.12697045, -1.6077816 ])}
episode index:132
target Thresh 0.6176476286179289
current state at start:  [ 3.91803982 -2.00584054]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.91803982, -2.00584054]), 'currentState': array([3.90959063, 3.78369785]), 'targetState': array([-0.90314748,  0.38382436]), 'effectorPosition': array([-0.55930044,  0.29242005])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9774107362479155
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.91803982, -2.00584054]), 'currentState': array([3.90959063, 3.78369785]), 'targetState': array([-0.90314748,  0.38382436]), 'effectorPosition': array([-0.55930044,  0.29242005])}
episode index:133
target Thresh 0.6204095704981654
current state at start:  [-0.72811258  1.75837776]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.72811258,  1.75837776]), 'currentState': array([5.61781398, 1.53676957]), 'targetState': array([1.00029086e+00, 5.31430840e-04]), 'effectorPosition': array([1.4304448 , 0.14787852])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9775793128430803
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.72811258,  1.75837776]), 'currentState': array([5.61781398, 1.53676957]), 'targetState': array([1.00029086e+00, 5.31430840e-04]), 'effectorPosition': array([1.4304448 , 0.14787852])}
episode index:134
target Thresh 0.6231659940148448
current state at start:  [-1.13682663 -1.9418816 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.13682663, -1.9418816 ]), 'currentState': array([5.17204097, 4.02150062]), 'targetState': array([-0.29505514, -1.25705553]), 'effectorPosition': array([-0.52974754, -0.66702578])}
done in step count: 19
reward sum = 0.8261686238355866
running average episode reward sum: 0.9764577521837656
{'reset': False, 'endBeforeDone': False, 'stepCount': 20, 'initial state': array([-1.13682663, -1.9418816 ]), 'currentState': array([3.67182177, 2.00228924]), 'targetState': array([-0.29505514, -1.25705553]), 'effectorPosition': array([-0.04251324, -1.07783947])}
episode index:135
target Thresh 0.6259169101936644
current state at start:  [-3.77262466  2.62180021]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.77262466,  2.62180021]), 'currentState': array([3.01056064, 2.12180021]), 'targetState': array([-0.37105314, -0.50463811]), 'effectorPosition': array([-0.58369281, -0.78244303])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9766308569471204
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.77262466,  2.62180021]), 'currentState': array([3.01056064, 2.12180021]), 'targetState': array([-0.37105314, -0.50463811]), 'effectorPosition': array([-0.58369281, -0.78244303])}
episode index:136
target Thresh 0.6286623300382923
current state at start:  [ 1.71807433 -2.54214742]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.71807433, -2.54214742]), 'currentState': array([2.21807433, 3.24103788]), 'targetState': array([0.4274068 , 0.29927482]), 'effectorPosition': array([0.0762203 , 0.06380965])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9768014346336377
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.71807433, -2.54214742]), 'currentState': array([2.21807433, 3.24103788]), 'targetState': array([0.4274068 , 0.29927482]), 'effectorPosition': array([0.0762203 , 0.06380965])}
episode index:137
target Thresh 0.6314022645304123
current state at start:  [ 1.38940482 -2.3072952 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.38940482, -2.3072952 ]), 'currentState': array([1.88940482, 3.48006592]), 'targetState': array([0.51033569, 0.32675857]), 'effectorPosition': array([0.29756347, 0.15789413])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9769695401797708
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.38940482, -2.3072952 ]), 'currentState': array([1.88940482, 3.48006592]), 'targetState': array([0.51033569, 0.32675857]), 'effectorPosition': array([0.29756347, 0.15789413])}
episode index:138
target Thresh 0.6341367246297656
current state at start:  [ 4.07926515 -1.93549553]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.07926515, -1.93549553]), 'currentState': array([4.57926515, 3.9795675 ]), 'targetState': array([-1.00245285,  0.0786539 ]), 'effectorPosition': array([-0.78065133, -0.22944401])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9771352269410674
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.07926515, -1.93549553]), 'currentState': array([4.57926515, 3.9795675 ]), 'targetState': array([-1.00245285,  0.0786539 ]), 'effectorPosition': array([-0.78065133, -0.22944401])}
episode index:139
target Thresh 0.6368657212741959
current state at start:  [-1.21773819 -1.83159614]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.21773819, -1.83159614]), 'currentState': array([5.56544712, 4.23003182]), 'targetState': array([-0.85303236, -1.08071138]), 'effectorPosition': array([-0.17877842, -1.01995143])}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.9766808128020857
{'reset': False, 'endBeforeDone': False, 'stepCount': 10, 'initial state': array([-1.21773819, -1.83159614]), 'currentState': array([3.78226181, 0.43169833]), 'targetState': array([-0.85303236, -1.08071138]), 'effectorPosition': array([-1.27974209, -1.47606677])}
episode index:140
target Thresh 0.6395892653796942
current state at start:  [ 0.18782886 -2.84722697]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.18782886, -2.84722697]), 'currentState': array([0.68782886, 2.93595834]), 'targetState': array([-0.15553412, -0.19340475]), 'effectorPosition': array([-0.11335318,  0.17113659])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9768461971084539
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.18782886, -2.84722697]), 'currentState': array([0.68782886, 2.93595834]), 'targetState': array([-0.15553412, -0.19340475]), 'effectorPosition': array([-0.11335318,  0.17113659])}
episode index:141
target Thresh 0.6423073678404398
current state at start:  [-0.37480266 -2.98633707]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.37480266, -2.98633707]), 'currentState': array([0.12519734, 2.97506344]), 'targetState': array([-0.34120022,  0.13945168]), 'effectorPosition': array([-0.00697292,  0.16619063])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9770092520583944
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.37480266, -2.98633707]), 'currentState': array([0.12519734, 2.97506344]), 'targetState': array([-0.34120022,  0.13945168]), 'effectorPosition': array([-0.00697292,  0.16619063])}
episode index:142
target Thresh 0.6450200395288468
current state at start:  [-0.67581795  2.57928799]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.67581795,  2.57928799]), 'currentState': array([6.10736736, 2.22159569]), 'targetState': array([0.26982058, 0.18940539]), 'effectorPosition': array([0.52726188, 0.71438769])}
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.97631353017686
{'reset': False, 'endBeforeDone': False, 'stepCount': 14, 'initial state': array([-0.67581795,  2.57928799]), 'currentState': array([0.02085642, 3.14249955]), 'targetState': array([0.26982058, 0.18940539]), 'effectorPosition': array([ 1.93244806e-05, -9.06695000e-04])}
episode index:143
target Thresh 0.6477272912956051
current state at start:  [1.6645035  1.61937828]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.6645035 , 1.61937828]), 'currentState': array([2.1645035 , 1.11937828]), 'targetState': array([-1.08399824,  0.70994744]), 'effectorPosition': array([-1.54933161,  0.68706296])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9764780195506317
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.6645035 , 1.61937828]), 'currentState': array([2.1645035 , 1.11937828]), 'targetState': array([-1.08399824,  0.70994744]), 'effectorPosition': array([-1.54933161,  0.68706296])}
episode index:144
target Thresh 0.6504291339697257
current state at start:  [-0.27378564 -1.96836117]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.27378564, -1.96836117]), 'currentState': array([0.22621436, 3.81482413]), 'targetState': array([ 0.42890552, -1.09160817]), 'effectorPosition': array([ 0.3524785 , -0.55869237])}
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.9758566874966007
{'reset': False, 'endBeforeDone': False, 'stepCount': 13, 'initial state': array([-0.27378564, -1.96836117]), 'currentState': array([5.67870675, 5.29096601]), 'targetState': array([ 0.42890552, -1.09160817]), 'effectorPosition': array([ 0.79689993, -1.56799769])}
episode index:145
target Thresh 0.6531255783585825
current state at start:  [ 2.35655864 -1.59460064]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.35655864, -1.59460064]), 'currentState': array([2.85655864, 4.48322983]), 'targetState': array([-0.11192744,  1.40848386]), 'effectorPosition': array([-0.46781958,  1.15187992])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9760220526507335
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.35655864, -1.59460064]), 'currentState': array([2.85655864, 4.48322983]), 'targetState': array([-0.11192744,  1.40848386]), 'effectorPosition': array([-0.46781958,  1.15187992])}
episode index:146
target Thresh 0.6558166352479571
current state at start:  [0.30019541 2.05598137]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.30019541, 2.05598137]), 'currentState': array([0.80019541, 1.92959885]), 'targetState': array([0.07868829, 1.06825441]), 'effectorPosition': array([-0.21983596,  1.11775025])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9761851679388238
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.30019541, 2.05598137]), 'currentState': array([0.80019541, 1.92959885]), 'targetState': array([0.07868829, 1.06825441]), 'effectorPosition': array([-0.21983596,  1.11775025])}
episode index:147
target Thresh 0.6585023154020804
current state at start:  [0.04861076 2.6621244 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.04861076, 2.6621244 ]), 'currentState': array([0.54861076, 2.41986478]), 'targetState': array([-0.01978809,  0.17836008]), 'effectorPosition': array([-0.13180278,  0.69375606])}
done in step count: 18
reward sum = 0.8345137614500875
running average episode reward sum: 0.9752279287057919
{'reset': False, 'endBeforeDone': False, 'stepCount': 19, 'initial state': array([0.04861076, 2.6621244 ]), 'currentState': array([0.78341032, 3.58760945]), 'targetState': array([-0.01978809,  0.17836008]), 'effectorPosition': array([ 0.37373339, -0.2365974 ])}
episode index:148
target Thresh 0.6611826295636767
current state at start:  [ 3.00842295 -2.57048626]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.00842295, -2.57048626]), 'currentState': array([3.25591537, 3.59055393]), 'targetState': array([-0.05704894,  0.37393956]), 'effectorPosition': array([-0.14796614,  0.41989186])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9753941842178335
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.00842295, -2.57048626]), 'currentState': array([3.25591537, 3.59055393]), 'targetState': array([-0.05704894,  0.37393956]), 'effectorPosition': array([-0.14796614,  0.41989186])}
episode index:149
target Thresh 0.6638575884540061
current state at start:  [2.1029541  1.85072564]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.1029541 , 1.85072564]), 'currentState': array([2.46505819, 1.67788838]), 'targetState': array([-1.31305087,  0.01632133]), 'effectorPosition': array([-1.31890968, -0.21610719])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9755582229897146
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.1029541 , 1.85072564]), 'currentState': array([2.46505819, 1.67788838]), 'targetState': array([-1.31305087,  0.01632133]), 'effectorPosition': array([-1.31890968, -0.21610719])}
episode index:150
target Thresh 0.6665272027729079
current state at start:  [ 1.73054441 -1.7868715 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.73054441, -1.7868715 ]), 'currentState': array([2.23054441, 4.09009018]), 'targetState': array([0.9323355 , 0.70413315]), 'effectorPosition': array([0.38638104, 0.82758719])}
done in step count: 14
reward sum = 0.8687458127689782
running average episode reward sum: 0.9748508560346105
{'reset': False, 'endBeforeDone': False, 'stepCount': 15, 'initial state': array([ 1.73054441, -1.7868715 ]), 'currentState': array([1.37283312, 4.32094798]), 'targetState': array([0.9323355 , 0.70413315]), 'effectorPosition': array([1.02794473, 0.42460333])}
episode index:151
target Thresh 0.6691914831988426
current state at start:  [ 4.28009865 -3.08305116]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.28009865, -3.08305116]), 'currentState': array([4.78009865, 3.01602461]), 'targetState': array([0.12033873, 0.03541431]), 'effectorPosition': array([0.12548404, 0.0006181 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9750163109291197
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.28009865, -3.08305116]), 'currentState': array([4.78009865, 3.01602461]), 'targetState': array([0.12033873, 0.03541431]), 'effectorPosition': array([0.12548404, 0.0006181 ])}
episode index:152
target Thresh 0.671850440388936
current state at start:  [ 3.39253409 -2.00596108]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.39253409, -2.00596108]), 'currentState': array([3.89253409, 4.02359109]), 'targetState': array([-0.51807158,  0.75472554]), 'effectorPosition': array([-0.79315038,  0.31574241])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9751796030145502
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.39253409, -2.00596108]), 'currentState': array([3.89253409, 4.02359109]), 'targetState': array([-0.51807158,  0.75472554]), 'effectorPosition': array([-0.79315038,  0.31574241])}
episode index:153
target Thresh 0.6745040849790198
current state at start:  [-1.36227238 -1.85697356]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.36227238, -1.85697356]), 'currentState': array([5.41326425, 3.99275676]), 'targetState': array([-0.53355454, -0.62031443]), 'effectorPosition': array([-0.35493721, -0.74552218])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9753407744235467
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.36227238, -1.85697356]), 'currentState': array([5.41326425, 3.99275676]), 'targetState': array([-0.53355454, -0.62031443]), 'effectorPosition': array([-0.35493721, -0.74552218])}
episode index:154
target Thresh 0.6771524275836762
current state at start:  [-1.4618513  -2.14874025]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.4618513 , -2.14874025]), 'currentState': array([5.00296661, 3.63444506]), 'targetState': array([-0.78775965, -0.72166255]), 'effectorPosition': array([-0.41920805, -0.24958146])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9754998662014592
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.4618513 , -2.14874025]), 'currentState': array([5.00296661, 3.63444506]), 'targetState': array([-0.78775965, -0.72166255]), 'effectorPosition': array([-0.41920805, -0.24958146])}
episode index:155
target Thresh 0.6797954787962794
current state at start:  [ 2.40798118 -2.31661377]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.40798118, -2.31661377]), 'currentState': array([2.90798118, 3.58140334]), 'targetState': array([0.52573632, 0.56935969]), 'effectorPosition': array([0.00597945, 0.43623352])}
done in step count: 62
reward sum = 0.536268225207185
running average episode reward sum: 0.9726842787591883
{'reset': False, 'endBeforeDone': False, 'stepCount': 63, 'initial state': array([ 2.40798118, -2.31661377]), 'currentState': array([6.07920567, 2.92825352]), 'targetState': array([0.52573632, 0.56935969]), 'effectorPosition': array([0.06508923, 0.20274274])}
episode index:156
target Thresh 0.6824332491890372
current state at start:  [-0.33490469  1.73304764]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.33490469,  1.73304764]), 'currentState': array([0.16509531, 1.23304764]), 'targetState': array([1.11055347, 0.62202669]), 'effectorPosition': array([1.15819958, 1.14947873])}
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.9721346010073216
{'reset': False, 'endBeforeDone': False, 'stepCount': 13, 'initial state': array([-0.33490469,  1.73304764]), 'currentState': array([5.33891357, 2.27101172]), 'targetState': array([1.11055347, 0.62202669]), 'effectorPosition': array([0.82797372, 0.16029564])}
episode index:157
target Thresh 0.685065749313035
current state at start:  [ 0.6966829  -1.96130872]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.6966829 , -1.96130872]), 'currentState': array([0.76602835, 3.82187659]), 'targetState': array([ 1.26446887, -0.27214042]), 'effectorPosition': array([ 0.59650702, -0.2989834 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.9659818503680349
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.6966829 , -1.96130872]), 'currentState': array([4.61315845, 3.22207191]), 'targetState': array([ 1.26446887, -0.27214042]), 'effectorPosition': array([-0.08031759,  0.00474351])}
episode index:158
target Thresh 0.6876929896982773
current state at start:  [ 1.72984337 -2.54009527]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.72984337, -2.54009527]), 'currentState': array([2.10878336, 3.24309004]), 'targetState': array([0.46884198, 0.16303833]), 'effectorPosition': array([0.0843734 , 0.05633833])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.966195800994651
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.72984337, -2.54009527]), 'currentState': array([2.10878336, 3.24309004]), 'targetState': array([0.46884198, 0.16303833]), 'effectorPosition': array([0.0843734 , 0.05633833])}
episode index:159
target Thresh 0.6903149808537281
current state at start:  [2.18533489 1.86291258]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.18533489, 1.86291258]), 'currentState': array([2.68533489, 1.36291258]), 'targetState': array([-0.87958404,  0.10676189]), 'effectorPosition': array([-1.51409092, -0.34685447])}
done in step count: 23
reward sum = 0.7936142836436554
running average episode reward sum: 0.9651171665112072
{'reset': False, 'endBeforeDone': False, 'stepCount': 24, 'initial state': array([2.18533489, 1.86291258]), 'currentState': array([1.11495813, 2.42252751]), 'targetState': array([-0.87958404,  0.10676189]), 'effectorPosition': array([-0.48243749,  0.5122601 ])}
episode index:160
target Thresh 0.6929317332673564
current state at start:  [ 1.51063424 -2.33637182]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.51063424, -2.33637182]), 'currentState': array([1.76435488, 3.61163326]), 'targetState': array([0.59475074, 0.11191188]), 'effectorPosition': array([0.42360398, 0.19354555])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9653338300732494
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.51063424, -2.33637182]), 'currentState': array([1.76435488, 3.61163326]), 'targetState': array([0.59475074, 0.11191188]), 'effectorPosition': array([0.42360398, 0.19354555])}
episode index:161
target Thresh 0.6955432574061748
current state at start:  [-1.04061599  2.67125459]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.04061599,  2.67125459]), 'currentState': array([5.62133302, 2.34191527]), 'targetState': array([0.75152752, 0.43979003]), 'effectorPosition': array([0.67980585, 0.37945725])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9655478187765009
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.04061599,  2.67125459]), 'currentState': array([5.62133302, 2.34191527]), 'targetState': array([0.75152752, 0.43979003]), 'effectorPosition': array([0.67980585, 0.37945725])}
episode index:162
target Thresh 0.6981495637162838
current state at start:  [ 1.44227331 -1.83831911]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.44227331, -1.83831911]), 'currentState': array([1.94227331, 4.30026447]), 'targetState': array([1.23057483, 0.54936602]), 'effectorPosition': array([0.63618193, 0.89115589])}
done in step count: 37
reward sum = 0.6894490858690777
running average episode reward sum: 0.9638539615194002
{'reset': False, 'endBeforeDone': False, 'stepCount': 38, 'initial state': array([ 1.44227331, -1.83831911]), 'currentState': array([6.08997394, 2.00196495]), 'targetState': array([1.23057483, 0.54936602]), 'effectorPosition': array([0.74567474, 0.77981002])}
episode index:163
target Thresh 0.7007506626229114
current state at start:  [ 0.96306475 -1.94426728]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.96306475, -1.94426728]), 'currentState': array([1.46306475, 3.83891802]), 'targetState': array([1.09227224, 0.08034404]), 'effectorPosition': array([0.66354675, 0.16303596])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9640743641930624
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.96306475, -1.94426728]), 'currentState': array([1.46306475, 3.83891802]), 'targetState': array([1.09227224, 0.08034404]), 'effectorPosition': array([0.66354675, 0.16303596])}
episode index:164
target Thresh 0.7033465645304575
current state at start:  [0.2615736 2.8119439]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.2615736, 2.8119439]), 'currentState': array([0.75277414, 2.31459196]), 'targetState': array([0.12277947, 0.01690144]), 'effectorPosition': array([-0.26745138,  0.75782436])}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9637125927434609
{'reset': False, 'endBeforeDone': False, 'stepCount': 11, 'initial state': array([0.2615736, 2.8119439]), 'currentState': array([5.75277414, 3.59777727]), 'targetState': array([0.12277947, 0.01690144]), 'effectorPosition': array([-0.13464734, -0.43172964])}
episode index:165
target Thresh 0.705937279822533
current state at start:  [ 1.33377997 -2.8045033 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.33377997, -2.8045033 ]), 'currentState': array([1.83377997, 2.978682  ]), 'targetState': array([ 0.01194937, -0.25087024]), 'effectorPosition': array([-0.16005672, -0.02937823])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9639311915823557
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.33377997, -2.8045033 ]), 'currentState': array([1.83377997, 2.978682  ]), 'targetState': array([ 0.01194937, -0.25087024]), 'effectorPosition': array([-0.16005672, -0.02937823])}
episode index:166
target Thresh 0.7085228188620021
current state at start:  [0.93224579 2.30717425]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.93224579, 2.30717425]), 'currentState': array([1.43224579, 1.80717425]), 'targetState': array([-0.45274867,  0.59219014]), 'effectorPosition': array([-0.85711103,  0.8927458 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9641471724710841
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.93224579, 2.30717425]), 'currentState': array([1.43224579, 1.80717425]), 'targetState': array([-0.45274867,  0.59219014]), 'effectorPosition': array([-0.85711103,  0.8927458 ])}
episode index:167
target Thresh 0.7111031919910247
current state at start:  [ 0.0977115  -1.71550451]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.0977115 , -1.71550451]), 'currentState': array([0.5977115 , 4.06768079]), 'targetState': array([ 0.7375997 , -1.18285579]), 'effectorPosition': array([ 0.77964625, -0.43614365])}
done in step count: 40
reward sum = 0.6689717585696803
running average episode reward sum: 0.9623901759597663
{'reset': False, 'endBeforeDone': False, 'stepCount': 41, 'initial state': array([ 0.0977115 , -1.71550451]), 'currentState': array([0.224786  , 4.49430579]), 'targetState': array([ 0.7375997 , -1.18285579]), 'effectorPosition': array([ 0.98154459, -0.77707979])}
episode index:168
target Thresh 0.7136784095310968
current state at start:  [-3.90867371  1.99897921]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.90867371,  1.99897921]), 'currentState': array([2.69823966, 1.49897921]), 'targetState': array([-0.78721178, -0.02931019]), 'effectorPosition': array([-1.3960013 , -0.44123822])}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.962046932758873
{'reset': False, 'endBeforeDone': False, 'stepCount': 11, 'initial state': array([-3.90867371,  1.99897921]), 'currentState': array([4.46728873, 4.44078986]), 'targetState': array([-0.78721178, -0.02931019]), 'effectorPosition': array([-1.11210805, -0.47609992])}
episode index:169
target Thresh 0.7162484817830919
current state at start:  [-1.88074996 -2.2113041 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.88074996, -2.2113041 ]), 'currentState': array([4.4666441, 3.8423561]), 'targetState': array([-0.63837357, -0.1730841 ]), 'effectorPosition': array([-0.68275789, -0.07170351])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9622701860955856
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.88074996, -2.2113041 ]), 'currentState': array([4.4666441, 3.8423561]), 'targetState': array([-0.63837357, -0.1730841 ]), 'effectorPosition': array([-0.68275789, -0.07170351])}
episode index:170
target Thresh 0.7188134190273026
current state at start:  [ 2.31030221 -1.59512449]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.31030221, -1.59512449]), 'currentState': array([2.54496766, 4.4632956 ]), 'targetState': array([0.18283389, 1.29780655]), 'effectorPosition': array([-0.07878886,  1.22504753])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.962490828282161
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.31030221, -1.59512449]), 'currentState': array([2.54496766, 4.4632956 ]), 'targetState': array([0.18283389, 1.29780655]), 'effectorPosition': array([-0.07878886,  1.22504753])}
episode index:171
target Thresh 0.7213732315234809
current state at start:  [1.48246893 1.77234758]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.48246893, 1.77234758]), 'currentState': array([1.62262982, 1.51253791]), 'targetState': array([-0.78292747,  0.58944025]), 'effectorPosition': array([-1.05178965,  1.00508182])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.962708904861916
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.48246893, 1.77234758]), 'currentState': array([1.62262982, 1.51253791]), 'targetState': array([-0.78292747,  0.58944025]), 'effectorPosition': array([-1.05178965,  1.00508182])}
episode index:172
target Thresh 0.7239279295108805
current state at start:  [ 0.84421181 -2.48075173]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.84421181, -2.48075173]), 'currentState': array([1.23578011, 3.65685367]), 'targetState': array([ 0.70856782, -0.2799207 ]), 'effectorPosition': array([ 0.5080549 , -0.03939486])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9629244603251419
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.84421181, -2.48075173]), 'currentState': array([1.23578011, 3.65685367]), 'targetState': array([ 0.70856782, -0.2799207 ]), 'effectorPosition': array([ 0.5080549 , -0.03939486])}
episode index:173
target Thresh 0.726477523208297
current state at start:  [1.51720169 2.92683621]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.51720169, 2.92683621]), 'currentState': array([1.84534308, 2.95630854]), 'targetState': array([0.09491089, 0.1097876 ]), 'effectorPosition': array([-0.18196655, -0.03347056])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9631375381393652
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.51720169, 2.92683621]), 'currentState': array([1.84534308, 2.95630854]), 'targetState': array([0.09491089, 0.1097876 ]), 'effectorPosition': array([-0.18196655, -0.03347056])}
episode index:174
target Thresh 0.729022022814108
current state at start:  [-2.97259199  2.89392753]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.97259199,  2.89392753]), 'currentState': array([3.53767157, 3.2831374 ]), 'targetState': array([ 0.12069147, -0.03188203]), 'effectorPosition': array([-0.06365283,  0.12629253])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9633481807785688
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.97259199,  2.89392753]), 'currentState': array([3.53767157, 3.2831374 ]), 'targetState': array([ 0.12069147, -0.03188203]), 'effectorPosition': array([-0.06365283,  0.12629253])}
episode index:175
target Thresh 0.7315614385063158
current state at start:  [ 0.0952787  -2.97619647]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.0952787 , -2.97619647]), 'currentState': array([0.50258093, 3.02132601]), 'targetState': array([-0.25915927, -0.0400089 ]), 'effectorPosition': array([-0.05146146,  0.10862025])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9635564297514179
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.0952787 , -2.97619647]), 'currentState': array([0.50258093, 3.02132601]), 'targetState': array([-0.25915927, -0.0400089 ]), 'effectorPosition': array([-0.05146146,  0.10862025])}
episode index:176
target Thresh 0.7340957804425863
current state at start:  [-0.91747156 -2.41982116]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.91747156, -2.41982116]), 'currentState': array([5.76930312, 3.6861194 ]), 'targetState': array([-0.67060491, -0.68324478]), 'effectorPosition': array([-0.12868775, -0.52220148])}
done in step count: 27
reward sum = 0.7623427143471035
running average episode reward sum: 0.9624196290994161
{'reset': False, 'endBeforeDone': False, 'stepCount': 28, 'initial state': array([-0.91747156, -2.41982116]), 'currentState': array([4.89364284, 4.24177485]), 'targetState': array([-0.67060491, -0.68324478]), 'effectorPosition': array([-0.77816358, -0.69827928])}
episode index:177
target Thresh 0.7366250587602907
current state at start:  [1.27791897 2.04180622]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.27791897, 2.04180622]), 'currentState': array([1.77791897, 1.54180622]), 'targetState': array([-0.3620444 ,  0.57839035]), 'effectorPosition': array([-1.1898212 ,  0.80143471])}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9621967362080033
{'reset': False, 'endBeforeDone': False, 'stepCount': 9, 'initial state': array([1.27791897, 2.04180622]), 'currentState': array([5.68197647, 2.95770905]), 'targetState': array([-0.3620444 ,  0.57839035]), 'effectorPosition': array([0.11732953, 0.14125082])}
episode index:178
target Thresh 0.7391492835765456
current state at start:  [ 1.48459014 -2.2514058 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.48459014, -2.2514058 ]), 'currentState': array([1.7975347 , 3.84305722]), 'targetState': array([0.51611953, 0.28092627]), 'effectorPosition': array([0.57574372, 0.37513122])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9624079276258357
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.48459014, -2.2514058 ]), 'currentState': array([1.7975347 , 3.84305722]), 'targetState': array([0.51611953, 0.28092627]), 'effectorPosition': array([0.57574372, 0.37513122])}
episode index:179
target Thresh 0.7416684649882537
current state at start:  [0.07687573 1.70050875]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.07687573, 1.70050875]), 'currentState': array([0.34065194, 1.20050875]), 'targetState': array([0.78375568, 0.88608614]), 'effectorPosition': array([0.97216835, 1.33366254])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9626167724723588
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.07687573, 1.70050875]), 'currentState': array([0.34065194, 1.20050875]), 'targetState': array([0.78375568, 0.88608614]), 'effectorPosition': array([0.97216835, 1.33366254])}
episode index:180
target Thresh 0.7441826130721441
current state at start:  [ 2.46641095 -2.22700545]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.46641095, -2.22700545]), 'currentState': array([2.91640259, 4.25794592]), 'targetState': array([0.55052178, 1.15314785]), 'effectorPosition': array([-0.34624397,  1.00109498])}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.9623964847483565
{'reset': False, 'endBeforeDone': False, 'stepCount': 9, 'initial state': array([ 2.46641095, -2.22700545]), 'currentState': array([0.39975292, 1.09374847]), 'targetState': array([0.55052178, 1.15314785]), 'effectorPosition': array([0.99837518, 1.38620499])}
episode index:181
target Thresh 0.7466917378848121
current state at start:  [-1.46190176 -2.07516458]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.46190176, -2.07516458]), 'currentState': array([5.31798747, 4.70802073]), 'targetState': array([-0.59603338, -0.31160092]), 'effectorPosition': array([-0.25538612, -1.38781896])}
done in step count: 40
reward sum = 0.6689717585696803
running average episode reward sum: 0.960784260978144
{'reset': False, 'endBeforeDone': False, 'stepCount': 41, 'initial state': array([-1.46190176, -2.07516458]), 'currentState': array([4.44367573, 3.64363388]), 'targetState': array([-0.59603338, -0.31160092]), 'effectorPosition': array([-0.49670768,  0.00878898])}
episode index:182
target Thresh 0.7491958494627609
current state at start:  [1.56556532 2.5852529 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.56556532, 2.5852529 ]), 'currentState': array([1.27068117, 2.17603015]), 'targetState': array([-0.19565278, -0.09938555]), 'effectorPosition': array([-0.65818109,  0.65489609])}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.9604760523116449
{'reset': False, 'endBeforeDone': False, 'stepCount': 11, 'initial state': array([1.56556532, 2.5852529 ]), 'currentState': array([4.64351558, 3.04908504]), 'targetState': array([-0.19565278, -0.09938555]), 'effectorPosition': array([ 0.09186247, -0.01062284])}
episode index:183
target Thresh 0.7516949578224394
current state at start:  [-1.38231321 -2.34308766]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.38231321, -2.34308766]), 'currentState': array([5.35021462, 4.39936258]), 'targetState': array([-0.43751391, -0.05668039]), 'effectorPosition': array([-0.35226483, -1.1225109 ])}
done in step count: 20
reward sum = 0.8179069375972308
running average episode reward sum: 0.9597012201664579
{'reset': False, 'endBeforeDone': False, 'stepCount': 21, 'initial state': array([-1.38231321, -2.34308766]), 'currentState': array([4.54540899, 3.48355845]), 'targetState': array([-0.43751391, -0.05668039]), 'effectorPosition': array([-0.34029927, -0.0013622 ])}
episode index:184
target Thresh 0.7541890729602854
current state at start:  [-0.47967384  2.41441322]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.47967384,  2.41441322]), 'currentState': array([5.30351147, 1.9654992 ]), 'targetState': array([0.17468763, 0.21536153]), 'effectorPosition': array([1.10946857, 0.00341247])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.9597060568682607
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([-0.47967384,  2.41441322]), 'currentState': array([4.78887613, 2.43755189]), 'targetState': array([0.17468763, 0.21536153]), 'effectorPosition': array([ 0.66357884, -0.18760992])}
episode index:185
target Thresh 0.7566782048527616
current state at start:  [ 3.37766782 -1.88165129]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.37766782, -1.88165129]), 'currentState': array([3.38082218, 4.90153402]), 'targetState': array([-0.91545713,  1.04907041]), 'effectorPosition': array([-1.38691362,  0.67268797])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9599226909711195
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.37766782, -1.88165129]), 'currentState': array([3.38082218, 4.90153402]), 'targetState': array([-0.91545713,  1.04907041]), 'effectorPosition': array([-1.38691362,  0.67268797])}
episode index:186
target Thresh 0.7591623634563998
current state at start:  [-3.34118664  2.69183261]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.34118664,  2.69183261]), 'currentState': array([2.97519336, 3.10404418]), 'targetState': array([-0.14328658, -0.20454747]), 'effectorPosition': array([-0.00691291, -0.03690439])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9601370081317018
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.34118664,  2.69183261]), 'currentState': array([2.97519336, 3.10404418]), 'targetState': array([-0.14328658, -0.20454747]), 'effectorPosition': array([-0.00691291, -0.03690439])}
episode index:187
target Thresh 0.7616415587078369
current state at start:  [-0.20261947  2.53576384]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.20261947,  2.53576384]), 'currentState': array([5.58056584, 2.04455659]), 'targetState': array([0.27985214, 0.39016089]), 'effectorPosition': array([0.99001867, 0.32770689])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.9601910612799375
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-0.20261947,  2.53576384]), 'currentState': array([4.73822659, 2.67085517]), 'targetState': array([0.27985214, 0.39016089]), 'effectorPosition': array([ 0.45620224, -0.09701246])}
episode index:188
target Thresh 0.7641158005238582
current state at start:  [-0.98816167  2.46682447]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.98816167,  2.46682447]), 'currentState': array([4.79502364, 2.12007034]), 'targetState': array([0.6671842 , 0.27887493]), 'effectorPosition': array([ 0.8894422 , -0.40590176])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9603487805324247
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.98816167,  2.46682447]), 'currentState': array([4.76907279, 2.57040083]), 'targetState': array([0.6671842 , 0.27887493]), 'effectorPosition': array([ 0.54876007, -0.12785896])}
episode index:189
target Thresh 0.7665850988014333
current state at start:  [ 1.26376215 -2.41398582]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.26376215, -2.41398582]), 'currentState': array([0.76376215, 3.43081665]), 'targetState': array([0.4258809 , 0.20151567]), 'effectorPosition': array([ 0.22726048, -0.17726167])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9605574711612014
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.26376215, -2.41398582]), 'currentState': array([0.76376215, 3.43081665]), 'targetState': array([0.4258809 , 0.20151567]), 'effectorPosition': array([ 0.22726048, -0.17726167])}
episode index:190
target Thresh 0.7690494634177594
current state at start:  [ 2.89192605 -2.41829037]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.89192605, -2.41829037]), 'currentState': array([2.94058091, 4.17387886]), 'targetState': array([-0.36097507,  0.66356616]), 'effectorPosition': array([-0.30593032,  0.93845168])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9607639765477919
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.89192605, -2.41829037]), 'currentState': array([2.94058091, 4.17387886]), 'targetState': array([-0.36097507,  0.66356616]), 'effectorPosition': array([-0.30593032,  0.93845168])}
episode index:191
target Thresh 0.7715089042302978
current state at start:  [ 3.04452376 -2.31070381]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.04452376, -2.31070381]), 'currentState': array([3.25224766, 4.21527345]), 'targetState': array([-0.59808346,  0.61986977]), 'effectorPosition': array([-0.61697163,  0.81581961])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9609683308366055
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.04452376, -2.31070381]), 'currentState': array([3.25224766, 4.21527345]), 'targetState': array([-0.59808346,  0.61986977]), 'effectorPosition': array([-0.61697163,  0.81581961])}
episode index:192
target Thresh 0.7739634310768151
current state at start:  [ 3.61835746 -2.61681636]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.61835746, -2.61681636]), 'currentState': array([3.81844933, 3.9769807 ]), 'targetState': array([-0.5806447 ,  0.46608971]), 'effectorPosition': array([-0.72102722,  0.37194059])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9611705674643951
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.61835746, -2.61681636]), 'currentState': array([3.81844933, 3.9769807 ]), 'targetState': array([-0.5806447 ,  0.46608971]), 'effectorPosition': array([-0.72102722,  0.37194059])}
episode index:193
target Thresh 0.7764130537754221
current state at start:  [0.14269449 2.06759453]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.14269449, 2.06759453]), 'currentState': array([5.9258798 , 1.56759453]), 'targetState': array([0.24806327, 0.5598077 ]), 'effectorPosition': array([1.2895916, 0.5859668])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.9562160800032384
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.14269449, 2.06759453]), 'currentState': array([4.60003925, 1.35170404]), 'targetState': array([0.24806327, 0.5598077 ]), 'effectorPosition': array([ 0.83346056, -1.31910231])}
episode index:194
target Thresh 0.7788577821246128
current state at start:  [ 1.81614522 -1.92736857]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.81614522, -1.92736857]), 'currentState': array([1.31614522, 3.85581674]), 'targetState': array([0.43902318, 1.066074  ]), 'effectorPosition': array([0.69547322, 0.07150925])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.9513124077980936
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.81614522, -1.92736857]), 'currentState': array([4.5755508, 5.330725 ]), 'targetState': array([0.43902318, 1.066074  ]), 'effectorPosition': array([-1.02271379, -1.45375949])}
episode index:195
target Thresh 0.7812976259033035
current state at start:  [-1.76831621  2.08548773]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.76831621,  2.08548773]), 'currentState': array([4.0148691 , 1.96963588]), 'targetState': array([ 0.95058283, -0.72407852]), 'effectorPosition': array([ 0.31340684, -1.06069679])}
done in step count: 20
reward sum = 0.8179069375972308
running average episode reward sum: 0.9506317676440076
{'reset': False, 'endBeforeDone': False, 'stepCount': 21, 'initial state': array([-1.76831621,  2.08548773]), 'currentState': array([4.22874779, 2.08322342]), 'targetState': array([ 0.95058283, -0.72407852]), 'effectorPosition': array([ 0.53457989, -0.85652569])}
episode index:196
target Thresh 0.7837325948708731
current state at start:  [ 1.22532841 -2.98041875]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.22532841, -2.98041875]), 'currentState': array([0.87589433, 2.80276656]), 'targetState': array([0.02669769, 0.07851321]), 'effectorPosition': array([-0.21890216,  0.25649727])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9508823678082512
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.22532841, -2.98041875]), 'currentState': array([0.87589433, 2.80276656]), 'targetState': array([0.02669769, 0.07851321]), 'effectorPosition': array([-0.21890216,  0.25649727])}
episode index:197
target Thresh 0.7861626987672004
current state at start:  [ 0.45110079 -2.41394789]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.45110079, -2.41394789]), 'currentState': array([6.28226352, 3.36923742]), 'targetState': array([ 0.67994079, -0.21209067]), 'effectorPosition': array([ 0.02559132, -0.22570737])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9510299316071994
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 0.45110079, -2.41394789]), 'currentState': array([5.28226352, 2.36923742]), 'targetState': array([ 0.67994079, -0.21209067]), 'effectorPosition': array([0.74062638, 0.13760205])}
episode index:198
target Thresh 0.7885879473127044
current state at start:  [ 2.73975041 -2.08778018]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.73975041, -2.08778018]), 'currentState': array([3.18260004, 4.32230788]), 'targetState': array([0.10001955, 0.90123521]), 'effectorPosition': array([-0.65713179,  0.89869404])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.9462508867247511
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.73975041, -2.08778018]), 'currentState': array([4.25121662, 5.72612729]), 'targetState': array([0.10001955, 0.90123521]), 'effectorPosition': array([-1.29617883, -1.42040445])}
episode index:199
target Thresh 0.7910083502083824
current state at start:  [ 3.93049985 -1.82506741]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.93049985, -1.82506741]), 'currentState': array([4.43049985, 4.9581179 ]), 'targetState': array([-0.91324043,  0.51736085]), 'effectorPosition': array([-1.27751701, -0.92437931])}
done in step count: 29
reward sum = 0.7471720943315961
running average episode reward sum: 0.9452554927627854
{'reset': False, 'endBeforeDone': False, 'stepCount': 30, 'initial state': array([ 3.93049985, -1.82506741]), 'currentState': array([3.87795603, 3.80654905]), 'targetState': array([-0.91324043,  0.51736085]), 'effectorPosition': array([-0.57224938,  0.31407526])}
episode index:200
target Thresh 0.7934239171358493
current state at start:  [-1.39579589 -3.00528357]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.39579589, -3.00528357]), 'currentState': array([4.38738942, 3.09298223]), 'targetState': array([ 0.05139332, -0.24676684]), 'effectorPosition': array([ 0.04567039, -0.01663502])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9455278534953089
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.39579589, -3.00528357]), 'currentState': array([4.38738942, 3.09298223]), 'targetState': array([ 0.05139332, -0.24676684]), 'effectorPosition': array([ 0.04567039, -0.01663502])}
episode index:201
target Thresh 0.7958346577573758
current state at start:  [ 3.41881598 -2.63591355]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.41881598, -2.63591355]), 'currentState': array([3.71495915, 4.14727176]), 'targetState': array([-0.43197488,  0.7410084 ]), 'effectorPosition': array([-0.84832872,  0.45750273])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9457975175869162
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.41881598, -2.63591355]), 'currentState': array([3.71495915, 4.14727176]), 'targetState': array([-0.43197488,  0.7410084 ]), 'effectorPosition': array([-0.84832872,  0.45750273])}
episode index:202
target Thresh 0.7982405817159279
current state at start:  [-1.31931736  1.8657577 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.31931736,  1.8657577 ]), 'currentState': array([4.54403396, 1.96651902]), 'targetState': array([ 1.19417282, -0.56806393]), 'effectorPosition': array([ 0.80670228, -0.760448  ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9460645248894437
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.31931736,  1.8657577 ]), 'currentState': array([4.54403396, 1.96651902]), 'targetState': array([ 1.19417282, -0.56806393]), 'effectorPosition': array([ 0.80670228, -0.760448  ])}
episode index:203
target Thresh 0.8006416986352045
current state at start:  [ 3.45086761 -3.07807333]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.45086761, -3.07807333]), 'currentState': array([3.95086761, 3.70511198]), 'targetState': array([-0.04131439, -0.05693197]), 'effectorPosition': array([-0.49331258,  0.25667448])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.946328914473319
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.45086761, -3.07807333]), 'currentState': array([3.95086761, 3.70511198]), 'targetState': array([-0.04131439, -0.05693197]), 'effectorPosition': array([-0.49331258,  0.25667448])}
episode index:204
target Thresh 0.8030380181196766
current state at start:  [0.78169731 2.56615617]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.78169731, 2.56615617]), 'currentState': array([0.39796589, 2.41011598]), 'targetState': array([-0.54796619,  0.28774744]), 'effectorPosition': array([-0.02304766,  0.71490637])}
done in step count: 69
reward sum = 0.4998370298991989
running average episode reward sum: 0.9441509052802746
{'reset': False, 'endBeforeDone': False, 'stepCount': 70, 'initial state': array([0.78169731, 2.56615617]), 'currentState': array([3.02509097, 3.70205064]), 'targetState': array([-0.54796619,  0.28774744]), 'effectorPosition': array([-0.09016191,  0.54575391])}
episode index:205
target Thresh 0.8054295497546251
current state at start:  [-0.21733965 -2.47939671]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.21733965, -2.47939671]), 'currentState': array([5.59195785, 3.79041326]), 'targetState': array([ 0.12373815, -0.59847007]), 'effectorPosition': array([-0.22863685, -0.59508923])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9444220173905644
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.21733965, -2.47939671]), 'currentState': array([5.59195785, 3.79041326]), 'targetState': array([ 0.12373815, -0.59847007]), 'effectorPosition': array([-0.22863685, -0.59508923])}
episode index:206
target Thresh 0.8078163031061798
current state at start:  [ 4.32494097 -2.5321921 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.32494097, -2.5321921 ]), 'currentState': array([4.68136914, 4.2509932 ]), 'targetState': array([-0.20420323,  0.04379731]), 'effectorPosition': array([-0.9122083 , -0.52676303])}
done in step count: 46
reward sum = 0.6298236312032323
running average episode reward sum: 0.9429022184234759
{'reset': False, 'endBeforeDone': False, 'stepCount': 47, 'initial state': array([ 4.32494097, -2.5321921 ]), 'currentState': array([4.19850252, 2.89666169]), 'targetState': array([-0.20420323,  0.04379731]), 'effectorPosition': array([ 0.19649835, -0.14519043])}
episode index:207
target Thresh 0.8101982877213574
current state at start:  [ 4.25437905 -2.3567557 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.25437905, -2.3567557 ]), 'currentState': array([4.75437905, 4.4264296 ]), 'targetState': array([-0.65381164, -0.04268034]), 'effectorPosition': array([-0.92840908, -0.75756227])}
done in step count: 17
reward sum = 0.8429431933839268
running average episode reward sum: 0.9424216461877089
{'reset': False, 'endBeforeDone': False, 'stepCount': 18, 'initial state': array([ 4.25437905, -2.3567557 ]), 'currentState': array([4.28234855, 4.15295218]), 'targetState': array([-0.65381164, -0.04268034]), 'effectorPosition': array([-0.96603439, -0.07320987])}
episode index:208
target Thresh 0.8125755131280996
current state at start:  [-0.74970924 -2.28401654]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.74970924, -2.28401654]), 'currentState': array([5.03347606, 3.49916876]), 'targetState': array([ 0.08800539, -0.68972688]), 'effectorPosition': array([-0.31215473, -0.1704803 ])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9426019253925523
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-0.74970924, -2.28401654]), 'currentState': array([4.03347606, 2.49916876]), 'targetState': array([ 0.08800539, -0.68972688]), 'effectorPosition': array([ 0.34109863, -0.53137556])}
episode index:209
target Thresh 0.814947988835311
current state at start:  [-0.86495834  1.65966817]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.86495834,  1.65966817]), 'currentState': array([4.91822697, 1.15966817]), 'targetState': array([ 1.02346981, -0.02446976]), 'effectorPosition': array([ 1.1833894, -1.1827413])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.9381133447954448
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.86495834,  1.65966817]), 'currentState': array([4.64450171, 4.61945538]), 'targetState': array([ 1.02346981, -0.02446976]), 'effectorPosition': array([-1.05493131, -0.837568  ])}
episode index:210
target Thresh 0.8173157243328979
current state at start:  [-1.18194505  1.61400339]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.18194505,  1.61400339]), 'currentState': array([4.60124026, 1.11400339]), 'targetState': array([ 1.17473836, -0.25245412]), 'effectorPosition': array([ 0.73208993, -1.53172732])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.9336673099859878
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.18194505,  1.61400339]), 'currentState': array([3.87616327, 4.05883455]), 'targetState': array([ 1.17473836, -0.25245412]), 'effectorPosition': array([-0.82304622,  0.32645142])}
episode index:211
target Thresh 0.8196787290918048
current state at start:  [-3.78504003  1.61001291]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.78504003,  1.61001291]), 'currentState': array([2.99814528, 1.93443992]), 'targetState': array([-1.2878367 , -0.45085011]), 'effectorPosition': array([-0.77130795, -0.83289868])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.9337041630020964
{'reset': False, 'endBeforeDone': False, 'stepCount': 7, 'initial state': array([-3.78504003,  1.61001291]), 'currentState': array([2.88834197, 1.28866078]), 'targetState': array([-1.2878367 , -0.45085011]), 'effectorPosition': array([-1.47827633, -0.60951938])}
episode index:212
target Thresh 0.8220370125640546
current state at start:  [ 1.8278575  -1.88502165]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.8278575 , -1.88502165]), 'currentState': array([2.14181215, 4.89816365]), 'targetState': array([0.66440145, 1.2259797 ]), 'effectorPosition': array([0.18655637, 1.52794391])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9340154110631194
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.8278575 , -1.88502165]), 'currentState': array([2.14181215, 4.89816365]), 'targetState': array([0.66440145, 1.2259797 ]), 'effectorPosition': array([0.18655637, 1.52794391])}
episode index:213
target Thresh 0.8243905841827839
current state at start:  [-1.85110428  3.01881865]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.85110428,  3.01881865]), 'currentState': array([3.93208103, 2.86109138]), 'targetState': array([0.44039233, 0.03116867]), 'effectorPosition': array([ 0.16925249, -0.22253094])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.934323750263759
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.85110428,  3.01881865]), 'currentState': array([3.93208103, 2.86109138]), 'targetState': array([0.44039233, 0.03116867]), 'effectorPosition': array([ 0.16925249, -0.22253094])}
episode index:214
target Thresh 0.8267394533622825
current state at start:  [-0.49835372  2.41916774]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.49835372,  2.41916774]), 'currentState': array([5.41959176, 1.96077896]), 'targetState': array([0.56884045, 0.53021624]), 'effectorPosition': array([1.10581262, 0.12974491])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.929978058402067
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.49835372,  2.41916774]), 'currentState': array([2.52028384, 3.15915291]), 'targetState': array([0.56884045, 0.53021624]), 'effectorPosition': array([0.01009593, 0.01436756])}
episode index:215
target Thresh 0.8290836294980302
current state at start:  [-2.17708253  2.73131998]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.17708253,  2.73131998]), 'currentState': array([3.60610278, 3.04187103]), 'targetState': array([ 0.49832593, -0.25030158]), 'effectorPosition': array([ 0.04015811, -0.09123317])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.930302234057613
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.17708253,  2.73131998]), 'currentState': array([3.60610278, 3.04187103]), 'targetState': array([ 0.49832593, -0.25030158]), 'effectorPosition': array([ 0.04015811, -0.09123317])}
episode index:216
target Thresh 0.8314231219667345
current state at start:  [ 2.39715693 -2.75823585]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.39715693, -2.75823585]), 'currentState': array([2.86488456, 4.02494946]), 'targetState': array([0.14324523, 0.02026201]), 'effectorPosition': array([-0.14039671,  0.84330782])}
done in step count: 14
reward sum = 0.8687458127689782
running average episode reward sum: 0.9300185639134259
{'reset': False, 'endBeforeDone': False, 'stepCount': 15, 'initial state': array([ 2.39715693, -2.75823585]), 'currentState': array([2.93501306, 2.66352707]), 'targetState': array([0.14324523, 0.02026201]), 'effectorPosition': array([-0.20409473, -0.42728477])}
episode index:217
target Thresh 0.8337579401263688
current state at start:  [-1.63407849 -1.7635386 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.63407849, -1.7635386 ]), 'currentState': array([4.26357116, 4.19807578]), 'targetState': array([-1.10888434, -0.85995593]), 'effectorPosition': array([-1.00485301, -0.07997742])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9302937081156579
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.63407849, -1.7635386 ]), 'currentState': array([4.20145129, 4.69807578]), 'targetState': array([-1.10888434, -0.85995593]), 'effectorPosition': array([-1.35419356, -0.37085627])}
episode index:218
target Thresh 0.8360880933162087
current state at start:  [-4.04590166  2.54229736]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.04590166,  2.54229736]), 'currentState': array([2.73728365, 3.04229736]), 'targetState': array([-0.74000239,  0.08708741]), 'effectorPosition': array([-0.04352557, -0.08920192])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.9305211341059973
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-4.04590166,  2.54229736]), 'currentState': array([3.73728365, 4.04229736]), 'targetState': array([-0.74000239,  0.08708741]), 'effectorPosition': array([-0.75342899,  0.43615268])}
episode index:219
target Thresh 0.8384135908568697
current state at start:  [ 2.0101289  -2.88714727]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.0101289 , -2.88714727]), 'currentState': array([2.5101289 , 3.89603804]), 'targetState': array([-0.00046559, -0.07476871]), 'effectorPosition': array([0.185283  , 0.71299874])}
done in step count: 16
reward sum = 0.8514577710948755
running average episode reward sum: 0.9301617551832195
{'reset': False, 'endBeforeDone': False, 'stepCount': 17, 'initial state': array([ 2.0101289 , -2.88714727]), 'currentState': array([2.90839573, 2.72586287]), 'targetState': array([-0.00046559, -0.07476871]), 'effectorPosition': array([-0.17619971, -0.37324254])}
episode index:220
target Thresh 0.8407344420503455
current state at start:  [ 1.80310043 -2.41674698]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.80310043, -2.41674698]), 'currentState': array([1.98871627, 4.36643833]), 'targetState': array([0.75459293, 0.22546248]), 'effectorPosition': array([0.59155103, 0.98584231])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.9259528784629335
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.80310043, -2.41674698]), 'currentState': array([3.39319468, 3.67563158]), 'targetState': array([0.75459293, 0.22546248]), 'effectorPosition': array([-0.26157975,  0.45832258])}
episode index:221
target Thresh 0.8430506561800437
current state at start:  [ 3.90465578 -2.83573555]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.90465578, -2.83573555]), 'currentState': array([4.07032327, 3.94744976]), 'targetState': array([ 0.0390566 , -0.03464283]), 'effectorPosition': array([-0.76191108,  0.18575574])}
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.9258149747503019
{'reset': False, 'endBeforeDone': False, 'stepCount': 12, 'initial state': array([ 3.90465578, -2.83573555]), 'currentState': array([2.51166762, 2.90653999]), 'targetState': array([ 0.0390566 , -0.03464283]), 'effectorPosition': array([-0.15941459, -0.17199662])}
episode index:222
target Thresh 0.8453622425108243
current state at start:  [-1.44290343 -2.00795105]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.44290343, -2.00795105]), 'currentState': array([4.34028187, 3.86478681]), 'targetState': array([-0.77297001, -0.71550001]), 'effectorPosition': array([-0.70749789,  0.0074361 ])}
done in step count: 15
reward sum = 0.8600583546412884
running average episode reward sum: 0.9255201020143871
{'reset': False, 'endBeforeDone': False, 'stepCount': 16, 'initial state': array([-1.44290343, -2.00795105]), 'currentState': array([2.38575908, 2.08116081]), 'targetState': array([-0.77297001, -0.71550001]), 'effectorPosition': array([-0.97071143, -0.28412794])}
episode index:223
target Thresh 0.8476692102890351
current state at start:  [ 1.56952135 -1.89604598]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.56952135, -1.89604598]), 'currentState': array([1.50818504, 4.88713933]), 'targetState': array([0.86851912, 0.31801251]), 'effectorPosition': array([1.05628938, 1.10994474])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.92138831584468
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.56952135, -1.89604598]), 'currentState': array([2.09547464, 1.63267437]), 'targetState': array([0.86851912, 0.31801251]), 'effectorPosition': array([-1.33378627,  0.31198887])}
episode index:224
target Thresh 0.8499715687425506
current state at start:  [0.77054871 2.33905582]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.77054871, 2.33905582]), 'currentState': array([1.27054871, 2.83905582]), 'targetState': array([0.12342795, 0.39386776]), 'effectorPosition': array([-0.27118163,  0.13150308])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9217377011075926
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.77054871, 2.33905582]), 'currentState': array([1.27054871, 2.83905582]), 'targetState': array([0.12342795, 0.39386776]), 'effectorPosition': array([-0.27118163,  0.13150308])}
episode index:225
target Thresh 0.8522693270808079
current state at start:  [-1.24116554  2.88702111]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.24116554,  2.88702111]), 'currentState': array([4.54617865, 2.61376198]), 'targetState': array([ 0.11161934, -0.03776843]), 'effectorPosition': array([ 0.47420248, -0.21755136])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9220839944655236
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.24116554,  2.88702111]), 'currentState': array([4.54617865, 2.61376198]), 'targetState': array([ 0.11161934, -0.03776843]), 'effectorPosition': array([ 0.47420248, -0.21755136])}
episode index:226
target Thresh 0.8545624944948433
current state at start:  [-1.70672406  1.67444673]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.70672406,  1.67444673]), 'currentState': array([4.07646124, 1.34417817]), 'targetState': array([ 0.56718226, -1.11656264]), 'effectorPosition': array([ 0.05658182, -1.56402218])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.918021950437041
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.70672406,  1.67444673]), 'currentState': array([2.3653913 , 2.84305525]), 'targetState': array([ 0.56718226, -1.11656264]), 'effectorPosition': array([-0.2376179, -0.178892 ])}
episode index:227
target Thresh 0.8568510801573292
current state at start:  [-1.54290413  2.4964658 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.54290413,  2.4964658 ]), 'currentState': array([4.24028118, 2.09149134]), 'targetState': array([ 0.38596963, -0.58583015]), 'effectorPosition': array([ 0.54405535, -0.84204362])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9183815032860014
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.54290413,  2.4964658 ]), 'currentState': array([4.24028118, 2.09149134]), 'targetState': array([ 0.38596963, -0.58583015]), 'effectorPosition': array([ 0.54405535, -0.84204362])}
episode index:228
target Thresh 0.8591350932226118
current state at start:  [0.22922196 2.36345677]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.22922196, 2.36345677]), 'currentState': array([0.37059372, 2.81658162]), 'targetState': array([0.21306472, 0.98975596]), 'effectorPosition': array([-0.06684881,  0.31660201])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9186942478131368
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.22922196, 2.36345677]), 'currentState': array([6.15377903, 2.33879415]), 'targetState': array([0.21306472, 0.98975596]), 'effectorPosition': array([0.39557355, 0.67389067])}
episode index:229
target Thresh 0.8614145428267459
current state at start:  [-1.76403155e-04 -2.27472289e+00]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.76403155e-04, -2.27472289e+00]), 'currentState': array([5.7830089 , 3.62147772]), 'targetState': array([ 0.02937787, -0.97236625]), 'effectorPosition': array([-0.12229616, -0.45929039])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.914699924996558
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.76403155e-04, -2.27472289e+00]), 'currentState': array([2.41820208, 1.0493878 ]), 'targetState': array([ 0.02937787, -0.97236625]), 'effectorPosition': array([-1.69689755,  0.34167628])}
episode index:230
target Thresh 0.8636894380875333
current state at start:  [ 1.98124857 -2.7071042 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.98124857, -2.7071042 ]), 'currentState': array([2.48124857, 4.07608111]), 'targetState': array([0.17044441, 0.04488049]), 'effectorPosition': array([0.17287597, 0.884112  ])}
done in step count: 60
reward sum = 0.5471566423907612
running average episode reward sum: 0.913108828535061
{'reset': False, 'endBeforeDone': False, 'stepCount': 61, 'initial state': array([ 1.98124857, -2.7071042 ]), 'currentState': array([3.95936952, 3.41724283]), 'targetState': array([0.17044441, 0.04488049]), 'effectorPosition': array([-0.22440081,  0.15857931])}
episode index:231
target Thresh 0.865959788104558
current state at start:  [ 2.43690001 -1.74265281]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.43690001, -1.74265281]), 'currentState': array([2.93690001, 4.96176878]), 'targetState': array([-0.24170407,  1.27415662]), 'effectorPosition': array([-1.02379579,  1.20226792])}
done in step count: 14
reward sum = 0.8687458127689782
running average episode reward sum: 0.9129176086395177
{'reset': False, 'endBeforeDone': False, 'stepCount': 15, 'initial state': array([ 2.43690001, -1.74265281]), 'currentState': array([2.47522446, 5.10612268]), 'targetState': array([-0.24170407,  1.27415662]), 'effectorPosition': array([-0.51680223,  1.58120006])}
episode index:232
target Thresh 0.8682256019592227
current state at start:  [ 2.62203254 -1.72828399]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.62203254, -1.72828399]), 'currentState': array([3.12203254, 4.88321258]), 'targetState': array([0.09999523, 1.21604596]), 'effectorPosition': array([-1.15049601,  1.00814035])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.9132484343535112
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 2.62203254, -1.72828399]), 'currentState': array([2.74912257, 4.38321258]), 'targetState': array([0.09999523, 1.21604596]), 'effectorPosition': array([-0.26334553,  1.1331909 ])}
episode index:233
target Thresh 0.8704868887147867
current state at start:  [-1.31056732  1.7087765 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.31056732,  1.7087765 ]), 'currentState': array([4.47608981, 1.2087765 ]), 'targetState': array([ 0.82596471, -0.45329024]), 'effectorPosition': array([ 0.59217737, -1.5354653 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.9093456632665303
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.31056732,  1.7087765 ]), 'currentState': array([1.76061193, 0.83441846]), 'targetState': array([ 0.82596471, -0.45329024]), 'effectorPosition': array([-1.04299415,  1.50179244])}
episode index:234
target Thresh 0.8727436574163994
current state at start:  [ 0.97336247 -2.56634254]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.97336247, -2.56634254]), 'currentState': array([1.47336247, 4.21684276]), 'targetState': array([ 0.38270671, -0.56192521]), 'effectorPosition': array([0.92655876, 0.43642226])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.9054761072526303
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.97336247, -2.56634254]), 'currentState': array([2.08171591, 5.59454795]), 'targetState': array([ 0.38270671, -0.56192521]), 'effectorPosition': array([-0.31219584,  1.85654493])}
episode index:235
target Thresh 0.8749959170911386
current state at start:  [-0.9527609  -2.77287241]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.9527609 , -2.77287241]), 'currentState': array([5.16841177, 3.0103129 ]), 'targetState': array([-0.26795333, -0.1001501 ]), 'effectorPosition': array([0.12131555, 0.04992167])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9058766322218987
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.9527609 , -2.77287241]), 'currentState': array([5.16841177, 3.0103129 ]), 'targetState': array([-0.26795333, -0.1001501 ]), 'effectorPosition': array([0.12131555, 0.04992167])}
episode index:236
target Thresh 0.877243676748046
current state at start:  [ 0.50715539 -2.82149748]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.50715539, -2.82149748]), 'currentState': array([1.00715539, 3.11877772]), 'targetState': array([ 0.03600379, -0.05013505]), 'effectorPosition': array([-0.0191451 ,  0.01240821])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9062737772336207
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.50715539, -2.82149748]), 'currentState': array([1.00715539, 3.11877772]), 'targetState': array([ 0.03600379, -0.05013505]), 'effectorPosition': array([-0.0191451 ,  0.01240821])}
episode index:237
target Thresh 0.8794869453781637
current state at start:  [ 0.14931298 -2.63082204]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.14931298, -2.63082204]), 'currentState': array([6.20137012, 3.15236326]), 'targetState': array([ 0.17600158, -0.34531785]), 'effectorPosition': array([-0.00082239, -0.01073911])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.9066675848923029
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.14931298, -2.63082204]), 'currentState': array([6.20137012, 3.15236326]), 'targetState': array([ 0.17600158, -0.34531785]), 'effectorPosition': array([-0.00082239, -0.01073911])}
episode index:238
target Thresh 0.8817257319545688
current state at start:  [-3.00358301  2.07489638]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.00358301,  2.07489638]), 'currentState': array([3.11017922, 1.65551017]), 'targetState': array([ 0.02057368, -1.06742305]), 'effectorPosition': array([-0.94623146, -0.9671716 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.9028739966709962
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.00358301,  2.07489638]), 'currentState': array([1.10120825, 0.84308518]), 'targetState': array([ 0.02057368, -1.06742305]), 'effectorPosition': array([0.08764533, 1.82281181])}
episode index:239
target Thresh 0.8839600454324108
current state at start:  [ 1.31814078 -1.64880699]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.31814078, -1.64880699]), 'currentState': array([1.81814078, 5.13437832]), 'targetState': array([1.32150272, 0.40930942]), 'effectorPosition': array([0.5394051 , 1.59002966])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.8991120216848671
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.31814078, -1.64880699]), 'currentState': array([0.81584076, 0.53671624]), 'targetState': array([1.32150272, 0.40930942]), 'effectorPosition': array([0.90176737, 1.70458216])}
episode index:240
target Thresh 0.8861898947489464
current state at start:  [-0.13903181  2.62601331]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.13903181,  2.62601331]), 'currentState': array([5.6441535 , 2.19148866]), 'targetState': array([0.45181685, 0.74956093]), 'effectorPosition': array([0.82101203, 0.40341325])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8995306440015274
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.13903181,  2.62601331]), 'currentState': array([5.6441535 , 2.19148866]), 'targetState': array([0.45181685, 0.74956093]), 'effectorPosition': array([0.82101203, 0.40341325])}
episode index:241
target Thresh 0.8884152888235759
current state at start:  [ 0.62909296 -1.82463954]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.62909296, -1.82463954]), 'currentState': array([0.90519771, 4.90588107]), 'targetState': array([ 1.27779315, -0.50408192]), 'effectorPosition': array([1.50814238, 0.33178387])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.8958135752246615
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.62909296, -1.82463954]), 'currentState': array([1.10039776, 5.91913538]), 'targetState': array([ 1.27779315, -0.50408192]), 'effectorPosition': array([1.19416784, 1.56297412])}
episode index:242
target Thresh 0.8906362365578786
current state at start:  [ 2.01195919 -2.07743779]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.01195919, -2.07743779]), 'currentState': array([2.16707569, 4.36601249]), 'targetState': array([0.68296261, 0.61847911]), 'effectorPosition': array([0.40736865, 1.07474058])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8962423259439016
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.01195919, -2.07743779]), 'currentState': array([2.16707569, 4.36601249]), 'targetState': array([0.68296261, 0.61847911]), 'effectorPosition': array([0.40736865, 1.07474058])}
episode index:243
target Thresh 0.8928527468356484
current state at start:  [1.85358827 2.18022404]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.85358827, 2.18022404]), 'currentState': array([1.41293211, 1.90514655]), 'targetState': array([-1.0836032 , -0.08934631]), 'effectorPosition': array([-0.82725739,  0.81199405])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.8925692016572463
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.85358827, 2.18022404]), 'currentState': array([0.92738533, 6.20574658]), 'targetState': array([-1.0836032 , -0.08934631]), 'effectorPosition': array([1.25995117, 1.55129923])}
episode index:244
target Thresh 0.8950648285229292
current state at start:  [-1.03911303  2.36535724]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.03911303,  2.36535724]), 'currentState': array([5.60740288, 1.86882608]), 'targetState': array([0.35241353, 0.0693415 ]), 'effectorPosition': array([1.1490503 , 0.30398789])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.8889260620586453
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.03911303,  2.36535724]), 'currentState': array([1.56717917, 5.81434164]), 'targetState': array([0.35241353, 0.0693415 ]), 'effectorPosition': array([0.45869605, 1.89044457])}
episode index:245
target Thresh 0.8972724904680509
current state at start:  [ 0.31172593 -2.22399525]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.31172593, -2.22399525]), 'currentState': array([0.81172593, 4.45169791]), 'targetState': array([ 0.89514773, -0.5903232 ]), 'effectorPosition': array([ 1.21181653, -0.12650704])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8893775821315777
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.31172593, -2.22399525]), 'currentState': array([0.81172593, 4.45169791]), 'targetState': array([ 0.89514773, -0.5903232 ]), 'effectorPosition': array([ 1.21181653, -0.12650704])}
episode index:246
target Thresh 0.8994757415016643
current state at start:  [ 2.65520845 -2.44824427]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.65520845, -2.44824427]), 'currentState': array([2.47069083, 4.26315124]), 'targetState': array([0.28084715, 0.44599388]), 'effectorPosition': array([0.11689992, 1.05724942])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.8857768631755794
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.65520845, -2.44824427]), 'currentState': array([0.66385061, 6.09502161]), 'targetState': array([0.28084715, 0.44599388]), 'effectorPosition': array([1.67660387, 1.07410345])}
episode index:247
target Thresh 0.9016745904367762
current state at start:  [-1.1824356  -2.12282856]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.1824356 , -2.12282856]), 'currentState': array([4.60074971, 3.66035674]), 'targetState': array([-1.02216737, -0.92406366]), 'effectorPosition': array([-0.50737831, -0.0755117 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.8822051822756778
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.1824356 , -2.12282856]), 'currentState': array([1.29619402, 5.67886058]), 'targetState': array([-1.02216737, -0.92406366]), 'effectorPosition': array([1.04121896, 1.60051086])}
episode index:248
target Thresh 0.9038690460687857
current state at start:  [-0.29884506 -2.65847211]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.29884506, -2.65847211]), 'currentState': array([5.48434025, 3.14083509]), 'targetState': array([ 0.29660917, -0.25151337]), 'effectorPosition': array([0.00054303, 0.00052822])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8826782538328036
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.29884506, -2.65847211]), 'currentState': array([5.48434025, 3.14083509]), 'targetState': array([ 0.29660917, -0.25151337]), 'effectorPosition': array([0.00054303, 0.00052822])}
episode index:249
target Thresh 0.9060591171755177
current state at start:  [ 1.84209403 -2.42100689]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.84209403, -2.42100689]), 'currentState': array([1.97998703, 4.2468681 ]), 'targetState': array([0.47062836, 0.40335278]), 'effectorPosition': array([0.6005469 , 0.86114272])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8831475408174724
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.84209403, -2.42100689]), 'currentState': array([1.97998703, 4.2468681 ]), 'targetState': array([0.47062836, 0.40335278]), 'effectorPosition': array([0.6005469 , 0.86114272])}
episode index:250
target Thresh 0.9082448125172597
current state at start:  [-2.30974641  2.25051723]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.30974641,  2.25051723]), 'currentState': array([4.46208294, 1.86579008]), 'targetState': array([-0.06758859, -0.35819373]), 'effectorPosition': array([ 0.75130119, -0.92416382])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.879629024718598
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.30974641,  2.25051723]), 'currentState': array([0.8206206 , 0.11759952]), 'targetState': array([-0.06758859, -0.35819373]), 'effectorPosition': array([1.27299177, 1.53807614])}
episode index:251
target Thresh 0.9104261408367962
current state at start:  [-3.06197067  2.39060888]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.06197067,  2.39060888]), 'currentState': array([2.7872908 , 2.89060888]), 'targetState': array([ 0.20221864, -0.36714548]), 'effectorPosition': array([-0.11554932, -0.22206131])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.880106687318921
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.06197067,  2.39060888]), 'currentState': array([2.7872908 , 2.89060888]), 'targetState': array([ 0.20221864, -0.36714548]), 'effectorPosition': array([-0.11554932, -0.22206131])}
episode index:252
target Thresh 0.9126031108594435
current state at start:  [-0.88940852  1.99597198]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.88940852,  1.99597198]), 'currentState': array([5.89377679, 1.84469313]), 'targetState': array([1.09851671, 0.45568224]), 'effectorPosition': array([1.04038879, 0.61369465])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8805805739303088
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.88940852,  1.99597198]), 'currentState': array([5.89377679, 1.84469313]), 'targetState': array([1.09851671, 0.45568224]), 'effectorPosition': array([1.04038879, 0.61369465])}
episode index:253
target Thresh 0.9147757312930842
current state at start:  [0.60802658 2.64292896]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.60802658, 2.64292896]), 'currentState': array([0.33413152, 2.50554079]), 'targetState': array([-0.01195699,  0.00557665]), 'effectorPosition': array([-0.01007175,  0.62530308])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.8771137212770398
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.60802658, 2.64292896]), 'currentState': array([1.00656737, 6.23611614]), 'targetState': array([-0.01195699,  0.00557665]), 'effectorPosition': array([1.10869542, 1.66390485])}
episode index:254
target Thresh 0.9169440108282032
current state at start:  [ 0.11715566 -2.8716728 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.11715566, -2.8716728 ]), 'currentState': array([6.10179352, 3.4618144 ]), 'targetState': array([ 0.49751291, -0.20220392]), 'effectorPosition': array([-0.00678502, -0.31878312])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.8775175890367376
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 0.11715566, -2.8716728 ]), 'currentState': array([5.17333426, 2.71122896]), 'targetState': array([ 0.49751291, -0.20220392]), 'effectorPosition': array([0.41421811, 0.10389998])}
episode index:255
target Thresh 0.9191079581379213
current state at start:  [ 0.98845472 -2.40885313]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.98845472, -2.40885313]), 'currentState': array([1.47359131, 4.31659256]), 'targetState': array([ 0.8988213 , -0.26907987]), 'effectorPosition': array([0.97796834, 0.52200729])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.8740897859545629
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.98845472, -2.40885313]), 'currentState': array([0.61111956, 5.88249611]), 'targetState': array([ 0.8988213 , -0.26907987]), 'effectorPosition': array([1.79694726, 0.78266552])}
episode index:256
target Thresh 0.9212675818780309
current state at start:  [-0.98266795 -1.87015741]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.98266795, -1.87015741]), 'currentState': array([5.68581946, 4.56840755]), 'targetState': array([-0.74399139, -1.00387855]), 'effectorPosition': array([ 0.15153788, -1.30002589])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.8706886583827552
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.98266795, -1.87015741]), 'currentState': array([1.46393321, 5.78840342]), 'targetState': array([-0.74399139, -1.00387855]), 'effectorPosition': array([0.67265924, 1.81870122])}
episode index:257
target Thresh 0.9234228906870297
current state at start:  [ 2.47034885 -2.18703012]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.47034885, -2.18703012]), 'currentState': array([2.97034885, 4.59615518]), 'targetState': array([0.22973346, 1.08114807]), 'effectorPosition': array([-0.70183933,  1.1293702 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.8673138961409617
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.47034885, -2.18703012]), 'currentState': array([0.7942034 , 0.02931186]), 'targetState': array([0.22973346, 1.08114807]), 'effectorPosition': array([1.38050003, 1.44684503])}
episode index:258
target Thresh 0.9255738931861557
current state at start:  [-0.28697359 -2.47226961]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.28697359, -2.47226961]), 'currentState': array([6.25874732, 4.24946295]), 'targetState': array([ 0.30756454, -1.1133543 ]), 'effectorPosition': array([ 0.53140297, -0.90800591])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8678261977002629
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.28697359, -2.47226961]), 'currentState': array([6.25874732, 4.24946295]), 'targetState': array([ 0.30756454, -1.1133543 ]), 'effectorPosition': array([ 0.53140297, -0.90800591])}
episode index:259
target Thresh 0.9277205979794219
current state at start:  [-4.32963879  2.44155699]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.32963879,  2.44155699]), 'currentState': array([2.14572491, 2.54565402]), 'targetState': array([-0.39988645,  0.22249679]), 'effectorPosition': array([-0.56478336, -0.16054816])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8683345584783388
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.32963879,  2.44155699]), 'currentState': array([2.14572491, 2.54565402]), 'targetState': array([-0.39988645,  0.22249679]), 'effectorPosition': array([-0.56478336, -0.16054816])}
episode index:260
target Thresh 0.9298630136536501
current state at start:  [-3.53386373  1.92968089]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.53386373,  1.92968089]), 'currentState': array([2.82382872, 2.39448382]), 'targetState': array([-0.54241605, -0.267338  ]), 'effectorPosition': array([-0.46532093, -0.56228406])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8688390237715253
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.53386373,  1.92968089]), 'currentState': array([2.82382872, 2.39448382]), 'targetState': array([-0.54241605, -0.267338  ]), 'effectorPosition': array([-0.46532093, -0.56228406])}
episode index:261
target Thresh 0.9320011487785065
current state at start:  [ 3.30524162 -1.61167157]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.30524162, -1.61167157]), 'currentState': array([3.02749513, 5.17151374]), 'targetState': array([-1.0890679,  0.8025398]), 'effectorPosition': array([-1.33172024,  1.05491637])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.869339638184611
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.30524162, -1.61167157]), 'currentState': array([3.02749513, 5.17151374]), 'targetState': array([-1.0890679,  0.8025398]), 'effectorPosition': array([-1.33172024,  1.05491637])}
episode index:262
target Thresh 0.9341350119065337
current state at start:  [0.16320441 2.83910143]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.16320441, 2.83910143]), 'currentState': array([5.94638972, 2.59470417]), 'targetState': array([-0.40349366, -0.0188685 ]), 'effectorPosition': array([0.30951109, 0.44261655])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.8660341642751639
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.16320441, 2.83910143]), 'currentState': array([1.3620523 , 6.02213303]), 'targetState': array([-0.40349366, -0.0188685 ]), 'effectorPosition': array([0.65993603, 1.86995248])}
episode index:263
target Thresh 0.9362646115731874
current state at start:  [-1.74518191 -2.64035034]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.74518191, -2.64035034]), 'currentState': array([4.73398001, 3.83172808]), 'targetState': array([-0.18653227,  0.17382224]), 'effectorPosition': array([-0.63155272, -0.24253154])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8665416106226065
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.74518191, -2.64035034]), 'currentState': array([4.73398001, 3.83172808]), 'targetState': array([-0.18653227,  0.17382224]), 'effectorPosition': array([-0.63155272, -0.24253154])}
episode index:264
target Thresh 0.9383899562968692
current state at start:  [ 3.26741644 -1.76484818]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.26741644, -1.76484818]), 'currentState': array([3.59571495, 4.87531734]), 'targetState': array([-0.59482739,  1.13213871]), 'effectorPosition': array([-1.47727863,  0.37691485])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.8632716422806344
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.26741644, -1.76484818]), 'currentState': array([1.08548327, 0.19710007]), 'targetState': array([-0.59482739,  1.13213871]), 'effectorPosition': array([0.75072467, 1.8432823 ])}
episode index:265
target Thresh 0.9405110545789606
current state at start:  [1.71468773 2.49326658]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.71468773, 2.49326658]), 'currentState': array([2.15169474, 2.84605554]), 'targetState': array([-0.41106642, -0.33911744]), 'effectorPosition': array([-0.26727105, -0.12359005])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8637856586630379
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.71468773, 2.49326658]), 'currentState': array([2.15169474, 2.84605554]), 'targetState': array([-0.41106642, -0.33911744]), 'effectorPosition': array([-0.26727105, -0.12359005])}
episode index:266
target Thresh 0.9426279149038579
current state at start:  [0.4031071  2.20773986]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.4031071 , 2.20773986]), 'currentState': array([6.18629241, 2.01390099]), 'targetState': array([0.37451292, 0.71443048]), 'effectorPosition': array([0.65597276, 0.84392358])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8642958247354611
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.4031071 , 2.20773986]), 'currentState': array([6.18629241, 2.01390099]), 'targetState': array([0.37451292, 0.71443048]), 'effectorPosition': array([0.65597276, 0.84392358])}
episode index:267
target Thresh 0.9447405457390046
current state at start:  [-3.88243203  2.19436689]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.88243203,  2.19436689]), 'currentState': array([2.754651  , 2.69436689]), 'targetState': array([-1.18042234, -0.62915007]), 'effectorPosition': array([-0.25427284, -0.36337949])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.8646193106502541
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([-3.88243203,  2.19436689]), 'currentState': array([4.40094752, 5.06357255]), 'targetState': array([-1.18042234, -0.62915007]), 'effectorPosition': array([-1.30564146, -0.99162449])}
episode index:268
target Thresh 0.9468489555349275
current state at start:  [-0.51630598 -2.66643644]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.51630598, -2.66643644]), 'currentState': array([5.98878951, 4.11674887]), 'targetState': array([ 0.13863567, -0.0057566 ]), 'effectorPosition': array([ 0.17988328, -0.91954582])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.8614051124693982
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.51630598, -2.66643644]), 'currentState': array([1.34466681, 5.65453725]), 'targetState': array([ 0.13863567, -0.0057566 ]), 'effectorPosition': array([0.97863221, 1.63092781])}
episode index:269
target Thresh 0.9489531527252684
current state at start:  [-2.88478737  2.50923253]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.88478737,  2.50923253]), 'currentState': array([3.89839793, 2.77455253]), 'targetState': array([-0.04504352, -0.84970426]), 'effectorPosition': array([ 0.1979651 , -0.30663109])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.861808423163956
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-2.88478737,  2.50923253]), 'currentState': array([5.39839793, 3.84541253]), 'targetState': array([-0.04504352, -0.84970426]), 'effectorPosition': array([-0.35021598, -0.59379896])}
episode index:270
target Thresh 0.9510531457268185
current state at start:  [1.98614665 1.69076163]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.98614665, 1.69076163]), 'currentState': array([2.30054103, 1.93258746]), 'targetState': array([-1.34131988,  0.04448116]), 'effectorPosition': array([-1.12780248, -0.14199155])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8623183551818012
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.98614665, 1.69076163]), 'currentState': array([2.30054103, 1.93258746]), 'targetState': array([-1.34131988,  0.04448116]), 'effectorPosition': array([-1.12780248, -0.14199155])}
episode index:271
target Thresh 0.9531489429395532
current state at start:  [-2.57675271  2.1310578 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.57675271,  2.1310578 ]), 'currentState': array([4.2064326 , 2.49591953]), 'targetState': array([ 0.50888641, -0.92571005]), 'effectorPosition': array([ 0.42878414, -0.46771183])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8628245376995152
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.57675271,  2.1310578 ]), 'currentState': array([4.2064326 , 2.49591953]), 'targetState': array([ 0.50888641, -0.92571005]), 'effectorPosition': array([ 0.42878414, -0.46771183])}
episode index:272
target Thresh 0.9552405527466636
current state at start:  [ 0.24073017 -2.03310996]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.24073017, -2.03310996]), 'currentState': array([0.74073017, 4.75007535]), 'targetState': array([ 0.74832961, -0.54611342]), 'effectorPosition': array([ 1.44012885, -0.03719932])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.8596640082573924
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.24073017, -2.03310996]), 'currentState': array([3.71948687, 5.59843978]), 'targetState': array([ 0.74832961, -0.54611342]), 'effectorPosition': array([-1.83191164, -0.43961321])}
episode index:273
target Thresh 0.9573279835145923
current state at start:  [ 2.01043492 -2.73609363]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.01043492, -2.73609363]), 'currentState': array([2.51043492, 4.04709167]), 'targetState': array([0.14216651, 0.00971061]), 'effectorPosition': array([0.15525896, 0.86099276])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.8565265483732413
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.01043492, -2.73609363]), 'currentState': array([1.31332132, 0.30194758]), 'targetState': array([0.14216651, 0.00971061]), 'effectorPosition': array([0.21018169, 1.96604728])}
episode index:274
target Thresh 0.9594112435930646
current state at start:  [-0.50861988  2.65916883]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.50861988,  2.65916883]), 'currentState': array([6.18642273, 2.15916883]), 'targetState': array([0.55559319, 0.15443241]), 'effectorPosition': array([0.52327639, 0.78496239])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.8534119063791568
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.50861988,  2.65916883]), 'currentState': array([0.65929244, 0.24791888]), 'targetState': array([0.55559319, 0.15443241]), 'effectorPosition': array([1.40637089, 1.40034686])}
episode index:275
target Thresh 0.9614903413151239
current state at start:  [-1.89203825  2.49207959]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.89203825,  2.49207959]), 'currentState': array([4.89114706, 1.99207959]), 'targetState': array([ 0.19463515, -0.26404905]), 'effectorPosition': array([ 1.00311985, -0.41938869])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.8503198342545947
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.89203825,  2.49207959]), 'currentState': array([0.9348254 , 0.23130199]), 'targetState': array([ 0.19463515, -0.26404905]), 'effectorPosition': array([0.98767336, 1.72372818])}
episode index:276
target Thresh 0.9635652849971639
current state at start:  [ 1.84245081 -2.61894159]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.84245081, -2.61894159]), 'currentState': array([2.29536609, 4.16424372]), 'targetState': array([ 0.02720822, -0.07773228]), 'effectorPosition': array([0.32166417, 0.92429536])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.8472500875605348
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.84245081, -2.61894159]), 'currentState': array([0.38643332, 0.02091737]), 'targetState': array([ 0.02720822, -0.07773228]), 'effectorPosition': array([1.84443283, 0.77306535])}
episode index:277
target Thresh 0.9656360829389616
current state at start:  [ 2.42816695 -2.49739567]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.42816695, -2.49739567]), 'currentState': array([2.84646323, 4.28578964]), 'targetState': array([-0.03209927,  0.26622124]), 'effectorPosition': array([-0.29608113,  1.04152837])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.8442024253750652
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.42816695, -2.49739567]), 'currentState': array([0.48051352, 0.0729296 ]), 'targetState': array([-0.03209927,  0.26622124]), 'effectorPosition': array([1.73747747, 0.98785407])}
episode index:278
target Thresh 0.9677027434237124
current state at start:  [ 1.53805832 -3.03080798]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.53805832, -3.03080798]), 'currentState': array([1.52302676, 3.64449822]), 'targetState': array([-0.10649563,  0.14195144]), 'effectorPosition': array([0.48733588, 0.100658  ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.8411766102303517
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.53805832, -3.03080798]), 'currentState': array([0.44574494, 0.79589412]), 'targetState': array([-0.10649563,  0.14195144]), 'effectorPosition': array([1.22553541, 1.37744524])}
episode index:279
target Thresh 0.9697652747180603
current state at start:  [-1.35145938  1.80812165]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.35145938,  1.80812165]), 'currentState': array([5.2852657 , 1.47342065]), 'targetState': array([ 0.96060686, -0.75236463]), 'effectorPosition': array([ 1.43111519, -0.38256116])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8417438366223862
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.35145938,  1.80812165]), 'currentState': array([5.2852657 , 1.47342065]), 'targetState': array([ 0.96060686, -0.75236463]), 'effectorPosition': array([ 1.43111519, -0.38256116])}
episode index:280
target Thresh 0.9718236850721331
current state at start:  [ 2.45407244 -2.1138274 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.45407244, -2.1138274 ]), 'currentState': array([1.95407244, 4.66935791]), 'targetState': array([-0.18903453,  1.20344091]), 'effectorPosition': array([0.56871203, 1.26116257])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.8387483069546908
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.45407244, -2.1138274 ]), 'currentState': array([1.10275225, 5.66020614]), 'targetState': array([-0.18903453,  1.20344091]), 'effectorPosition': array([1.33824127, 1.35403028])}
episode index:281
target Thresh 0.9738779827195758
current state at start:  [1.31393093 1.97427159]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.31393093, 1.97427159]), 'currentState': array([0.86109385, 1.47427159]), 'targetState': array([-0.30916269,  0.52946094]), 'effectorPosition': array([-0.04061799,  1.48023647])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.8357740221782558
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.31393093, 1.97427159]), 'currentState': array([0.85036622, 5.79897647]), 'targetState': array([-0.30916269,  0.52946094]), 'effectorPosition': array([1.59341797, 1.10955225])}
episode index:282
target Thresh 0.9759281758775809
current state at start:  [ 2.39584829 -2.32764405]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.39584829, -2.32764405]), 'currentState': array([2.84968178, 4.45554126]), 'targetState': array([0.6822806 , 1.20788083]), 'effectorPosition': array([-0.43606721,  1.14095552])}
done in step count: 16
reward sum = 0.8514577710948755
running average episode reward sum: 0.835829441785735
{'reset': False, 'endBeforeDone': False, 'stepCount': 17, 'initial state': array([ 2.39584829, -2.32764405]), 'currentState': array([0.71308014, 1.1992284 ]), 'targetState': array([0.6822806 , 1.20788083]), 'effectorPosition': array([0.42143819, 1.59641582])}
episode index:283
target Thresh 0.9779742727469241
current state at start:  [ 3.40504482 -2.92167782]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.40504482, -2.92167782]), 'currentState': array([3.8611736 , 3.86150749]), 'targetState': array([-0.0412401 , -0.22168234]), 'effectorPosition': array([-0.62115838,  0.33232289])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.8328863803709965
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.40504482, -2.92167782]), 'currentState': array([1.24041596, 0.64365971]), 'targetState': array([-0.0412401 , -0.22168234]), 'effectorPosition': array([0.01622282, 1.89724708])}
episode index:284
target Thresh 0.9800162815119957
current state at start:  [-1.39068193 -2.58471555]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.39068193, -2.58471555]), 'currentState': array([4.88684213, 4.16872141]), 'targetState': array([-0.91235311, -0.60411008]), 'effectorPosition': array([-0.75904152, -0.6239387 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8334727439486421
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.39068193, -2.58471555]), 'currentState': array([4.88684213, 4.16872141]), 'targetState': array([-0.91235311, -0.60411008]), 'effectorPosition': array([-0.75904152, -0.6239387 ])}
episode index:285
target Thresh 0.9820542103408332
current state at start:  [ 0.98701865 -1.8745672 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.98701865, -1.8745672 ]), 'currentState': array([1.36053098, 4.90861811]), 'targetState': array([1.33521414, 0.40714332]), 'effectorPosition': array([1.20862091, 0.9639398 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.8305585035851853
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.98701865, -1.8745672 ]), 'currentState': array([1.59992028, 0.79354366]), 'targetState': array([1.33521414, 0.40714332]), 'effectorPosition': array([-0.76208297,  1.67984429])}
episode index:286
target Thresh 0.9840880673851549
current state at start:  [0.92339015 2.23724714]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.92339015, 2.23724714]), 'currentState': array([0.45184034, 1.95007032]), 'targetState': array([-0.30637893,  0.37318992]), 'effectorPosition': array([0.16096214, 1.11067496])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.8276645715169443
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.92339015, 2.23724714]), 'currentState': array([5.6695537 , 0.38944093]), 'targetState': array([-0.30637893,  0.37318992]), 'effectorPosition': array([ 1.79253654, -0.79815768])}
episode index:287
target Thresh 0.9861178607803915
current state at start:  [ 2.20587869 -1.84438497]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.20587869, -1.84438497]), 'currentState': array([2.70587869, 4.93880034]), 'targetState': array([0.41234536, 0.7820042 ]), 'effectorPosition': array([-0.69879116,  1.40023382])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.8247907361991771
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.20587869, -1.84438497]), 'currentState': array([1.71177585, 6.1953477 ]), 'targetState': array([0.41234536, 0.7820042 ]), 'effectorPosition': array([-0.19362989,  1.98866714])}
episode index:288
target Thresh 0.9881435986457197
current state at start:  [-0.68774379  2.47037978]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.68774379,  2.47037978]), 'currentState': array([6.09544152, 1.97037978]), 'targetState': array([ 0.60171349, -0.08493342]), 'effectorPosition': array([0.77216905, 0.79100296])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.8219367890150969
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.68774379,  2.47037978]), 'currentState': array([1.91211872, 6.20230588]), 'targetState': array([ 0.60171349, -0.08493342]), 'effectorPosition': array([-0.5922421 ,  1.90858885])}
episode index:289
target Thresh 0.9901652890840928
current state at start:  [ 4.13384569 -2.43535475]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.13384569, -2.43535475]), 'currentState': array([4.54764956, 4.34783056]), 'targetState': array([-0.33595163,  0.40835523]), 'effectorPosition': array([-1.0271571 , -0.48153374])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.8191025242253896
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 4.13384569, -2.43535475]), 'currentState': array([5.89423817, 5.33762023]), 'targetState': array([-0.33595163,  0.40835523]), 'effectorPosition': array([ 1.15940044, -1.35142895])}
episode index:290
target Thresh 0.9921829401822764
current state at start:  [-3.45271727  2.86237533]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.45271727,  2.86237533]), 'currentState': array([3.33046804, 3.36237533]), 'targetState': array([-0.25052582, -0.19943096]), 'effectorPosition': array([-0.06495894,  0.21054131])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.8197241650356117
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.45271727,  2.86237533]), 'currentState': array([3.33046804, 3.36237533]), 'targetState': array([-0.25052582, -0.19943096]), 'effectorPosition': array([-0.06495894,  0.21054131])}
episode index:291
target Thresh 0.9941965600108766
current state at start:  [ 3.82696039 -2.82599157]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.82696039, -2.82599157]), 'currentState': array([4.32696039, 3.95719374]), 'targetState': array([-0.53899084, -0.00339062]), 'effectorPosition': array([-0.79298391, -0.01774356])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.820341548032065
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.82696039, -2.82599157]), 'currentState': array([4.32696039, 3.95719374]), 'targetState': array([-0.53899084, -0.00339062]), 'effectorPosition': array([-0.79298391, -0.01774356])}
episode index:292
target Thresh 0.9962061566243756
current state at start:  [-1.04589818  2.06363537]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.04589818,  2.06363537]), 'currentState': array([5.73728713, 1.60139992]), 'targetState': array([ 1.05156304, -0.36128416]), 'effectorPosition': array([1.34745252, 0.35096165])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.8175417475268361
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.04589818,  2.06363537]), 'currentState': array([2.07895814, 5.72525543]), 'targetState': array([ 1.05156304, -0.36128416]), 'effectorPosition': array([-0.43682463,  1.87240222])}
episode index:293
target Thresh 0.9982117380611633
current state at start:  [0.48942756 2.76063897]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.48942756, 2.76063897]), 'currentState': array([6.27261287, 2.26063897]), 'targetState': array([-0.04889181, -0.09138553]), 'effectorPosition': array([0.37171873, 0.76745916])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.8147609932835475
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.48942756, 2.76063897]), 'currentState': array([5.54370121, 0.3786698 ]), 'targetState': array([-0.04889181, -0.09138553]), 'effectorPosition': array([ 1.67442599, -1.02694305])}
episode index:294
target Thresh 1.000213312343567
current state at start:  [ 3.10253403 -2.59586964]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.10253403, -2.59586964]), 'currentState': array([3.60253403, 4.18731566]), 'targetState': array([-0.303445  ,  0.15581039]), 'effectorPosition': array([-0.83154619,  0.55315282])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.8119990916113998
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.10253403, -2.59586964]), 'currentState': array([5.1627102 , 0.83007642]), 'targetState': array([-0.303445  ,  0.15581039]), 'effectorPosition': array([ 1.39338455, -1.18664158])}
episode index:295
target Thresh 1.0022108874778872
current state at start:  [-4.43834464  2.91152983]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.43834464,  2.91152983]), 'currentState': array([1.43284955, 3.41152983]), 'targetState': array([-0.54530287, -0.33996531]), 'effectorPosition': array([ 0.26911718, -0.00080148])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.809255851437037
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-4.43834464,  2.91152983]), 'currentState': array([5.37772775, 0.29329309]), 'targetState': array([-0.54530287, -0.33996531]), 'effectorPosition': array([ 1.43573183, -1.36134791])}
episode index:296
target Thresh 1.0042044714544271
current state at start:  [ 0.10034096 -2.1005472 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.10034096, -2.1005472 ]), 'currentState': array([0.58898699, 4.62771159]), 'targetState': array([ 0.20982823, -0.71515001]), 'effectorPosition': array([ 1.31470696, -0.3199893 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.8065310842604814
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.10034096, -2.1005472 ]), 'currentState': array([2.10129808, 0.0834363 ]), 'targetState': array([ 0.20982823, -0.71515001]), 'effectorPosition': array([-1.08205701,  1.679939  ])}
episode index:297
target Thresh 1.0061940722475249
current state at start:  [1.90330864 1.64904736]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.90330864, 1.64904736]), 'currentState': array([1.40330864, 1.14904736]), 'targetState': array([-1.27135534,  0.12910182]), 'effectorPosition': array([-0.66465941,  1.54173326])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.8038246041119563
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.90330864, 1.64904736]), 'currentState': array([5.44666329, 5.80592528]), 'targetState': array([-1.27135534,  0.12910182]), 'effectorPosition': array([ 0.92424268, -1.70947044])}
episode index:298
target Thresh 1.0081796978155868
current state at start:  [-2.42512206  2.84336907]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.42512206,  2.84336907]), 'currentState': array([4.04021236, 2.34336907]), 'targetState': array([ 0.05998038, -0.00685558]), 'effectorPosition': array([ 0.37227395, -0.6822406 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.8011362275095751
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.42512206,  2.84336907]), 'currentState': array([5.82983698, 6.20892306]), 'targetState': array([ 0.05998038, -0.00685558]), 'effectorPosition': array([ 1.76299819, -0.94144837])}
episode index:299
target Thresh 1.0101613561011171
current state at start:  [ 2.7996506 -2.3968097]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.7996506, -2.3968097]), 'currentState': array([2.35288399, 4.38637561]), 'targetState': array([-0.46848402,  0.65817769]), 'effectorPosition': array([0.19302637, 1.14987083])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.7984657734178766
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.7996506, -2.3968097]), 'currentState': array([5.59567456, 5.78091934]), 'targetState': array([-0.46848402,  0.65817769]), 'effectorPosition': array([ 1.14469527, -1.56290135])}
episode index:300
target Thresh 1.0121390550307525
current state at start:  [-1.17045611  2.50065351]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.17045611,  2.50065351]), 'currentState': array([5.6127292, 2.080575 ]), 'targetState': array([0.47686768, 0.31957354]), 'effectorPosition': array([0.9435253, 0.3657757])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.7991353223433986
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.17045611,  2.50065351]), 'currentState': array([5.6127292, 2.080575 ]), 'targetState': array([0.47686768, 0.31957354]), 'effectorPosition': array([0.9435253, 0.3657757])}
episode index:301
target Thresh 1.0141128025152906
current state at start:  [-2.66701597  2.91445697]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.66701597,  2.91445697]), 'currentState': array([4.11616934, 2.58251936]), 'targetState': array([0.34323525, 0.27801437]), 'effectorPosition': array([ 0.35339486, -0.42381373])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.7964891788919304
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.66701597,  2.91445697]), 'currentState': array([5.87245197, 0.48114037]), 'targetState': array([0.34323525, 0.27801437]), 'effectorPosition': array([ 1.91435071, -0.3289329 ])}
episode index:302
target Thresh 1.0160826064497241
current state at start:  [ 2.56710914 -2.20360318]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.56710914, -2.20360318]), 'currentState': array([2.93671975, 4.52828715]), 'targetState': array([0.24506646, 0.45252926]), 'effectorPosition': array([-0.59984691,  1.12874109])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.7938605017338712
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.56710914, -2.20360318]), 'currentState': array([5.76848464, 0.0071921 ]), 'targetState': array([0.24506646, 0.45252926]), 'effectorPosition': array([ 1.74439817, -0.97827567])}
episode index:303
target Thresh 1.018048474713272
current state at start:  [1.71438975 2.12930444]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.71438975, 2.12930444]), 'currentState': array([1.22782449, 1.915093  ]), 'targetState': array([-1.35266593, -0.05876611]), 'effectorPosition': array([-0.66371179,  0.9404346 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.7912491185044835
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.71438975, 2.12930444]), 'currentState': array([0.23682738, 5.40580019]), 'targetState': array([-1.35266593, -0.05876611]), 'effectorPosition': array([ 1.77384978, -0.36302296])}
episode index:304
target Thresh 1.0200104151694092
current state at start:  [1.16979349 2.45411586]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.16979349, 2.45411586]), 'currentState': array([0.66979349, 2.0885213 ]), 'targetState': array([-0.44419797,  0.49173189]), 'effectorPosition': array([-0.14349393,  0.99478662])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.7886548590995508
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.16979349, 2.45411586]), 'currentState': array([0.17481238, 5.80476496]), 'targetState': array([-0.44419797,  0.49173189]), 'effectorPosition': array([ 1.93902323, -0.12504172])}
episode index:305
target Thresh 1.0219684356659005
current state at start:  [ 0.23082384 -1.73297999]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.23082384, -1.73297999]), 'currentState': array([0.59408706, 5.05020531]), 'targetState': array([ 1.21482828, -0.60700455]), 'effectorPosition': array([ 1.63141627, -0.03655464])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.7860775556384411
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.23082384, -1.73297999]), 'currentState': array([3.03637971, 0.0980976 ]), 'targetState': array([ 1.21482828, -0.60700455]), 'effectorPosition': array([-1.99444491,  0.11213422])}
episode index:306
target Thresh 1.0239225440348303
current state at start:  [ 0.94128031 -2.00350431]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.94128031, -2.00350431]), 'currentState': array([1.44128031, 4.5828062 ]), 'targetState': array([1.01460804, 0.23112128]), 'effectorPosition': array([1.0957755 , 0.73541498])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.7835170424278923
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.94128031, -2.00350431]), 'currentState': array([3.77322984, 0.76719089]), 'targetState': array([1.01460804, 0.23112128]), 'effectorPosition': array([-0.97818379, -1.57571672])}
episode index:307
target Thresh 1.0258727480926348
current state at start:  [1.846436   1.82904271]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.846436  , 1.82904271]), 'currentState': array([1.39763722, 1.51022059]), 'targetState': array([-1.22200246,  0.69149931]), 'effectorPosition': array([-0.80051308,  1.21665779])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.7809731559265031
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.846436  , 1.82904271]), 'currentState': array([4.22579294, 0.17110742]), 'targetState': array([-1.22200246,  0.69149931]), 'effectorPosition': array([-0.77790075, -1.83457462])}
episode index:308
target Thresh 1.027819055640133
current state at start:  [-3.25524352  2.59381303]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.25524352,  2.59381303]), 'currentState': array([3.52794179, 2.71941505]), 'targetState': array([-0.02057157, -0.04561387]), 'effectorPosition': array([ 0.07306732, -0.41262997])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.781681980664605
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.25524352,  2.59381303]), 'currentState': array([3.52794179, 2.71941505]), 'targetState': array([-0.02057157, -0.04561387]), 'effectorPosition': array([ 0.07306732, -0.41262997])}
episode index:309
target Thresh 1.0297614744625574
current state at start:  [-1.48253733  1.64285904]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.48253733,  1.64285904]), 'currentState': array([4.5743268 , 1.24244127]), 'targetState': array([ 1.04030121, -0.80056523]), 'effectorPosition': array([ 0.75556116, -1.44017365])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.7791604258882676
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.48253733,  1.64285904]), 'currentState': array([4.03349038, 6.20829816]), 'targetState': array([ 1.04030121, -0.80056523]), 'effectorPosition': array([-1.31234008, -1.50736792])}
episode index:310
target Thresh 1.031700012329586
current state at start:  [ 4.21536279 -2.8633415 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.21536279, -2.8633415 ]), 'currentState': array([4.71536279, 3.68279738]), 'targetState': array([-0.27965574,  0.30983497]), 'effectorPosition': array([-0.51474166, -0.14444271])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.7798705209818745
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.21536279, -2.8633415 ]), 'currentState': array([4.71536279, 3.68279738]), 'targetState': array([-0.27965574,  0.30983497]), 'effectorPosition': array([-0.51474166, -0.14444271])}
episode index:311
target Thresh 1.0336346769953728
current state at start:  [-0.56045842  2.56001256]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.56045842,  2.56001256]), 'currentState': array([5.41398162, 2.1668245 ]), 'targetState': array([-0.00712695,  0.39870958]), 'effectorPosition': array([0.91522554, 0.19910382])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.7773709359787274
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.56045842,  2.56001256]), 'currentState': array([4.03830118, 1.16715434]), 'targetState': array([-0.00712695,  0.39870958]), 'effectorPosition': array([-0.15085551, -1.66216218])}
episode index:312
target Thresh 1.035565476198579
current state at start:  [0.348857   2.64283654]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.348857  , 2.64283654]), 'currentState': array([0.11353338, 2.14283654]), 'targetState': array([-0.07294845,  0.09134204]), 'effectorPosition': array([0.3604449 , 0.88734566])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.7748873227647378
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.348857  , 2.64283654]), 'currentState': array([3.64408489, 0.87882598]), 'targetState': array([-0.07294845,  0.09134204]), 'effectorPosition': array([-1.06473136, -1.46371386])}
episode index:313
target Thresh 1.0374924176624045
current state at start:  [-0.57339359 -2.75862296]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.57339359, -2.75862296]), 'currentState': array([6.18171593, 4.02456235]), 'targetState': array([-0.13127905, -0.01977595]), 'effectorPosition': array([ 0.28499881, -0.80564057])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.772419528743194
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.57339359, -2.75862296]), 'currentState': array([4.238273  , 1.81014802]), 'targetState': array([-0.13127905, -0.01977595]), 'effectorPosition': array([ 0.51601708, -1.12231042])}
episode index:314
target Thresh 1.0394155090946167
current state at start:  [-1.48949002  1.91556534]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.48949002,  1.91556534]), 'currentState': array([4.31579585, 1.57714662]), 'targetState': array([ 0.5664343 , -0.25327888]), 'effectorPosition': array([ 0.53853856, -1.30279535])}
done in step count: 40
reward sum = 0.6689717585696803
running average episode reward sum: 0.7720911231235955
{'reset': False, 'endBeforeDone': False, 'stepCount': 41, 'initial state': array([-1.48949002,  1.91556534]), 'currentState': array([3.68394717, 2.51968235]), 'targetState': array([ 0.5664343 , -0.25327888]), 'effectorPosition': array([ 0.14034134, -0.59562595])}
episode index:315
target Thresh 1.0413347581875851
current state at start:  [-4.13246657  2.0542578 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.13246657,  2.0542578 ]), 'currentState': array([2.46633213, 1.65126457]), 'targetState': array([-0.72208883, -0.15652752]), 'effectorPosition': array([-1.34088085, -0.20316422])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.7696477967845967
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-4.13246657,  2.0542578 ]), 'currentState': array([4.54173509, 1.45401071]), 'targetState': array([-0.72208883, -0.15652752]), 'effectorPosition': array([ 0.78914613, -1.26897165])}
episode index:316
target Thresh 1.0432501726183077
current state at start:  [-0.05975804  2.03706833]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.05975804,  2.03706833]), 'currentState': array([5.72342727, 1.64802237]), 'targetState': array([0.35260519, 1.1072327 ]), 'effectorPosition': array([1.31140717, 0.35484168])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.7672198857537305
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.05975804,  2.03706833]), 'currentState': array([4.24840751, 0.64804763]), 'targetState': array([0.35260519, 1.1072327 ]), 'effectorPosition': array([-0.26448363, -1.87738543])}
episode index:317
target Thresh 1.0451617600484453
current state at start:  [-3.49149524  2.34872205]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.49149524,  2.34872205]), 'currentState': array([3.24841721, 2.22656658]), 'targetState': array([-1.0030546, -0.0928526]), 'effectorPosition': array([-0.30349974, -0.82966745])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.7648072446035614
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.49149524,  2.34872205]), 'currentState': array([4.74623749, 0.48371866]), 'targetState': array([-1.0030546, -0.0928526]), 'effectorPosition': array([ 0.52860946, -1.86845263])}
episode index:318
target Thresh 1.0470695281243498
current state at start:  [ 0.0110553  -2.33506843]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.0110553 , -2.33506843]), 'currentState': array([0.5110553 , 4.44811688]), 'targetState': array([ 0.71537405, -0.58535265]), 'effectorPosition': array([ 1.11651473, -0.48060528])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.7655445259684405
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.0110553 , -2.33506843]), 'currentState': array([0.5110553 , 4.44811688]), 'targetState': array([ 0.71537405, -0.58535265]), 'effectorPosition': array([ 1.11651473, -0.48060528])}
episode index:319
target Thresh 1.0489734844770964
current state at start:  [-0.26517405  1.97534198]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.26517405,  1.97534198]), 'currentState': array([5.51801126, 1.68288464]), 'targetState': array([0.38365746, 0.54594112]), 'effectorPosition': array([1.32890184, 0.10155003])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.7631521993247892
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.26517405,  1.97534198]), 'currentState': array([4.95252646, 0.60416841]), 'targetState': array([0.38365746, 0.54594112]), 'effectorPosition': array([ 0.98534639, -1.63555559])}
episode index:320
target Thresh 1.0508736367225127
current state at start:  [ 1.83232834 -2.74520627]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.83232834, -2.74520627]), 'currentState': array([2.33232834, 3.96593783]), 'targetState': array([ 0.09946968, -0.17477625]), 'effectorPosition': array([0.3098552 , 0.73886001])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.760774778143092
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.83232834, -2.74520627]), 'currentState': array([2.56070052, 4.96259127]), 'targetState': array([ 0.09946968, -0.17477625]), 'effectorPosition': array([-0.51127784,  1.49458853])}
episode index:321
target Thresh 1.0527699924612102
current state at start:  [0.7359201  1.97080171]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.7359201 , 1.97080171]), 'currentState': array([0.31529177, 1.47080171]), 'targetState': array([-0.51044941,  1.10029799]), 'effectorPosition': array([0.73706822, 1.28700682])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.7584121235525856
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.7359201 , 1.97080171]), 'currentState': array([5.10574742, 1.00792572]), 'targetState': array([-0.51044941,  1.10029799]), 'effectorPosition': array([ 1.3689597 , -1.09232854])}
episode index:322
target Thresh 1.054662559278615
current state at start:  [-0.72510256  2.68573266]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.72510256,  2.68573266]), 'currentState': array([6.01497649, 2.28968805]), 'targetState': array([ 0.70921532, -0.00152158]), 'effectorPosition': array([0.52866676, 0.63514513])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.756064098402268
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.72510256,  2.68573266]), 'currentState': array([4.65921368, 0.96542009]), 'targetState': array([ 0.70921532, -0.00152158]), 'effectorPosition': array([ 0.73772924, -1.61055846])}
episode index:323
target Thresh 1.0565513447449963
current state at start:  [-1.31287663  2.93663943]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.31287663,  2.93663943]), 'currentState': array([4.80622611, 3.34921217]), 'targetState': array([ 0.64274557, -0.09997293]), 'effectorPosition': array([-0.203212  , -0.04069552])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.7537305672343597
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.31287663,  2.93663943]), 'currentState': array([4.4210802 , 0.57549013]), 'targetState': array([ 0.64274557, -0.09997293]), 'effectorPosition': array([-0.00683438, -1.91776031])}
episode index:324
target Thresh 1.0584363564154986
current state at start:  [ 0.01464236 -1.95629456]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.01464236, -1.95629456]), 'currentState': array([0.51464236, 4.82689075]), 'targetState': array([ 0.22687408, -1.1887827 ]), 'effectorPosition': array([ 1.45892179, -0.31630788])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.751411396258254
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.01464236, -1.95629456]), 'currentState': array([3.70876623, 0.13246842]), 'targetState': array([ 0.22687408, -1.1887827 ]), 'effectorPosition': array([-1.60849562, -1.18119415])}
episode index:325
target Thresh 1.060317601830171
current state at start:  [1.06620735 2.0225057 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.06620735, 2.0225057 ]), 'currentState': array([0.5921798 , 1.61617884]), 'targetState': array([-0.95381759,  0.66796778]), 'effectorPosition': array([0.23448754, 1.36172014])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.7491064533249465
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.06620735, 2.0225057 ]), 'currentState': array([4.52639465, 0.94928865]), 'targetState': array([-0.95381759,  0.66796778]), 'effectorPosition': array([ 0.50638173, -1.70531542])}
episode index:326
target Thresh 1.062195088513998
current state at start:  [ 0.47034216 -1.85108048]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.47034216, -1.85108048]), 'currentState': array([0.8948842 , 4.93210483]), 'targetState': array([ 1.01539845, -0.37674208]), 'effectorPosition': array([1.52334383, 0.33960007])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.7468156079019345
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.47034216, -1.85108048]), 'currentState': array([3.30078713, 4.83653749]), 'targetState': array([ 1.01539845, -0.37674208]), 'effectorPosition': array([-1.26692219,  0.8016033 ])}
episode index:327
target Thresh 1.0640688239769287
current state at start:  [-1.57475953 -2.42293602]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.57475953, -2.42293602]), 'currentState': array([5.18992298, 4.28500367]), 'targetState': array([-0.34646014, -0.16180195]), 'effectorPosition': array([-0.53915237, -0.93825865])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.7445387310485749
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.57475953, -2.42293602]), 'currentState': array([3.96971158, 1.48325911]), 'targetState': array([-0.34646014, -0.16180195]), 'effectorPosition': array([-0.0015453 , -1.47473677])}
episode index:328
target Thresh 1.0659388157139071
current state at start:  [-2.46911073  2.24439594]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.46911073,  2.24439594]), 'currentState': array([3.31407457, 1.74534899]), 'targetState': array([ 0.58331895, -0.64871655]), 'effectorPosition': array([-0.64505116, -1.11201338])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.7422756953918923
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.46911073,  2.24439594]), 'currentState': array([3.06415619, 5.53787012]), 'targetState': array([ 0.58331895, -0.64871655]), 'effectorPosition': array([-1.67721006,  0.81037939])}
episode index:329
target Thresh 1.0678050712049034
current state at start:  [ 0.86652014 -2.42057285]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.86652014, -2.42057285]), 'currentState': array([1.0985258 , 4.31681166]), 'targetState': array([1.1225319 , 0.20753311]), 'effectorPosition': array([1.10137945, 0.12759829])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.743056678133129
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.86652014, -2.42057285]), 'currentState': array([1.0985258 , 4.31681166]), 'targetState': array([1.1225319 , 0.20753311]), 'effectorPosition': array([1.10137945, 0.12759829])}
episode index:330
target Thresh 1.0696675979149415
current state at start:  [-0.14699799 -3.09649905]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.14699799, -3.09649905]), 'currentState': array([0.02736231, 3.37002373]), 'targetState': array([0.01872548, 0.00473373]), 'effectorPosition': array([ 0.03216281, -0.22565417])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.7438329419454156
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.14699799, -3.09649905]), 'currentState': array([0.02736231, 3.37002373]), 'targetState': array([0.01872548, 0.00473373]), 'effectorPosition': array([ 0.03216281, -0.22565417])}
episode index:331
target Thresh 1.0715264032941305
current state at start:  [-0.51734698 -2.16417481]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.51734698, -2.16417481]), 'currentState': array([6.24843595, 4.61901049]), 'targetState': array([-0.52653097, -0.4650181 ]), 'effectorPosition': array([ 0.87161874, -1.02654521])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.7415924812769054
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.51734698, -2.16417481]), 'currentState': array([4.21148329, 1.11361955]), 'targetState': array([-0.52653097, -0.4650181 ]), 'effectorPosition': array([ 0.0948696 , -1.69523831])}
episode index:332
target Thresh 1.0733814947776947
current state at start:  [-0.89274354  1.96272453]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.89274354,  1.96272453]), 'currentState': array([4.89044176, 1.46272453]), 'targetState': array([0.61437891, 0.15871265]), 'effectorPosition': array([ 1.17466581, -0.91426656])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.7393654768286264
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.89274354,  1.96272453]), 'currentState': array([3.61069403, 5.78979923]), 'targetState': array([0.61437891, 0.15871265]), 'effectorPosition': array([-1.89168004, -0.4278026 ])}
episode index:333
target Thresh 1.075232879786003
current state at start:  [-3.53494891  2.37606024]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.53494891,  2.37606024]), 'currentState': array([3.2482364 , 2.75805228]), 'targetState': array([-0.85293117, -0.87203002]), 'effectorPosition': array([-0.0324105 , -0.37981353])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.7371518077363252
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.53494891,  2.37606024]), 'currentState': array([4.34332779, 0.80731257]), 'targetState': array([-0.85293117, -0.87203002]), 'effectorPosition': array([ 0.06361676, -1.83816151])}
episode index:334
target Thresh 1.077080565724597
current state at start:  [ 1.41772222 -1.96557123]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.41772222, -1.96557123]), 'currentState': array([1.20774428, 4.68367729]), 'targetState': array([0.56234352, 0.71140944]), 'effectorPosition': array([1.27936606, 0.55299819])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.7349513545789033
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.41772222, -1.96557123]), 'currentState': array([3.73569078, 0.54094675]), 'targetState': array([0.56234352, 0.71140944]), 'effectorPosition': array([-1.25074542, -1.46631476])}
episode index:335
target Thresh 1.0789245599842237
current state at start:  [-0.875081   2.6225733]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.875081 ,  2.6225733]), 'currentState': array([5.4471779 , 2.14395909]), 'targetState': array([0.06937058, 0.10998844]), 'effectorPosition': array([0.9302591 , 0.22368248])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.7327639993569423
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.875081 ,  2.6225733]), 'currentState': array([4.38569582, 0.20994557]), 'targetState': array([0.06937058, 0.10998844]), 'effectorPosition': array([-0.43739542, -1.94030146])}
episode index:336
target Thresh 1.0807648699408618
current state at start:  [-2.07888813  2.05557127]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.07888813,  2.05557127]), 'currentState': array([3.79499107, 1.57486121]), 'targetState': array([ 0.67608937, -0.50654931]), 'effectorPosition': array([-0.18291162, -1.39943331])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.7305896254716101
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.07888813,  2.05557127]), 'currentState': array([3.00078355, 5.8694355 ]), 'targetState': array([ 0.67608937, -0.50654931]), 'effectorPosition': array([-1.84023556,  0.66691262])}
episode index:337
target Thresh 1.0826015029557543
current state at start:  [ 4.08118039 -2.1550423 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.08118039, -2.1550423 ]), 'currentState': array([4.58118039, 4.57940605]), 'targetState': array([-1.02045125, -0.38694637]), 'effectorPosition': array([-1.09613637, -0.73027556])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.7313866975855994
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.08118039, -2.1550423 ]), 'currentState': array([4.58118039, 4.57940605]), 'targetState': array([-1.02045125, -0.38694637]), 'effectorPosition': array([-1.09613637, -0.73027556])}
episode index:338
target Thresh 1.0844344663754355
current state at start:  [-2.59550423  2.60539211]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.59550423,  2.60539211]), 'currentState': array([4.18451052, 2.10539211]), 'targetState': array([-0.223351  , -0.58573742]), 'effectorPosition': array([ 0.49627572, -0.85716036])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.729229214701866
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.59550423,  2.60539211]), 'currentState': array([3.67639019, 1.33060483]), 'targetState': array([-0.223351  , -0.58573742]), 'effectorPosition': array([-0.57000894, -1.46658347])}
episode index:339
target Thresh 1.086263767531761
current state at start:  [0.71963285 1.95186168]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.71963285, 1.95186168]), 'currentState': array([0.21963285, 1.45186168]), 'targetState': array([-0.00658713,  0.88476898]), 'effectorPosition': array([0.87544939, 1.21280553])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.7270844228939194
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.71963285, 1.95186168]), 'currentState': array([3.70718948, 1.80800346]), 'targetState': array([-0.00658713,  0.88476898]), 'effectorPosition': array([-0.12496209, -1.23061233])}
episode index:340
target Thresh 1.0880894137419388
current state at start:  [-0.72090237 -1.68574758]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.72090237, -1.68574758]), 'currentState': array([5.99008768, 5.04194377]), 'targetState': array([-0.4598987 , -0.85528929]), 'effectorPosition': array([ 0.99380259, -1.28825464])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.7249522105100663
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.72090237, -1.68574758]), 'currentState': array([4.80790888, 1.11300567]), 'targetState': array([-0.4598987 , -0.85528929]), 'effectorPosition': array([ 1.0304692 , -1.34983996])}
episode index:341
target Thresh 1.0899114123085554
current state at start:  [-2.48054934  2.23197023]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.48054934,  2.23197023]), 'currentState': array([3.85083819, 2.60589344]), 'targetState': array([ 0.36042494, -1.219035  ]), 'effectorPosition': array([ 0.22612515, -0.47858495])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.7228324672044814
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.48054934,  2.23197023]), 'currentState': array([3.50459813, 5.98270046]), 'targetState': array([ 0.36042494, -1.219035  ]), 'effectorPosition': array([-1.93288007, -0.41756537])}
episode index:342
target Thresh 1.0917297705196078
current state at start:  [-3.29735154  2.05650428]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.29735154,  2.05650428]), 'currentState': array([3.48583377, 2.32687596]), 'targetState': array([-0.35739198, -1.03565781]), 'effectorPosition': array([-0.04997903, -0.79079266])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.7236405358132146
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.29735154,  2.05650428]), 'currentState': array([3.48583377, 2.32687596]), 'targetState': array([-0.35739198, -1.03565781]), 'effectorPosition': array([-0.04997903, -0.79079266])}
episode index:343
target Thresh 1.0935444956485316
current state at start:  [-0.19230204 -2.15515318]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.19230204, -2.15515318]), 'currentState': array([0.30769796, 4.62043087]), 'targetState': array([-0.15372899, -1.01631873]), 'effectorPosition': array([ 1.16710349, -0.67395276])}
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.7240878628108477
{'reset': False, 'endBeforeDone': False, 'stepCount': 14, 'initial state': array([-0.19230204, -2.15515318]), 'currentState': array([4.19820291, 1.43937157]), 'targetState': array([-0.15372899, -1.01631873]), 'effectorPosition': array([ 0.30690605, -1.47237977])}
episode index:344
target Thresh 1.0953555949542289
current state at start:  [1.34232316 3.0185287 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.34232316, 3.0185287 ]), 'currentState': array([0.84232316, 3.4946478 ]), 'targetState': array([-0.6605069,  0.4038603]), 'effectorPosition': array([ 0.29906963, -0.1841627 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.721989057411396
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.34232316, 3.0185287 ]), 'currentState': array([4.34522491, 1.58322811]), 'targetState': array([-0.6605069,  0.4038603]), 'effectorPosition': array([ 0.57876955, -1.28068844])}
episode index:345
target Thresh 1.0971630756811
current state at start:  [-4.60067247  3.00518352]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.60067247,  3.00518352]), 'currentState': array([1.43189211, 3.34656867]), 'targetState': array([ 0.00347428, -0.32931467]), 'effectorPosition': array([ 0.20448171, -0.00744974])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.7227925572454671
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.60067247,  3.00518352]), 'currentState': array([1.43189211, 3.34656867]), 'targetState': array([ 0.00347428, -0.32931467]), 'effectorPosition': array([ 0.20448171, -0.00744974])}
episode index:346
target Thresh 1.09896694505907
current state at start:  [ 3.95558234 -2.4789451 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.95558234, -2.4789451 ]), 'currentState': array([4.4360665 , 3.80945213]), 'targetState': array([-0.95296236,  0.74664104]), 'effectorPosition': array([-0.65442903, -0.03774162])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.7207095815761718
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.95558234, -2.4789451 ]), 'currentState': array([4.09482332, 2.13335469]), 'targetState': array([-0.95296236,  0.74664104]), 'effectorPosition': array([ 0.4194353 , -0.87027004])}
episode index:347
target Thresh 1.100767210303619
current state at start:  [0.27127352 2.72070773]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.27127352, 2.72070773]), 'currentState': array([6.06168833, 2.22070773]), 'targetState': array([-0.07534044, -0.00364356]), 'effectorPosition': array([0.56014062, 0.68993531])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.7186385770314128
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.27127352, 2.72070773]), 'currentState': array([3.64833938, 1.7335345 ]), 'targetState': array([-0.07534044, -0.00364356]), 'effectorPosition': array([-0.2537459 , -1.26947682])}
episode index:348
target Thresh 1.1025638786158103
current state at start:  [ 2.44840229 -2.25772921]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.44840229, -2.25772921]), 'currentState': array([1.94840229, 4.5254561 ]), 'targetState': array([-0.16547702,  0.57095155]), 'effectorPosition': array([0.61318074, 1.11906979])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.7165794407075405
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.44840229, -2.25772921]), 'currentState': array([1.21702979, 5.78117232]), 'targetState': array([-0.16547702,  0.57095155]), 'effectorPosition': array([1.10151578, 1.59370462])}
episode index:349
target Thresh 1.1043569571823193
current state at start:  [ 0.60012543 -2.89068462]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.60012543, -2.89068462]), 'currentState': array([0.8396822, 3.8273762]), 'targetState': array([0.39115491, 0.02258735]), 'effectorPosition': array([ 0.62238439, -0.25454178])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.7173892137340905
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.60012543, -2.89068462]), 'currentState': array([0.8396822, 3.8273762]), 'targetState': array([0.39115491, 0.02258735]), 'effectorPosition': array([ 0.62238439, -0.25454178])}
episode index:350
target Thresh 1.1061464531754628
current state at start:  [0.31116686 2.21545362]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.31116686, 2.21545362]), 'currentState': array([6.09435217, 1.71545362]), 'targetState': array([0.0364073 , 0.46075293]), 'effectorPosition': array([1.02638541, 0.8113115 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.7153453698203182
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.31116686, 2.21545362]), 'currentState': array([3.68628312, 1.78681665]), 'targetState': array([0.0364073 , 0.46075293]), 'effectorPosition': array([-0.16585124, -1.24249952])}
episode index:351
target Thresh 1.1079323737532274
current state at start:  [ 3.50958954 -2.54619303]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.50958954, -2.54619303]), 'currentState': array([4.00958954, 4.23699227]), 'targetState': array([0.03099708, 0.00921645]), 'effectorPosition': array([-1.02894835,  0.16088163])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.713313138656056
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.50958954, -2.54619303]), 'currentState': array([4.24330191, 0.82260958]), 'targetState': array([0.03099708, 0.00921645]), 'effectorPosition': array([-0.10586753, -1.8301404 ])}
episode index:352
target Thresh 1.1097147260592974
current state at start:  [-3.16764268  2.70912581]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.16764268,  2.70912581]), 'currentState': array([3.56549976, 2.76364616]), 'targetState': array([ 0.03397303, -0.03532641]), 'effectorPosition': array([ 0.08745518, -0.36538043])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.7141252827391832
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.16764268,  2.70912581]), 'currentState': array([3.56549976, 2.76364616]), 'targetState': array([ 0.03397303, -0.03532641]), 'effectorPosition': array([ 0.08745518, -0.36538043])}
episode index:353
target Thresh 1.1114935172230846
current state at start:  [1.41954071 1.67057135]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.41954071, 1.67057135]), 'currentState': array([0.91954071, 1.17057135]), 'targetState': array([-0.61855495,  1.23149678]), 'effectorPosition': array([0.10989931, 1.66348226])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.7121079796805979
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.41954071, 1.67057135]), 'currentState': array([3.69081259, 1.88899767]), 'targetState': array([-0.61855495,  1.23149678]), 'effectorPosition': array([-0.09026842, -1.16881744])}
episode index:354
target Thresh 1.1132687543597561
current state at start:  [-3.55220775  2.5360834 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.55220775,  2.5360834 ]), 'currentState': array([3.23097756, 2.88743854]), 'targetState': array([-0.41827334, -0.4394647 ]), 'effectorPosition': array([-0.00955159, -0.2532906 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.7129189431181173
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.55220775,  2.5360834 ]), 'currentState': array([3.23097756, 2.88743854]), 'targetState': array([-0.41827334, -0.4394647 ]), 'effectorPosition': array([-0.00955159, -0.2532906 ])}
episode index:355
target Thresh 1.1150404445702629
current state at start:  [ 0.0758786  -2.11259767]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.0758786 , -2.11259767]), 'currentState': array([0.5758786 , 4.62415678]), 'targetState': array([ 0.90215685, -0.7335602 ]), 'effectorPosition': array([ 1.30726209, -0.33886619])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.7137253505812687
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.0758786 , -2.11259767]), 'currentState': array([0.5758786 , 4.62415678]), 'targetState': array([ 0.90215685, -0.7335602 ]), 'effectorPosition': array([ 1.30726209, -0.33886619])}
episode index:356
target Thresh 1.1168085949413677
current state at start:  [1.90855205 2.15325459]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.90855205, 2.15325459]), 'currentState': array([1.42306325, 1.65325459]), 'targetState': array([-0.42414002,  0.06141654]), 'effectorPosition': array([-0.85067408,  1.05433577])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.7117261199073717
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.90855205, 2.15325459]), 'currentState': array([1.99003411, 6.23331994]), 'targetState': array([-0.42414002,  0.06141654]), 'effectorPosition': array([-0.7680946 ,  1.84595359])}
episode index:357
target Thresh 1.1185732125456749
current state at start:  [-0.14903426 -2.22315974]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.14903426, -2.22315974]), 'currentState': array([0.29008055, 4.56002557]), 'targetState': array([-0.1730302 , -0.38778705]), 'effectorPosition': array([ 1.09550306, -0.70450257])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.7097380581199209
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.14903426, -2.22315974]), 'currentState': array([3.94577312, 1.67509616]), 'targetState': array([-0.1730302 , -0.38778705]), 'effectorPosition': array([ 0.09486838, -1.33520722])}
episode index:358
target Thresh 1.120334304441657
current state at start:  [-4.32541965  2.38046508]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.32541965,  2.38046508]), 'currentState': array([1.46936246, 2.42155434]), 'targetState': array([-1.14193444, -0.02486361]), 'effectorPosition': array([-0.63088937,  0.31371591])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.7077610718856034
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-4.32541965,  2.38046508]), 'currentState': array([1.51404114, 5.87627676]), 'targetState': array([-1.14193444, -0.02486361]), 'effectorPosition': array([0.50395274, 1.89280984])}
episode index:359
target Thresh 1.122091877673684
current state at start:  [-4.05298632  2.23910421]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.05298632,  2.23910421]), 'currentState': array([2.40372435, 1.80465907]), 'targetState': array([-0.61974257,  0.15883632]), 'effectorPosition': array([-1.22284115, -0.20294296])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.7057950689081434
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-4.05298632,  2.23910421]), 'currentState': array([3.99941951, 1.40303964]), 'targetState': array([-0.61974257,  0.15883632]), 'effectorPosition': array([-0.01749153, -1.52762428])}
episode index:360
target Thresh 1.123845939272051
current state at start:  [ 0.82931382 -2.58292783]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.82931382, -2.58292783]), 'currentState': array([0.76448127, 4.20025748]), 'targetState': array([0.03877952, 0.08203683]), 'effectorPosition': array([ 0.97142149, -0.2761657 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.703839957913938
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.82931382, -2.58292783]), 'currentState': array([1.87718662, 0.28488071]), 'targetState': array([0.03877952, 0.08203683]), 'effectorPosition': array([-0.85903571,  1.78366141])}
episode index:361
target Thresh 1.125596496253007
current state at start:  [-0.61379022  2.14380048]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.61379022,  2.14380048]), 'currentState': array([6.08795386, 1.65262558]), 'targetState': array([0.93363159, 0.22154084]), 'effectorPosition': array([1.09416209, 0.79958327])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.7018956486379326
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.61379022,  2.14380048]), 'currentState': array([3.15432444, 0.31008312]), 'targetState': array([0.93363159, 0.22154084]), 'effectorPosition': array([-1.94826514, -0.32996876])}
episode index:362
target Thresh 1.1273435556187823
current state at start:  [-1.92908845  2.17818324]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.92908845,  2.17818324]), 'currentState': array([4.54415629, 1.67818324]), 'targetState': array([ 0.4865663 , -0.95242004]), 'effectorPosition': array([ 0.83070922, -1.04669046])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.7027168727463681
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.92908845,  2.17818324]), 'currentState': array([4.54415629, 1.67818324]), 'targetState': array([ 0.4865663 , -0.95242004]), 'effectorPosition': array([ 0.83070922, -1.04669046])}
episode index:363
target Thresh 1.1290871243576162
current state at start:  [-1.51344025 -2.25295176]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.51344025, -2.25295176]), 'currentState': array([5.26580332, 4.47283016]), 'targetState': array([-0.87558626, -0.35282397]), 'effectorPosition': array([-0.42555535, -1.15946303])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.7007863318871748
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.51344025, -2.25295176]), 'currentState': array([4.3235771, 1.7006693]), 'targetState': array([-0.87558626, -0.35282397]), 'effectorPosition': array([ 0.58757297, -1.1814151 ])}
episode index:364
target Thresh 1.1308272094437863
current state at start:  [-3.59616804  2.35907183]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.59616804,  2.35907183]), 'currentState': array([3.18701727, 2.1770627 ]), 'targetState': array([-0.36371306, -0.18702599]), 'effectorPosition': array([-0.39243677, -0.84046829])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.6988663693340592
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.59616804,  2.35907183]), 'currentState': array([4.17217417, 1.14435219]), 'targetState': array([-0.36371306, -0.18702599]), 'effectorPosition': array([ 0.05373214, -1.68059064])}
episode index:365
target Thresh 1.1325638178376356
current state at start:  [1.41207714 2.35287189]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.41207714, 2.35287189]), 'currentState': array([0.91207714, 2.02334344]), 'targetState': array([-1.21791337,  0.58351206]), 'effectorPosition': array([-0.3667172 ,  0.99549142])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.6969568983795946
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.41207714, 2.35287189]), 'currentState': array([3.66233908, 1.93943877]), 'targetState': array([-1.21791337,  0.58351206]), 'effectorPosition': array([-0.0907611 , -1.12741456])}
episode index:366
target Thresh 1.1342969564855996
current state at start:  [-1.34626061  1.95529548]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.34626061,  1.95529548]), 'currentState': array([4.43692469, 1.522283  ]), 'targetState': array([ 1.20363414, -0.38026172]), 'effectorPosition': array([ 0.67598294, -1.28063877])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.695057833261394
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.34626061,  1.95529548]), 'currentState': array([3.40333424, 5.81558958]), 'targetState': array([ 1.20363414, -0.38026172]), 'effectorPosition': array([-1.94482754, -0.05435987])}
episode index:367
target Thresh 1.136026632320235
current state at start:  [-0.01568364 -2.00664872]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.01568364, -2.00664872]), 'currentState': array([0.48431636, 4.497835  ]), 'targetState': array([ 0.89611725, -0.96732613]), 'effectorPosition': array([ 1.15149587, -0.4982308 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6958864804536183
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.01568364, -2.00664872]), 'currentState': array([0.48431636, 4.497835  ]), 'targetState': array([ 0.89611725, -0.96732613]), 'effectorPosition': array([ 1.15149587, -0.4982308 ])}
episode index:368
target Thresh 1.137752852260248
current state at start:  [ 2.45562961 -2.46053997]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.45562961, -2.46053997]), 'currentState': array([2.17373609, 4.30090136]), 'targetState': array([0.0801866 , 0.14152483]), 'effectorPosition': array([0.41466263, 1.01395684])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.6940006092328769
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.45562961, -2.46053997]), 'currentState': array([4.24978558, 5.26351775]), 'targetState': array([0.0801866 , 0.14152483]), 'effectorPosition': array([-1.44236357, -0.98330348])}
episode index:369
target Thresh 1.1394756232105203
current state at start:  [-0.84906095 -2.19437552]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.84906095, -2.19437552]), 'currentState': array([5.93238032, 4.58880978]), 'targetState': array([-0.27766215, -0.69293257]), 'effectorPosition': array([ 0.48230567, -1.23322807])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.6921249319106259
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.84906095, -2.19437552]), 'currentState': array([4.3811618 , 1.35559303]), 'targetState': array([-0.27766215, -0.69293257]), 'effectorPosition': array([ 0.52918107, -1.46528478])}
episode index:370
target Thresh 1.141194952062138
current state at start:  [ 0.80838451 -2.06303354]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.80838451, -2.06303354]), 'currentState': array([1.30838451, 4.69896518]), 'targetState': array([0.76588366, 0.12559977]), 'effectorPosition': array([1.22160851, 0.69341607])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.6902593660564194
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.80838451, -2.06303354]), 'currentState': array([2.89388378, 6.05753964]), 'targetState': array([0.76588366, 0.12559977]), 'effectorPosition': array([-1.85952076,  0.70105794])}
episode index:371
target Thresh 1.1429108456924189
current state at start:  [-3.56620058  2.52397864]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.56620058,  2.52397864]), 'currentState': array([3.11904413, 3.02397864]), 'targetState': array([-0.35979626, -0.99346127]), 'effectorPosition': array([-0.00955249, -0.11715745])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.6884038301261601
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.56620058,  2.52397864]), 'currentState': array([4.30510413, 0.31540745]), 'targetState': array([-0.35979626, -0.99346127]), 'effectorPosition': array([-0.48786593, -1.91398197])}
episode index:372
target Thresh 1.14462331096494
current state at start:  [ 2.25023573 -2.86827386]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.25023573, -2.86827386]), 'currentState': array([1.79305628, 3.8614724 ]), 'targetState': array([-0.18528027, -0.18144069]), 'effectorPosition': array([0.58838367, 0.38734302])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.6865582434502187
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.25023573, -2.86827386]), 'currentState': array([1.41131765, 5.9744458 ]), 'targetState': array([-0.18528027, -0.18144069]), 'effectorPosition': array([0.61010047, 1.87968404])}
episode index:373
target Thresh 1.146332354729564
current state at start:  [-2.43948899  2.38134613]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.43948899,  2.38134613]), 'currentState': array([4.30997481, 1.94553613]), 'targetState': array([-0.21345199, -1.02034567]), 'effectorPosition': array([ 0.60797629, -0.94778902])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.6847225262217421
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.43948899,  2.38134613]), 'currentState': array([3.24423069, 5.80147153]), 'targetState': array([-0.21345199, -1.02034567]), 'effectorPosition': array([-1.9237444 ,  0.26760407])}
episode index:374
target Thresh 1.1480379838224692
current state at start:  [ 0.65385863 -2.11120581]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.65385863, -2.11120581]), 'currentState': array([1.12030196, 4.67197949]), 'targetState': array([ 0.9361069 , -0.01194356]), 'effectorPosition': array([1.31731775, 0.42880877])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6855632661518175
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.65385863, -2.11120581]), 'currentState': array([1.12030196, 4.67197949]), 'targetState': array([ 0.9361069 , -0.01194356]), 'effectorPosition': array([1.31731775, 0.42880877])}
episode index:375
target Thresh 1.1497402050661736
current state at start:  [-1.81098296  2.68796337]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.81098296,  2.68796337]), 'currentState': array([4.64956812, 2.40043021]), 'targetState': array([ 0.46636597, -0.20847158]), 'effectorPosition': array([ 0.65734604, -0.30418368])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6863995340609882
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.81098296,  2.68796337]), 'currentState': array([4.64956812, 2.40043021]), 'targetState': array([ 0.46636597, -0.20847158]), 'effectorPosition': array([ 0.65734604, -0.30418368])}
episode index:376
target Thresh 1.1514390252695645
current state at start:  [-1.22427817  1.81351481]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.22427817,  1.81351481]), 'currentState': array([4.55890713, 1.34698503]), 'targetState': array([ 1.10103107, -0.44271797]), 'effectorPosition': array([ 0.77678529, -1.35665012])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.6845788456417283
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.22427817,  1.81351481]), 'currentState': array([3.27579393, 0.17701892]), 'targetState': array([ 1.10103107, -0.44271797]), 'effectorPosition': array([-1.94296914, -0.44001926])}
episode index:377
target Thresh 1.153134451227925
current state at start:  [-1.99912092  3.01502439]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.99912092,  3.01502439]), 'currentState': array([4.57515866, 3.47976094]), 'targetState': array([ 0.58162707, -0.24340924]), 'effectorPosition': array([-0.33638851, -0.01071889])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.682767790494528
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.99912092,  3.01502439]), 'currentState': array([4.35948119, 5.41862297]), 'targetState': array([ 0.58162707, -0.24340924]), 'effectorPosition': array([-1.28385482, -1.28439211])}
episode index:378
target Thresh 1.1548264897229612
current state at start:  [ 1.37208397 -1.88352044]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.37208397, -1.88352044]), 'currentState': array([1.84173314, 4.89966487]), 'targetState': array([ 0.5635514, -0.0805319]), 'effectorPosition': array([0.62921035, 1.40586648])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.680966292366574
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.37208397, -1.88352044]), 'currentState': array([5.24370698, 4.98179615]), 'targetState': array([ 0.5635514, -0.0805319]), 'effectorPosition': array([-0.18951624, -1.58000116])}
episode index:379
target Thresh 1.1565151475228297
current state at start:  [ 3.20064274 -2.52202844]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.20064274, -2.52202844]), 'currentState': array([2.91000731, 4.26115687]), 'targetState': array([-0.12165411,  0.04338867]), 'effectorPosition': array([-0.34232245,  1.00531887])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.6791742758077146
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.20064274, -2.52202844]), 'currentState': array([4.10849372, 0.38238355]), 'targetState': array([-0.12165411,  0.04338867]), 'effectorPosition': array([-0.78755773, -1.79869636])}
episode index:380
target Thresh 1.1582004313821632
current state at start:  [ 1.46480974 -2.46704694]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.46480974, -2.46704694]), 'currentState': array([1.93958448, 4.20080284]), 'targetState': array([ 0.6947102 , -0.09785227]), 'effectorPosition': array([0.62933635, 0.79045171])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.6773916661599254
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.46480974, -2.46704694]), 'currentState': array([5.00086594, 5.46159256]), 'targetState': array([ 0.6947102 , -0.09785227]), 'effectorPosition': array([-0.22372676, -1.81990603])}
episode index:381
target Thresh 1.1598823480421
current state at start:  [ 2.36392676 -2.82231536]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.36392676, -2.82231536]), 'currentState': array([2.2847356 , 3.96086994]), 'targetState': array([ 0.1580163 , -0.23409141]), 'effectorPosition': array([0.34447786, 0.71821733])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.6756183895469413
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.36392676, -2.82231536]), 'currentState': array([4.03107271, 0.0103649 ]), 'targetState': array([ 0.1580163 , -0.23409141]), 'effectorPosition': array([-1.25154738, -1.55997491])}
episode index:382
target Thresh 1.161560904230309
current state at start:  [ 2.5170076  -2.24467822]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.5170076 , -2.24467822]), 'currentState': array([2.0170076 , 4.53850709]), 'targetState': array([0.11797129, 0.44588154]), 'effectorPosition': array([0.53159609, 1.17106431])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.6738543728640511
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.5170076 , -2.24467822]), 'currentState': array([1.74940794, 5.53833284]), 'targetState': array([0.11797129, 0.44588154]), 'effectorPosition': array([0.35879998, 1.82801488])}
episode index:383
target Thresh 1.163236106661017
current state at start:  [0.04123465 1.6338566 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.04123465, 1.6338566 ]), 'currentState': array([0.45328394, 1.1338566 ]), 'targetState': array([1.06369913, 0.62014349]), 'effectorPosition': array([0.88267036, 1.43778664])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.6720995437680509
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.04123465, 1.6338566 ]), 'currentState': array([4.92228116, 5.50028079]), 'targetState': array([1.06369913, 0.62014349]), 'effectorPosition': array([-0.33381123, -1.81832499])}
episode index:384
target Thresh 1.164907962035036
current state at start:  [-0.7966622  -2.32693535]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.7966622 , -2.32693535]), 'currentState': array([5.9865231 , 4.45624995]), 'targetState': array([ 0.04140588, -1.03478164]), 'effectorPosition': array([ 0.43124426, -1.14338686])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6729512332647574
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.7966622 , -2.32693535]), 'currentState': array([5.9865231 , 4.45624995]), 'targetState': array([ 0.04140588, -1.03478164]), 'effectorPosition': array([ 0.43124426, -1.14338686])}
episode index:385
target Thresh 1.1665764770397895
current state at start:  [ 0.93172835 -2.29463778]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.93172835, -2.29463778]), 'currentState': array([1.43172835, 4.48854752]), 'targetState': array([0.99265045, 0.17333371]), 'effectorPosition': array([1.07348809, 0.63534996])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.673798509862517
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.93172835, -2.29463778]), 'currentState': array([1.43172835, 4.48854752]), 'targetState': array([0.99265045, 0.17333371]), 'effectorPosition': array([1.07348809, 0.63534996])}
episode index:386
target Thresh 1.16824165834934
current state at start:  [-0.55064284  1.8170632 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.55064284,  1.8170632 ]), 'currentState': array([5.32564367, 1.3170632 ]), 'targetState': array([0.90952146, 0.79567413]), 'effectorPosition': array([ 1.51159738, -0.46595275])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.6720574284416836
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.55064284,  1.8170632 ]), 'currentState': array([4.83328233, 5.81405662]), 'targetState': array([0.90952146, 0.79567413]), 'effectorPosition': array([-0.22064052, -1.93267764])}
episode index:387
target Thresh 1.1699035126244148
current state at start:  [ 0.76543908 -2.5716789 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.76543908, -2.5716789 ]), 'currentState': array([1.25777807, 3.34615944]), 'targetState': array([ 0.84805053, -0.08045182]), 'effectorPosition': array([ 0.19969263, -0.04271641])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.6703253216673494
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.76543908, -2.5716789 ]), 'currentState': array([4.3177947 , 5.01847561]), 'targetState': array([ 0.84805053, -0.08045182]), 'effectorPosition': array([-1.38051944, -0.83476046])}
episode index:388
target Thresh 1.1715620465124332
current state at start:  [-1.63308293  1.84117778]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.63308293,  1.84117778]), 'currentState': array([4.15010238, 1.34117778]), 'targetState': array([ 0.61693181, -1.02682052]), 'effectorPosition': array([ 0.16936857, -1.5577312 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.6686021203263023
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.63308293,  1.84117778]), 'currentState': array([3.38929528, 5.7574093 ]), 'targetState': array([ 0.61693181, -1.02682052]), 'effectorPosition': array([-1.93106433,  0.02932619])}
episode index:389
target Thresh 1.1732172666475333
current state at start:  [-0.43675787  2.56901885]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.43675787,  2.56901885]), 'currentState': array([5.34642744, 2.14910076]), 'targetState': array([0.00276154, 0.55638169]), 'effectorPosition': array([0.94322952, 0.13079883])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.6668877559152091
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.43675787,  2.56901885]), 'currentState': array([4.38351265, 5.96865276]), 'targetState': array([0.00276154, 0.55638169]), 'effectorPosition': array([-0.922906 , -1.7464612])}
episode index:390
target Thresh 1.1748691796505977
current state at start:  [ 3.67326323 -2.62158413]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.67326323, -2.62158413]), 'currentState': array([4.12966058, 3.16160117]), 'targetState': array([-0.80549188,  0.53381098]), 'effectorPosition': array([-0.01681544,  0.01084291])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.6651821606315386
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.67326323, -2.62158413]), 'currentState': array([4.65126838, 1.8269923 ]), 'targetState': array([-0.80549188,  0.53381098]), 'effectorPosition': array([ 0.91995051, -0.80429224])}
episode index:391
target Thresh 1.1765177921292804
current state at start:  [-0.83580156 -1.94984662]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.83580156, -1.94984662]), 'currentState': array([5.93630492, 4.78339166]), 'targetState': array([-0.63617833, -0.78510758]), 'effectorPosition': array([ 0.66804628, -1.30215216])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.6634852673646213
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.83580156, -1.94984662]), 'currentState': array([4.64295796, 0.82108402]), 'targetState': array([-0.63617833, -0.78510758]), 'effectorPosition': array([ 0.61347206, -1.72815176])}
episode index:392
target Thresh 1.1781631106780335
current state at start:  [ 1.48100016 -3.00451074]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.48100016, -3.00451074]), 'currentState': array([0.99969081, 3.65412989]), 'targetState': array([ 0.01139118, -0.00050611]), 'effectorPosition': array([ 0.48202765, -0.15698148])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6643415389489353
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.48100016, -3.00451074]), 'currentState': array([0.99969081, 3.65412989]), 'targetState': array([ 0.01139118, -0.00050611]), 'effectorPosition': array([ 0.48202765, -0.15698148])}
episode index:393
target Thresh 1.1798051418781337
current state at start:  [-3.70622219  2.33209878]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.70622219,  2.33209878]), 'currentState': array([2.41788967, 2.28713437]), 'targetState': array([-0.26587311, -0.97742567]), 'effectorPosition': array([-0.75672376, -0.33780881])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.6626553929109938
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.70622219,  2.33209878]), 'currentState': array([2.66632724, 4.77502374]), 'targetState': array([-0.26587311, -0.97742567]), 'effectorPosition': array([-0.48815074,  1.37364351])}
episode index:394
target Thresh 1.1814438922977075
current state at start:  [-0.94965038 -2.47553627]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.94965038, -2.47553627]), 'currentState': array([5.83353493, 4.30764904]), 'targetState': array([-0.12447331, -0.11874127]), 'effectorPosition': array([ 0.14642842, -1.09132913])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.6609777843213458
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.94965038, -2.47553627]), 'currentState': array([4.10729017, 0.33291952]), 'targetState': array([-0.12447331, -0.11874127]), 'effectorPosition': array([-0.83767448, -1.78563322])}
episode index:395
target Thresh 1.1830793684917595
current state at start:  [ 3.34616536 -2.78523998]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.34616536, -2.78523998]), 'currentState': array([3.81277207, 3.84263383]), 'targetState': array([0.15138049, 0.74612584]), 'effectorPosition': array([-0.58581547,  0.35843854])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.6593086485023525
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.34616536, -2.78523998]), 'currentState': array([4.5434294 , 0.22950763]), 'targetState': array([0.15138049, 0.74612584]), 'effectorPosition': array([-0.10764578, -1.98392778])}
episode index:396
target Thresh 1.184711577002196
current state at start:  [ 2.82239745 -2.10894471]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.82239745, -2.10894471]), 'currentState': array([2.32239745, 4.64065249]), 'targetState': array([0.16769664, 0.47710084]), 'effectorPosition': array([0.09484843, 1.3592843 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.6576479214280392
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.82239745, -2.10894471]), 'currentState': array([2.13830723, 5.68528743]), 'targetState': array([0.16769664, 0.47710084]), 'effectorPosition': array([-0.50715251,  1.84277991])}
episode index:397
target Thresh 1.1863405243578535
current state at start:  [ 0.74789791 -2.56012007]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.74789791, -2.56012007]), 'currentState': array([0.39975606, 4.22306524]), 'targetState': array([0.0249349, 0.0344405]), 'effectorPosition': array([ 0.83170799, -0.60679785])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.6559955397159085
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.74789791, -2.56012007]), 'currentState': array([4.12174698, 0.72412471]), 'targetState': array([0.0249349, 0.0344405]), 'effectorPosition': array([-0.4238077 , -1.82168773])}
episode index:398
target Thresh 1.1879662170745238
current state at start:  [-0.4261151  -2.00657698]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.4261151 , -2.00657698]), 'currentState': array([0.06176573, 4.71570263]), 'targetState': array([ 0.02913084, -0.58701154]), 'effectorPosition': array([ 1.06312655, -0.93615662])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.6543514406188761
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.4261151 , -2.00657698]), 'currentState': array([4.64135792, 0.74283531]), 'targetState': array([ 0.02913084, -0.58701154]), 'effectorPosition': array([ 0.55142785, -1.78017833])}
episode index:399
target Thresh 1.1895886616549793
current state at start:  [-1.50994268  2.74411685]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.50994268,  2.74411685]), 'currentState': array([4.27324263, 2.24411685]), 'targetState': array([-0.04117025,  0.22203018]), 'effectorPosition': array([ 0.54753933, -0.67307516])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.6527155620173289
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.50994268,  2.74411685]), 'currentState': array([3.80805779, 1.71612322]), 'targetState': array([-0.04117025,  0.22203018]), 'effectorPosition': array([-0.06049025, -1.30641079])}
episode index:400
target Thresh 1.1912078645890012
current state at start:  [-0.81914639  2.27805824]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.81914639,  2.27805824]), 'currentState': array([5.02344118, 1.78249408]), 'targetState': array([0.59971042, 0.0596719 ]), 'effectorPosition': array([ 1.17251001, -0.45274735])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.6510878424113007
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.81914639,  2.27805824]), 'currentState': array([2.24647955, 4.50809565]), 'targetState': array([0.59971042, 0.0596719 ]), 'effectorPosition': array([0.2655074 , 1.23440486])}
episode index:401
target Thresh 1.1928238323534028
current state at start:  [ 3.9388381  -1.76969516]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.9388381 , -1.76969516]), 'currentState': array([4.41327194, 5.01349015]), 'targetState': array([-0.8721398 ,  0.06019519]), 'effectorPosition': array([-1.2946746 , -0.95758117])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.6494682209127651
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.9388381 , -1.76969516]), 'currentState': array([4.33451629, 1.95098022]), 'targetState': array([-0.8721398 ,  0.06019519]), 'effectorPosition': array([ 0.63105325, -0.92714039])}
episode index:402
target Thresh 1.1944365714120577
current state at start:  [-0.94941585  1.88345725]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.94941585,  1.88345725]), 'currentState': array([4.85848157, 1.38345725]), 'targetState': array([1.06183165, 0.49841675]), 'effectorPosition': array([ 1.14472295, -1.03058223])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.6478566372380435
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.94941585,  1.88345725]), 'currentState': array([2.37611307, 4.64776172]), 'targetState': array([1.06183165, 0.49841675]), 'effectorPosition': array([0.01695332, 1.3676798 ])}
episode index:403
target Thresh 1.1960460882159243
current state at start:  [-3.43816671  2.39776728]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.43816671,  2.39776728]), 'currentState': array([2.3450186 , 2.18870269]), 'targetState': array([ 0.11207003, -0.9576807 ]), 'effectorPosition': array([-0.87687887, -0.26911633])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.6462530317003257
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.43816671,  2.39776728]), 'currentState': array([3.16396097, 4.22722156]), 'targetState': array([ 0.11207003, -0.9576807 ]), 'effectorPosition': array([-0.55329533,  0.87243988])}
episode index:404
target Thresh 1.1976523892030717
current state at start:  [1.31048843 1.95120745]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.31048843, 1.95120745]), 'currentState': array([0.86673391, 1.45120745]), 'targetState': array([-0.14327932,  0.35186222]), 'effectorPosition': array([-0.03222756,  1.49585075])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.6446573452023001
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.31048843, 1.95120745]), 'currentState': array([3.84646845, 1.52951415]), 'targetState': array([-0.14327932,  0.35186222]), 'effectorPosition': array([-0.14574021, -1.43572306])}
episode index:405
target Thresh 1.1992554807987061
current state at start:  [-1.24836236  2.22048824]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.24836236,  2.22048824]), 'currentState': array([4.53482295, 1.76648756]), 'targetState': array([ 0.74755433, -0.68419913]), 'effectorPosition': array([ 0.82320134, -0.96615232])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6455325734160876
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.24836236,  2.22048824]), 'currentState': array([4.53482295, 1.76648756]), 'targetState': array([ 0.74755433, -0.68419913]), 'effectorPosition': array([ 0.82320134, -0.96615232])}
episode index:406
target Thresh 1.200855369415196
current state at start:  [ 3.43282905 -2.11638739]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.43282905, -2.11638739]), 'currentState': array([2.93282905, 4.48409496]), 'targetState': array([-1.24475976,  0.08238796]), 'effectorPosition': array([-0.5550124 ,  1.11325152])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.6439464982971291
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.43282905, -2.11638739]), 'currentState': array([4.05381169, 2.47902889]), 'targetState': array([-1.24475976,  0.08238796]), 'effectorPosition': array([ 0.35700535, -0.54379378])}
episode index:407
target Thresh 1.202452061452098
current state at start:  [-2.5523625   2.24735713]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.5523625 ,  2.24735713]), 'currentState': array([4.17209083, 1.80879513]), 'targetState': array([ 0.24870975, -0.44646174]), 'effectorPosition': array([ 0.44026277, -1.15527143])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.6423681980562048
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.5523625 ,  2.24735713]), 'currentState': array([3.14933852, 3.99437577]), 'targetState': array([ 0.24870975, -0.44646174]), 'effectorPosition': array([-0.34793351,  0.7504418 ])}
episode index:408
target Thresh 1.2040455632961824
current state at start:  [ 4.27436639 -2.60635193]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.27436639, -2.60635193]), 'currentState': array([4.77436639, 4.17602367]), 'targetState': array([-0.47841552, -0.24057836]), 'effectorPosition': array([-0.82763475, -0.54128599])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6432426034399304
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.27436639, -2.60635193]), 'currentState': array([4.77436639, 4.17602367]), 'targetState': array([-0.47841552, -0.24057836]), 'effectorPosition': array([-0.82763475, -0.54128599])}
episode index:409
target Thresh 1.205635881321459
current state at start:  [ 0.5452713  -2.31084627]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.5452713 , -2.31084627]), 'currentState': array([0.97798356, 4.47233904]), 'targetState': array([0.84769621, 0.07074611]), 'effectorPosition': array([1.23145657, 0.08951216])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6441127434315405
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.5452713 , -2.31084627]), 'currentState': array([0.97798356, 4.47233904]), 'targetState': array([0.84769621, 0.07074611]), 'effectorPosition': array([1.23145657, 0.08951216])}
episode index:410
target Thresh 1.2072230218892013
current state at start:  [-1.23847237 -2.43443873]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.23847237, -2.43443873]), 'currentState': array([5.54471293, 4.34874658]), 'targetState': array([-0.42723944, -0.29558849]), 'effectorPosition': array([-0.15266686, -1.12486942])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.6425455591409527
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.23847237, -2.43443873]), 'currentState': array([3.92846541, 1.79207113]), 'targetState': array([-0.42723944, -0.29558849]), 'effectorPosition': array([ 0.13978184, -1.24157722])}
episode index:411
target Thresh 1.2088069913479744
current state at start:  [1.00766953 2.26939269]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.00766953, 2.26939269]), 'currentState': array([0.50766953, 1.76939269]), 'targetState': array([-0.07297539,  0.11760258]), 'effectorPosition': array([0.22488239, 1.24693262])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.6409859825410961
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.00766953, 2.26939269]), 'currentState': array([4.48386643, 1.03212326]), 'targetState': array([-0.07297539,  0.11760258]), 'effectorPosition': array([ 0.49332134, -1.66812137])}
episode index:412
target Thresh 1.210387796033658
current state at start:  [-1.7369283   1.83373129]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.7369283 ,  1.83373129]), 'currentState': array([4.06479602, 1.33373129]), 'targetState': array([ 0.65890984, -1.07203428]), 'effectorPosition': array([ 0.03028569, -1.57123656])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.6394339583702944
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.7369283 ,  1.83373129]), 'currentState': array([3.17399732, 4.07697037]), 'targetState': array([ 0.65890984, -1.07203428]), 'effectorPosition': array([-0.43234759,  0.79123107])}
episode index:413
target Thresh 1.2119654422694728
current state at start:  [ 1.03209026 -2.01621158]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.03209026, -2.01621158]), 'currentState': array([1.52289395, 4.76697373]), 'targetState': array([0.94841366, 0.31527798]), 'effectorPosition': array([1.04786173, 1.00553522])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.6401407974754555
{'reset': False, 'endBeforeDone': False, 'stepCount': 8, 'initial state': array([ 1.03209026, -2.01621158]), 'currentState': array([1.80386439, 4.2326755 ]), 'targetState': array([0.94841366, 0.31527798]), 'effectorPosition': array([0.73877319, 0.72881009])}
episode index:414
target Thresh 1.213539936366006
current state at start:  [ 1.35975074 -3.05873251]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.35975074, -3.05873251]), 'currentState': array([0.85975074, 3.55783889]), 'targetState': array([-0.32208369,  0.35776498]), 'effectorPosition': array([ 0.36207849, -0.19918055])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.6385982895297314
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.35975074, -3.05873251]), 'currentState': array([4.41223188, 1.59544286]), 'targetState': array([-0.32208369,  0.35776498]), 'effectorPosition': array([ 0.66661614, -1.22732833])}
episode index:415
target Thresh 1.2151112846212357
current state at start:  [ 3.35841597 -2.81774614]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.35841597, -2.81774614]), 'currentState': array([3.84021766, 3.57144045]), 'targetState': array([-0.26026906,  0.31182904]), 'effectorPosition': array([-0.33768673,  0.26059412])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6394670436414388
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.35841597, -2.81774614]), 'currentState': array([3.84021766, 3.57144045]), 'targetState': array([-0.26026906,  0.31182904]), 'effectorPosition': array([-0.33768673,  0.26059412])}
episode index:416
target Thresh 1.2166794933205578
current state at start:  [-4.32784893  2.61735951]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.32784893,  2.61735951]), 'currentState': array([1.4610997, 2.139245 ]), 'targetState': array([0.01291699, 0.01259046]), 'effectorPosition': array([-0.78712907,  0.55115983])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.6379335495319869
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-4.32784893,  2.61735951]), 'currentState': array([0.67984496, 5.69514338]), 'targetState': array([0.01291699, 0.01259046]), 'effectorPosition': array([1.77345926, 0.72034659])}
episode index:417
target Thresh 1.2182445687368086
current state at start:  [-3.60037895  1.97678121]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.60037895,  1.97678121]), 'currentState': array([3.1671594 , 2.44072911]), 'targetState': array([-1.30329912, -0.47372524]), 'effectorPosition': array([-0.21915174, -0.65069296])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.6364073927149247
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.60037895,  1.97678121]), 'currentState': array([4.05025703, 2.36888341]), 'targetState': array([-1.30329912, -0.47372524]), 'effectorPosition': array([ 0.37597264, -0.65314661])}
episode index:418
target Thresh 1.2198065171302923
current state at start:  [-0.7951329   2.40786986]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.7951329 ,  2.40786986]), 'currentState': array([4.98805241, 1.93454675]), 'targetState': array([ 0.12446423, -0.27662444]), 'effectorPosition': array([ 1.07463104, -0.36551965])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.6348885206559393
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.7951329 ,  2.40786986]), 'currentState': array([4.22021523, 1.1623755 ]), 'targetState': array([ 0.12446423, -0.27662444]), 'effectorPosition': array([ 0.14860137, -1.66500412])}
episode index:419
target Thresh 1.221365344748804
current state at start:  [ 1.96231734 -2.4801882 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.96231734, -2.4801882 ]), 'currentState': array([1.5153616 , 4.30299711]), 'targetState': array([0.49439635, 0.37139564]), 'effectorPosition': array([0.94930565, 0.55019609])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6357578337019966
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.96231734, -2.4801882 ]), 'currentState': array([1.5153616 , 4.30299711]), 'targetState': array([0.49439635, 0.37139564]), 'effectorPosition': array([0.94930565, 0.55019609])}
episode index:420
target Thresh 1.2229210578276564
current state at start:  [-1.61170125  2.78833684]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.61170125,  2.78833684]), 'currentState': array([4.33887902, 2.28833684]), 'targetState': array([-0.02496071,  0.00985596]), 'effectorPosition': array([ 0.57651724, -0.59376815])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.6342477200827519
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.61170125,  2.78833684]), 'currentState': array([4.70565169, 1.00611165]), 'targetState': array([-0.02496071,  0.00985596]), 'effectorPosition': array([ 0.83439555, -1.54080596])}
episode index:421
target Thresh 1.2244736625897041
current state at start:  [-1.58607287 -1.8504674 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.58607287, -1.8504674 ]), 'currentState': array([5.14640236, 4.88142334]), 'targetState': array([-1.30144839, -0.35834612]), 'effectorPosition': array([-0.40309544, -1.47444063])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.6327447634000913
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.58607287, -1.8504674 ]), 'currentState': array([4.30280087, 1.98652196]), 'targetState': array([-1.30144839, -0.35834612]), 'effectorPosition': array([ 0.60174962, -0.91114744])}
episode index:422
target Thresh 1.2260231652453684
current state at start:  [1.49444587 2.53782513]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.49444587, 2.53782513]), 'currentState': array([1.01646928, 2.03782513]), 'targetState': array([0.00926193, 0.50687559]), 'effectorPosition': array([-0.46982069,  0.93744226])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6336129790894528
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.49444587, 2.53782513]), 'currentState': array([1.01646928, 2.03782513]), 'targetState': array([0.00926193, 0.50687559]), 'effectorPosition': array([-0.46982069,  0.93744226])}
episode index:423
target Thresh 1.2275695719926614
current state at start:  [1.28740672 2.00282453]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.28740672, 2.00282453]), 'currentState': array([0.86013899, 1.50282453]), 'targetState': array([-0.42008621,  0.62475415]), 'effectorPosition': array([-0.05954484,  1.46023743])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.6321186088557513
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.28740672, 2.00282453]), 'currentState': array([4.09159652, 1.35789265]), 'targetState': array([-0.42008621,  0.62475415]), 'effectorPosition': array([ 0.09046372, -1.55383851])}
episode index:424
target Thresh 1.2291128890172125
current state at start:  [-3.69271915  2.64591137]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.69271915,  2.64591137]), 'currentState': array([2.09046616, 2.70078362]), 'targetState': array([-0.08098855, -0.83744397]), 'effectorPosition': array([-0.4178145 , -0.12890891])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.6306312709525613
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.69271915,  2.64591137]), 'currentState': array([2.8998464 , 3.92130563]), 'targetState': array([-0.08098855, -0.83744397]), 'effectorPosition': array([-0.11216912,  0.75178944])}
episode index:425
target Thresh 1.2306531224922919
current state at start:  [-1.93048695  2.48127478]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.93048695,  2.48127478]), 'currentState': array([3.85269835, 2.00836178]), 'targetState': array([0.50578451, 0.15553417]), 'effectorPosition': array([ 0.15457964, -1.06237189])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.6291509158564286
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.93048695,  2.48127478]), 'currentState': array([2.02191691, 5.14290841]), 'targetState': array([0.50578451, 0.15553417]), 'effectorPosition': array([0.19991198, 1.6717419 ])}
episode index:426
target Thresh 1.2321902785788355
current state at start:  [ 1.74415501 -1.78866054]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.74415501, -1.78866054]), 'currentState': array([1.25708081, 4.98047086]), 'targetState': array([0.53131166, 0.97361139]), 'effectorPosition': array([1.3075539 , 0.90557575])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.6276774945078186
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.74415501, -1.78866054]), 'currentState': array([3.90095081, 0.02679268]), 'targetState': array([0.53131166, 0.97361139]), 'effectorPosition': array([-1.4318524 , -1.39609487])}
episode index:427
target Thresh 1.2337243634254698
current state at start:  [-0.52127829 -2.40586124]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.52127829, -2.40586124]), 'currentState': array([6.19606925, 4.33961718]), 'targetState': array([ 0.15707411, -0.10717139]), 'effectorPosition': array([ 0.55236018, -0.98310819])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.6262109583056975
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.52127829, -2.40586124]), 'currentState': array([2.21626639, 4.28425815]), 'targetState': array([ 0.15707411, -0.10717139]), 'effectorPosition': array([0.37490065, 1.0144493 ])}
episode index:428
target Thresh 1.2352553831685358
current state at start:  [ 0.52759415 -2.94279025]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.52759415, -2.94279025]), 'currentState': array([0.58278359, 3.78879168]), 'targetState': array([0.18769842, 0.26189769]), 'effectorPosition': array([ 0.50067983, -0.39213282])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.6247512591021878
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.52759415, -2.94279025]), 'currentState': array([3.68126344, 0.26972532]), 'targetState': array([0.18769842, 0.26189769]), 'effectorPosition': array([-1.54781359, -1.23772425])}
episode index:429
target Thresh 1.2367833439321148
current state at start:  [-0.3194258  -1.73066807]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.3194258 , -1.73066807]), 'currentState': array([0.14587759, 5.05251724]), 'targetState': array([ 0.42566402, -1.29544335]), 'effectorPosition': array([ 1.4564767 , -0.73884481])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.623298349197299
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.3194258 , -1.73066807]), 'currentState': array([3.53465479, 3.52901853]), 'targetState': array([ 0.42566402, -1.29544335]), 'effectorPosition': array([-0.21317029,  0.32060744])}
episode index:430
target Thresh 1.2383082518280522
current state at start:  [ 3.50235139 -2.54239278]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.50235139, -2.54239278]), 'currentState': array([3.47708435, 4.24079253]), 'targetState': array([ 0.11319946, -0.13640433]), 'effectorPosition': array([-0.80856361,  0.66151854])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.6218521813337321
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.50235139, -2.54239278]), 'currentState': array([2.86630982, 4.30711104]), 'targetState': array([ 0.11319946, -0.13640433]), 'effectorPosition': array([-0.33311939,  1.04903912])}
episode index:431
target Thresh 1.239830112955981
current state at start:  [ 0.25625896 -2.04700763]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.25625896, -2.04700763]), 'currentState': array([0.75625896, 4.70108753]), 'targetState': array([ 0.78724   , -0.40068884]), 'effectorPosition': array([ 1.40534879, -0.04891172])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.6204127086917559
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.25625896, -2.04700763]), 'currentState': array([3.25180318, 3.84791642]), 'targetState': array([ 0.78724   , -0.40068884]), 'effectorPosition': array([-0.30918192,  0.61878951])}
episode index:432
target Thresh 1.2413489334033483
current state at start:  [ 1.1365592 -2.1910774]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.1365592, -2.1910774]), 'currentState': array([1.58033301, 3.5921079 ]), 'targetState': array([ 1.33059066, -0.38583046]), 'effectorPosition': array([0.4344581 , 0.10392508])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.6189798848841537
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.1365592, -2.1910774]), 'currentState': array([3.40175774, 3.91244764]), 'targetState': array([ 1.33059066, -0.38583046]), 'effectorPosition': array([-0.45240345,  0.60058361])}
episode index:433
target Thresh 1.2428647192454376
current state at start:  [-0.93231335  2.16894226]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.93231335,  2.16894226]), 'currentState': array([4.92815102, 1.66894226]), 'targetState': array([ 0.5742933 , -0.08056285]), 'effectorPosition': array([ 1.165226  , -0.66803554])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.6175536639512409
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.93231335,  2.16894226]), 'currentState': array([3.23895669, 4.65401092]), 'targetState': array([ 0.5742933 , -0.08056285]), 'effectorPosition': array([-1.03423997,  0.90202986])}
episode index:434
target Thresh 1.2443774765453943
current state at start:  [-4.33176199  2.48428305]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.33176199,  2.48428305]), 'currentState': array([1.46898147, 2.87435039]), 'targetState': array([-1.26472103,  0.18911383]), 'effectorPosition': array([-0.25909716,  0.06215345])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.6161340003559507
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-4.33176199,  2.48428305]), 'currentState': array([4.42407694, 2.69568414]), 'targetState': array([-1.26472103,  0.18911383]), 'effectorPosition': array([ 0.38567439, -0.21637197])}
episode index:435
target Thresh 1.2458872113542498
current state at start:  [ 4.1098824  -2.40868672]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.1098824 , -2.40868672]), 'currentState': array([4.6098824 , 4.34770683]), 'targetState': array([-0.25880166, -0.23535825]), 'effectorPosition': array([-0.99516511, -0.54437274])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.6147208489789875
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 4.1098824 , -2.40868672]), 'currentState': array([3.99100013, 1.22465266]), 'targetState': array([-0.25880166, -0.23535825]), 'effectorPosition': array([-0.17814094, -1.62690235])}
episode index:436
target Thresh 1.2473939297109453
current state at start:  [-2.21931077 -1.70207678]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.21931077, -1.70207678]), 'currentState': array([4.55244958, 4.99727275]), 'targetState': array([-1.23520193, -0.36490488]), 'effectorPosition': array([-1.15146298, -1.11185647])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.613314165114047
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.21931077, -1.70207678]), 'currentState': array([3.957268  , 2.00816746]), 'targetState': array([-1.23520193, -0.36490488]), 'effectorPosition': array([ 0.26456407, -1.04061847])}
episode index:437
target Thresh 1.248897637642356
current state at start:  [ 2.78920279 -2.79193936]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.78920279, -2.79193936]), 'currentState': array([2.35792379, 3.97899597]), 'targetState': array([ 0.2626291, -0.2077643]), 'effectorPosition': array([0.29022813, 0.75959152])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.6119139044631017
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.78920279, -2.79193936]), 'currentState': array([1.07732943, 4.78014831]), 'targetState': array([ 0.2626291, -0.2077643]), 'effectorPosition': array([1.38442877, 0.46773064])}
episode index:438
target Thresh 1.250398341163316
current state at start:  [ 3.08745665 -1.7971283 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.08745665, -1.7971283 ]), 'currentState': array([2.58745665, 4.84418866]), 'targetState': array([-1.25538539,  0.44735625]), 'effectorPosition': array([-0.44046278,  1.43834258])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.6105200231317507
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.08745665, -1.7971283 ]), 'currentState': array([4.24682963, 2.59554861]), 'targetState': array([-1.25538539,  0.44735625]), 'effectorPosition': array([ 0.39876085, -0.36306837])}
episode index:439
target Thresh 1.2518960462766409
current state at start:  [0.585476   2.54348858]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.585476  , 2.54348858]), 'currentState': array([0.15195929, 2.11976503]), 'targetState': array([0.23929105, 0.33933621]), 'effectorPosition': array([0.34354921, 0.91561916])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.6091324776246331
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.585476  , 2.54348858]), 'currentState': array([3.78064277, 0.05160738]), 'targetState': array([0.23929105, 0.33933621]), 'effectorPosition': array([-1.57348999, -1.23347741])}
episode index:440
target Thresh 1.2533907589731537
current state at start:  [-1.95043446 -1.63859678]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.95043446, -1.63859678]), 'currentState': array([4.83275084, 5.12743002]), 'targetState': array([-1.12314319,  0.06396412]), 'effectorPosition': array([-0.73999169, -1.50295285])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.6077512248409037
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.95043446, -1.63859678]), 'currentState': array([4.41012512, 2.24525939]), 'targetState': array([-1.12314319,  0.06396412]), 'effectorPosition': array([ 0.63384763, -0.59100009])}
episode index:441
target Thresh 1.2548824852317066
current state at start:  [-1.52777658  2.00229058]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.52777658,  2.00229058]), 'currentState': array([4.25540873, 1.54832626]), 'targetState': array([ 1.05773652, -0.67193567]), 'effectorPosition': array([ 0.44600838, -1.35868057])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.6063762220697705
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.52777658,  2.00229058]), 'currentState': array([3.78253835, 4.05243778]), 'targetState': array([ 1.05773652, -0.67193567]), 'effectorPosition': array([-0.78252627,  0.40186569])}
episode index:442
target Thresh 1.2563712310192072
current state at start:  [-2.98772016  1.84893998]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.98772016,  1.84893998]), 'currentState': array([3.75974594, 1.91135332]), 'targetState': array([-0.66156164, -0.43883976]), 'effectorPosition': array([ 0.00350113, -1.1541072 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.6050074269860916
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.98772016,  1.84893998]), 'currentState': array([4.27071581, 1.88304724]), 'targetState': array([-0.66156164, -0.43883976]), 'effectorPosition': array([ 0.56418395, -1.03309898])}
episode index:443
target Thresh 1.2578570022906401
current state at start:  [0.29026034 1.92129387]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.29026034, 1.92129387]), 'currentState': array([6.24999011, 1.42129387]), 'targetState': array([0.77710515, 1.00854262]), 'effectorPosition': array([1.18113208, 0.95016805])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6058970498982851
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.29026034, 1.92129387]), 'currentState': array([6.24999011, 1.42129387]), 'targetState': array([0.77710515, 1.00854262]), 'effectorPosition': array([1.18113208, 0.95016805])}
episode index:444
target Thresh 1.259339804989093
current state at start:  [2.07743263 1.76804628]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.07743263, 1.76804628]), 'currentState': array([1.57743263, 1.31219011]), 'targetState': array([-1.05860751,  0.32218172]), 'effectorPosition': array([-0.97505943,  1.24929014])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.6045354834940192
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([2.07743263, 1.76804628]), 'currentState': array([4.58051904, 2.6830006 ]), 'targetState': array([-1.05860751,  0.32218172]), 'effectorPosition': array([ 0.42525678, -0.1606342 ])}
episode index:445
target Thresh 1.260819645045778
current state at start:  [-1.03131959 -2.40395366]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.03131959, -2.40395366]), 'currentState': array([5.75186572, 4.37528266]), 'targetState': array([ 0.11480417, -0.88509894]), 'effectorPosition': array([ 0.09882625, -1.15270032])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.605422175235064
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.03131959, -2.40395366]), 'currentState': array([5.75186572, 4.37528266]), 'targetState': array([ 0.11480417, -0.88509894]), 'effectorPosition': array([ 0.09882625, -1.15270032])}
episode index:446
target Thresh 1.262296528380058
current state at start:  [-0.13474663  2.49238087]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.13474663,  2.49238087]), 'currentState': array([5.64843868, 2.00610278]), 'targetState': array([0.06965212, 0.72441676]), 'effectorPosition': array([1.0033426 , 0.38720413])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.6040677632099296
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.13474663,  2.49238087]), 'currentState': array([3.64050983, 5.91538482]), 'targetState': array([0.06965212, 0.72441676]), 'effectorPosition': array([-1.86951769, -0.60921633])}
episode index:447
target Thresh 1.2637704608994675
current state at start:  [0.43483563 2.61465066]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.43483563, 2.61465066]), 'currentState': array([0.06320267, 2.11465066]), 'targetState': array([0.42756464, 0.82070454]), 'effectorPosition': array([0.42755061, 0.88449101])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.6049515405241932
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.43483563, 2.61465066]), 'currentState': array([0.06320267, 2.11465066]), 'targetState': array([0.42756464, 0.82070454]), 'effectorPosition': array([0.42755061, 0.88449101])}
episode index:448
target Thresh 1.2652414484997392
current state at start:  [0.0373272  2.27568674]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.0373272 , 2.27568674]), 'currentState': array([5.95008505, 1.77568674]), 'targetState': array([-0.01405708,  0.90302423]), 'effectorPosition': array([1.07289207, 0.66481793])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.6036042096989723
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.0373272 , 2.27568674]), 'currentState': array([3.91722346, 0.3478958 ]), 'targetState': array([-0.01405708,  0.90302423]), 'effectorPosition': array([-1.14648496, -1.60179791])}
episode index:449
target Thresh 1.266709497064825
current state at start:  [-1.809079    2.33551091]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.809079  ,  2.33551091]), 'currentState': array([3.97410631, 1.88249743]), 'targetState': array([ 0.93553018, -0.01767628]), 'effectorPosition': array([ 0.23736676, -1.15338658])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.6022628670107524
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.809079  ,  2.33551091]), 'currentState': array([3.51438163, 4.3947437 ]), 'targetState': array([ 0.93553018, -0.01767628]), 'effectorPosition': array([-0.98643094,  0.63426571])}
episode index:450
target Thresh 1.2681746124669215
current state at start:  [ 2.33377823 -2.66272712]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.33377823, -2.66272712]), 'currentState': array([1.85698405, 4.06526855]), 'targetState': array([ 0.08023584, -0.06311191]), 'effectorPosition': array([0.65327078, 0.60618004])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.6009274726271365
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.33377823, -2.66272712]), 'currentState': array([4.04098104, 5.84758148]), 'targetState': array([ 0.08023584, -0.06311191]), 'effectorPosition': array([-1.51645487, -1.23028267])}
episode index:451
target Thresh 1.2696368005664922
current state at start:  [0.5916303  2.84941765]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.5916303 , 2.84941765]), 'currentState': array([0.17886149, 2.34941765]), 'targetState': array([0.20080203, 0.01099474]), 'effectorPosition': array([0.16630156, 0.75348957])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5995979870682269
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.5916303 , 2.84941765]), 'currentState': array([3.43593581, 5.7643472 ]), 'targetState': array([0.20080203, 0.01099474]), 'effectorPosition': array([-1.93189957, -0.0674973 ])}
episode index:452
target Thresh 1.2710960672122913
current state at start:  [-0.92798511  2.60693474]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.92798511,  2.60693474]), 'currentState': array([4.85845724, 2.10693474]), 'targetState': array([-0.0090036 , -0.06940429]), 'effectorPosition': array([ 0.92173268, -0.35884365])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5982743712027341
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.92798511,  2.60693474]), 'currentState': array([3.76174939, 6.0691061 ]), 'targetState': array([-0.0090036 , -0.06940429]), 'effectorPosition': array([-1.73246468, -0.9761716 ])}
episode index:453
target Thresh 1.2725524182413872
current state at start:  [ 4.00294858 -2.60253426]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.00294858, -2.60253426]), 'currentState': array([4.50294858, 4.18065104]), 'targetState': array([-0.31058084,  0.61323192]), 'effectorPosition': array([-0.94558607, -0.30298981])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5969565862441378
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 4.00294858, -2.60253426]), 'currentState': array([4.0919967 , 1.69729437]), 'targetState': array([-0.31058084,  0.61323192]), 'effectorPosition': array([ 0.29913906, -1.28770879])}
episode index:454
target Thresh 1.2740058594791863
current state at start:  [-0.82029335 -2.74535182]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.82029335, -2.74535182]), 'currentState': array([5.95975038, 4.03783348]), 'targetState': array([-0.55039243,  0.03021488]), 'effectorPosition': array([ 0.1077658 , -0.85981747])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5956445937468979
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.82029335, -2.74535182]), 'currentState': array([4.17934361, 2.45342214]), 'targetState': array([-0.55039243,  0.03021488]), 'effectorPosition': array([ 0.43135794, -0.51875988])}
episode index:455
target Thresh 1.2754563967394552
current state at start:  [ 2.61502805 -1.79506349]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.61502805, -1.79506349]), 'currentState': array([2.15082487, 4.93725587]), 'targetState': array([-0.71852944,  0.98833103]), 'effectorPosition': array([0.14513879, 1.55720517])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5943383556027161
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.61502805, -1.79506349]), 'currentState': array([5.73587041, 4.28145078]), 'targetState': array([-0.71852944,  0.98833103]), 'effectorPosition': array([ 0.02440188, -1.07886873])}
episode index:456
target Thresh 1.276904035824345
current state at start:  [-1.59061406 -1.63424647]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.59061406, -1.63424647]), 'currentState': array([5.19257125, 5.14893884]), 'targetState': array([-0.50739545, -1.04729537]), 'effectorPosition': array([-0.14647601, -1.68052837])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5930378340368458
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.59061406, -1.63424647]), 'currentState': array([4.40990558, 1.67444327]), 'targetState': array([-0.50739545, -1.04729537]), 'effectorPosition': array([ 0.6824053, -1.1521285])}
episode index:457
target Thresh 1.2783487825244142
current state at start:  [ 1.90659049 -2.51150443]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.90659049, -2.51150443]), 'currentState': array([1.40659049, 4.23906173]), 'targetState': array([-0.00724508, -0.18467493]), 'effectorPosition': array([0.96703545, 0.39133357])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.591742991604451
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.90659049, -2.51150443]), 'currentState': array([3.35471521, 5.52504458]), 'targetState': array([-0.00724508, -0.18467493]), 'effectorPosition': array([-1.83249309,  0.30692079])}
episode index:458
target Thresh 1.279790642618651
current state at start:  [-0.60842204  2.65629208]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.60842204,  2.65629208]), 'currentState': array([5.1864793 , 2.33660256]), 'targetState': array([0.70793496, 0.74435915]), 'effectorPosition': array([0.7814234 , 0.05604201])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5904537911870121
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.60842204,  2.65629208]), 'currentState': array([3.54028089, 5.27193239]), 'targetState': array([0.70793496, 0.74435915]), 'effectorPosition': array([-1.73974713,  0.18675792])}
episode index:459
target Thresh 1.2812296218744983
current state at start:  [ 0.06051447 -2.07541749]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.06051447, -2.07541749]), 'currentState': array([0.56051447, 4.70776782]), 'targetState': array([ 0.07470746, -1.13807164]), 'effectorPosition': array([ 1.37468403, -0.31780737])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5891701959887795
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.06051447, -2.07541749]), 'currentState': array([3.74348021, 4.1595308 ]), 'targetState': array([ 0.07470746, -1.13807164]), 'effectorPosition': array([-0.87327809,  0.43259897])}
episode index:460
target Thresh 1.2826657260478744
current state at start:  [-1.14069032 -1.58431951]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.14069032, -1.58431951]), 'currentState': array([5.64249499, 5.18847755]), 'targetState': array([-1.11529788, -0.7967342 ]), 'effectorPosition': array([ 0.63782383, -1.58423269])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5878921695332724
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.14069032, -1.58431951]), 'currentState': array([4.32632468, 1.40122476]), 'targetState': array([-1.11529788, -0.7967342 ]), 'effectorPosition': array([ 0.47301989, -1.45388182])}
episode index:461
target Thresh 1.2840989608831985
current state at start:  [ 3.3092191  -2.52922597]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.3092191 , -2.52922597]), 'currentState': array([2.84348667, 4.18869225]), 'targetState': array([0.06720893, 0.01759458]), 'effectorPosition': array([-0.22352001,  0.9746123 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5866196756598238
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.3092191 , -2.52922597]), 'currentState': array([5.60309965, 6.09793016]), 'targetState': array([0.06720893, 0.01759458]), 'effectorPosition': array([ 1.42589955, -1.3901759 ])}
episode index:462
target Thresh 1.2855293321134116
current state at start:  [1.46174049 2.65420622]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.46174049, 2.65420622]), 'currentState': array([0.96174049, 2.15420622]), 'targetState': array([ 0.02021045, -0.00694972]), 'effectorPosition': array([-0.42757783,  0.84583167])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5853526785201697
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.46174049, 2.65420622]), 'currentState': array([2.12954731, 5.18240098]), 'targetState': array([ 0.02021045, -0.00694972]), 'effectorPosition': array([-0.01424859,  1.7045794 ])}
episode index:463
target Thresh 1.2869568454600002
current state at start:  [-0.41381809 -2.38321102]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.41381809, -2.38321102]), 'currentState': array([0.0429487 , 4.38799987]), 'targetState': array([ 0.08813092, -0.99200122]), 'effectorPosition': array([ 0.72133816, -0.91772088])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5840911425750831
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.41381809, -2.38321102]), 'currentState': array([3.3320601 , 4.51810402]), 'targetState': array([ 0.08813092, -0.99200122]), 'effectorPosition': array([-0.97809834,  0.8106748 ])}
episode index:464
target Thresh 1.2883815066330202
current state at start:  [-3.490537    2.40318671]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.490537  ,  2.40318671]), 'currentState': array([3.2926483 , 1.91450298]), 'targetState': array([-0.05537305, -0.07817701]), 'effectorPosition': array([-0.5137903 , -1.03056345])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5828350325910506
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.490537  ,  2.40318671]), 'currentState': array([4.83107041, 0.89576331]), 'targetState': array([-0.05537305, -0.07817701]), 'effectorPosition': array([ 0.96759047, -1.52105715])}
episode index:465
target Thresh 1.2898033213311182
current state at start:  [-0.13476372  2.67979951]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.13476372,  2.67979951]), 'currentState': array([5.64842159, 2.17979951]), 'targetState': array([-0.04545842,  0.34503877]), 'effectorPosition': array([0.83096951, 0.40668094])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5815843136369926
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.13476372,  2.67979951]), 'currentState': array([4.93123353, 0.88423718]), 'targetState': array([-0.04545842,  0.34503877]), 'effectorPosition': array([ 1.10970286, -1.42699646])}
episode index:466
target Thresh 1.2912222952415542
current state at start:  [-2.86870657  2.06834519]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.86870657,  2.06834519]), 'currentState': array([3.88873335, 2.26523201]), 'targetState': array([-0.21003446, -1.14068809]), 'effectorPosition': array([ 0.25802782, -0.80840449])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.5824802787041511
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.86870657,  2.06834519]), 'currentState': array([3.88873335, 2.26523201]), 'targetState': array([-0.21003446, -1.14068809]), 'effectorPosition': array([ 0.25802782, -0.80840449])}
episode index:467
target Thresh 1.2926384340402262
current state at start:  [ 0.83552018 -1.61129802]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.83552018, -1.61129802]), 'currentState': array([1.33552018, 5.15299759]), 'targetState': array([0.84153786, 0.174155  ]), 'effectorPosition': array([1.21210479, 1.17634265])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5812356627240141
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.83552018, -1.61129802]), 'currentState': array([3.39198834, 4.74755665]), 'targetState': array([0.84153786, 0.174155  ]), 'effectorPosition': array([-1.25051249,  0.71171578])}
episode index:468
target Thresh 1.294051743391691
current state at start:  [ 3.40892438 -2.9662281 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.40892438, -2.9662281 ]), 'currentState': array([2.99366639, 3.70325479]), 'targetState': array([-0.26581222, -0.29048114]), 'effectorPosition': array([-0.07345357,  0.54942015])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5799963542747091
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.40892438, -2.9662281 ]), 'currentState': array([1.29835238, 4.74219694]), 'targetState': array([-0.26581222, -0.29048114]), 'effectorPosition': array([1.23979406, 0.72285391])}
episode index:469
target Thresh 1.2954622289491882
current state at start:  [-0.0050934  -1.62577095]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.0050934 , -1.62577095]), 'currentState': array([0.4949066 , 5.15741435]), 'targetState': array([ 0.50097108, -1.1829473 ]), 'effectorPosition': array([ 1.68753105, -0.1148935 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5787623194783799
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.0050934 , -1.62577095]), 'currentState': array([3.81686805, 3.93330535]), 'targetState': array([ 0.50097108, -1.1829473 ]), 'effectorPosition': array([-0.67691294,  0.36950446])}
episode index:470
target Thresh 1.296869896354662
current state at start:  [ 3.28681107 -2.19318231]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.28681107, -2.19318231]), 'currentState': array([3.41372204, 4.590003  ]), 'targetState': array([-0.14561982,  0.2995473 ]), 'effectorPosition': array([-1.11238515,  0.72002632])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5775335247448802
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.28681107, -2.19318231]), 'currentState': array([4.91463313, 0.69743542]), 'targetState': array([-0.14561982,  0.2995473 ]), 'effectorPosition': array([ 0.98399594, -1.6014792 ])}
episode index:471
target Thresh 1.2982747512387838
current state at start:  [-1.25906929 -2.55898632]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.25906929, -2.55898632]), 'currentState': array([5.52411602, 4.16768181]), 'targetState': array([-0.00984229,  0.06608171]), 'effectorPosition': array([-0.23908463, -0.95210462])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5763099367687258
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.25906929, -2.55898632]), 'currentState': array([4.48031364, 0.86980344]), 'targetState': array([-0.00984229,  0.06608171]), 'effectorPosition': array([ 0.3653739 , -1.77664162])}
episode index:472
target Thresh 1.2996767992209746
current state at start:  [0.79817797 2.32906799]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.79817797, 2.32906799]), 'currentState': array([0.3009385, 1.861093 ]), 'targetState': array([-0.1615709,  0.1608532]), 'effectorPosition': array([0.39767177, 1.12666951])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5750915225260858
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.79817797, 2.32906799]), 'currentState': array([4.91994132, 0.97300583]), 'targetState': array([-0.1615709,  0.1608532]), 'effectorPosition': array([ 1.13088388, -1.3589469 ])}
episode index:473
target Thresh 1.3010760459094286
current state at start:  [ 1.70795708 -1.7460177 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.70795708, -1.7460177 ]), 'currentState': array([2.20632109, 4.98095274]), 'targetState': array([1.05591347, 0.64211697]), 'effectorPosition': array([0.02480223, 1.59062213])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5738782492718113
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.70795708, -1.7460177 ]), 'currentState': array([3.99387597, 5.18373416]), 'targetState': array([1.05591347, 0.64211697]), 'effectorPosition': array([-1.62787524, -0.50812655])}
episode index:474
target Thresh 1.3024724969011343
current state at start:  [1.79952887 2.29054549]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.79952887, 2.29054549]), 'currentState': array([1.30762956, 1.9746224 ]), 'targetState': array([-1.23600215,  0.04273983]), 'effectorPosition': array([-0.72998419,  0.82537508])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5726700845365023
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.79952887, 2.29054549]), 'currentState': array([4.10074903, 2.98119741]), 'targetState': array([-1.23600215,  0.04273983]), 'effectorPosition': array([ 0.12338401, -0.10221503])}
episode index:475
target Thresh 1.3038661577818977
current state at start:  [-2.63997336  2.50628801]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.63997336,  2.50628801]), 'currentState': array([4.13912879, 2.14891554]), 'targetState': array([0.04511362, 0.00700163]), 'effectorPosition': array([ 0.45761426, -0.83527819])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5714669961236104
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.63997336,  2.50628801]), 'currentState': array([4.77191385, 0.1086148 ]), 'targetState': array([0.04511362, 0.00700163]), 'effectorPosition': array([ 0.22683828, -1.98412671])}
episode index:476
target Thresh 1.305257034126364
current state at start:  [-1.5626688 -2.1486803]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.5626688, -2.1486803]), 'currentState': array([5.22051651, 4.63450501]), 'targetState': array([-1.23424426, -0.16044514]), 'effectorPosition': array([-0.42232199, -1.29074925])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5702689521065798
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.5626688, -2.1486803]), 'currentState': array([4.35452345, 2.59561992]), 'targetState': array([-1.23424426, -0.16044514]), 'effectorPosition': array([ 0.43543125, -0.31804783])}
episode index:477
target Thresh 1.3066451314980405
current state at start:  [2.22585475 1.59265922]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.22585475, 1.59265922]), 'currentState': array([1.73279922, 1.15854747]), 'targetState': array([-1.11767706,  0.08861541]), 'effectorPosition': array([-1.13014674,  1.23454847])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5690759208260221
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([2.22585475, 1.59265922]), 'currentState': array([4.61554306, 2.62179456]), 'targetState': array([-1.11767706,  0.08861541]), 'effectorPosition': array([ 0.48160593, -0.17949028])}
episode index:478
target Thresh 1.3080304554493187
current state at start:  [ 4.02995379 -2.83513662]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.02995379, -2.83513662]), 'currentState': array([4.52995379, 3.93935043]), 'targetState': array([-0.14117843,  0.06741185]), 'effectorPosition': array([-0.75864686, -0.16681752])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.567887870886928
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 4.02995379, -2.83513662]), 'currentState': array([4.0067077 , 0.65314577]), 'targetState': array([-0.14117843,  0.06741185]), 'effectorPosition': array([-0.70106389, -1.75979021])}
episode index:479
target Thresh 1.309413011521496
current state at start:  [-2.06858858 -1.77723156]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.06858858, -1.77723156]), 'currentState': array([4.69731526, 4.95416884]), 'targetState': array([-0.71753902, -0.28687766]), 'effectorPosition': array([-0.98948519, -1.22465557])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5667047711559137
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.06858858, -1.77723156]), 'currentState': array([4.26580039, 2.3449164 ]), 'targetState': array([-0.71753902, -0.28687766]), 'effectorPosition': array([ 0.51494815, -0.58021899])}
episode index:480
target Thresh 1.3107928052447981
current state at start:  [ 1.354395   -1.83111085]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.354395  , -1.83111085]), 'currentState': array([0.854395  , 4.88017489]), 'targetState': array([0.54522457, 0.70717836]), 'effectorPosition': array([1.50992231, 0.23266744])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5655265907585001
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.354395  , -1.83111085]), 'currentState': array([5.43350136, 5.41869334]), 'targetState': array([0.54522457, 0.70717836]), 'effectorPosition': array([ 0.51733173, -1.74081052])}
episode index:481
target Thresh 1.312169842138403
current state at start:  [-2.16764672 -1.92505981]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.16764672, -1.92505981]), 'currentState': array([4.61553859, 4.8581255 ]), 'targetState': array([-1.39888161, -0.00465523]), 'effectorPosition': array([-1.09550436, -1.04418032])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5643532990764285
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.16764672, -1.92505981]), 'currentState': array([4.15507136, 2.59142158]), 'targetState': array([-1.39888161, -0.00465523]), 'effectorPosition': array([ 0.36566755, -0.40176742])}
episode index:482
target Thresh 1.313544127710459
current state at start:  [ 3.58055907 -1.92641211]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.58055907, -1.92641211]), 'currentState': array([4.08055907, 4.83841237]), 'targetState': array([-0.83273834,  1.01717241]), 'effectorPosition': array([-1.46540638, -0.32243495])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5631848657450074
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.58055907, -1.92641211]), 'currentState': array([5.98782449e+00, 2.66947640e-03]), 'targetState': array([-0.83273834,  1.01717241]), 'effectorPosition': array([ 1.91416799, -0.57961521])}
episode index:483
target Thresh 1.3149156674581104
current state at start:  [-2.0221325   2.81102608]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.0221325 ,  2.81102608]), 'currentState': array([4.52709853, 2.40400739]), 'targetState': array([0.13736262, 0.26223058]), 'effectorPosition': array([ 0.61310847, -0.37935305])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5620212606504928
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.0221325 ,  2.81102608]), 'currentState': array([4.9230854, 5.7697983]), 'targetState': array([0.13736262, 0.26223058]), 'effectorPosition': array([-0.08894857, -1.93242341])}
episode index:484
target Thresh 1.3162844668675184
current state at start:  [-3.43846528  2.4887606 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.43846528,  2.4887606 ]), 'currentState': array([3.34472003, 1.9887606 ]), 'targetState': array([-0.23058452,  0.09381434]), 'effectorPosition': array([-0.39751719, -1.01497708])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5608624539275022
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.43846528,  2.4887606 ]), 'currentState': array([4.56302268, 1.24144611]), 'targetState': array([-0.23058452,  0.09381434]), 'effectorPosition': array([ 0.73877536, -1.44950593])}
episode index:485
target Thresh 1.3176505314138822
current state at start:  [-1.5552761   2.67173831]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.5552761 ,  2.67173831]), 'currentState': array([4.40722033, 2.17173831]), 'targetState': array([ 0.00399224, -0.64676247]), 'effectorPosition': array([ 0.65612298, -0.66231661])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5597084159564579
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.5552761 ,  2.67173831]), 'currentState': array([3.71061258, 4.34001495]), 'targetState': array([ 0.00399224, -0.64676247]), 'effectorPosition': array([-1.03781043,  0.44192076])}
episode index:486
target Thresh 1.3190138665614617
current state at start:  [-3.50832393  2.00323113]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.50832393,  2.00323113]), 'currentState': array([3.27486138, 1.5487411 ]), 'targetState': array([-0.35977252, -0.47720911]), 'effectorPosition': array([-0.88014847, -1.12669674])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5585591173610648
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.50832393,  2.00323113]), 'currentState': array([3.90485157, 1.54443953]), 'targetState': array([-0.35977252, -0.47720911]), 'effectorPosition': array([-0.05059004, -1.43183384])}
episode index:487
target Thresh 1.3203744777635995
current state at start:  [-3.48039672  2.42223067]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.48039672,  2.42223067]), 'currentState': array([3.27832223, 2.04688816]), 'targetState': array([-0.0200653 ,  0.08145509]), 'effectorPosition': array([-0.41548933, -0.95433241])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5574145290058167
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.48039672,  2.42223067]), 'currentState': array([4.21906534, 0.54099552]), 'targetState': array([-0.0200653 ,  0.08145509]), 'effectorPosition': array([-0.42590201, -1.87962771])}
episode index:488
target Thresh 1.3217323704627424
current state at start:  [-1.78456795 -1.79239013]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.78456795, -1.79239013]), 'currentState': array([4.9556093 , 4.93817905]), 'targetState': array([-1.2950023 , -0.46813183]), 'effectorPosition': array([-0.65118662, -1.42257122])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5562746219935348
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.78456795, -1.79239013]), 'currentState': array([4.22957471, 2.60527163]), 'targetState': array([-1.2950023 , -0.46813183]), 'effectorPosition': array([ 0.38738156, -0.36158926])}
episode index:489
target Thresh 1.3230875500904626
current state at start:  [ 1.12062934 -2.88960894]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.12062934, -2.88960894]), 'currentState': array([0.62785712, 3.89357637]), 'targetState': array([-0.30048385, -0.18836494]), 'effectorPosition': array([ 0.61949101, -0.39441143])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5551393676629358
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.12062934, -2.88960894]), 'currentState': array([4.1984153 , 1.32905093]), 'targetState': array([-0.30048385, -0.18836494]), 'effectorPosition': array([ 0.2361372 , -1.55660994])}
episode index:490
target Thresh 1.3244400220674808
current state at start:  [-4.29081802  3.02838791]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.29081802,  3.02838791]), 'currentState': array([1.49236729, 3.41440305]), 'targetState': array([-0.34351392,  0.49264913]), 'effectorPosition': array([0.27150824, 0.01575867])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5540087375862293
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-4.29081802,  3.02838791]), 'currentState': array([4.20333532, 1.31392716]), 'targetState': array([-0.34351392,  0.49264913]), 'effectorPosition': array([ 0.23339185, -1.56640851])}
episode index:491
target Thresh 1.3257897918036865
current state at start:  [-3.66540881  2.49057052]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.66540881,  2.49057052]), 'currentState': array([2.71673753, 2.03377014]), 'targetState': array([ 0.06596861, -0.48657652]), 'effectorPosition': array([-0.87298899, -0.58708478])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5528827035667451
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.66540881,  2.49057052]), 'currentState': array([3.58955901, 5.61372585]), 'targetState': array([ 0.06596861, -0.48657652]), 'effectorPosition': array([-1.87690033, -0.21344694])}
episode index:492
target Thresh 1.3271368646981603
current state at start:  [-0.00415709  2.13808521]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.00415709,  2.13808521]), 'currentState': array([5.91512082, 1.63808521]), 'targetState': array([0.33483864, 0.26979169]), 'effectorPosition': array([1.22928659, 0.59529677])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5517612376365894
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.00415709,  2.13808521]), 'currentState': array([4.54624322, 5.16698942]), 'targetState': array([0.33483864, 0.26979169]), 'effectorPosition': array([-1.12406704, -1.27070061])}
episode index:493
target Thresh 1.3284812461391957
current state at start:  [1.38644998 2.38202594]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.38644998, 2.38202594]), 'currentState': array([0.88644998, 1.88202594]), 'targetState': array([-0.0010584 , -0.00172265]), 'effectorPosition': array([-0.29902908,  1.13935192])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5506443120543291
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.38644998, 2.38202594]), 'currentState': array([2.64168973, 4.78861274]), 'targetState': array([-0.0010584 , -0.00172265]), 'effectorPosition': array([-0.46651201,  1.39092289])}
episode index:494
target Thresh 1.3298229415043206
current state at start:  [-0.48945285 -1.79643704]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.48945285, -1.79643704]), 'currentState': array([0.01054715, 4.95834183]), 'targetState': array([ 0.36705287, -0.66757836]), 'effectorPosition': array([ 1.253641  , -0.95673689])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5495318993027042
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.48945285, -1.79643704]), 'currentState': array([3.80734972, 4.07561492]), 'targetState': array([ 0.36705287, -0.66757836]), 'effectorPosition': array([-0.81542836,  0.38192532])}
episode index:495
target Thresh 1.3311619561603178
current state at start:  [-2.05162275  2.39070902]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.05162275,  2.39070902]), 'currentState': array([3.92134392, 1.98696546]), 'targetState': array([-0.00800425, -0.13959971]), 'effectorPosition': array([ 0.21946461, -1.06925965])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5484239720863681
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.05162275,  2.39070902]), 'currentState': array([5.04322585, 0.76133248]), 'targetState': array([-0.00800425, -0.13959971]), 'effectorPosition': array([ 1.21246275, -1.4063317 ])}
episode index:496
target Thresh 1.3324982954632478
current state at start:  [-1.33121827 -2.9099406 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.33121827, -2.9099406 ]), 'currentState': array([5.39203576, 3.87324471]), 'targetState': array([-0.0453475,  0.0252007]), 'effectorPosition': array([-0.35878889, -0.61897267])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.547320503329655
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.33121827, -2.9099406 ]), 'currentState': array([4.4726183 , 1.18634783]), 'targetState': array([-0.0453475,  0.0252007]), 'effectorPosition': array([ 0.57393986, -1.55585634])}
episode index:497
target Thresh 1.3338319647584695
current state at start:  [-1.69655046 -2.27859588]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.69655046, -2.27859588]), 'currentState': array([5.08663485, 4.50458943]), 'targetState': array([-0.79226051, -0.89349697]), 'effectorPosition': array([-0.62060907, -1.0964624 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.5482294983028887
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.69655046, -2.27859588]), 'currentState': array([5.08663485, 4.50458943]), 'targetState': array([-0.79226051, -0.89349697]), 'effectorPosition': array([-0.62060907, -1.0964624 ])}
episode index:498
target Thresh 1.3351629693806624
current state at start:  [ 4.22820478 -2.46986569]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.22820478, -2.46986569]), 'currentState': array([4.72820478, 4.31331962]), 'targetState': array([-0.6851435,  0.6960886]), 'effectorPosition': array([-0.91163777, -0.62593496])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5471308419936645
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 4.22820478, -2.46986569]), 'currentState': array([4.91704986, 2.36858591]), 'targetState': array([-0.6851435,  0.6960886]), 'effectorPosition': array([ 0.74147382, -0.13633752])}
episode index:499
target Thresh 1.3364913146538462
current state at start:  [-1.47733851  2.688465  ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.47733851,  2.688465  ]), 'currentState': array([4.31957876, 2.188465  ]), 'targetState': array([0.22904792, 0.43727135]), 'effectorPosition': array([ 0.59203957, -0.70086862])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.546036580309677
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.47733851,  2.688465  ]), 'currentState': array([4.87551754, 0.97934269]), 'targetState': array([0.22904792, 0.43727135]), 'effectorPosition': array([ 1.07206872, -1.40207179])}
episode index:500
target Thresh 1.3378170058914036
current state at start:  [1.23303186 3.02997771]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.23303186, 3.02997771]), 'currentState': array([0.73607128, 2.52997771]), 'targetState': array([-0.22848487,  0.0654408 ]), 'effectorPosition': array([-0.25115336,  0.54724619])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.5469426949198374
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.23303186, 3.02997771]), 'currentState': array([0.73607128, 2.52997771]), 'targetState': array([-0.22848487,  0.0654408 ]), 'effectorPosition': array([-0.25115336,  0.54724619])}
episode index:501
target Thresh 1.3391400483961022
current state at start:  [ 0.90011346 -2.63604824]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.90011346, -2.63604824]), 'currentState': array([1.40011346, 4.09711974]), 'targetState': array([ 0.09644254, -0.66764879]), 'effectorPosition': array([0.87657031, 0.27797064])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5458531676391206
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.90011346, -2.63604824]), 'currentState': array([3.25811504, 4.63658081]), 'targetState': array([ 0.09644254, -0.66764879]), 'effectorPosition': array([-1.03392192,  0.8829124 ])}
episode index:502
target Thresh 1.340460447460113
current state at start:  [-0.30014867  2.40509461]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.30014867,  2.40509461]), 'currentState': array([5.52156815, 1.90509461]), 'targetState': array([0.00869676, 0.36393318]), 'effectorPosition': array([1.13815322, 0.21998745])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5447679724748281
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.30014867,  2.40509461]), 'currentState': array([5.428314  , 0.77854258]), 'targetState': array([0.00869676, 0.36393318]), 'effectorPosition': array([ 1.65340399, -0.83074108])}
episode index:503
target Thresh 1.3417782083650343
current state at start:  [ 1.68910689 -2.94509975]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.68910689, -2.94509975]), 'currentState': array([1.22079755, 3.79880967]), 'targetState': array([-0.18685118,  0.31677068]), 'effectorPosition': array([ 0.64530495, -0.01380535])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5436870836405527
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.68910689, -2.94509975]), 'currentState': array([4.31869405, 1.04267018]), 'targetState': array([-0.18685118,  0.31677068]), 'effectorPosition': array([ 0.22076702, -1.72020152])}
episode index:504
target Thresh 1.3430933363819113
current state at start:  [ 2.02684127 -1.87750966]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.02684127, -1.87750966]), 'currentState': array([1.52684127, 4.88307529]), 'targetState': array([0.24001549, 1.02829795]), 'effectorPosition': array([1.03592124, 1.12542643])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5426104755541358
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.02684127, -1.87750966]), 'currentState': array([5.07787778, 0.77812839]), 'targetState': array([0.24001549, 1.02829795]), 'effectorPosition': array([ 1.26754392, -1.34825425])}
episode index:505
target Thresh 1.3444058367712581
current state at start:  [-2.53390279  1.70160318]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.53390279,  1.70160318]), 'currentState': array([4.11326638, 1.74078889]), 'targetState': array([-0.33823469, -1.27051412]), 'effectorPosition': array([ 0.34540997, -1.24191059])}
done in step count: 15
reward sum = 0.8600583546412884
running average episode reward sum: 0.5432378429041104
{'reset': False, 'endBeforeDone': False, 'stepCount': 16, 'initial state': array([-2.53390279,  1.70160318]), 'currentState': array([4.18158505, 1.23657318]), 'targetState': array([-0.33823469, -1.27051412]), 'effectorPosition': array([ 0.14239269, -1.62351321])}
episode index:506
target Thresh 1.3457157147830778
current state at start:  [0.03588113 2.99659745]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.03588113, 2.99659745]), 'currentState': array([0.53588113, 2.51711113]), 'targetState': array([ 0.32031408, -0.37247886]), 'effectorPosition': array([-0.13625849,  0.59908337])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5421663678687966
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.03588113, 2.99659745]), 'currentState': array([3.09316882, 4.79903784]), 'targetState': array([ 0.32031408, -0.37247886]), 'effectorPosition': array([-1.03704352,  1.04767442])}
episode index:507
target Thresh 1.3470229756568841
current state at start:  [ 1.87913577 -2.72303914]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.87913577, -2.72303914]), 'currentState': array([1.89751456, 4.06014616]), 'targetState': array([ 0.07878778, -0.11436613]), 'effectorPosition': array([0.62654649, 0.62729482])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5410991112391336
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.87913577, -2.72303914]), 'currentState': array([4.54192943, 0.84248675]), 'targetState': array([ 0.07878778, -0.11436613]), 'effectorPosition': array([ 0.45293841, -1.76806811])}
episode index:508
target Thresh 1.3483276246217226
current state at start:  [-3.8129599   2.22177077]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.8129599 ,  2.22177077]), 'currentState': array([2.91437318, 2.48945806]), 'targetState': array([-0.88391441,  0.27897632]), 'effectorPosition': array([-0.33664767, -0.54505782])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5400360481522197
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.8129599 ,  2.22177077]), 'currentState': array([4.73272714, 2.48971289]), 'targetState': array([-0.88391441,  0.27897632]), 'effectorPosition': array([ 0.61072647, -0.19267486])}
episode index:509
target Thresh 1.3496296668961907
current state at start:  [ 3.57458219 -1.5955523 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.57458219, -1.5955523 ]), 'currentState': array([4.06429014, 5.18763301]), 'targetState': array([-1.29177488, -0.03175246]), 'effectorPosition': array([-1.5887696 , -0.62523759])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5389771539401566
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.57458219, -1.5955523 ]), 'currentState': array([4.07272139, 2.55062689]), 'targetState': array([-1.29177488, -0.03175246]), 'effectorPosition': array([ 0.34577152, -0.4686535 ])}
episode index:510
target Thresh 1.350929107688459
current state at start:  [1.03191993 2.28540138]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.03191993, 2.28540138]), 'currentState': array([0.53191993, 1.78540138]), 'targetState': array([-0.11161   ,  0.02069769]), 'effectorPosition': array([0.18274287, 1.24124209])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5379224041281406
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.03191993, 2.28540138]), 'currentState': array([2.07124388, 5.14232149]), 'targetState': array([-0.11161   ,  0.02069769]), 'effectorPosition': array([0.11771102, 1.679215  ])}
episode index:511
target Thresh 1.3522259521962927
current state at start:  [1.60924844 1.88355205]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.60924844, 1.88355205]), 'currentState': array([1.10924844, 1.39097534]), 'targetState': array([-1.34548006,  0.40040085]), 'effectorPosition': array([-0.35594296,  1.4936571 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5368717744325778
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.60924844, 1.88355205]), 'currentState': array([5.96203282, 5.78538845]), 'targetState': array([-1.34548006,  0.40040085]), 'effectorPosition': array([ 1.63186127, -1.04608897])}
episode index:512
target Thresh 1.3535202056070719
current state at start:  [0.41292884 3.10887154]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.41292884, 3.10887154]), 'currentState': array([0.22776212, 3.32399138]), 'targetState': array([-0.08109297,  0.13741927]), 'effectorPosition': array([ 0.05711745, -0.17295883])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.5377745584980114
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.41292884, 3.10887154]), 'currentState': array([0.22776212, 3.32399138]), 'targetState': array([-0.08109297,  0.13741927]), 'effectorPosition': array([ 0.05711745, -0.17295883])}
episode index:513
target Thresh 1.3548118730978111
current state at start:  [1.997662   2.01128838]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.997662  , 2.01128838]), 'currentState': array([1.5495347 , 1.55750007]), 'targetState': array([-0.81080746,  0.44046771]), 'effectorPosition': array([-0.97814291,  1.03432499])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5367283044931515
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.997662  , 2.01128838]), 'currentState': array([4.40273976, 2.78462777]), 'targetState': array([-0.81080746,  0.44046771]), 'effectorPosition': array([ 0.31360394, -0.16652076])}
episode index:514
target Thresh 1.3561009598351825
current state at start:  [-1.2479667   2.26701177]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.2479667 ,  2.26701177]), 'currentState': array([4.53521861, 1.78327466]), 'targetState': array([0.97444289, 0.15732177]), 'effectorPosition': array([ 0.82313179, -0.94904572])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5356861136106404
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.2479667 ,  2.26701177]), 'currentState': array([3.08338348, 4.54783582]), 'targetState': array([0.97444289, 0.15732177]), 'effectorPosition': array([-0.77738178,  1.03346721])}
episode index:515
target Thresh 1.3573874709755347
current state at start:  [ 2.23885915 -2.87924949]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.23885915, -2.87924949]), 'currentState': array([2.65917412, 3.90393582]), 'targetState': array([0.41630312, 0.14850298]), 'effectorPosition': array([0.07520076, 0.74020627])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5346479622276741
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.23885915, -2.87924949]), 'currentState': array([4.22158155, 4.39435995]), 'targetState': array([0.41630312, 0.14850298]), 'effectorPosition': array([-1.16167886, -0.15846815])}
episode index:516
target Thresh 1.3586714116649141
current state at start:  [-3.06366239  1.6744939 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.06366239,  1.6744939 ]), 'currentState': array([3.7076348 , 1.24758168]), 'targetState': array([-0.6334648 , -0.87046313]), 'effectorPosition': array([-0.60358203, -1.5069577 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5336138269042163
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.06366239,  1.6744939 ]), 'currentState': array([4.58157314, 1.88900485]), 'targetState': array([-0.6334648 , -0.87046313]), 'effectorPosition': array([ 0.85205026, -0.80515794])}
episode index:517
target Thresh 1.3599527870390848
current state at start:  [0.14167189 2.76277224]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.14167189, 2.76277224]), 'currentState': array([6.00236186, 2.38659868]), 'targetState': array([-0.42649139,  0.39923516]), 'effectorPosition': array([0.45100465, 0.58313245])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5325836843812353
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.14167189, 2.76277224]), 'currentState': array([4.68866352, 0.98299489]), 'targetState': array([-0.42649139,  0.39923516]), 'effectorPosition': array([ 0.79504911, -1.57383688])}
episode index:518
target Thresh 1.3612316022235507
current state at start:  [-1.16357272 -2.7579724 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.16357272, -2.7579724 ]), 'currentState': array([5.61147187, 3.27123745]), 'targetState': array([ 0.17385437, -0.72667396]), 'effectorPosition': array([-0.07388679, -0.10641892])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5315575115789593
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.16357272, -2.7579724 ]), 'currentState': array([3.67322383, 3.83689379]), 'targetState': array([ 0.17385437, -0.72667396]), 'effectorPosition': array([-0.5248539 ,  0.43451897])}
episode index:519
target Thresh 1.3625078623335736
current state at start:  [2.24619381 1.74189262]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.24619381, 1.74189262]), 'currentState': array([1.74619381, 1.24189262]), 'targetState': array([-0.63055442, -0.59397534]), 'effectorPosition': array([-1.16274058,  1.13756131])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5305352855951535
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([2.24619381, 1.74189262]), 'currentState': array([1.85883992, 5.17191946]), 'targetState': array([-0.63055442, -0.59397534]), 'effectorPosition': array([0.44926336, 1.63866321])}
episode index:520
target Thresh 1.3637815724741957
current state at start:  [ 1.67910412 -2.89312504]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.67910412, -2.89312504]), 'currentState': array([2.1236004 , 2.97743585]), 'targetState': array([0.68256112, 0.38531065]), 'effectorPosition': array([-0.1461388 , -0.07436699])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5295169837034163
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.67910412, -2.89312504]), 'currentState': array([3.47530954, 5.11884254]), 'targetState': array([0.68256112, 0.38531065]), 'effectorPosition': array([-1.61924515,  0.4107965 ])}
episode index:521
target Thresh 1.3650527377402595
current state at start:  [ 2.84354519 -2.67672788]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.84354519, -2.67672788]), 'currentState': array([2.34354519, 4.10645742]), 'targetState': array([-0.10275435, -0.02674889]), 'effectorPosition': array([0.28801218, 0.88203906])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5285025833514939
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.84354519, -2.67672788]), 'currentState': array([1.97546684, 5.34520072]), 'targetState': array([-0.10275435, -0.02674889]), 'effectorPosition': array([0.11467407, 1.78035913])}
episode index:522
target Thresh 1.3663213632164277
current state at start:  [-0.02773526 -2.96652584]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.02773526, -2.96652584]), 'currentState': array([0.47226474, 2.8714269 ]), 'targetState': array([ 0.36361685, -0.4002408 ]), 'effectorPosition': array([-0.08910708,  0.25417825])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5274920621596173
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.02773526, -2.96652584]), 'currentState': array([3.08790381, 4.06479933]), 'targetState': array([ 0.36361685, -0.4002408 ]), 'effectorPosition': array([-0.3533641 ,  0.81768099])}
episode index:523
target Thresh 1.367587453977204
current state at start:  [-1.96777003  2.85275521]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.96777003,  2.85275521]), 'currentState': array([4.31253119, 2.35275521]), 'targetState': array([-0.01649218,  0.00971027]), 'effectorPosition': array([ 0.5385959 , -0.54824551])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5264853979188546
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.96777003,  2.85275521]), 'currentState': array([3.92447987, 1.11951414]), 'targetState': array([-0.01649218,  0.00971027]), 'effectorPosition': array([-0.38331903, -1.65085007])}
episode index:524
target Thresh 1.3688510150869528
current state at start:  [-1.60655581  3.09341916]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.60655581,  3.09341916]), 'currentState': array([4.51653515, 2.60509395]), 'targetState': array([-0.61848597, -0.62730672]), 'effectorPosition': array([ 0.47401672, -0.23727836])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5254825685894854
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.60655581,  3.09341916]), 'currentState': array([3.97149141, 1.88574379]), 'targetState': array([-0.61848597, -0.62730672]), 'effectorPosition': array([ 0.2356961 , -1.15104922])}
episode index:525
target Thresh 1.3701120515999206
current state at start:  [ 1.1114925  -2.34147072]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.1114925 , -2.34147072]), 'currentState': array([1.60300036, 4.44171458]), 'targetState': array([0.52652515, 0.33974382]), 'effectorPosition': array([0.93950197, 0.76326494])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.526384692983802
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.1114925 , -2.34147072]), 'currentState': array([1.60300036, 4.44171458]), 'targetState': array([0.52652515, 0.33974382]), 'effectorPosition': array([0.93950197, 0.76326494])}
episode index:526
target Thresh 1.3713705685602546
current state at start:  [1.64705386 1.95115222]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.64705386, 1.95115222]), 'currentState': array([1.14705386, 1.51506136]), 'targetState': array([-0.79314329,  0.08413178]), 'effectorPosition': array([-0.47606131,  1.37287212])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5253858605492976
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.64705386, 1.95115222]), 'currentState': array([4.64382173, 2.15720186]), 'targetState': array([-0.79314329,  0.08413178]), 'effectorPosition': array([ 0.80037773, -0.50264719])}
episode index:527
target Thresh 1.3726265710020247
current state at start:  [-0.53292055 -2.59866006]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.53292055, -2.59866006]), 'currentState': array([6.25026475, 4.18452525]), 'targetState': array([-0.26882006, -0.46173888]), 'effectorPosition': array([ 0.46760764, -0.87975286])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5243908115709845
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.53292055, -2.59866006]), 'currentState': array([3.1287512 , 4.70002951]), 'targetState': array([-0.26882006, -0.46173888]), 'effectorPosition': array([-0.9747193 ,  1.01252357])}
episode index:528
target Thresh 1.3738800639492426
current state at start:  [1.54446509 1.98775822]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.54446509, 1.98775822]), 'currentState': array([1.04446509, 1.48775822]), 'targetState': array([-1.04294108,  0.84220837]), 'effectorPosition': array([-0.31764462,  1.43700637])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5233995245925895
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.54446509, 1.98775822]), 'currentState': array([4.70706246, 1.59026167]), 'targetState': array([-1.04294108,  0.84220837]), 'effectorPosition': array([ 0.99457355, -0.98584747])}
episode index:529
target Thresh 1.3751310524158815
current state at start:  [-2.49191219  2.56276035]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.49191219,  2.56276035]), 'currentState': array([3.94665927, 2.12005833]), 'targetState': array([ 0.01795097, -0.58624609]), 'effectorPosition': array([ 0.28359899, -0.93565793])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.5242987707726035
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.49191219,  2.56276035]), 'currentState': array([3.94665927, 2.12005833]), 'targetState': array([ 0.01795097, -0.58624609]), 'effectorPosition': array([ 0.28359899, -0.93565793])}
episode index:530
target Thresh 1.3763795414058966
current state at start:  [ 1.05378416 -1.91869337]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.05378416, -1.91869337]), 'currentState': array([1.09380446, 4.86449194]), 'targetState': array([0.49248699, 0.69903623]), 'effectorPosition': array([1.40679509, 0.56917649])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5233113907899809
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.05378416, -1.91869337]), 'currentState': array([4.07727813, 0.75069484]), 'targetState': array([0.49248699, 0.69903623]), 'effectorPosition': array([-0.47793994, -1.79833354])}
episode index:531
target Thresh 1.3776255359132459
current state at start:  [-1.97363364 -1.72607668]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.97363364, -1.72607668]), 'currentState': array([4.80955167, 5.05710863]), 'targetState': array([-1.3028868 ,  0.04371375]), 'effectorPosition': array([-0.80693842, -1.42292518])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5223277227621802
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.97363364, -1.72607668]), 'currentState': array([4.6856788 , 2.66575994]), 'targetState': array([-1.3028868 ,  0.04371375]), 'effectorPosition': array([ 0.45494858, -0.12328271])}
episode index:532
target Thresh 1.3788690409219093
current state at start:  [-0.05250834 -2.1754985 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.05250834, -2.1754985 ]), 'currentState': array([0.34687294, 4.56899383]), 'targetState': array([-0.20328507, -0.38973171]), 'effectorPosition': array([ 1.14251696, -0.63941107])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5213477457963974
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.05250834, -2.1754985 ]), 'currentState': array([2.45758684, 4.23959015]), 'targetState': array([-0.20328507, -0.38973171]), 'effectorPosition': array([0.14047474, 1.03416978])}
episode index:533
target Thresh 1.380110061405908
current state at start:  [-0.0836744   2.14546575]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.0836744 ,  2.14546575]), 'currentState': array([5.71084363, 1.64546575]), 'targetState': array([0.38040096, 0.80162258]), 'effectorPosition': array([1.31801647, 0.33709414])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5203714391563293
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.0836744 ,  2.14546575]), 'currentState': array([4.46399526, 5.6208604 ]), 'targetState': array([0.38040096, 0.80162258]), 'effectorPosition': array([-1.03579189, -1.5824868 ])}
episode index:534
target Thresh 1.3813486023293258
current state at start:  [ 3.19291652 -2.0106369 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.19291652, -2.0106369 ]), 'currentState': array([2.73604885, 4.74668679]), 'targetState': array([-1.21479226,  0.41285953]), 'effectorPosition': array([-0.55611117,  1.32639456])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.51939878226071
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.19291652, -2.0106369 ]), 'currentState': array([5.95890777, 4.31744675]), 'targetState': array([-1.21479226,  0.41285953]), 'effectorPosition': array([ 0.28908328, -1.07094403])}
episode index:535
target Thresh 1.3825846686463281
current state at start:  [ 0.60962943 -2.42465348]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.60962943, -2.42465348]), 'currentState': array([1.10118015, 3.62344707]), 'targetState': array([0.96616834, 0.16530077]), 'effectorPosition': array([ 0.46478198, -0.10818307])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5184297546818654
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.60962943, -2.42465348]), 'currentState': array([3.5527248 , 4.17971375]), 'targetState': array([0.96616834, 0.16530077]), 'effectorPosition': array([-0.79542489,  0.59297534])}
episode index:536
target Thresh 1.3838182653011817
current state at start:  [-1.95269089  1.78612604]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.95269089,  1.78612604]), 'currentState': array([3.83049442, 1.31274947]), 'targetState': array([ 0.43550558, -1.06597633]), 'effectorPosition': array([-0.35429688, -1.54429882])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5174643361442828
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.95269089,  1.78612604]), 'currentState': array([3.27229859, 3.50138781]), 'targetState': array([ 0.43550558, -1.06597633]), 'effectorPosition': array([-0.10937321,  0.34073387])}
episode index:537
target Thresh 1.385049397228275
current state at start:  [-2.32383728  2.32885092]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.32383728,  2.32885092]), 'currentState': array([3.45934803, 2.38005568]), 'targetState': array([ 0.63741126, -0.71784659]), 'effectorPosition': array([-0.04680465, -0.74179291])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5165025065231967
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.32383728,  2.32885092]), 'currentState': array([3.65818618, 4.20957411]), 'targetState': array([ 0.63741126, -0.71784659]), 'effectorPosition': array([-0.88328497,  0.50598401])}
episode index:538
target Thresh 1.3862780693521373
current state at start:  [-3.01484124  2.34838806]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.01484124,  2.34838806]), 'currentState': array([3.71000277, 1.92306528]), 'targetState': array([-0.10796061, -0.10954138]), 'effectorPosition': array([-0.04674503, -1.14357259])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5155442458431908
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.01484124,  2.34838806]), 'currentState': array([4.00429048, 1.33328413]), 'targetState': array([-0.10796061, -0.10954138]), 'effectorPosition': array([-0.06514278, -1.57045446])}
episode index:539
target Thresh 1.3875042865874585
current state at start:  [ 0.85778658 -2.63544147]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.85778658, -2.63544147]), 'currentState': array([1.35778658, 4.14774384]), 'targetState': array([-0.06015236, -0.09560843]), 'effectorPosition': array([0.92396343, 0.27578876])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5145895342768145
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.85778658, -2.63544147]), 'currentState': array([2.34397336, 4.46651789]), 'targetState': array([-0.06015236, -0.09560843]), 'effectorPosition': array([0.16575333, 1.21890247])}
episode index:540
target Thresh 1.3887280538391096
current state at start:  [ 0.61494492 -2.71880729]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.61494492, -2.71880729]), 'currentState': array([1.11494492, 3.06437802]), 'targetState': array([ 0.20316441, -0.79298   ]), 'effectorPosition': array([-0.06794942,  0.03663351])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.513638352143216
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.61494492, -2.71880729]), 'currentState': array([3.84150295, 4.20105686]), 'targetState': array([ 0.20316441, -0.79298   ]), 'effectorPosition': array([-0.95236243,  0.3381227 ])}
episode index:541
target Thresh 1.389949376002161
current state at start:  [0.66366657 1.64563245]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.66366657, 1.64563245]), 'currentState': array([0.20263909, 1.14563245]), 'targetState': array([0.04869186, 1.27613331]), 'effectorPosition': array([1.20023171, 1.17659848])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5126906799067894
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.66366657, 1.64563245]), 'currentState': array([3.95342472, 1.35709614]), 'targetState': array([0.04869186, 1.27613331]), 'effectorPosition': array([-0.12507068, -1.55193816])}
episode index:542
target Thresh 1.391168257961903
current state at start:  [-0.64363069 -2.21188732]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.64363069, -2.21188732]), 'currentState': array([6.11181658, 4.57129799]), 'targetState': array([-0.24631497, -0.44997746]), 'effectorPosition': array([ 0.6779521 , -1.12211152])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5117464981758376
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.64363069, -2.21188732]), 'currentState': array([2.88281708, 4.64484172]), 'targetState': array([-0.24631497, -0.44997746]), 'effectorPosition': array([-0.64614194,  1.20312459])}
episode index:543
target Thresh 1.3923847045938649
current state at start:  [ 4.17136106 -2.27276891]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.17136106, -2.27276891]), 'currentState': array([4.62204569, 4.46114517]), 'targetState': array([-0.70642126,  0.70253708]), 'effectorPosition': array([-1.03244464, -0.6609389 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5108057877012497
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 4.17136106, -2.27276891]), 'currentState': array([4.78389825, 2.51068454]), 'targetState': array([-0.70642126,  0.70253708]), 'effectorPosition': array([ 0.60212511, -0.14987002])}
episode index:544
target Thresh 1.3935987207638352
current state at start:  [-2.16590172  1.83479   ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.16590172,  1.83479   ]), 'currentState': array([3.72307187, 1.39447332]), 'targetState': array([-0.21979585, -0.74755922]), 'effectorPosition': array([-0.44148875, -1.46830148])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5098685293751923
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.16590172,  1.83479   ]), 'currentState': array([4.24503318, 1.3627038 ]), 'targetState': array([-0.21979585, -0.74755922]), 'effectorPosition': array([ 0.3298995 , -1.51800995])}
episode index:545
target Thresh 1.39481031132788
current state at start:  [ 4.11509542 -2.52286469]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.11509542, -2.52286469]), 'currentState': array([4.36873262, 3.31839014]), 'targetState': array([-0.74232425, -0.35655878]), 'effectorPosition': array([-0.17084623,  0.04458231])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5089347042298166
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 4.11509542, -2.52286469]), 'currentState': array([3.92978717, 1.88503789]), 'targetState': array([-0.74232425, -0.35655878]), 'effectorPosition': array([ 0.18718301, -1.16050506])}
episode index:546
target Thresh 1.3960194811323632
current state at start:  [ 1.75113075 -2.44552012]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.75113075, -2.44552012]), 'currentState': array([1.66039266, 4.18171816]), 'targetState': array([-0.00608373,  0.03976105]), 'effectorPosition': array([0.81481696, 0.56907757])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5080042934359777
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.75113075, -2.44552012]), 'currentState': array([2.58418394, 4.3504295 ]), 'targetState': array([-0.00608373,  0.03976105]), 'effectorPosition': array([-0.05341002,  1.13531164])}
episode index:547
target Thresh 1.3972262350139655
current state at start:  [-2.85509738  2.35429995]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.85509738,  2.35429995]), 'currentState': array([3.92808792, 1.98113768]), 'targetState': array([-0.06683659, -0.5456573 ]), 'effectorPosition': array([ 0.22455757, -1.07318646])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5070772783019706
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.85509738,  2.35429995]), 'currentState': array([4.39141477, 0.17090557]), 'targetState': array([-0.06683659, -0.5456573 ]), 'effectorPosition': array([-0.46499717, -1.93768933])}
episode index:548
target Thresh 1.3984305777997044
current state at start:  [ 3.09102548 -1.83631633]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.09102548, -1.83631633]), 'currentState': array([3.54369236, 4.94686898]), 'targetState': array([-0.06724271,  1.16164903]), 'effectorPosition': array([-1.51468985,  0.4127822 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5061536402722767
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.09102548, -1.83631633]), 'currentState': array([4.49360132, 2.03532204]), 'targetState': array([-0.06724271,  1.16164903]), 'effectorPosition': array([ 0.7529117 , -0.73288903])}
episode index:549
target Thresh 1.3996325143069521
current state at start:  [ 2.71541763 -2.55970244]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.71541763, -2.55970244]), 'currentState': array([2.24215386, 4.22348287]), 'targetState': array([-0.26900259,  0.38259444]), 'effectorPosition': array([0.36135239, 0.96441878])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5052333609263271
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.71541763, -2.55970244]), 'currentState': array([1.378281  , 5.57229798]), 'targetState': array([-0.26900259,  0.38259444]), 'effectorPosition': array([0.97676585, 1.60046707])}
episode index:550
target Thresh 1.4008320493434567
current state at start:  [-2.19954876  1.92515799]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.19954876,  1.92515799]), 'currentState': array([3.58363654, 1.47023168]), 'targetState': array([ 0.3083505 , -1.17002917]), 'effectorPosition': array([-0.56899791, -1.37004811])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5043164219772776
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.19954876,  1.92515799]), 'currentState': array([3.76662723, 4.07512084]), 'targetState': array([ 0.3083505 , -1.17002917]), 'effectorPosition': array([-0.79870962,  0.41479986])}
episode index:551
target Thresh 1.40202918770736
current state at start:  [1.38274125 2.05125571]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.38274125, 2.05125571]), 'currentState': array([0.88274125, 1.5536348 ]), 'targetState': array([-1.26460937,  0.35520008]), 'effectorPosition': array([-0.1264352 ,  1.42068135])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.503402805270797
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.38274125, 2.05125571]), 'currentState': array([4.65753772, 2.71143636]), 'targetState': array([-1.26460937,  0.35520008]), 'effectorPosition': array([ 0.41139128, -0.11382462])}
episode index:552
target Thresh 1.4032239341872166
current state at start:  [ 0.77151695 -1.99703244]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.77151695, -1.99703244]), 'currentState': array([1.21301249, 4.68290314]), 'targetState': array([1.24653396, 0.10385348]), 'effectorPosition': array([1.27614292, 0.55901351])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.504300811047884
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.77151695, -1.99703244]), 'currentState': array([1.21301249, 4.68290314]), 'targetState': array([1.24653396, 0.10385348]), 'effectorPosition': array([1.27614292, 0.55901351])}
episode index:553
target Thresh 1.4044162935620141
current state at start:  [-3.45541759  2.06646081]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.45541759,  2.06646081]), 'currentState': array([3.29371815, 1.56646081]), 'targetState': array([-0.25889008, -0.46582773]), 'effectorPosition': array([-0.84119865, -1.14063834])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5033905207752344
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.45541759,  2.06646081]), 'currentState': array([4.04587702, 1.32686808]), 'targetState': array([-0.25889008, -0.46582773]), 'effectorPosition': array([-0.00485007, -1.57575676])}
episode index:554
target Thresh 1.405606270601192
current state at start:  [0.11589385 2.52105467]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.11589385, 2.52105467]), 'currentState': array([5.89941408, 2.13443605]), 'targetState': array([-0.50998896,  0.78757088]), 'effectorPosition': array([0.74835902, 0.6094472 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5024835108278917
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.11589385, 2.52105467]), 'currentState': array([4.48104589, 1.84789839]), 'targetState': array([-0.50998896,  0.78757088]), 'effectorPosition': array([ 0.7696682 , -0.92761632])}
episode index:555
target Thresh 1.4067938700646598
current state at start:  [1.70350405 1.69418959]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.70350405, 1.69418959]), 'currentState': array([1.22539493, 1.245618  ]), 'targetState': array([-0.91147329,  0.1383466 ]), 'effectorPosition': array([-0.44488715,  1.56237991])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5015797635062588
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.70350405, 1.69418959]), 'currentState': array([4.28131605, 2.39717644]), 'targetState': array([-0.91147329,  0.1383466 ]), 'effectorPosition': array([ 0.50503249, -0.52342625])}
episode index:556
target Thresh 1.4079790967028167
current state at start:  [1.05291997 2.29774834]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.05291997, 2.29774834]), 'currentState': array([0.55291997, 1.79774834]), 'targetState': array([-0.28455222,  0.24183594]), 'effectorPosition': array([0.14780626, 1.23617791])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5006792612378453
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.05291997, 2.29774834]), 'currentState': array([3.92034759, 1.44521339]), 'targetState': array([-0.28455222,  0.24183594]), 'effectorPosition': array([-0.10408008, -1.49655389])}
episode index:557
target Thresh 1.4091619552565713
current state at start:  [ 2.87398381 -2.37334647]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.87398381, -2.37334647]), 'currentState': array([2.37398381, 4.40983883]), 'targetState': array([-0.51056048,  0.46597103]), 'effectorPosition': array([0.15770365, 1.17440137])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.49978198657612877
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.87398381, -2.37334647]), 'currentState': array([4.39664882, 1.5346261 ]), 'targetState': array([-0.51056048,  0.46597103]), 'effectorPosition': array([ 0.62819581, -1.29525855])}
episode index:558
target Thresh 1.410342450457359
current state at start:  [ 4.62432797 -3.07335164]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.62432797, -3.07335164]), 'currentState': array([5.08695747, 3.17772952]), 'targetState': array([-0.04091722, -0.00054214]), 'effectorPosition': array([-0.03338516, -0.01382615])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.5006768309650802
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.62432797, -3.07335164]), 'currentState': array([5.08695747, 3.17772952]), 'targetState': array([-0.04091722, -0.00054214]), 'effectorPosition': array([-0.03338516, -0.01382615])}
episode index:559
target Thresh 1.4115205870271623
current state at start:  [-1.83790884 -1.71818978]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.83790884, -1.71818978]), 'currentState': array([4.94317958, 4.9774285 ]), 'targetState': array([-0.77669278, -1.10199471]), 'effectorPosition': array([-0.65082684, -1.44924782])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.501568479481214
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.83790884, -1.71818978]), 'currentState': array([4.94317958, 4.9774285 ]), 'targetState': array([-0.77669278, -1.10199471]), 'effectorPosition': array([-0.65082684, -1.44924782])}
episode index:560
target Thresh 1.412696369678529
current state at start:  [ 2.37244555 -3.02098371]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.37244555, -3.02098371]), 'currentState': array([2.87244555, 2.93856027]), 'targetState': array([0.44738193, 0.63872778]), 'effectorPosition': array([-0.07341893, -0.18891903])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5006744180204632
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.37244555, -3.02098371]), 'currentState': array([5.06365597, 0.62614187]), 'targetState': array([0.44738193, 0.63872778]), 'effectorPosition': array([ 1.17313897, -1.49811012])}
episode index:561
target Thresh 1.4138698031145913
current state at start:  [-2.23275026  2.69955261]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.23275026,  2.69955261]), 'currentState': array([3.87490381, 2.57097452]), 'targetState': array([ 0.54708973, -0.14808659]), 'effectorPosition': array([ 0.24383244, -0.50735711])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.5015628977037008
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.23275026,  2.69955261]), 'currentState': array([3.87490381, 2.57097452]), 'targetState': array([ 0.54708973, -0.14808659]), 'effectorPosition': array([ 0.24383244, -0.50735711])}
episode index:562
target Thresh 1.4150408920290847
current state at start:  [ 1.35260687 -2.95212061]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.35260687, -2.95212061]), 'currentState': array([0.86373732, 3.8310647 ]), 'targetState': array([-0.33186265,  0.0096913 ]), 'effectorPosition': array([ 0.63201456, -0.23956972])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5006720222193248
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.35260687, -2.95212061]), 'currentState': array([2.03717603, 5.5661992 ]), 'targetState': array([-0.33186265,  0.0096913 ]), 'effectorPosition': array([-0.20166412,  1.86196424])}
episode index:563
target Thresh 1.416209641106366
current state at start:  [ 2.49871579 -1.9889404 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.49871579, -1.9889404 ]), 'currentState': array([2.03883875, 4.78971701]), 'targetState': array([0.14442579, 1.18109034]), 'effectorPosition': array([0.40379508, 1.41118798])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.5015573555132622
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.49871579, -1.9889404 ]), 'currentState': array([2.03883875, 4.78971701]), 'targetState': array([0.14442579, 1.18109034]), 'effectorPosition': array([0.40379508, 1.41118798])}
episode index:564
target Thresh 1.4173760550214336
current state at start:  [ 0.0854939  -1.99587923]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.0854939 , -1.99587923]), 'currentState': array([0.5854939 , 4.78730608]), 'targetState': array([ 0.02953843, -0.64475405]), 'effectorPosition': array([ 1.44688074, -0.2371291 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.5006696433796104
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.0854939 , -1.99587923]), 'currentState': array([3.35155477, 3.81353415]), 'targetState': array([ 0.02953843, -0.64475405]), 'effectorPosition': array([-0.34235601,  0.56352752])}
episode index:565
target Thresh 1.4185401384399445
current state at start:  [-1.55721651 -2.04310315]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.55721651, -2.04310315]), 'currentState': array([5.20993187, 4.72361012]), 'targetState': array([-1.00484586, -0.95459148]), 'effectorPosition': array([-0.39607944, -1.3658561 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.49978506803795025
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.55721651, -2.04310315]), 'currentState': array([2.20954408, 4.3155236 ]), 'targetState': array([-1.00484586, -0.95459148]), 'effectorPosition': array([0.37469826, 1.04237359])}
episode index:566
target Thresh 1.4197018960182342
current state at start:  [ 2.65002478 -2.44607121]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.65002478, -2.44607121]), 'currentState': array([3.14256538, 4.32541326]), 'targetState': array([0.60054807, 0.25084833]), 'effectorPosition': array([-0.623511  ,  0.92544856])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.49890361289149887
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.65002478, -2.44607121]), 'currentState': array([1.15140576, 6.10387308]), 'targetState': array([0.60054807, 0.25084833]), 'effectorPosition': array([0.97077529, 1.73940464])}
episode index:567
target Thresh 1.4208613324033337
current state at start:  [-1.66751613 -2.87645262]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.66751613, -2.87645262]), 'currentState': array([5.11566917, 3.90673268]), 'targetState': array([ 0.15189763, -0.0793229 ]), 'effectorPosition': array([-0.5276956, -0.5281729])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.49802526146035186
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.66751613, -2.87645262]), 'currentState': array([2.5934758 , 4.56383273]), 'targetState': array([ 0.15189763, -0.0793229 ]), 'effectorPosition': array([-0.21183774,  1.28806207])}
episode index:568
target Thresh 1.4220184522329906
current state at start:  [1.04957601 3.01407175]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.04957601, 3.01407175]), 'currentState': array([0.55025643, 3.30064665]), 'targetState': array([-0.05349972,  0.61094423]), 'effectorPosition': array([ 0.09357928, -0.12840485])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4971499973804567
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.04957601, 3.01407175]), 'currentState': array([5.53316045, 1.65517448]), 'targetState': array([-0.05349972,  0.61094423]), 'effectorPosition': array([1.34923983, 0.10486062])}
episode index:569
target Thresh 1.4231732601356861
current state at start:  [-0.71719708  2.98977467]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.71719708,  2.98977467]), 'currentState': array([5.12978635, 2.86832554]), 'targetState': array([-0.13918022,  0.42922405]), 'effectorPosition': array([0.26175088, 0.07548411])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.4980321903675085
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.71719708,  2.98977467]), 'currentState': array([5.12978635, 2.86832554]), 'targetState': array([-0.13918022,  0.42922405]), 'effectorPosition': array([0.26175088, 0.07548411])}
episode index:570
target Thresh 1.4243257607306528
current state at start:  [ 4.40269043 -2.53031323]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.40269043, -2.53031323]), 'currentState': array([4.90269043, 3.63464916]), 'targetState': array([-1.21608501,  0.37501376]), 'effectorPosition': array([-0.44224562, -0.20649038])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4971599798764971
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 4.40269043, -2.53031323]), 'currentState': array([4.83090529, 2.88022589]), 'targetState': array([-1.21608501,  0.37501376]), 'effectorPosition': array([ 0.26060416, -0.00317095])}
episode index:571
target Thresh 1.4254759586278951
current state at start:  [-0.36543544 -2.4553403 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.36543544, -2.4553403 ]), 'currentState': array([0.13456456, 4.32784501]), 'targetState': array([-0.06367767, -0.72577305]), 'effectorPosition': array([ 0.74357583, -0.8347587 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4962908190725172
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.36543544, -2.4553403 ]), 'currentState': array([2.9295049 , 4.23115456]), 'targetState': array([-0.06367767, -0.72577305]), 'effectorPosition': array([-0.33849769,  0.97962841])}
episode index:572
target Thresh 1.4266238584282058
current state at start:  [-2.26922263  1.91429234]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.26922263,  1.91429234]), 'currentState': array([4.51396268, 1.56081271]), 'targetState': array([-0.40438341, -0.58209487]), 'effectorPosition': array([ 0.78123439, -1.1872825 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.49542469198862105
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.26922263,  1.91429234]), 'currentState': array([2.6759657 , 4.81500635]), 'targetState': array([-0.40438341, -0.58209487]), 'effectorPosition': array([-0.53845095,  1.38381549])}
episode index:573
target Thresh 1.4277694647231858
current state at start:  [0.55017238 2.8139367 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.55017238, 2.8139367 ]), 'currentState': array([0.05017238, 3.23203053]), 'targetState': array([-0.18211174,  0.72297837]), 'effectorPosition': array([ 0.00861098, -0.08999604])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.49456158276912865
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.55017238, 2.8139367 ]), 'currentState': array([4.73723722, 1.78105269]), 'targetState': array([-0.18211174,  0.72297837]), 'effectorPosition': array([ 0.99733566, -0.76674659])}
episode index:574
target Thresh 1.4289127820952614
current state at start:  [ 3.35570241 -2.14844775]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.35570241, -2.14844775]), 'currentState': array([3.37544689, 4.63473755]), 'targetState': array([-0.50971204,  0.43166697]), 'effectorPosition': array([-1.12834886,  0.75609656])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4937014756686606
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.35570241, -2.14844775]), 'currentState': array([5.18331836, 0.72413478]), 'targetState': array([-0.50971204,  0.43166697]), 'effectorPosition': array([ 1.38395389, -1.25810072])}
episode index:575
target Thresh 1.430053815117704
current state at start:  [ 1.53316269 -2.13711161]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.53316269, -2.13711161]), 'currentState': array([1.09011922, 4.62734229]), 'targetState': array([0.48455663, 0.92802845]), 'effectorPosition': array([1.3065805 , 0.35065506])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4928443550511803
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.53316269, -2.13711161]), 'currentState': array([5.51765399, 6.10970286]), 'targetState': array([0.48455663, 0.92802845]), 'effectorPosition': array([ 1.31159848, -1.49989622])}
episode index:576
target Thresh 1.4311925683546474
current state at start:  [-1.94793879 -2.37979309]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.94793879, -2.37979309]), 'currentState': array([4.83524652, 4.34656554]), 'targetState': array([-0.27955132,  0.27726053]), 'effectorPosition': array([-0.84808   , -0.75188003])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.49199020538904653
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.94793879, -2.37979309]), 'currentState': array([5.12483515, 0.40474054]), 'targetState': array([-0.27955132,  0.27726053]), 'effectorPosition': array([ 1.13007522, -1.60041844])}
episode index:577
target Thresh 1.4323290463611056
current state at start:  [-0.91943411  2.04625091]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.91943411,  2.04625091]), 'currentState': array([4.91180333, 1.54625091]), 'targetState': array([1.09722462, 0.68034739]), 'effectorPosition': array([ 1.18284467, -0.80620369])}
done in step count: 59
reward sum = 0.5526834771623851
running average episode reward sum: 0.492095211049554
{'reset': False, 'endBeforeDone': False, 'stepCount': 60, 'initial state': array([-0.91943411,  2.04625091]), 'currentState': array([1.02492702, 4.98123457]), 'targetState': array([1.09722462, 0.68034739]), 'effectorPosition': array([1.48103496, 0.58118224])}
episode index:578
target Thresh 1.4334632536829925
current state at start:  [-0.77611583 -2.76417557]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.77611583, -2.76417557]), 'currentState': array([5.98749388, 4.00181415]), 'targetState': array([-0.00651194, -0.10077726]), 'effectorPosition': array([ 0.11176077, -0.8264202 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4912453056764114
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.77611583, -2.76417557]), 'currentState': array([2.38073587, 4.95985972]), 'targetState': array([-0.00651194, -0.10077726]), 'effectorPosition': array([-0.23311589,  1.56062874])}
episode index:579
target Thresh 1.4345951948571387
current state at start:  [ 3.57885273 -1.94602179]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.57885273, -1.94602179]), 'currentState': array([4.07885273, 4.83716352]), 'targetState': array([-0.44385081,  0.64812101]), 'effectorPosition': array([-1.4653468 , -0.31884293])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4903983310114521
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.57885273, -1.94602179]), 'currentState': array([4.96243188, 1.27199613]), 'targetState': array([-0.44385081,  0.64812101]), 'effectorPosition': array([ 1.24625712, -1.01763979])}
episode index:580
target Thresh 1.4357248744113105
current state at start:  [ 0.52476584 -2.46471834]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.52476584, -2.46471834]), 'currentState': array([0.98925497, 3.37641222]), 'targetState': array([ 0.81671508, -0.94028299]), 'effectorPosition': array([ 0.20949606, -0.1048748 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4895542719219315
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.52476584, -2.46471834]), 'currentState': array([3.60300457, 3.13270773]), 'targetState': array([ 0.81671508, -0.94028299]), 'effectorPosition': array([ 0.00392029, -0.00797325])}
episode index:581
target Thresh 1.4368522968642274
current state at start:  [ 2.87849186 -2.87850112]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.87849186, -2.87850112]), 'currentState': array([3.35356275, 3.53440952]), 'targetState': array([-0.20206905,  0.6569094 ]), 'effectorPosition': array([-0.15499508,  0.35820053])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.49043132643752957
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.87849186, -2.87850112]), 'currentState': array([3.35356275, 3.53440952]), 'targetState': array([-0.20206905,  0.6569094 ]), 'effectorPosition': array([-0.15499508,  0.35820053])}
episode index:582
target Thresh 1.437977466725581
current state at start:  [0.98212165 2.68196089]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.98212165, 2.68196089]), 'currentState': array([0.50345203, 2.18196089]), 'targetState': array([-0.03394302,  0.70236238]), 'effectorPosition': array([-0.02181961,  0.92297383])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.4913053721897808
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.98212165, 2.68196089]), 'currentState': array([0.50345203, 2.18196089]), 'targetState': array([-0.03394302,  0.70236238]), 'effectorPosition': array([-0.02181961,  0.92297383])}
episode index:583
target Thresh 1.439100388496052
current state at start:  [-4.38028768  3.09237189]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.38028768,  3.09237189]), 'currentState': array([1.40752199, 3.54100831]), 'targetState': array([-0.26976163, -0.14251741]), 'effectorPosition': array([0.39650264, 0.01445237])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.49046409586753803
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-4.38028768,  3.09237189]), 'currentState': array([2.48442382, 5.05663064]), 'targetState': array([-0.26976163, -0.14251741]), 'effectorPosition': array([-0.48387992,  1.56231433])}
episode index:584
target Thresh 1.4402210666673294
current state at start:  [ 2.0486747 -2.2221313]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.0486747, -2.2221313]), 'currentState': array([2.5486747 , 4.33609529]), 'targetState': array([0.92658628, 0.33328869]), 'effectorPosition': array([-0.0048739 ,  1.12473295])}
done in step count: 37
reward sum = 0.6894490858690777
running average episode reward sum: 0.4908042411495919
{'reset': False, 'endBeforeDone': False, 'stepCount': 38, 'initial state': array([ 2.0486747, -2.2221313]), 'currentState': array([1.33639454, 4.63897279]), 'targetState': array([0.92658628, 0.33328869]), 'effectorPosition': array([1.18525812, 0.66967356])}
episode index:585
target Thresh 1.441339505722127
current state at start:  [ 2.72949852 -2.48507688]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.72949852, -2.48507688]), 'currentState': array([2.2907521 , 4.29810842]), 'targetState': array([-0.04899981,  0.22672315]), 'effectorPosition': array([0.29429255, 1.05277205])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.48996669125001924
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.72949852, -2.48507688]), 'currentState': array([2.08517688, 4.23491612]), 'targetState': array([-0.04899981,  0.22672315]), 'effectorPosition': array([0.50732334, 0.90749696])}
episode index:586
target Thresh 1.4424557101342024
current state at start:  [ 1.91439888 -2.04218751]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.91439888, -2.04218751]), 'currentState': array([2.41439888, 3.7409978 ]), 'targetState': array([1.33640169, 0.12530324]), 'effectorPosition': array([0.24480329, 0.53733476])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.48913199501279603
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.91439888, -2.04218751]), 'currentState': array([1.93658795, 0.87626623]), 'targetState': array([1.33640169, 0.12530324]), 'effectorPosition': array([-1.30413904,  1.25669021])}
episode index:587
target Thresh 1.4435696843683754
current state at start:  [ 1.24638994 -1.9307249 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.24638994, -1.9307249 ]), 'currentState': array([1.74638994, 4.85246041]), 'targetState': array([0.9622841 , 0.18809489]), 'effectorPosition': array([0.77589747, 1.29507173])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4883001378784205
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.24638994, -1.9307249 ]), 'currentState': array([3.53460527, 4.5233439 ]), 'targetState': array([0.9622841 , 0.18809489]), 'effectorPosition': array([-1.12631571,  0.59629756])}
episode index:588
target Thresh 1.4446814328805435
current state at start:  [-3.94398461  2.17387164]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.94398461,  2.17387164]), 'currentState': array([2.62492981, 2.67387164]), 'targetState': array([-1.27827638,  0.19489845]), 'effectorPosition': array([-0.31609609, -0.33894996])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.48747110538626703
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.94398461,  2.17387164]), 'currentState': array([4.61789646, 2.64040732]), 'targetState': array([-1.27827638,  0.19489845]), 'effectorPosition': array([ 0.46671803, -0.16777054])}
episode index:589
target Thresh 1.4457909601177028
current state at start:  [ 3.30542667 -1.8455261 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.30542667, -1.8455261 ]), 'currentState': array([3.79863063, 4.93543697]), 'targetState': array([-0.49971798,  0.49546718]), 'effectorPosition': array([-1.56259848,  0.02631069])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.48664488317374793
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.30542667, -1.8455261 ]), 'currentState': array([4.78296288, 1.23360143]), 'targetState': array([-0.49971798,  0.49546718]), 'effectorPosition': array([ 1.03518201, -1.26098403])}
episode index:590
target Thresh 1.4468982705179636
current state at start:  [-0.24801238  1.99775305]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.24801238,  1.99775305]), 'currentState': array([5.59859385, 1.49775305]), 'targetState': array([0.76032491, 0.50468949]), 'effectorPosition': array([1.46188255, 0.09410689])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4858214569754844
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.24801238,  1.99775305]), 'currentState': array([5.37086934, 5.66747121]), 'targetState': array([0.76032491, 0.50468949]), 'effectorPosition': array([ 0.65466887, -1.7900087 ])}
episode index:591
target Thresh 1.448003368510569
current state at start:  [ 3.34309895 -1.88099967]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.34309895, -1.88099967]), 'currentState': array([3.76815284, 4.90218564]), 'targetState': array([-0.733669  ,  1.04889537]), 'effectorPosition': array([-1.53870482,  0.09851853])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.48500081262248523
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.34309895, -1.88099967]), 'currentState': array([4.3536492 , 2.40973129]), 'targetState': array([-0.733669  ,  1.04889537]), 'effectorPosition': array([ 0.53581025, -0.47438773])}
episode index:592
target Thresh 1.4491062585159127
current state at start:  [-0.27369398  2.82293283]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.27369398,  2.82293283]), 'currentState': array([5.56531975, 3.32293283]), 'targetState': array([-0.25327768,  0.84150513]), 'effectorPosition': array([-0.10627849, -0.1466258 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.48418293604133433
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.27369398,  2.82293283]), 'currentState': array([4.46033723, 0.54439886]), 'targetState': array([-0.25327768,  0.84150513]), 'effectorPosition': array([ 0.03880914, -1.92597285])}
episode index:593
target Thresh 1.4502069449455557
current state at start:  [ 1.65974637 -2.66436219]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.65974637, -2.66436219]), 'currentState': array([2.15974637, 4.06569189]), 'targetState': array([ 0.34578038, -0.4325377 ]), 'effectorPosition': array([0.44284484, 0.77380942])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.48336781325338596
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.65974637, -2.66436219]), 'currentState': array([3.38940052, 3.58722158]), 'targetState': array([ 0.34578038, -0.4325377 ]), 'effectorPosition': array([-0.20039862,  0.39390465])}
episode index:594
target Thresh 1.4513054322022456
current state at start:  [-3.28783617  2.64396144]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.28783617,  2.64396144]), 'currentState': array([3.4695571 , 2.18743433]), 'targetState': array([ 0.06505839, -0.08834679]), 'effectorPosition': array([-0.13643598, -0.90818168])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.48255543037396853
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.28783617,  2.64396144]), 'currentState': array([4.66146289, 0.47440849]), 'targetState': array([ 0.06505839, -0.08834679]), 'effectorPosition': array([ 0.36003365, -1.91036697])}
episode index:595
target Thresh 1.4524017246799326
current state at start:  [ 0.35600047 -2.09888933]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.35600047, -2.09888933]), 'currentState': array([0.85349544, 4.66244876]), 'targetState': array([ 0.53274144, -0.36441353]), 'effectorPosition': array([1.37718156, 0.05943078])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4817457736115961
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.35600047, -2.09888933]), 'currentState': array([2.96865948, 3.91294833]), 'targetState': array([ 0.53274144, -0.36441353]), 'effectorPosition': array([-0.15885898,  0.73541232])}
episode index:596
target Thresh 1.4534958267637883
current state at start:  [-1.46129464 -1.89504536]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.46129464, -1.89504536]), 'currentState': array([5.26041688, 4.82454805]), 'targetState': array([-0.29685099, -0.76056933]), 'effectorPosition': array([-0.26887263, -1.4668182 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.48093882926718806
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.46129464, -1.89504536]), 'currentState': array([3.0005205 , 4.58899909]), 'targetState': array([-0.29685099, -0.76056933]), 'effectorPosition': array([-0.72867576,  1.10583796])}
episode index:597
target Thresh 1.4545877428302223
current state at start:  [-3.37209752  1.94405238]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.37209752,  1.94405238]), 'currentState': array([3.41108779, 1.75999655]), 'targetState': array([-0.65732014, -0.51005605]), 'effectorPosition': array([-0.52112673, -1.16287576])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4801345837332964
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.37209752,  1.94405238]), 'currentState': array([4.61363838, 1.83661172]), 'targetState': array([-0.65732014, -0.51005605]), 'effectorPosition': array([ 0.88748693, -0.82883939])}
episode index:598
target Thresh 1.4556774772469003
current state at start:  [-3.86612976  1.87211407]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.86612976,  1.87211407]), 'currentState': array([2.0008654 , 2.25604145]), 'targetState': array([-1.39601341, -0.13630782]), 'effectorPosition': array([-0.85682893,  0.01088791])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.479333023493341
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.86612976,  1.87211407]), 'currentState': array([4.17896666, 3.00639025]), 'targetState': array([-1.39601341, -0.13630782]), 'effectorPosition': array([ 0.11142425, -0.07639697])}
episode index:599
target Thresh 1.4567650343727618
current state at start:  [-4.50235332  2.75650533]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.50235332,  2.75650533]), 'currentState': array([1.28812178, 2.30743991]), 'targetState': array([-0.06771553, -0.1868907 ]), 'effectorPosition': array([-0.61978858,  0.52177687])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.47853413512085213
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-4.50235332,  2.75650533]), 'currentState': array([4.72586187, 0.73595942]), 'targetState': array([-0.06771553, -0.1868907 ]), 'effectorPosition': array([ 0.69469576, -1.73198495])}
episode index:600
target Thresh 1.457850418558036
current state at start:  [-1.44507591 -2.50348222]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.44507591, -2.50348222]), 'currentState': array([5.3381094 , 4.01043178]), 'targetState': array([-0.036848  , -0.99721321]), 'effectorPosition': array([-0.41141403, -0.73437844])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.4794017987895362
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.44507591, -2.50348222]), 'currentState': array([5.3381094 , 4.01043178]), 'targetState': array([-0.036848  , -0.99721321]), 'effectorPosition': array([-0.41141403, -0.73437844])}
episode index:601
target Thresh 1.458933634144262
current state at start:  [-1.70474833  1.83075224]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.70474833,  1.83075224]), 'currentState': array([4.09441594, 1.39467181]), 'targetState': array([ 0.64415822, -1.06425442]), 'effectorPosition': array([ 0.12154443, -1.52828587])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4786054502865636
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.70474833,  1.83075224]), 'currentState': array([3.26476906, 3.52058986]), 'targetState': array([ 0.64415822, -1.06425442]), 'effectorPosition': array([-0.11588497,  0.35846677])}
episode index:602
target Thresh 1.4600146854643032
current state at start:  [ 3.55291245 -2.6924315 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.55291245, -2.6924315 ]), 'currentState': array([3.05847184, 4.09075381]), 'targetState': array([-0.10113184, -0.269989  ]), 'effectorPosition': array([-0.34869949,  0.84479479])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.477811743072158
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.55291245, -2.6924315 ]), 'currentState': array([2.52505004, 5.01940932]), 'targetState': array([-0.10113184, -0.269989  ]), 'effectorPosition': array([-0.5112788,  1.530697 ])}
episode index:603
target Thresh 1.4610935768423658
current state at start:  [-1.21258833  1.75761287]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.21258833,  1.75761287]), 'currentState': array([4.57059697, 1.25761287]), 'targetState': array([1.34567684, 0.24472305]), 'effectorPosition': array([ 0.75695445, -1.42940462])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.47702066402733656
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.21258833,  1.75761287]), 'currentState': array([4.5772089 , 3.62552115]), 'targetState': array([1.34567684, 0.24472305]), 'effectorPosition': array([-0.47649058, -0.05107593])}
episode index:604
target Thresh 1.4621703125940178
current state at start:  [ 1.79887793 -1.84431287]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.79887793, -1.84431287]), 'currentState': array([1.29887793, 4.93887243]), 'targetState': array([0.70358756, 1.20835062]), 'effectorPosition': array([1.26754785, 0.91783811])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.47623220011985334
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.79887793, -1.84431287]), 'currentState': array([5.38295039, 0.11065685]), 'targetState': array([0.70358756, 1.20835062]), 'effectorPosition': array([ 1.32557091, -1.49352915])}
episode index:605
target Thresh 1.4632448970262026
current state at start:  [-0.45028013  2.90998352]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.45028013,  2.90998352]), 'currentState': array([5.4004905 , 3.34550826]), 'targetState': array([0.42957044, 0.79614654]), 'effectorPosition': array([-0.14326793, -0.14460978])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.47544633840348394
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.45028013,  2.90998352]), 'currentState': array([4.8873893 , 5.94777425]), 'targetState': array([0.42957044, 0.79614654]), 'effectorPosition': array([ 0.01438477, -1.97188825])}
episode index:606
target Thresh 1.46431733443726
current state at start:  [ 3.5075081  -2.30200668]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.5075081 , -2.30200668]), 'currentState': array([3.98029924, 3.59886934]), 'targetState': array([-0.61077837,  1.26897426]), 'effectorPosition': array([-0.39705838,  0.21869675])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4746630660173167
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.5075081 , -2.30200668]), 'currentState': array([4.86865441, 1.47224613]), 'targetState': array([-0.61077837,  1.26897426]), 'effectorPosition': array([ 1.15396517, -0.93013218])}
episode index:607
target Thresh 1.465387629116941
current state at start:  [-1.74699716 -1.64616305]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.74699716, -1.64616305]), 'currentState': array([4.94319295, 5.13702226]), 'targetState': array([-0.51721213, -0.22079015]), 'effectorPosition': array([-0.56402125, -1.58298874])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4738823701850514
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.74699716, -1.64616305]), 'currentState': array([2.43488747, 5.04282391]), 'targetState': array([-0.51721213, -0.22079015]), 'effectorPosition': array([-0.39305121,  1.57937318])}
episode index:608
target Thresh 1.4664557853464255
current state at start:  [0.17445412 1.81119063]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.17445412, 1.81119063]), 'currentState': array([6.05412931, 1.31119063]), 'targetState': array([0.09670233, 0.87221371]), 'effectorPosition': array([1.44332581, 0.65590363])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4731042382143042
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.17445412, 1.81119063]), 'currentState': array([5.4004367 , 0.48968295]), 'targetState': array([0.09670233, 0.87221371]), 'effectorPosition': array([ 1.55876947, -1.15550932])}
episode index:609
target Thresh 1.4675218073983403
current state at start:  [0.43335466 1.9688229 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.43335466, 1.9688229 ]), 'currentState': array([0.93335466, 1.49609391]), 'targetState': array([0.17301292, 0.47477988]), 'effectorPosition': array([-0.16182109,  1.45707922])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4723286574959201
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.43335466, 1.9688229 ]), 'currentState': array([1.70237237, 4.9232783 ]), 'targetState': array([0.17301292, 0.47477988]), 'effectorPosition': array([0.8107329 , 1.32716666])}
episode index:610
target Thresh 1.4685856995367743
current state at start:  [-2.415245    2.77909098]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.415245  ,  2.77909098]), 'currentState': array([3.36794031, 3.12057386]), 'targetState': array([ 0.41294009, -0.64568651]), 'effectorPosition': array([ 0.00450143, -0.02053072])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4715556155032918
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.415245  ,  2.77909098]), 'currentState': array([2.83231873, 3.57048559]), 'targetState': array([ 0.41294009, -0.64568651]), 'effectorPosition': array([0.04029936, 0.42370104])}
episode index:611
target Thresh 1.4696474660172982
current state at start:  [-2.85568741  2.41604595]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.85568741,  2.41604595]), 'currentState': array([3.88326252, 1.91604595]), 'targetState': array([0.031889  , 0.01324204]), 'effectorPosition': array([ 0.14785646, -1.14073455])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4707850997916851
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.85568741,  2.41604595]), 'currentState': array([5.32291598, 0.44976232]), 'targetState': array([0.031889  , 0.01324204]), 'effectorPosition': array([ 1.44579622, -1.30796567])}
episode index:612
target Thresh 1.470707111086979
current state at start:  [ 3.30711435 -1.75969172]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.30711435, -1.75969172]), 'currentState': array([3.80711435, 4.95422774]), 'targetState': array([-0.56125999,  1.11951312]), 'effectorPosition': array([-1.57447574, -0.00164204])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4700170979975714
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.30711435, -1.75969172]), 'currentState': array([4.73586147, 1.27390194]), 'targetState': array([-0.56125999,  1.11951312]), 'effectorPosition': array([ 0.98632286, -1.26975233])}
episode index:613
target Thresh 1.4717646389843981
current state at start:  [-2.77137127  2.67044714]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.77137127,  2.67044714]), 'currentState': array([4.00568922, 2.22789836]), 'targetState': array([-0.05522545, -0.00554348]), 'effectorPosition': array([ 0.34944283, -0.81008635])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4692515978379662
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.77137127,  2.67044714]), 'currentState': array([4.3160466 , 1.34905405]), 'targetState': array([-0.05522545, -0.00554348]), 'effectorPosition': array([ 0.428943  , -1.50195441])}
episode index:614
target Thresh 1.4728200539396692
current state at start:  [-0.88924326  1.81417488]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.88924326,  1.81417488]), 'currentState': array([4.89394204, 1.31520396]), 'targetState': array([1.00246864, 0.59788724]), 'effectorPosition': array([ 1.17781767, -1.05753614])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4684885871097744
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.88924326,  1.81417488]), 'currentState': array([5.79462848, 4.7192614 ]), 'targetState': array([1.00246864, 0.59788724]), 'effectorPosition': array([ 0.41973855, -1.35556788])}
episode index:615
target Thresh 1.4738733601744531
current state at start:  [-1.46682833  2.25011173]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.46682833,  2.25011173]), 'currentState': array([4.52468719, 1.76387876]), 'targetState': array([ 1.07269538, -0.70499286]), 'effectorPosition': array([ 0.81338398, -0.97705506])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.4693514303125183
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.46682833,  2.25011173]), 'currentState': array([4.52468719, 1.76387876]), 'targetState': array([ 1.07269538, -0.70499286]), 'effectorPosition': array([ 0.81338398, -0.97705506])}
episode index:616
target Thresh 1.4749245619019762
current state at start:  [-3.06942912  2.54814468]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.06942912,  2.54814468]), 'currentState': array([2.71375619, 3.04814468]), 'targetState': array([ 0.14253281, -1.03942045]), 'effectorPosition': array([-0.04268529, -0.08309114])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4685907310737622
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.06942912,  2.54814468]), 'currentState': array([3.44858272, 3.32964732]), 'targetState': array([ 0.14253281, -1.03942045]), 'effectorPosition': array([-0.0733    ,  0.17288022])}
episode index:617
target Thresh 1.4759736633270466
current state at start:  [0.22101874 2.98384052]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.22101874, 2.98384052]), 'currentState': array([0.06412285, 2.48384052]), 'targetState': array([ 0.01767852, -0.0028284 ]), 'effectorPosition': array([0.16902882, 0.62345199])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.46783249364484025
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.22101874, 2.98384052]), 'currentState': array([2.48163837, 4.93833332]), 'targetState': array([ 0.01767852, -0.0028284 ]), 'effectorPosition': array([-0.36950791,  1.52036755])}
episode index:618
target Thresh 1.4770206686460718
current state at start:  [ 3.55667705 -2.59803472]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.55667705, -2.59803472]), 'currentState': array([3.08338443, 4.08750009]), 'targetState': array([-0.22723162, -0.30632145]), 'effectorPosition': array([-0.36710815,  0.83379691])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.46707670609452545
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.55667705, -2.59803472]), 'currentState': array([2.20477371, 4.0901436 ]), 'targetState': array([-0.22723162, -0.30632145]), 'effectorPosition': array([0.40757726, 0.8174096 ])}
episode index:619
target Thresh 1.478065582047074
current state at start:  [1.92828997 2.21082311]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.92828997, 2.21082311]), 'currentState': array([1.42828997, 1.72461187]), 'targetState': array([-0.9416739 , -0.09043372]), 'effectorPosition': array([-0.85791155,  0.97855419])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.46632335656856655
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.92828997, 2.21082311]), 'currentState': array([1.23519653, 5.34522489]), 'targetState': array([-0.9416739 , -0.09043372]), 'effectorPosition': array([1.28548518, 1.23709159])}
episode index:620
target Thresh 1.4791084077097088
current state at start:  [ 2.34104763 -2.51526062]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.34104763, -2.51526062]), 'currentState': array([2.81814478, 4.12683256]), 'targetState': array([0.62032883, 0.5196506 ]), 'effectorPosition': array([-0.15925296,  0.93236909])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.4671666361876188
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 2.34104763, -2.51526062]), 'currentState': array([2.35518228, 4.19002726]), 'targetState': array([0.62032883, 0.5196506 ]), 'effectorPosition': array([0.25947693, 0.96685838])}
episode index:621
target Thresh 1.4801491498052797
current state at start:  [-2.01126519 -2.11571596]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.01126519, -2.11571596]), 'currentState': array([4.28890408, 4.61175992]), 'targetState': array([-1.20209187, -0.46550975]), 'effectorPosition': array([-1.27670769, -0.4112163 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.4680232814670599
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.01126519, -2.11571596]), 'currentState': array([4.28890408, 4.61175992]), 'targetState': array([-1.20209187, -0.46550975]), 'effectorPosition': array([-1.27670769, -0.4112163 ])}
episode index:622
target Thresh 1.4811878124967568
current state at start:  [ 3.41054614 -2.06402209]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.41054614, -2.06402209]), 'currentState': array([2.91054614, 4.69371806]), 'targetState': array([-0.20168794,  0.1869262 ]), 'effectorPosition': array([-0.72629711,  1.19797864])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4672720402448014
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.41054614, -2.06402209]), 'currentState': array([2.06788622, 6.20084082]), 'targetState': array([-0.20168794,  0.1869262 ]), 'effectorPosition': array([-0.87982658,  1.79419297])}
episode index:623
target Thresh 1.4822243999387923
current state at start:  [-1.56878419  2.89781062]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.56878419,  2.89781062]), 'currentState': array([4.21440112, 2.60723792]), 'targetState': array([ 0.63719349, -0.42103124]), 'effectorPosition': array([ 0.3808439 , -0.36573632])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.4681257709495373
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.56878419,  2.89781062]), 'currentState': array([4.21440112, 2.60723792]), 'targetState': array([ 0.63719349, -0.42103124]), 'effectorPosition': array([ 0.3808439 , -0.36573632])}
episode index:624
target Thresh 1.483258916277737
current state at start:  [0.92107793 2.38132934]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.92107793, 2.38132934]), 'currentState': array([0.90564434, 1.88132934]), 'targetState': array([ 0.02855786, -0.02202442]), 'effectorPosition': array([-0.32060013,  1.13405606])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.46737676971601805
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.92107793, 2.38132934]), 'currentState': array([2.3702122 , 4.74581377]), 'targetState': array([ 0.02855786, -0.02202442]), 'effectorPosition': array([-0.04417218,  1.4369711 ])}
episode index:625
target Thresh 1.4842913656516579
current state at start:  [-4.07400831  2.39743849]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.07400831,  2.39743849]), 'currentState': array([1.76288642, 1.89743849]), 'targetState': array([-0.24336942, -0.84073941]), 'effectorPosition': array([-1.05935936,  0.4858278 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.46663016145768577
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-4.07400831,  2.39743849]), 'currentState': array([2.59194038, 3.59064872]), 'targetState': array([-0.24336942, -0.84073941]), 'effectorPosition': array([0.14223825, 0.42196413])}
episode index:626
target Thresh 1.4853217521903537
current state at start:  [ 2.93667797 -2.61393409]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.93667797, -2.61393409]), 'currentState': array([3.37407729, 3.88199279]), 'targetState': array([0.69949668, 0.94616534]), 'effectorPosition': array([-0.41017938,  0.59611701])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.46588593472489837
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.93667797, -2.61393409]), 'currentState': array([5.64734079, 5.69035086]), 'targetState': array([0.69949668, 0.94616534]), 'effectorPosition': array([ 1.14005296, -1.53590364])}
episode index:627
target Thresh 1.486350080015372
current state at start:  [-4.09458615  2.7324139 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.09458615,  2.7324139 ]), 'currentState': array([1.69036018, 3.22391732]), 'targetState': array([-1.01384384,  0.35960543]), 'effectorPosition': array([0.08124066, 0.01317111])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4651440781409415
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-4.09458615,  2.7324139 ]), 'currentState': array([4.61489471, 2.65176514]), 'targetState': array([-1.01384384,  0.35960543]), 'effectorPosition': array([ 0.4567937 , -0.16282345])}
episode index:628
target Thresh 1.4873763532400255
current state at start:  [-3.25769861  2.68813442]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.25769861,  2.68813442]), 'currentState': array([3.47396251, 2.3875071 ]), 'targetState': array([-0.06623462, -0.46543455]), 'effectorPosition': array([-0.03288375, -0.73561054])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.46599440552068566
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.25769861,  2.68813442]), 'currentState': array([3.47396251, 2.3875071 ]), 'targetState': array([-0.06623462, -0.46543455]), 'effectorPosition': array([-0.03288375, -0.73561054])}
episode index:629
target Thresh 1.4884005759694086
current state at start:  [-0.56243869 -2.36203164]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.56243869, -2.36203164]), 'currentState': array([6.22074662, 4.416978  ]), 'targetState': array([ 0.04050396, -0.39039523]), 'effectorPosition': array([ 0.64779041, -0.99905029])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.46525473186112903
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.56243869, -2.36203164]), 'currentState': array([2.92551527, 4.78835458]), 'targetState': array([ 0.04050396, -0.39039523]), 'effectorPosition': array([-0.83709217,  1.20460027])}
episode index:630
target Thresh 1.4894227523004133
current state at start:  [1.69917492 2.4834067 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.69917492, 2.4834067 ]), 'currentState': array([1.19917492, 2.97933693]), 'targetState': array([-1.33999057, -0.33219714]), 'effectorPosition': array([-0.14574811,  0.07089922])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.46451740265057256
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.69917492, 2.4834067 ]), 'currentState': array([1.19981898, 5.29714367]), 'targetState': array([-1.33999057, -0.33219714]), 'effectorPosition': array([1.33976298, 1.14412623])}
episode index:631
target Thresh 1.4904428863217465
current state at start:  [1.6370878 2.5867358]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.6370878, 2.5867358]), 'currentState': array([1.14290748, 3.0867358 ]), 'targetState': array([-0.87494321,  0.53618486]), 'effectorPosition': array([-0.04926195,  0.02412013])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.46378240676030263
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.6370878, 2.5867358]), 'currentState': array([4.29547288, 2.96460208]), 'targetState': array([-0.87494321,  0.53618486]), 'effectorPosition': array([ 0.15466034, -0.08558127])}
episode index:632
target Thresh 1.4914609821139455
current state at start:  [1.00810276 1.63035196]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.00810276, 1.63035196]), 'currentState': array([0.58902882, 1.23329475]), 'targetState': array([-0.88672386,  0.93707074]), 'effectorPosition': array([0.58259717, 1.52408721])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4630497331319294
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.00810276, 1.63035196]), 'currentState': array([4.34527251, 2.99156966]), 'targetState': array([-0.88672386,  0.93707074]), 'effectorPosition': array([ 0.13547014, -0.06412923])}
episode index:633
target Thresh 1.492477043749395
current state at start:  [ 3.83088795 -1.82869087]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.83088795, -1.82869087]), 'currentState': array([4.27825189, 4.95449444]), 'targetState': array([-0.69613272, -0.10122117]), 'effectorPosition': array([-1.40224621, -0.71637977])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.46231937077683166
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.83088795, -1.82869087]), 'currentState': array([4.20937463, 2.19145984]), 'targetState': array([-0.69613272, -0.10122117]), 'effectorPosition': array([ 0.51101862, -0.75875547])}
episode index:634
target Thresh 1.4934910752923427
current state at start:  [-1.64706658  1.96872189]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.64706658,  1.96872189]), 'currentState': array([4.13611873, 1.46872189]), 'targetState': array([1.08397437, 0.05900145]), 'effectorPosition': array([ 0.23371216, -1.46600586])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.46159130877560833
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.64706658,  1.96872189]), 'currentState': array([4.78324704, 3.76049547]), 'targetState': array([1.08397437, 0.05900145]), 'effectorPosition': array([-0.56555396, -0.22609241])}
episode index:635
target Thresh 1.4945030807989164
current state at start:  [ 2.36087463 -1.7223335 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.36087463, -1.7223335 ]), 'currentState': array([2.85183273, 4.9217323 ]), 'targetState': array([0.71675805, 1.17820871]), 'effectorPosition': array([-0.87798253,  1.2824905 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.46086553627753346
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.36087463, -1.7223335 ]), 'currentState': array([5.41521596, 0.29449976]), 'targetState': array([0.71675805, 1.17820871]), 'effectorPosition': array([ 1.48640092, -1.30556779])}
episode index:636
target Thresh 1.495513064317139
current state at start:  [ 3.94975016 -2.45447531]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.94975016, -2.45447531]), 'currentState': array([3.77449571, 3.34345389]), 'targetState': array([-1.16359118,  0.26293236]), 'effectorPosition': array([-0.1349614 ,  0.14965027])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4601420425000177
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.94975016, -2.45447531]), 'currentState': array([4.58533925, 2.85776214]), 'targetState': array([-1.16359118,  0.26293236]), 'effectorPosition': array([ 0.27270825, -0.07517044])}
episode index:637
target Thresh 1.4965210298869467
current state at start:  [ 3.5730848  -2.39727571]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.5730848 , -2.39727571]), 'currentState': array([3.0730848 , 3.79580334]), 'targetState': array([-0.63772053,  0.0345922 ]), 'effectorPosition': array([-0.16433048,  0.62123948])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4594208167280741
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.5730848 , -2.39727571]), 'currentState': array([1.7043005 , 5.57857149]), 'targetState': array([-0.63772053,  0.0345922 ]), 'effectorPosition': array([0.40745799, 1.8324032 ])}
episode index:638
target Thresh 1.4975269815402021
current state at start:  [0.3576629  2.34877746]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.3576629 , 2.34877746]), 'currentState': array([6.20054825, 1.84877746]), 'targetState': array([-0.68987661,  0.21714343]), 'effectorPosition': array([0.80248342, 0.89843791])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4587018483137892
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.3576629 , 2.34877746]), 'currentState': array([4.01837841, 2.63722119]), 'targetState': array([-0.68987661,  0.21714343]), 'effectorPosition': array([ 0.29182639, -0.40482165])}
episode index:639
target Thresh 1.4985309233007142
current state at start:  [-2.38746748  1.7237744 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.38746748,  1.7237744 ]), 'currentState': array([3.39571783, 1.26134404]), 'targetState': array([ 0.64060618, -0.96205324]), 'effectorPosition': array([-1.02318248, -1.24986862])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4579851266757989
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.38746748,  1.7237744 ]), 'currentState': array([2.91877264, 3.46556683]), 'targetState': array([ 0.64060618, -0.96205324]), 'effectorPosition': array([0.01961012, 0.32196254])}
episode index:640
target Thresh 1.4995328591842505
current state at start:  [-1.88934231  2.3453981 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.88934231,  2.3453981 ]), 'currentState': array([3.90466082, 1.85877806]), 'targetState': array([ 0.08415524, -0.89265322]), 'effectorPosition': array([ 0.14522627, -1.18780218])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.45883070370126566
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.88934231,  2.3453981 ]), 'currentState': array([3.90466082, 1.85877806]), 'targetState': array([ 0.08415524, -0.89265322]), 'effectorPosition': array([ 0.14522627, -1.18780218])}
episode index:641
target Thresh 1.5005327931985564
current state at start:  [-3.31842534  2.73791064]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.31842534,  2.73791064]), 'currentState': array([3.44841894, 2.2526588 ]), 'targetState': array([ 0.07077704, -0.06538313]), 'effectorPosition': array([-0.11799115, -0.85182029])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4581160141316375
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.31842534,  2.73791064]), 'currentState': array([2.73998558, 4.71618507]), 'targetState': array([ 0.07077704, -0.06538313]), 'effectorPosition': array([-0.53303278,  1.31280928])}
episode index:642
target Thresh 1.501530729343369
current state at start:  [ 2.27935753 -2.28107663]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.27935753, -2.28107663]), 'currentState': array([1.77935753, 4.4809558 ]), 'targetState': array([-0.22826607,  0.04137784]), 'effectorPosition': array([0.79268595, 0.95545984])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.45740354754667384
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.27935753, -2.28107663]), 'currentState': array([1.65666375, 5.44643468]), 'targetState': array([-0.22826607,  0.04137784]), 'effectorPosition': array([0.59652278, 1.72740221])}
episode index:643
target Thresh 1.5025266716104346
current state at start:  [-3.63760027  2.32647215]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.63760027,  2.32647215]), 'currentState': array([2.18505583, 1.82647215]), 'targetState': array([-0.1423274 , -1.08870269]), 'effectorPosition': array([-1.22122952,  0.05291322])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.45669329359085603
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.63760027,  2.32647215]), 'currentState': array([3.41077064, 3.75108936]), 'targetState': array([-0.1423274 , -1.08870269]), 'effectorPosition': array([-0.32581777,  0.50395467])}
episode index:644
target Thresh 1.5035206239835233
current state at start:  [-1.83642952 -1.69849523]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.83642952, -1.69849523]), 'currentState': array([4.85397964, 5.00616033]), 'targetState': array([-0.95955828, -0.93024869]), 'effectorPosition': array([-0.7655994 , -1.41173145])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.45753562956978494
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.83642952, -1.69849523]), 'currentState': array([4.85397964, 5.00616033]), 'targetState': array([-0.95955828, -0.93024869]), 'effectorPosition': array([-0.7655994 , -1.41173145])}
episode index:645
target Thresh 1.5045125904384458
current state at start:  [-3.40922415  2.33818318]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.40922415,  2.33818318]), 'currentState': array([3.37396116, 1.83818318]), 'targetState': array([ 0.0497    , -0.00434558]), 'effectorPosition': array([-0.49391287, -1.10798284])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4568273700812868
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.40922415,  2.33818318]), 'currentState': array([2.30060923, 4.63376414]), 'targetState': array([ 0.0497    , -0.00434558]), 'effectorPosition': array([0.12863404, 1.35143093])}
episode index:646
target Thresh 1.5055025749430695
current state at start:  [1.64429487 1.95715415]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.64429487, 1.95715415]), 'currentState': array([1.23733331, 2.13282467]), 'targetState': array([-1.37191931, -0.04309138]), 'effectorPosition': array([-0.64667523,  0.71833411])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.45612129995751355
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.64429487, 1.95715415]), 'currentState': array([4.10417107, 2.99961671]), 'targetState': array([-1.37191931, -0.04309138]), 'effectorPosition': array([ 0.11037473, -0.0891109 ])}
episode index:647
target Thresh 1.5064905814573337
current state at start:  [ 3.58280388 -2.69269219]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.58280388, -2.69269219]), 'currentState': array([3.09290287, 3.09049311]), 'targetState': array([-0.78199663, -0.14980053]), 'effectorPosition': array([-0.00378971, -0.05095324])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.45694518684029517
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.58280388, -2.69269219]), 'currentState': array([2.66397598, 2.59049311]), 'targetState': array([-0.78199663, -0.14980053]), 'effectorPosition': array([-0.37217396, -0.3969735 ])}
episode index:648
target Thresh 1.5074766139332656
current state at start:  [ 1.48350615 -2.43469847]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.48350615, -2.43469847]), 'currentState': array([1.98350615, 3.86659657]), 'targetState': array([ 0.91757232, -0.29375952]), 'effectorPosition': array([0.5065833 , 0.49636651])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4562411110516353
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.48350615, -2.43469847]), 'currentState': array([3.32746631, 3.30506138]), 'targetState': array([ 0.91757232, -0.29375952]), 'effectorPosition': array([-0.04317716,  0.15747477])}
episode index:649
target Thresh 1.5084606763149964
current state at start:  [-1.3410757   2.02036115]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.3410757 ,  2.02036115]), 'currentState': array([4.4423513, 1.5381478]), 'targetState': array([ 1.12021246, -0.06123891]), 'effectorPosition': array([ 0.68777147, -1.26184621])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4555392016500174
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.3410757 ,  2.02036115]), 'currentState': array([4.81183795, 4.18053709]), 'targetState': array([ 1.12021246, -0.06123891]), 'effectorPosition': array([-0.8086763 , -0.57600525])}
episode index:650
target Thresh 1.5094427725387773
current state at start:  [-0.60040621  1.94458122]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.60040621,  1.94458122]), 'currentState': array([5.30750837, 1.44458122]), 'targetState': array([1.25828562, 0.45299008]), 'effectorPosition': array([ 1.45267161, -0.37617247])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4548394486520911
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.60040621,  1.94458122]), 'currentState': array([5.08173638, 4.3055713 ]), 'targetState': array([1.25828562, 0.45299008]), 'effectorPosition': array([-0.63829116, -0.89510163])}
episode index:651
target Thresh 1.5104229065329942
current state at start:  [-0.26762126  2.84083374]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.26762126,  2.84083374]), 'currentState': array([5.55341404, 2.36063614]), 'targetState': array([-0.22427036, -0.06316806]), 'effectorPosition': array([0.68529449, 0.33149725])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4541418421357535
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.26762126,  2.84083374]), 'currentState': array([4.62332958, 1.24112015]), 'targetState': array([-0.22427036, -0.06316806]), 'effectorPosition': array([ 0.82466208, -1.40264243])}
episode index:652
target Thresh 1.5114010822181845
current state at start:  [-3.87537379  2.53286004]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.87537379,  2.53286004]), 'currentState': array([2.8289873 , 2.11597356]), 'targetState': array([-0.23585623, -0.29783009]), 'effectorPosition': array([-0.72105464, -0.66553808])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.4549777658078274
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.87537379,  2.53286004]), 'currentState': array([2.8289873 , 2.11597356]), 'targetState': array([-0.23585623, -0.29783009]), 'effectorPosition': array([-0.72105464, -0.66553808])}
episode index:653
target Thresh 1.5123773035070522
current state at start:  [1.34608227 2.55767565]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.34608227, 2.55767565]), 'currentState': array([0.86954156, 2.16984119]), 'targetState': array([-0.17376629, -0.1806995 ]), 'effectorPosition': array([-0.34960424,  0.86606527])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4542820811506289
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.34608227, 2.55767565]), 'currentState': array([2.29615689, 4.96288235]), 'targetState': array([-0.17376629, -0.1806995 ]), 'effectorPosition': array([-0.10294423,  1.57644106])}
episode index:654
target Thresh 1.5133515743044836
current state at start:  [-4.0086195   2.71630806]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.0086195 ,  2.71630806]), 'currentState': array([1.81860166, 2.23813317]), 'targetState': array([-0.2655514 , -0.36689285]), 'effectorPosition': array([-0.85495481,  0.17680379])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4535885207213913
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-4.0086195 ,  2.71630806]), 'currentState': array([2.22815937, 4.38284931]), 'targetState': array([-0.2655514 , -0.36689285]), 'effectorPosition': array([0.33571388, 1.11358933])}
episode index:655
target Thresh 1.5143238985075638
current state at start:  [-3.95852903  2.10191014]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.95852903,  2.10191014]), 'currentState': array([2.82465627, 1.62479108]), 'targetState': array([-0.43792198,  0.13434457]), 'effectorPosition': array([-1.21011687, -0.65397257])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.45289707480565744
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.95852903,  2.10191014]), 'currentState': array([4.40456162, 1.96565339]), 'targetState': array([-0.43792198,  0.13434457]), 'effectorPosition': array([ 0.69322647, -0.86607422])}
episode index:656
target Thresh 1.5152942800055902
current state at start:  [-1.34822738 -2.84939723]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.34822738, -2.84939723]), 'currentState': array([5.19644657, 3.83231492]), 'targetState': array([-0.2556772 ,  0.03647006]), 'effectorPosition': array([-0.45723052, -0.49936773])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.45220773374811457
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.34822738, -2.84939723]), 'currentState': array([2.59468006, 5.0804943 ]), 'targetState': array([-0.2556772 ,  0.03647006]), 'effectorPosition': array([-0.6762782 ,  1.50410918])}
episode index:657
target Thresh 1.5162627226800902
current state at start:  [-1.12084353  1.89303369]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.12084353,  1.89303369]), 'currentState': array([4.79472613, 1.39303369]), 'targetState': array([1.33587714, 0.18265606]), 'effectorPosition': array([ 1.0776946 , -1.09189293])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.45152048795214483
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.12084353,  1.89303369]), 'currentState': array([5.4026689 , 4.69704228]), 'targetState': array([1.33587714, 0.18265606]), 'effectorPosition': array([-0.14399564, -1.39591299])}
episode index:658
target Thresh 1.517229230404836
current state at start:  [ 1.42126018 -1.73913491]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.42126018, -1.73913491]), 'currentState': array([0.96269584, 4.99747676]), 'targetState': array([0.50910676, 1.29508275]), 'effectorPosition': array([1.51959291, 0.50330981])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4508353278793798
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.42126018, -1.73913491]), 'currentState': array([6.07410736, 5.69610237]), 'targetState': array([0.50910676, 1.29508275]), 'effectorPosition': array([ 1.67767829, -0.92223409])}
episode index:659
target Thresh 1.5181938070458598
current state at start:  [1.26318633 2.38787948]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.26318633, 2.38787948]), 'currentState': array([0.7646312 , 1.92631628]), 'targetState': array([-0.37282544,  0.58723119]), 'effectorPosition': array([-0.17852858,  1.12781729])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4501522440492595
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.26318633, 2.38787948]), 'currentState': array([4.68213828, 2.22259134]), 'targetState': array([-0.37282544,  0.58723119]), 'effectorPosition': array([ 0.7827341 , -0.41725113])}
episode index:660
target Thresh 1.5191564564614695
current state at start:  [-0.64834365 -2.29229728]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.64834365, -2.29229728]), 'currentState': array([6.13250805, 4.20086655]), 'targetState': array([ 0.04139548, -0.77920243]), 'effectorPosition': array([ 0.37381653, -0.93874941])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.4509840863426797
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.64834365, -2.29229728]), 'currentState': array([6.13250805, 4.20086655]), 'targetState': array([ 0.04139548, -0.77920243]), 'effectorPosition': array([ 0.37381653, -0.93874941])}
episode index:661
target Thresh 1.5201171825022637
current state at start:  [-1.7381127   2.11584639]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.7381127 ,  2.11584639]), 'currentState': array([4.08253749, 1.61584639]), 'targetState': array([0.22735574, 0.0576291 ]), 'effectorPosition': array([ 0.24479697, -1.36014881])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.45030284149926175
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.7381127 ,  2.11584639]), 'currentState': array([2.91795518, 4.55629368]), 'targetState': array([0.22735574, 0.0576291 ]), 'effectorPosition': array([-0.6044249 ,  1.15054169])}
episode index:662
target Thresh 1.521075989011148
current state at start:  [0.13147507 2.4788947 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.13147507, 2.4788947 ]), 'currentState': array([5.96632017, 1.9788947 ]), 'targetState': array([0.0301451 , 0.45943195]), 'effectorPosition': array([0.85911015, 0.68425183])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4496236516930789
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.13147507, 2.4788947 ]), 'currentState': array([4.69481942, 0.75910999]), 'targetState': array([0.0301451 , 0.45943195]), 'effectorPosition': array([ 0.65785601, -1.73727465])}
episode index:663
target Thresh 1.52203287982335
current state at start:  [ 2.02578998 -1.6845896 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.02578998, -1.6845896 ]), 'currentState': array([2.52578998, 4.99010587]), 'targetState': array([0.92656349, 0.70475309]), 'effectorPosition': array([-0.48462823,  1.52100524])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4489465076393242
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.02578998, -1.6845896 ]), 'currentState': array([4.67163201, 0.2682694 ]), 'targetState': array([0.92656349, 0.70475309]), 'effectorPosition': array([ 0.18480907, -1.97340004])}
episode index:664
target Thresh 1.522987858766434
current state at start:  [ 1.52039245 -2.21932051]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.52039245, -2.21932051]), 'currentState': array([1.97058496, 4.47085925]), 'targetState': array([0.8890753 , 1.04321217]), 'effectorPosition': array([0.59827952, 1.07874239])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.44977515950753577
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.52039245, -2.21932051]), 'currentState': array([1.97058496, 4.47085925]), 'targetState': array([0.8890753 , 1.04321217]), 'effectorPosition': array([0.59827952, 1.07874239])}
episode index:665
target Thresh 1.5239409296603168
current state at start:  [-0.79278915 -2.97220348]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.79278915, -2.97220348]), 'currentState': array([5.8207205 , 3.73292961]), 'targetState': array([-0.07331953,  0.1778997 ]), 'effectorPosition': array([-0.09675194, -0.57467107])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4490998214301971
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.79278915, -2.97220348]), 'currentState': array([2.06693759, 5.19071367]), 'targetState': array([-0.07331953,  0.1778997 ]), 'effectorPosition': array([0.0855744 , 1.70682808])}
episode index:666
target Thresh 1.5248920963172838
current state at start:  [-0.76445633 -1.60289516]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.76445633, -1.60289516]), 'currentState': array([5.01872898, 4.23353423]), 'targetState': array([ 0.42423782, -0.99333631]), 'effectorPosition': array([-0.68358514, -0.78178339])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.44842650835458964
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.76445633, -1.60289516]), 'currentState': array([3.18419539, 3.59186773]), 'targetState': array([ 0.42423782, -0.99333631]), 'effectorPosition': array([-0.11811781,  0.43057328])}
episode index:667
target Thresh 1.5258413625420024
current state at start:  [0.262307   2.50690645]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.262307  , 2.50690645]), 'currentState': array([0.57037524, 2.05206239]), 'targetState': array([-0.1050099 , -0.05455889]), 'effectorPosition': array([-0.0265403,  1.0360946])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.44775521118639416
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.262307  , 2.50690645]), 'currentState': array([2.63217221, 4.99730978]), 'targetState': array([-0.1050099 , -0.05455889]), 'effectorPosition': array([-0.6504087 ,  1.46257698])}
episode index:668
target Thresh 1.526788732131539
current state at start:  [-2.45430556  2.03417761]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.45430556,  2.03417761]), 'currentState': array([4.22247768, 1.57381211]), 'targetState': array([-0.3884169 , -0.99065481]), 'effectorPosition': array([ 0.41324203, -1.35025904])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4470859208856671
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.45430556,  2.03417761]), 'currentState': array([3.21359384, 4.02492765]), 'targetState': array([-0.3884169 , -0.99065481]), 'effectorPosition': array([-0.42007474,  0.74456888])}
episode index:669
target Thresh 1.5277342088753731
current state at start:  [-1.36094774 -2.61221009]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.36094774, -2.61221009]), 'currentState': array([5.42223757, 4.11866567]), 'targetState': array([-0.84758236,  0.07602011]), 'effectorPosition': array([-0.34154609, -0.87432502])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.44641862846643476
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.36094774, -2.61221009]), 'currentState': array([1.30289878, 5.06486349]), 'targetState': array([-0.84758236,  0.07602011]), 'effectorPosition': array([1.26113007, 1.04880572])}
episode index:670
target Thresh 1.5286777965554132
current state at start:  [ 0.98440941 -2.86316358]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.98440941, -2.86316358]), 'currentState': array([1.21729893, 3.92002173]), 'targetState': array([-0.13003087,  0.07289956]), 'effectorPosition': array([0.7584396 , 0.02710082])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.44575332499629106
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.98440941, -2.86316358]), 'currentState': array([2.58487129, 4.81317062]), 'targetState': array([-0.13003087,  0.07289956]), 'effectorPosition': array([-0.40868589,  1.42625316])}
episode index:671
target Thresh 1.529619498946011
current state at start:  [-3.50766529  1.97997252]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.50766529,  1.97997252]), 'currentState': array([3.27552002, 1.51749748]), 'targetState': array([-0.67792626,  0.00683512]), 'effectorPosition': array([-0.91050393, -1.13027864])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.44509000159599893
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.50766529,  1.97997252]), 'currentState': array([4.40807279, 1.89394977]), 'targetState': array([-0.67792626,  0.00683512]), 'effectorPosition': array([ 0.70018173, -0.93521594])}
episode index:672
target Thresh 1.5305593198139773
current state at start:  [ 2.90788225 -2.00443575]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.90788225, -2.00443575]), 'currentState': array([2.40788225, 4.04977525]), 'targetState': array([-0.92864232,  1.02068346]), 'effectorPosition': array([0.24212338, 0.8432183 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.44442864943909555
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.90788225, -2.00443575]), 'currentState': array([4.37997091, 2.04381223]), 'targetState': array([-0.92864232,  1.02068346]), 'effectorPosition': array([ 0.66380272, -0.80512095])}
episode index:673
target Thresh 1.5314972629185972
current state at start:  [-0.13312202  2.68210931]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.13312202,  2.68210931]), 'currentState': array([5.65006329, 2.66972866]), 'targetState': array([0.4921046 , 0.76129667]), 'effectorPosition': array([0.35703732, 0.30179335])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.445252939276723
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.13312202,  2.68210931]), 'currentState': array([5.65006329, 2.66972866]), 'targetState': array([0.4921046 , 0.76129667]), 'effectorPosition': array([0.35703732, 0.30179335])}
episode index:674
target Thresh 1.5324333320116441
current state at start:  [ 1.58659584 -1.98109795]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.58659584, -1.98109795]), 'currentState': array([1.08659584, 4.80208736]), 'targetState': array([0.37120648, 1.34858113]), 'effectorPosition': array([1.38868894, 0.50069881])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4445933052926093
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.58659584, -1.98109795]), 'currentState': array([5.88911654, 5.93591194]), 'targetState': array([0.37120648, 1.34858113]), 'effectorPosition': array([ 1.66091742, -1.05922692])}
episode index:675
target Thresh 1.5333675308373953
current state at start:  [1.91388853 2.01640958]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.91388853, 2.01640958]), 'currentState': array([1.41388853, 1.51640958]), 'targetState': array([-0.6401358 , -0.33386602]), 'effectorPosition': array([-0.8214955 ,  1.19744103])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.44393562288833033
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.91388853, 2.01640958]), 'currentState': array([2.07378555, 4.63977415]), 'targetState': array([-0.6401358 , -0.33386602]), 'effectorPosition': array([0.42676293, 1.29335661])}
episode index:676
target Thresh 1.5342998631326479
current state at start:  [-1.30150346 -2.38237691]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.30150346, -2.38237691]), 'currentState': array([5.45917615, 4.4008084 ]), 'targetState': array([-0.26424859, -0.38388083]), 'effectorPosition': array([-0.22749851, -1.15547282])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4432798834158217
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.30150346, -2.38237691]), 'currentState': array([2.5376065 , 4.99938112]), 'targetState': array([-0.26424859, -0.38388083]), 'effectorPosition': array([-0.51136657,  1.5181046 ])}
episode index:677
target Thresh 1.535230332626732
current state at start:  [-0.74543843 -2.74821983]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.74543843, -2.74821983]), 'currentState': array([6.00048935, 4.0221959 ]), 'targetState': array([-0.01297497, -0.41624331]), 'effectorPosition': array([ 0.13379146, -0.84185965])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.4441010045317276
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.74543843, -2.74821983]), 'currentState': array([6.00048935, 4.0221959 ]), 'targetState': array([-0.01297497, -0.41624331]), 'effectorPosition': array([ 0.13379146, -0.84185965])}
episode index:678
target Thresh 1.536158943041527
current state at start:  [ 2.80579598 -2.17941926]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.80579598, -2.17941926]), 'currentState': array([2.30579598, 3.9252776 ]), 'targetState': array([-0.83182873,  0.85594347]), 'effectorPosition': array([0.32805559, 0.68974284])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4434469529786617
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.80579598, -2.17941926]), 'currentState': array([4.12706031, 1.98276943]), 'targetState': array([-0.83182873,  0.85594347]), 'effectorPosition': array([ 0.43253815, -1.00601913])}
episode index:679
target Thresh 1.5370856980914755
current state at start:  [-2.08608033  2.52492044]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.08608033,  2.52492044]), 'currentState': array([3.74866627, 2.02492044]), 'targetState': array([ 0.49457275, -1.12300309]), 'effectorPosition': array([ 0.05161946, -1.05829329])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.4442654133419284
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.08608033,  2.52492044]), 'currentState': array([3.74866627, 2.02492044]), 'targetState': array([ 0.49457275, -1.12300309]), 'effectorPosition': array([ 0.05161946, -1.05829329])}
episode index:680
target Thresh 1.5380106014835995
current state at start:  [ 0.27108587 -2.96696873]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.27108587, -2.96696873]), 'currentState': array([0.77108587, 3.37245121]), 'targetState': array([-0.04196436, -0.42621447]), 'effectorPosition': array([ 0.17848923, -0.14560558])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.44508147000368764
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.27108587, -2.96696873]), 'currentState': array([0.77108587, 3.37245121]), 'targetState': array([-0.04196436, -0.42621447]), 'effectorPosition': array([ 0.17848923, -0.14560558])}
episode index:681
target Thresh 1.5389336569175132
current state at start:  [-1.04904209 -2.58544417]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.04904209, -2.58544417]), 'currentState': array([5.73414322, 4.19774114]), 'targetState': array([0.05759337, 0.00463397]), 'effectorPosition': array([-0.02112863, -1.00752018])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4444288578775825
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.04904209, -2.58544417]), 'currentState': array([2.44790351, 4.79652436]), 'targetState': array([0.05759337, 0.00463397]), 'effectorPosition': array([-0.19639085,  1.45928165])}
episode index:682
target Thresh 1.53985486808544
current state at start:  [0.98298875 2.73413956]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.98298875, 2.73413956]), 'currentState': array([0.48298875, 3.21706506]), 'targetState': array([-0.82407645,  0.93509995]), 'effectorPosition': array([ 0.0375393 , -0.06545367])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4437781567679521
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.98298875, 2.73413956]), 'currentState': array([4.39355648, 2.61612922]), 'targetState': array([-0.82407645,  0.93509995]), 'effectorPosition': array([ 0.4340455 , -0.28534429])}
episode index:683
target Thresh 1.5407742386722254
current state at start:  [-0.86147909 -2.23266337]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.86147909, -2.23266337]), 'currentState': array([5.92170622, 4.22163401]), 'targetState': array([ 0.35616443, -0.58463033]), 'effectorPosition': array([ 0.18262179, -1.01196122])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.4445913465972387
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.86147909, -2.23266337]), 'currentState': array([5.92170622, 4.22163401]), 'targetState': array([ 0.35616443, -0.58463033]), 'effectorPosition': array([ 0.18262179, -1.01196122])}
episode index:684
target Thresh 1.5416917723553532
current state at start:  [1.64062777 2.01222098]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.64062777, 2.01222098]), 'currentState': array([1.15395259, 2.09691814]), 'targetState': array([-1.31411723, -0.14539641]), 'effectorPosition': array([-0.58915862,  0.80531067])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.443942308135053
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.64062777, 2.01222098]), 'currentState': array([3.93559482, 2.42706273]), 'targetState': array([-1.31411723, -0.14539641]), 'effectorPosition': array([ 0.29584701, -0.63377586])}
episode index:685
target Thresh 1.5426074728049595
current state at start:  [-0.12888882 -1.8482952 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.12888882, -1.8482952 ]), 'currentState': array([0.37111118, 4.01542123]), 'targetState': array([ 0.72035072, -1.05576857]), 'effectorPosition': array([ 0.61180455, -0.58472567])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.44475288786080364
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.12888882, -1.8482952 ]), 'currentState': array([0.37111118, 4.01542123]), 'targetState': array([ 0.72035072, -1.05576857]), 'effectorPosition': array([ 0.61180455, -0.58472567])}
episode index:686
target Thresh 1.543521343683847
current state at start:  [-2.95862829  2.51747061]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.95862829,  2.51747061]), 'currentState': array([3.70004557, 2.09267161]), 'targetState': array([-0.09096701, -0.55966938]), 'effectorPosition': array([ 0.03403657, -1.00091366])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.4455611078202493
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.95862829,  2.51747061]), 'currentState': array([3.70004557, 2.09267161]), 'targetState': array([-0.09096701, -0.55966938]), 'effectorPosition': array([ 0.03403657, -1.00091366])}
episode index:687
target Thresh 1.5444333886475008
current state at start:  [ 0.90212728 -2.49444023]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.90212728, -2.49444023]), 'currentState': array([1.40212728, 4.28874508]), 'targetState': array([-0.02801194, -0.02276996]), 'effectorPosition': array([0.99752206, 0.42752761])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4449134899309757
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.90212728, -2.49444023]), 'currentState': array([2.7397986 , 5.07323944]), 'targetState': array([-0.02801194, -0.02276996]), 'effectorPosition': array([-0.87942872,  1.39023208])}
episode index:688
target Thresh 1.5453436113441015
current state at start:  [ 2.69216791 -2.40259303]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.69216791, -2.40259303]), 'currentState': array([3.19216791, 4.24942833]), 'targetState': array([0.50793192, 0.07492684]), 'effectorPosition': array([-0.59792545,  0.86561368])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4442677519194649
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.69216791, -2.40259303]), 'currentState': array([2.82164099, 4.19941737]), 'targetState': array([0.50793192, 0.07492684]), 'effectorPosition': array([-0.20934956,  0.98723638])}
episode index:689
target Thresh 1.5462520154145416
current state at start:  [ 0.49565995 -2.30533779]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.49565995, -2.30533779]), 'currentState': array([0.99565995, 3.48090139]), 'targetState': array([ 1.01970934, -0.31473044]), 'effectorPosition': array([ 0.31030144, -0.13320317])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4436238856123352
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.49565995, -2.30533779]), 'currentState': array([4.95060428, 5.23726786]), 'targetState': array([ 1.01970934, -0.31473044]), 'effectorPosition': array([-0.48673219, -1.66292157])}
episode index:690
target Thresh 1.5471586044924384
current state at start:  [-2.89706043  2.57832075]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.89706043,  2.57832075]), 'currentState': array([2.93447622, 2.1514254 ]), 'targetState': array([-0.56309266, -1.20989016]), 'effectorPosition': array([-0.61373983, -0.72541255])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.4444290608864129
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.89706043,  2.57832075]), 'currentState': array([2.93447622, 2.1514254 ]), 'targetState': array([-0.56309266, -1.20989016]), 'effectorPosition': array([-0.61373983, -0.72541255])}
episode index:691
target Thresh 1.5480633822041492
current state at start:  [ 3.98775512 -2.2564508 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.98775512, -2.2564508 ]), 'currentState': array([3.54245076, 3.55568467]), 'targetState': array([-1.23717711, -0.23849281]), 'effectorPosition': array([-0.2348218 ,  0.33748282])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.44378682235912037
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.98775512, -2.2564508 ]), 'currentState': array([1.40068357, 4.57309401]), 'targetState': array([-1.23717711, -0.23849281]), 'effectorPosition': array([1.12180756, 0.68107114])}
episode index:692
target Thresh 1.5489663521687862
current state at start:  [-1.33702237  1.96484419]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.33702237,  1.96484419]), 'currentState': array([4.44616293, 1.46484419]), 'targetState': array([0.39471784, 0.13606126]), 'effectorPosition': array([ 0.66844515, -1.32841601])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4431464373340711
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.33702237,  1.96484419]), 'currentState': array([2.53420903, 4.25285453]), 'targetState': array([0.39471784, 0.13606126]), 'effectorPosition': array([0.05457258, 1.05354641])}
episode index:693
target Thresh 1.5498675179982304
current state at start:  [-0.87026587  1.85924725]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.87026587,  1.85924725]), 'currentState': array([5.89174027, 1.35924725]), 'targetState': array([ 0.72940958, -0.37899904]), 'effectorPosition': array([1.4914698 , 0.44211676])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4425078977990076
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.87026587,  1.85924725]), 'currentState': array([2.03757453, 6.15990715]), 'targetState': array([ 0.72940958, -0.37899904]), 'effectorPosition': array([-0.78679623,  1.83460443])}
episode index:694
target Thresh 1.5507668832971468
current state at start:  [0.40551677 2.66312954]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.40551677, 2.66312954]), 'currentState': array([6.19623748, 3.04577858]), 'targetState': array([-0.15965002,  0.85482584]), 'effectorPosition': array([0.01287694, 0.09490785])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.441871195787786
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.40551677, 2.66312954]), 'currentState': array([4.79937677, 1.02167736]), 'targetState': array([-0.15965002,  0.85482584]), 'effectorPosition': array([ 0.98198246, -1.44207569])}
episode index:695
target Thresh 1.5516644516629972
current state at start:  [-2.0303045  -2.06554136]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.0303045 , -2.06554136]), 'currentState': array([4.053559  , 4.71764395]), 'targetState': array([-1.14633249, -0.32668261]), 'effectorPosition': array([-1.40610729, -0.1826805 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.44267310498924034
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.0303045 , -2.06554136]), 'currentState': array([4.053559  , 4.71764395]), 'targetState': array([-1.14633249, -0.32668261]), 'effectorPosition': array([-1.40610729, -0.1826805 ])}
episode index:696
target Thresh 1.5525602266860565
current state at start:  [ 0.45776399 -1.8403135 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.45776399, -1.8403135 ]), 'currentState': array([0.89546784, 4.92347569]), 'targetState': array([ 1.12637603, -0.39401682]), 'effectorPosition': array([1.51931505, 0.33275668])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4420379929304323
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.45776399, -1.8403135 ]), 'currentState': array([2.86252951, 3.63756814]), 'targetState': array([ 1.12637603, -0.39401682]), 'effectorPosition': array([0.01525269, 0.49067051])}
episode index:697
target Thresh 1.553454211949426
current state at start:  [1.13579565 2.42058647]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.13579565, 2.42058647]), 'currentState': array([0.63579565, 1.92058647]), 'targetState': array([-0.04324916, -0.04169081]), 'effectorPosition': array([-0.02899633,  1.14619277])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.44140470067695026
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.13579565, 2.42058647]), 'currentState': array([2.13960772, 4.6760044 ]), 'targetState': array([-0.04324916, -0.04169081]), 'effectorPosition': array([0.32294671, 1.35016752])}
episode index:698
target Thresh 1.554346411029048
current state at start:  [-0.53007319  2.12622532]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.53007319,  2.12622532]), 'currentState': array([6.16271553, 1.65224337]), 'targetState': array([ 1.05860951, -0.00193203]), 'effectorPosition': array([1.03176512, 0.87906012])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.44077322041847106
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.53007319,  2.12622532]), 'currentState': array([2.50789905, 3.87471034]), 'targetState': array([ 1.05860951, -0.00193203]), 'effectorPosition': array([0.18921556, 0.69138563])}
episode index:699
target Thresh 1.5552368274937196
current state at start:  [ 3.20660382 -2.49539134]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.20660382, -2.49539134]), 'currentState': array([2.72391846, 4.24354289]), 'targetState': array([0.07259096, 0.07098022]), 'effectorPosition': array([-0.13915797,  1.03774788])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4401435443893018
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.20660382, -2.49539134]), 'currentState': array([2.33562546, 4.53836847]), 'targetState': array([0.07259096, 0.07098022]), 'effectorPosition': array([0.13807679, 1.27853344])}
episode index:700
target Thresh 1.5561254649051084
current state at start:  [ 2.26360535 -2.11439969]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.26360535, -2.11439969]), 'currentState': array([1.76360535, 4.66878562]), 'targetState': array([-0.01311853,  0.56248366]), 'effectorPosition': array([0.79727285, 1.13012252])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.43951566486806176
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.26360535, -2.11439969]), 'currentState': array([2.15570387, 5.71809005]), 'targetState': array([-0.01311853,  0.56248366]), 'effectorPosition': array([-0.5719333 ,  1.83356688])}
episode index:701
target Thresh 1.5570123268177647
current state at start:  [ 1.53651697 -2.19357206]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.53651697, -2.19357206]), 'currentState': array([2.01829574, 4.58961325]), 'targetState': array([ 0.21923908, -0.17971661]), 'effectorPosition': array([0.51502639, 1.22057887])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4388895741773665
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.53651697, -2.19357206]), 'currentState': array([2.59376334, 4.11986142]), 'targetState': array([ 0.21923908, -0.17971661]), 'effectorPosition': array([0.05512536, 0.93810565])}
episode index:702
target Thresh 1.557897416779138
current state at start:  [-0.31242048 -2.09494079]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.31242048, -2.09494079]), 'currentState': array([5.5055166 , 3.71156769]), 'targetState': array([ 0.90628601, -0.25599259]), 'effectorPosition': array([-0.26595794, -0.49541648])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.43826526468351534
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.31242048, -2.09494079]), 'currentState': array([3.03404482, 3.64194587]), 'targetState': array([ 0.90628601, -0.25599259]), 'effectorPosition': array([-0.07038346,  0.49012227])}
episode index:703
target Thresh 1.5587807383295886
current state at start:  [-1.09429047  2.03996853]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.09429047,  2.03996853]), 'currentState': array([4.68889483, 1.53996853]), 'targetState': array([ 0.52871807, -0.11661888]), 'effectorPosition': array([ 0.97503294, -1.05401925])}
done in step count: 76
reward sum = 0.46588077516979337
running average episode reward sum: 0.43830449126091064
{'reset': False, 'endBeforeDone': False, 'stepCount': 77, 'initial state': array([-1.09429047,  2.03996853]), 'currentState': array([0.05901477, 3.63101286]), 'targetState': array([ 0.52871807, -0.11661888]), 'effectorPosition': array([ 0.14491764, -0.46237185])}
episode index:704
target Thresh 1.5596622950024046
current state at start:  [-3.25210775  2.79528215]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.25210775,  2.79528215]), 'currentState': array([2.53107756, 2.80477873]), 'targetState': array([-0.80559839, -0.91154118]), 'effectorPosition': array([-0.2354992 , -0.23856936])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4376827827626682
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.25210775,  2.79528215]), 'currentState': array([3.03102967, 3.6947046 ]), 'targetState': array([-0.80559839, -0.91154118]), 'effectorPosition': array([-0.09023111,  0.53858212])}
episode index:705
target Thresh 1.5605420903238132
current state at start:  [1.12072342 1.88935797]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.12072342, 1.88935797]), 'currentState': array([0.62072342, 1.61130839]), 'targetState': array([-0.72158813,  1.00671135]), 'effectorPosition': array([0.19936551, 1.37085792])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4370628354783018
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.12072342, 1.88935797]), 'currentState': array([4.24809206, 2.95272413]), 'targetState': array([-0.72158813,  1.00671135]), 'effectorPosition': array([ 0.15990907, -0.09997249])}
episode index:706
target Thresh 1.5614201278129973
current state at start:  [1.65020764 2.92329383]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.65020764, 2.92329383]), 'currentState': array([1.16341579, 3.42329383]), 'targetState': array([-0.74210717,  0.10347976]), 'effectorPosition': array([ 0.27085683, -0.07395092])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4364446419344853
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.65020764, 2.92329383]), 'currentState': array([4.58544994, 1.86494835]), 'targetState': array([-0.74210717,  0.10347976]), 'effectorPosition': array([ 0.85945404, -0.8255192 ])}
episode index:707
target Thresh 1.5622964109821078
current state at start:  [-0.63510412 -2.52345786]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.63510412, -2.52345786]), 'currentState': array([6.14808118, 4.25972745]), 'targetState': array([0.06766106, 0.08351732]), 'effectorPosition': array([ 0.43638428, -0.96687519])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4358281947001145
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.63510412, -2.52345786]), 'currentState': array([5.19076203, 0.22246171]), 'targetState': array([0.06766106, 0.08351732]), 'effectorPosition': array([ 1.10519139, -1.65204919])}
episode index:708
target Thresh 1.5631709433362786
current state at start:  [1.0989554  1.78519423]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.0989554 , 1.78519423]), 'currentState': array([0.70393771, 1.41139148]), 'targetState': array([-0.67731463,  0.83115953]), 'effectorPosition': array([0.24428095, 1.50259378])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.43521348638601
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.0989554 , 1.78519423]), 'currentState': array([4.25351683, 2.6014417 ]), 'targetState': array([-0.67731463,  0.83115953]), 'effectorPosition': array([ 0.39800555, -0.35542856])}
episode index:709
target Thresh 1.5640437283736404
current state at start:  [0.08554732 1.72812048]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.08554732, 1.72812048]), 'currentState': array([5.97842547, 1.27635899]), 'targetState': array([0.30389034, 0.51777945]), 'effectorPosition': array([1.51789873, 0.52572457])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.43460050964462127
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.08554732, 1.72812048]), 'currentState': array([5.69690358, 0.42212675]), 'targetState': array([0.30389034, 0.51777945]), 'effectorPosition': array([ 1.81956043, -0.71668625])}
episode index:710
target Thresh 1.5649147695853345
current state at start:  [-0.39073368  2.88379899]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.39073368,  2.88379899]), 'currentState': array([0.10632704, 2.38379899]), 'targetState': array([-0.32663484, -0.55519089]), 'effectorPosition': array([0.19915724, 0.71248012])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4339892571697343
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.39073368,  2.88379899]), 'currentState': array([2.46882714, 4.00212696]), 'targetState': array([-0.32663484, -0.55519089]), 'effectorPosition': array([0.20032185, 0.80981865])}
episode index:711
target Thresh 1.5657840704555266
current state at start:  [-0.39107097 -2.36787699]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.39107097, -2.36787699]), 'currentState': array([0.10892903, 4.41530832]), 'targetState': array([-0.74500715, -0.20946093]), 'effectorPosition': array([ 0.80702964, -0.8736379 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.43337972169618133
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.39107097, -2.36787699]), 'currentState': array([1.6779322, 4.3812743]), 'targetState': array([-0.74500715, -0.20946093]), 'effectorPosition': array([0.8680904 , 0.77215565])}
episode index:712
target Thresh 1.5666516344614216
current state at start:  [ 1.52939242 -1.6260736 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.52939242, -1.6260736 ]), 'currentState': array([2.02939242, 4.63021057]), 'targetState': array([1.31200937, 0.13194069]), 'effectorPosition': array([0.48729773, 1.2642662 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.43277189599955274
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.52939242, -1.6260736 ]), 'currentState': array([2.95064944, 4.60786559]), 'targetState': array([1.31200937, 0.13194069]), 'effectorPosition': array([-0.69063939,  1.14645143])}
episode index:713
target Thresh 1.5675174650732768
current state at start:  [-1.59963495  3.0238554 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.59963495,  3.0238554 ]), 'currentState': array([4.19525656, 2.6370358 ]), 'targetState': array([-0.01787317,  0.37533049]), 'effectorPosition': array([ 0.35860136, -0.34731469])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4321657728959119
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.59963495,  3.0238554 ]), 'currentState': array([5.12964197, 6.24550824]), 'targetState': array([-0.01787317,  0.37533049]), 'effectorPosition': array([ 0.77577727, -1.84302747])}
episode index:714
target Thresh 1.5683815657544156
current state at start:  [ 3.38020002 -1.82515337]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.38020002, -1.82515337]), 'currentState': array([2.93382906, 4.4500667 ]), 'targetState': array([-1.03927342, -0.01920167]), 'effectorPosition': array([-0.52553182,  1.0978015 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.431561345241512
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.38020002, -1.82515337]), 'currentState': array([4.15270603, 2.44588929]), 'targetState': array([-1.03927342, -0.01920167]), 'effectorPosition': array([ 0.41975172, -0.5372172 ])}
episode index:715
target Thresh 1.569243939961242
current state at start:  [-1.23898677  2.26929049]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.23898677,  2.26929049]), 'currentState': array([4.58245557, 1.76929049]), 'targetState': array([ 0.38929426, -0.52708789]), 'effectorPosition': array([ 0.86808252, -0.92306347])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.43235525397720825
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.23898677,  2.26929049]), 'currentState': array([4.58245557, 1.76929049]), 'targetState': array([ 0.38929426, -0.52708789]), 'effectorPosition': array([ 0.86808252, -0.92306347])}
episode index:716
target Thresh 1.5701045911432536
current state at start:  [-1.2859793  -2.39714853]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.2859793 , -2.39714853]), 'currentState': array([5.49720601, 4.33628413]), 'targetState': array([-0.3549843 , -0.07613673]), 'effectorPosition': array([-0.21093766, -1.10494549])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4317522480441856
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.2859793 , -2.39714853]), 'currentState': array([4.60620235, 0.99268841]), 'targetState': array([-0.3549843 , -0.07613673]), 'effectorPosition': array([ 0.66887799, -1.62649403])}
episode index:717
target Thresh 1.5709635227430567
current state at start:  [ 0.01287633 -2.36382564]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.01287633, -2.36382564]), 'currentState': array([0.51287633, 4.3817289 ]), 'targetState': array([-6.92111627e-05,  2.90029311e-03]), 'effectorPosition': array([ 1.05254632, -0.49275897])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.43115092179342773
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.01287633, -2.36382564]), 'currentState': array([2.30872749, 5.22410417]), 'targetState': array([-6.92111627e-05,  2.90029311e-03]), 'effectorPosition': array([-0.35710075,  1.68873502])}
episode index:718
target Thresh 1.571820738196379
current state at start:  [ 3.02757626 -1.87228637]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.02757626, -1.87228637]), 'currentState': array([2.5410006 , 4.90023924]), 'targetState': array([-0.58408893,  0.70312479]), 'effectorPosition': array([-0.42387879,  1.48115549])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.43055126821652445
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.02757626, -1.87228637]), 'currentState': array([4.3325604 , 2.64428033]), 'targetState': array([-0.58408893,  0.70312479]), 'effectorPosition': array([ 0.39815278, -0.28937605])}
episode index:719
target Thresh 1.572676240932083
current state at start:  [-3.76441058  2.57454082]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.76441058,  2.57454082]), 'currentState': array([3.01877473, 2.14023283]), 'targetState': array([-0.14194883, -0.13356081]), 'effectorPosition': array([-0.56054909, -0.77940337])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.42995328034400154
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.76441058,  2.57454082]), 'currentState': array([4.97265742, 1.26117009]), 'targetState': array([-0.14194883, -0.13356081]), 'effectorPosition': array([ 1.25612211, -1.01565869])}
episode index:720
target Thresh 1.5735300343721808
current state at start:  [ 2.33467777 -2.75759242]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.33467777, -2.75759242]), 'currentState': array([2.73884363, 3.89817306]), 'targetState': array([0.10029901, 0.58760441]), 'effectorPosition': array([0.01806505, 0.73844327])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.4307439137970612
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.33467777, -2.75759242]), 'currentState': array([2.73884363, 3.89817306]), 'targetState': array([0.10029901, 0.58760441]), 'effectorPosition': array([0.01806505, 0.73844327])}
episode index:721
target Thresh 1.5743821219318477
current state at start:  [ 3.62828787 -1.80841147]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.62828787, -1.80841147]), 'currentState': array([4.09616407, 4.93384684]), 'targetState': array([-1.11767885,  0.76096966]), 'effectorPosition': array([-1.50104474, -0.43147294])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.43014731557850566
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.62828787, -1.80841147]), 'currentState': array([3.99973297, 3.04754827]), 'targetState': array([-1.11767885,  0.76096966]), 'effectorPosition': array([ 0.06816248, -0.06474339])}
episode index:722
target Thresh 1.5752325070194346
current state at start:  [ 3.47577203 -1.80188666]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.47577203, -1.80188666]), 'currentState': array([2.97577203, 4.93401134]), 'targetState': array([-0.46690078,  0.00171129]), 'effectorPosition': array([-1.04205601,  1.16350524])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.42955236770080374
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.47577203, -1.80188666]), 'currentState': array([4.69544233, 1.58982627]), 'targetState': array([-0.46690078,  0.00171129]), 'effectorPosition': array([ 0.98305199, -0.99777311])}
episode index:723
target Thresh 1.5760811930364835
current state at start:  [ 4.29451535 -2.81227177]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.29451535, -2.81227177]), 'currentState': array([4.47015341, 3.02685386]), 'targetState': array([-0.93458906,  0.49342241]), 'effectorPosition': array([ 0.10956741, -0.03384575])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.42895906332552636
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 4.29451535, -2.81227177]), 'currentState': array([4.1071985 , 2.56889065]), 'targetState': array([-0.93458906,  0.49342241]), 'effectorPosition': array([ 0.35488242, -0.43952115])}
episode index:724
target Thresh 1.576928183377739
current state at start:  [-1.19422995 -2.81625425]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.19422995, -2.81625425]), 'currentState': array([5.58895536, 3.85241429]), 'targetState': array([0.47259528, 0.58760925]), 'effectorPosition': array([-0.23131576, -0.65638474])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4283673956519739
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.19422995, -2.81625425]), 'currentState': array([6.26816861, 4.90271358]), 'targetState': array([0.47259528, 0.58760925]), 'effectorPosition': array([ 1.17429858, -0.99968902])}
episode index:725
target Thresh 1.5777734814311641
current state at start:  [-0.66261238 -2.90016224]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.66261238, -2.90016224]), 'currentState': array([6.06517401, 3.84985547]), 'targetState': array([-0.08840394, -0.07220222]), 'effectorPosition': array([ 0.09411505, -0.68713622])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4277773579169161
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.66261238, -2.90016224]), 'currentState': array([1.62533916, 4.96756236]), 'targetState': array([-0.08840394, -0.07220222]), 'effectorPosition': array([0.89790431, 1.30330127])}
episode index:726
target Thresh 1.5786170905779522
current state at start:  [ 2.90702941 -2.30823038]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.90702941, -2.30823038]), 'currentState': array([2.40702941, 4.47495493]), 'targetState': array([0.04808826, 0.55465003]), 'effectorPosition': array([0.08388957, 1.23391396])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4271889433943344
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.90702941, -2.30823038]), 'currentState': array([5.2217537, 6.2253943]), 'targetState': array([0.04808826, 0.55465003]), 'effectorPosition': array([ 0.92400476, -1.77281593])}
episode index:727
target Thresh 1.5794590141925404
current state at start:  [-1.77421545  2.43792372]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.77421545,  2.43792372]), 'currentState': array([4.00896986, 1.97940306]), 'targetState': array([-0.00330898, -0.12476928]), 'effectorPosition': array([ 0.31002767, -1.0531954 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.42660214539516633
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.77421545,  2.43792372]), 'currentState': array([5.21626709, 0.50113906]), 'targetState': array([-0.00330898, -0.12476928]), 'effectorPosition': array([ 1.32699646, -1.41179042])}
episode index:728
target Thresh 1.5802992556426247
current state at start:  [ 4.20886175 -2.23835768]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.20886175, -2.23835768]), 'currentState': array([3.73730953, 4.54482763]), 'targetState': array([-0.36451959, -0.49124682]), 'effectorPosition': array([-1.24294   ,  0.34863082])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.42601695726705224
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 4.20886175, -2.23835768]), 'currentState': array([2.27621026, 4.58484229]), 'targetState': array([-0.36451959, -0.49124682]), 'effectorPosition': array([0.18928052, 1.30758196])}
episode index:729
target Thresh 1.581137818289172
current state at start:  [-1.80931881 -1.94929408]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.80931881, -1.94929408]), 'currentState': array([4.9738665 , 4.83389123]), 'targetState': array([-0.85286477,  0.33285597]), 'effectorPosition': array([-0.66904713, -1.3396951 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4254333723940837
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.80931881, -1.94929408]), 'currentState': array([4.49954255, 2.4065145 ]), 'targetState': array([-0.85286477,  0.33285597]), 'effectorPosition': array([ 0.60096357, -0.39406358])}
episode index:730
target Thresh 1.5819747054864342
current state at start:  [ 2.69893793 -2.20573989]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.69893793, -2.20573989]), 'currentState': array([3.19893793, 4.57744542]), 'targetState': array([0.67137673, 1.23601582]), 'effectorPosition': array([-0.92083577,  0.93967692])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.42485138419655416
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.69893793, -2.20573989]), 'currentState': array([0.38533971, 4.11108599]), 'targetState': array([0.67137673, 1.23601582]), 'effectorPosition': array([ 0.71238237, -0.60089647])}
episode index:731
target Thresh 1.5828099205819608
current state at start:  [-1.93408767 -2.3849069 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.93408767, -2.3849069 ]), 'currentState': array([3.8501772 , 4.39827841]), 'targetState': array([-0.08531928, -0.7623978 ]), 'effectorPosition': array([-1.14360637,  0.27243916])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4242709861307119
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.93408767, -2.3849069 ]), 'currentState': array([2.32036053, 3.73894514]), 'targetState': array([-0.08531928, -0.7623978 ]), 'effectorPosition': array([0.29372363, 0.50997176])}
episode index:732
target Thresh 1.5836434669166133
current state at start:  [-1.26215329 -2.6066142 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.26215329, -2.6066142 ]), 'currentState': array([5.49979747, 4.16938714]), 'targetState': array([-0.01995031,  0.039035  ]), 'effectorPosition': array([-0.26175421, -0.94766449])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4236921716885145
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.26215329, -2.6066142 ]), 'currentState': array([5.22241588, 0.5202906 ]), 'targetState': array([-0.01995031,  0.039035  ]), 'effectorPosition': array([ 1.34566313, -1.387278  ])}
episode index:733
target Thresh 1.5844753478245786
current state at start:  [-0.34578244  2.70227712]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.34578244,  2.70227712]), 'currentState': array([0.15138094, 2.29313397]), 'targetState': array([ 0.19429815, -0.41542921]), 'effectorPosition': array([0.22184228, 0.7927833 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4231149343973857
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.34578244,  2.70227712]), 'currentState': array([2.52033538, 3.35712496]), 'targetState': array([ 0.19429815, -0.41542921]), 'effectorPosition': array([0.10566921, 0.18737299])}
episode index:734
target Thresh 1.585305566633381
current state at start:  [-1.82353349  2.12424946]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.82353349,  2.12424946]), 'currentState': array([3.95965182, 1.62424946]), 'targetState': array([ 0.30865533, -1.16982779]), 'effectorPosition': array([ 0.08166428, -1.37349029])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.42389981203766136
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.82353349,  2.12424946]), 'currentState': array([3.95965182, 1.62424946]), 'targetState': array([ 0.30865533, -1.16982779]), 'effectorPosition': array([ 0.08166428, -1.37349029])}
episode index:735
target Thresh 1.586134126663897
current state at start:  [ 1.84779077 -2.29342144]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.84779077, -2.29342144]), 'currentState': array([1.44812208, 4.43588893]), 'targetState': array([0.43653271, 0.67467326]), 'effectorPosition': array([1.04374901, 0.60382726])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.42332386120608845
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.84779077, -2.29342144]), 'currentState': array([6.13312004, 5.12857325]), 'targetState': array([0.43653271, 0.67467326]), 'effectorPosition': array([ 1.25175037, -1.11430148])}
episode index:736
target Thresh 1.586961031230368
current state at start:  [-2.78179044  2.28865106]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.78179044,  2.28865106]), 'currentState': array([3.98704606, 1.78865106]), 'targetState': array([ 0.09135618, -0.26832716]), 'effectorPosition': array([ 0.21057589, -1.23425551])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.42274947333470975
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.78179044,  2.28865106]), 'currentState': array([5.69004712, 0.21276899]), 'targetState': array([ 0.09135618, -0.26832716]), 'effectorPosition': array([ 1.75771825, -0.93022924])}
episode index:737
target Thresh 1.587786283640413
current state at start:  [ 2.15996952 -1.92494534]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.15996952, -1.92494534]), 'currentState': array([1.69634582, 4.85823997]), 'targetState': array([-0.37666184,  1.13864729]), 'effectorPosition': array([0.83817648, 1.26020993])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4221766420700286
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.15996952, -1.92494534]), 'currentState': array([5.15077778, 1.38718353]), 'targetState': array([-0.37666184,  1.13864729]), 'effectorPosition': array([ 1.39220095, -0.65340811])}
episode index:738
target Thresh 1.5886098871950431
current state at start:  [1.75540941 2.69162886]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.75540941, 2.69162886]), 'currentState': array([2.23575665, 2.19162886]), 'targetState': array([ 0.0682914 , -0.31863315]), 'effectorPosition': array([-0.89818869, -0.17271941])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4216053610929379
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.75540941, 2.69162886]), 'currentState': array([5.46857263, 0.16398818]), 'targetState': array([ 0.0682914 , -0.31863315]), 'effectorPosition': array([ 1.48185591, -1.33314333])}
episode index:739
target Thresh 1.5894318451886735
current state at start:  [1.29920507 2.38487018]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.29920507, 2.38487018]), 'currentState': array([0.83931965, 2.76138852]), 'targetState': array([-0.42514238,  0.88970337]), 'effectorPosition': array([-0.22847552,  0.30103345])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.42103562411848794
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.29920507, 2.38487018]), 'currentState': array([4.70239401, 2.09699285]), 'targetState': array([-0.42514238,  0.88970337]), 'effectorPosition': array([ 0.85970548, -0.50636985])}
episode index:740
target Thresh 1.5902521609091371
current state at start:  [ 1.79922899 -1.6292399 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.79922899, -1.6292399 ]), 'currentState': array([1.33455845, 5.12992014]), 'targetState': array([0.12035425, 0.98481735]), 'effectorPosition': array([1.21765799, 1.15252718])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.420467424895656
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.79922899, -1.6292399 ]), 'currentState': array([5.22709835, 0.45368771]), 'targetState': array([0.12035425, 0.98481735]), 'effectorPosition': array([ 1.31626041, -1.43705686])}
episode index:741
target Thresh 1.591070837637698
current state at start:  [ 1.73764056 -2.81043366]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.73764056, -2.81043366]), 'currentState': array([1.23764056, 3.93709186]), 'targetState': array([0.01870998, 0.03646826]), 'effectorPosition': array([0.77307363, 0.05000535])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4199007572071174
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.73764056, -2.81043366]), 'currentState': array([5.33653443, 0.53383224]), 'targetState': array([0.01870998, 0.03646826]), 'effectorPosition': array([ 1.5003977 , -1.21265559])}
episode index:742
target Thresh 1.5918878786490642
current state at start:  [-2.33204174  2.35057685]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.33204174,  2.35057685]), 'currentState': array([3.62342361, 1.85057685]), 'targetState': array([-0.10277973, -0.44542054]), 'effectorPosition': array([-0.19605933, -1.18712734])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.419335614869019
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.33204174,  2.35057685]), 'currentState': array([5.3608445 , 0.04473368]), 'targetState': array([-0.10277973, -0.44542054]), 'effectorPosition': array([ 1.24294974, -1.5662296 ])}
episode index:743
target Thresh 1.5927032872114009
current state at start:  [ 0.35761241 -1.80353077]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.35761241, -1.80353077]), 'currentState': array([0.76666192, 4.56405821]), 'targetState': array([ 1.00256426, -0.13835663]), 'effectorPosition': array([ 1.29990653, -0.12111206])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.4201160777522595
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.35761241, -1.80353077]), 'currentState': array([0.76666192, 4.56405821]), 'targetState': array([ 1.00256426, -0.13835663]), 'effectorPosition': array([ 1.29990653, -0.12111206])}
episode index:744
target Thresh 1.5935170665863434
current state at start:  [-3.6355209   2.29843723]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.6355209 ,  2.29843723]), 'currentState': array([3.07492066, 2.21489063]), 'targetState': array([-0.76448397, -0.29790611]), 'effectorPosition': array([-0.45191226, -0.77124989])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.420894445433129
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.6355209 ,  2.29843723]), 'currentState': array([3.07492066, 2.21489063]), 'targetState': array([-0.76448397, -0.29790611]), 'effectorPosition': array([-0.45191226, -0.77124989])}
episode index:745
target Thresh 1.5943292200290102
current state at start:  [ 3.88922304 -2.39896355]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.88922304, -2.39896355]), 'currentState': array([4.29002347, 4.37938967]), 'targetState': array([-0.0964633 ,  0.02022106]), 'effectorPosition': array([-1.13794072, -0.22656752])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4203302437636476
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.88922304, -2.39896355]), 'currentState': array([5.20578223, 1.36576983]), 'targetState': array([-0.0964633 ,  0.02022106]), 'effectorPosition': array([ 1.43232678, -0.59634404])}
episode index:746
target Thresh 1.5951397507880163
current state at start:  [-1.23517252  2.94245586]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.23517252,  2.94245586]), 'currentState': array([5.54801279, 3.44245586]), 'targetState': array([0.83192025, 0.79627699]), 'effectorPosition': array([-0.16544584, -0.24993119])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4197675526742719
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.23517252,  2.94245586]), 'currentState': array([6.22777287, 3.28033131]), 'targetState': array([0.83192025, 0.79627699]), 'effectorPosition': array([ 0.00193474, -0.13861391])}
episode index:747
target Thresh 1.595948662105486
current state at start:  [-0.08558866 -1.66060572]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.08558866, -1.66060572]), 'currentState': array([0.36006794, 5.10158317]), 'targetState': array([ 0.3072062 , -0.27768435]), 'effectorPosition': array([ 1.61697157, -0.37985382])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4192063661065255
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.08558866, -1.66060572]), 'currentState': array([5.39542078, 4.6761315 ]), 'targetState': array([ 0.3072062 , -0.27768435]), 'effectorPosition': array([-0.16688422, -1.37827812])}
episode index:748
target Thresh 1.5967559572170649
current state at start:  [-1.6630841  -2.27266548]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.6630841 , -2.27266548]), 'currentState': array([4.97784021, 4.44842708]), 'targetState': array([-0.35209669, -1.00996418]), 'effectorPosition': array([-0.73765417, -0.96646355])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.4199817915189334
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.6630841 , -2.27266548]), 'currentState': array([4.97784021, 4.44842708]), 'targetState': array([-0.35209669, -1.00996418]), 'effectorPosition': array([-0.73765417, -0.96646355])}
episode index:749
target Thresh 1.5975616393519352
current state at start:  [ 0.86343968 -2.01599373]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.86343968, -2.01599373]), 'currentState': array([1.36343968, 4.68472074]), 'targetState': array([ 0.97953335, -0.13429117]), 'effectorPosition': array([1.17838244, 0.74571135])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4194218157969081
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.86343968, -2.01599373]), 'currentState': array([4.68347073, 5.36370667]), 'targetState': array([ 0.97953335, -0.13429117]), 'effectorPosition': array([-0.84139618, -1.58256823])}
episode index:750
target Thresh 1.5983657117328263
current state at start:  [-1.58950084  1.81730028]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.58950084,  1.81730028]), 'currentState': array([4.22128142, 1.36662309]), 'targetState': array([ 1.05380063, -0.69373004]), 'effectorPosition': array([ 0.29627102, -1.52241215])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.41886333135510134
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.58950084,  1.81730028]), 'currentState': array([3.02863336, 2.08995896]), 'targetState': array([ 1.05380063, -0.69373004]), 'effectorPosition': array([-0.59850241, -0.80590837])}
episode index:751
target Thresh 1.599168177576029
current state at start:  [-0.37379811 -2.42941956]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.37379811, -2.42941956]), 'currentState': array([0.12620189, 4.35376575]), 'targetState': array([-0.5625568 , -1.21974939]), 'effectorPosition': array([ 0.76171267, -0.84724438])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4183063322442568
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.37379811, -2.42941956]), 'currentState': array([2.75120468, 0.74184562]), 'targetState': array([-0.5625568 , -1.21974939]), 'effectorPosition': array([-1.86363338,  0.03628052])}
episode index:752
target Thresh 1.5999690400914073
current state at start:  [-0.5469951   2.22098342]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.5469951 ,  2.22098342]), 'currentState': array([5.23619021, 1.79451401]), 'targetState': array([0.12968457, 0.40487179]), 'effectorPosition': array([ 1.23355314, -0.18610288])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.41775081254672125
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.5469951 ,  2.22098342]), 'currentState': array([6.04861363, 0.17355348]), 'targetState': array([0.12968457, 0.40487179]), 'effectorPosition': array([ 1.97075295, -0.29340675])}
episode index:753
target Thresh 1.6007683024824126
current state at start:  [0.30161255 2.08662242]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.30161255, 2.08662242]), 'currentState': array([6.08479786, 1.58662242]), 'targetState': array([0.00223795, 0.3547472 ]), 'effectorPosition': array([1.16193462, 0.78629324])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4171967663762349
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.30161255, 2.08662242]), 'currentState': array([5.62266508, 0.67434722]), 'targetState': array([0.00223795, 0.3547472 ]), 'effectorPosition': array([ 1.78957757, -0.59970118])}
episode index:754
target Thresh 1.6015659679460956
current state at start:  [0.51154504 2.53022522]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.51154504, 2.53022522]), 'currentState': array([0.01154504, 3.03022522]), 'targetState': array([-0.08218878,  1.07095139]), 'effectorPosition': array([0.00491148, 0.11120147])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4166441878777233
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.51154504, 2.53022522]), 'currentState': array([5.22311699, 0.14675398]), 'targetState': array([-0.08218878,  1.07095139]), 'effectorPosition': array([ 1.09993818, -1.66392244])}
episode index:755
target Thresh 1.6023620396731193
current state at start:  [ 3.30467453 -2.17365939]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.30467453, -2.17365939]), 'currentState': array([3.10723486, 4.59823305]), 'targetState': array([0.02135486, 0.17902637]), 'effectorPosition': array([-0.85144144,  1.02334313])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4160930712270914
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.30467453, -2.17365939]), 'currentState': array([4.71019102, 0.41871093]), 'targetState': array([0.02135486, 0.17902637]), 'effectorPosition': array([ 0.40237605, -1.91450284])}
episode index:756
target Thresh 1.6031565208477714
current state at start:  [-0.59187338 -2.14651355]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.59187338, -2.14651355]), 'currentState': array([6.19131193, 4.63667175]), 'targetState': array([-0.07765645, -0.51879518]), 'effectorPosition': array([ 0.82897541, -1.07773372])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.41554341063101863
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.59187338, -2.14651355]), 'currentState': array([4.56836799, 0.33603713]), 'targetState': array([-0.07765645, -0.51879518]), 'effectorPosition': array([ 0.04731474, -1.97126836])}
episode index:757
target Thresh 1.6039494146479776
current state at start:  [ 1.25700386 -2.64701669]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.25700386, -2.64701669]), 'currentState': array([0.75700386, 4.13026933]), 'targetState': array([0.08433668, 0.4870902 ]), 'effectorPosition': array([ 0.90089098, -0.29800004])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4149952003267561
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.25700386, -2.64701669]), 'currentState': array([5.19980212, 0.05135257]), 'targetState': array([0.08433668, 0.4870902 ]), 'effectorPosition': array([ 0.98141878, -1.74188997])}
episode index:758
target Thresh 1.6047407242453144
current state at start:  [ 3.34749971 -2.41523581]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.34749971, -2.41523581]), 'currentState': array([2.94803799, 4.3679495 ]), 'targetState': array([-0.17747154, -0.1037129 ]), 'effectorPosition': array([-0.46891219,  1.05108663])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.41444843458192504
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.34749971, -2.41523581]), 'currentState': array([5.41540644, 0.21256999]), 'targetState': array([-0.17747154, -0.1037129 ]), 'effectorPosition': array([ 1.4394433 , -1.37221969])}
episode index:759
target Thresh 1.6055304528050214
current state at start:  [0.07236765 2.59617689]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.07236765, 2.59617689]), 'currentState': array([5.85555295, 2.12253547]), 'targetState': array([-0.6950602 ,  0.21220045]), 'effectorPosition': array([0.78616176, 0.57759111])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4139031076943172
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.07236765, 2.59617689]), 'currentState': array([4.60329087, 1.7943848 ]), 'targetState': array([-0.6950602 ,  0.21220045]), 'effectorPosition': array([ 0.88457132, -0.87981431])}
episode index:760
target Thresh 1.6063186034860135
current state at start:  [ 1.62431719 -2.30565537]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.62431719, -2.30565537]), 'currentState': array([2.12431719, 4.47752993]), 'targetState': array([ 0.57197118, -0.03601098]), 'effectorPosition': array([0.42396991, 1.16397496])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.41335921399169656
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.62431719, -2.30565537]), 'currentState': array([5.59214266, 4.79465822]), 'targetState': array([ 0.57197118, -0.03601098]), 'effectorPosition': array([ 0.19872026, -1.45769105])}
episode index:761
target Thresh 1.6071051794408946
current state at start:  [1.01331145 2.46372978]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.01331145, 2.46372978]), 'currentState': array([1.48394809, 1.98442308]), 'targetState': array([-0.03958413, -0.00295521]), 'effectorPosition': array([-0.86034223,  0.67523737])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4128167478316025
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.01331145, 2.46372978]), 'currentState': array([5.03923898, 0.55339175]), 'targetState': array([-0.03958413, -0.00295521]), 'effectorPosition': array([ 1.09195427, -1.58402319])}
episode index:762
target Thresh 1.6078901838159696
current state at start:  [ 3.49458043 -2.25373404]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.49458043, -2.25373404]), 'currentState': array([3.99458043, 4.52945127]), 'targetState': array([-0.29194901,  0.53015512]), 'effectorPosition': array([-1.27876077,  0.03054164])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4122757036011548
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.49458043, -2.25373404]), 'currentState': array([4.4400298 , 1.24200484]), 'targetState': array([-0.29194901,  0.53015512]), 'effectorPosition': array([ 0.55568095, -1.52873073])}
episode index:763
target Thresh 1.608673619751257
current state at start:  [-4.10925484  2.69150042]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.10925484,  2.69150042]), 'currentState': array([2.67032123, 2.20359569]), 'targetState': array([ 0.3175453 , -0.21570379]), 'effectorPosition': array([-0.73016531, -0.53296322])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.41173607571686005
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-4.10925484,  2.69150042]), 'currentState': array([3.01962844, 0.14115943]), 'targetState': array([ 0.3175453 , -0.21570379]), 'effectorPosition': array([-1.99238736,  0.10246803])}
episode index:764
target Thresh 1.6094554903805018
current state at start:  [ 3.70688575 -2.15236804]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.70688575, -2.15236804]), 'currentState': array([3.26898503, 3.69814691]), 'targetState': array([-1.10867053, -0.11034204]), 'effectorPosition': array([-0.21681151,  0.50480883])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4111978586244197
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.70688575, -2.15236804]), 'currentState': array([4.0054781 , 2.17442378]), 'targetState': array([-1.10867053, -0.11034204]), 'effectorPosition': array([ 0.34518301, -0.86347175])}
episode index:765
target Thresh 1.6102357988311873
current state at start:  [ 1.74076998 -1.72229886]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.74076998, -1.72229886]), 'currentState': array([1.24995157, 5.06088645]), 'targetState': array([0.2300859 , 1.08594541]), 'effectorPosition': array([1.31498601, 0.97661853])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.41066104679853926
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.74076998, -1.72229886]), 'currentState': array([0.19288681, 4.66891738]), 'targetState': array([0.2300859 , 1.08594541]), 'effectorPosition': array([ 1.13031483, -0.79716534])}
episode index:766
target Thresh 1.6110145482245484
current state at start:  [ 0.63505084 -2.51188629]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.63505084, -2.51188629]), 'currentState': array([1.13505084, 4.22218154]), 'targetState': array([ 0.3431234 , -0.72730083]), 'effectorPosition': array([1.02315963, 0.10736173])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4101256347427394
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.63505084, -2.51188629]), 'currentState': array([4.88319675, 5.71426176]), 'targetState': array([ 0.3431234 , -0.72730083]), 'effectorPosition': array([-0.21770375, -1.9072409 ])}
episode index:767
target Thresh 1.6117917416755838
current state at start:  [ 4.19826046 -2.22929092]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.19826046, -2.22929092]), 'currentState': array([4.68114132, 4.43077107]), 'targetState': array([-0.28773857,  0.44998333]), 'effectorPosition': array([-0.98269807, -0.69172548])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4095916169891681
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 4.19826046, -2.22929092]), 'currentState': array([5.473043  , 0.71394837]), 'targetState': array([-0.28773857,  0.44998333]), 'effectorPosition': array([ 1.68477228, -0.82043094])}
episode index:768
target Thresh 1.6125673822930684
current state at start:  [1.66426293 2.27367698]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.66426293, 2.27367698]), 'currentState': array([1.17676173, 2.77367698]), 'targetState': array([-1.0360467 ,  0.94359136]), 'effectorPosition': array([-0.30641682,  0.19987658])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.40905898809841496
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.66426293, 2.27367698]), 'currentState': array([3.83712629, 2.66995873]), 'targetState': array([-1.0360467 ,  0.94359136]), 'effectorPosition': array([ 0.20732714, -0.41876154])}
episode index:769
target Thresh 1.6133414731795654
current state at start:  [ 0.47828458 -1.69632151]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.47828458, -1.69632151]), 'currentState': array([0.97828458, 5.0433454 ]), 'targetState': array([ 1.14901298, -0.38098462]), 'effectorPosition': array([1.52443534, 0.57095734])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4085277426593261
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.47828458, -1.69632151]), 'currentState': array([4.88774587, 6.02255152]), 'targetState': array([ 1.14901298, -0.38098462]), 'effectorPosition': array([ 0.08928599, -1.98103047])}
episode index:770
target Thresh 1.6141140174314397
current state at start:  [ 1.82304561 -1.59417144]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.82304561, -1.59417144]), 'currentState': array([2.27433559, 5.15851391]), 'targetState': array([0.59386412, 0.92215311]), 'effectorPosition': array([-0.2381267 ,  1.67518406])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.40799787528882114
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.82304561, -1.59417144]), 'currentState': array([5.91543345, 3.88476248]), 'targetState': array([0.59386412, 0.92215311]), 'effectorPosition': array([ 0.0027835 , -0.72617993])}
episode index:771
target Thresh 1.6148850181388692
current state at start:  [ 3.56221082 -2.38578393]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.56221082, -2.38578393]), 'currentState': array([3.11198085, 4.34130679]), 'targetState': array([-0.1401884 , -0.01784789]), 'effectorPosition': array([-0.60950415,  0.95039799])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4074693806317113
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.56221082, -2.38578393]), 'currentState': array([4.90342241, 5.9115564 ]), 'targetState': array([-0.1401884 , -0.01784789]), 'effectorPosition': array([ 0.01025822, -1.96554545])}
episode index:772
target Thresh 1.6156544783858577
current state at start:  [ 0.20113558 -1.88483139]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.20113558, -1.88483139]), 'currentState': array([0.70113558, 4.89782561]), 'targetState': array([ 0.4643944 , -0.11076053]), 'effectorPosition': array([1.53901983, 0.01301384])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.40694225336051887
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.20113558, -1.88483139]), 'currentState': array([5.05336938, 4.34760479]), 'targetState': array([ 0.4643944 , -0.11076053]), 'effectorPosition': array([-0.66530549, -0.91862572])}
episode index:773
target Thresh 1.6164224012502473
current state at start:  [ 2.84017397 -2.16494218]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.84017397, -2.16494218]), 'currentState': array([3.17326377, 4.58893123]), 'targetState': array([0.06369441, 0.36689355]), 'effectorPosition': array([-0.9078407 ,  0.96412474])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4064164881752986
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.84017397, -2.16494218]), 'currentState': array([5.2022839 , 5.77842595]), 'targetState': array([0.06369441, 0.36689355]), 'effectorPosition': array([ 0.45566928, -1.88227183])}
episode index:774
target Thresh 1.6171887898037305
current state at start:  [ 2.38955818 -1.71645352]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.38955818, -1.71645352]), 'currentState': array([1.91297553, 5.06427393]), 'targetState': array([-0.69457348,  0.80925682]), 'effectorPosition': array([0.43311191, 1.58169207])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4058920798034595
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.38955818, -1.71645352]), 'currentState': array([4.58323151, 1.86465124]), 'targetState': array([-0.69457348,  0.80925682]), 'effectorPosition': array([ 0.85766933, -0.82771688])}
episode index:775
target Thresh 1.6179536471118625
current state at start:  [-2.5601752   2.48264234]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.5601752 ,  2.48264234]), 'currentState': array([3.41131769, 2.01109855]), 'targetState': array([ 0.71343134, -0.007121  ]), 'effectorPosition': array([-0.31198975, -1.02481053])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.40536902299958905
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.5601752 ,  2.48264234]), 'currentState': array([5.19929771, 4.94422158]), 'targetState': array([ 0.71343134, -0.007121  ]), 'effectorPosition': array([-0.28473897, -1.54222135])}
episode index:776
target Thresh 1.6187169762340736
current state at start:  [-0.29796009 -1.6624864 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.29796009, -1.6624864 ]), 'currentState': array([0.18944896, 5.07755888]), 'targetState': array([-0.10718782, -0.89435539]), 'effectorPosition': array([ 1.50872749, -0.66178347])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4048473125452781
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.29796009, -1.6624864 ]), 'currentState': array([2.68193277, 0.93178304]), 'targetState': array([-0.10718782, -0.89435539]), 'effectorPosition': array([-1.78680817, -0.01113488])}
episode index:777
target Thresh 1.6194787802236812
current state at start:  [ 1.96944526 -2.49395673]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.96944526, -2.49395673]), 'currentState': array([2.45500362, 4.28922858]), 'targetState': array([ 0.02616129, -0.10671531]), 'effectorPosition': array([0.12217451, 1.07878872])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4043269432489474
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.96944526, -2.49395673]), 'currentState': array([4.78902493, 0.32584834]), 'targetState': array([ 0.02616129, -0.10671531]), 'effectorPosition': array([ 0.46826627, -1.91715563])}
episode index:778
target Thresh 1.6202390621279024
current state at start:  [-0.14519541  2.92969602]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.14519541,  2.92969602]), 'currentState': array([0.25235491, 2.56889531]), 'targetState': array([-0.03741761, -0.04506181]), 'effectorPosition': array([0.01919948, 0.56457657])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.40380790994567534
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.14519541,  2.92969602]), 'currentState': array([5.06671956, 5.91398273]), 'targetState': array([-0.03741761, -0.04506181]), 'effectorPosition': array([ 0.33209117, -1.93776838])}
episode index:779
target Thresh 1.6209978249878656
current state at start:  [-0.07762246 -3.08491465]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.07762246, -3.08491465]), 'currentState': array([0.42237754, 2.7203183 ]), 'targetState': array([ 0.79515489, -0.43182299]), 'effectorPosition': array([-0.0878825 ,  0.40882702])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.40329020749702704
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.07762246, -3.08491465]), 'currentState': array([5.11765397, 5.51982345]), 'targetState': array([ 0.79515489, -0.43182299]), 'effectorPosition': array([ 0.04376983, -1.85556351])}
episode index:780
target Thresh 1.6217550718386236
current state at start:  [-0.67467853 -2.82434566]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.67467853, -2.82434566]), 'currentState': array([6.10850678, 3.95883965]), 'targetState': array([-0.13255773, -0.36513487]), 'effectorPosition': array([ 0.18422322, -0.77304519])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.40405424052199884
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.67467853, -2.82434566]), 'currentState': array([6.10850678, 3.95883965]), 'targetState': array([-0.13255773, -0.36513487]), 'effectorPosition': array([ 0.18422322, -0.77304519])}
episode index:781
target Thresh 1.6225108057091644
current state at start:  [-4.19529818  2.11123741]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.19529818,  2.11123741]), 'currentState': array([2.58788713, 1.61320955]), 'targetState': array([-0.30376132,  0.253849  ]), 'effectorPosition': array([-1.33988653, -0.34627022])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.4035375471197968
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-4.19529818,  2.11123741]), 'currentState': array([5.93144843, 0.05042223]), 'targetState': array([-0.30376132,  0.253849  ]), 'effectorPosition': array([ 1.89372289, -0.64130474])}
episode index:782
target Thresh 1.623265029622425
current state at start:  [-3.1098987   1.79606285]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.1098987 ,  1.79606285]), 'currentState': array([3.65999787, 1.47836101]), 'targetState': array([-0.63466044, -0.52985959]), 'effectorPosition': array([-0.45540629, -1.40613392])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.40302217349639985
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.1098987 ,  1.79606285]), 'currentState': array([4.30011576, 1.70072974]), 'targetState': array([-0.63466044, -0.52985959]), 'effectorPosition': array([ 0.55971308, -1.1948159 ])}
episode index:783
target Thresh 1.6240177465953014
current state at start:  [ 0.39836704 -2.28247931]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.39836704, -2.28247931]), 'currentState': array([0.81674262, 4.500706  ]), 'targetState': array([-0.09481444, -0.06033769]), 'effectorPosition': array([ 1.25341033, -0.09354848])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.40250811460163405
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.39836704, -2.28247931]), 'currentState': array([5.42046165, 0.04350408]), 'targetState': array([-0.09481444, -0.06033769]), 'effectorPosition': array([ 1.33316255, -1.49022995])}
episode index:784
target Thresh 1.6247689596386632
current state at start:  [-2.38202936  2.28724942]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.38202936,  2.28724942]), 'currentState': array([3.40535402, 1.78724942]), 'targetState': array([ 0.41834195, -0.01597838]), 'effectorPosition': array([-0.50344678, -1.14760954])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.40199536541105874
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.38202936,  2.28724942]), 'currentState': array([5.20527552, 5.45165371]), 'targetState': array([ 0.41834195, -0.01597838]), 'effectorPosition': array([ 0.1409614 , -1.82417636])}
episode index:785
target Thresh 1.625518671757363
current state at start:  [-2.03582636 -1.69512316]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.03582636, -1.69512316]), 'currentState': array([4.73357553, 5.08806215]), 'targetState': array([-0.67146614,  0.46293953]), 'effectorPosition': array([-0.90109438, -1.3862996 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.40148392092580293
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.03582636, -1.69512316]), 'currentState': array([4.41169039, 2.28880689]), 'targetState': array([-0.67146614,  0.46293953]), 'effectorPosition': array([ 0.61799419, -0.54982523])}
episode index:786
target Thresh 1.6262668859502507
current state at start:  [ 2.02091407 -2.52698301]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.02091407, -2.52698301]), 'currentState': array([2.52091407, 4.2562023 ]), 'targetState': array([ 0.10577013, -0.04622446]), 'effectorPosition': array([0.066992  , 1.05567806])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.40097377617240293
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.02091407, -2.52698301]), 'currentState': array([5.34987664, 6.23684848]), 'targetState': array([ 0.10577013, -0.04622446]), 'effectorPosition': array([ 1.15249534, -1.63389344])}
episode index:787
target Thresh 1.627013605210184
current state at start:  [ 0.71936708 -2.70971698]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.71936708, -2.70971698]), 'currentState': array([0.58499468, 4.07346832]), 'targetState': array([0.04590123, 0.13230765]), 'effectorPosition': array([ 0.77981518, -0.4463514 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.40046492620264096
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.71936708, -2.70971698]), 'currentState': array([5.80754747, 5.96008531]), 'targetState': array([0.04590123, 0.13230765]), 'effectorPosition': array([ 1.58661241, -1.17438173])}
episode index:788
target Thresh 1.6277588325240406
current state at start:  [-0.69647157  2.38597058]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.69647157,  2.38597058]), 'currentState': array([5.19084508, 1.88597058]), 'targetState': array([ 0.06961364, -0.02315918]), 'effectorPosition': array([ 1.16167104, -0.17480301])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3999573660933854
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.69647157,  2.38597058]), 'currentState': array([5.64696857, 5.84370801]), 'targetState': array([ 0.06961364, -0.02315918]), 'effectorPosition': array([ 1.27947102, -1.47407675])}
episode index:789
target Thresh 1.6285025708727312
current state at start:  [0.51409326 2.79594008]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.51409326, 2.79594008]), 'currentState': array([1.01409326, 2.34059603]), 'targetState': array([ 0.6766357 , -0.47833996]), 'effectorPosition': array([-0.44899073,  0.63751428])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3994510909464318
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.51409326, 2.79594008]), 'currentState': array([4.41651423, 5.5432903 ]), 'targetState': array([ 0.6766357 , -0.47833996]), 'effectorPosition': array([-1.15183178, -1.46641135])}
episode index:790
target Thresh 1.6292448232312098
current state at start:  [ 0.92692909 -2.16716397]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.92692909, -2.16716397]), 'currentState': array([1.42692909, 4.60302609]), 'targetState': array([ 0.47569787, -0.3822374 ]), 'effectorPosition': array([1.11147969, 0.73913657])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.39894609588834523
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.92692909, -2.16716397]), 'currentState': array([5.26031232, 5.22441701]), 'targetState': array([ 0.47569787, -0.3822374 ]), 'effectorPosition': array([ 0.03200119, -1.72593983])}
episode index:791
target Thresh 1.629985592568487
current state at start:  [-0.15365719  2.9197044 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.15365719,  2.9197044 ]), 'currentState': array([5.71353797, 3.35442257]), 'targetState': array([0.00105947, 0.38852872]), 'effectorPosition': array([-0.09492199, -0.19004122])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3984423760703044
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.15365719,  2.9197044 ]), 'currentState': array([5.35723085, 0.04923372]), 'targetState': array([0.00105947, 0.38852872]), 'effectorPosition': array([ 1.24074725, -1.56784017])}
episode index:792
target Thresh 1.6307248818476412
current state at start:  [ 0.50747487 -2.56974087]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.50747487, -2.56974087]), 'currentState': array([1.00747487, 3.22473313]), 'targetState': array([ 1.12327616, -0.2291559 ]), 'effectorPosition': array([ 0.07205769, -0.04142521])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3979399266679459
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.50747487, -2.56974087]), 'currentState': array([5.14872258, 4.21952286]), 'targetState': array([ 1.12327616, -0.2291559 ]), 'effectorPosition': array([-0.57578303, -0.84980483])}
episode index:793
target Thresh 1.6314626940258303
current state at start:  [-1.26309087 -2.37670308]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.26309087, -2.37670308]), 'currentState': array([5.48982103, 4.40648222]), 'targetState': array([-1.01951745,  0.32131922]), 'effectorPosition': array([-0.18942495, -1.16696284])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.39743874288121045
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.26309087, -2.37670308]), 'currentState': array([4.68477709, 1.93312712]), 'targetState': array([-1.01951745,  0.32131922]), 'effectorPosition': array([ 0.91689431, -0.67111513])}
episode index:794
target Thresh 1.632199032054304
current state at start:  [-1.51162986  2.94261484]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.51162986,  2.94261484]), 'currentState': array([4.27155545, 2.44261484]), 'targetState': array([-0.22612971,  0.31592511]), 'effectorPosition': array([ 0.48186124, -0.4866304 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.39693881993419006
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.51162986,  2.94261484]), 'currentState': array([4.98528611, 6.27869927]), 'targetState': array([-0.22612971,  0.31592511]), 'effectorPosition': array([ 0.53472224, -1.92718759])}
episode index:795
target Thresh 1.632933898878416
current state at start:  [-2.93891656  2.15309209]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.93891656,  2.15309209]), 'currentState': array([3.70304329, 1.65309209]), 'targetState': array([ 0.15212249, -0.67520831]), 'effectorPosition': array([-0.24628745, -1.3322675 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.39644015307497626
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.93891656,  2.15309209]), 'currentState': array([4.74134525, 6.25201727]), 'targetState': array([ 0.15212249, -0.67520831]), 'effectorPosition': array([ 0.02674047, -1.99957835])}
episode index:796
target Thresh 1.6336672974376336
current state at start:  [-4.24470319  2.76008952]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.24470319,  2.76008952]), 'currentState': array([1.53848212, 3.25215462]), 'targetState': array([-1.06503179, -0.21232495]), 'effectorPosition': array([0.11047652, 0.00253774])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3959427375755095
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-4.24470319,  2.76008952]), 'currentState': array([1.21273762, 5.73719215]), 'targetState': array([-1.06503179, -0.21232495]), 'effectorPosition': array([1.13629587, 1.55500987])}
episode index:797
target Thresh 1.6343992306655526
current state at start:  [ 2.83192911 -2.11551161]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.83192911, -2.11551161]), 'currentState': array([3.12047152, 4.64580914]), 'targetState': array([0.14761006, 0.25934641]), 'effectorPosition': array([-0.91218837,  1.01727629])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3954465687314299
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.83192911, -2.11551161]), 'currentState': array([5.07738987, 5.46891994]), 'targetState': array([0.14761006, 0.25934641]), 'effectorPosition': array([-0.077353  , -1.83489023])}
episode index:798
target Thresh 1.635129701489907
current state at start:  [ 0.23930029 -2.28253944]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.23930029, -2.28253944]), 'currentState': array([0.66927228, 4.42917149]), 'targetState': array([-0.12077787,  0.11272849]), 'effectorPosition': array([ 1.16080987, -0.30598636])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.39495164186192877
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.23930029, -2.28253944]), 'currentState': array([4.71261894, 6.20375421]), 'targetState': array([-0.12077787,  0.11272849]), 'effectorPosition': array([-0.0788884, -1.9968652])}
episode index:799
target Thresh 1.6358587128325808
current state at start:  [-3.98002497  2.13987903]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.98002497,  2.13987903]), 'currentState': array([2.7616688, 2.5595539]), 'targetState': array([-1.09383637,  0.35736134]), 'effectorPosition': array([-0.35678175, -0.44946583])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.39445795230960135
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.98002497,  2.13987903]), 'currentState': array([3.98153336, 2.75743343]), 'targetState': array([-1.09383637,  0.35736134]), 'effectorPosition': array([ 0.23041035, -0.30443939])}
episode index:800
target Thresh 1.6365862676096203
current state at start:  [ 3.23282062 -2.03462556]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.23282062, -2.03462556]), 'currentState': array([3.30680139, 4.7197944 ]), 'targetState': array([0.12645677, 0.02907883]), 'effectorPosition': array([-1.15814229,  0.8206809 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.393965495440301
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.23282062, -2.03462556]), 'currentState': array([5.61615949, 6.06118115]), 'targetState': array([0.12645677, 0.02907883]), 'effectorPosition': array([ 1.41583063, -1.39511285])}
episode index:801
target Thresh 1.6373123687312456
current state at start:  [ 3.47334441 -2.86350266]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.47334441, -2.86350266]), 'currentState': array([3.1012383 , 3.89652767]), 'targetState': array([ 0.59413402, -0.35970342]), 'effectorPosition': array([-0.24381778,  0.69564412])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3934742666429939
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.47334441, -2.86350266]), 'currentState': array([5.40394761, 4.97433924]), 'targetState': array([ 0.59413402, -0.35970342]), 'effectorPosition': array([ 0.05891317, -1.58570451])}
episode index:802
target Thresh 1.6380370191018625
current state at start:  [-1.60710948  2.8108501 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.60710948,  2.8108501 ]), 'currentState': array([4.17607582, 2.34970592]), 'targetState': array([-0.00635413,  0.22736877]), 'effectorPosition': array([ 0.45974725, -0.61937455])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.39298426132961534
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.60710948,  2.8108501 ]), 'currentState': array([2.60772702, 5.91118504]), 'targetState': array([-0.00635413,  0.22736877]), 'effectorPosition': array([-1.4778508 ,  1.29582457])}
episode index:803
target Thresh 1.638760221620073
current state at start:  [-4.15634225  3.0134287 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.15634225,  3.0134287 ]), 'currentState': array([2.62684306, 2.5134287 ]), 'targetState': array([0.35398022, 0.00553546]), 'effectorPosition': array([-0.45547064, -0.41752941])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.39249547493492676
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-4.15634225,  3.0134287 ]), 'currentState': array([5.25091582, 5.46410044]), 'targetState': array([0.35398022, 0.00553546]), 'effectorPosition': array([ 0.23598   , -1.81936623])}
episode index:804
target Thresh 1.6394819791786885
current state at start:  [ 2.62380433 -2.09752387]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.62380433, -2.09752387]), 'currentState': array([2.1436375 , 4.68566144]), 'targetState': array([-0.23726803,  0.46847305]), 'effectorPosition': array([0.31252757, 1.35973446])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.39200790291637405
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.62380433, -2.09752387]), 'currentState': array([5.32242322, 6.01252217]), 'targetState': array([-0.23726803,  0.46847305]), 'effectorPosition': array([ 0.90578966, -1.76259261])}
episode index:805
target Thresh 1.6402022946647399
current state at start:  [-0.34495146  2.01211601]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.34495146,  2.01211601]), 'currentState': array([0.14356231, 1.51211601]), 'targetState': array([0.96871108, 0.46704914]), 'effectorPosition': array([0.90493252, 1.13946937])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.39152154075394674
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.34495146,  2.01211601]), 'currentState': array([5.83695515, 3.82912205]), 'targetState': array([0.96871108, 0.46704914]), 'effectorPosition': array([-0.06894787, -0.67053234])}
episode index:806
target Thresh 1.6409211709594902
current state at start:  [-0.44528948  1.78288869]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.44528948,  1.78288869]), 'currentState': array([5.33789582, 1.28288869]), 'targetState': array([0.6640104 , 0.82876767]), 'effectorPosition': array([ 1.52906081, -0.47944369])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.39103638395003854
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.44528948,  1.78288869]), 'currentState': array([5.90017523, 3.74229309]), 'targetState': array([0.6640104 , 0.82876767]), 'effectorPosition': array([-0.04885495, -0.5896892 ])}
episode index:807
target Thresh 1.6416386109384458
current state at start:  [-0.41612249  2.18556308]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.41612249,  2.18556308]), 'currentState': array([5.36706282, 1.70820405]), 'targetState': array([0.20887597, 1.25829594]), 'effectorPosition': array([ 1.3112657 , -0.08142974])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3905524280293083
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.41612249,  2.18556308]), 'currentState': array([6.06904715, 4.96169785]), 'targetState': array([0.20887597, 1.25829594]), 'effectorPosition': array([ 1.01232337, -1.21188692])}
episode index:808
target Thresh 1.642354617471367
current state at start:  [-2.631099    2.89698303]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.631099  ,  2.89698303]), 'currentState': array([4.12770809, 2.39698303]), 'targetState': array([-0.00533146,  0.27633607]), 'effectorPosition': array([ 0.41904563, -0.59472325])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.39006966853854275
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.631099  ,  2.89698303]), 'currentState': array([5.57126248, 6.03162939]), 'targetState': array([-0.00533146,  0.27633607]), 'effectorPosition': array([ 1.32777388, -1.4744725 ])}
episode index:809
target Thresh 1.6430691934222814
current state at start:  [ 0.56684867 -2.27244349]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.56684867, -2.27244349]), 'currentState': array([1.06684867, 3.5489678 ]), 'targetState': array([ 1.07280421, -0.00435895]), 'effectorPosition': array([ 0.38646372, -0.11965738])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.38958810104651986
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.56684867, -2.27244349]), 'currentState': array([5.40447603, 4.03013555]), 'targetState': array([ 1.07280421, -0.00435895]), 'effectorPosition': array([-0.36180623, -0.77974931])}
episode index:810
target Thresh 1.6437823416494937
current state at start:  [-2.73700707  2.23831659]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.73700707,  2.23831659]), 'currentState': array([4.04617823, 1.73831659]), 'targetState': array([-0.22886338, -0.74050583]), 'effectorPosition': array([ 0.26019819, -1.26444502])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3891077211438731
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.73700707,  2.23831659]), 'currentState': array([4.25861619, 0.68543732]), 'targetState': array([-0.22886338, -0.74050583]), 'effectorPosition': array([-0.20876173, -1.87208524])}
episode index:811
target Thresh 1.6444940650055975
current state at start:  [ 2.26962021 -2.89487041]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.26962021, -2.89487041]), 'currentState': array([2.76962021, 2.88831489]), 'targetState': array([0.68865519, 0.94070389]), 'effectorPosition': array([-0.12079556, -0.22184647])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.38862852444295704
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.26962021, -2.89487041]), 'currentState': array([5.8645415 , 3.93032047]), 'targetState': array([0.68865519, 0.94070389]), 'effectorPosition': array([-0.01865586, -0.76821551])}
episode index:812
target Thresh 1.6452043663374871
current state at start:  [-0.38809719 -2.48270062]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.38809719, -2.48270062]), 'currentState': array([0.09737612, 3.94245078]), 'targetState': array([-0.31470918, -1.229467  ]), 'effectorPosition': array([ 0.37227053, -0.68500578])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.38815050657771355
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.38809719, -2.48270062]), 'currentState': array([1.85917508, 6.01993143]), 'targetState': array([-0.31470918, -1.229467  ]), 'effectorPosition': array([-0.30952053,  1.9583906 ])}
episode index:813
target Thresh 1.6459132484863692
current state at start:  [1.62250041 2.29667291]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.62250041, 2.29667291]), 'currentState': array([1.12250041, 1.81319794]), 'targetState': array([-0.03021234,  0.12531031]), 'effectorPosition': array([-0.54544808,  1.10562966])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3876736632035394
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.62250041, 2.29667291]), 'currentState': array([1.60043495, 6.2266563 ]), 'targetState': array([-0.03021234,  0.12531031]), 'effectorPosition': array([-0.00274715,  1.99919928])}
episode index:814
target Thresh 1.6466207142877731
current state at start:  [ 3.51165061 -2.99449973]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.51165061, -2.99449973]), 'currentState': array([4.01165061, 2.78868558]), 'targetState': array([-0.37598752,  0.42296864]), 'effectorPosition': array([ 0.22444908, -0.2699607 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3871979899971547
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.51165061, -2.99449973]), 'currentState': array([4.66631497, 0.00468877]), 'targetState': array([-0.37598752,  0.42296864]), 'effectorPosition': array([-0.08743114, -1.99808253])}
episode index:815
target Thresh 1.6473267665715632
current state at start:  [1.58395105 2.30035152]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.58395105, 2.30035152]), 'currentState': array([1.08395105, 1.80035152]), 'targetState': array([-0.28053457, -0.37549328]), 'effectorPosition': array([-0.49924306,  1.13827393])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.38672348265647194
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.58395105, 2.30035152]), 'currentState': array([2.02026068, 0.31731319]), 'targetState': array([-0.28053457, -0.37549328]), 'effectorPosition': array([-1.12830134,  1.62083017])}
episode index:816
target Thresh 1.6480314081619492
current state at start:  [1.40129901 2.71293489]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.40129901, 2.71293489]), 'currentState': array([1.04487372, 2.22257331]), 'targetState': array([ 0.08504857, -0.021885  ]), 'effectorPosition': array([-0.49007964,  0.73933875])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.38625013690046645
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.40129901, 2.71293489]), 'currentState': array([2.23248611, 0.48828725]), 'targetState': array([ 0.08504857, -0.021885  ]), 'effectorPosition': array([-1.52720545,  1.19746347])}
episode index:817
target Thresh 1.6487346418774984
current state at start:  [-4.19741686  2.94767858]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.19741686,  2.94767858]), 'currentState': array([2.06749407, 2.56381823]), 'targetState': array([-0.052469 ,  0.0290883]), 'effectorPosition': array([-0.55751281, -0.11755412])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3857779484690478
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-4.19741686,  2.94767858]), 'currentState': array([5.14431622, 0.33036656]), 'targetState': array([-0.052469 ,  0.0290883]), 'effectorPosition': array([ 1.10920409, -1.63141451])}
episode index:818
target Thresh 1.649436470531147
current state at start:  [-1.79402323  2.10694436]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.79402323,  2.10694436]), 'currentState': array([4.01806905, 1.67764005]), 'targetState': array([ 0.15586651, -0.28855713]), 'effectorPosition': array([ 0.19247921, -1.32275116])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.38530691312293175
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.79402323,  2.10694436]), 'currentState': array([4.25399187, 0.18556099]), 'targetState': array([ 0.15586651, -0.28855713]), 'effectorPosition': array([-0.71197499, -1.85977349])}
episode index:819
target Thresh 1.6501368969302102
current state at start:  [-0.89235919 -2.76962801]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.89235919, -2.76962801]), 'currentState': array([5.84691452, 3.56075413]), 'targetState': array([-0.60794759, -0.42254394]), 'effectorPosition': array([-0.09351985, -0.40545402])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.38483702664351355
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.89235919, -2.76962801]), 'currentState': array([1.59113646, 0.48004529]), 'targetState': array([-0.60794759, -0.42254394]), 'effectorPosition': array([-0.50010247,  1.87719086])}
episode index:820
target Thresh 1.6508359238763946
current state at start:  [ 3.22192387 -2.04719527]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.22192387, -2.04719527]), 'currentState': array([3.28507428, 4.73599003]), 'targetState': array([-0.06012229,  0.2320992 ]), 'effectorPosition': array([-1.15603053,  0.84308431])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3843682848327419
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.22192387, -2.04719527]), 'currentState': array([4.49706364, 0.69667977]), 'targetState': array([-0.06012229,  0.2320992 ]), 'effectorPosition': array([ 0.24931485, -1.86327559])}
episode index:821
target Thresh 1.651533554165809
current state at start:  [-2.48530618  2.05207798]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.48530618,  2.05207798]), 'currentState': array([4.19091111, 1.63315526]), 'targetState': array([-0.20627838, -0.71577549]), 'effectorPosition': array([ 0.39828117, -1.31024237])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.38390068351299406
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.48530618,  2.05207798]), 'currentState': array([4.20636068, 1.413169  ]), 'targetState': array([-0.20627838, -0.71577549]), 'effectorPosition': array([ 0.30303851, -1.49067718])}
episode index:822
target Thresh 1.6522297905889753
current state at start:  [-1.93161476  2.23722233]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.93161476,  2.23722233]), 'currentState': array([3.85157055, 2.47754352]), 'targetState': array([ 0.69049142, -1.20213243]), 'effectorPosition': array([ 0.24056918, -0.60590439])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.38343421852695153
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.93161476,  2.23722233]), 'currentState': array([2.99129218, 5.98717824]), 'targetState': array([ 0.69049142, -1.20213243]), 'effectorPosition': array([-1.89077318,  0.58137294])}
episode index:823
target Thresh 1.6529246359308405
current state at start:  [ 2.71574228 -2.43767086]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.71574228, -2.43767086]), 'currentState': array([3.12810298, 4.29899287]), 'targetState': array([0.11503916, 0.06623429]), 'effectorPosition': array([-0.58587095,  0.92374883])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.38296888573747706
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.71574228, -2.43767086]), 'currentState': array([5.14898256, 5.79934729]), 'targetState': array([0.11503916, 0.06623429]), 'effectorPosition': array([ 0.37562817, -1.90508153])}
episode index:824
target Thresh 1.6536180929707864
current state at start:  [ 1.00089282 -2.88226372]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.00089282, -2.88226372]), 'currentState': array([0.5974052 , 3.85864768]), 'targetState': array([0.08766243, 0.31843374]), 'effectorPosition': array([ 0.57325989, -0.40482641])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.38250468102749224
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.00089282, -2.88226372]), 'currentState': array([4.97673095, 5.77059984]), 'targetState': array([0.08766243, 0.31843374]), 'effectorPosition': array([ 0.01557247, -1.93461013])}
episode index:825
target Thresh 1.6543101644826426
current state at start:  [ 3.79434877 -2.26602811]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.79434877, -2.26602811]), 'currentState': array([4.27541696, 4.50666079]), 'targetState': array([-0.02901362,  0.8847823 ]), 'effectorPosition': array([-1.22367823, -0.30667816])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.38204160029985607
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.79434877, -2.26602811]), 'currentState': array([5.44995355, 6.1720449 ]), 'targetState': array([-0.02901362,  0.8847823 ]), 'effectorPosition': array([ 1.25873905, -1.55023757])}
episode index:826
target Thresh 1.6550008532346956
current state at start:  [ 2.86375251 -3.03460796]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.86375251, -3.03460796]), 'currentState': array([2.36375251, 3.73561012]), 'targetState': array([-0.33903629, -0.55188402]), 'effectorPosition': array([0.27072127, 0.51895313])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3815796394772444
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.86375251, -3.03460796]), 'currentState': array([2.3385933 , 0.64375066]), 'targetState': array([-0.33903629, -0.55188402]), 'effectorPosition': array([-1.68189867,  0.87801899])}
episode index:827
target Thresh 1.6556901619897018
current state at start:  [ 2.31744832 -2.51327981]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.31744832, -2.51327981]), 'currentState': array([2.81744832, 4.2699055 ]), 'targetState': array([0.75815827, 0.24946617]), 'effectorPosition': array([-0.25421324,  1.03875188])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3811187945020303
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.31744832, -2.51327981]), 'currentState': array([5.48599096, 4.19841907]), 'targetState': array([0.75815827, 0.24946617]), 'effectorPosition': array([-0.26776789, -0.97212353])}
episode index:828
target Thresh 1.6563780935048966
current state at start:  [-0.67067015 -2.50277453]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.67067015, -2.50277453]), 'currentState': array([6.11251516, 4.28041078]), 'targetState': array([-0.26774561, -0.11084462]), 'effectorPosition': array([ 0.4186449 , -0.99368015])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3806590613361654
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.67067015, -2.50277453]), 'currentState': array([1.79973074, 6.12499655]), 'targetState': array([-0.26774561, -0.11084462]), 'effectorPosition': array([-0.29762652,  1.97140734])}
episode index:829
target Thresh 1.6570646505320075
current state at start:  [-1.68492724 -1.69879022]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.68492724, -1.69879022]), 'currentState': array([5.07087894, 5.05165318]), 'targetState': array([-0.92157469, -0.09475728]), 'effectorPosition': array([-0.41542647, -1.57892606])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.38020043596106157
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.68492724, -1.69879022]), 'currentState': array([1.45590773, 5.33100859]), 'targetState': array([-0.92157469, -0.09475728]), 'effectorPosition': array([0.99042373, 1.47610403])}
episode index:830
target Thresh 1.6577498358172629
current state at start:  [ 1.57262144 -2.57836145]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.57262144, -2.57836145]), 'currentState': array([2.0182623 , 4.20446095]), 'targetState': array([ 0.2461706 , -0.39507395]), 'effectorPosition': array([0.56549034, 0.8411212 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.37974291437747426
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.57262144, -2.57836145]), 'currentState': array([2.45406294, 0.56421635]), 'targetState': array([ 0.2461706 , -0.39507395]), 'effectorPosition': array([-1.76522262,  0.75763113])}
episode index:831
target Thresh 1.6584336521014056
current state at start:  [-1.62150287  2.13779959]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.62150287,  2.13779959]), 'currentState': array([4.16168244, 2.5114975 ]), 'targetState': array([ 1.19041977, -0.54602757]), 'effectorPosition': array([ 0.40162166, -0.47197156])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.37928649260538594
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.62150287,  2.13779959]), 'currentState': array([3.1173309 , 0.57692274]), 'targetState': array([ 1.19041977, -0.54602757]), 'effectorPosition': array([-1.85083634, -0.50069456])}
episode index:832
target Thresh 1.6591161021197012
current state at start:  [1.64360656 2.01590574]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.64360656, 2.01590574]), 'currentState': array([1.14748801, 2.42501182]), 'targetState': array([-1.09248942,  0.84350836]), 'effectorPosition': array([-0.4978082 ,  0.49403972])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3788311666838909
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.64360656, 2.01590574]), 'currentState': array([4.34534026, 2.57948763]), 'targetState': array([-1.09248942,  0.84350836]), 'effectorPosition': array([ 0.44225143, -0.33487837])}
episode index:833
target Thresh 1.6597971886019507
current state at start:  [0.90341073 2.19745621]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.90341073, 2.19745621]), 'currentState': array([0.40341073, 1.69745621]), 'targetState': array([0.14450581, 0.85327834]), 'effectorPosition': array([0.41413318, 1.25532893])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.37957597343846655
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.90341073, 2.19745621]), 'currentState': array([0.40341073, 1.69745621]), 'targetState': array([0.14450581, 0.85327834]), 'effectorPosition': array([0.41413318, 1.25532893])}
episode index:834
target Thresh 1.660476914272501
current state at start:  [-1.73452248  2.60582582]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.73452248,  2.60582582]), 'currentState': array([4.04866282, 2.10582582]), 'targetState': array([ 0.26879825, -0.79225296]), 'effectorPosition': array([ 0.37567378, -0.91604388])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.3803189962247678
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.73452248,  2.60582582]), 'currentState': array([4.04866282, 2.10582582]), 'targetState': array([ 0.26879825, -0.79225296]), 'effectorPosition': array([ 0.37567378, -0.91604388])}
episode index:835
target Thresh 1.6611552818502557
current state at start:  [ 1.24510775 -1.85953069]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.24510775, -1.85953069]), 'currentState': array([1.67925952, 4.8823598 ]), 'targetState': array([ 0.52407694, -0.23450968]), 'effectorPosition': array([0.85323637, 1.26897395])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3798640691957908
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.24510775, -1.85953069]), 'currentState': array([4.88911096, 5.09456333]), 'targetState': array([ 0.52407694, -0.23450968]), 'effectorPosition': array([-0.67203728, -1.51467606])}
episode index:836
target Thresh 1.661832294048686
current state at start:  [-4.47147865  2.73930023]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.47147865,  2.73930023]), 'currentState': array([1.39997831, 2.27937002]), 'targetState': array([-0.34232257, -0.24715376]), 'effectorPosition': array([-0.68887189,  0.47323632])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.37941022920869905
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-4.47147865,  2.73930023]), 'currentState': array([1.64962857, 6.21558444]), 'targetState': array([-0.34232257, -0.24715376]), 'effectorPosition': array([-0.08998176,  1.99683128])}
episode index:837
target Thresh 1.6625079535758418
current state at start:  [-0.16529512 -1.86004764]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.16529512, -1.86004764]), 'currentState': array([0.27142353, 4.92313767]), 'targetState': array([ 0.16635886, -0.71862945]), 'effectorPosition': array([ 1.42709505, -0.61788663])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3789574723719345
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.16529512, -1.86004764]), 'currentState': array([2.82569287, 6.22195758]), 'targetState': array([ 0.16635886, -0.71862945]), 'effectorPosition': array([-1.88024349,  0.67892322])}
episode index:838
target Thresh 1.6631822631343618
current state at start:  [-2.18043912  2.87042245]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.18043912,  2.87042245]), 'currentState': array([3.63179364, 2.43518722]), 'targetState': array([-0.2276101 , -0.09541297]), 'effectorPosition': array([ 0.09448047, -0.68532721])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.37850579481249236
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.18043912,  2.87042245]), 'currentState': array([4.1740685, 1.0545184]), 'targetState': array([-0.2276101 , -0.09541297]), 'effectorPosition': array([-0.01911769, -1.72827305])}
episode index:839
target Thresh 1.6638552254214851
current state at start:  [ 1.62266404 -1.93018395]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.62266404, -1.93018395]), 'currentState': array([2.08516279, 4.85300136]), 'targetState': array([0.11880381, 0.04731124]), 'effectorPosition': array([0.30107743, 1.47974705])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.37805519267581084
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.62266404, -1.93018395]), 'currentState': array([4.97088767, 6.15371881]), 'targetState': array([0.11880381, 0.04731124]), 'effectorPosition': array([ 0.38430385, -1.95846174])}
episode index:840
target Thresh 1.664526843129062
current state at start:  [0.07417398 1.93388685]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.07417398, 1.93388685]), 'currentState': array([0.54049568, 1.47251749]), 'targetState': array([-0.02537524,  0.16671034]), 'effectorPosition': array([0.42950961, 1.41836628])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3776056621256612
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.07417398, 1.93388685]), 'currentState': array([5.35827282, 5.91351394]), 'targetState': array([-0.02537524,  0.16671034]), 'effectorPosition': array([ 0.87461813, -1.76066334])}
episode index:841
target Thresh 1.6651971189435641
current state at start:  [ 3.69027627 -1.84231053]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.69027627, -1.84231053]), 'currentState': array([4.17670987, 4.89339077]), 'targetState': array([-0.7216058 ,  0.38541079]), 'effectorPosition': array([-1.44818374, -0.5126344 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3771571993440393
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.69027627, -1.84231053]), 'currentState': array([4.45765327, 2.00464761]), 'targetState': array([-0.7216058 ,  0.38541079]), 'effectorPosition': array([ 0.73201199, -0.78957056])}
episode index:842
target Thresh 1.6658660555460956
current state at start:  [ 3.79271646 -2.24884867]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.79271646, -2.24884867]), 'currentState': array([4.2448427 , 3.53433664]), 'targetState': array([-1.09874787,  0.73912498]), 'effectorPosition': array([-0.37596471,  0.10452675])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.37670980053105707
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.79271646, -2.24884867]), 'currentState': array([4.16732067, 3.09758864]), 'targetState': array([-1.09874787,  0.73912498]), 'effectorPosition': array([ 0.03711343, -0.02363543])}
episode index:843
target Thresh 1.6665336556124037
current state at start:  [ 0.10794901 -2.74660562]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.10794901, -2.74660562]), 'currentState': array([0.60520899, 3.85548   ]), 'targetState': array([0.56301732, 0.03816799]), 'effectorPosition': array([ 0.57333247, -0.39955648])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.3774482960280582
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.10794901, -2.74660562]), 'currentState': array([0.60520899, 3.85548   ]), 'targetState': array([0.56301732, 0.03816799]), 'effectorPosition': array([ 0.57333247, -0.39955648])}
episode index:844
target Thresh 1.6671999218128897
current state at start:  [-0.28480326  2.58789322]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.28480326,  2.58789322]), 'currentState': array([0.20781015, 2.13795165]), 'targetState': array([0.21106119, 0.0134311 ]), 'effectorPosition': array([0.27879366, 0.92076286])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3770016116540605
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.28480326,  2.58789322]), 'currentState': array([4.55024577, 5.40223027]), 'targetState': array([0.21106119, 0.0134311 ]), 'effectorPosition': array([-1.02540216, -1.49042945])}
episode index:845
target Thresh 1.6678648568126193
current state at start:  [-0.20911389 -2.35352759]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.20911389, -2.35352759]), 'currentState': array([0.21042157, 3.43928345]), 'targetState': array([ 0.82819977, -0.98877732]), 'effectorPosition': array([ 0.10427849, -0.27765676])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.37655598327149065
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.20911389, -2.35352759]), 'currentState': array([3.13823506, 0.38031181]), 'targetState': array([ 0.82819977, -0.98877732]), 'effectorPosition': array([-1.92978443, -0.36473265])}
episode index:846
target Thresh 1.668528463271333
current state at start:  [-0.93771636  2.00869104]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.93771636,  2.00869104]), 'currentState': array([4.84546895, 1.51814205]), 'targetState': array([0.77903715, 0.29137762]), 'effectorPosition': array([ 1.1294551 , -0.91081891])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.37611140714011937
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.93771636,  2.00869104]), 'currentState': array([6.0130869 , 4.58116006]), 'targetState': array([0.77903715, 0.29137762]), 'effectorPosition': array([ 0.5731041 , -1.18736957])}
episode index:847
target Thresh 1.6691907438434583
current state at start:  [-0.7841636   2.90645273]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.7841636 ,  2.90645273]), 'currentState': array([5.99902171, 2.44405503]), 'targetState': array([-0.46580388, -0.65011203]), 'effectorPosition': array([0.40428759, 0.5510891 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3756678795373598
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.7841636 ,  2.90645273]), 'currentState': array([1.84038217, 5.9709315 ]), 'targetState': array([-0.46580388, -0.65011203]), 'effectorPosition': array([-0.22367724,  1.96297114])}
episode index:848
target Thresh 1.6698517011781175
current state at start:  [-0.30815006 -2.56378725]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.30815006, -2.56378725]), 'currentState': array([0.16502156, 4.21939806]), 'targetState': array([-0.64289461, -0.45208543]), 'effectorPosition': array([ 0.66429352, -0.78242481])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.37522539675816385
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.30815006, -2.56378725]), 'currentState': array([2.39807435, 0.62379733]), 'targetState': array([-0.64289461, -0.45208543]), 'effectorPosition': array([-1.72893364,  0.79631708])}
episode index:849
target Thresh 1.6705113379191414
current state at start:  [-2.58840009  2.80918188]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.58840009,  2.80918188]), 'currentState': array([4.19478521, 2.36222471]), 'targetState': array([-0.00461964,  0.0790148 ]), 'effectorPosition': array([ 0.46794449, -0.5985918 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3747839551149189
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.58840009,  2.80918188]), 'currentState': array([4.93055891, 0.13017047]), 'targetState': array([-0.00461964,  0.0790148 ]), 'effectorPosition': array([ 0.55778165, -1.91623568])}
episode index:850
target Thresh 1.6711696567050776
current state at start:  [-2.7041922   2.31191744]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.7041922 ,  2.31191744]), 'currentState': array([4.07899311, 1.81191744]), 'targetState': array([ 0.17597915, -0.05176231]), 'effectorPosition': array([ 0.33215652, -1.18831357])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.37434355093734556
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.7041922 ,  2.31191744]), 'currentState': array([4.59682015, 5.66837636]), 'targetState': array([ 0.17597915, -0.05176231]), 'effectorPosition': array([-0.78246285, -1.73825177])}
episode index:851
target Thresh 1.6718266601692022
current state at start:  [ 1.42020901 -2.35110551]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.42020901, -2.35110551]), 'currentState': array([1.82052322, 4.36745826]), 'targetState': array([-0.00584338, -0.21599834]), 'effectorPosition': array([0.7483322 , 0.87391988])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.37390418057239566
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.42020901, -2.35110551]), 'currentState': array([2.75360026, 0.82471896]), 'targetState': array([-0.00584338, -0.21599834]), 'effectorPosition': array([-1.83181156, -0.04464474])}
episode index:852
target Thresh 1.67248235093953
current state at start:  [1.79971556 2.52736592]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.79971556, 2.52736592]), 'currentState': array([1.31368972, 2.78977656]), 'targetState': array([-0.63516084,  0.39708464]), 'effectorPosition': array([-0.31770079,  0.14686508])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.374638173326707
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.79971556, 2.52736592]), 'currentState': array([1.31368972, 2.78977656]), 'targetState': array([-0.63516084,  0.39708464]), 'effectorPosition': array([-0.31770079,  0.14686508])}
episode index:853
target Thresh 1.6731367316388246
current state at start:  [ 2.57745218 -2.58554162]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.57745218, -2.58554162]), 'currentState': array([2.10861837, 4.19764369]), 'targetState': array([-0.52904568,  0.15573347]), 'effectorPosition': array([0.48746702, 0.88190112])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3741994869410786
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.57745218, -2.58554162]), 'currentState': array([2.17761233, 0.15728807]), 'targetState': array([-0.52904568,  0.15573347]), 'effectorPosition': array([-1.26214522,  1.5434704 ])}
episode index:854
target Thresh 1.67378980488461
current state at start:  [-2.54062656  2.30174977]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.54062656,  2.30174977]), 'currentState': array([3.26111391, 2.53255715]), 'targetState': array([ 0.7749657 , -0.87692164]), 'effectorPosition': array([-0.11030447, -0.58943413])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.373761826722434
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.54062656,  2.30174977]), 'currentState': array([2.51598128, 0.13300213]), 'targetState': array([ 0.7749657 , -0.87692164]), 'effectorPosition': array([-1.69170713,  1.05851947])}
episode index:855
target Thresh 1.6744415732891802
current state at start:  [-3.99071555  2.88318666]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.99071555,  2.88318666]), 'currentState': array([1.79246976, 2.54742583]), 'targetState': array([-0.09077799, -0.45258443]), 'effectorPosition': array([-0.58380138,  0.04410809])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.3744934133734592
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.99071555,  2.88318666]), 'currentState': array([1.79246976, 2.54742583]), 'targetState': array([-0.09077799, -0.45258443]), 'effectorPosition': array([-0.58380138,  0.04410809])}
episode index:856
target Thresh 1.6750920394596094
current state at start:  [1.50865898 1.76078552]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.50865898, 1.76078552]), 'currentState': array([1.00865898, 1.29510498]), 'targetState': array([-0.32395193,  0.13495823]), 'effectorPosition': array([-0.13608224,  1.58930995])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3740564315608881
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.50865898, 1.76078552]), 'currentState': array([2.22170709, 0.51349401]), 'targetState': array([-0.32395193,  0.13495823]), 'effectorPosition': array([-1.52446441,  1.19082964])}
episode index:857
target Thresh 1.6757412059977632
current state at start:  [-3.24729116  2.15682326]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.24729116,  2.15682326]), 'currentState': array([3.48407664, 2.30001217]), 'targetState': array([-1.05817092, -0.04081258]), 'effectorPosition': array([-0.06390802, -0.8144603 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3736204683539407
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.24729116,  2.15682326]), 'currentState': array([4.20270389, 2.37291497]), 'targetState': array([-1.05817092, -0.04081258]), 'effectorPosition': array([ 0.46964277, -0.58461488])}
episode index:858
target Thresh 1.6763890755003086
current state at start:  [1.18583808 2.20529714]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.18583808, 2.20529714]), 'currentState': array([1.68583808, 1.70615554]), 'targetState': array([-0.09135322, -0.03317728]), 'effectorPosition': array([-1.08360131,  0.74559755])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.373185520195205
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.18583808, 2.20529714]), 'currentState': array([4.32161242, 0.19878017]), 'targetState': array([-0.09135322, -0.03317728]), 'effectorPosition': array([-0.57172554, -1.90623878])}
episode index:859
target Thresh 1.6770356505587245
current state at start:  [-1.50755599  2.23927076]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.50755599,  2.23927076]), 'currentState': array([4.27562932, 1.73927076]), 'targetState': array([1.01333946, 0.29410772]), 'effectorPosition': array([ 0.54122133, -1.17120549])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3727515835438152
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.50755599,  2.23927076]), 'currentState': array([5.43802574, 4.19064918]), 'targetState': array([1.01333946, 0.29410772]), 'effectorPosition': array([-0.31567301, -0.9505641 ])}
episode index:860
target Thresh 1.6776809337593122
current state at start:  [-2.66840488  1.92365413]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.66840488,  1.92365413]), 'currentState': array([3.22671354, 1.47158658]), 'targetState': array([ 0.59276428, -0.92307354]), 'effectorPosition': array([-1.0104678 , -1.08491889])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.37231865487535554
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.66840488,  1.92365413]), 'currentState': array([2.59309597, 1.82526298]), 'targetState': array([ 0.59276428, -0.92307354]), 'effectorPosition': array([-1.14312097, -0.43567868])}
episode index:861
target Thresh 1.678324927683205
current state at start:  [-3.21345554  1.75264748]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.21345554,  1.75264748]), 'currentState': array([3.56972977, 2.18730035]), 'targetState': array([-1.3172895 , -0.13425974]), 'effectorPosition': array([-0.04499638, -0.91738907])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3718867306817646
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.21345554,  1.75264748]), 'currentState': array([4.57641939, 2.23140222]), 'targetState': array([-1.3172895 , -0.13425974]), 'effectorPosition': array([ 0.72995516, -0.48987211])}
episode index:862
target Thresh 1.6789676349063798
current state at start:  [ 1.01972939 -1.70871412]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.01972939, -1.70871412]), 'currentState': array([1.51352547, 5.07447119]), 'targetState': array([1.07473267, 0.39278126]), 'effectorPosition': array([1.01114314, 1.2984737 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.37145580747124113
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.01972939, -1.70871412]), 'currentState': array([5.99885939, 4.22468475]), 'targetState': array([1.07473267, 0.39278126]), 'effectorPosition': array([ 0.26225969, -0.99700643])}
episode index:863
target Thresh 1.679609057999666
current state at start:  [-4.11769094  2.06981257]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.11769094,  2.06981257]), 'currentState': array([2.10798914, 1.56981257]), 'targetState': array([-0.19460797, -0.01427241]), 'effectorPosition': array([-1.3713778 ,  0.34826779])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.37102588176814943
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-4.11769094,  2.06981257]), 'currentState': array([4.47868783, 1.56604353]), 'targetState': array([-0.19460797, -0.01427241]), 'effectorPosition': array([ 0.74012467, -1.20901655])}
episode index:864
target Thresh 1.680249199528757
current state at start:  [ 1.10700705 -2.4282646 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.10700705, -2.4282646 ]), 'currentState': array([0.75664678, 4.32229858]), 'targetState': array([0.21794962, 0.70699147]), 'effectorPosition': array([ 1.08554475, -0.24708004])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3705969501129261
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.10700705, -2.4282646 ]), 'currentState': array([5.91449792, 4.53602314]), 'targetState': array([0.21794962, 0.70699147]), 'effectorPosition': array([ 0.4143376 , -1.21549103])}
episode index:865
target Thresh 1.68088806205422
current state at start:  [ 2.408367  -2.2914253]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.408367 , -2.2914253]), 'currentState': array([1.908367  , 4.44245779]), 'targetState': array([-0.43798976,  0.20551128]), 'effectorPosition': array([0.66651747, 1.01114995])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3701690090619874
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.408367 , -2.2914253]), 'currentState': array([2.24040622, 6.07855588]), 'targetState': array([-0.43798976,  0.20551128]), 'effectorPosition': array([-1.0690855 ,  1.67789418])}
episode index:866
target Thresh 1.6815256481315055
current state at start:  [-0.06049081  2.17584156]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.06049081,  2.17584156]), 'currentState': array([0.43950919, 1.67584156]), 'targetState': array([ 0.01567715, -0.01728756]), 'effectorPosition': array([0.3869236 , 1.28085355])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3697420551876368
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.06049081,  2.17584156]), 'currentState': array([4.78703518, 0.24526879]), 'targetState': array([ 0.01567715, -0.01728756]), 'effectorPosition': array([ 0.38906276, -1.94647742])}
episode index:867
target Thresh 1.682161960310959
current state at start:  [-0.04218585 -2.31924563]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.04218585, -2.31924563]), 'currentState': array([0.41107201, 4.27524961]), 'targetState': array([-0.16488552, -0.43887432]), 'effectorPosition': array([ 0.89062857, -0.600068  ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3693160850779736
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.04218585, -2.31924563]), 'currentState': array([2.37371576, 5.73975896]), 'targetState': array([-0.16488552, -0.43887432]), 'effectorPosition': array([-0.97597767,  1.66112964])}
episode index:868
target Thresh 1.68279700113783
current state at start:  [-0.9273091  -2.53005332]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.9273091 , -2.53005332]), 'currentState': array([5.85587621, 3.25313198]), 'targetState': array([-0.22231996, -1.06031903]), 'effectorPosition': array([-0.04047339, -0.10387509])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3688910953368022
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.9273091 , -2.53005332]), 'currentState': array([2.91000004, 6.17911475]), 'targetState': array([-0.22231996, -1.06031903]), 'effectorPosition': array([-1.91749415,  0.55892331])}
episode index:869
target Thresh 1.6834307731522826
current state at start:  [-3.44731305  1.98242523]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.44731305,  1.98242523]), 'currentState': array([2.40436876, 1.59369032]), 'targetState': array([-0.6619558 , -1.03302635]), 'effectorPosition': array([-1.39544889, -0.08329715])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3684670825835415
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.44731305,  1.98242523]), 'currentState': array([2.52414494, 0.00287885]), 'targetState': array([-0.6619558 , -1.03302635]), 'effectorPosition': array([-1.63238089,  1.15556234])}
episode index:870
target Thresh 1.6840632788894057
current state at start:  [-0.75971746  2.63333422]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.75971746,  2.63333422]), 'currentState': array([5.99309946, 2.13333422]), 'targetState': array([ 0.04040048, -0.24496324]), 'effectorPosition': array([0.68912548, 0.67707947])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.36804404345313557
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.75971746,  2.63333422]), 'currentState': array([4.66804997, 0.00621037]), 'targetState': array([ 0.04040048, -0.24496324]), 'effectorPosition': array([-0.08244388, -1.99829038])}
episode index:871
target Thresh 1.684694520879223
current state at start:  [-3.79269879  2.42493509]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.79269879,  2.42493509]), 'currentState': array([2.10016616, 2.87022456]), 'targetState': array([-1.34055128, -0.42442034]), 'effectorPosition': array([-0.24984059, -0.10377629])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3676219745959646
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.79269879,  2.42493509]), 'currentState': array([1.06090137, 5.14412934]), 'targetState': array([-1.34055128, -0.42442034]), 'effectorPosition': array([1.48503306, 0.79472072])}
episode index:872
target Thresh 1.6853245016467036
current state at start:  [ 0.30689827 -2.74008767]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.30689827, -2.74008767]), 'currentState': array([0.80689827, 4.04309763]), 'targetState': array([-0.12299997, -0.23859675]), 'effectorPosition': array([ 0.82891471, -0.26840204])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.36720087267775614
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.30689827, -2.74008767]), 'currentState': array([2.50528828, 5.96782414]), 'targetState': array([-0.12299997, -0.23859675]), 'effectorPosition': array([-1.38462479,  1.40861031])}
episode index:873
target Thresh 1.685953223711771
current state at start:  [ 2.87607982 -2.57548469]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.87607982, -2.57548469]), 'currentState': array([2.39311584, 4.13321541]), 'targetState': array([ 0.00673057, -0.00815599]), 'effectorPosition': array([0.23785909, 0.92128068])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3667807343794978
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.87607982, -2.57548469]), 'currentState': array([4.16691077, 0.99576542]), 'targetState': array([ 0.00673057, -0.00815599]), 'effectorPosition': array([-0.08360282, -1.75520142])}
episode index:874
target Thresh 1.6865806895893147
current state at start:  [-0.33452546 -2.30550488]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.33452546, -2.30550488]), 'currentState': array([0.16340608, 4.44038628]), 'targetState': array([-0.71813821, -0.45875893]), 'effectorPosition': array([ 0.8782956 , -0.83142933])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3663615563973498
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.33452546, -2.30550488]), 'currentState': array([2.48218866, 6.19175376]), 'targetState': array([-0.71813821, -0.45875893]), 'effectorPosition': array([-1.52147658,  1.29489579])}
episode index:875
target Thresh 1.6872069017891986
current state at start:  [-1.48095424  2.84017637]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.48095424,  2.84017637]), 'currentState': array([4.30223107, 2.34017637]), 'targetState': array([ 0.28256059, -0.16955295]), 'effectorPosition': array([ 0.53741642, -0.56551175])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.36708488795397387
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.48095424,  2.84017637]), 'currentState': array([4.30223107, 2.34017637]), 'targetState': array([ 0.28256059, -0.16955295]), 'effectorPosition': array([ 0.53741642, -0.56551175])}
episode index:876
target Thresh 1.687831862816273
current state at start:  [ 2.04989292 -1.94418521]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.04989292, -1.94418521]), 'currentState': array([2.50697659, 4.83089062]), 'targetState': array([0.3842452 , 1.31320468]), 'effectorPosition': array([-0.31179497,  1.46261166])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.36666631909655767
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.04989292, -1.94418521]), 'currentState': array([6.26140405, 4.50590383]), 'targetState': array([0.3842452 , 1.31320468]), 'effectorPosition': array([ 0.77347355, -0.99583969])}
episode index:877
target Thresh 1.6884555751703823
current state at start:  [-1.88912207  2.21190321]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.88912207,  2.21190321]), 'currentState': array([3.9484224, 1.760919 ]), 'targetState': array([ 0.55173774, -0.70299371]), 'effectorPosition': array([ 0.14802933, -1.2649619 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3662487036989534
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.88912207,  2.21190321]), 'currentState': array([2.8172734 , 0.45535626]), 'targetState': array([ 0.55173774, -0.70299371]), 'effectorPosition': array([-1.9392948 ,  0.18800128])}
episode index:878
target Thresh 1.6890780413463768
current state at start:  [-1.3913946   2.98057971]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.3913946 ,  2.98057971]), 'currentState': array([4.39179071, 2.48057971]), 'targetState': array([-0.03351499, -0.03875654]), 'effectorPosition': array([ 0.51625937, -0.39336334])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.36583203850703194
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.3913946 ,  2.98057971]), 'currentState': array([4.59567224, 5.87340558]), 'targetState': array([-0.03351499, -0.03875654]), 'effectorPosition': array([-0.61895929, -1.85776925])}
episode index:879
target Thresh 1.6896992638341222
current state at start:  [ 0.64712329 -2.3214253 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.64712329, -2.3214253 ]), 'currentState': array([1.14712329, 4.39805999]), 'targetState': array([-0.00839275, -0.11070954]), 'effectorPosition': array([1.15092579, 0.23877394])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.36541632028145576
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.64712329, -2.3214253 ]), 'currentState': array([2.6072828 , 5.88529112]), 'targetState': array([-0.00839275, -0.11070954]), 'effectorPosition': array([-1.45668602,  1.31218285])}
episode index:880
target Thresh 1.690319245118509
current state at start:  [ 1.46234731 -1.80534393]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.46234731, -1.80534393]), 'currentState': array([1.9337606 , 4.97784137]), 'targetState': array([0.8578164 , 0.91626716]), 'effectorPosition': array([0.45391238, 1.52271312])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.36500154579759486
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.46234731, -1.80534393]), 'currentState': array([0.04623575, 4.2409175 ]), 'targetState': array([0.8578164 , 0.91626716]), 'effectorPosition': array([ 0.58639579, -0.86472223])}
episode index:881
target Thresh 1.6909379876794635
current state at start:  [-1.06416151 -2.44114272]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.06416151, -2.44114272]), 'currentState': array([5.71092192, 3.34690352]), 'targetState': array([ 0.33667637, -1.06482538]), 'effectorPosition': array([-0.09274761, -0.18276371])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3645877118454434
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.06416151, -2.44114272]), 'currentState': array([2.88341455, 5.48039   ]), 'targetState': array([ 0.33667637, -1.06482538]), 'effectorPosition': array([-1.45487944,  1.1281504 ])}
episode index:882
target Thresh 1.6915554939919568
current state at start:  [-0.69023019 -2.70284262]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.69023019, -2.70284262]), 'currentState': array([5.901115  , 4.03713104]), 'targetState': array([-0.72141304, -0.04082009]), 'effectorPosition': array([ 0.05684851, -0.86404335])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.36417481522953693
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.69023019, -2.70284262]), 'currentState': array([1.21090482, 4.81140852]), 'targetState': array([-0.72141304, -0.04082009]), 'effectorPosition': array([1.31833814, 0.67801193])}
episode index:883
target Thresh 1.6921717665260145
current state at start:  [-2.28889625  2.56729795]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.28889625,  2.56729795]), 'currentState': array([3.57809498, 3.06729795]), 'targetState': array([ 0.60073147, -0.73030128]), 'effectorPosition': array([ 0.02888093, -0.06843286])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.36376285276887
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.28889625,  2.56729795]), 'currentState': array([4.81821192, 5.24433064]), 'targetState': array([ 0.60073147, -0.73030128]), 'effectorPosition': array([-0.69780318, -1.58980692])}
episode index:884
target Thresh 1.692786807746728
current state at start:  [-0.34463669 -2.26490361]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.34463669, -2.26490361]), 'currentState': array([5.79861088, 4.5182817 ]), 'targetState': array([ 0.18780144, -0.12888262]), 'effectorPosition': array([ 0.25710587, -1.2442328 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3633518212968148
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.34463669, -2.26490361]), 'currentState': array([4.50909234, 5.54239004]), 'targetState': array([ 0.18780144, -0.12888262]), 'effectorPosition': array([-1.01186386, -1.56588496])}
episode index:885
target Thresh 1.693400620114263
current state at start:  [-3.06361816  2.56482366]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.06361816,  2.56482366]), 'currentState': array([3.67227411, 2.06482366]), 'targetState': array([-0.30047358,  0.08754959]), 'effectorPosition': array([-0.00789938, -1.02546896])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3629417176610396
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.06361816,  2.56482366]), 'currentState': array([3.97289345, 1.58011795]), 'targetState': array([-0.30047358,  0.08754959]), 'effectorPosition': array([ 0.07114312, -1.40580784])}
episode index:886
target Thresh 1.6940132060838695
current state at start:  [ 3.37465143 -2.96686059]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.37465143, -2.96686059]), 'currentState': array([3.14803316, 3.74910865]), 'targetState': array([ 0.09126305, -0.22896434]), 'effectorPosition': array([-0.1826042 ,  0.56966545])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3625325387234285
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.37465143, -2.96686059]), 'currentState': array([4.61357874, 5.54824258]), 'targetState': array([ 0.09126305, -0.22896434]), 'effectorPosition': array([-0.83910848, -1.66722382])}
episode index:887
target Thresh 1.6946245681058925
current state at start:  [0.73236317 2.10796313]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.73236317, 2.10796313]), 'currentState': array([0.23236317, 1.60796313]), 'targetState': array([-0.73059539,  0.13021571]), 'effectorPosition': array([0.70684653, 1.19417398])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.36212428136000124
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.73236317, 2.10796313]), 'currentState': array([4.11314835, 2.34326701]), 'targetState': array([-0.73059539,  0.13021571]), 'effectorPosition': array([ 0.42101759, -0.65339919])}
episode index:888
target Thresh 1.6952347086257806
current state at start:  [-0.01378909 -2.24198368]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.01378909, -2.24198368]), 'currentState': array([0.47656247, 4.54120163]), 'targetState': array([-0.31411219, -1.02661261]), 'effectorPosition': array([ 1.18922802, -0.49500686])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.36171694246083363
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.01378909, -2.24198368]), 'currentState': array([2.75933924, 5.81773693]), 'targetState': array([-0.31411219, -1.02661261]), 'effectorPosition': array([-1.58953444,  1.12277384])}
episode index:889
target Thresh 1.6958436300840969
current state at start:  [ 1.52926513 -2.06953451]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.52926513, -2.06953451]), 'currentState': array([1.05282893, 4.71365079]), 'targetState': array([0.42801546, 1.09950316]), 'effectorPosition': array([1.36456658, 0.37480886])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.36131051892997873
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.52926513, -2.06953451]), 'currentState': array([5.98276708, 4.26350253]), 'targetState': array([0.42801546, 1.09950316]), 'effectorPosition': array([ 0.27408297, -1.02808238])}
episode index:890
target Thresh 1.696451334916528
current state at start:  [1.34870186 2.65888727]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.34870186, 2.65888727]), 'currentState': array([0.88222107, 3.15888727]), 'targetState': array([-1.24820916, -0.35752976]), 'effectorPosition': array([ 0.01344844, -0.01087363])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3609050076853884
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.34870186, 2.65888727]), 'currentState': array([1.07904644, 4.78211566]), 'targetState': array([-1.24820916, -0.35752976]), 'effectorPosition': array([1.38443124, 0.47190099])}
episode index:891
target Thresh 1.6970578255538942
current state at start:  [-2.84528783  1.99219875]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.84528783,  1.99219875]), 'currentState': array([3.03214157, 1.80604852]), 'targetState': array([-0.10040161, -1.18982911]), 'effectorPosition': array([-0.86854665, -0.88286478])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3605004056588353
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.84528783,  1.99219875]), 'currentState': array([2.72561528, 5.31233195]), 'targetState': array([-0.10040161, -1.18982911]), 'effectorPosition': array([-1.0976515 ,  1.38721015])}
episode index:892
target Thresh 1.6976631044221584
current state at start:  [-1.50415462 -1.98487671]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.50415462, -1.98487671]), 'currentState': array([5.18723855, 4.77724718]), 'targetState': array([-1.32676756, -0.29391681]), 'effectorPosition': array([-0.40065423, -1.40324683])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.36009670979583547
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.50415462, -1.98487671]), 'currentState': array([1.18325417, 4.80914353]), 'targetState': array([-1.32676756, -0.29391681]), 'effectorPosition': array([1.33593235, 0.63913385])}
episode index:893
target Thresh 1.6982671739424373
current state at start:  [-3.91569983  2.71299852]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.91569983,  2.71299852]), 'currentState': array([2.86748547, 2.29172377]), 'targetState': array([-0.26725796,  0.13180778]), 'effectorPosition': array([-0.5305671 , -0.63113807])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3596939170555717
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.91569983,  2.71299852]), 'currentState': array([4.30433744, 2.23362357]), 'targetState': array([-0.26725796,  0.13180778]), 'effectorPosition': array([ 0.57089825, -0.66586739])}
episode index:894
target Thresh 1.6988700365310097
current state at start:  [-2.47197912  1.92986692]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.47197912,  1.92986692]), 'currentState': array([4.31120618, 1.47654243]), 'targetState': array([-0.65265932, -0.95296454]), 'effectorPosition': array([ 0.48925368, -1.39601563])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.35929202441081687
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.47197912,  1.92986692]), 'currentState': array([4.44312907, 1.41200117]), 'targetState': array([-0.65265932, -0.95296454]), 'effectorPosition': array([ 0.64375673, -1.37907017])}
episode index:895
target Thresh 1.6994716945993267
current state at start:  [-2.61121753  2.44289184]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.61121753,  2.44289184]), 'currentState': array([3.23698276, 2.88328001]), 'targetState': array([ 0.53732792, -1.01394668]), 'effectorPosition': array([-0.00869636, -0.25744824])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.35889102884785834
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.61121753,  2.44289184]), 'currentState': array([4.02531698, 5.68519032]), 'targetState': array([ 0.53732792, -1.01394668]), 'effectorPosition': array([-1.59373258, -1.05496379])}
episode index:896
target Thresh 1.7000721505540215
current state at start:  [ 1.17331705 -2.38993249]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.17331705, -2.38993249]), 'currentState': array([1.55376962, 4.39325281]), 'targetState': array([-0.10405379, -0.12064818]), 'effectorPosition': array([0.96105324, 0.66998787])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.35849092736642263
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.17331705, -2.38993249]), 'currentState': array([4.28157187, 1.37793019]), 'targetState': array([-0.10405379, -0.12064818]), 'effectorPosition': array([ 0.39411946, -1.49265374])}
episode index:897
target Thresh 1.7006714067969184
current state at start:  [-0.13484236  2.87525031]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.13484236,  2.87525031]), 'currentState': array([0.30416421, 2.40297923]), 'targetState': array([ 0.58965208, -0.1102257 ]), 'effectorPosition': array([0.04699559, 0.7204067 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.35809171697960035
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.13484236,  2.87525031]), 'currentState': array([5.17822918, 4.69790669]), 'targetState': array([ 0.58965208, -0.1102257 ]), 'effectorPosition': array([-0.45068199, -1.32963235])}
episode index:898
target Thresh 1.7012694657250436
current state at start:  [ 2.0418777 -1.9114734]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.0418777, -1.9114734]), 'currentState': array([2.5418777 , 4.85152867]), 'targetState': array([0.90997211, 0.41427161]), 'effectorPosition': array([-0.38103303,  1.46020415])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3576933947137721
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.0418777, -1.9114734]), 'currentState': array([5.99979451, 3.93584281]), 'targetState': array([0.90997211, 0.41427161]), 'effectorPosition': array([ 0.08778818, -0.76853986])}
episode index:899
target Thresh 1.7018663297306331
current state at start:  [ 3.46861597 -2.21324554]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.46861597, -2.21324554]), 'currentState': array([3.02408039, 4.0640185 ]), 'targetState': array([-0.76945738, -0.17435843]), 'effectorPosition': array([-0.29992985,  0.83801274])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.35729595760853455
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.46861597, -2.21324554]), 'currentState': array([1.66857289, 4.76438449]), 'targetState': array([-0.76945738, -0.17435843]), 'effectorPosition': array([0.89118427, 1.14443644])}
episode index:900
target Thresh 1.7024620012011442
current state at start:  [-1.95799939 -2.05609714]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.95799939, -2.05609714]), 'currentState': array([3.95815899, 4.72708816]), 'targetState': array([-0.44218496, -0.27771152]), 'effectorPosition': array([-1.42351254, -0.05485765])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3568994027166272
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.95799939, -2.05609714]), 'currentState': array([2.72826286, 4.97380849]), 'targetState': array([-0.44218496, -0.27771152]), 'effectorPosition': array([-0.76446176,  1.39014474])}
episode index:901
target Thresh 1.7030564825192633
current state at start:  [0.94510139 2.65813789]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.94510139, 2.65813789]), 'currentState': array([1.34359492, 2.15813789]), 'targetState': array([0.18495807, 0.10163397]), 'effectorPosition': array([-0.7105957 ,  0.62189519])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3565037271038593
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.94510139, 2.65813789]), 'currentState': array([5.00580569, 5.60178889]), 'targetState': array([0.18495807, 0.10163397]), 'effectorPosition': array([-0.08909446, -1.88293653])}
episode index:902
target Thresh 1.7036497760629168
current state at start:  [-2.9427612   2.78466126]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.9427612 ,  2.78466126]), 'currentState': array([3.84042411, 2.33897909]), 'targetState': array([-0.26564514,  0.29769435]), 'effectorPosition': array([ 0.22902501, -0.7469194 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.35610892784903775
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.9427612 ,  2.78466126]), 'currentState': array([4.42696619, 2.75340136]), 'targetState': array([-0.26564514,  0.29769435]), 'effectorPosition': array([ 0.34225156, -0.17797044])}
episode index:903
target Thresh 1.7042418842052791
current state at start:  [-0.04532704  1.77089577]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.04532704,  1.77089577]), 'currentState': array([5.80061579, 1.33214866]), 'targetState': array([0.12159049, 1.37963438]), 'effectorPosition': array([1.54610472, 0.28694578])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.355715002043895
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.04532704,  1.77089577]), 'currentState': array([6.28070473, 4.66772916]), 'targetState': array([0.12159049, 1.37963438]), 'effectorPosition': array([ 0.95287399, -1.00136967])}
episode index:904
target Thresh 1.7048328093147842
current state at start:  [-0.06478187 -1.85316465]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.06478187, -1.85316465]), 'currentState': array([0.43521813, 4.89158356]), 'targetState': array([-0.07559667, -0.55022769]), 'effectorPosition': array([ 1.48325684, -0.39550394])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.35532194679301776
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.06478187, -1.85316465]), 'currentState': array([2.43298224, 5.74956211]), 'targetState': array([-0.07559667, -0.55022769]), 'effectorPosition': array([-1.08194989,  1.59728644])}
episode index:905
target Thresh 1.7054225537551326
current state at start:  [-1.41477376 -2.15519021]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.41477376, -2.15519021]), 'currentState': array([5.36841155, 4.61337247]), 'targetState': array([0.01502084, 0.01538633]), 'effectorPosition': array([-0.23887178, -1.3210718 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.35492975921377606
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.41477376, -2.15519021]), 'currentState': array([4.4961564 , 1.34104361]), 'targetState': array([0.01502084, 0.01538633]), 'effectorPosition': array([ 0.68763463, -1.40805969])}
episode index:906
target Thresh 1.7060111198853036
current state at start:  [-1.81985636  2.41700671]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.81985636,  2.41700671]), 'currentState': array([3.98241823, 2.07726378]), 'targetState': array([-0.08149121,  0.0523928 ]), 'effectorPosition': array([ 0.3082791 , -0.96684104])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3545384364362526
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.81985636,  2.41700671]), 'currentState': array([4.61808742, 0.35001312]), 'targetState': array([-0.08149121,  0.0523928 ]), 'effectorPosition': array([ 0.15877204, -1.96304047])}
episode index:907
target Thresh 1.706598510059562
current state at start:  [-0.38717022  2.48346578]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.38717022,  2.48346578]), 'currentState': array([0.03394751, 1.98346578]), 'targetState': array([-0.19633502,  0.00549698]), 'effectorPosition': array([0.56750703, 0.93585444])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.354147975603173
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.38717022,  2.48346578]), 'currentState': array([2.43198085, 5.61136633]), 'targetState': array([-0.19633502,  0.00549698]), 'effectorPosition': array([-0.94685068,  1.63366319])}
episode index:908
target Thresh 1.7071847266274696
current state at start:  [ 3.12170894 -2.57455405]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.12170894, -2.57455405]), 'currentState': array([3.62170894, 3.30060772]), 'targetState': array([0.36499541, 1.16833382]), 'effectorPosition': array([-0.08432701,  0.13461616])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.35375837386983616
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.12170894, -2.57455405]), 'currentState': array([6.12530146, 3.91224014]), 'targetState': array([0.36499541, 1.16833382]), 'effectorPosition': array([ 0.16950053, -0.73235921])}
episode index:909
target Thresh 1.7077697719338931
current state at start:  [1.90266778 1.74515938]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.90266778, 1.74515938]), 'currentState': array([1.43615326, 2.22495418]), 'targetState': array([-1.13817456,  0.79852467]), 'effectorPosition': array([-0.73382355,  0.49449031])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.3544685295029463
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.90266778, 1.74515938]), 'currentState': array([1.43615326, 2.22495418]), 'targetState': array([-1.13817456,  0.79852467]), 'effectorPosition': array([-0.73382355,  0.49449031])}
episode index:910
target Thresh 1.7083536483190147
current state at start:  [ 3.91172789 -2.09318666]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.91172789, -2.09318666]), 'currentState': array([4.11451281, 4.19628424]), 'targetState': array([-1.17750647,  0.10633801]), 'effectorPosition': array([-1.00398063,  0.07092878])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.355177126067707
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.91172789, -2.09318666]), 'currentState': array([4.11451281, 4.19628424]), 'targetState': array([-1.17750647,  0.10633801]), 'effectorPosition': array([-1.00398063,  0.07092878])}
episode index:911
target Thresh 1.7089363581183408
current state at start:  [-0.64110178 -2.61294861]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.64110178, -2.61294861]), 'currentState': array([6.14208353, 3.20637666]), 'targetState': array([ 0.6528841 , -0.89881711]), 'effectorPosition': array([-0.00702756, -0.06439032])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3547876774645626
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.64110178, -2.61294861]), 'currentState': array([3.26120019, 6.23263268]), 'targetState': array([ 0.6528841 , -0.89881711]), 'effectorPosition': array([-1.9904722, -0.1883226])}
episode index:912
target Thresh 1.709517903662711
current state at start:  [-4.06908405  2.55502384]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.06908405,  2.55502384]), 'currentState': array([2.6954034 , 3.02989509]), 'targetState': array([-0.75667116,  0.62934976]), 'effectorPosition': array([-0.05372239, -0.0978636 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.35439908197993547
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-4.06908405,  2.55502384]), 'currentState': array([4.17426407, 2.89905307]), 'targetState': array([-0.75667116,  0.62934976]), 'effectorPosition': array([ 0.19122485, -0.14822517])}
episode index:913
target Thresh 1.710098287278309
current state at start:  [ 3.88222819 -2.07289216]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.88222819, -2.07289216]), 'currentState': array([3.46034526, 4.71029315]), 'targetState': array([-0.13789439, -0.02941133]), 'effectorPosition': array([-1.26101837,  0.63689953])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3540113368136555
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.88222819, -2.07289216]), 'currentState': array([4.0198406 , 2.24506966]), 'targetState': array([-0.13789439, -0.02941133]), 'effectorPosition': array([ 0.36133248, -0.78789541])}
episode index:914
target Thresh 1.7106775112866694
current state at start:  [ 0.00843025 -1.65016557]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.00843025, -1.65016557]), 'currentState': array([0.50843025, 5.13301974]), 'targetState': array([ 0.80815046, -0.77472036]), 'effectorPosition': array([ 1.67456797, -0.11177978])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.35362443917779357
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.00843025, -1.65016557]), 'currentState': array([4.58327928, 5.69080679]), 'targetState': array([ 0.80815046, -0.77472036]), 'effectorPosition': array([-0.78925409, -1.74250051])}
episode index:915
target Thresh 1.711255578004689
current state at start:  [-0.43597818  2.01199949]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.43597818,  2.01199949]), 'currentState': array([0.02198198, 1.51199949]), 'targetState': array([0.76389225, 0.21869975]), 'effectorPosition': array([1.03656495, 1.02130262])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3532383862965951
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.43597818,  2.01199949]), 'currentState': array([5.3117703 , 4.15386808]), 'targetState': array([0.76389225, 0.21869975]), 'effectorPosition': array([-0.43503358, -0.86653384])}
episode index:916
target Thresh 1.7118324897446358
current state at start:  [ 0.55817218 -2.43881043]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.55817218, -2.43881043]), 'currentState': array([1.01128675, 4.34437488]), 'targetState': array([ 0.28360696, -0.0398929 ]), 'effectorPosition': array([1.13058784, 0.04737847])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3528531754064134
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.55817218, -2.43881043]), 'currentState': array([5.08076064, 5.76463979]), 'targetState': array([ 0.28360696, -0.0398929 ]), 'effectorPosition': array([ 0.21048677, -1.92166002])}
episode index:917
target Thresh 1.7124082488141572
current state at start:  [ 0.10321011 -2.71159601]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.10321011, -2.71159601]), 'currentState': array([0.48699291, 3.90735141]), 'targetState': array([ 0.22686254, -0.27508529]), 'effectorPosition': array([ 0.5710342 , -0.48187818])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.3535581283743803
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.10321011, -2.71159601]), 'currentState': array([0.48699291, 3.90735141]), 'targetState': array([ 0.22686254, -0.27508529]), 'effectorPosition': array([ 0.5710342 , -0.48187818])}
episode index:918
target Thresh 1.7129828575162906
current state at start:  [-0.43065343 -2.08255067]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.43065343, -2.08255067]), 'currentState': array([6.24381995, 4.70063464]), 'targetState': array([-0.7156723, -0.6587953]), 'effectorPosition': array([ 0.94812785, -1.03804886])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3531734078864865
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.43065343, -2.08255067]), 'currentState': array([2.08148058, 3.93560599]), 'targetState': array([-0.7156723, -0.6587953]), 'effectorPosition': array([0.47602984, 0.60944077])}
episode index:919
target Thresh 1.7135563181494713
current state at start:  [0.74306092 1.86666262]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.74306092, 1.86666262]), 'currentState': array([1.204368  , 1.36666262]), 'targetState': array([0.25484886, 0.47237315]), 'effectorPosition': array([-0.48331439,  1.47371811])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.35278952374747946
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.74306092, 1.86666262]), 'currentState': array([6.06313415, 4.45067893]), 'targetState': array([0.25484886, 0.47237315]), 'effectorPosition': array([ 0.51254564, -1.10445981])}
episode index:920
target Thresh 1.7141286330075427
current state at start:  [-0.31238857 -2.32531101]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.31238857, -2.32531101]), 'currentState': array([6.14146499, 4.41838098]), 'targetState': array([ 0.00802865, -0.09857207]), 'effectorPosition': array([ 0.5679037 , -1.04780927])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.35240647323309565
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.31238857, -2.32531101]), 'currentState': array([3.91781797, 1.97556684]), 'targetState': array([ 0.00802865, -0.09857207]), 'effectorPosition': array([ 0.21142177, -1.08059483])}
episode index:921
target Thresh 1.714699804379765
current state at start:  [ 2.70637342 -3.00588369]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.70637342, -3.00588369]), 'currentState': array([3.20637342, 3.77730162]), 'targetState': array([0.01328326, 0.0718758 ]), 'effectorPosition': array([-0.23337586,  0.57985671])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.35202425363089057
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.70637342, -3.00588369]), 'currentState': array([4.53895332, 0.6540554 ]), 'targetState': array([0.01328326, 0.0718758 ]), 'effectorPosition': array([ 0.28976132, -1.87170627])}
episode index:922
target Thresh 1.7152698345508244
current state at start:  [ 2.4724552  -2.09197033]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.4724552 , -2.09197033]), 'currentState': array([2.90960633, 4.63806307]), 'targetState': array([0.23108035, 0.64957264]), 'effectorPosition': array([-0.67166705,  1.18336317])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.35164286224017455
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.4724552 , -2.09197033]), 'currentState': array([5.716348  , 5.28077561]), 'targetState': array([0.23108035, 0.64957264]), 'effectorPosition': array([ 0.84515278, -1.53696548])}
episode index:923
target Thresh 1.7158387258008423
current state at start:  [-0.70070908 -2.48346944]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.70070908, -2.48346944]), 'currentState': array([6.08247623, 3.31900316]), 'targetState': array([ 0.30958519, -1.37913088]), 'effectorPosition': array([-0.01980314, -0.17606776])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3512622963719492
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.70070908, -2.48346944]), 'currentState': array([3.87899224, 4.53041672]), 'targetState': array([ 0.30958519, -1.37913088]), 'effectorPosition': array([-1.26752592,  0.17730988])}
episode index:924
target Thresh 1.7164064804053845
current state at start:  [-1.56463096 -2.14034133]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.56463096, -2.14034133]), 'currentState': array([5.21855435, 4.62440975]), 'targetState': array([-0.80960273, -0.56664363]), 'effectorPosition': array([-0.42900005, -1.28071363])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.35088255334884444
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.56463096, -2.14034133]), 'currentState': array([4.30395777, 1.36543824]), 'targetState': array([-0.80960273, -0.56664363]), 'effectorPosition': array([ 0.4203013 , -1.49371426])}
episode index:925
target Thresh 1.7169731006354703
current state at start:  [-3.6406435   2.23864573]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.6406435 ,  2.23864573]), 'currentState': array([3.07186294, 2.70187723]), 'targetState': array([-1.39583114, -0.16377149]), 'effectorPosition': array([-0.12455462, -0.4180197 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3505036305050552
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.6406435 ,  2.23864573]), 'currentState': array([4.37787569, 2.09202781]), 'targetState': array([-1.39583114, -0.16377149]), 'effectorPosition': array([ 0.65430927, -0.75893507])}
episode index:926
target Thresh 1.7175385887575811
current state at start:  [ 1.08338552 -2.53203125]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.08338552, -2.53203125]), 'currentState': array([1.5524944 , 3.29861181]), 'targetState': array([ 1.05787091, -0.92220762]), 'effectorPosition': array([0.15657368, 0.00943834])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3501255251862795
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.08338552, -2.53203125]), 'currentState': array([4.1730591 , 5.51326288]), 'targetState': array([ 1.05787091, -0.92220762]), 'effectorPosition': array([-1.479553  , -1.11662539])}
episode index:927
target Thresh 1.7181029470336706
current state at start:  [1.93910015 2.36307075]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.93910015, 2.36307075]), 'currentState': array([1.50791976, 1.97881543]), 'targetState': array([-0.63915712, -0.03089593]), 'effectorPosition': array([-0.87819209,  0.6596931 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.34974823474965633
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.93910015, 2.36307075]), 'currentState': array([2.29737419, 4.43059767]), 'targetState': array([-0.63915712, -0.03089593]), 'effectorPosition': array([0.23838688, 1.17771736])}
episode index:928
target Thresh 1.7186661777211723
current state at start:  [ 2.993291   -1.60243596]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.993291  , -1.60243596]), 'currentState': array([3.493291  , 5.18074935]), 'targetState': array([-0.03248984,  0.49302425]), 'effectorPosition': array([-1.66997488,  0.33768559])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.34937175656370406
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.993291  , -1.60243596]), 'currentState': array([4.56650787, 1.25594633]), 'targetState': array([-0.03248984,  0.49302425]), 'effectorPosition': array([ 0.75036344, -1.43398131])}
episode index:929
target Thresh 1.7192282830730097
current state at start:  [-2.22003095 -1.80468135]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.22003095, -1.80468135]), 'currentState': array([3.56315436, 4.71600497]), 'targetState': array([-0.5574273 , -0.56949336]), 'effectorPosition': array([-1.32493369,  0.50177952])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.34899608800825926
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.22003095, -1.80468135]), 'currentState': array([2.70347173, 3.73357836]), 'targetState': array([-0.5574273 , -0.56949336]), 'effectorPosition': array([0.08263571, 0.57749701])}
episode index:930
target Thresh 1.7197892653376048
current state at start:  [ 3.22469334 -2.70669324]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.22469334, -2.70669324]), 'currentState': array([2.72469334, 3.94088557]), 'targetState': array([-0.45664312, -0.27943883]), 'effectorPosition': array([0.01342526, 0.77806955])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3486212264744158
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.22469334, -2.70669324]), 'currentState': array([2.09776608, 4.13311955]), 'targetState': array([-0.45664312, -0.27943883]), 'effectorPosition': array([0.49571617, 0.81205917])}
episode index:931
target Thresh 1.720349126758888
current state at start:  [1.02280944 2.76132724]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.02280944, 2.76132724]), 'currentState': array([1.33284062, 2.26132724]), 'targetState': array([-0.10942033, -0.14196815]), 'effectorPosition': array([-0.66360756,  0.53453895])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3482471693644647
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.02280944, 2.76132724]), 'currentState': array([2.23740536, 5.56613439]), 'targetState': array([-0.10942033, -0.14196815]), 'effectorPosition': array([-0.56790401,  1.78465098])}
episode index:932
target Thresh 1.7209078695763051
current state at start:  [ 1.37691251 -2.25825517]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.37691251, -2.25825517]), 'currentState': array([0.95702777, 4.52493014]), 'targetState': array([0.42254846, 0.85826485]), 'effectorPosition': array([1.27177798, 0.09927263])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.347873914091834
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.37691251, -2.25825517]), 'currentState': array([6.10928437, 3.78921307]), 'targetState': array([0.42254846, 0.85826485]), 'effectorPosition': array([ 0.09503967, -0.62922507])}
episode index:933
target Thresh 1.7214654960248286
current state at start:  [-1.4444441  -2.44022643]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.4444441 , -2.44022643]), 'currentState': array([5.33874121, 4.30789114]), 'targetState': array([-0.92891157,  0.09872399]), 'effectorPosition': array([-0.38929774, -1.03021014])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.347501458081029
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.4444441 , -2.44022643]), 'currentState': array([4.46388447, 2.50729463]), 'targetState': array([-0.92891157,  0.09872399]), 'effectorPosition': array([ 0.5265668 , -0.33429271])}
episode index:934
target Thresh 1.7220220083349647
current state at start:  [-1.99554924  2.39820648]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.99554924,  2.39820648]), 'currentState': array([3.94996309, 2.28952954]), 'targetState': array([0.00781841, 0.06733757]), 'effectorPosition': array([ 0.30836784, -0.7668414 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3471297987675734
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.99554924,  2.39820648]), 'currentState': array([4.31792886, 1.63366891]), 'targetState': array([0.00781841, 0.06733757]), 'effectorPosition': array([ 0.56121689, -1.24874867])}
episode index:935
target Thresh 1.7225774087327634
current state at start:  [ 2.38172215 -2.76127176]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.38172215, -2.76127176]), 'currentState': array([2.88172215, 3.95268716]), 'targetState': array([-0.1366512 ,  0.70092977]), 'effectorPosition': array([-0.11453915,  0.78068574])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.34782730966632597
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.38172215, -2.76127176]), 'currentState': array([2.88172215, 3.95268716]), 'targetState': array([-0.1366512 ,  0.70092977]), 'effectorPosition': array([-0.11453915,  0.78068574])}
episode index:936
target Thresh 1.7231316994398274
current state at start:  [-2.23138521  2.04835351]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.23138521,  2.04835351]), 'currentState': array([4.19684699, 1.63780926]), 'targetState': array([ 0.95759132, -0.2960156 ]), 'effectorPosition': array([ 0.40807947, -1.3036662 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3474560958886671
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.23138521,  2.04835351]), 'currentState': array([5.4542759 , 5.01830169]), 'targetState': array([ 0.95759132, -0.2960156 ]), 'effectorPosition': array([ 0.17620164, -1.6035212 ])}
episode index:937
target Thresh 1.7236848826733198
current state at start:  [ 2.74378534 -2.29817271]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.74378534, -2.29817271]), 'currentState': array([2.24378534, 4.46875003]), 'targetState': array([-0.87793103,  0.48768109]), 'effectorPosition': array([0.28591044, 1.19824198])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3470856736116003
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.74378534, -2.29817271]), 'currentState': array([4.10818805, 2.74940683]), 'targetState': array([-0.87793103,  0.48768109]), 'effectorPosition': array([ 0.27140859, -0.2796171 ])}
episode index:938
target Thresh 1.7242369606459744
current state at start:  [-0.65254081 -2.76183612]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.65254081, -2.76183612]), 'currentState': array([6.08782944, 3.02134918]), 'targetState': array([-0.11050429, -1.08092129]), 'effectorPosition': array([0.03036813, 0.11627062])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.34671604030636965
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.65254081, -2.76183612]), 'currentState': array([2.48836918, 5.35182051]), 'targetState': array([-0.11050429, -1.08092129]), 'effectorPosition': array([-0.78033736,  1.6076543 ])}
episode index:939
target Thresh 1.724787935566104
current state at start:  [-0.0443234  -1.79004752]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.0443234 , -1.79004752]), 'currentState': array([0.02628574, 4.96759645]), 'targetState': array([ 0.54899491, -0.34043771]), 'effectorPosition': array([ 1.27744494, -0.934359  ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3463471934549799
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.0443234 , -1.79004752]), 'currentState': array([5.42950997, 5.44720846]), 'targetState': array([ 0.54899491, -0.34043771]), 'effectorPosition': array([ 0.53864127, -1.74664594])}
episode index:940
target Thresh 1.725337809637609
current state at start:  [-3.00027717  2.66143136]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.00027717,  2.66143136]), 'currentState': array([3.78290814, 2.24235328]), 'targetState': array([-0.08144913,  0.00868865]), 'effectorPosition': array([ 0.16561216, -0.85332374])}
done in step count: 30
reward sum = 0.7397003733882802
running average episode reward sum: 0.3467652095866837
{'reset': False, 'endBeforeDone': False, 'stepCount': 31, 'initial state': array([-3.00027717,  2.66143136]), 'currentState': array([4.06789739, 2.53508069]), 'targetState': array([-0.08144913,  0.00868865]), 'effectorPosition': array([ 0.3485085 , -0.48503547])}
episode index:941
target Thresh 1.7258865850599863
current state at start:  [-1.02054345  2.35230697]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.02054345,  2.35230697]), 'currentState': array([4.76264185, 1.97233082]), 'targetState': array([-0.00555643, -0.00156898]), 'effectorPosition': array([ 0.94989995, -0.56216333])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3463970936529399
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.02054345,  2.35230697]), 'currentState': array([3.92406391, 1.50792597]), 'targetState': array([-0.00555643, -0.00156898]), 'effectorPosition': array([-0.05008881, -1.45710295])}
episode index:942
target Thresh 1.7264342640283383
current state at start:  [-4.2118161   2.50269249]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.2118161 ,  2.50269249]), 'currentState': array([2.56044493, 2.00269249]), 'targetState': array([0.11044319, 0.08483805]), 'effectorPosition': array([-0.98453118, -0.43989904])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.34602975845288375
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-4.2118161 ,  2.50269249]), 'currentState': array([5.39832184, 5.37059319]), 'targetState': array([0.11044319, 0.08483805]), 'effectorPosition': array([ 0.40867168, -1.74825109])}
episode index:943
target Thresh 1.7269808487333818
current state at start:  [-3.14322659  2.52660437]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.14322659,  2.52660437]), 'currentState': array([3.63995872, 2.03266854]), 'targetState': array([-0.23240544,  0.0362244 ]), 'effectorPosition': array([-0.05903654, -1.05131576])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3456632015053701
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.14322659,  2.52660437]), 'currentState': array([4.31948921, 2.63530678]), 'targetState': array([-0.23240544,  0.0362244 ]), 'effectorPosition': array([ 0.3999516 , -0.30155504])}
episode index:944
target Thresh 1.727526341361456
current state at start:  [0.1933708 2.8381251]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.1933708, 2.8381251]), 'currentState': array([0.6933708 , 2.34285738]), 'targetState': array([0.58983257, 0.22719904]), 'effectorPosition': array([-0.2253583,  0.7443029])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.34529742033975597
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.1933708, 2.8381251]), 'currentState': array([5.68947496, 4.07125665]), 'targetState': array([0.58983257, 0.22719904]), 'effectorPosition': array([-0.11522568, -0.88910992])}
episode index:945
target Thresh 1.7280707440945324
current state at start:  [ 1.37076835 -2.67410152]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.37076835, -2.67410152]), 'currentState': array([1.83004637, 4.06763438]), 'targetState': array([-0.07457439, -0.23837981]), 'effectorPosition': array([0.6702531, 0.5905558])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.34493241249584505
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.37076835, -2.67410152]), 'currentState': array([2.33463904, 5.6770736 ]), 'targetState': array([-0.07457439, -0.23837981]), 'effectorPosition': array([-0.84877947,  1.70976957])}
episode index:946
target Thresh 1.7286140591102228
current state at start:  [ 0.84634658 -2.74523221]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.84634658, -2.74523221]), 'currentState': array([1.16561445, 4.03310158]), 'targetState': array([0.22315416, 0.1207263 ]), 'effectorPosition': array([0.86156787, 0.03497523])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3445681755238325
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.84634658, -2.74523221]), 'currentState': array([2.26739914, 5.34853592]), 'targetState': array([0.22315416, 0.1207263 ]), 'effectorPosition': array([-0.40581092,  1.73882676])}
episode index:947
target Thresh 1.7291562885817875
current state at start:  [ 2.10502632 -2.20632872]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.10502632, -2.20632872]), 'currentState': array([2.60095863, 4.46037671]), 'targetState': array([-0.12756486, -0.08616093]), 'effectorPosition': array([-0.14516917,  1.21664275])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.34420470698425043
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.10502632, -2.20632872]), 'currentState': array([2.70761258, 6.04360485]), 'targetState': array([-0.12756486, -0.08616093]), 'effectorPosition': array([-1.68890504,  1.04425811])}
episode index:948
target Thresh 1.7296974346781455
current state at start:  [ 0.80379087 -2.31142233]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.80379087, -2.31142233]), 'currentState': array([1.30379087, 4.43901696]), 'targetState': array([ 0.01451664, -0.02474735]), 'effectorPosition': array([1.12135874, 0.45010559])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.34384200444791296
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.80379087, -2.31142233]), 'currentState': array([2.46777323, 5.63279672]), 'targetState': array([ 0.01451664, -0.02474735]), 'effectorPosition': array([-1.02554105,  1.59372604])}
episode index:949
target Thresh 1.730237499563882
current state at start:  [-2.5383508   2.18499651]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.5383508 ,  2.18499651]), 'currentState': array([4.18293339, 1.74071326]), 'targetState': array([ 0.25999786, -0.23699637]), 'effectorPosition': array([ 0.4309957 , -1.21492458])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3434800654958625
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.5383508 ,  2.18499651]), 'currentState': array([4.55380044, 6.25041727]), 'targetState': array([ 0.25999786, -0.23699637]), 'effectorPosition': array([-0.3481155, -1.9691983])}
episode index:950
target Thresh 1.7307764853992569
current state at start:  [0.42533065 2.27749964]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.42533065, 2.27749964]), 'currentState': array([0.92533065, 1.77749964]), 'targetState': array([0.0997536 , 0.12968996]), 'effectorPosition': array([-0.30370763,  1.2236391 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.34311888771931587
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.42533065, 2.27749964]), 'currentState': array([2.22289692, 5.80522684]), 'targetState': array([0.0997536 , 0.12968996]), 'effectorPosition': array([-0.78012062,  1.77968633])}
episode index:951
target Thresh 1.7313143943402145
current state at start:  [ 1.99391125 -2.82967323]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.99391125, -2.82967323]), 'currentState': array([2.49391125, 3.82247914]), 'targetState': array([0.10237525, 0.178572  ]), 'effectorPosition': array([0.20196392, 0.63653796])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.3438088888876779
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.99391125, -2.82967323]), 'currentState': array([2.49391125, 3.82247914]), 'targetState': array([0.10237525, 0.178572  ]), 'effectorPosition': array([0.20196392, 0.63653796])}
episode index:952
target Thresh 1.7318512285383911
current state at start:  [ 0.54872242 -2.14366929]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.54872242, -2.14366929]), 'currentState': array([1.04095767, 4.54945331]), 'targetState': array([ 0.01539355, -0.04671671]), 'effectorPosition': array([1.27487121, 0.2242142 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3434481240514894
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.54872242, -2.14366929]), 'currentState': array([2.4256408, 5.341786 ]), 'targetState': array([ 0.01539355, -0.04671671]), 'effectorPosition': array([-0.66802205,  1.65259233])}
episode index:953
target Thresh 1.7323869901411244
current state at start:  [-2.13608001  2.0952399 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.13608001,  2.0952399 ]), 'currentState': array([3.66878288, 1.64319905]), 'targetState': array([ 0.2985316 , -1.17769026]), 'effectorPosition': array([-0.29991763, -1.32867244])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.34308811553571217
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.13608001,  2.0952399 ]), 'currentState': array([5.74218379, 2.03956601]), 'targetState': array([ 0.2985316 , -1.17769026]), 'effectorPosition': array([0.92936238, 0.48239767])}
episode index:954
target Thresh 1.7329216812914614
current state at start:  [ 0.22922105 -1.95424659]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.22922105, -1.95424659]), 'currentState': array([0.69931949, 4.82893872]), 'targetState': array([ 0.34038371, -0.39088796]), 'effectorPosition': array([ 1.49360191, -0.04153852])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3427288609644706
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.22922105, -1.95424659]), 'currentState': array([4.610325  , 0.72784579]), 'targetState': array([ 0.34038371, -0.39088796]), 'effectorPosition': array([ 0.48384424, -1.80530143])}
episode index:955
target Thresh 1.7334553041281675
current state at start:  [ 3.57690014 -2.23428467]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.57690014, -2.23428467]), 'currentState': array([3.07690014, 4.30838717]), 'targetState': array([-0.74262924, -0.26493646]), 'effectorPosition': array([-0.54618637,  0.95680625])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3423703579718299
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.57690014, -2.23428467]), 'currentState': array([2.17336897, 4.14176606]), 'targetState': array([-0.74262924, -0.26493646]), 'effectorPosition': array([0.43272575, 0.85582455])}
episode index:956
target Thresh 1.7339878607857349
current state at start:  [ 2.58591001 -2.34899223]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.58591001, -2.34899223]), 'currentState': array([2.75441696, 4.43419308]), 'targetState': array([-0.07428567,  0.71918865]), 'effectorPosition': array([-0.30862763,  1.16426211])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.34305753628115926
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.58591001, -2.34899223]), 'currentState': array([2.75441696, 4.43419308]), 'targetState': array([-0.07428567,  0.71918865]), 'effectorPosition': array([-0.30862763,  1.16426211])}
episode index:957
target Thresh 1.7345193533943906
current state at start:  [-1.60630925 -1.69911015]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.60630925, -1.69911015]), 'currentState': array([5.15994494, 5.08407516]), 'targetState': array([-1.13624021, -0.60787693]), 'effectorPosition': array([-0.25001162, -1.63213607])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.34269943864412256
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.60630925, -1.69911015]), 'currentState': array([2.24643335, 3.24698682]), 'targetState': array([-1.13624021, -0.60787693]), 'effectorPosition': array([0.07861762, 0.07012078])}
episode index:958
target Thresh 1.7350497840801058
current state at start:  [0.15648651 2.04551637]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.15648651, 2.04551637]), 'currentState': array([0.60962272, 1.54551637]), 'targetState': array([0.35330561, 0.34443544]), 'effectorPosition': array([0.26821278, 1.40663301])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3423420878217616
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.15648651, 2.04551637]), 'currentState': array([0.03118952, 5.68162075]), 'targetState': array([0.35330561, 0.34443544]), 'effectorPosition': array([ 1.84121218, -0.50876329])}
episode index:959
target Thresh 1.735579154964604
current state at start:  [-3.17034811  2.26485309]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.17034811,  2.26485309]), 'currentState': array([3.6128372 , 1.89040291]), 'targetState': array([-1.12728743, -0.01648446]), 'effectorPosition': array([-0.18005189, -1.15723599])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.34198548148028063
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.17034811,  2.26485309]), 'currentState': array([0.8193363 , 4.57807177]), 'targetState': array([-1.12728743, -0.01648446]), 'effectorPosition': array([ 1.31539411, -0.04371409])}
episode index:960
target Thresh 1.7361074681653696
current state at start:  [-3.01769374  2.04601544]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.01769374,  2.04601544]), 'currentState': array([3.64927562, 1.55769742]), 'targetState': array([-0.14613118, -0.31318793]), 'effectorPosition': array([-0.39920769, -1.36631998])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3416296172955977
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.01769374,  2.04601544]), 'currentState': array([4.11416253, 1.81178315]), 'targetState': array([-0.14613118, -0.31318793]), 'effectorPosition': array([ 0.37368785, -1.17602521])}
episode index:961
target Thresh 1.7366347257956563
current state at start:  [-0.22578401  2.68920628]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.22578401,  2.68920628]), 'currentState': array([0.27302307, 2.21641911]), 'targetState': array([ 0.84259631, -0.31550147]), 'effectorPosition': array([0.16817963, 0.87654072])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3412744929532946
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.22578401,  2.68920628]), 'currentState': array([5.17824452, 5.4620489 ]), 'targetState': array([ 0.84259631, -0.31550147]), 'effectorPosition': array([ 0.10133363, -1.83098642])}
episode index:962
target Thresh 1.7371609299644946
current state at start:  [ 0.54937575 -1.59640753]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.54937575, -1.59640753]), 'currentState': array([1.02765269, 5.17111364]), 'targetState': array([ 0.54475034, -0.46157282]), 'effectorPosition': array([1.5132686 , 0.77176945])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3409201061485663
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.54937575, -1.59640753]), 'currentState': array([3.16293796, 4.53923738]), 'targetState': array([ 0.54475034, -0.46157282]), 'effectorPosition': array([-0.84854831,  0.96715585])}
episode index:963
target Thresh 1.7376860827767024
current state at start:  [-0.66336844  2.84806255]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.66336844,  2.84806255]), 'currentState': array([5.99568551, 2.36761898]), 'targetState': array([ 0.45872674, -0.65716562]), 'effectorPosition': array([0.47136965, 0.58951934])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3405664545861716
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.66336844,  2.84806255]), 'currentState': array([6.11865766, 1.9908573 ]), 'targetState': array([ 0.45872674, -0.65716562]), 'effectorPosition': array([0.73373438, 0.80374225])}
episode index:964
target Thresh 1.7382101863328918
current state at start:  [-2.7260484  1.5809637]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.7260484,  1.5809637]), 'currentState': array([4.00545378, 1.0809637 ]), 'targetState': array([-0.0443839 , -0.69984404]), 'effectorPosition': array([-0.28413811, -1.69121907])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3402135359803828
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.7260484,  1.5809637]), 'currentState': array([3.55741708, 5.18362037]), 'targetState': array([-0.0443839 , -0.69984404]), 'effectorPosition': array([-1.68999889,  0.2277529 ])}
episode index:965
target Thresh 1.7387332427294773
current state at start:  [1.28754205 2.26573199]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.28754205, 2.26573199]), 'currentState': array([0.83947203, 1.8691667 ]), 'targetState': array([-0.21158589,  0.85140655]), 'effectorPosition': array([-0.2398745 ,  1.16384461])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.34089654474230785
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.28754205, 2.26573199]), 'currentState': array([0.83947203, 1.8691667 ]), 'targetState': array([-0.21158589,  0.85140655]), 'effectorPosition': array([-0.2398745 ,  1.16384461])}
episode index:966
target Thresh 1.7392552540586852
current state at start:  [ 1.72128166 -2.04940413]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.72128166, -2.04940413]), 'currentState': array([1.22854171, 4.73378118]), 'targetState': array([0.25613405, 1.09168378]), 'effectorPosition': array([1.28457557, 0.62661531])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.34054401470637996
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.72128166, -2.04940413]), 'currentState': array([5.86343546, 3.74948543]), 'targetState': array([0.25613405, 1.09168378]), 'effectorPosition': array([-0.06916235, -0.59456695])}
episode index:967
target Thresh 1.739776222408562
current state at start:  [ 4.36024183 -2.73156232]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.36024183, -2.73156232]), 'currentState': array([4.76060164, 3.92597502]), 'targetState': array([-0.28959785,  0.05425324]), 'effectorPosition': array([-0.69148623, -0.32587946])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.3412252708895345
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.36024183, -2.73156232]), 'currentState': array([4.76060164, 3.92597502]), 'targetState': array([-0.28959785,  0.05425324]), 'effectorPosition': array([-0.69148623, -0.32587946])}
episode index:968
target Thresh 1.7402961498629812
current state at start:  [-3.16158321  2.03721654]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.16158321,  2.03721654]), 'currentState': array([3.54386423, 2.07895557]), 'targetState': array([-0.96611807, -0.76353452]), 'effectorPosition': array([-0.13040595, -1.00491516])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.34087312922710983
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.16158321,  2.03721654]), 'currentState': array([4.77562037, 1.13697529]), 'targetState': array([-0.96611807, -0.76353452]), 'effectorPosition': array([ 0.99530322, -1.36016668])}
episode index:969
target Thresh 1.7408150385016539
current state at start:  [ 3.39932703 -2.05698601]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.39932703, -2.05698601]), 'currentState': array([3.88960462, 4.61960917]), 'targetState': array([-0.22393111,  0.68787897]), 'effectorPosition': array([-1.34238588,  0.11272369])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.34052171362996847
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.39932703, -2.05698601]), 'currentState': array([5.95352493, 4.74011596]), 'targetState': array([-0.22393111,  0.68787897]), 'effectorPosition': array([ 0.64878565, -1.27848506])}
episode index:970
target Thresh 1.7413328904001348
current state at start:  [-1.41984564  2.29405077]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.41984564,  2.29405077]), 'currentState': array([4.36333967, 1.79970617]), 'targetState': array([1.01347627, 0.14714366]), 'effectorPosition': array([ 0.65078733, -1.05954895])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.34017102185486037
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.41984564,  2.29405077]), 'currentState': array([5.08758526, 4.86933485]), 'targetState': array([1.01347627, 0.14714366]), 'effectorPosition': array([-0.495267  , -1.43781615])}
episode index:971
target Thresh 1.7418497076298323
current state at start:  [-2.31313806  1.61163761]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.31313806,  1.61163761]), 'currentState': array([3.52243564, 1.15738304]), 'targetState': array([ 0.2921346 , -0.96815363]), 'effectorPosition': array([-0.96091616, -1.37117283])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3398210516677669
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.31313806,  1.61163761]), 'currentState': array([1.01149351, 0.44073628]), 'targetState': array([ 0.2921346 , -0.96815363]), 'effectorPosition': array([0.6488843 , 1.84060446])}
episode index:972
target Thresh 1.7423654922580163
current state at start:  [ 0.27466746 -1.63674174]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.27466746, -1.63674174]), 'currentState': array([6.06495892, 5.00927545]), 'targetState': array([0.34398744, 0.14409794]), 'effectorPosition': array([ 1.05486196, -1.21340631])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3394718008438534
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.27466746, -1.63674174]), 'currentState': array([6.17557319, 5.43737119]), 'targetState': array([0.34398744, 0.14409794]), 'effectorPosition': array([ 1.57310813, -0.92280824])}
episode index:973
target Thresh 1.7428802463478257
current state at start:  [0.24361262 2.17249399]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.24361262, 2.17249399]), 'currentState': array([0.74361262, 1.67249399]), 'targetState': array([0.99492382, 0.51626008]), 'effectorPosition': array([-0.01214921,  1.34045048])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.33912326716742236
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.24361262, 2.17249399]), 'currentState': array([5.95690714, 4.68246458]), 'targetState': array([0.99492382, 0.51626008]), 'effectorPosition': array([ 0.59852412, -1.25774759])}
episode index:974
target Thresh 1.7433939719582778
current state at start:  [-3.82206988  1.64657521]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.82206988,  1.64657521]), 'currentState': array([2.73021344, 1.23978969]), 'targetState': array([-0.87768296, -0.11560038]), 'effectorPosition': array([-1.59261805, -0.33698385])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.338775448431866
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.82206988,  1.64657521]), 'currentState': array([4.84940538, 0.0379858 ]), 'targetState': array([-0.87768296, -0.11560038]), 'effectorPosition': array([ 0.31069839, -1.97535409])}
episode index:975
target Thresh 1.7439066711442757
current state at start:  [ 2.9731733 -1.625702 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.9731733, -1.625702 ]), 'currentState': array([3.42604156, 5.0716834 ]), 'targetState': array([-0.18558604,  1.34308531]), 'effectorPosition': array([-1.56001021,  0.51922611])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3384283424396203
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.9731733, -1.625702 ]), 'currentState': array([5.98719639, 3.75657042]), 'targetState': array([-0.18558604,  1.34308531]), 'effectorPosition': array([ 0.00696115, -0.60529249])}
episode index:976
target Thresh 1.7444183459566163
current state at start:  [2.16196866 1.76647272]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.16196866, 1.76647272]), 'currentState': array([1.8656731 , 2.24079885]), 'targetState': array([-1.33702666,  0.42157916]), 'effectorPosition': array([-0.86013804,  0.13485778])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.339105488455547
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.16196866, 1.76647272]), 'currentState': array([1.8656731 , 2.24079885]), 'targetState': array([-1.33702666,  0.42157916]), 'effectorPosition': array([-0.86013804,  0.13485778])}
episode index:977
target Thresh 1.7449289984420002
current state at start:  [-1.55629058 -2.43900284]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.55629058, -2.43900284]), 'currentState': array([5.22689473, 4.34418247]), 'targetState': array([-0.16996378,  0.09432746]), 'effectorPosition': array([-0.49721269, -1.01631396])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3387587548272693
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.55629058, -2.43900284]), 'currentState': array([6.10573344, 5.69948834]), 'targetState': array([-0.16996378,  0.09432746]), 'effectorPosition': array([ 1.70834076, -0.86627574])}
episode index:978
target Thresh 1.7454386306430378
current state at start:  [ 2.7786836  -1.84995387]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.7786836 , -1.84995387]), 'currentState': array([3.22712249, 4.93323143]), 'targetState': array([0.26202868, 1.07822459]), 'effectorPosition': array([-1.2979464 ,  0.86800837])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.33841272954143964
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.7786836 , -1.84995387]), 'currentState': array([6.05009778, 4.06721492]), 'targetState': array([0.26202868, 1.07822459]), 'effectorPosition': array([ 0.20332778, -0.86947269])}
episode index:979
target Thresh 1.7459472445982587
current state at start:  [ 0.23305484 -1.9030283 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.23305484, -1.9030283 ]), 'currentState': array([0.73305484, 4.64377336]), 'targetState': array([ 1.07228847, -0.60763015]), 'effectorPosition': array([ 1.3597515 , -0.11811978])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.33908781859292797
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.23305484, -1.9030283 ]), 'currentState': array([0.73305484, 4.64377336]), 'targetState': array([ 1.07228847, -0.60763015]), 'effectorPosition': array([ 1.3597515 , -0.11811978])}
episode index:980
target Thresh 1.7464548423421191
current state at start:  [-1.18902122  1.91728653]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.18902122,  1.91728653]), 'currentState': array([4.67271058, 1.49594866]), 'targetState': array([ 1.04544794, -0.25364871]), 'effectorPosition': array([ 0.95378107, -1.11348879])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.33874216332422974
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.18902122,  1.91728653]), 'currentState': array([4.28750951, 5.2427274 ]), 'targetState': array([ 1.04544794, -0.25364871]), 'effectorPosition': array([-1.40665533, -1.016352  ])}
episode index:981
target Thresh 1.7469614259050106
current state at start:  [-2.98572621  2.4299162 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.98572621,  2.4299162 ]), 'currentState': array([3.76644123, 2.07978993]), 'targetState': array([-0.42739214, -0.5794325 ]), 'effectorPosition': array([ 0.09499311, -1.00815622])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.33839721203774886
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.98572621,  2.4299162 ]), 'currentState': array([4.45663772, 1.47656417]), 'targetState': array([-0.42739214, -0.5794325 ]), 'effectorPosition': array([ 0.6864061 , -1.31035575])}
episode index:982
target Thresh 1.7474669973132686
current state at start:  [-3.51858788  2.03920863]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.51858788,  2.03920863]), 'currentState': array([3.24085189, 1.56254736]), 'targetState': array([-0.01593152, -0.29479875]), 'effectorPosition': array([-0.90419317, -1.09495775])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.33805296258501466
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.51858788,  2.03920863]), 'currentState': array([3.44516236, 4.98255266]), 'targetState': array([-0.01593152, -0.29479875]), 'effectorPosition': array([-1.49704691,  0.54095187])}
episode index:983
target Thresh 1.747971558589179
current state at start:  [-2.33978245  2.53777034]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.33978245,  2.53777034]), 'currentState': array([3.50122792, 2.13714857]), 'targetState': array([ 0.42820883, -0.34288943]), 'effectorPosition': array([-0.13681056, -0.95297851])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.33770941282629
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.33978245,  2.53777034]), 'currentState': array([5.20370633, 0.87522032]), 'targetState': array([ 0.42820883, -0.34288943]), 'effectorPosition': array([ 1.45099945, -1.08455339])}
episode index:984
target Thresh 1.748475111750988
current state at start:  [-2.46618559  2.200724  ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.46618559,  2.200724  ]), 'currentState': array([4.28750161, 1.86474102]), 'targetState': array([-0.27623824, -1.01099485]), 'effectorPosition': array([ 0.57922108, -1.04165397])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.3383716367726593
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.46618559,  2.200724  ]), 'currentState': array([3.99471147, 1.43976631]), 'targetState': array([-0.27623824, -1.01099485]), 'effectorPosition': array([ 0.00331677, -1.50376188])}
episode index:985
target Thresh 1.7489776588129082
current state at start:  [1.20736468 2.51532229]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.20736468, 2.51532229]), 'currentState': array([1.24362533, 2.0893678 ]), 'targetState': array([0.1637286 , 0.40881792]), 'effectorPosition': array([-0.6603734 ,  0.75672129])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3380284606704558
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.20736468, 2.51532229]), 'currentState': array([5.72647701, 6.27563494]), 'targetState': array([0.1637286 , 0.40881792]), 'effectorPosition': array([ 1.69398432, -1.06318396])}
episode index:986
target Thresh 1.7494792017851293
current state at start:  [0.20084555 1.74518406]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.20084555, 1.74518406]), 'currentState': array([5.98403086, 1.25913217]), 'targetState': array([-0.17629745,  0.86998494]), 'effectorPosition': array([1.52912426, 0.52446648])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.33768597996055666
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.20084555, 1.74518406]), 'currentState': array([5.67933352, 4.92457488]), 'targetState': array([-0.17629745,  0.86998494]), 'effectorPosition': array([ 0.44142594, -1.49209172])}
episode index:987
target Thresh 1.7499797426738235
current state at start:  [1.86904227 1.82186196]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.86904227, 1.82186196]), 'currentState': array([2.25442609, 2.24351639]), 'targetState': array([-0.65365201,  1.12871652]), 'effectorPosition': array([-0.84441792, -0.2018091 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.33734419253144676
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.86904227, 1.82186196]), 'currentState': array([5.98143301, 5.65765643]), 'targetState': array([-0.65365201,  1.12871652]), 'effectorPosition': array([ 1.55482842, -1.09718536])}
episode index:988
target Thresh 1.750479283481155
current state at start:  [1.2962458  2.19184659]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.2962458 , 2.19184659]), 'currentState': array([1.69016936, 1.69184659]), 'targetState': array([-0.58092191, -0.24283304]), 'effectorPosition': array([-1.09032699,  0.75476973])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.33700309628015107
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.2962458 , 2.19184659]), 'currentState': array([3.40185495, 5.23675723]), 'targetState': array([-0.58092191, -0.24283304]), 'effectorPosition': array([-1.6728863 ,  0.45031533])}
episode index:989
target Thresh 1.7509778262052875
current state at start:  [ 1.30852432 -2.66279107]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.30852432, -2.66279107]), 'currentState': array([1.80852432, 4.12039424]), 'targetState': array([-0.08794172, -0.41168871]), 'effectorPosition': array([0.70240598, 0.62497279])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3366626891121913
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.30852432, -2.66279107]), 'currentState': array([3.48146967, 4.83301833]), 'targetState': array([-0.08794172, -0.41168871]), 'effectorPosition': array([-1.38719745,  0.56245644])}
episode index:990
target Thresh 1.751475372840393
current state at start:  [-3.06965786  2.57764784]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.06965786,  2.57764784]), 'currentState': array([3.68664766, 2.10126299]), 'targetState': array([ 0.0167372 , -0.05778081]), 'effectorPosition': array([ 0.02473943, -0.99373845])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3363229689415433
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.06965786,  2.57764784]), 'currentState': array([3.4011133 , 4.50059055]), 'targetState': array([ 0.0167372 , -0.05778081]), 'effectorPosition': array([-1.0142172 ,  0.74224423])}
episode index:991
target Thresh 1.7519719253766584
current state at start:  [-0.50979219 -2.38423755]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.50979219, -2.38423755]), 'currentState': array([6.27339312, 4.36661248]), 'targetState': array([-0.1789645 , -0.14395339]), 'effectorPosition': array([ 0.65182851, -0.9472407 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.33598393369059415
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.50979219, -2.38423755]), 'currentState': array([2.81531169, 4.77233183]), 'targetState': array([-0.1789645 , -0.14395339]), 'effectorPosition': array([-0.68404049,  1.2852636 ])}
episode index:992
target Thresh 1.7524674858002947
current state at start:  [-1.90477915  2.25550053]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.90477915,  2.25550053]), 'currentState': array([4.87840615, 1.84756279]), 'targetState': array([ 0.38967574, -1.34093403]), 'effectorPosition': array([ 1.0688181 , -0.55779446])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3356455812901001
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.90477915,  2.25550053]), 'currentState': array([1.78718214, 0.0896156 ]), 'targetState': array([ 0.38967574, -1.34093403]), 'effectorPosition': array([-0.51594934,  1.93022556])}
episode index:993
target Thresh 1.752962056093544
current state at start:  [-0.87373399  1.84143269]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.87373399,  1.84143269]), 'currentState': array([4.90945131, 1.34143269]), 'targetState': array([0.49873304, 0.15709047]), 'effectorPosition': array([ 1.19526773, -1.01294166])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.33530790967914426
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.87373399,  1.84143269]), 'currentState': array([5.84101035, 6.18255347]), 'targetState': array([0.49873304, 0.15709047]), 'effectorPosition': array([ 1.76008536, -0.94444762])}
episode index:994
target Thresh 1.7534556382346884
current state at start:  [0.92583601 1.88468767]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.92583601, 1.88468767]), 'currentState': array([0.47283624, 1.39496312]), 'targetState': array([-0.06254431,  1.11880404]), 'effectorPosition': array([0.59762444, 1.41163102])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3349709168050949
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.92583601, 1.88468767]), 'currentState': array([5.67919578, 5.10370813]), 'targetState': array([-0.06254431,  1.11880404]), 'effectorPosition': array([ 0.61200553, -1.54540143])}
episode index:995
target Thresh 1.753948234198057
current state at start:  [-0.07998103 -2.36044487]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.07998103, -2.36044487]), 'currentState': array([0.37031883, 4.4086674 ]), 'targetState': array([-0.08751216, -0.1257958 ]), 'effectorPosition': array([ 0.99876003, -0.63587056])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.33463460062356365
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.07998103, -2.36044487]), 'currentState': array([3.40889148, 4.8361889 ]), 'targetState': array([-0.08751216, -0.1257958 ]), 'effectorPosition': array([-1.34569229,  0.66036362])}
episode index:996
target Thresh 1.7544398459540345
current state at start:  [ 2.57047328 -2.53245109]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.57047328, -2.53245109]), 'currentState': array([3.07047328, 4.21271918]), 'targetState': array([0.00571605, 0.00030709]), 'effectorPosition': array([-0.4571758 ,  0.91253428])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3342989590983645
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.57047328, -2.53245109]), 'currentState': array([3.39147687, 4.6791832 ]), 'targetState': array([0.00571605, 0.00030709]), 'effectorPosition': array([-1.18392798,  0.72932515])}
episode index:997
target Thresh 1.7549304754690682
current state at start:  [0.44524009 2.36964309]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.44524009, 2.36964309]), 'currentState': array([6.24418341, 1.86964309]), 'targetState': array([-0.14460657,  0.95605717]), 'effectorPosition': array([0.7423089 , 0.92743784])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3339639902014723
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.44524009, 2.36964309]), 'currentState': array([6.01032133, 5.9460109 ]), 'targetState': array([-0.14460657,  0.95605717]), 'effectorPosition': array([ 1.78262906, -0.84238948])}
episode index:998
target Thresh 1.7554201247056769
current state at start:  [ 2.68970208 -2.63781209]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.68970208, -2.63781209]), 'currentState': array([2.20938124, 3.96868499]), 'targetState': array([-0.58014893,  0.69751646]), 'effectorPosition': array([0.39842027, 0.69801445])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.33362969191298236
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.68970208, -2.63781209]), 'currentState': array([5.25854022, 5.48727677]), 'targetState': array([-0.58014893,  0.69751646]), 'effectorPosition': array([ 0.2722334 , -1.82350234])}
episode index:999
target Thresh 1.7559087956224586
current state at start:  [-1.66092461  1.63297766]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.66092461,  1.63297766]), 'currentState': array([4.16836832, 1.17684891]), 'targetState': array([ 0.26126915, -0.17481313]), 'effectorPosition': array([ 0.07384732, -1.66199262])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3332960622210694
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.66092461,  1.63297766]), 'currentState': array([3.7549364 , 4.06076857]), 'targetState': array([ 0.26126915, -0.17481313]), 'effectorPosition': array([-0.7794606 ,  0.42366259])}
episode index:1000
target Thresh 1.7563964901740972
current state at start:  [-2.50771357  2.38132464]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.50771357,  2.38132464]), 'currentState': array([4.15965411, 1.97706814]), 'targetState': array([-0.10087629,  0.09126428]), 'effectorPosition': array([ 0.46427663, -0.99703183])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.33296309912194744
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.50771357,  2.38132464]), 'currentState': array([3.01662306, 4.57172998]), 'targetState': array([-0.10087629,  0.09126428]), 'effectorPosition': array([-0.72968559,  1.08957224])}
episode index:1001
target Thresh 1.7568832103113716
current state at start:  [ 2.36654876 -1.66911697]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.36654876, -1.66911697]), 'currentState': array([2.80048058, 5.03357668]), 'targetState': array([0.51697384, 0.9219988 ]), 'effectorPosition': array([-0.92246017,  1.33433681])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.33263080061982975
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.36654876, -1.66911697]), 'currentState': array([1.81878223e-03, 5.12180214e+00]), 'targetState': array([0.51697384, 0.9219988 ]), 'effectorPosition': array([ 1.39973721, -0.91481028])}
episode index:1002
target Thresh 1.7573689579811633
current state at start:  [-3.68983553  2.15158565]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.68983553,  2.15158565]), 'currentState': array([3.09334977, 1.65160267]), 'targetState': array([-0.07940659, -0.06157765]), 'effectorPosition': array([-0.96627883, -0.95124569])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.33229916472688875
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.68983553,  2.15158565]), 'currentState': array([3.05073506, 4.38189127]), 'targetState': array([-0.07940659, -0.06157765]), 'effectorPosition': array([-0.5868777,  1.0032681])}
episode index:1003
target Thresh 1.7578537351264631
current state at start:  [-3.84504959  2.25038906]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.84504959,  2.25038906]), 'currentState': array([2.01470036, 2.09175336]), 'targetState': array([-0.96776262, -0.85650139]), 'effectorPosition': array([-0.99899947,  0.0811121 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.33196818946321655
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.84504959,  2.25038906]), 'currentState': array([0.83499964, 0.23936395]), 'targetState': array([-0.96776262, -0.85650139]), 'effectorPosition': array([1.14746988, 1.62058348])}
episode index:1004
target Thresh 1.7583375436863808
current state at start:  [0.78584254 2.79290262]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.78584254, 2.79290262]), 'currentState': array([1.06039447, 2.38003183]), 'targetState': array([0.5577995 , 0.60545309]), 'effectorPosition': array([-0.46715259,  0.57814252])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3316378728567855
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.78584254, 2.79290262]), 'currentState': array([5.80636124, 6.03128959]), 'targetState': array([0.5577995 , 0.60545309]), 'effectorPosition': array([ 1.63448455, -1.12487492])}
episode index:1005
target Thresh 1.758820385596151
current state at start:  [ 1.7951017 -2.1321426]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.7951017, -2.1321426]), 'currentState': array([2.24673468, 4.65104271]), 'targetState': array([0.58765662, 0.90841638]), 'effectorPosition': array([0.19137911, 1.35674553])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.33230224872869724
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.7951017, -2.1321426]), 'currentState': array([2.24673468, 4.65104271]), 'targetState': array([0.58765662, 0.90841638]), 'effectorPosition': array([0.19137911, 1.35674553])}
episode index:1006
target Thresh 1.7593022627871422
current state at start:  [-3.40203142  1.83750481]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.40203142,  1.83750481]), 'currentState': array([3.34850869, 2.17306773]), 'targetState': array([-1.33578203, -0.39389673]), 'effectorPosition': array([-0.25494247, -0.89552944])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3319722564260868
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.40203142,  1.83750481]), 'currentState': array([2.73102493, 3.60031221]), 'targetState': array([-1.33578203, -0.39389673]), 'effectorPosition': array([0.08194655, 0.44726316])}
episode index:1007
target Thresh 1.7597831771868633
current state at start:  [ 3.20377559 -2.19277329]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.20377559, -2.19277329]), 'currentState': array([3.69567579, 4.01474172]), 'targetState': array([0.28174032, 0.20498547]), 'effectorPosition': array([-0.70731175,  0.46354852])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.33164291887010855
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.20377559, -2.19277329]), 'currentState': array([2.01935973, 4.66869601]), 'targetState': array([0.28174032, 0.20498547]), 'effectorPosition': array([0.48548193, 1.29497072])}
episode index:1008
target Thresh 1.760263130718973
current state at start:  [ 1.30420628 -2.18087746]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.30420628, -2.18087746]), 'currentState': array([0.89366901, 4.53148355]), 'targetState': array([0.48431847, 0.57662236]), 'effectorPosition': array([1.28048379, 0.02281824])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.33131423411404304
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.30420628, -2.18087746]), 'currentState': array([5.85927587, 4.87478671]), 'targetState': array([0.48431847, 0.57662236]), 'effectorPosition': array([ 0.6529467 , -1.37732723])}
episode index:1009
target Thresh 1.7607421253032858
current state at start:  [2.03784122 1.8633151 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.03784122, 1.8633151 ]), 'currentState': array([2.53784122, 1.3633151 ]), 'targetState': array([-0.34754933,  0.7247191 ]), 'effectorPosition': array([-1.54834814, -0.12087042])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3309862002188806
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([2.03784122, 1.8633151 ]), 'currentState': array([5.94613189, 5.18586095]), 'targetState': array([-0.34754933,  0.7247191 ]), 'effectorPosition': array([ 1.07972903, -1.32141716])}
episode index:1010
target Thresh 1.7612201628557809
current state at start:  [-0.16212736 -2.70354808]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.16212736, -2.70354808]), 'currentState': array([5.66176634, 4.05515307]), 'targetState': array([-0.32332333,  0.32553303]), 'effectorPosition': array([-0.14457616, -0.87019304])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3306588152532833
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.16212736, -2.70354808]), 'currentState': array([0.52690339, 5.65611715]), 'targetState': array([-0.32332333,  0.32553303]), 'effectorPosition': array([1.85935607, 0.40286178])}
episode index:1011
target Thresh 1.761697245288609
current state at start:  [-0.01888813 -2.40020994]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.01888813, -2.40020994]), 'currentState': array([0.48111187, 3.40020189]), 'targetState': array([ 1.05502292, -0.84080507]), 'effectorPosition': array([ 0.14782435, -0.21131682])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.33033207729354686
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.01888813, -2.40020994]), 'currentState': array([2.08182735, 5.47018901]), 'targetState': array([ 1.05502292, -0.84080507]), 'effectorPosition': array([-0.19167967,  1.82699459])}
episode index:1012
target Thresh 1.7621733745101007
current state at start:  [-1.33088938 -2.03670169]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.33088938, -2.03670169]), 'currentState': array([5.35324091, 4.74646475]), 'targetState': array([-0.08416573, -0.63784891]), 'effectorPosition': array([-0.18287358, -1.42642757])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3300059844235631
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.33088938, -2.03670169]), 'currentState': array([3.73255616, 4.41936852]), 'targetState': array([-0.08416573, -0.63784891]), 'effectorPosition': array([-1.12395873,  0.39878096])}
episode index:1013
target Thresh 1.762648552424773
current state at start:  [ 3.96633485 -2.3240512 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.96633485, -2.3240512 ]), 'currentState': array([3.7177034 , 4.45913411]), 'targetState': array([ 0.02374442, -0.02359321]), 'effectorPosition': array([-1.15586389,  0.4035666 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3296805347347824
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.96633485, -2.3240512 ]), 'currentState': array([4.71392734, 5.80889778]), 'targetState': array([ 0.02374442, -0.02359321]), 'effectorPosition': array([-0.45379728, -1.89031868])}
episode index:1014
target Thresh 1.7631227809333387
current state at start:  [-0.64629766  2.23411821]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.64629766,  2.23411821]), 'currentState': array([6.13688765, 1.76543952]), 'targetState': array([ 1.3250312 , -0.17877464]), 'effectorPosition': array([0.94099086, 0.85305524])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.32935572632617677
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.64629766,  2.23411821]), 'currentState': array([5.0244036 , 5.41674498]), 'targetState': array([ 1.3250312 , -0.17877464]), 'effectorPosition': array([-0.21947851, -1.80191998])}
episode index:1015
target Thresh 1.7635960619327125
current state at start:  [-3.59392071  1.86966697]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.59392071,  1.86966697]), 'currentState': array([3.1892646 , 2.18130491]), 'targetState': array([-1.2075805 , -0.33396654]), 'effectorPosition': array([-0.38718544, -0.83876036])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3290315573042022
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.59392071,  1.86966697]), 'currentState': array([1.51879638, 4.34461454]), 'targetState': array([-1.2075805 , -0.33396654]), 'effectorPosition': array([0.96515743, 0.59109387])}
episode index:1016
target Thresh 1.7640683973160187
current state at start:  [-1.21377863  1.59287596]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.21377863,  1.59287596]), 'currentState': array([4.56940668, 1.09287596]), 'targetState': array([1.38840334, 0.16780322]), 'effectorPosition': array([ 0.67085804, -1.57156501])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3287080257827624
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.21377863,  1.59287596]), 'currentState': array([5.39778886, 4.71809369]), 'targetState': array([1.38840334, 0.16780322]), 'effectorPosition': array([-0.13755979, -1.41155469])}
episode index:1017
target Thresh 1.7645397889725993
current state at start:  [-3.74462906  1.85757395]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.74462906,  1.85757395]), 'currentState': array([2.97845194, 1.53730407]), 'targetState': array([-1.00047727,  0.34502733]), 'effectorPosition': array([-1.18209035, -0.81831193])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3283851298831723
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.74462906,  1.85757395]), 'currentState': array([0.05407619, 5.95504099]), 'targetState': array([-1.00047727,  0.34502733]), 'effectorPosition': array([ 1.96121607, -0.21660013])}
episode index:1018
target Thresh 1.7650102387880222
current state at start:  [ 3.110272   -1.99538297]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.110272  , -1.99538297]), 'currentState': array([3.610272  , 4.47073589]), 'targetState': array([0.30909354, 0.65483934]), 'effectorPosition': array([-1.1172467,  0.5226316])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3280628677341211
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.110272  , -1.99538297]), 'currentState': array([6.17355285, 5.31471478]), 'targetState': array([0.30909354, 0.65483934]), 'effectorPosition': array([ 1.46699699, -0.99047507])}
episode index:1019
target Thresh 1.7654797486440867
current state at start:  [-3.71314926  2.54819785]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.71314926,  2.54819785]), 'currentState': array([3.07003604, 2.04819785]), 'targetState': array([-0.12708012,  0.34672508]), 'effectorPosition': array([-0.60264573, -0.8472736 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3277412374716367
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.71314926,  2.54819785]), 'currentState': array([0.38437855, 5.46983763]), 'targetState': array([-0.12708012,  0.34672508]), 'effectorPosition': array([ 1.83642665, -0.04095045])}
episode index:1020
target Thresh 1.7659483204188333
current state at start:  [ 0.27148056 -2.03860017]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.27148056, -2.03860017]), 'currentState': array([0.77148056, 4.68846191]), 'targetState': array([ 0.92324136, -0.45451986]), 'effectorPosition': array([ 1.39672585, -0.03615692])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.32839966916853025
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.27148056, -2.03860017]), 'currentState': array([0.77148056, 4.68846191]), 'targetState': array([ 0.92324136, -0.45451986]), 'effectorPosition': array([ 1.39672585, -0.03615692])}
episode index:1021
target Thresh 1.7664159559865493
current state at start:  [-0.3314156  1.8398855]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.3314156,  1.8398855]), 'currentState': array([0.1685844, 1.3398855]), 'targetState': array([0.62198326, 0.4465537 ]), 'effectorPosition': array([1.04810936, 1.16584532])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.32807833876816966
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.3314156,  1.8398855]), 'currentState': array([5.84252382, 4.95825847]), 'targetState': array([0.62198326, 0.4465537 ]), 'effectorPosition': array([ 0.71090725, -1.40762581])}
episode index:1022
target Thresh 1.766882657217778
current state at start:  [-0.61059051  2.74723078]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.61059051,  2.74723078]), 'currentState': array([6.15415398, 3.23307423]), 'targetState': array([1.03078961, 0.81257611]), 'effectorPosition': array([-0.00760809, -0.09113265])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3277576365797355
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.61059051,  2.74723078]), 'currentState': array([5.68978802, 4.298782  ]), 'targetState': array([1.03078961, 0.81257611]), 'effectorPosition': array([-0.01618896, -1.09357597])}
episode index:1023
target Thresh 1.7673484259793246
current state at start:  [1.12651029 2.26163345]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.12651029, 2.26163345]), 'currentState': array([0.62651029, 1.76163345]), 'targetState': array([-0.71472154,  0.20565744]), 'effectorPosition': array([0.08074491, 1.27047963])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3274375607627631
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.12651029, 2.26163345]), 'currentState': array([1.87062047, 4.71811169]), 'targetState': array([-0.71472154,  0.20565744]), 'effectorPosition': array([0.65833039, 1.25620318])}
episode index:1024
target Thresh 1.767813264134265
current state at start:  [ 2.77864292 -2.52423266]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.77864292, -2.52423266]), 'currentState': array([2.27864292, 4.24880772]), 'targetState': array([-0.1788372 ,  0.29932236]), 'effectorPosition': array([0.32011607, 1.00160731])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.32711810948397013
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.77864292, -2.52423266]), 'currentState': array([1.75907196, 4.5648352 ]), 'targetState': array([-0.1788372 ,  0.29932236]), 'effectorPosition': array([0.8120057 , 1.02303903])}
episode index:1025
target Thresh 1.7682771735419525
current state at start:  [ 0.90088484 -2.79996422]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.90088484, -2.79996422]), 'currentState': array([1.40088484, 3.05057427]), 'targetState': array([ 0.35577238, -0.88152611]), 'effectorPosition': array([-0.08888394,  0.01944923])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.32679928091722166
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.90088484, -2.79996422]), 'currentState': array([5.84683453, 2.68519004]), 'targetState': array([ 0.35577238, -0.88152611]), 'effectorPosition': array([0.27902992, 0.35616682])}
episode index:1026
target Thresh 1.768740156058025
current state at start:  [-1.27985558  1.76906364]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.27985558,  1.76906364]), 'currentState': array([4.51105121, 1.26906364]), 'targetState': array([1.04605323, 0.30916315]), 'effectorPosition': array([ 0.67612611, -1.46191778])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.326481073243495
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.27985558,  1.76906364]), 'currentState': array([5.62490744, 4.44397515]), 'targetState': array([1.04605323, 0.30916315]), 'effectorPosition': array([-0.00859081, -1.21223818])}
episode index:1027
target Thresh 1.7692022135344132
current state at start:  [0.34443169 2.23933877]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.34443169, 2.23933877]), 'currentState': array([0.84443169, 1.74022085]), 'targetState': array([0.09307466, 0.04222817]), 'effectorPosition': array([-0.18472026,  1.27618499])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3261634846508457
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.34443169, 2.23933877]), 'currentState': array([1.39174464, 5.02623511]), 'targetState': array([0.09307466, 0.04222817]), 'effectorPosition': array([1.16902548, 1.11839965])}
episode index:1028
target Thresh 1.7696633478193482
current state at start:  [ 2.91515949 -2.03609856]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.91515949, -2.03609856]), 'currentState': array([2.41515949, 4.58613481]), 'targetState': array([-1.09804992,  0.42512243]), 'effectorPosition': array([0.00550302, 1.32216931])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3258465133343726
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.91515949, -2.03609856]), 'currentState': array([0.57811331, 5.6009823 ]), 'targetState': array([-1.09804992,  0.42512243]), 'effectorPosition': array([1.83208267, 0.44254298])}
episode index:1029
target Thresh 1.770123560757367
current state at start:  [-0.09426485 -2.14237528]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.09426485, -2.14237528]), 'currentState': array([0.40573515, 3.64081003]), 'targetState': array([ 1.08264454, -0.87538944]), 'effectorPosition': array([ 0.30108957, -0.3917015 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3255301574961839
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.09426485, -2.14237528]), 'currentState': array([3.61965585, 3.46844376]), 'targetState': array([ 1.08264454, -0.87538944]), 'effectorPosition': array([-0.19471463,  0.26071087])}
episode index:1030
target Thresh 1.7705828541893227
current state at start:  [0.19534292 2.63852107]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.19534292, 2.63852107]), 'currentState': array([5.97852823, 3.13852107]), 'targetState': array([0.3973521 , 1.20129202]), 'effectorPosition': array([0.00092587, 0.00292872])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.32521441534536316
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.19534292, 2.63852107]), 'currentState': array([5.66137822, 3.86882431]), 'targetState': array([0.3973521 , 1.20129202]), 'effectorPosition': array([-0.18162083, -0.68773435])}
episode index:1031
target Thresh 1.771041229952389
current state at start:  [ 3.06079965 -2.7080647 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.06079965, -2.7080647 ]), 'currentState': array([3.52584618, 3.07512061]), 'targetState': array([0.05802636, 1.09633805]), 'effectorPosition': array([ 0.02285243, -0.06240731])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3248992850979355
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.06079965, -2.7080647 ]), 'currentState': array([5.53190112, 4.07906949]), 'targetState': array([0.05802636, 1.09633805]), 'effectorPosition': array([-0.25190326, -0.86769652])}
episode index:1032
target Thresh 1.77149868988007
current state at start:  [-1.76761309 -1.93393652]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.76761309, -1.93393652]), 'currentState': array([4.17431378, 4.797809  ]), 'targetState': array([-0.16669115, -0.59503152]), 'effectorPosition': array([-1.41177314, -0.42134185])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.32458476497683386
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.76761309, -1.93393652]), 'currentState': array([2.81094373, 3.44175776]), 'targetState': array([-0.16669115, -0.59503152]), 'effectorPosition': array([0.05370354, 0.29417777])}
episode index:1033
target Thresh 1.7719552358022057
current state at start:  [ 0.67898961 -1.96810446]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.67898961, -1.96810446]), 'currentState': array([0.75510445, 4.8026981 ]), 'targetState': array([0.19718069, 0.17841344]), 'effectorPosition': array([1.47644551, 0.02194285])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.32427085321186594
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.67898961, -1.96810446]), 'currentState': array([6.09101161, 5.51705722]), 'targetState': array([0.19718069, 0.17841344]), 'effectorPosition': array([ 1.55650172, -1.00920945])}
episode index:1034
target Thresh 1.7724108695449807
current state at start:  [ 1.47122931 -2.67883793]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.47122931, -2.67883793]), 'currentState': array([1.96867942, 4.06177053]), 'targetState': array([ 0.17577474, -0.41277392]), 'effectorPosition': array([0.58076439, 0.67182994])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3239575480396806
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.47122931, -2.67883793]), 'currentState': array([2.83351483, 4.07196694]), 'targetState': array([ 0.17577474, -0.41277392]), 'effectorPosition': array([-0.1403762 ,  0.88613019])}
episode index:1035
target Thresh 1.7728655929309303
current state at start:  [-0.36069896 -2.08631733]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.36069896, -2.08631733]), 'currentState': array([5.65147559, 4.32624065]), 'targetState': array([ 0.85367959, -0.37691061]), 'effectorPosition': array([-0.04396598, -1.11571532])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.323644847703735
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.36069896, -2.08631733]), 'currentState': array([5.01720078, 5.2055706 ]), 'targetState': array([ 0.85367959, -0.37691061]), 'effectorPosition': array([-0.39803108, -1.6698601 ])}
episode index:1036
target Thresh 1.7733194077789487
current state at start:  [-2.46653671  2.21711441]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.46653671,  2.21711441]), 'currentState': array([3.93553801, 1.76866281]), 'targetState': array([-0.45217228, -0.88023802]), 'effectorPosition': array([ 0.1359815 , -1.26029888])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.32333275045426174
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.46653671,  2.21711441]), 'currentState': array([2.29968328, 3.38058916]), 'targetState': array([-0.45217228, -0.88023802]), 'effectorPosition': array([0.15764758, 0.17887203])}
episode index:1037
target Thresh 1.7737723159042962
current state at start:  [ 3.75722748 -1.90162571]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.75722748, -1.90162571]), 'currentState': array([4.23519719, 4.8815596 ]), 'targetState': array([-0.67172636,  0.88584827]), 'effectorPosition': array([-1.41222186, -0.58511465])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.32302125454823644
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.75722748, -1.90162571]), 'currentState': array([5.84554833, 5.6562314 ]), 'targetState': array([-0.67172636,  0.88584827]), 'effectorPosition': array([ 1.39061771, -1.29839096])}
episode index:1038
target Thresh 1.7742243191186056
current state at start:  [-0.69088548  2.36545115]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.69088548,  2.36545115]), 'currentState': array([6.09229983, 1.86545115]), 'targetState': array([ 1.0635828 , -0.06190855]), 'effectorPosition': array([0.87825341, 0.80489243])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.32271035824934496
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.69088548,  2.36545115]), 'currentState': array([5.21328642, 4.59976709]), 'targetState': array([ 1.0635828 , -0.06190855]), 'effectorPosition': array([-0.44535038, -1.25574484])}
episode index:1039
target Thresh 1.7746754192298904
current state at start:  [ 3.92119148 -1.96455313]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.92119148, -1.96455313]), 'currentState': array([3.47353205, 4.62750727]), 'targetState': array([-0.73453719, -0.32351738]), 'effectorPosition': array([-1.18996416,  0.643759  ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.32240005982795134
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.92119148, -1.96455313]), 'currentState': array([2.46133111, 4.04322648]), 'targetState': array([-0.73453719, -0.32351738]), 'effectorPosition': array([0.19818882, 0.848565  ])}
episode index:1040
target Thresh 1.7751256180425516
current state at start:  [-1.83469601  2.60210415]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.83469601,  2.60210415]), 'currentState': array([4.09333502, 2.12414681]), 'targetState': array([0.55824098, 0.37688304]), 'effectorPosition': array([ 0.41757737, -0.88008398])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3220903575610657
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.83469601,  2.60210415]), 'currentState': array([6.11331198, 5.74818923]), 'targetState': array([0.55824098, 0.37688304]), 'effectorPosition': array([ 1.74730237, -0.81699186])}
episode index:1041
target Thresh 1.7755749173573852
current state at start:  [0.33662661 1.83890724]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.33662661, 1.83890724]), 'currentState': array([0.83662661, 1.36733327]), 'targetState': array([0.5790634 , 0.91719192]), 'effectorPosition': array([0.07827296, 1.54854695])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3217812497323123
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.33662661, 1.83890724]), 'currentState': array([5.63487251, 4.3803423 ]), 'targetState': array([0.5790634 , 0.91719192]), 'effectorPosition': array([-0.03359382, -1.16056635])}
episode index:1042
target Thresh 1.776023318971589
current state at start:  [-1.32174564 -1.97332942]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.32174564, -1.97332942]), 'currentState': array([5.37077853, 4.80985589]), 'targetState': array([-0.07869702, -0.84792286]), 'effectorPosition': array([-0.11584054, -1.47689075])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3214727346318978
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.32174564, -1.97332942]), 'currentState': array([2.68049494, 3.59868669]), 'targetState': array([-0.07869702, -0.84792286]), 'effectorPosition': array([0.10442735, 0.44092779])}
episode index:1043
target Thresh 1.7764708246787702
current state at start:  [-2.65913367  2.13514812]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.65913367,  2.13514812]), 'currentState': array([4.05077532, 1.63514812]), 'targetState': array([ 0.40030216, -0.5607308 ]), 'effectorPosition': array([ 0.21248776, -1.35138232])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3211648105565799
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.65913367,  2.13514812]), 'currentState': array([4.37573751, 0.91589396]), 'targetState': array([ 0.40030216, -0.5607308 ]), 'effectorPosition': array([ 0.21706177, -1.78074361])}
episode index:1044
target Thresh 1.776917436268952
current state at start:  [-3.88308444  2.16624935]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.88308444,  2.16624935]), 'currentState': array([2.90010086, 1.77019267]), 'targetState': array([-0.54846961,  0.32001871]), 'effectorPosition': array([-1.01306531, -0.75996272])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3208574758096358
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.88308444,  2.16624935]), 'currentState': array([2.0627814 , 4.58619102]), 'targetState': array([-0.54846961,  0.32001871]), 'effectorPosition': array([0.46146605, 1.23908134])}
episode index:1045
target Thresh 1.7773631555285814
current state at start:  [-1.5573064  2.4206148]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.5573064,  2.4206148]), 'currentState': array([4.22587891, 1.96870508]), 'targetState': array([0.36650326, 0.00716453]), 'effectorPosition': array([ 0.52853372, -0.97245538])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3205507287008312
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.5573064,  2.4206148]), 'currentState': array([5.49060251, 0.41433462]), 'targetState': array([0.36650326, 0.00716453]), 'effectorPosition': array([ 1.63132127, -1.08146183])}
episode index:1046
target Thresh 1.7778079842405359
current state at start:  [ 3.57565055 -1.64567692]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.57565055, -1.64567692]), 'currentState': array([4.07565055, 5.13750838]), 'targetState': array([-0.50494536,  0.62235255]), 'effectorPosition': array([-1.57226831, -0.59399621])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.32024456754638914
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.57565055, -1.64567692]), 'currentState': array([1.69439672, 5.01931876]), 'targetState': array([-0.50494536,  0.62235255]), 'effectorPosition': array([0.78545868, 1.40972385])}
episode index:1047
target Thresh 1.7782519241841312
current state at start:  [1.20776129 2.59502941]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.20776129, 2.59502941]), 'currentState': array([0.70776129, 3.09502941]), 'targetState': array([-1.28149483,  0.45700839]), 'effectorPosition': array([-0.02943788,  0.03607153])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.31993899066895937
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.20776129, 2.59502941]), 'currentState': array([1.95386669, 5.18224354]), 'targetState': array([-1.28149483,  0.45700839]), 'effectorPosition': array([0.28401284, 1.68072899])}
episode index:1048
target Thresh 1.7786949771351277
current state at start:  [-1.85783093 -2.05782601]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.85783093, -2.05782601]), 'currentState': array([4.8053443 , 4.63631476]), 'targetState': array([-1.16099621, -0.52129881]), 'effectorPosition': array([-0.90703601, -1.01256306])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.3205872852441081
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.85783093, -2.05782601]), 'currentState': array([4.8053443 , 4.63631476]), 'targetState': array([-1.16099621, -0.52129881]), 'effectorPosition': array([-0.90703601, -1.01256306])}
episode index:1049
target Thresh 1.7791371448657376
current state at start:  [ 3.57487615 -2.31598372]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.57487615, -2.31598372]), 'currentState': array([3.16425838, 3.73768965]), 'targetState': array([-0.79778429, -0.2792182 ]), 'effectorPosition': array([-0.1851464 ,  0.55736393])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3202819640200661
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.57487615, -2.31598372]), 'currentState': array([2.20891624, 3.80049596]), 'targetState': array([-0.79778429, -0.2792182 ]), 'effectorPosition': array([0.36707125, 0.53285118])}
episode index:1050
target Thresh 1.7795784291446326
current state at start:  [-2.09687595 -1.90535715]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.09687595, -1.90535715]), 'currentState': array([3.75338061, 4.87782816]), 'targetState': array([-0.59832775, -0.33459101]), 'effectorPosition': array([-1.5199279 ,  0.13852886])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3199772238069167
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.09687595, -1.90535715]), 'currentState': array([2.38533677, 3.98178453]), 'targetState': array([-0.59832775, -0.33459101]), 'effectorPosition': array([0.26906911, 0.77004022])}
episode index:1051
target Thresh 1.78001883173695
current state at start:  [ 2.35272017 -2.43090549]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.35272017, -2.43090549]), 'currentState': array([1.8691822 , 4.30779136]), 'targetState': array([-0.54962387,  1.05193355]), 'effectorPosition': array([0.70038705, 0.84980008])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3196730629477846
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.35272017, -2.43090549]), 'currentState': array([5.48644702, 6.17720801]), 'targetState': array([-0.54962387,  1.05193355]), 'effectorPosition': array([ 1.31852329, -1.50009188])}
episode index:1052
target Thresh 1.7804583544043013
current state at start:  [-2.61886543  1.76056149]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.61886543,  1.76056149]), 'currentState': array([4.16431987, 1.26056149]), 'targetState': array([ 0.31552618, -0.5920014 ]), 'effectorPosition': array([ 0.13268175, -1.61026709])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3193694797920887
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.61886543,  1.76056149]), 'currentState': array([3.75901821, 4.1882052 ]), 'targetState': array([ 0.31552618, -0.5920014 ]), 'effectorPosition': array([-0.90847833,  0.41671818])}
episode index:1053
target Thresh 1.7808969989047774
current state at start:  [ 1.40958178 -2.01262768]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.40958178, -2.01262768]), 'currentState': array([1.90958178, 4.76808975]), 'targetState': array([1.26047425, 0.55513556]), 'effectorPosition': array([0.59085232, 1.32749293])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.31906647269551175
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.40958178, -2.01262768]), 'currentState': array([5.35710143, 5.45444646]), 'targetState': array([1.26047425, 0.55513556]), 'effectorPosition': array([ 0.41797917, -1.78238748])}
episode index:1054
target Thresh 1.781334766992957
current state at start:  [-0.08070369 -1.69672358]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.08070369, -1.69672358]), 'currentState': array([0.05616726, 5.05422926]), 'targetState': array([ 0.3338415 , -0.23939763]), 'effectorPosition': array([ 1.38600543, -0.86569733])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.318764040019971
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.08070369, -1.69672358]), 'currentState': array([3.28448382, 3.95746852]), 'targetState': array([ 0.3338415 , -0.23939763]), 'effectorPosition': array([-0.41527883,  0.67607841])}
episode index:1055
target Thresh 1.781771660419913
current state at start:  [1.82006772 1.76550439]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.82006772, 1.76550439]), 'currentState': array([1.32181616, 1.30141645]), 'targetState': array([-1.03951926, -0.23610774]), 'effectorPosition': array([-0.62221718,  1.46462051])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.31846218013358846
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.82006772, 1.76550439]), 'currentState': array([2.58599912, 3.89655411]), 'targetState': array([-1.03951926, -0.23610774]), 'effectorPosition': array([0.13060443, 0.72549747])}
episode index:1056
target Thresh 1.7822076809332197
current state at start:  [0.64893254 2.23261015]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.64893254, 2.23261015]), 'currentState': array([1.14893254, 1.7627479 ]), 'targetState': array([0.13929273, 0.2386646 ]), 'effectorPosition': array([-0.56422486,  1.14021943])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3181608914106617
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.64893254, 2.23261015]), 'currentState': array([5.35453737, 0.13775445]), 'targetState': array([0.13929273, 0.2386646 ]), 'effectorPosition': array([ 1.30212762, -1.51179277])}
episode index:1057
target Thresh 1.7826428302769597
current state at start:  [-1.60129625  1.68309688]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.60129625,  1.68309688]), 'currentState': array([4.20527023, 1.18309688]), 'targetState': array([ 0.2637938 , -0.60957107]), 'effectorPosition': array([ 0.14000002, -1.65424279])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3178601722316346
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.60129625,  1.68309688]), 'currentState': array([3.52268444, 4.06636647]), 'targetState': array([ 0.2637938 , -0.60957107]), 'effectorPosition': array([-0.66641671,  0.59317649])}
episode index:1058
target Thresh 1.783077110191731
current state at start:  [-1.81180966  2.12472503]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.81180966,  2.12472503]), 'currentState': array([3.97137564, 1.62472503]), 'targetState': array([ 0.43788627, -0.96409696]), 'effectorPosition': array([ 0.09806259, -1.37207091])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.3185043080463356
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.81180966,  2.12472503]), 'currentState': array([3.97137564, 1.62472503]), 'targetState': array([ 0.43788627, -0.96409696]), 'effectorPosition': array([ 0.09806259, -1.37207091])}
episode index:1059
target Thresh 1.783510522414654
current state at start:  [-1.5856877  -2.18332241]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.5856877 , -2.18332241]), 'currentState': array([5.18698889, 4.58590424]), 'targetState': array([-0.03931364,  0.03016987]), 'effectorPosition': array([-0.48303474, -1.23060226])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.31820383228402777
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.5856877 , -2.18332241]), 'currentState': array([2.26331123, 5.17999977]), 'targetState': array([-0.03931364,  0.03016987]), 'effectorPosition': array([-0.23925048,  1.68649604])}
episode index:1060
target Thresh 1.7839430686793778
current state at start:  [-1.02261583  2.22878749]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.02261583,  2.22878749]), 'currentState': array([4.76056948, 1.73208124]), 'targetState': array([0.34616659, 0.36261889]), 'effectorPosition': array([ 1.02630408, -0.79090251])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.31790392292277986
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.02261583,  2.22878749]), 'currentState': array([5.30233186, 0.24419966]), 'targetState': array([0.34616659, 0.36261889]), 'effectorPosition': array([ 1.29703429, -1.50278552])}
episode index:1061
target Thresh 1.7843747507160883
current state at start:  [-1.41697465  1.88314291]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.41697465,  1.88314291]), 'currentState': array([4.38403895, 1.441949  ]), 'targetState': array([ 1.08359203, -0.42749031]), 'effectorPosition': array([ 0.57481155, -1.38801077])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3176045783625889
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.41697465,  1.88314291]), 'currentState': array([4.59130446, 0.64193502]), 'targetState': array([ 1.08359203, -0.42749031]), 'effectorPosition': array([ 0.37682919, -1.86007449])}
episode index:1062
target Thresh 1.7848055702515144
current state at start:  [-0.11743313 -1.84661301]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.11743313, -1.84661301]), 'currentState': array([6.15535092, 4.86069118]), 'targetState': array([ 0.19782776, -0.16006205]), 'effectorPosition': array([ 1.01230669, -1.12727704])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.31730579700947265
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.11743313, -1.84661301]), 'currentState': array([5.7592286 , 6.08172525]), 'targetState': array([ 0.19782776, -0.16006205]), 'effectorPosition': array([ 1.61406936, -1.16375729])}
episode index:1063
target Thresh 1.7852355290089343
current state at start:  [ 1.39418343 -1.98978967]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.39418343, -1.98978967]), 'currentState': array([1.83612958, 4.79339564]), 'targetState': array([1.05505009, 0.71772138]), 'effectorPosition': array([0.67839058, 1.3044625 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.31700757727544115
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.39418343, -1.98978967]), 'currentState': array([6.13005807, 5.89464438]), 'targetState': array([1.05505009, 0.71772138]), 'effectorPosition': array([ 1.84514874, -0.66809559])}
episode index:1064
target Thresh 1.7856646287081839
current state at start:  [ 0.16098378 -1.81061851]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.16098378, -1.81061851]), 'currentState': array([0.63911278, 4.97256679]), 'targetState': array([ 0.53548706, -0.97648467]), 'effectorPosition': array([ 1.58551102, -0.02568193])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.31670991757846895
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.16098378, -1.81061851]), 'currentState': array([3.62848547, 3.65863827]), 'targetState': array([ 0.53548706, -0.97648467]), 'effectorPosition': array([-0.34680687,  0.37571035])}
episode index:1065
target Thresh 1.7860928710656627
current state at start:  [-1.647809    2.10521698]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.647809  ,  2.10521698]), 'currentState': array([4.20848066, 1.60521698]), 'targetState': array([ 0.1039831 , -1.07071275]), 'effectorPosition': array([ 0.40894846, -1.32813156])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.3173509026464066
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.647809  ,  2.10521698]), 'currentState': array([4.20848066, 1.60521698]), 'targetState': array([ 0.1039831 , -1.07071275]), 'effectorPosition': array([ 0.40894846, -1.32813156])}
episode index:1066
target Thresh 1.7865202577943404
current state at start:  [-3.26946114  2.63197314]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.26946114,  2.63197314]), 'currentState': array([3.51372416, 2.15795761]), 'targetState': array([-0.02105489, -0.21400622]), 'effectorPosition': array([-0.11276868, -0.93770106])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.31705347912002757
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.26946114,  2.63197314]), 'currentState': array([3.02193905, 4.02810645]), 'targetState': array([-0.02105489, -0.21400622]), 'effectorPosition': array([-0.27275719,  0.81324601])}
episode index:1067
target Thresh 1.7869467906037646
current state at start:  [ 2.72727508 -1.78122626]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.72727508, -1.78122626]), 'currentState': array([3.22727508, 5.00195904]), 'targetState': array([-0.00380407,  1.02529679]), 'effectorPosition': array([-1.36283897,  0.84483748])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.31675661256654436
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.72727508, -1.78122626]), 'currentState': array([5.0399526 , 6.27124264]), 'targetState': array([-0.00380407,  1.02529679]), 'effectorPosition': array([ 0.63214396, -1.89743284])}
episode index:1068
target Thresh 1.7873724712000674
current state at start:  [1.42019702 2.10195483]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.42019702, 2.10195483]), 'currentState': array([0.92019702, 1.95945723]), 'targetState': array([-0.40748531,  1.0552051 ]), 'effectorPosition': array([-0.36022644,  1.05467428])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.31739575511793205
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.42019702, 2.10195483]), 'currentState': array([0.92019702, 1.95945723]), 'targetState': array([-0.40748531,  1.0552051 ]), 'effectorPosition': array([-0.36022644,  1.05467428])}
episode index:1069
target Thresh 1.7877973012859714
current state at start:  [-0.90522968 -2.19908068]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.90522968, -2.19908068]), 'currentState': array([5.6126369 , 4.55861706]), 'targetState': array([ 0.1624931 , -0.66827665]), 'effectorPosition': array([ 0.04939458, -1.3004718 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3170991235710928
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.90522968, -2.19908068]), 'currentState': array([3.3568969 , 3.95855465]), 'targetState': array([ 0.1624931 , -0.66827665]), 'effectorPosition': array([-0.46403676,  0.64481883])}
episode index:1070
target Thresh 1.7882212825607975
current state at start:  [-3.33796063  2.0354315 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.33796063,  2.0354315 ]), 'currentState': array([3.42093006, 1.70582949]), 'targetState': array([-1.13276799, -0.41330966]), 'effectorPosition': array([-0.55862449, -1.19108872])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.31680304595804787
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.33796063,  2.0354315 ]), 'currentState': array([2.80194563, 4.16737177]), 'targetState': array([-1.13276799, -0.41330966]), 'effectorPosition': array([-0.16917001,  0.96670362])}
episode index:1071
target Thresh 1.7886444167204714
current state at start:  [-0.88186021 -2.23486258]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.88186021, -2.23486258]), 'currentState': array([5.9013251 , 4.54667526]), 'targetState': array([-0.47807415, -0.51747758]), 'effectorPosition': array([ 0.40735563, -1.22643742])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.31650752072860944
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.88186021, -2.23486258]), 'currentState': array([3.45054911, 3.83922679]), 'targetState': array([-0.47807415, -0.51747758]), 'effectorPosition': array([-0.41790658,  0.54094893])}
episode index:1072
target Thresh 1.7890667054575307
current state at start:  [ 2.49796818 -2.86144744]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.49796818, -2.86144744]), 'currentState': array([2.99796818, 3.78836649]), 'targetState': array([ 0.08470828, -0.5008794 ]), 'effectorPosition': array([-0.11363539,  0.62531818])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.31621254633836837
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.49796818, -2.86144744]), 'currentState': array([3.70133928, 3.94287809]), 'targetState': array([ 0.08470828, -0.5008794 ]), 'effectorPosition': array([-0.63916033,  0.44710852])}
episode index:1073
target Thresh 1.7894881504611302
current state at start:  [ 1.87690165 -2.25093835]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.87690165, -2.25093835]), 'currentState': array([2.37690165, 4.47506178]), 'targetState': array([0.75244217, 1.02766269]), 'effectorPosition': array([0.1209634 , 1.23091701])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3159181212486678
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.87690165, -2.25093835]), 'currentState': array([5.4755264 , 5.49238155]), 'targetState': array([0.75244217, 1.02766269]), 'effectorPosition': array([ 0.66352936, -1.72228832])}
episode index:1074
target Thresh 1.789908753417051
current state at start:  [ 0.60314196 -2.44155023]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.60314196, -2.44155023]), 'currentState': array([0.10314196, 4.2418308 ]), 'targetState': array([0.18382057, 0.2554771 ]), 'effectorPosition': array([ 0.63548028, -0.83029938])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.315624243926576
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.60314196, -2.44155023]), 'currentState': array([5.49263713, 0.1385947 ]), 'targetState': array([0.18382057, 0.2554771 ]), 'effectorPosition': array([ 1.49835588, -1.31747937])}
episode index:1075
target Thresh 1.7903285160077054
current state at start:  [ 2.14316657 -2.67586043]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.14316657, -2.67586043]), 'currentState': array([1.69112047, 4.10732488]), 'targetState': array([-0.36178272,  1.18251232]), 'effectorPosition': array([0.76476214, 0.52679149])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.31533091284485987
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.14316657, -2.67586043]), 'currentState': array([5.15784843, 0.53491959]), 'targetState': array([-0.36178272,  1.18251232]), 'effectorPosition': array([ 1.26158098, -1.45912051])}
episode index:1076
target Thresh 1.7907474399121444
current state at start:  [-3.62632     1.97733876]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.62632   ,  1.97733876]), 'currentState': array([3.15686531, 1.48235863]), 'targetState': array([-0.76516016, -0.28425864]), 'effectorPosition': array([-1.07298315, -1.0125967 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.31503812648195845
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.62632   ,  1.97733876]), 'currentState': array([2.96124231, 4.02051778]), 'targetState': array([-0.76516016, -0.28425864]), 'effectorPosition': array([-0.21802135,  0.82250122])}
episode index:1077
target Thresh 1.7911655268060638
current state at start:  [-2.85385844  1.7747087 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.85385844,  1.7747087 ]), 'currentState': array([3.92244539, 1.35795416]), 'targetState': array([-0.6406708 , -0.44230293]), 'effectorPosition': array([-0.17235749, -1.54685826])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.31474588332195663
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.85385844,  1.7747087 ]), 'currentState': array([2.68462169, 3.91917058]), 'targetState': array([-0.6406708 , -0.44230293]), 'effectorPosition': array([0.05165119, 0.75637456])}
episode index:1078
target Thresh 1.7915827783618121
current state at start:  [1.08032014 2.15367937]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.08032014, 2.15367937]), 'currentState': array([0.58032014, 1.65367937]), 'targetState': array([-0.52702251,  0.4056938 ]), 'effectorPosition': array([0.22064296, 1.33631595])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3144541818545591
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.08032014, 2.15367937]), 'currentState': array([2.6310203 , 5.13350207]), 'targetState': array([-0.52702251,  0.4056938 ]), 'effectorPosition': array([-0.78312497,  1.48467787])}
episode index:1079
target Thresh 1.7919991962483959
current state at start:  [ 1.65341552 -1.83385138]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.65341552, -1.83385138]), 'currentState': array([2.15341552, 4.92639037]), 'targetState': array([ 1.00317504, -0.00119581]), 'effectorPosition': array([0.14891407, 1.55002194])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3141630205750641
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.65341552, -1.83385138]), 'currentState': array([5.46794219, 0.24839398]), 'targetState': array([ 1.00317504, -0.00119581]), 'effectorPosition': array([ 1.52928855, -1.26486899])}
episode index:1080
target Thresh 1.7924147821314875
current state at start:  [ 1.32032523 -2.09241906]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.32032523, -2.09241906]), 'currentState': array([1.76896861, 4.69076625]), 'targetState': array([ 0.11134406, -0.11406499]), 'effectorPosition': array([0.78757785, 1.15606187])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.31387239798433786
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.32032523, -2.09241906]), 'currentState': array([3.97473873, 4.08071775]), 'targetState': array([ 0.11134406, -0.11406499]), 'effectorPosition': array([-0.8726654 ,  0.23972158])}
episode index:1081
target Thresh 1.7928295376734307
current state at start:  [ 0.95295824 -2.62303044]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.95295824, -2.62303044]), 'currentState': array([0.51065923, 4.09280293]), 'targetState': array([0.1572794, 0.2814189]), 'effectorPosition': array([ 0.76371096, -0.50532086])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.31358231258878855
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.95295824, -2.62303044]), 'currentState': array([3.87902843, 4.61126858]), 'targetState': array([0.1572794, 0.2814189]), 'effectorPosition': array([-1.33443113,  0.13189865])}
episode index:1082
target Thresh 1.7932434645332485
current state at start:  [-1.09072578  2.15333561]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.09072578,  2.15333561]), 'currentState': array([5.69245953, 1.6975543 ]), 'targetState': array([ 0.88779185, -0.56135635]), 'effectorPosition': array([1.27803663, 0.33732   ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3132927629003409
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.09072578,  2.15333561]), 'currentState': array([3.41428825, 4.6209099 ]), 'targetState': array([ 0.88779185, -0.56135635]), 'effectorPosition': array([-1.14327469,  0.71429677])}
episode index:1083
target Thresh 1.7936565643666484
current state at start:  [ 1.21361483 -2.49946556]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.21361483, -2.49946556]), 'currentState': array([1.6682145 , 3.28371975]), 'targetState': array([ 0.79092275, -0.68746191]), 'effectorPosition': array([0.13999675, 0.02381264])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.31300374743641074
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.21361483, -2.49946556]), 'currentState': array([4.54885331, 6.15628407]), 'targetState': array([ 0.79092275, -0.68746191]), 'effectorPosition': array([-0.44917857, -1.94477667])}
episode index:1084
target Thresh 1.794068838826031
current state at start:  [ 1.31980407 -2.53469773]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.31980407, -2.53469773]), 'currentState': array([0.85265187, 4.18564363]), 'targetState': array([0.32763824, 0.44967112]), 'effectorPosition': array([ 0.97815625, -0.19433293])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3127152647198795
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.31980407, -2.53469773]), 'currentState': array([5.28438483, 5.82507353]), 'targetState': array([0.32763824, 0.44967112]), 'effectorPosition': array([ 0.65494934, -1.83434449])}
episode index:1085
target Thresh 1.7944802895604943
current state at start:  [-0.32354677 -2.62416543]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.32354677, -2.62416543]), 'currentState': array([0.11972233, 3.15901988]), 'targetState': array([-0.41254589, -1.12696749]), 'effectorPosition': array([ 0.00223211, -0.01728347])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.31242731327906925
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.32354677, -2.62416543]), 'currentState': array([3.51851247, 3.50451062]), 'targetState': array([-0.41254589, -1.12696749]), 'effectorPosition': array([-0.1912248 ,  0.30610985])}
episode index:1086
target Thresh 1.794890918215842
current state at start:  [-1.4628071  -2.55516944]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.4628071 , -2.55516944]), 'currentState': array([5.3203782 , 4.22139501]), 'targetState': array([0.06415663, 0.286193  ]), 'effectorPosition': array([-0.42194568, -0.9375268 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.31213989164771777
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.4628071 , -2.55516944]), 'currentState': array([5.40857807, 6.23477728]), 'targetState': array([0.06415663, 0.286193  ]), 'effectorPosition': array([ 1.24471673, -1.56471639])}
episode index:1087
target Thresh 1.7953007264345886
current state at start:  [-2.59882958  2.21563815]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.59882958,  2.21563815]), 'currentState': array([4.18435573, 1.7501324 ]), 'targetState': array([-0.15832621, -0.24152332]), 'effectorPosition': array([ 0.43598321, -1.20547334])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.31185299836495334
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.59882958,  2.21563815]), 'currentState': array([2.49701607, 4.29659194]), 'targetState': array([-0.15832621, -0.24152332]), 'effectorPosition': array([0.07318382, 1.08940615])}
episode index:1088
target Thresh 1.7957097158559683
current state at start:  [-0.68315306  2.0088801 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.68315306,  2.0088801 ]), 'currentState': array([5.10003224, 1.5088801 ]), 'targetState': array([0.75475596, 1.03296459]), 'effectorPosition': array([ 1.32542592, -0.60580482])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3115666319752702
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.68315306,  2.0088801 ]), 'currentState': array([5.88356981, 4.476967  ]), 'targetState': array([0.75475596, 1.03296459]), 'effectorPosition': array([ 0.32800297, -1.19411363])}
episode index:1089
target Thresh 1.796117888115939
current state at start:  [ 0.43882117 -1.97730256]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.43882117, -1.97730256]), 'currentState': array([6.25047553, 4.80588275]), 'targetState': array([0.45575938, 0.15012782]), 'effectorPosition': array([ 1.06021165, -1.03085717])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.31128079102850387
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.43882117, -1.97730256]), 'currentState': array([4.62506607, 0.74985468]), 'targetState': array([0.45575938, 0.15012782]), 'effectorPosition': array([ 0.52790298, -1.78462721])}
episode index:1090
target Thresh 1.7965252448471902
current state at start:  [ 1.1339716  -1.93875309]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.1339716 , -1.93875309]), 'currentState': array([1.62176099, 4.84443221]), 'targetState': array([0.86590109, 0.48207882]), 'effectorPosition': array([0.93235813, 1.18068964])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3109954740798068
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.1339716 , -1.93875309]), 'currentState': array([5.23603784, 0.11960299]), 'targetState': array([0.86590109, 0.48207882]), 'effectorPosition': array([ 1.09984395, -1.66614989])}
episode index:1091
target Thresh 1.7969317876791497
current state at start:  [0.33174678 2.75146738]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.33174678, 2.75146738]), 'currentState': array([0.81869015, 2.25146738]), 'targetState': array([0.69439441, 0.07083903]), 'effectorPosition': array([-0.31427128,  0.80162598])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.31071067968962385
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.33174678, 2.75146738]), 'currentState': array([5.03714531, 0.96319942]), 'targetState': array([0.69439441, 0.07083903]), 'effectorPosition': array([ 1.27934442, -1.22681299])}
episode index:1092
target Thresh 1.797337518237989
current state at start:  [ 1.58742673 -1.6052722 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.58742673, -1.6052722 ]), 'currentState': array([2.03394048, 5.0950966 ]), 'targetState': array([0.33287418, 0.56038747]), 'effectorPosition': array([0.21633072, 1.64318842])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3104264064236681
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.58742673, -1.6052722 ]), 'currentState': array([4.84349294, 0.7907399 ]), 'targetState': array([0.33287418, 0.56038747]), 'effectorPosition': array([ 0.92744603, -1.59577033])}
episode index:1093
target Thresh 1.7977424381466311
current state at start:  [-1.17119459 -2.79082037]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.17119459, -2.79082037]), 'currentState': array([5.58058074, 3.44251755]), 'targetState': array([-0.93526547,  0.33224161]), 'effectorPosition': array([-0.15724392, -0.25524271])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.31014265285289694
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.17119459, -2.79082037]), 'currentState': array([5.53305259, 0.17830081]), 'targetState': array([-0.93526547,  0.33224161]), 'effectorPosition': array([ 1.57250941, -1.22290929])}
episode index:1094
target Thresh 1.7981465490247561
current state at start:  [0.53587428 2.83592045]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.53587428, 2.83592045]), 'currentState': array([0.03587428, 3.25859624]), 'targetState': array([-0.6954061 ,  0.39819812]), 'effectorPosition': array([ 0.01101967, -0.11641648])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3098594175534879
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.53587428, 2.83592045]), 'currentState': array([5.64743538, 0.40772252]), 'targetState': array([-0.6954061 ,  0.39819812]), 'effectorPosition': array([ 1.77874083, -0.81983754])}
episode index:1095
target Thresh 1.798549852488808
current state at start:  [ 3.7322439  -1.93210508]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.7322439 , -1.93210508]), 'currentState': array([4.2322439 , 4.85108022]), 'targetState': array([-0.46312831,  0.72108296]), 'effectorPosition': array([-1.40417669, -0.55207057])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.309576699106815
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.7322439 , -1.93210508]), 'currentState': array([5.28772179, 0.69253327]), 'targetState': array([-0.46312831,  0.72108296]), 'effectorPosition': array([ 1.4985805 , -1.13732956])}
episode index:1096
target Thresh 1.7989523501520015
current state at start:  [-1.78039216 -2.46856529]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.78039216, -2.46856529]), 'currentState': array([5.00279314, 4.31462001]), 'targetState': array([0.19759129, 0.56626335]), 'effectorPosition': array([-0.70790244, -0.85096957])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.309294496099425
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.78039216, -2.46856529]), 'currentState': array([5.00949277, 6.2628501 ]), 'targetState': array([0.19759129, 0.56626335]), 'effectorPosition': array([ 0.56600075, -1.91813181])}
episode index:1097
target Thresh 1.7993540436243272
current state at start:  [ 3.40191029 -2.06356597]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.40191029, -2.06356597]), 'currentState': array([3.86953487, 4.62374443]), 'targetState': array([-0.63141849,  0.66856843]), 'effectorPosition': array([-1.34317705,  0.13718018])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3090128071230139
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.40191029, -2.06356597]), 'currentState': array([5.60198855, 0.15725812]), 'targetState': array([-0.63141849,  0.66856843]), 'effectorPosition': array([ 1.64267507, -1.13001744])}
episode index:1098
target Thresh 1.79975493451256
current state at start:  [-0.18400518 -2.58578359]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.18400518, -2.58578359]), 'currentState': array([5.75236484, 4.07920448]), 'targetState': array([-0.10184238, -0.07298297]), 'effectorPosition': array([-0.05600308, -0.90190565])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3087316307744033
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.18400518, -2.58578359]), 'currentState': array([5.48979028, 6.17501521]), 'targetState': array([-0.10184238, -0.07298297]), 'effectorPosition': array([ 1.3218128, -1.4970376])}
episode index:1099
target Thresh 1.8001550244202638
current state at start:  [-0.77894822  2.2774568 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.77894822,  2.2774568 ]), 'currentState': array([6.00423708, 1.7774568 ]), 'targetState': array([0.31737014, 0.06068985]), 'effectorPosition': array([1.03357038, 0.7220437 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3084509656555175
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.77894822,  2.2774568 ]), 'currentState': array([5.2127754 , 0.62230746]), 'targetState': array([0.31737014, 0.06068985]), 'effectorPosition': array([ 1.38103547, -1.31065334])}
episode index:1100
target Thresh 1.800554314947799
current state at start:  [1.1601985  2.65254016]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.1601985 , 2.65254016]), 'currentState': array([1.62693004, 2.16191645]), 'targetState': array([0.26087224, 0.29158419]), 'effectorPosition': array([-0.85384697,  0.39542696])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.30817081037335986
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.1601985 , 2.65254016]), 'currentState': array([5.60198721, 0.0214634 ]), 'targetState': array([0.26087224, 0.29158419]), 'effectorPosition': array([ 1.56697366, -1.24263143])}
episode index:1101
target Thresh 1.800952807692328
current state at start:  [ 0.74095744 -2.50150158]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.74095744, -2.50150158]), 'currentState': array([0.24095744, 4.28168373]), 'targetState': array([0.01583695, 0.21959543]), 'effectorPosition': array([ 0.78249871, -0.74341931])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3078911635399902
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.74095744, -2.50150158]), 'currentState': array([5.10344339, 0.31510521]), 'targetState': array([0.01583695, 0.21959543]), 'effectorPosition': array([ 1.03008001, -1.68536724])}
episode index:1102
target Thresh 1.8013505042478224
current state at start:  [ 3.56963018 -2.39372751]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.56963018, -2.39372751]), 'currentState': array([3.08036202, 4.2239289 ]), 'targetState': array([-0.24775296,  0.00316541]), 'effectorPosition': array([-0.47570246,  0.91387852])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3076120237725015
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.56963018, -2.39372751]), 'currentState': array([2.8162442 , 5.12249015]), 'targetState': array([-0.24775296,  0.00316541]), 'effectorPosition': array([-1.03219069,  1.31604962])}
episode index:1103
target Thresh 1.8017474062050687
current state at start:  [-1.32747727 -1.95977215]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.32747727, -1.95977215]), 'currentState': array([5.45570803, 4.82341316]), 'targetState': array([-1.18877132, -0.64305426]), 'effectorPosition': array([ 0.02002126, -1.49036627])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.30733338969299745
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.32747727, -1.95977215]), 'currentState': array([5.90253348, 5.65533602]), 'targetState': array([-1.18877132, -0.64305426]), 'effectorPosition': array([ 1.46155208, -1.21755942])}
episode index:1104
target Thresh 1.8021435151516758
current state at start:  [ 0.10088431 -1.7590458 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.10088431, -1.7590458 ]), 'currentState': array([0.01115264, 4.89066012]), 'targetState': array([ 1.12507442, -0.37337027]), 'effectorPosition': array([ 1.18823083, -0.97096049])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3070552599285694
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.10088431, -1.7590458 ]), 'currentState': array([4.30650782, 6.05821074]), 'targetState': array([ 1.12507442, -0.37337027]), 'effectorPosition': array([-0.98466447, -1.72627792])}
episode index:1105
target Thresh 1.8025388326720795
current state at start:  [ 3.38775    -1.82578963]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.38775   , -1.82578963]), 'currentState': array([2.88775   , 4.11283968]), 'targetState': array([-0.47697005, -0.108246  ]), 'effectorPosition': array([-0.21443987,  0.90855636])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3067776331112741
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.38775   , -1.82578963]), 'currentState': array([2.92461253, 3.9479077 ]), 'targetState': array([-0.47697005, -0.108246  ]), 'effectorPosition': array([-0.1452415,  0.7710898])}
episode index:1106
target Thresh 1.8029333603475506
current state at start:  [-0.12534427 -2.43225498]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.12534427, -2.43225498]), 'currentState': array([5.94552465, 3.41446715]), 'targetState': array([ 0.83307351, -0.30367905]), 'effectorPosition': array([-0.05436989, -0.26653991])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.30650050787811123
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.12534427, -2.43225498]), 'currentState': array([5.17235175, 0.25884234]), 'targetState': array([ 0.83307351, -0.30367905]), 'effectorPosition': array([ 1.10240062, -1.64866211])}
episode index:1107
target Thresh 1.8033270997562005
current state at start:  [0.75118487 2.45110803]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.75118487, 2.45110803]), 'currentState': array([0.30910813, 2.77280634]), 'targetState': array([-1.11197353,  0.4885508 ]), 'effectorPosition': array([-0.04561452,  0.36385193])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.306223882871001
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.75118487, 2.45110803]), 'currentState': array([5.12393257, 0.89959736]), 'targetState': array([-1.11197353,  0.4885508 ]), 'effectorPosition': array([ 1.36650302, -1.17325194])}
episode index:1108
target Thresh 1.803720052472987
current state at start:  [1.88228563 1.89624114]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.88228563, 1.89624114]), 'currentState': array([2.17830816, 1.4554861 ]), 'targetState': array([-0.26121037, -0.11723927]), 'effectorPosition': array([-1.45212086,  0.34850357])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.30594775673676206
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.88228563, 1.89624114]), 'currentState': array([2.88030369, 4.06417264]), 'targetState': array([-0.26121037, -0.11723927]), 'effectorPosition': array([-0.17685778,  0.87246222])}
episode index:1109
target Thresh 1.8041122200697217
current state at start:  [1.27389573 2.21916047]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.27389573, 2.21916047]), 'currentState': array([0.79212566, 1.73048825]), 'targetState': array([-0.66666081,  0.19283651]), 'effectorPosition': array([-0.11213766,  1.29205148])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.30567212812708927
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.27389573, 2.21916047]), 'currentState': array([2.41963853, 5.31183422]), 'targetState': array([-0.66666081,  0.19283651]), 'effectorPosition': array([-0.62831311,  1.6533577 ])}
episode index:1110
target Thresh 1.8045036041150757
current state at start:  [-1.83387674 -2.18311321]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.83387674, -2.18311321]), 'currentState': array([3.94930857, 4.08382555]), 'targetState': array([-0.51943985, -0.88886401]), 'effectorPosition': array([-0.86934665,  0.26128465])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.305396995698532
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.83387674, -2.18311321]), 'currentState': array([3.57266342, 3.35378343]), 'targetState': array([-0.51943985, -0.88886401]), 'effectorPosition': array([-0.10837514,  0.18196448])}
episode index:1111
target Thresh 1.8048942061745852
current state at start:  [-1.507287   2.2808708]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.507287 ,  2.2808708]), 'currentState': array([5.27589831, 1.7808708 ]), 'targetState': array([ 0.46168192, -0.98397565]), 'effectorPosition': array([ 1.24956747, -0.14668218])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3051223581124722
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.507287 ,  2.2808708]), 'currentState': array([3.87814879, 3.76687493]), 'targetState': array([ 0.46168192, -0.98397565]), 'effectorPosition': array([-0.53334573,  0.30650688])}
episode index:1112
target Thresh 1.8052840278106594
current state at start:  [0.46851626 2.03172998]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.46851626, 2.03172998]), 'currentState': array([6.25170156, 1.70794289]), 'targetState': array([0.33370411, 1.05417829]), 'effectorPosition': array([0.89403812, 0.96294433])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3048482140351025
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.46851626, 2.03172998]), 'currentState': array([5.08233891, 0.39242412]), 'targetState': array([0.33370411, 1.05417829]), 'effectorPosition': array([ 1.05220905, -1.65554388])}
episode index:1113
target Thresh 1.8056730705825854
current state at start:  [0.93975685 1.60894341]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.93975685, 1.60894341]), 'currentState': array([0.45663209, 1.17443079]), 'targetState': array([-0.06375896,  1.25462524]), 'effectorPosition': array([0.83731251, 1.43911229])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3045745621374049
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.93975685, 1.60894341]), 'currentState': array([5.39717796, 0.25566882]), 'targetState': array([-0.06375896,  1.25462524]), 'effectorPosition': array([ 1.4403376, -1.3639708])}
episode index:1114
target Thresh 1.8060613360465345
current state at start:  [ 4.29050413 -2.47041682]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.29050413, -2.47041682]), 'currentState': array([4.01152236, 3.31276848]), 'targetState': array([-1.25424032, -0.06288503]), 'effectorPosition': array([-0.13961374,  0.09867974])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3043014010951292
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 4.29050413, -2.47041682]), 'currentState': array([5.49722394, 6.25872164]), 'targetState': array([-1.25424032, -0.06288503]), 'effectorPosition': array([ 1.39589895, -1.43208508])}
episode index:1115
target Thresh 1.806448825755569
current state at start:  [-0.10147199  2.95017799]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.10147199,  2.95017799]), 'currentState': array([0.18155897, 2.4665783 ]), 'targetState': array([-0.03110459, -0.02109923]), 'effectorPosition': array([0.10286199, 0.65423501])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3040287295887716
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.10147199,  2.95017799]), 'currentState': array([3.78950592, 3.91125149]), 'targetState': array([-0.03110459, -0.02109923]), 'effectorPosition': array([-0.64471956,  0.38476024])}
episode index:1116
target Thresh 1.8068355412596486
current state at start:  [0.42382015 2.40901852]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.42382015, 2.40901852]), 'currentState': array([0.67847318, 1.9174943 ]), 'targetState': array([-0.32688491,  0.20418337]), 'effectorPosition': array([-0.07627116,  1.14655767])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3037565463035533
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.42382015, 2.40901852]), 'currentState': array([5.64837995, 0.19457651]), 'targetState': array([-0.32688491,  0.20418337]), 'effectorPosition': array([ 1.7098413 , -1.01916731])}
episode index:1117
target Thresh 1.8072214841056358
current state at start:  [-0.04139501 -2.21020725]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.04139501, -2.21020725]), 'currentState': array([5.77678573, 4.16245965]), 'targetState': array([ 0.43143668, -0.21635821]), 'effectorPosition': array([ 0.00394158, -0.97710312])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3034848499293999
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.04139501, -2.21020725]), 'currentState': array([5.62809263, 6.26552247]), 'targetState': array([ 0.43143668, -0.21635821]), 'effectorPosition': array([ 1.57509903, -1.23237619])}
episode index:1118
target Thresh 1.8076066558373023
current state at start:  [-1.60487554  2.14016573]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.60487554,  2.14016573]), 'currentState': array([4.29569259, 1.64016573]), 'targetState': array([ 0.0410086 , -1.10510469]), 'effectorPosition': array([ 0.53554418, -1.25481666])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.30410729421007066
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.60487554,  2.14016573]), 'currentState': array([4.29569259, 1.64016573]), 'targetState': array([ 0.0410086 , -1.10510469]), 'effectorPosition': array([ 0.53554418, -1.25481666])}
episode index:1119
target Thresh 1.8079910579953355
current state at start:  [-1.71815929  2.81449226]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.71815929,  2.81449226]), 'currentState': array([4.14282558, 2.31449226]), 'targetState': array([-0.59159533, -0.48644834]), 'effectorPosition': array([ 0.44561278, -0.66888265])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.30383576984024024
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.71815929,  2.81449226]), 'currentState': array([5.9858976 , 5.68245544]), 'targetState': array([-0.59159533, -0.48644834]), 'effectorPosition': array([ 1.57929614, -1.07502105])}
episode index:1120
target Thresh 1.808374692117345
current state at start:  [-3.65052024  2.15554908]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.65052024,  2.15554908]), 'currentState': array([3.09981385, 1.65554908]), 'targetState': array([-0.51051575, -0.4027121 ]), 'effectorPosition': array([-0.95616667, -0.95731011])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.303564729902827
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.65052024,  2.15554908]), 'currentState': array([5.96929888, 5.83961069]), 'targetState': array([-0.51051575, -0.4027121 ]), 'effectorPosition': array([ 1.67772361, -0.9958364 ])}
episode index:1121
target Thresh 1.8087575597378671
current state at start:  [ 0.41272013 -2.04303687]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.41272013, -2.04303687]), 'currentState': array([0.91272013, 4.5785528 ]), 'targetState': array([ 0.8421111 , -0.83621013]), 'effectorPosition': array([1.31408149, 0.0794723 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3032941731025571
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.41272013, -2.04303687]), 'currentState': array([4.24317653, 3.1259399 ]), 'targetState': array([ 0.8421111 , -0.83621013]), 'effectorPosition': array([ 0.01390511, -0.0071869 ])}
episode index:1122
target Thresh 1.8091396623883735
current state at start:  [-0.49053732 -2.24167917]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.49053732, -2.24167917]), 'currentState': array([6.2528289 , 3.61099952]), 'targetState': array([ 0.31025203, -1.19135845]), 'effectorPosition': array([ 0.09438357, -0.45543192])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3030240981487703
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.49053732, -2.24167917]), 'currentState': array([3.83703358, 3.92894819]), 'targetState': array([ 0.31025203, -1.19135845]), 'effectorPosition': array([-0.67988494,  0.35540648])}
episode index:1123
target Thresh 1.8095210015972747
current state at start:  [0.59404358 2.02534128]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.59404358, 2.02534128]), 'currentState': array([0.13256475, 1.52644599]), 'targetState': array([-0.79547001,  0.31340287]), 'effectorPosition': array([0.9031261 , 1.12828846])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.30275450375539953
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.59404358, 2.02534128]), 'currentState': array([2.68983671, 5.35939357]), 'targetState': array([-0.79547001,  0.31340287]), 'effectorPosition': array([-1.0936924 ,  1.41754546])}
episode index:1124
target Thresh 1.8099015788899284
current state at start:  [ 0.21714026 -1.79199114]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.21714026, -1.79199114]), 'currentState': array([6.00032556, 4.16130439]), 'targetState': array([ 1.2502768 , -0.11094546]), 'effectorPosition': array([ 0.21967365, -0.95106276])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.30248538864095026
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.21714026, -1.79199114]), 'currentState': array([4.91883623, 5.27331386]), 'targetState': array([ 1.2502768 , -0.11094546]), 'effectorPosition': array([-0.51475365, -1.67301161])}
episode index:1125
target Thresh 1.810281395788644
current state at start:  [-1.50830462  2.72791636]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.50830462,  2.72791636]), 'currentState': array([4.87976946, 2.34474245]), 'targetState': array([0.57173099, 0.70814202]), 'effectorPosition': array([ 0.75531621, -0.17768476])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.30221675152848054
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.50830462,  2.72791636]), 'currentState': array([5.68529016, 0.37791227]), 'targetState': array([0.57173099, 0.70814202]), 'effectorPosition': array([ 1.80242346, -0.78111692])}
episode index:1126
target Thresh 1.81066045381269
current state at start:  [-1.81430257  1.61340396]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.81430257,  1.61340396]), 'currentState': array([3.97677844, 1.21631987]), 'targetState': array([ 0.30415936, -1.0780183 ]), 'effectorPosition': array([-0.20863171, -1.62808834])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.30194859114558037
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.81430257,  1.61340396]), 'currentState': array([3.68090746, 4.08492755]), 'targetState': array([ 0.30415936, -1.0780183 ]), 'effectorPosition': array([-0.77002825,  0.48256942])}
episode index:1127
target Thresh 1.8110387544782989
current state at start:  [-2.36984166  2.72901116]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.36984166,  2.72901116]), 'currentState': array([3.86869612, 3.22336631]), 'targetState': array([ 0.73568127, -0.95113284]), 'effectorPosition': array([-0.0567916 ,  0.05880408])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.301680906224352
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.36984166,  2.72901116]), 'currentState': array([4.13846154, 3.37027033]), 'targetState': array([ 0.73568127, -0.95113284]), 'effectorPosition': array([-0.20450268,  0.10121584])}
episode index:1128
target Thresh 1.8114162992986738
current state at start:  [-4.10369263  2.25493475]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.10369263,  2.25493475]), 'currentState': array([1.74967977, 1.75493475]), 'targetState': array([-0.20536843, -0.58777203]), 'effectorPosition': array([-1.11275897,  0.6289422 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3014136955013898
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-4.10369263,  2.25493475]), 'currentState': array([3.30426837, 4.04652423]), 'targetState': array([-0.20536843, -0.58777203]), 'effectorPosition': array([-0.50457572,  0.71409002])}
episode index:1129
target Thresh 1.8117930897839942
current state at start:  [ 1.66009562 -2.29497815]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.66009562, -2.29497815]), 'currentState': array([2.16009562, 4.46171096]), 'targetState': array([-0.00611973, -0.00086038]), 'effectorPosition': array([0.38743491, 1.1635173 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.30114695771776023
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.66009562, -2.29497815]), 'currentState': array([3.69954772, 4.29681782]), 'targetState': array([-0.00611973, -0.00086038]), 'effectorPosition': array([-0.99024288,  0.46042801])}
episode index:1130
target Thresh 1.8121691274414229
current state at start:  [ 2.52314621 -2.41061823]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.52314621, -2.41061823]), 'currentState': array([2.96407044, 3.96245316]), 'targetState': array([0.87792188, 0.23920682]), 'effectorPosition': array([-0.18418659,  0.77646101])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3008806916189824
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.52314621, -2.41061823]), 'currentState': array([5.72513132, 5.80445529]), 'targetState': array([0.87792188, 0.23920682]), 'effectorPosition': array([ 1.35727833, -1.39030819])}
episode index:1131
target Thresh 1.812544413775111
current state at start:  [-0.80694227 -2.30870769]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.80694227, -2.30870769]), 'currentState': array([5.07708939, 4.36515257]), 'targetState': array([ 0.28409862, -0.49201325]), 'effectorPosition': array([-0.64317808, -0.95169377])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.30061489595500807
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.80694227, -2.30870769]), 'currentState': array([4.13301652, 3.94863747]), 'targetState': array([ 0.28409862, -0.49201325]), 'effectorPosition': array([-0.77320948,  0.13738802])}
episode index:1132
target Thresh 1.8129189502862042
current state at start:  [-0.83933208 -1.68326351]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.83933208, -1.68326351]), 'currentState': array([5.90675453, 5.09992179]), 'targetState': array([-0.55135348, -0.7944767 ]), 'effectorPosition': array([ 0.94108442, -1.36754188])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.30034956948020225
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.83933208, -1.68326351]), 'currentState': array([3.52814227, 3.45043871]), 'targetState': array([-0.55135348, -0.7944767 ]), 'effectorPosition': array([-0.15841509,  0.26369442])}
episode index:1133
target Thresh 1.813292738472849
current state at start:  [ 2.41236721 -1.98975592]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.41236721, -1.98975592]), 'currentState': array([2.84642594, 4.79015646]), 'targetState': array([-0.04266532,  1.21903831]), 'effectorPosition': array([-0.74106285,  1.26736107])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.30008471095332373
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.41236721, -1.98975592]), 'currentState': array([4.86816264, 0.47594359]), 'targetState': array([-0.04266532,  1.21903831]), 'effectorPosition': array([ 0.7456759 , -1.79490641])}
episode index:1134
target Thresh 1.813665779830199
current state at start:  [-2.70249655  2.64459512]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.70249655,  2.64459512]), 'currentState': array([3.9846128 , 2.54023064]), 'targetState': array([-0.51267641, -0.67381249]), 'effectorPosition': array([ 0.30573164, -0.50734265])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.29982031913750584
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.70249655,  2.64459512]), 'currentState': array([0.04077401, 5.18564486]), 'targetState': array([-0.51267641, -0.67381249]), 'effectorPosition': array([ 1.4908592 , -0.83000741])}
episode index:1135
target Thresh 1.8140380758504198
current state at start:  [-1.16215832  2.53656833]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.16215832,  2.53656833]), 'currentState': array([4.80615887, 2.57540918]), 'targetState': array([1.04269   , 0.76247241]), 'effectorPosition': array([ 0.54866937, -0.10513421])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2995563928002369
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.16215832,  2.53656833]), 'currentState': array([5.11248004, 4.59585139]), 'targetState': array([1.04269   , 0.76247241]), 'effectorPosition': array([-0.57056515, -1.2007945 ])}
episode index:1136
target Thresh 1.8144096280226958
current state at start:  [-2.27772358  1.7258446 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.27772358,  1.7258446 ]), 'currentState': array([3.86572683, 1.34117273]), 'targetState': array([-0.34005816, -1.34515758]), 'effectorPosition': array([-0.27447237, -1.54268822])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.3001724381891549
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.27772358,  1.7258446 ]), 'currentState': array([3.86572683, 1.34117273]), 'targetState': array([-0.34005816, -1.34515758]), 'effectorPosition': array([-0.27447237, -1.54268822])}
episode index:1137
target Thresh 1.8147804378332366
current state at start:  [-0.56660221 -1.9976256 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.56660221, -1.9976256 ]), 'currentState': array([5.2165831 , 3.93129291]), 'targetState': array([ 0.70390763, -0.23664078]), 'effectorPosition': array([-0.47880499, -0.60218715])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.29990866627510465
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.56660221, -1.9976256 ]), 'currentState': array([5.32109117, 6.25476708]), 'targetState': array([ 0.70390763, -0.23664078]), 'effectorPosition': array([ 1.12006467, -1.6566978 ])}
episode index:1138
target Thresh 1.8151505067652818
current state at start:  [ 0.30321425 -1.73516623]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.30321425, -1.73516623]), 'currentState': array([6.08639955, 4.0579057 ]), 'targetState': array([ 1.37955827, -0.08257827]), 'effectorPosition': array([ 0.22858274, -0.85454735])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.29964535752508265
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.30321425, -1.73516623]), 'currentState': array([3.85812394, 3.63760475]), 'targetState': array([ 1.37955827, -0.08257827]), 'effectorPosition': array([-0.40344979,  0.27973793])}
episode index:1139
target Thresh 1.8155198362991076
current state at start:  [-3.35794898  2.22271799]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.35794898,  2.22271799]), 'currentState': array([3.37298725, 1.77053754]), 'targetState': array([ 0.0056277 , -0.05137945]), 'effectorPosition': array([-0.55544456, -1.13782685])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2993825107202361
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.35794898,  2.22271799]), 'currentState': array([5.60939087, 6.21572022]), 'targetState': array([ 0.0056277 , -0.05137945]), 'effectorPosition': array([ 1.51907843, -1.29917317])}
episode index:1140
target Thresh 1.8158884279120326
current state at start:  [-1.60912676 -2.28810127]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.60912676, -2.28810127]), 'currentState': array([4.61289491, 4.43851613]), 'targetState': array([0.02829383, 0.0248559 ]), 'effectorPosition': array([-1.03043453, -0.6303021 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2991201246459852
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.60912676, -2.28810127]), 'currentState': array([5.77830777, 0.11387173]), 'targetState': array([0.02829383, 0.0248559 ]), 'effectorPosition': array([ 1.79975991, -0.86481876])}
episode index:1141
target Thresh 1.8162562830784237
current state at start:  [-0.40945311 -2.73813499]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.40945311, -2.73813499]), 'currentState': array([0.0655524 , 3.45493229]), 'targetState': array([-0.08765039, -0.53306455]), 'effectorPosition': array([ 0.06877718, -0.30438585])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.2997338548345614
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.40945311, -2.73813499]), 'currentState': array([0.0655524 , 3.45493229]), 'targetState': array([-0.08765039, -0.53306455]), 'effectorPosition': array([ 0.06877718, -0.30438585])}
episode index:1142
target Thresh 1.8166234032697022
current state at start:  [-1.18158451  2.08940108]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.18158451,  2.08940108]), 'currentState': array([5.11774138, 1.58940108]), 'targetState': array([ 0.37465345, -0.58649603]), 'effectorPosition': array([ 1.30581085, -0.50759301])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2994716204908741
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.18158451,  2.08940108]), 'currentState': array([4.11789326, 3.69688556]), 'targetState': array([ 0.37465345, -0.58649603]), 'effectorPosition': array([-0.52089829,  0.17080062])}
episode index:1143
target Thresh 1.8169897899543492
current state at start:  [2.10061633 1.71280866]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.10061633, 1.71280866]), 'currentState': array([2.59623753, 1.27730396]), 'targetState': array([-0.94220451,  0.46216381]), 'effectorPosition': array([-1.59881651, -0.14959886])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.29920984459883665
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([2.10061633, 1.71280866]), 'currentState': array([5.58455578, 6.26665955]), 'targetState': array([-0.94220451,  0.46216381]), 'effectorPosition': array([ 1.52071577, -1.29890355])}
episode index:1144
target Thresh 1.817355444597912
current state at start:  [-0.42843584  2.14530132]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.42843584,  2.14530132]), 'currentState': array([0.07156416, 1.64530132]), 'targetState': array([-0.00034085,  0.01642107]), 'effectorPosition': array([0.8518901 , 1.06085395])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2989485259572656
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.42843584,  2.14530132]), 'currentState': array([5.89990922, 6.21936781]), 'targetState': array([-0.00034085,  0.01642107]), 'effectorPosition': array([ 1.82915197, -0.8063075 ])}
episode index:1145
target Thresh 1.81772036866301
current state at start:  [ 1.62327635 -2.14798368]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.62327635, -2.14798368]), 'currentState': array([2.12327635, 4.63380014]), 'targetState': array([ 0.21704469, -0.13934736]), 'effectorPosition': array([0.36499937, 1.30757773])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.29868766336917024
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.62327635, -2.14798368]), 'currentState': array([5.81386175, 6.08681395]), 'targetState': array([ 0.21704469, -0.13934736]), 'effectorPosition': array([ 1.67836223, -1.06988891])}
episode index:1146
target Thresh 1.8180845636093392
current state at start:  [-3.72354473  2.81507889]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.72354473,  2.81507889]), 'currentState': array([3.05964058, 2.31507889]), 'targetState': array([-0.19671195,  0.46564389]), 'effectorPosition': array([-0.38168755, -0.70670085])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.29842725564173417
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.72354473,  2.81507889]), 'currentState': array([5.55903983, 0.04723761]), 'targetState': array([-0.19671195,  0.46564389]), 'effectorPosition': array([ 1.52857912, -1.28888126])}
episode index:1147
target Thresh 1.8184480308936806
current state at start:  [ 1.42962502 -1.85599768]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.42962502, -1.85599768]), 'currentState': array([1.92962502, 4.87471131]), 'targetState': array([ 0.27856931, -0.21670002]), 'effectorPosition': array([0.51606891, 1.43418749])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2981673015862971
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.42962502, -1.85599768]), 'currentState': array([3.85670644, 4.22837173]), 'targetState': array([ 0.27856931, -0.21670002]), 'effectorPosition': array([-0.98406368,  0.31771249])}
episode index:1148
target Thresh 1.8188107719699032
current state at start:  [0.980612   2.39465161]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.980612  , 2.39465161]), 'currentState': array([1.28801712, 1.89678263]), 'targetState': array([-0.12989272, -0.22274439]), 'effectorPosition': array([-0.72004117,  0.91709003])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2979078000183369
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.980612  , 2.39465161]), 'currentState': array([5.93772013, 5.9767595 ]), 'targetState': array([-0.12989272, -0.22274439]), 'effectorPosition': array([ 1.73585601, -0.94532511])}
episode index:1149
target Thresh 1.819172788288972
current state at start:  [-0.40418426 -2.10006933]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.40418426, -2.10006933]), 'currentState': array([5.59847611, 4.66434702]), 'targetState': array([-0.07929326, -0.09396557]), 'effectorPosition': array([ 0.10568579, -1.3757847 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.29764874975745137
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.40418426, -2.10006933]), 'currentState': array([2.10759292, 5.20035123]), 'targetState': array([-0.07929326, -0.09396557]), 'effectorPosition': array([0.00791922, 1.71394024])}
episode index:1150
target Thresh 1.8195340812989533
current state at start:  [ 3.45060909 -2.59681201]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.45060909, -2.59681201]), 'currentState': array([3.95060909, 4.1863733 ]), 'targetState': array([-0.14196199,  0.09333987]), 'effectorPosition': array([-0.96944877,  0.23661318])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2973901496273406
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.45060909, -2.59681201]), 'currentState': array([5.77699043, 6.0034652 ]), 'targetState': array([-0.14196199,  0.09333987]), 'effectorPosition': array([ 1.581337  , -1.19232495])}
episode index:1151
target Thresh 1.819894652445019
current state at start:  [0.82414544 2.57750936]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.82414544, 2.57750936]), 'currentState': array([0.32414544, 3.07750936]), 'targetState': array([-0.70500278,  0.9488846 ]), 'effectorPosition': array([-0.01845075,  0.06135823])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.29713199845578914
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.82414544, 2.57750936]), 'currentState': array([5.52273143, 1.08810939]), 'targetState': array([-0.70500278,  0.9488846 ]), 'effectorPosition': array([ 1.67132271, -0.36742622])}
episode index:1152
target Thresh 1.8202545031694541
current state at start:  [ 2.64106918 -2.42564819]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.64106918, -2.42564819]), 'currentState': array([3.08540163, 4.11008632]), 'targetState': array([-0.70870484, -0.1029644 ]), 'effectorPosition': array([-0.38649552,  0.84707634])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2968742950746479
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.64106918, -2.42564819]), 'currentState': array([2.39454579, 5.51484184]), 'targetState': array([-0.70870484, -0.1029644 ]), 'effectorPosition': array([-0.7890763 ,  1.67794049])}
episode index:1153
target Thresh 1.8206136349116626
current state at start:  [-0.42202428  2.33460218]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.42202428,  2.33460218]), 'currentState': array([0.07136685, 1.83460218]), 'targetState': array([0.88230326, 0.25821073]), 'effectorPosition': array([0.6685222, 1.0156598])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.29661703831981723
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.42202428,  2.33460218]), 'currentState': array([5.38361051, 0.13400094]), 'targetState': array([0.88230326, 0.25821073]), 'effectorPosition': array([ 1.34292781, -1.47601338])}
episode index:1154
target Thresh 1.8209720491081713
current state at start:  [-0.96576526  2.50449404]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.96576526,  2.50449404]), 'currentState': array([5.81742005, 2.00449404]), 'targetState': array([ 0.01255505, -0.53989185]), 'effectorPosition': array([0.92554019, 0.55037921])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2963602270312286
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.96576526,  2.50449404]), 'currentState': array([3.68781791, 4.05697155]), 'targetState': array([ 0.01255505, -0.53989185]), 'effectorPosition': array([-0.74551614,  0.474579  ])}
episode index:1155
target Thresh 1.8213297471926377
current state at start:  [-3.09460937  2.42804502]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.09460937,  2.42804502]), 'currentState': array([3.64654745, 1.92804502]), 'targetState': array([-0.16764804, -0.23960477]), 'effectorPosition': array([-0.11591798, -1.13453386])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2961038600528279
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.09460937,  2.42804502]), 'currentState': array([6.03385622, 6.03815262]), 'targetState': array([-0.16764804, -0.23960477]), 'effectorPosition': array([ 1.84934989, -0.72122379])}
episode index:1156
target Thresh 1.8216867305958548
current state at start:  [-3.93817443  1.71921012]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.93817443,  1.71921012]), 'currentState': array([2.77230567, 1.21921012]), 'targetState': array([-0.42162381, -0.32968752]), 'effectorPosition': array([-1.59262583, -0.3902791 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2958479362325575
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.93817443,  1.71921012]), 'currentState': array([5.86502168, 5.62879934]), 'targetState': array([-0.42162381, -0.32968752]), 'effectorPosition': array([ 1.39172236, -1.28450477])}
episode index:1157
target Thresh 1.8220430007457566
current state at start:  [1.15677225 2.98488888]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.15677225, 2.98488888]), 'currentState': array([1.61139688, 2.57569941]), 'targetState': array([0.21918154, 0.19057277]), 'effectorPosition': array([-0.54205565,  0.13399871])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2955924544223394
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.15677225, 2.98488888]), 'currentState': array([5.71049165, 0.0062089 ]), 'targetState': array([0.21918154, 0.19057277]), 'effectorPosition': array([ 1.68423705, -1.07856712])}
episode index:1158
target Thresh 1.8223985590674239
current state at start:  [ 2.39855548 -1.70430606]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.39855548, -1.70430606]), 'currentState': array([2.89855548, 5.01182286]), 'targetState': array([0.01565429, 1.40095088]), 'effectorPosition': array([-1.02697836,  1.23906177])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2953374134780578
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.39855548, -1.70430606]), 'currentState': array([5.31323539, 1.16984117]), 'targetState': array([0.01565429, 1.40095088]), 'effectorPosition': array([ 1.54542902, -0.62629466])}
episode index:1159
target Thresh 1.8227534069830909
current state at start:  [-0.62311731  2.30584848]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.62311731,  2.30584848]), 'currentState': array([6.160068  , 1.83149123]), 'targetState': array([1.26217498, 0.00626448]), 'effectorPosition': array([0.85528663, 0.86774461])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.29508281225954225
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.62311731,  2.30584848]), 'currentState': array([5.59386346, 0.14289986]), 'targetState': array([1.26217498, 0.00626448]), 'effectorPosition': array([ 1.62606676, -1.15564755])}
episode index:1160
target Thresh 1.8231075459121493
current state at start:  [0.64294956 2.58872017]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.64294956, 2.58872017]), 'currentState': array([0.18231256, 2.99303609]), 'targetState': array([-0.40550045,  0.62313481]), 'effectorPosition': array([-0.01600327,  0.14755471])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.2956899760732722
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.64294956, 2.58872017]), 'currentState': array([0.18231256, 2.99303609]), 'targetState': array([-0.40550045,  0.62313481]), 'effectorPosition': array([-0.01600327,  0.14755471])}
episode index:1161
target Thresh 1.8234609772711554
current state at start:  [1.11931023 2.03505197]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.11931023, 2.03505197]), 'currentState': array([0.78540552, 1.53505197]), 'targetState': array([-0.15275187,  0.25512871]), 'effectorPosition': array([0.02571079, 1.43903177])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2954355096566859
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.11931023, 2.03505197]), 'currentState': array([5.39502623, 0.22302798]), 'targetState': array([-0.15275187,  0.25512871]), 'effectorPosition': array([ 1.41767737, -1.39307402])}
episode index:1162
target Thresh 1.8238137024738355
current state at start:  [ 3.49862064 -2.37087158]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.49862064, -2.37087158]), 'currentState': array([2.99862064, 3.62284952]), 'targetState': array([-0.97242536, -0.31796955]), 'effectorPosition': array([-0.04647164,  0.47435507])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2951814808435675
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.49862064, -2.37087158]), 'currentState': array([2.61928072, 3.86511682]), 'targetState': array([-0.97242536, -0.31796955]), 'effectorPosition': array([0.11315692, 0.6987424 ])}
episode index:1163
target Thresh 1.8241657229310904
current state at start:  [-1.77413752 -1.70159971]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.77413752, -1.70159971]), 'currentState': array([4.90521637, 5.08158559]), 'targetState': array([-1.08180581e+00,  9.04059953e-04]), 'effectorPosition': array([-0.65454361, -1.51436629])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.29492788850607304
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.77413752, -1.70159971]), 'currentState': array([5.95742779, 5.56944635]), 'targetState': array([-1.08180581e+00,  9.04059953e-04]), 'effectorPosition': array([ 1.45406301, -1.18217578])}
episode index:1164
target Thresh 1.8245170400510025
current state at start:  [ 0.93528679 -2.65507275]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.93528679, -2.65507275]), 'currentState': array([1.43528679, 3.12811256]), 'targetState': array([ 0.89259477, -0.56412961]), 'effectorPosition': array([-0.01334384,  0.00191106])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2946747315202309
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.93528679, -2.65507275]), 'currentState': array([3.5196685 , 3.01324875]), 'targetState': array([ 0.89259477, -0.56412961]), 'effectorPosition': array([ 0.03960208, -0.12198867])}
episode index:1165
target Thresh 1.824867655238841
current state at start:  [-0.45999589  2.39125732]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.45999589,  2.39125732]), 'currentState': array([0.04000411, 1.89830819]), 'targetState': array([ 0.19911557, -0.00143122]), 'effectorPosition': array([0.63990154, 0.97321617])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.29442200876592534
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.45999589,  2.39125732]), 'currentState': array([5.72520831, 5.86595157]), 'targetState': array([ 0.19911557, -0.00143122]), 'effectorPosition': array([ 1.40932158, -1.35729125])}
episode index:1166
target Thresh 1.8252175698970667
current state at start:  [0.88613637 2.1830864 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.88613637, 2.1830864 ]), 'currentState': array([0.3933645, 1.6830864]), 'targetState': array([0.02576134, 0.7544671 ]), 'effectorPosition': array([0.43924447, 1.25815571])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.29416971912688
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.88613637, 2.1830864 ]), 'currentState': array([4.97360093, 0.57141551]), 'targetState': array([0.02576134, 0.7544671 ]), 'effectorPosition': array([ 0.99795361, -1.63901225])}
episode index:1167
target Thresh 1.8255667854253392
current state at start:  [-3.39812093  2.28748557]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.39812093,  2.28748557]), 'currentState': array([3.37036873, 2.35965256]), 'targetState': array([-0.9449803 , -0.14274535]), 'effectorPosition': array([-0.12307823, -0.75216767])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.29391786149064125
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.39812093,  2.28748557]), 'currentState': array([6.02935273, 5.67421939]), 'targetState': array([-0.9449803 , -0.14274535]), 'effectorPosition': array([ 1.61827121, -1.01078101])}
episode index:1168
target Thresh 1.8259153032205209
current state at start:  [0.49057369 2.46038228]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.49057369, 2.46038228]), 'currentState': array([0.00856041, 2.0658277 ]), 'targetState': array([-0.76504345,  0.40287971]), 'effectorPosition': array([0.51738884, 0.88441522])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.293666434748562
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.49057369, 2.46038228]), 'currentState': array([5.39404378, 0.10382961]), 'targetState': array([-0.76504345,  0.40287971]), 'effectorPosition': array([ 1.33724665, -1.48357693])}
episode index:1169
target Thresh 1.8262631246766832
current state at start:  [ 2.66080641 -2.24378357]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.66080641, -2.24378357]), 'currentState': array([2.16080641, 4.51855656]), 'targetState': array([-0.86793875,  0.39442991]), 'effectorPosition': array([0.36617335, 1.21682997])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2934154377957855
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.66080641, -2.24378357]), 'currentState': array([1.26855426, 5.29740509]), 'targetState': array([-0.86793875,  0.39442991]), 'effectorPosition': array([1.25794651, 1.2336921 ])}
episode index:1170
target Thresh 1.8266102511851126
current state at start:  [ 0.39371    -2.82605774]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.39371   , -2.82605774]), 'currentState': array([0.85161839, 2.98615101]), 'targetState': array([ 0.03868832, -0.66031085]), 'effectorPosition': array([-0.10853318,  0.11105873])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2931648695312289
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.39371   , -2.82605774]), 'currentState': array([2.66202345, 4.12957142]), 'targetState': array([ 0.03868832, -0.66031085]), 'effectorPosition': array([-0.01367395,  0.9481856 ])}
episode index:1171
target Thresh 1.8269566841343154
current state at start:  [ 1.4857758  -1.62261941]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.4857758 , -1.62261941]), 'currentState': array([0.9857758, 5.1605659]), 'targetState': array([0.35723527, 1.26367695]), 'effectorPosition': array([1.54286801, 0.69728384])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2929147288575674
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.4857758 , -1.62261941]), 'currentState': array([5.16481323, 4.80845653]), 'targetState': array([0.35723527, 1.26367695]), 'effectorPosition': array([-0.41616471, -1.42079085])}
episode index:1172
target Thresh 1.8273024249100243
current state at start:  [ 0.56823117 -2.66826508]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.56823117, -2.66826508]), 'currentState': array([0.40579632, 4.11492022]), 'targetState': array([-0.17520764, -0.22122895]), 'effectorPosition': array([ 0.72828737, -0.58693647])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.29266501468121825
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.56823117, -2.66826508]), 'currentState': array([5.95080985, 5.44496905]), 'targetState': array([-0.17520764, -0.22122895]), 'effectorPosition': array([ 1.33487672, -1.24727069])}
episode index:1173
target Thresh 1.8276474748952023
current state at start:  [ 2.3374734  -1.75894135]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.3374734 , -1.75894135]), 'currentState': array([2.8374734 , 5.02424395]), 'targetState': array([-0.07237403,  0.91293837]), 'effectorPosition': array([-0.9618467 ,  1.29942304])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.29241572591232456
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.3374734 , -1.75894135]), 'currentState': array([5.20890038, 0.28669312]), 'targetState': array([-0.07237403,  0.91293837]), 'effectorPosition': array([ 1.18191504, -1.58790596])}
episode index:1174
target Thresh 1.8279918354700502
current state at start:  [0.55338857 1.95697165]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.55338857, 1.95697165]), 'currentState': array([0.08193568, 1.53893531]), 'targetState': array([0.00922423, 1.04240473]), 'effectorPosition': array([0.94659141, 1.08059056])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.29216686146473964
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.55338857, 1.95697165]), 'currentState': array([5.55628495, 5.00714885]), 'targetState': array([0.00922423, 1.04240473]), 'effectorPosition': array([ 0.32842241, -1.57262802])}
episode index:1175
target Thresh 1.8283355080120107
current state at start:  [-2.74174945  2.54577989]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.74174945,  2.54577989]), 'currentState': array([4.04143586, 2.07156197]), 'targetState': array([ 0.93128085, -0.36512077]), 'effectorPosition': array([ 0.36382025, -0.95259656])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2919184202560111
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.74174945,  2.54577989]), 'currentState': array([4.04870306, 3.84328479]), 'targetState': array([ 0.93128085, -0.36512077]), 'effectorPosition': array([-0.65402159,  0.21155088])}
episode index:1176
target Thresh 1.8286784938957743
current state at start:  [-1.13201105  2.75425458]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.13201105,  2.75425458]), 'currentState': array([4.89005611, 2.33226534]), 'targetState': array([-0.34167726, -0.34233979]), 'effectorPosition': array([ 0.76721932, -0.17721036])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.29167040120736537
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.13201105,  2.75425458]), 'currentState': array([5.85482924, 5.59275434]), 'targetState': array([-0.34167726, -0.34233979]), 'effectorPosition': array([ 1.34642374, -1.31494728])}
episode index:1177
target Thresh 1.829020794493285
current state at start:  [-1.86662372 -2.52211752]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.86662372, -2.52211752]), 'currentState': array([4.82982312, 3.75904775]), 'targetState': array([-0.68893497, -0.08516902]), 'effectorPosition': array([-0.55334057, -0.25120751])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.2922716996783269
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.86662372, -2.52211752]), 'currentState': array([4.82982312, 3.75904775]), 'targetState': array([-0.68893497, -0.08516902]), 'effectorPosition': array([-0.55334057, -0.25120751])}
episode index:1178
target Thresh 1.8293624111737457
current state at start:  [0.89822578 1.79843466]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.89822578, 1.79843466]), 'currentState': array([0.39822578, 1.34209271]), 'targetState': array([0.08094724, 1.16927582]), 'effectorPosition': array([0.75303908, 1.37344906])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.29202380171422315
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.89822578, 1.79843466]), 'currentState': array([5.4468782 , 5.40357139]), 'targetState': array([0.08094724, 1.16927582]), 'effectorPosition': array([ 0.52559234, -1.73166106])}
episode index:1179
target Thresh 1.8297033453036238
current state at start:  [ 0.50978254 -1.92684385]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.50978254, -1.92684385]), 'currentState': array([1.00978254, 4.69166634]), 'targetState': array([ 1.18946306, -0.16541758]), 'effectorPosition': array([1.36755465, 0.29724059])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.2926237815432789
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.50978254, -1.92684385]), 'currentState': array([1.00978254, 4.69166634]), 'targetState': array([ 1.18946306, -0.16541758]), 'effectorPosition': array([1.36755465, 0.29724059])}
episode index:1180
target Thresh 1.8300435982466559
current state at start:  [-2.40600627  2.87983403]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.40600627,  2.87983403]), 'currentState': array([4.37717904, 2.7972606 ]), 'targetState': array([ 0.7081601 , -0.17409576]), 'effectorPosition': array([ 0.2994694 , -0.16648064])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.2932227453184328
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.40600627,  2.87983403]), 'currentState': array([4.37717904, 2.7972606 ]), 'targetState': array([ 0.7081601 , -0.17409576]), 'effectorPosition': array([ 0.2994694 , -0.16648064])}
episode index:1181
target Thresh 1.8303831713638543
current state at start:  [-0.49148615  1.92560598]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.49148615,  1.92560598]), 'currentState': array([5.77941469, 1.42560598]), 'targetState': array([0.25307803, 0.29803536]), 'effectorPosition': array([1.48012752, 0.31398103])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2929746719298385
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.49148615,  1.92560598]), 'currentState': array([5.64950676, 5.68186923]), 'targetState': array([0.25307803, 0.29803536]), 'effectorPosition': array([ 1.13538105, -1.53625956])}
episode index:1182
target Thresh 1.830722066013512
current state at start:  [ 0.58828638 -2.06563523]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.58828638, -2.06563523]), 'currentState': array([0.7173441 , 4.71648852]), 'targetState': array([ 0.02524793, -0.15710413]), 'effectorPosition': array([ 1.41402366, -0.0934674 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.29272701793835093
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.58828638, -2.06563523]), 'currentState': array([5.93114758, 5.4475207 ]), 'targetState': array([ 0.02524793, -0.15710413]), 'effectorPosition': array([ 1.312464  , -1.27232385])}
episode index:1183
target Thresh 1.8310602835512082
current state at start:  [-0.94383529  2.06848448]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.94383529,  2.06848448]), 'currentState': array([4.95721719, 1.56848448]), 'targetState': array([0.85532715, 0.10991007]), 'effectorPosition': array([ 1.21312641, -0.73003287])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.29247978228130844
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.94383529,  2.06848448]), 'currentState': array([4.91173675, 0.24404927]), 'targetState': array([0.85532715, 0.10991007]), 'effectorPosition': array([ 0.62704055, -1.88349546])}
episode index:1184
target Thresh 1.831397825329813
current state at start:  [-1.45790511  2.07893042]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.45790511,  2.07893042]), 'currentState': array([4.50701545, 1.57893042]), 'targetState': array([0.71564282, 0.01754927]), 'effectorPosition': array([ 0.77667842, -1.17494792])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.29223296389963643
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.45790511,  2.07893042]), 'currentState': array([5.79209953, 6.00715542]), 'targetState': array([0.71564282, 0.01754927]), 'effectorPosition': array([ 1.60173691, -1.16564529])}
episode index:1185
target Thresh 1.8317346926994948
current state at start:  [ 0.92538009 -2.39637318]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.92538009, -2.39637318]), 'currentState': array([1.42538009, 4.38681213]), 'targetState': array([ 0.3604856 , -0.06765863]), 'effectorPosition': array([1.03602238, 0.53567421])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2919865617378324
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.92538009, -2.39637318]), 'currentState': array([5.93071826, 6.0158003 ]), 'targetState': array([ 0.3604856 , -0.06765863]), 'effectorPosition': array([ 1.75248832, -0.92612898])}
episode index:1186
target Thresh 1.8320708870077227
current state at start:  [-0.59864205 -2.23199193]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.59864205, -2.23199193]), 'currentState': array([6.15772796, 3.61317023]), 'targetState': array([ 0.16741215, -1.32794445]), 'effectorPosition': array([ 0.05144454, -0.46437918])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2917405747439505
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.59864205, -2.23199193]), 'currentState': array([3.64780977, 3.89888916]), 'targetState': array([ 0.16741215, -1.32794445]), 'effectorPosition': array([-0.57211524,  0.46828672])}
episode index:1187
target Thresh 1.832406409599275
current state at start:  [0.9956072  2.06422288]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.9956072 , 2.06422288]), 'currentState': array([1.41583562, 1.56422288]), 'targetState': array([0.09289868, 0.99177199]), 'effectorPosition': array([-0.83264043,  1.14885017])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2914950018695869
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.9956072 , 2.06422288]), 'currentState': array([4.76910526, 6.13310589]), 'targetState': array([0.09289868, 0.99177199]), 'effectorPosition': array([-0.03654169, -1.99403689])}
episode index:1188
target Thresh 1.832741261816242
current state at start:  [-0.20773371 -2.78724266]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.20773371, -2.78724266]), 'currentState': array([0.2299522, 3.9741145]), 'targetState': array([-0.00378404, -0.17286779]), 'effectorPosition': array([ 0.48696495, -0.64563132])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.29209088496305236
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.20773371, -2.78724266]), 'currentState': array([0.2299522, 3.9741145]), 'targetState': array([-0.00378404, -0.17286779]), 'effectorPosition': array([ 0.48696495, -0.64563132])}
episode index:1189
target Thresh 1.8330754449980333
current state at start:  [ 4.31877373 -2.47244421]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.31877373, -2.47244421]), 'currentState': array([3.81877373, 3.42496795]), 'targetState': array([-1.01517641, -0.39095126]), 'effectorPosition': array([-0.20627802,  0.19291192])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2918454304378733
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 4.31877373, -2.47244421]), 'currentState': array([2.9486418 , 5.15640245]), 'targetState': array([-1.01517641, -0.39095126]), 'effectorPosition': array([-1.22987607,  1.1604048 ])}
episode index:1190
target Thresh 1.8334089604813821
current state at start:  [ 1.2385422 -2.5114271]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.2385422, -2.5114271]), 'currentState': array([1.69273296, 3.34726519]), 'targetState': array([ 1.06880441, -0.4712436 ]), 'effectorPosition': array([0.20014559, 0.04576057])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2916003880949364
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.2385422, -2.5114271]), 'currentState': array([4.34873887, 2.93236505]), 'targetState': array([ 1.06880441, -0.4712436 ]), 'effectorPosition': array([ 0.18636456, -0.09426017])}
episode index:1191
target Thresh 1.8337418096003506
current state at start:  [ 1.06000822 -2.32911517]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.06000822, -2.32911517]), 'currentState': array([1.55296575, 4.45407014]), 'targetState': array([ 0.40842232, -0.06081678]), 'effectorPosition': array([0.97994207, 0.72718806])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.29135575689687015
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.06000822, -2.32911517]), 'currentState': array([5.5150019 , 5.58751226]), 'targetState': array([ 0.40842232, -0.06081678]), 'effectorPosition': array([ 0.82591025, -1.68911731])}
episode index:1192
target Thresh 1.834073993686336
current state at start:  [-0.80914367 -2.35955582]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.80914367, -2.35955582]), 'currentState': array([5.90428352, 4.42362948]), 'targetState': array([-1.17650388, -0.51970447]), 'effectorPosition': array([ 0.30992027, -1.1551722 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.29111153580978144
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.80914367, -2.35955582]), 'currentState': array([5.86225132, 5.83249648]), 'targetState': array([-1.17650388, -0.51970447]), 'effectorPosition': array([ 1.55629304, -1.17398745])}
episode index:1193
target Thresh 1.8344055140680748
current state at start:  [ 2.95587302 -2.44447868]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.95587302, -2.44447868]), 'currentState': array([3.45587302, 3.84223947]), 'targetState': array([0.18083444, 1.24574633]), 'effectorPosition': array([-0.4233373 ,  0.54030997])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.29086772380324055
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.95587302, -2.44447868]), 'currentState': array([5.02756676, 6.20517752]), 'targetState': array([0.18083444, 1.24574633]), 'effectorPosition': array([ 0.54493829, -1.92274807])}
episode index:1194
target Thresh 1.834736372071649
current state at start:  [-1.67258753 -1.97410578]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.67258753, -1.97410578]), 'currentState': array([4.42580896, 4.72545573]), 'targetState': array([-0.75808148, -0.6432748 ]), 'effectorPosition': array([-1.24550124, -0.68910044])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.2914611399339492
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.67258753, -1.97410578]), 'currentState': array([4.42580896, 4.72545573]), 'targetState': array([-0.75808148, -0.6432748 ]), 'effectorPosition': array([-1.24550124, -0.68910044])}
episode index:1195
target Thresh 1.8350665690204913
current state at start:  [-3.37680682  1.79555404]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.37680682,  1.79555404]), 'currentState': array([3.35249124, 1.92186838]), 'targetState': array([-1.19103434, -0.17853447]), 'effectorPosition': array([-0.44498839, -1.05554535])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.29121744332865324
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.37680682,  1.79555404]), 'currentState': array([6.0116778 , 4.99844508]), 'targetState': array([-1.19103434, -0.17853447]), 'effectorPosition': array([ 0.97791578, -1.2680782 ])}
episode index:1196
target Thresh 1.8353961062353896
current state at start:  [ 0.4230426  -2.48801264]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.4230426 , -2.48801264]), 'currentState': array([6.20622791, 3.29517267]), 'targetState': array([0.77162661, 0.34001465]), 'effectorPosition': array([-2.56824676e-05, -1.53429118e-01])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2909741539023135
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.4230426 , -2.48801264]), 'currentState': array([4.56462821, 6.05264035]), 'targetState': array([0.77162661, 0.34001465]), 'effectorPosition': array([-0.5165702 , -1.91839497])}
episode index:1197
target Thresh 1.8357249850344934
current state at start:  [-1.58824825  2.30054696]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.58824825,  2.30054696]), 'currentState': array([4.30565942, 1.80054696]), 'targetState': array([ 0.28458508, -0.93344213]), 'effectorPosition': array([ 0.58877225, -1.09447605])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.2915659951761847
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.58824825,  2.30054696]), 'currentState': array([4.30565942, 1.80054696]), 'targetState': array([ 0.28458508, -0.93344213]), 'effectorPosition': array([ 0.58877225, -1.09447605])}
episode index:1198
target Thresh 1.8360532067333184
current state at start:  [ 3.87643858 -2.94183885]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.87643858, -2.94183885]), 'currentState': array([4.37643858, 3.43574638]), 'targetState': array([ 0.54652419, -0.10802482]), 'effectorPosition': array([-0.28788209,  0.05502923])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2913228208682813
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.87643858, -2.94183885]), 'currentState': array([5.64445743, 5.87176215]), 'targetState': array([ 0.54652419, -0.10802482]), 'effectorPosition': array([ 1.30029484, -1.46367296])}
episode index:1199
target Thresh 1.8363807726447519
current state at start:  [-0.87006582 -1.97260971]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.87006582, -1.97260971]), 'currentState': array([5.41347947, 4.8105756 ]), 'targetState': array([ 0.18858368, -0.26510106]), 'effectorPosition': array([-0.05217375, -1.48099148])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2910800518508911
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.87006582, -1.97260971]), 'currentState': array([5.86699014, 5.85848107]), 'targetState': array([ 0.18858368, -0.26510106]), 'effectorPosition': array([ 1.5814266, -1.1495265])}
episode index:1200
target Thresh 1.8367076840790575
current state at start:  [-1.80314095  1.99245254]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.80314095,  1.99245254]), 'currentState': array([4.01923739, 1.70323766]), 'targetState': array([ 1.27054173, -0.5634683 ]), 'effectorPosition': array([ 0.20791295, -1.30102392])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2908376871116314
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.80314095,  1.99245254]), 'currentState': array([4.00160122, 3.32735263]), 'targetState': array([ 1.27054173, -0.5634683 ]), 'effectorPosition': array([-0.15119393,  0.10746186])}
episode index:1201
target Thresh 1.8370339423438817
current state at start:  [ 2.33904424 -1.96544148]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.33904424, -1.96544148]), 'currentState': array([2.83904424, 4.77559569]), 'targetState': array([0.01982892, 1.38271445]), 'effectorPosition': array([-0.71751713,  1.26944808])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2905957256414886
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.33904424, -1.96544148]), 'currentState': array([4.54071563, 5.44627802]), 'targetState': array([0.01982892, 1.38271445]), 'effectorPosition': array([-1.01690743, -1.51836243])}
episode index:1202
target Thresh 1.8373595487442582
current state at start:  [-0.49129627 -1.84993611]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.49129627, -1.84993611]), 'currentState': array([6.19272384, 4.87118207]), 'targetState': array([-0.69832856, -1.16224314]), 'effectorPosition': array([ 1.06418961, -1.08800444])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.29035416643480405
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.49129627, -1.84993611]), 'currentState': array([3.49564609, 3.58330898]), 'targetState': array([-0.69832856, -1.16224314]), 'effectorPosition': array([-0.23824003,  0.36769978])}
episode index:1203
target Thresh 1.8376845045826127
current state at start:  [ 3.87880125 -1.85162736]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.87880125, -1.85162736]), 'currentState': array([4.35663104, 4.84678453]), 'targetState': array([-1.07242952,  0.65203146]), 'effectorPosition': array([-1.32390018, -0.71782379])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2901130084892602
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.87880125, -1.85162736]), 'currentState': array([5.40293771, 1.35481873]), 'targetState': array([-1.07242952,  0.65203146]), 'effectorPosition': array([ 1.52644907, -0.3139396 ])}
episode index:1204
target Thresh 1.8380088111587691
current state at start:  [ 0.98148236 -3.03247772]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.98148236, -3.03247772]), 'currentState': array([1.39125702, 2.93580379]), 'targetState': array([ 0.10170096, -0.14399814]), 'effectorPosition': array([-0.19728696,  0.05725093])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.29070212632453885
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.98148236, -3.03247772]), 'currentState': array([1.39125702, 2.93580379]), 'targetState': array([ 0.10170096, -0.14399814]), 'effectorPosition': array([-0.19728696,  0.05725093])}
episode index:1205
target Thresh 1.8383324697699543
current state at start:  [ 1.70210744 -1.86761548]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.70210744, -1.86761548]), 'currentState': array([2.12322523, 4.90939711]), 'targetState': array([0.08672432, 0.19391369]), 'effectorPosition': array([0.20731612, 1.53247918])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2904610797852979
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.70210744, -1.86761548]), 'currentState': array([5.66709297, 5.65246568]), 'targetState': array([0.08672432, 0.19391369]), 'effectorPosition': array([ 1.13448888, -1.52582491])}
episode index:1206
target Thresh 1.838655481710803
current state at start:  [ 3.95777745 -2.33711835]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.95777745, -2.33711835]), 'currentState': array([4.24509038, 4.15223253]), 'targetState': array([-0.14423613, -0.19016176]), 'effectorPosition': array([-0.96747511, -0.03680243])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2902204326603722
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.95777745, -2.33711835]), 'currentState': array([5.78230442, 5.16284557]), 'targetState': array([-0.14423613, -0.19016176]), 'effectorPosition': array([ 0.82675697, -1.47892737])}
episode index:1207
target Thresh 1.8389778482733632
current state at start:  [ 2.95320007 -1.77076299]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.95320007, -1.77076299]), 'currentState': array([3.43352466, 4.94321885]), 'targetState': array([-0.60185342,  0.68343835]), 'effectorPosition': array([-1.45696468,  0.57864052])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.28998018395783876
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.95320007, -1.77076299]), 'currentState': array([5.29648763, 6.25497808]), 'targetState': array([-0.60185342,  0.68343835]), 'effectorPosition': array([ 1.0791484 , -1.68363985])}
episode index:1208
target Thresh 1.8392995707471018
current state at start:  [-3.31211752  2.59037874]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.31211752,  2.59037874]), 'currentState': array([3.32956359, 3.09037874]), 'targetState': array([ 0.01356804, -0.85778651]), 'effectorPosition': array([ 0.0082779 , -0.05053482])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2897403326890564
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.31211752,  2.59037874]), 'currentState': array([3.70024342, 4.04036557]), 'targetState': array([ 0.01356804, -0.85778651]), 'effectorPosition': array([-0.7348411 ,  0.46353763])}
episode index:1209
target Thresh 1.8396206504189094
current state at start:  [1.56262946 2.53572835]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.56262946, 2.53572835]), 'currentState': array([2.01204687, 2.03572835]), 'targetState': array([ 0.09837429, -0.53924153]), 'effectorPosition': array([-1.04382571,  0.11706325])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2895008778686522
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.56262946, 2.53572835]), 'currentState': array([4.19402589, 3.64271942]), 'targetState': array([ 0.09837429, -0.53924153]), 'effectorPosition': array([-0.47822346,  0.13122009])}
episode index:1210
target Thresh 1.8399410885731045
current state at start:  [ 1.82249566 -1.61608525]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.82249566, -1.61608525]), 'currentState': array([2.32249566, 5.05389158]), 'targetState': array([-0.01118502,  0.39258054]), 'effectorPosition': array([-0.22323708,  1.6186327 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.289261818514508
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.82249566, -1.61608525]), 'currentState': array([5.10393637, 0.08206723]), 'targetState': array([-0.01118502,  0.39258054]), 'effectorPosition': array([ 0.83772516, -1.81424511])}
episode index:1211
target Thresh 1.8402608864914407
current state at start:  [-0.80905583 -2.569503  ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.80905583, -2.569503  ]), 'currentState': array([5.77001209, 4.15738015]), 'targetState': array([-0.45958009,  0.31131397]), 'effectorPosition': array([-0.00513518, -0.97266234])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.28902315364774683
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.80905583, -2.569503  ]), 'currentState': array([5.39779331, 5.91164728]), 'targetState': array([-0.45958009,  0.31131397]), 'effectorPosition': array([ 0.94172443, -1.72531019])}
episode index:1212
target Thresh 1.8405800454531098
current state at start:  [ 0.08841406 -2.05202626]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.08841406, -2.05202626]), 'currentState': array([0.00740658, 4.73010464]), 'targetState': array([-0.12857767, -0.29712142]), 'effectorPosition': array([ 1.02509217, -0.99227794])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.28878488229271987
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.08841406, -2.05202626]), 'currentState': array([5.89396117, 5.01333249]), 'targetState': array([-0.12857767, -0.29712142]), 'effectorPosition': array([ 0.83703776, -1.37557649])}
episode index:1213
target Thresh 1.8408985667347484
current state at start:  [1.88722681 2.2287999 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.88722681, 2.2287999 ]), 'currentState': array([2.22223123, 1.74485352]), 'targetState': array([-0.45367926,  0.49330228]), 'effectorPosition': array([-1.2845235 ,  0.06033299])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.28854700347699275
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.88722681, 2.2287999 ]), 'currentState': array([5.3873409 , 6.04500637]), 'targetState': array([-0.45367926,  0.49330228]), 'effectorPosition': array([ 1.04787738, -1.68685846])}
episode index:1214
target Thresh 1.8412164516104415
current state at start:  [-1.0926193  -2.39119653]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.0926193 , -2.39119653]), 'currentState': array([5.66461227, 4.32634391]), 'targetState': array([-0.55739565, -0.61634976]), 'effectorPosition': array([-0.02925043, -1.11628375])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.28830951623133266
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.0926193 , -2.39119653]), 'currentState': array([6.17100845, 5.22505295]), 'targetState': array([-0.55739565, -0.61634976]), 'effectorPosition': array([ 1.38358172, -1.03281294])}
episode index:1215
target Thresh 1.8415337013517294
current state at start:  [-1.29916497 -2.07625382]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.29916497, -2.07625382]), 'currentState': array([5.44647454, 4.65285592]), 'targetState': array([-0.19642495, -0.00050613]), 'effectorPosition': array([-0.111078  , -1.36699154])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.28807241958969504
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.29916497, -2.07625382]), 'currentState': array([5.83823427, 5.78875185]), 'targetState': array([-0.19642495, -0.00050613]), 'effectorPosition': array([ 1.49291671, -1.23760862])}
episode index:1216
target Thresh 1.8418503172276115
current state at start:  [ 1.98520823 -2.44642688]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.98520823, -2.44642688]), 'currentState': array([2.48520823, 4.33675843]), 'targetState': array([0.26133221, 0.47849579]), 'effectorPosition': array([0.06613077, 1.12334694])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2878357125892105
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.98520823, -2.44642688]), 'currentState': array([4.34666461, 5.88018815]), 'targetState': array([0.26133221, 0.47849579]), 'effectorPosition': array([-1.0528427 , -1.65266502])}
episode index:1217
target Thresh 1.8421663005045517
current state at start:  [-3.50911235  2.2791747 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.50911235,  2.2791747 ]), 'currentState': array([3.27407296, 1.84869082]), 'targetState': array([-0.5129264 ,  0.30917918]), 'effectorPosition': array([-0.59228427, -1.04906448])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2875993942701717
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.50911235,  2.2791747 ]), 'currentState': array([3.2999888 , 5.62128214]), 'targetState': array([-0.5129264 ,  0.30917918]), 'effectorPosition': array([-1.86337735,  0.32476566])}
episode index:1218
target Thresh 1.842481652446483
current state at start:  [-1.27561322  2.20580473]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.27561322,  2.20580473]), 'currentState': array([4.57155135, 1.78351455]), 'targetState': array([1.18351572, 0.5520235 ]), 'effectorPosition': array([ 0.8570452 , -0.91828005])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.28736346367602067
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.27561322,  2.20580473]), 'currentState': array([4.5317587 , 5.70464207]), 'targetState': array([1.18351572, 0.5520235 ]), 'effectorPosition': array([-0.86797179, -1.7091358 ])}
episode index:1219
target Thresh 1.8427963743148146
current state at start:  [ 0.03062342 -2.2935327 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.03062342, -2.2935327 ]), 'currentState': array([0.53062342, 3.5846741 ]), 'targetState': array([ 0.00910116, -1.41053365]), 'effectorPosition': array([ 0.30025217, -0.32090327])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2871279198533354
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.03062342, -2.2935327 ]), 'currentState': array([3.57818257, 3.85225781]), 'targetState': array([ 0.00910116, -1.41053365]), 'effectorPosition': array([-0.49520752,  0.48878752])}
episode index:1220
target Thresh 1.8431104673684335
current state at start:  [-2.57651956  2.98556549]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.57651956,  2.98556549]), 'currentState': array([4.20666575, 2.48556549]), 'targetState': array([-0.23376573,  0.04023822]), 'effectorPosition': array([ 0.43306044, -0.47709019])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2868927618518175
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.57651956,  2.98556549]), 'currentState': array([1.17433439, 5.44875933]), 'targetState': array([-0.23376573,  0.04023822]), 'effectorPosition': array([1.32894234, 1.25583376])}
episode index:1221
target Thresh 1.843423932863713
current state at start:  [ 4.15001766 -2.88393386]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.15001766, -2.88393386]), 'currentState': array([3.67608465, 3.7547305 ]), 'targetState': array([-0.31118639, -0.50554976]), 'effectorPosition': array([-0.44987784,  0.40238925])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2866579887242792
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 4.15001766, -2.88393386]), 'currentState': array([3.91827792, 4.50767455]), 'targetState': array([-0.31118639, -0.50554976]), 'effectorPosition': array([-1.25453106,  0.13991674])}
episode index:1222
target Thresh 1.843736772054515
current state at start:  [-4.11450251  2.1439095 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.11450251,  2.1439095 ]), 'currentState': array([2.6686828 , 2.32611374]), 'targetState': array([-0.62750543,  0.53298778]), 'effectorPosition': array([-0.61157804, -0.50490861])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2864235995266306
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-4.11450251,  2.1439095 ]), 'currentState': array([5.34029884, 6.02805596]), 'targetState': array([-0.62750543,  0.53298778]), 'effectorPosition': array([ 0.95166096, -1.7405754 ])}
episode index:1223
target Thresh 1.844048986192197
current state at start:  [-0.52455795  2.21023786]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.52455795,  2.21023786]), 'currentState': array([6.25862736, 1.72043547]), 'targetState': array([ 0.98732494, -0.04721924]), 'effectorPosition': array([0.87494318, 0.96763206])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.28618959331786703
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.52455795,  2.21023786]), 'currentState': array([4.52075464, 5.94921205]), 'targetState': array([ 0.98732494, -0.04721924]), 'effectorPosition': array([-0.69220225, -1.84671351])}
episode index:1224
target Thresh 1.8443605765256157
current state at start:  [-1.54125888 -2.13588796]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.54125888, -2.13588796]), 'currentState': array([4.93767512, 4.64729734]), 'targetState': array([-0.04911622, -0.37523372]), 'effectorPosition': array([-0.763811  , -1.13424045])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2859559691600565
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.54125888, -2.13588796]), 'currentState': array([3.93839083, 3.91405713]), 'targetState': array([-0.04911622, -0.37523372]), 'effectorPosition': array([-0.69746631,  0.28487714])}
episode index:1225
target Thresh 1.844671544301133
current state at start:  [-2.11650801 -1.79920454]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.11650801, -1.79920454]), 'currentState': array([4.66667729, 4.9561186 ]), 'targetState': array([-0.32549486,  0.01071465]), 'effectorPosition': array([-1.0261542 , -1.19568179])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2857227261183273
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.11650801, -1.79920454]), 'currentState': array([5.84942362, 6.00874102]), 'targetState': array([-0.32549486,  0.01071465]), 'effectorPosition': array([ 1.66692125, -1.07075929])}
episode index:1226
target Thresh 1.8449818907626205
current state at start:  [-0.83484724  2.46722124]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.83484724,  2.46722124]), 'currentState': array([5.39290586, 1.98867155]), 'targetState': array([0.02617212, 0.00090665]), 'effectorPosition': array([1.08422335, 0.11322927])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2854898632608551
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.83484724,  2.46722124]), 'currentState': array([5.96864556, 5.44636115]), 'targetState': array([0.02617212, 0.00090665]), 'effectorPosition': array([ 1.358181  , -1.22269907])}
episode index:1227
target Thresh 1.8452916171514644
current state at start:  [ 3.9286261  -2.05598218]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.9286261 , -2.05598218]), 'currentState': array([3.4286261 , 4.25239353]), 'targetState': array([-1.35371758, -0.22459282]), 'effectorPosition': array([-0.78698704,  0.70197103])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2852573796588512
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.9286261 , -2.05598218]), 'currentState': array([2.55360806, 5.83014598]), 'targetState': array([-1.35371758, -0.22459282]), 'effectorPosition': array([-1.33739724,  1.41760732])}
episode index:1228
target Thresh 1.8456007247065704
current state at start:  [-1.63035865  2.49463884]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.63035865,  2.49463884]), 'currentState': array([4.22235166, 2.2294601 ]), 'targetState': array([ 0.66538873, -0.36821716]), 'effectorPosition': array([ 0.5151574 , -0.71448685])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.2858389440366715
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.63035865,  2.49463884]), 'currentState': array([4.22235166, 2.2294601 ]), 'targetState': array([ 0.66538873, -0.36821716]), 'effectorPosition': array([ 0.5151574 , -0.71448685])}
episode index:1229
target Thresh 1.8459092146643696
current state at start:  [1.38047427 2.22520445]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.38047427, 2.22520445]), 'currentState': array([0.8953475 , 1.75729118]), 'targetState': array([-1.0027869 ,  0.19669383]), 'effectorPosition': array([-0.25757701,  1.25012909])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2856065546512758
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.38047427, 2.22520445]), 'currentState': array([4.85143027, 0.47451865]), 'targetState': array([-1.0027869 ,  0.19669383]), 'effectorPosition': array([ 0.71437544, -1.80795278])}
episode index:1230
target Thresh 1.8462170882588218
current state at start:  [ 1.81566047 -2.69265278]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.81566047, -2.69265278]), 'currentState': array([2.23911431, 4.04327046]), 'targetState': array([ 0.01745278, -0.04787221]), 'effectorPosition': array([0.38033297, 0.78406453])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.28537454282783853
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.81566047, -2.69265278]), 'currentState': array([6.10321312, 5.37692448]), 'targetState': array([ 0.01745278, -0.04787221]), 'effectorPosition': array([ 1.44967066, -1.06388066])}
episode index:1231
target Thresh 1.846524346721422
current state at start:  [ 2.19326327 -2.03557145]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.19326327, -2.03557145]), 'currentState': array([2.69326327, 4.70189909]), 'targetState': array([0.4304971 , 1.21764647]), 'effectorPosition': array([-0.4582827 ,  1.33003668])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.28514290764697175
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.19326327, -2.03557145]), 'currentState': array([5.11415039, 5.62496115]), 'targetState': array([0.4304971 , 1.21764647]), 'effectorPosition': array([ 0.13737953, -1.88766693])}
episode index:1232
target Thresh 1.8468309912812046
current state at start:  [ 2.42956343 -2.18784243]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.42956343, -2.18784243]), 'currentState': array([2.90918493, 4.56394577]), 'targetState': array([-0.41769189,  0.6258637 ]), 'effectorPosition': array([-0.6014041 ,  1.15866985])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2849116481922702
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.42956343, -2.18784243]), 'currentState': array([5.2175009 , 6.12285138]), 'targetState': array([-0.41769189,  0.6258637 ]), 'effectorPosition': array([ 0.82189313, -1.81627083])}
episode index:1233
target Thresh 1.8471370231647481
current state at start:  [-0.9610167  -3.02676559]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.9610167 , -3.02676559]), 'currentState': array([5.60286563, 3.75641971]), 'targetState': array([0.03348425, 0.1974736 ]), 'effectorPosition': array([-0.22048446, -0.56359576])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2846807635502992
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.9610167 , -3.02676559]), 'currentState': array([4.48344204, 5.54342729]), 'targetState': array([0.03348425, 0.1974736 ]), 'effectorPosition': array([-1.05110501, -1.54027325])}
episode index:1234
target Thresh 1.8474424435961803
current state at start:  [ 1.36901121 -3.04602984]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.36901121, -3.04602984]), 'currentState': array([0.86901121, 3.73715547]), 'targetState': array([-0.37939901,  0.01295695]), 'effectorPosition': array([ 0.53955933, -0.23067275])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2844502528105824
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.36901121, -3.04602984]), 'currentState': array([0.42783482, 5.66390437]), 'targetState': array([-0.37939901,  0.01295695]), 'effectorPosition': array([1.89159631, 0.22462296])}
episode index:1235
target Thresh 1.8477472537971835
current state at start:  [1.33807294 2.68817209]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.33807294, 2.68817209]), 'currentState': array([1.75636886, 2.18817209]), 'targetState': array([0.2491371 , 0.01942311]), 'effectorPosition': array([-0.87909797,  0.26342371])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.28422011506559
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.33807294, 2.68817209]), 'currentState': array([5.9100447 , 5.72856118]), 'targetState': array([0.2491371 , 0.01942311]), 'effectorPosition': array([ 1.53081139, -1.16482333])}
episode index:1236
target Thresh 1.848051454986999
current state at start:  [ 3.48030104 -2.05238422]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.48030104, -2.05238422]), 'currentState': array([3.89414541, 4.41153609]), 'targetState': array([-0.74846676,  1.16406464]), 'effectorPosition': array([-1.16644198,  0.21620205])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2839903494107269
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.48030104, -2.05238422]), 'currentState': array([5.35591704, 2.07573126]), 'targetState': array([-0.74846676,  1.16406464]), 'effectorPosition': array([1.00991145, 0.11215118])}
episode index:1237
target Thresh 1.8483550483824318
current state at start:  [ 3.50790307 -2.32860606]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.50790307, -2.32860606]), 'currentState': array([4.00790307, 4.39835663]), 'targetState': array([-0.05152101,  0.14574535]), 'effectorPosition': array([-1.17227019,  0.089387  ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.28376095494432085
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.50790307, -2.32860606]), 'currentState': array([5.88010024, 5.3845788 ]), 'targetState': array([-0.05152101,  0.14574535]), 'effectorPosition': array([ 1.18572374, -1.35626732])}
episode index:1238
target Thresh 1.8486580351978559
current state at start:  [ 4.19540359 -2.85153319]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.19540359, -2.85153319]), 'currentState': array([4.69540359, 2.94506776]), 'targetState': array([-1.0712935 ,  0.45397225]), 'effectorPosition': array([ 0.1949072 , -0.02256262])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.28353193076761035
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 4.19540359, -2.85153319]), 'currentState': array([5.2946535 , 0.59140492]), 'targetState': array([-1.0712935 ,  0.45397225]), 'effectorPosition': array([ 1.47209275, -1.22198992])}
episode index:1239
target Thresh 1.848960416645219
current state at start:  [ 2.3666353  -2.73805588]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.3666353 , -2.73805588]), 'currentState': array([2.77958123, 3.75510262]), 'targetState': array([ 0.79337996, -0.35575735]), 'effectorPosition': array([0.03335423, 0.60301165])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.28330327598473326
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.3666353 , -2.73805588]), 'currentState': array([4.14275501, 3.0943272 ]), 'targetState': array([ 0.79337996, -0.35575735]), 'effectorPosition': array([ 0.03918503, -0.02642235])}
episode index:1240
target Thresh 1.8492621939340472
current state at start:  [-0.11650647 -2.39745934]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.11650647, -2.39745934]), 'currentState': array([5.66667884, 3.93691574]), 'targetState': array([ 0.80386048, -0.04867336]), 'effectorPosition': array([-0.16815152, -0.7560535 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.28307498970271494
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.11650647, -2.39745934]), 'currentState': array([4.8366967 , 6.10335259]), 'targetState': array([ 0.80386048, -0.04867336]), 'effectorPosition': array([ 0.06849135, -1.99074262])}
episode index:1241
target Thresh 1.8495633682714503
current state at start:  [1.61305386 2.69966977]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.61305386, 2.69966977]), 'currentState': array([2.11305386, 2.207143  ]), 'targetState': array([ 0.33441921, -0.48667829]), 'effectorPosition': array([-0.898286 , -0.0675276])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.28284707103145673
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.61305386, 2.69966977]), 'currentState': array([4.35296236, 3.71199485]), 'targetState': array([ 0.33441921, -0.48667829]), 'effectorPosition': array([-0.5611515 ,  0.04172842])}
episode index:1242
target Thresh 1.8498639408621258
current state at start:  [ 2.66757144 -2.42395368]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.66757144, -2.42395368]), 'currentState': array([3.16757144, 4.35923163]), 'targetState': array([0.47161112, 1.10901127]), 'effectorPosition': array([-0.67829002,  0.92097698])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.28261951908372424
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.66757144, -2.42395368]), 'currentState': array([3.97363146, 0.42358146]), 'targetState': array([0.47161112, 1.10901127]), 'effectorPosition': array([-0.98335373, -1.69004759])}
episode index:1243
target Thresh 1.8501639129083647
current state at start:  [-0.46448986  2.81283694]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.46448986,  2.81283694]), 'currentState': array([5.51103477, 3.31283694]), 'targetState': array([0.95395418, 0.57610069]), 'effectorPosition': array([-0.10841162, -0.13228732])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.28239233297513605
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.46448986,  2.81283694]), 'currentState': array([5.25907654, 5.72086735]), 'targetState': array([0.95395418, 0.57610069]), 'effectorPosition': array([ 0.50423067, -1.85412906])}
episode index:1244
target Thresh 1.8504632856100554
current state at start:  [-1.20305721 -2.23009674]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.20305721, -2.23009674]), 'currentState': array([4.7129527 , 3.74476081]), 'targetState': array([-0.16701583, -0.82886228]), 'effectorPosition': array([-0.56715486, -0.17677714])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.282165511824152
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.20305721, -2.23009674]), 'currentState': array([4.00819739, 4.32498726]), 'targetState': array([-0.16701583, -0.82886228]), 'effectorPosition': array([-1.10849003,  0.12522749])}
episode index:1245
target Thresh 1.8507620601646892
current state at start:  [ 0.96763426 -2.66404099]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.96763426, -2.66404099]), 'currentState': array([0.46763426, 4.08587977]), 'targetState': array([0.43546772, 0.13740528]), 'effectorPosition': array([ 0.73442978, -0.5366301 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.281939054752062
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.96763426, -2.66404099]), 'currentState': array([5.32116985, 4.68954671]), 'targetState': array([0.43546772, 0.13740528]), 'effectorPosition': array([-0.26132564, -1.37332747])}
episode index:1246
target Thresh 1.8510602377673646
current state at start:  [ 3.08518176 -2.22735336]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.08518176, -2.22735336]), 'currentState': array([3.51595973, 4.51406304]), 'targetState': array([-0.67483597,  0.038557  ]), 'effectorPosition': array([-1.10587253,  0.61886122])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.28171296088297454
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.08518176, -2.22735336]), 'currentState': array([5.9281215 , 5.61066564]), 'targetState': array([-0.67483597,  0.038557  ]), 'effectorPosition': array([ 1.45451334, -1.2037026 ])}
episode index:1247
target Thresh 1.8513578196107925
current state at start:  [0.58055552 2.50908143]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.58055552, 2.50908143]), 'currentState': array([1.08055552, 2.01134301]), 'targetState': array([ 0.19386742, -0.1407737 ]), 'effectorPosition': array([-0.52792715,  0.93189318])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2814872293438055
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.58055552, 2.50908143]), 'currentState': array([5.16939555, 0.00628781]), 'targetState': array([ 0.19386742, -0.1407737 ]), 'effectorPosition': array([ 0.88816147, -1.79196252])}
episode index:1248
target Thresh 1.8516548068853007
current state at start:  [ 3.97928955 -2.31435853]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.97928955, -2.31435853]), 'currentState': array([3.47928955, 4.22746191]), 'targetState': array([-0.97962685, -0.2267471 ]), 'effectorPosition': array([-0.79682138,  0.65786625])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2812618592642668
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.97928955, -2.31435853]), 'currentState': array([5.65283544, 0.08986421]), 'targetState': array([-0.97962685, -0.2267471 ]), 'effectorPosition': array([ 1.66528023, -1.1039799 ])}
episode index:1249
target Thresh 1.8519512007788386
current state at start:  [-0.61573876  2.19110845]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.61573876,  2.19110845]), 'currentState': array([5.16744655, 1.69110845]), 'targetState': array([0.15562632, 0.18310016]), 'effectorPosition': array([ 1.27850522, -0.35409073])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.28103684977685534
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.61573876,  2.19110845]), 'currentState': array([5.69744326, 6.05196834]), 'targetState': array([0.15562632, 0.18310016]), 'effectorPosition': array([ 1.51774356, -1.28188571])}
episode index:1250
target Thresh 1.8522470024769822
current state at start:  [ 3.82403274 -2.27026958]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.82403274, -2.27026958]), 'currentState': array([3.45969351, 4.39583542]), 'targetState': array([-0.49526572, -0.26505608]), 'effectorPosition': array([-0.95137841,  0.68723554])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2808122000168419
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.82403274, -2.27026958]), 'currentState': array([5.86860422, 5.8745923 ]), 'targetState': array([-0.49526572, -0.26505608]), 'effectorPosition': array([ 1.59518219, -1.13611412])}
episode index:1251
target Thresh 1.8525422131629385
current state at start:  [ 1.76981709 -1.69125765]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.76981709, -1.69125765]), 'currentState': array([2.26981709, 5.09192766]), 'targetState': array([0.15985133, 0.57356259]), 'effectorPosition': array([-0.17087003,  1.64675058])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2805879091222597
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.76981709, -1.69125765]), 'currentState': array([4.82875966, 4.87230938]), 'targetState': array([0.15985133, 0.57356259]), 'effectorPosition': array([-0.8459656 , -1.26602584])}
episode index:1252
target Thresh 1.8528368340175512
current state at start:  [-2.04430832  2.56927968]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.04430832,  2.56927968]), 'currentState': array([4.73520743, 2.06927968]), 'targetState': array([0.01847818, 0.00583996]), 'effectorPosition': array([ 0.88998807, -0.50173023])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.280363976233894
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.04430832,  2.56927968]), 'currentState': array([5.76118931, 5.64912839]), 'targetState': array([0.01847818, 0.00583996]), 'effectorPosition': array([ 1.2697808 , -1.41383105])}
episode index:1253
target Thresh 1.8531308662193036
current state at start:  [ 3.93654077 -2.75403904]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.93654077, -2.75403904]), 'currentState': array([4.41500824, 3.94769917]), 'targetState': array([ 0.1020446 , -0.21602111]), 'effectorPosition': array([-0.7800817 , -0.08274141])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2801404004952705
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.93654077, -2.75403904]), 'currentState': array([5.78915348, 5.87439578]), 'targetState': array([ 0.1020446 , -0.21602111]), 'effectorPosition': array([ 1.49982567, -1.25925704])}
episode index:1254
target Thresh 1.8534243109443251
current state at start:  [ 2.31983663 -3.00817472]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.31983663, -3.00817472]), 'currentState': array([2.81909491, 3.51622729]), 'targetState': array([-0.08572182,  0.54458559]), 'effectorPosition': array([0.05019443, 0.3690498 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.2807139938016488
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.31983663, -3.00817472]), 'currentState': array([2.81909491, 3.51622729]), 'targetState': array([-0.08572182,  0.54458559]), 'effectorPosition': array([0.05019443, 0.3690498 ])}
episode index:1255
target Thresh 1.853717169366395
current state at start:  [-3.22061805  2.25298885]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.22061805,  2.25298885]), 'currentState': array([3.56256726, 2.17740603]), 'targetState': array([-0.84671189, -0.25956033]), 'effectorPosition': array([-0.05663825, -0.92553847])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2804904953989405
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.22061805,  2.25298885]), 'currentState': array([5.84351764, 5.93195641]), 'targetState': array([-0.84671189, -0.25956033]), 'effectorPosition': array([ 1.60810132, -1.13662279])}
episode index:1256
target Thresh 1.8540094426569471
current state at start:  [-0.10804297 -2.53167691]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.10804297, -2.53167691]), 'currentState': array([0.22987993, 4.20904527]), 'targetState': array([-0.80214302, -0.15832149]), 'effectorPosition': array([ 0.70362564, -0.7349806 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.28026735260228264
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.10804297, -2.53167691]), 'currentState': array([5.77319836, 5.69534874]), 'targetState': array([-0.80214302, -0.15832149]), 'effectorPosition': array([ 1.32828562, -1.37838386])}
episode index:1257
target Thresh 1.8543011319850753
current state at start:  [1.04611672 2.72314895]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.04611672, 2.72314895]), 'currentState': array([0.79576943, 2.22314895]), 'targetState': array([-0.54040535, -0.34891621]), 'effectorPosition': array([-0.29274965,  0.83676903])}
done in step count: 35
reward sum = 0.7034476949995692
running average episode reward sum: 0.2806037439714379
{'reset': False, 'endBeforeDone': False, 'stepCount': 36, 'initial state': array([1.04611672, 2.72314895]), 'currentState': array([4.05873527, 4.1896413 ]), 'targetState': array([-0.54040535, -0.34891621]), 'effectorPosition': array([-0.99234066,  0.12936192])}
episode index:1258
target Thresh 1.8545922385175373
current state at start:  [2.10711729 1.89004809]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.10711729, 1.89004809]), 'currentState': array([1.68790653, 2.03840297]), 'targetState': array([-1.26468536,  0.41700212]), 'effectorPosition': array([-0.9507111 ,  0.44118714])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.28117514687535256
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.10711729, 1.89004809]), 'currentState': array([1.68790653, 2.03840297]), 'targetState': array([-1.26468536,  0.41700212]), 'effectorPosition': array([-0.9507111 ,  0.44118714])}
episode index:1259
target Thresh 1.8548827634187592
current state at start:  [ 1.03605481 -2.80715329]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.03605481, -2.80715329]), 'currentState': array([0.56727087, 3.94570875]), 'targetState': array([0.00531473, 0.75054585]), 'effectorPosition': array([ 0.64528014, -0.44285137])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.28095199199688003
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.03605481, -2.80715329]), 'currentState': array([5.10522746, 5.68183378]), 'targetState': array([0.00531473, 0.75054585]), 'effectorPosition': array([ 0.17580684, -1.90216598])}
episode index:1260
target Thresh 1.8551727078508415
current state at start:  [ 4.17294046 -2.22364379]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.17294046, -2.22364379]), 'currentState': array([4.65542328, 4.32753002]), 'targetState': array([-0.28356879, -0.13559239]), 'effectorPosition': array([-0.96090785, -0.57078827])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.280729191051601
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 4.17294046, -2.22364379]), 'currentState': array([5.79013408, 6.05331189]), 'targetState': array([-0.28356879, -0.13559239]), 'effectorPosition': array([ 1.63076682, -1.1348965 ])}
episode index:1261
target Thresh 1.8554620729735622
current state at start:  [ 1.85730108 -2.13561675]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.85730108, -2.13561675]), 'currentState': array([2.35730108, 4.57642115]), 'targetState': array([-0.01002698,  0.31041667]), 'effectorPosition': array([0.08786992, 1.31193762])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.28050674319815283
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.85730108, -2.13561675]), 'currentState': array([5.85210545, 5.55427391]), 'targetState': array([-0.01002698,  0.31041667]), 'effectorPosition': array([ 1.30786262, -1.33465172])}
episode index:1262
target Thresh 1.855750859944382
current state at start:  [-2.56858526  1.85791248]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.56858526,  1.85791248]), 'currentState': array([3.27603205, 1.35791248]), 'targetState': array([ 0.61168774, -0.89920057]), 'effectorPosition': array([-1.06934065, -1.1309596 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.28028464759783756
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.56858526,  1.85791248]), 'currentState': array([4.23803496, 3.20448822]), 'targetState': array([ 0.61168774, -0.89920057]), 'effectorPosition': array([-0.0568174 ,  0.02695053])}
episode index:1263
target Thresh 1.856039069918449
current state at start:  [-1.4712603   2.17288894]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.4712603 ,  2.17288894]), 'currentState': array([4.37086866, 1.7170291 ]), 'targetState': array([1.04601134, 0.01637212]), 'effectorPosition': array([ 0.64607192, -1.13629519])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.28006290341461143
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.4712603 ,  2.17288894]), 'currentState': array([4.12424038, 5.44845843]), 'targetState': array([1.04601134, 0.01637212]), 'effectorPosition': array([-1.54390131, -0.97935131])}
episode index:1264
target Thresh 1.856326704048604
current state at start:  [-0.99220151  1.86052632]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.99220151,  1.86052632]), 'currentState': array([4.7909838 , 1.36052632]), 'targetState': array([0.2717795 , 0.10594005]), 'effectorPosition': array([ 1.06985727, -1.12820802])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2798415098150742
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.99220151,  1.86052632]), 'currentState': array([5.45725287, 4.7418084 ]), 'targetState': array([0.2717795 , 0.10594005]), 'effectorPosition': array([-0.03705058, -1.43438405])}
episode index:1265
target Thresh 1.8566137634853837
current state at start:  [ 1.45473696 -1.66407911]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.45473696, -1.66407911]), 'currentState': array([1.95473696, 5.04182943]), 'targetState': array([0.23484603, 0.30702945]), 'effectorPosition': array([0.38157654, 1.58158989])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2796204659684588
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.45473696, -1.66407911]), 'currentState': array([4.73039389, 0.20890758]), 'targetState': array([0.23484603, 0.30702945]), 'effectorPosition': array([ 0.24297418, -1.97420355])}
episode index:1266
target Thresh 1.856900249377026
current state at start:  [0.63351922 1.61657024]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.63351922, 1.61657024]), 'currentState': array([1.13351922, 1.2443721 ]), 'targetState': array([-0.2139494 ,  0.59226587]), 'effectorPosition': array([-0.29880678,  1.59750767])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.27939977104662106
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.63351922, 1.61657024]), 'currentState': array([5.3764059 , 4.32427574]), 'targetState': array([-0.2139494 ,  0.59226587]), 'effectorPosition': array([-0.34589418, -1.05993957])}
episode index:1267
target Thresh 1.8571861628694748
current state at start:  [-2.73500909  2.2268684 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.73500909,  2.2268684 ]), 'currentState': array([3.98881121, 1.90495719]), 'targetState': array([-0.42523255, -0.73066123]), 'effectorPosition': array([ 0.26306036, -1.12909084])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2791794242240291
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.73500909,  2.2268684 ]), 'currentState': array([5.88152868, 5.59762814]), 'targetState': array([-0.42523255, -0.73066123]), 'effectorPosition': array([ 1.3853685 , -1.27627856])}
episode index:1268
target Thresh 1.857471505106385
current state at start:  [-0.5482339   2.26546114]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.5482339 ,  2.26546114]), 'currentState': array([6.2349514 , 1.76546114]), 'targetState': array([ 0.0401937, -0.2614371]), 'effectorPosition': array([0.8529288 , 0.94108293])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.27895942467775325
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.5482339 ,  2.26546114]), 'currentState': array([5.85462407, 5.76733192]), 'targetState': array([ 0.0401937, -0.2614371]), 'effectorPosition': array([ 1.49578181, -1.2257165 ])}
episode index:1269
target Thresh 1.8577562772291254
current state at start:  [-3.8791836   2.54183524]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.8791836 ,  2.54183524]), 'currentState': array([1.90400171, 2.38462682]), 'targetState': array([-0.65066737, -0.98781044]), 'effectorPosition': array([-0.73826498,  0.03344968])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2787397715874558
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.8791836 ,  2.54183524]), 'currentState': array([3.06642332, 4.48100857]), 'targetState': array([-0.65066737, -0.98781044]), 'effectorPosition': array([-0.69540508,  1.02847899])}
episode index:1270
target Thresh 1.8580404803767852
current state at start:  [1.55429261 1.94482409]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.55429261, 1.94482409]), 'currentState': array([2.01073711, 1.44482409]), 'targetState': array([-0.02482668,  0.03018379]), 'effectorPosition': array([-1.37700132,  0.59594127])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2785204641353807
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.55429261, 1.94482409]), 'currentState': array([6.07061687, 5.48012396]), 'targetState': array([-0.02482668,  0.03018379]), 'effectorPosition': array([ 1.50457711, -1.06078388])}
episode index:1271
target Thresh 1.858324115686177
current state at start:  [1.48185212 1.94660287]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.48185212, 1.94660287]), 'currentState': array([1.98185212, 1.44660287]), 'targetState': array([0.02402923, 0.03820084]), 'effectorPosition': array([-1.35871377,  0.6337553 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2783015015063434
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.48185212, 1.94660287]), 'currentState': array([5.63633774, 5.08684307]), 'targetState': array([0.02402923, 0.03820084]), 'effectorPosition': array([ 0.52895022, -1.56580352])}
episode index:1272
target Thresh 1.8586071842918428
current state at start:  [0.26463318 1.77283938]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.26463318, 1.77283938]), 'currentState': array([0.71200282, 1.29308809]), 'targetState': array([0.31189717, 0.51014417]), 'effectorPosition': array([0.33628428, 1.56051841])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.278082882887721
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.26463318, 1.77283938]), 'currentState': array([4.75914313, 4.93214821]), 'targetState': array([0.31189717, 0.51014417]), 'effectorPosition': array([-0.91795791, -1.26227674])}
episode index:1273
target Thresh 1.8588896873260572
current state at start:  [ 0.85012172 -1.60993052]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.85012172, -1.60993052]), 'currentState': array([0.35012172, 5.16543465]), 'targetState': array([0.88815772, 0.8026948 ]), 'effectorPosition': array([ 1.6588902 , -0.35141893])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.27786460746944175
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.85012172, -1.60993052]), 'currentState': array([5.47065913, 5.53995484]), 'targetState': array([0.88815772, 0.8026948 ]), 'effectorPosition': array([ 0.70270567, -1.72591356])}
episode index:1274
target Thresh 1.859171625918833
current state at start:  [-0.32417338  1.93403849]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.32417338,  1.93403849]), 'currentState': array([5.46394272, 1.43618468]), 'targetState': array([0.07810077, 0.60645242]), 'effectorPosition': array([ 1.49842619, -0.15208522])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2776466744439755
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.32417338,  1.93403849]), 'currentState': array([5.35302666, 4.10899546]), 'targetState': array([0.07810077, 0.60645242]), 'effectorPosition': array([-0.40159972, -0.83895032])}
episode index:1275
target Thresh 1.8594530011979242
current state at start:  [ 1.31855965 -2.49900229]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.31855965, -2.49900229]), 'currentState': array([1.81182555, 4.24620008]), 'targetState': array([ 0.00685315, -0.05008583]), 'effectorPosition': array([0.73605625, 0.7478308 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.27742908300632346
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.31855965, -2.49900229]), 'currentState': array([5.73876106, 5.3364736 ]), 'targetState': array([ 0.00685315, -0.05008583]), 'effectorPosition': array([ 0.93500177, -1.51475446])}
episode index:1276
target Thresh 1.859733814288833
current state at start:  [-1.17000763  2.50681971]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.17000763,  2.50681971]), 'currentState': array([4.62733184, 2.93448566]), 'targetState': array([1.10592324, 0.82364583]), 'effectorPosition': array([ 0.2030707 , -0.03876203])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2772118323540084
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.17000763,  2.50681971]), 'currentState': array([5.34741552, 4.63331267]), 'targetState': array([1.10592324, 0.82364583]), 'effectorPosition': array([-0.25620045, -1.33280662])}
episode index:1277
target Thresh 1.8600140663148121
current state at start:  [ 3.44501492 -2.50142215]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.44501492, -2.50142215]), 'currentState': array([3.03605637, 4.14867704]), 'targetState': array([-0.61914679, -0.22444741]), 'effectorPosition': array([-0.37403966,  0.88962877])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.27699492168706474
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.44501492, -2.50142215]), 'currentState': array([1.71447994, 4.60354756]), 'targetState': array([-0.61914679, -0.22444741]), 'effectorPosition': array([0.85620334, 1.0245304 ])}
episode index:1278
target Thresh 1.86029375839687
current state at start:  [-2.64986958  1.914913  ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.64986958,  1.914913  ]), 'currentState': array([4.07979862, 1.42107466]), 'targetState': array([-0.45463678, -0.59589564]), 'effectorPosition': array([ 0.11804978, -1.51141989])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2767783502080287
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.64986958,  1.914913  ]), 'currentState': array([3.58557442, 4.2648096 ]), 'targetState': array([-0.45463678, -0.59589564]), 'effectorPosition': array([-0.8994509 ,  0.57045494])}
episode index:1279
target Thresh 1.8605728916537747
current state at start:  [-0.03796884 -2.45322759]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.03796884, -2.45322759]), 'currentState': array([0.35798887, 4.26321297]), 'targetState': array([-0.55329275,  0.00542597]), 'effectorPosition': array([ 0.84554258, -0.64545402])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2765621171219287
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.03796884, -2.45322759]), 'currentState': array([3.79402217, 4.60813858]), 'targetState': array([-0.55329275,  0.00542597]), 'effectorPosition': array([-1.31574515,  0.24635615])}
episode index:1280
target Thresh 1.8608514672020604
current state at start:  [ 0.75663126 -2.56683166]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.75663126, -2.56683166]), 'currentState': array([0.78524114, 4.18478602]), 'targetState': array([0.17325692, 0.10602893]), 'effectorPosition': array([ 0.9620152 , -0.25999872])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.27634622163627537
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.75663126, -2.56683166]), 'currentState': array([4.66036396, 5.51096699]), 'targetState': array([0.17325692, 0.10602893]), 'effectorPosition': array([-0.78603569, -1.67775958])}
episode index:1281
target Thresh 1.8611294861560292
current state at start:  [0.12220497 2.92533859]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.12220497, 2.92533859]), 'currentState': array([5.90539028, 3.38341966]), 'targetState': array([0.78837421, 0.61850409]), 'effectorPosition': array([-0.06129033, -0.23332242])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.27613066296105204
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.12220497, 2.92533859]), 'currentState': array([4.63618429, 5.4167734 ]), 'targetState': array([0.78837421, 0.61850409]), 'effectorPosition': array([-0.88522953, -1.58477078])}
episode index:1282
target Thresh 1.8614069496277579
current state at start:  [ 0.08822789 -1.62319081]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.08822789, -1.62319081]), 'currentState': array([0.22350659, 5.15067039]), 'targetState': array([ 1.11315995, -0.50444794]), 'effectorPosition': array([ 1.58965459, -0.56724437])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.27669486353551737
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.08822789, -1.62319081]), 'currentState': array([0.22350659, 5.15067039]), 'targetState': array([ 1.11315995, -0.50444794]), 'effectorPosition': array([ 1.58965459, -0.56724437])}
episode index:1283
target Thresh 1.8616838587270998
current state at start:  [0.96064967 2.10217475]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.96064967, 2.10217475]), 'currentState': array([1.46064967, 1.63219284]), 'targetState': array([-0.01781768, -0.02745768]), 'effectorPosition': array([-0.88888788,  1.04267083])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2764793690935115
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.96064967, 2.10217475]), 'currentState': array([4.79455689, 4.23745533]), 'targetState': array([-0.01781768, -0.02745768]), 'effectorPosition': array([-0.84177854, -0.6138811 ])}
episode index:1284
target Thresh 1.8619602145616925
current state at start:  [ 2.23811581 -2.48274946]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.23811581, -2.48274946]), 'currentState': array([2.73383765, 3.74987936]), 'targetState': array([-0.52328104, -0.15237163]), 'effectorPosition': array([0.06194742, 0.5957398 ])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.27701175558448937
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([ 2.23811581, -2.48274946]), 'currentState': array([4.21046238, 4.18561904]), 'targetState': array([-0.52328104, -0.15237163]), 'effectorPosition': array([-0.99705126, -0.02003006])}
episode index:1285
target Thresh 1.8622360182369593
current state at start:  [-0.13967769  2.73042268]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.13967769,  2.73042268]), 'currentState': array([5.64350761, 2.78382844]), 'targetState': array([0.04112877, 0.57684755]), 'effectorPosition': array([0.2598351, 0.2431492])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.2775739548414221
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.13967769,  2.73042268]), 'currentState': array([5.64350761, 2.78382844]), 'targetState': array([0.04112877, 0.57684755]), 'effectorPosition': array([0.2598351, 0.2431492])}
episode index:1286
target Thresh 1.8625112708561153
current state at start:  [ 0.65303101 -2.36108363]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.65303101, -2.36108363]), 'currentState': array([0.15303101, 3.44240472]), 'targetState': array([1.3375351 , 0.25200798]), 'effectorPosition': array([ 0.08954473, -0.28598838])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.27735827966283516
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.65303101, -2.36108363]), 'currentState': array([4.49228062, 0.81300869]), 'targetState': array([1.3375351 , 0.25200798]), 'effectorPosition': array([ 0.34043332, -1.80519735])}
episode index:1287
target Thresh 1.8627859735201715
current state at start:  [ 3.56533525 -2.56906364]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.56533525, -2.56906364]), 'currentState': array([4.00686923, 3.21688807]), 'targetState': array([-0.75023065,  1.06163739]), 'effectorPosition': array([-0.05910358,  0.04662069])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.27714293938359386
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.56533525, -2.56906364]), 'currentState': array([5.54758497, 3.63760097]), 'targetState': array([-0.75023065,  1.06163739]), 'effectorPosition': array([-0.23000683, -0.43372606])}
episode index:1288
target Thresh 1.8630601273279388
current state at start:  [1.30234982 2.62674298]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.30234982, 2.62674298]), 'currentState': array([1.69558801, 2.12694393]), 'targetState': array([0.01024007, 0.2497122 ]), 'effectorPosition': array([-0.9014498,  0.3627005])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.27692793322425824
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.30234982, 2.62674298]), 'currentState': array([5.36189317, 4.44539406]), 'targetState': array([0.01024007, 0.2497122 ]), 'effectorPosition': array([-0.32293935, -1.16963332])}
episode index:1289
target Thresh 1.8633337333760327
current state at start:  [-4.30800613  2.34246373]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.30800613,  2.34246373]), 'currentState': array([2.4054365 , 1.86137491]), 'targetState': array([-0.28257646, -0.22303516]), 'effectorPosition': array([-1.17203408, -0.23091752])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2767132604078053
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-4.30800613,  2.34246373]), 'currentState': array([4.24311779, 4.15001111]), 'targetState': array([-0.28257646, -0.22303516]), 'effectorPosition': array([-0.96564079, -0.03375133])}
episode index:1290
target Thresh 1.8636067927588782
current state at start:  [-2.79213907  2.22320389]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.79213907,  2.22320389]), 'currentState': array([3.99104624, 1.72320389]), 'targetState': array([-0.6635452 , -0.49955936]), 'effectorPosition': array([ 0.18208155, -1.28965494])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2764989201596195
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.79213907,  2.22320389]), 'currentState': array([3.3330065 , 4.83594972]), 'targetState': array([-0.6635452 , -0.49955936]), 'effectorPosition': array([-1.29152854,  0.76055714])}
episode index:1291
target Thresh 1.8638793065687125
current state at start:  [-0.69573762 -1.64284619]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.69573762, -1.64284619]), 'currentState': array([5.15752776, 4.7255374 ]), 'targetState': array([ 0.63649073, -1.24535299]), 'effectorPosition': array([-0.46622844, -1.34496362])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2762849117074836
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.69573762, -1.64284619]), 'currentState': array([4.51738667, 3.57420288]), 'targetState': array([ 0.63649073, -1.24535299]), 'effectorPosition': array([-0.42914722, -0.00914342])}
episode index:1292
target Thresh 1.8641512758955918
current state at start:  [-1.10300691 -2.21156027]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.10300691, -2.21156027]), 'currentState': array([5.120884  , 4.30777643]), 'targetState': array([-0.12279688, -0.01522324]), 'effectorPosition': array([-0.60276384, -0.92160214])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2760712342815691
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.10300691, -2.21156027]), 'currentState': array([4.50542869, 4.59017348]), 'targetState': array([-0.12279688, -0.01522324]), 'effectorPosition': array([-1.15179511, -0.65539687])}
episode index:1293
target Thresh 1.8644227018273936
current state at start:  [0.24614046 2.28969692]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.24614046, 2.28969692]), 'currentState': array([0.70788009, 1.78969692]), 'targetState': array([ 0.47639667, -0.06825624]), 'effectorPosition': array([-0.03994918,  1.2506362 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2758578871144272
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.24614046, 2.28969692]), 'currentState': array([3.82235731, 0.02660338]), 'targetState': array([ 0.47639667, -0.06825624]), 'effectorPosition': array([-1.53716653, -1.27922295])}
episode index:1294
target Thresh 1.8646935854498219
current state at start:  [-0.65439261  1.6186156 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.65439261,  1.6186156 ]), 'currentState': array([5.25116288, 1.1186156 ]), 'targetState': array([ 1.05695608, -0.06361991]), 'effectorPosition': array([ 1.50933712, -0.77185342])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.27564486944097977
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.65439261,  1.6186156 ]), 'currentState': array([4.06259141, 0.45744513]), 'targetState': array([ 1.05695608, -0.06361991]), 'effectorPosition': array([-0.79619372, -1.77776353])}
episode index:1295
target Thresh 1.8649639278464114
current state at start:  [-2.96599361  2.1444339 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.96599361,  2.1444339 ]), 'currentState': array([3.8171917, 1.6444339]), 'targetState': array([-0.06443211, -0.23318683]), 'effectorPosition': array([-0.09925247, -1.35757389])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.27543218049850987
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.96599361,  2.1444339 ]), 'currentState': array([5.56485648, 0.12707555]), 'targetState': array([-0.06443211, -0.23318683]), 'effectorPosition': array([ 1.58314938, -1.21552933])}
episode index:1296
target Thresh 1.8652337300985324
current state at start:  [ 1.77741111 -2.28391538]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.77741111, -2.28391538]), 'currentState': array([2.2330548 , 4.38877031]), 'targetState': array([0.42307988, 0.53998874]), 'effectorPosition': array([0.32830794, 1.12080996])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2752198195266529
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.77741111, -2.28391538]), 'currentState': array([5.58125095, 4.17844324]), 'targetState': array([0.42307988, 0.53998874]), 'effectorPosition': array([-0.18084324, -0.97438601])}
episode index:1297
target Thresh 1.8655029932853942
current state at start:  [-0.99345788 -2.02229363]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.99345788, -2.02229363]), 'currentState': array([5.75383104, 4.20406836]), 'targetState': array([-0.78346469, -0.05033706]), 'effectorPosition': array([ 0.00190845, -1.01320016])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2750077857673874
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.99345788, -2.02229363]), 'currentState': array([5.50612424, 0.16142115]), 'targetState': array([-0.78346469, -0.05033706]), 'effectorPosition': array([ 1.52938143, -1.27866813])}
episode index:1298
target Thresh 1.8657717184840497
current state at start:  [-3.63816851  2.64379308]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.63816851,  2.64379308]), 'currentState': array([3.14501679, 2.14379308]), 'targetState': array([-0.04518679, -0.11332518]), 'effectorPosition': array([-0.45496749, -0.84184286])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.274796078465026
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.63816851,  2.64379308]), 'currentState': array([4.21533735, 6.01250583]), 'targetState': array([-0.04518679, -0.11332518]), 'effectorPosition': array([-1.17134061, -1.59848054])}
episode index:1299
target Thresh 1.8660399067694
current state at start:  [-0.12562427 -2.39447624]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.12562427, -2.39447624]), 'currentState': array([0.3378452 , 4.31872281]), 'targetState': array([ 0.01683381, -0.4012499 ]), 'effectorPosition': array([ 0.88767909, -0.66698754])}
done in step count: 63
reward sum = 0.5309055429551132
running average episode reward sum: 0.27499308574540304
{'reset': False, 'endBeforeDone': False, 'stepCount': 64, 'initial state': array([-0.12562427, -2.39447624]), 'currentState': array([4.35982179, 3.62859204]), 'targetState': array([ 0.01683381, -0.4012499 ]), 'effectorPosition': array([-0.47933587,  0.05248826])}
episode index:1300
target Thresh 1.866307559214199
current state at start:  [-2.57086548  2.42304106]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.57086548,  2.42304106]), 'currentState': array([4.1962407 , 1.92304106]), 'targetState': array([ 0.00013991, -0.01392258]), 'effectorPosition': array([ 0.49306399, -1.03289726])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.27478171519525285
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.57086548,  2.42304106]), 'currentState': array([4.89693799, 5.07630664]), 'targetState': array([ 0.00013991, -0.01392258]), 'effectorPosition': array([-0.66982175, -1.50439852])}
episode index:1301
target Thresh 1.8665746768890565
current state at start:  [-0.99749456 -1.72135369]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.99749456, -1.72135369]), 'currentState': array([5.66062127, 4.33202197]), 'targetState': array([-0.40746139, -0.56431899]), 'effectorPosition': array([-0.03066503, -1.12095366])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2745706693310476
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.99749456, -1.72135369]), 'currentState': array([3.40782074, 4.1588325 ]), 'targetState': array([-0.40746139, -0.56431899]), 'effectorPosition': array([-0.68137897,  0.69591012])}
episode index:1302
target Thresh 1.8668412608624436
current state at start:  [1.8048066  1.92567618]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.8048066 , 1.92567618]), 'currentState': array([2.3048066 , 1.48897626]), 'targetState': array([-0.14259109,  0.57233648]), 'effectorPosition': array([-1.46460903,  0.13556554])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2743599474052371
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.8048066 , 1.92567618]), 'currentState': array([5.4993205 , 3.74489034]), 'targetState': array([-0.14259109,  0.57233648]), 'effectorPosition': array([-0.27555181, -0.5264342 ])}
episode index:1303
target Thresh 1.8671073122006967
current state at start:  [-2.61014761  2.74155909]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.61014761,  2.74155909]), 'currentState': array([4.16408711, 2.26257343]), 'targetState': array([ 0.00594382, -0.05746189]), 'effectorPosition': array([ 0.46848629, -0.71042739])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2741495486725644
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.61014761,  2.74155909]), 'currentState': array([4.13147944, 4.94176549]), 'targetState': array([ 0.00594382, -0.05746189]), 'effectorPosition': array([-1.48763044, -0.49162637])}
episode index:1304
target Thresh 1.8673728319680216
current state at start:  [-0.24151357  2.40069794]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.24151357,  2.40069794]), 'currentState': array([6.25353836, 1.90069794]), 'targetState': array([0.31655539, 0.20736598]), 'effectorPosition': array([0.70379708, 0.92561859])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.27393947239005667
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.24151357,  2.40069794]), 'currentState': array([4.70196893, 5.85044778]), 'targetState': array([0.31655539, 0.20736598]), 'effectorPosition': array([-0.43921402, -1.90334793])}
episode index:1305
target Thresh 1.8676378212264972
current state at start:  [-3.33342426  2.73668522]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.33342426,  2.73668522]), 'currentState': array([3.44976105, 2.28340203]), 'targetState': array([ 0.31606778, -0.05324278]), 'effectorPosition': array([-0.10037782, -0.82602001])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.27372971781701677
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.33342426,  2.73668522]), 'currentState': array([3.65212952, 0.04326127]), 'targetState': array([ 0.31606778, -0.05324278]), 'effectorPosition': array([-1.72301543, -1.01456718])}
episode index:1306
target Thresh 1.8679022810360815
current state at start:  [ 4.29720755 -2.60075319]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.29720755, -2.60075319]), 'currentState': array([3.91289525, 3.90208644]), 'targetState': array([ 0.15867908, -0.37643712]), 'effectorPosition': array([-0.67801322,  0.3021698 ])}
done in step count: 46
reward sum = 0.6298236312032323
running average episode reward sum: 0.2740021691662029
{'reset': False, 'endBeforeDone': False, 'stepCount': 47, 'initial state': array([ 4.29720755, -2.60075319]), 'currentState': array([4.37091035, 3.4825204 ]), 'targetState': array([ 0.15867908, -0.37643712]), 'effectorPosition': array([-0.33432983,  0.05773932])}
episode index:1307
target Thresh 1.8681662124546135
current state at start:  [-1.68651602 -2.21997913]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.68651602, -2.21997913]), 'currentState': array([4.81250521, 4.56320618]), 'targetState': array([-0.10796938, -0.16941928]), 'effectorPosition': array([-0.89884741, -0.94594567])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2737926873854948
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.68651602, -2.21997913]), 'currentState': array([3.78888328, 5.52152879]), 'targetState': array([-0.10796938, -0.16941928]), 'effectorPosition': array([-1.7911879 , -0.48891056])}
episode index:1308
target Thresh 1.8684296165378198
current state at start:  [-1.66506757 -2.3032397 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.66506757, -2.3032397 ]), 'currentState': array([4.96634437, 4.4799456 ]), 'targetState': array([-0.29796154, -0.0292674 ]), 'effectorPosition': array([-0.74853419, -0.98943662])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.27358352566862276
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.66506757, -2.3032397 ]), 'currentState': array([4.38048068, 5.70898366]), 'targetState': array([-0.29796154, -0.0292674 ]), 'effectorPosition': array([-1.11295804, -1.56223456])}
episode index:1309
target Thresh 1.8686924943393166
current state at start:  [-0.99382269  2.51358227]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.99382269,  2.51358227]), 'currentState': array([4.78936261, 2.95655243]), 'targetState': array([1.12202505, 0.07322472]), 'effectorPosition': array([ 0.18475402, -0.00287251])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.27337468328261616
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.99382269,  2.51358227]), 'currentState': array([4.06292297, 0.08571056]), 'targetState': array([1.12202505, 0.07322472]), 'effectorPosition': array([-1.13912548, -1.64166115])}
episode index:1310
target Thresh 1.8689548469106159
current state at start:  [-3.44652424  2.79100123]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.44652424,  2.79100123]), 'currentState': array([2.3801701 , 3.20681563]), 'targetState': array([-0.23899906, -1.08826378]), 'effectorPosition': array([0.04342971, 0.04864555])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2731661594967408
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.44652424,  2.79100123]), 'currentState': array([3.31935262, 5.3872542 ]), 'targetState': array([-0.23899906, -1.08826378]), 'effectorPosition': array([-1.73725265,  0.48118334])}
episode index:1311
target Thresh 1.8692166753011281
current state at start:  [-1.33661467  3.06341814]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.33661467,  3.06341814]), 'currentState': array([4.58420205, 2.67990541]), 'targetState': array([-0.0033447 ,  0.00572384]), 'effectorPosition': array([ 0.42842031, -0.16078462])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.27372014870444145
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.33661467,  3.06341814]), 'currentState': array([4.58420205, 2.67990541]), 'targetState': array([-0.0033447 ,  0.00572384]), 'effectorPosition': array([ 0.42842031, -0.16078462])}
episode index:1312
target Thresh 1.869477980558167
current state at start:  [1.00076993 2.49193078]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.00076993, 2.49193078]), 'currentState': array([1.50076993, 2.05370819]), 'targetState': array([ 0.05659244, -0.09150967]), 'effectorPosition': array([-0.84599765,  0.59629516])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.27351167943657817
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.00076993, 2.49193078]), 'currentState': array([3.42950264, 0.5716814 ]), 'targetState': array([ 0.05659244, -0.09150967]), 'effectorPosition': array([-1.61158651, -1.04152476])}
episode index:1313
target Thresh 1.8697387637269542
current state at start:  [-1.01894876 -2.2611904 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.01894876, -2.2611904 ]), 'currentState': array([4.85307745, 4.21772869]), 'targetState': array([-0.04446217,  0.14824058]), 'effectorPosition': array([-0.79777856, -0.64349358])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2733035274735366
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.01894876, -2.2611904 ]), 'currentState': array([3.93805267, 5.09179996]), 'targetState': array([-0.04446217,  0.14824058]), 'effectorPosition': array([-1.62226706, -0.330146  ])}
episode index:1314
target Thresh 1.8699990258506225
current state at start:  [-1.99202494  2.55277631]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.99202494,  2.55277631]), 'currentState': array([3.79116036, 2.10269261]), 'targetState': array([ 0.25738365, -0.50867219]), 'effectorPosition': array([ 0.12881735, -0.98441301])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.2738561483651917
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.99202494,  2.55277631]), 'currentState': array([3.79116036, 2.10269261]), 'targetState': array([ 0.25738365, -0.50867219]), 'effectorPosition': array([ 0.12881735, -0.98441301])}
episode index:1315
target Thresh 1.870258767970221
current state at start:  [-1.90864389  2.28050307]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.90864389,  2.28050307]), 'currentState': array([4.7753822 , 1.78050307]), 'targetState': array([-0.14056313,  0.26138553]), 'effectorPosition': array([ 1.02599879, -0.72868398])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2736480509880145
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.90864389,  2.28050307]), 'currentState': array([4.95892431, 4.26640047]), 'targetState': array([-0.14056313,  0.26138553]), 'effectorPosition': array([-0.73612955, -0.7716304 ])}
episode index:1316
target Thresh 1.8705179911247183
current state at start:  [-1.73839319  1.72057588]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.73839319,  1.72057588]), 'currentState': array([4.08840686, 1.22057588]), 'targetState': array([ 1.14911239, -0.17318742]), 'effectorPosition': array([-0.02244359, -1.63881239])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2734402696281147
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.73839319,  1.72057588]), 'currentState': array([3.96680767, 3.79564484]), 'targetState': array([ 1.14911239, -0.17318742]), 'effectorPosition': array([-0.58699763,  0.26112047])}
episode index:1317
target Thresh 1.8707766963510075
current state at start:  [1.1534176  2.47069786]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.1534176 , 2.47069786]), 'currentState': array([1.61279435, 2.03391896]), 'targetState': array([0.06401749, 0.08741844]), 'effectorPosition': array([-0.91710178,  0.51520518])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2732328035661814
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.1534176 , 2.47069786]), 'currentState': array([5.58236887, 4.12151209]), 'targetState': array([0.06401749, 0.08741844]), 'effectorPosition': array([-0.19698698, -0.92033539])}
episode index:1318
target Thresh 1.87103488468391
current state at start:  [1.73649601 2.33580079]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.73649601, 2.33580079]), 'currentState': array([1.93798952, 1.83580079]), 'targetState': array([ 0.00174113, -0.38523762]), 'effectorPosition': array([-1.16572797,  0.34241955])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.273025652085085
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.73649601, 2.33580079]), 'currentState': array([1.9959556 , 3.65990494]), 'targetState': array([ 0.00174113, -0.38523762]), 'effectorPosition': array([0.39713484, 0.32399206])}
episode index:1319
target Thresh 1.871292557156179
current state at start:  [0.9109572  2.18221846]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.9109572 , 2.18221846]), 'currentState': array([1.40303172, 1.74807492]), 'targetState': array([-0.01690664,  0.83480734]), 'effectorPosition': array([-0.83297599,  0.97644665])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.272818814469869
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.9109572 , 2.18221846]), 'currentState': array([5.64304134, 4.37195191]), 'targetState': array([-0.01690664,  0.83480734]), 'effectorPosition': array([-0.0288111 , -1.15385082])}
episode index:1320
target Thresh 1.8715497147985052
current state at start:  [0.8535407  2.08554272]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.8535407 , 2.08554272]), 'currentState': array([1.3535407 , 1.62401237]), 'targetState': array([0.23245592, 0.15204389]), 'effectorPosition': array([-0.77102507,  1.13979757])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2726122900077419
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.8535407 , 2.08554272]), 'currentState': array([4.63555093, 5.09099691]), 'targetState': array([0.23245592, 0.15204389]), 'effectorPosition': array([-1.03157442, -1.29425999])}
episode index:1321
target Thresh 1.871806358639519
current state at start:  [-1.88466044  2.28667531]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.88466044,  2.28667531]), 'currentState': array([3.89852487, 2.17298432]), 'targetState': array([ 0.80941493, -0.63622324]), 'effectorPosition': array([ 0.25073408, -0.89679347])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2724060779880689
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.88466044,  2.28667531]), 'currentState': array([3.28063624, 3.68060014]), 'targetState': array([ 0.80941493, -0.63622324]), 'effectorPosition': array([-0.21155229,  0.4886804 ])}
episode index:1322
target Thresh 1.872062489705797
current state at start:  [ 2.60990749 -2.3172548 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.60990749, -2.3172548 ]), 'currentState': array([2.17408202, 4.46593051]), 'targetState': array([-0.10537682,  0.51833849]), 'effectorPosition': array([0.36965858, 1.172779  ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2722001777023636
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.60990749, -2.3172548 ]), 'currentState': array([5.36196943, 4.12414995]), 'targetState': array([-0.10537682,  0.51833849]), 'effectorPosition': array([-0.39326685, -0.8576406 ])}
episode index:1323
target Thresh 1.8723181090218626
current state at start:  [1.03374419 2.18509541]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.03374419, 2.18509541]), 'currentState': array([1.53374419, 1.84363029]), 'targetState': array([0.25016702, 1.02969602]), 'effectorPosition': array([-0.93528834,  0.76571039])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.27199458844428026
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.03374419, 2.18509541]), 'currentState': array([5.93379466, 4.46621745]), 'targetState': array([0.25016702, 1.02969602]), 'effectorPosition': array([ 0.37860725, -1.1701586 ])}
episode index:1324
target Thresh 1.8725732176101944
current state at start:  [-1.24551805  2.25326721]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.24551805,  2.25326721]), 'currentState': array([4.63390784, 1.88089425]), 'targetState': array([ 0.52621671, -0.51989873]), 'effectorPosition': array([ 0.89489593, -0.76737051])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.2725440264907374
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.24551805,  2.25326721]), 'currentState': array([4.63390784, 1.88089425]), 'targetState': array([ 0.52621671, -0.51989873]), 'effectorPosition': array([ 0.89489593, -0.76737051])}
episode index:1325
target Thresh 1.8728278164912266
current state at start:  [-3.94797414  1.73608204]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.94797414,  1.73608204]), 'currentState': array([1.94673083, 1.23608204]), 'targetState': array([-0.52808505, -0.54461659]), 'effectorPosition': array([-1.3662925 ,  0.88895639])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.272338488009221
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.94797414,  1.73608204]), 'currentState': array([1.59583428, 3.31106985]), 'targetState': array([-0.52808505, -0.54461659]), 'effectorPosition': array([0.16825551, 0.01854506])}
episode index:1326
target Thresh 1.8730819066833555
current state at start:  [-1.1082925  -2.56823845]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.1082925 , -2.56823845]), 'currentState': array([5.12566154, 4.1879934 ]), 'targetState': array([-0.15298783, -0.15947164]), 'effectorPosition': array([-0.59222367, -0.80491697])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.272133259306878
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.1082925 , -2.56823845]), 'currentState': array([2.99472784, 3.82848232]), 'targetState': array([-0.15298783, -0.15947164]), 'effectorPosition': array([-0.13153884,  0.66049473])}
episode index:1327
target Thresh 1.8733354892029417
current state at start:  [-0.32991018 -2.75849276]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.32991018, -2.75849276]), 'currentState': array([6.08998532, 3.13557155]), 'targetState': array([ 0.34843849, -0.65141332]), 'effectorPosition': array([0.00117384, 0.00590557])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.27192833968390595
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.32991018, -2.75849276]), 'currentState': array([3.11731041, 3.14752187]), 'targetState': array([ 0.34843849, -0.65141332]), 'effectorPosition': array([0.00012639, 0.00592786])}
episode index:1328
target Thresh 1.8735885650643158
current state at start:  [-3.42548758  2.1882754 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.42548758,  2.1882754 ]), 'currentState': array([2.35769773, 2.66983849]), 'targetState': array([-0.39432386, -1.11915257]), 'effectorPosition': array([-0.39821247, -0.24470772])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.27172372844260884
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.42548758,  2.1882754 ]), 'currentState': array([2.45971546, 3.03183556]), 'targetState': array([-0.39432386, -1.11915257]), 'effectorPosition': array([-0.07370753, -0.08125104])}
episode index:1329
target Thresh 1.8738411352797817
current state at start:  [ 0.64097362 -1.98066589]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.64097362, -1.98066589]), 'currentState': array([1.14097362, 4.80251941]), 'targetState': array([ 0.93621755, -0.79950822]), 'effectorPosition': array([1.35956689, 0.57584267])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.27151942488738884
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.64097362, -1.98066589]), 'currentState': array([3.44629966, 3.09170022]), 'targetState': array([ 0.93621755, -0.79950822]), 'effectorPosition': array([ 0.01377516, -0.04794772])}
episode index:1330
target Thresh 1.8740932008596203
current state at start:  [ 4.09849745 -2.56785959]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.09849745, -2.56785959]), 'currentState': array([4.50920752, 4.21532572]), 'targetState': array([0.250789  , 0.33408843]), 'effectorPosition': array([-0.96647087, -0.33502471])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.27131542832473865
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 4.09849745, -2.56785959]), 'currentState': array([5.29550408, 4.6790345 ]), 'targetState': array([0.250789  , 0.33408843]), 'effectorPosition': array([-0.30202268, -1.35723458])}
episode index:1331
target Thresh 1.8743447628120946
current state at start:  [-1.94886067 -2.17347932]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.94886067, -2.17347932]), 'currentState': array([3.8938278 , 4.58188099]), 'targetState': array([-0.25989449, -0.19958195]), 'effectorPosition': array([-1.31260347,  0.12960121])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.27111173806323363
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.94886067, -2.17347932]), 'currentState': array([3.01205442, 3.9425466 ]), 'targetState': array([-0.25989449, -0.19958195]), 'effectorPosition': array([-0.20867991,  0.75127129])}
episode index:1332
target Thresh 1.8745958221434527
current state at start:  [0.33629471 2.61613744]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.33629471, 2.61613744]), 'currentState': array([0.77613053, 2.12027189]), 'targetState': array([-0.26935178, -0.30961734]), 'effectorPosition': array([-0.25646164,  0.94326417])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2709083534135238
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.33629471, 2.61613744]), 'currentState': array([3.082718  , 3.84631833]), 'targetState': array([-0.26935178, -0.30961734]), 'effectorPosition': array([-0.19967954,  0.66071892])}
episode index:1333
target Thresh 1.874846379857932
current state at start:  [-1.50235851  2.34139786]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.50235851,  2.34139786]), 'currentState': array([4.37387877, 1.84139786]), 'targetState': array([ 0.86758519, -0.02717634]), 'effectorPosition': array([ 0.66561288, -1.01110694])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.27070527368832625
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.50235851,  2.34139786]), 'currentState': array([5.09393983, 4.81672355]), 'targetState': array([ 0.86758519, -0.02717634]), 'effectorPosition': array([-0.51190157, -1.39507976])}
episode index:1334
target Thresh 1.875096436957764
current state at start:  [-0.03670711  2.17697615]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.03670711,  2.17697615]), 'currentState': array([5.79074704, 1.81048039]), 'targetState': array([-0.07040988,  0.62636651]), 'effectorPosition': array([1.13125432, 0.4954515 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2705024982024174
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.03670711,  2.17697615]), 'currentState': array([5.26094391, 4.2942059 ]), 'targetState': array([-0.07040988,  0.62636651]), 'effectorPosition': array([-0.4700589 , -0.98328179])}
episode index:1335
target Thresh 1.8753459944431772
current state at start:  [-1.15649457  2.57627334]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.15649457,  2.57627334]), 'currentState': array([4.62669074, 2.08369156]), 'targetState': array([ 0.21615905, -0.03184269]), 'effectorPosition': array([ 0.82453729, -0.58200882])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.27030002627262517
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.15649457,  2.57627334]), 'currentState': array([3.57244953, 4.78359287]), 'targetState': array([ 0.21615905, -0.03184269]), 'effectorPosition': array([-1.38984122,  0.4589432 ])}
episode index:1336
target Thresh 1.8755950533124022
current state at start:  [-0.24751419  2.58883814]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.24751419,  2.58883814]), 'currentState': array([5.60055077, 2.12432719]), 'targetState': array([0.01725567, 0.48937627]), 'effectorPosition': array([0.90465877, 0.36083831])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2700978572178214
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.24751419,  2.58883814]), 'currentState': array([5.1299581 , 4.40862653]), 'targetState': array([0.01725567, 0.48937627]), 'effectorPosition': array([-0.58799136, -1.02763862])}
episode index:1337
target Thresh 1.8758436145616741
current state at start:  [-1.68185449  2.71948452]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.68185449,  2.71948452]), 'currentState': array([4.12228358, 2.21948452]), 'targetState': array([0.50562467, 0.49052068]), 'effectorPosition': array([ 0.44183592, -0.77233274])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2698959903589142
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.68185449,  2.71948452]), 'currentState': array([5.26681322, 4.27834963]), 'targetState': array([0.50562467, 0.49052068]), 'effectorPosition': array([-0.46630861, -0.97029801])}
episode index:1338
target Thresh 1.8760916791852391
current state at start:  [0.45842526 2.10420592]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.45842526, 2.10420592]), 'currentState': array([6.2599809 , 1.61007608]), 'targetState': array([-0.50323726,  0.87217537]), 'effectorPosition': array([0.98365614, 0.97666847])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.2703975468630532
{'reset': False, 'endBeforeDone': False, 'stepCount': 7, 'initial state': array([0.45842526, 2.10420592]), 'currentState': array([1.56203669, 1.30282013]), 'targetState': array([-0.50323726,  0.87217537]), 'effectorPosition': array([-0.95319286,  1.27317877])}
episode index:1339
target Thresh 1.8763392481753556
current state at start:  [-1.01075517  2.22751841]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.01075517,  2.22751841]), 'currentState': array([4.89037268, 1.80237478]), 'targetState': array([ 0.49000631, -0.30563892]), 'effectorPosition': array([ 1.09434075, -0.58599494])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.27019575764897624
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.01075517,  2.22751841]), 'currentState': array([3.41208701, 3.78921479]), 'targetState': array([ 0.49000631, -0.30563892]), 'effectorPosition': array([-0.35632131,  0.52725129])}
episode index:1340
target Thresh 1.8765863225222998
current state at start:  [-2.10287277  2.00555173]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.10287277,  2.00555173]), 'currentState': array([3.70245406, 1.50555173]), 'targetState': array([ 0.91180193, -0.31159551]), 'effectorPosition': array([-0.3712229 , -1.41159137])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.26999426938823873
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.10287277,  2.00555173]), 'currentState': array([3.58017409, 4.01291256]), 'targetState': array([ 0.91180193, -0.31159551]), 'effectorPosition': array([-0.64740962,  0.54150392])}
episode index:1341
target Thresh 1.8768329032143696
current state at start:  [-3.03528656  2.56755549]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.03528656,  2.56755549]), 'currentState': array([3.74047696, 2.06755549]), 'targetState': array([0.81707358, 0.22169861]), 'effectorPosition': array([ 0.06325773, -1.02119568])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2697930814080686
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.03528656,  2.56755549]), 'currentState': array([5.11291481, 4.77248652]), 'targetState': array([0.81707358, 0.22169861]), 'effectorPosition': array([-0.50587297, -1.36536269])}
episode index:1342
target Thresh 1.877078991237888
current state at start:  [ 0.37856784 -1.80215634]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.37856784, -1.80215634]), 'currentState': array([0.87856784, 4.82160269]), 'targetState': array([ 1.17063394, -0.51728084]), 'effectorPosition': array([1.473061  , 0.21928239])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.26959219303769777
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.37856784, -1.80215634]), 'currentState': array([4.16241441, 3.57744815]), 'targetState': array([ 1.17063394, -0.51728084]), 'effectorPosition': array([-0.40879401,  0.14095767])}
episode index:1343
target Thresh 1.8773245875772073
current state at start:  [-2.49930169  1.62206145]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.49930169,  1.62206145]), 'currentState': array([3.28388362, 1.12206145]), 'targetState': array([ 0.45444501, -1.10504957]), 'effectorPosition': array([-1.29156384, -1.09522366])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.26939160360835424
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.49930169,  1.62206145]), 'currentState': array([3.2261332 , 3.16487797]), 'targetState': array([ 0.45444501, -1.10504957]), 'effectorPosition': array([-0.00223615,  0.02317717])}
episode index:1344
target Thresh 1.8775696932147137
current state at start:  [ 3.56317434 -2.80955962]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.56317434, -2.80955962]), 'currentState': array([3.06317434, 3.90591636]), 'targetState': array([-0.3517644 , -0.07454619]), 'effectorPosition': array([-0.22308095,  0.71171187])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2691913124532551
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.56317434, -2.80955962]), 'currentState': array([2.94377651, 3.92515776]), 'targetState': array([-0.3517644 , -0.07454619]), 'effectorPosition': array([-0.14719983,  0.74935218])}
episode index:1345
target Thresh 1.8778143091308295
current state at start:  [ 4.19096965 -2.46716589]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.19096965, -2.46716589]), 'currentState': array([4.59304762, 4.29836684]), 'targetState': array([-0.24054279,  0.22991349]), 'effectorPosition': array([-0.98016011, -0.48445474])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2689913189075989
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 4.19096965, -2.46716589]), 'currentState': array([4.78325381, 4.1192846 ]), 'targetState': array([-0.24054279,  0.22991349]), 'effectorPosition': array([-0.79589868, -0.49866773])}
episode index:1346
target Thresh 1.878058436304019
current state at start:  [0.4416379  2.01185295]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.4416379 , 2.01185295]), 'currentState': array([0.92465877, 1.57650092]), 'targetState': array([0.12348295, 0.70369642]), 'effectorPosition': array([-0.19973005,  1.39595802])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2687916223085584
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.4416379 , 2.01185295]), 'currentState': array([4.47630908, 4.80822742]), 'targetState': array([0.12348295, 0.70369642]), 'effectorPosition': array([-1.22407534, -0.83248012])}
episode index:1347
target Thresh 1.8783020757107909
current state at start:  [-3.59860543  2.06961606]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.59860543,  2.06961606]), 'currentState': array([2.52636185, 2.28559616]), 'targetState': array([-0.81416907, -0.29038394]), 'effectorPosition': array([-0.71723567, -0.41790007])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.2693340617578844
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.59860543,  2.06961606]), 'currentState': array([2.52636185, 2.28559616]), 'targetState': array([-0.81416907, -0.29038394]), 'effectorPosition': array([-0.71723567, -0.41790007])}
episode index:1348
target Thresh 1.8785452283257036
current state at start:  [-3.25034544  1.88564324]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.25034544,  1.88564324]), 'currentState': array([2.56762532, 1.3900359 ]), 'targetState': array([-0.13949149, -0.52801198]), 'effectorPosition': array([-1.52484384, -0.18549018])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2691344071531714
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.25034544,  1.88564324]), 'currentState': array([2.81291878, 3.29128643]), 'targetState': array([-0.13949149, -0.52801198]), 'effectorPosition': array([0.03755454, 0.14476211])}
episode index:1349
target Thresh 1.8787878951213675
current state at start:  [-3.79053665  2.38287417]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.79053665,  2.38287417]), 'currentState': array([2.92850292, 1.88287417]), 'targetState': array([-0.02226651,  0.12631925]), 'effectorPosition': array([-0.87855563, -0.78362392])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2689350483330579
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.79053665,  2.38287417]), 'currentState': array([4.51838396, 4.25130801]), 'targetState': array([-0.02226651,  0.12631925]), 'effectorPosition': array([-0.98578586, -0.37201254])}
episode index:1350
target Thresh 1.8790300770684505
current state at start:  [ 3.51863815 -2.25708178]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.51863815, -2.25708178]), 'currentState': array([3.98075064, 4.46481287]), 'targetState': array([0.21528178, 0.42812289]), 'effectorPosition': array([-1.22576436,  0.0859787 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.26873598464073145
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.51863815, -2.25708178]), 'currentState': array([5.17174029, 5.4231679 ]), 'targetState': array([0.21528178, 0.42812289]), 'effectorPosition': array([ 0.05333498, -1.81714169])}
episode index:1351
target Thresh 1.8792717751356802
current state at start:  [-1.71817333  2.3423246 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.71817333,  2.3423246 ]), 'currentState': array([4.11654085, 1.8423246 ]), 'targetState': array([0.31869065, 0.24266357]), 'effectorPosition': array([ 0.38665675, -1.14633699])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2685372154213226
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.71817333,  2.3423246 ]), 'currentState': array([5.07352917, 5.01887837]), 'targetState': array([0.31869065, 0.24266357]), 'effectorPosition': array([-0.43195036, -1.55462081])}
episode index:1352
target Thresh 1.8795129902898497
current state at start:  [-2.03834136  2.50802568]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.03834136,  2.50802568]), 'currentState': array([3.88448044, 2.07170609]), 'targetState': array([-0.37432207, -0.35491464]), 'effectorPosition': array([ 0.21049232, -0.99761992])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2683387400218981
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.03834136,  2.50802568]), 'currentState': array([2.36168282, 3.62109604]), 'targetState': array([-0.37432207, -0.35491464]), 'effectorPosition': array([0.24423935, 0.40730684])}
episode index:1353
target Thresh 1.8797537234958197
current state at start:  [ 2.24043217 -2.62515353]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.24043217, -2.62515353]), 'currentState': array([2.34296248, 4.15803178]), 'targetState': array([-0.13544428,  0.27291545]), 'effectorPosition': array([0.27868455, 0.93249192])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.26814055779145357
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.24043217, -2.62515353]), 'currentState': array([5.08610946, 4.51551706]), 'targetState': array([-0.13544428,  0.27291545]), 'effectorPosition': array([-0.61932138, -1.10690368])}
episode index:1354
target Thresh 1.8799939757165232
current state at start:  [-1.82514314 -2.09167106]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.82514314, -2.09167106]), 'currentState': array([3.95804216, 4.43426882]), 'targetState': array([-0.10220525, -0.35895284]), 'effectorPosition': array([-1.19751517,  0.12984742])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.26794266808090633
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.82514314, -2.09167106]), 'currentState': array([3.24677568, 3.49523118]), 'targetState': array([-0.10220525, -0.35895284]), 'effectorPosition': array([-0.09789832,  0.33790266])}
episode index:1355
target Thresh 1.8802337479129696
current state at start:  [-0.11202347  1.76226778]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.11202347,  1.76226778]), 'currentState': array([0.3761273 , 1.78375968]), 'targetState': array([ 1.2698398 , -0.00333878]), 'effectorPosition': array([0.37448895, 1.19876752])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2677450702430885
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.11202347,  1.76226778]), 'currentState': array([5.46241559, 5.38330289]), 'targetState': array([ 1.2698398 , -0.00333878]), 'effectorPosition': array([ 0.53236268, -1.72046334])}
episode index:1356
target Thresh 1.880473041044248
current state at start:  [-0.95172864 -1.73543333]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.95172864, -1.73543333]), 'currentState': array([4.83145667, 4.35901512]), 'targetState': array([-0.08392838, -0.48012404]), 'effectorPosition': array([-0.85388911, -0.76075164])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2675477636327399
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.95172864, -1.73543333]), 'currentState': array([3.22918107, 3.53098652]), 'targetState': array([-0.08392838, -0.48012404]), 'effectorPosition': array([-0.10778219,  0.37162391])}
episode index:1357
target Thresh 1.8807118560675313
current state at start:  [-2.22556723  2.74926872]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.22556723,  2.74926872]), 'currentState': array([3.5815857 , 3.23423253]), 'targetState': array([ 0.24524753, -0.93343686]), 'effectorPosition': array([-0.04328157,  0.08187011])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2673507476065008
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.22556723,  2.74926872]), 'currentState': array([3.47134507, 3.52183681]), 'targetState': array([ 0.24524753, -0.93343686]), 'effectorPosition': array([-0.18775843,  0.32802238])}
episode index:1358
target Thresh 1.8809501939380797
current state at start:  [ 1.22690569 -2.82524742]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.22690569, -2.82524742]), 'currentState': array([1.65812119, 3.95793789]), 'targetState': array([0.39209054, 0.22292436]), 'effectorPosition': array([0.69838908, 0.3774587 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.2678898566958264
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.22690569, -2.82524742]), 'currentState': array([1.65812119, 3.95793789]), 'targetState': array([0.39209054, 0.22292436]), 'effectorPosition': array([0.69838908, 0.3774587 ])}
episode index:1359
target Thresh 1.8811880556092453
current state at start:  [0.76030732 2.37623836]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.76030732, 2.37623836]), 'currentState': array([0.26030732, 2.87623836]), 'targetState': array([-0.34979648,  1.20763122]), 'effectorPosition': array([-0.03367634,  0.26242448])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.26769287886002063
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.76030732, 2.37623836]), 'currentState': array([5.01029494, 5.23481113]), 'targetState': array([-0.34979648,  1.20763122]), 'effectorPosition': array([-0.38846222, -1.68732286])}
episode index:1360
target Thresh 1.8814254420324747
current state at start:  [1.3843803  2.53101377]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.3843803 , 2.53101377]), 'currentState': array([1.86268975, 2.08309374]), 'targetState': array([-0.09220195, -0.411436  ]), 'effectorPosition': array([-0.98146035,  0.23743116])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2674961904846643
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.3843803 , 2.53101377]), 'currentState': array([3.26353275, 3.8264425 ]), 'targetState': array([-0.09220195, -0.411436  ]), 'effectorPosition': array([-0.30075463,  0.60043199])}
episode index:1361
target Thresh 1.881662354157314
current state at start:  [-2.19643834  2.13867462]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.19643834,  2.13867462]), 'currentState': array([3.94569216, 1.63867462]), 'targetState': array([ 0.35029909, -0.14402837]), 'effectorPosition': array([ 0.07184272, -1.3635198 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2672997909321792
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.19643834,  2.13867462]), 'currentState': array([3.46615954, 4.83732738]), 'targetState': array([ 0.35029909, -0.14402837]), 'effectorPosition': array([-1.38230895,  0.58176386])}
episode index:1362
target Thresh 1.8818987929314126
current state at start:  [-0.60776606 -2.25413747]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.60776606, -2.25413747]), 'currentState': array([5.24509306, 4.45828592]), 'targetState': array([-0.33440453, -0.18856031]), 'effectorPosition': array([-0.45357653, -1.13644779])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.26710367956685843
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.60776606, -2.25413747]), 'currentState': array([2.72912838, 3.87040279]), 'targetState': array([-0.33440453, -0.18856031]), 'effectorPosition': array([0.03424279, 0.71196399])}
episode index:1363
target Thresh 1.882134759300525
current state at start:  [-0.77897117 -2.48619141]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.77897117, -2.48619141]), 'currentState': array([5.01219091, 4.03392348]), 'targetState': array([ 0.10053752, -0.57100739]), 'effectorPosition': array([-0.63382854, -0.58571596])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.26690785575485926
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.77897117, -2.48619141]), 'currentState': array([3.87191748, 3.75429635]), 'targetState': array([ 0.10053752, -0.57100739]), 'effectorPosition': array([-0.5191542 ,  0.30706121])}
episode index:1364
target Thresh 1.882370254208518
current state at start:  [0.85029465 2.36284997]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.85029465, 2.36284997]), 'currentState': array([1.35029465, 1.86284997]), 'targetState': array([-0.20946673, -0.08272578]), 'effectorPosition': array([-0.77872207,  0.90429691])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.26671231886419633
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.85029465, 2.36284997]), 'currentState': array([4.77656214, 4.98911083]), 'targetState': array([-0.20946673, -0.08272578]), 'effectorPosition': array([-0.87832669, -1.33227234])}
episode index:1365
target Thresh 1.8826052785973704
current state at start:  [ 3.16358542 -2.11828223]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.16358542, -2.11828223]), 'currentState': array([3.60206154, 4.55403874]), 'targetState': array([-0.32253147,  0.12996997]), 'effectorPosition': array([-1.19338779,  0.51034004])}
done in step count: 88
reward sum = 0.41294967113388814
running average episode reward sum: 0.2668193740269121
{'reset': False, 'endBeforeDone': False, 'stepCount': 89, 'initial state': array([ 3.16358542, -2.11828223]), 'currentState': array([4.78025327, 3.95706463]), 'targetState': array([-0.32253147,  0.12996997]), 'effectorPosition': array([-0.70504808, -0.36312189])}
episode index:1366
target Thresh 1.882839833407181
current state at start:  [-1.92228285  2.30019703]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.92228285,  2.30019703]), 'currentState': array([3.90095523, 1.80019703]), 'targetState': array([-0.04754954, -0.79535772]), 'effectorPosition': array([ 0.11007177, -1.23818265])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.26735571684035253
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.92228285,  2.30019703]), 'currentState': array([3.90095523, 1.80019703]), 'targetState': array([-0.04754954, -0.79535772]), 'effectorPosition': array([ 0.11007177, -1.23818265])}
episode index:1367
target Thresh 1.883073919576169
current state at start:  [-0.55016494 -2.13811029]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.55016494, -2.13811029]), 'currentState': array([6.03242454, 4.51355502]), 'targetState': array([-0.92156118, -0.25569813]), 'effectorPosition': array([ 0.53412335, -1.14876431])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.26716028137482595
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.55016494, -2.13811029]), 'currentState': array([5.46030817, 4.71992449]), 'targetState': array([-0.92156118, -0.25569813]), 'effectorPosition': array([-0.04784508, -1.41872539])}
episode index:1368
target Thresh 1.8833075380406792
current state at start:  [-0.60376635  2.66706466]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.60376635,  2.66706466]), 'currentState': array([5.51527596, 2.16706466]), 'targetState': array([0.37944301, 0.01064416]), 'effectorPosition': array([0.89016396, 0.29067299])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2669651314249539
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.60376635,  2.66706466]), 'currentState': array([4.97833226, 5.00368173]), 'targetState': array([0.37944301, 0.01064416]), 'effectorPosition': array([-0.58590056, -1.4936874 ])}
episode index:1369
target Thresh 1.883540689735186
current state at start:  [0.3292413  1.85804208]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.3292413 , 1.85804208]), 'currentState': array([6.11242661, 1.39980079]), 'targetState': array([-0.52391261,  1.09995167]), 'effectorPosition': array([1.32059651, 0.77223814])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.26677026636551965
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.3292413 , 1.85804208]), 'currentState': array([4.10601884, 5.60624162]), 'targetState': array([-0.52391261,  1.09995167]), 'effectorPosition': array([-1.5288492 , -1.10526099])}
episode index:1370
target Thresh 1.8837733755922967
current state at start:  [-0.66380363 -1.99043912]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.66380363, -1.99043912]), 'currentState': array([5.18536477, 4.77750317]), 'targetState': array([-0.17423067, -0.65570294]), 'effectorPosition': array([-0.40315173, -1.40271346])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2665756855731305
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.66380363, -1.99043912]), 'currentState': array([2.88906561, 3.66589412]), 'targetState': array([-0.17423067, -0.65570294]), 'effectorPosition': array([-0.00498804,  0.51829281])}
episode index:1371
target Thresh 1.8840055965427547
current state at start:  [-3.57937166  2.29626019]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.57937166,  2.29626019]), 'currentState': array([3.15837217, 1.83850424]), 'targetState': array([0.25443062, 0.18580464]), 'effectorPosition': array([-0.71919371, -0.97658437])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2663813884262113
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.57937166,  2.29626019]), 'currentState': array([4.87451503, 5.25560359]), 'targetState': array([0.25443062, 0.18580464]), 'effectorPosition': array([-0.59997401, -1.63517958])}
episode index:1372
target Thresh 1.8842373535154442
current state at start:  [-0.66738557 -1.99202544]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.66738557, -1.99202544]), 'currentState': array([5.11579974, 4.20737965]), 'targetState': array([ 0.13915072, -0.3485459 ]), 'effectorPosition': array([-0.60228571, -0.81830356])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2661873743049977
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.66738557, -1.99202544]), 'currentState': array([3.49755477, 4.21687961]), 'targetState': array([ 0.13915072, -0.3485459 ]), 'effectorPosition': array([-0.79821685,  0.64178675])}
episode index:1373
target Thresh 1.8844686474373933
current state at start:  [-3.64346931  2.16662998]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.64346931,  2.16662998]), 'currentState': array([2.139716  , 1.80081174]), 'targetState': array([-0.01360837, -0.92671364]), 'effectorPosition': array([-1.23619244,  0.12586971])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.26599364259152974
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.64346931,  2.16662998]), 'currentState': array([3.48017625, 3.29824256]), 'targetState': array([-0.01360837, -0.92671364]), 'effectorPosition': array([-0.06336831,  0.14308567])}
episode index:1374
target Thresh 1.8846994792337783
current state at start:  [ 3.7247612  -1.83015643]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.7247612 , -1.83015643]), 'currentState': array([4.09764845, 4.94939973]), 'targetState': array([-0.51720351,  0.0423313 ]), 'effectorPosition': array([-1.50625088, -0.44811188])}
done in step count: 39
reward sum = 0.6757290490602831
running average episode reward sum: 0.26629163197805245
{'reset': False, 'endBeforeDone': False, 'stepCount': 40, 'initial state': array([ 3.7247612 , -1.83015643]), 'currentState': array([4.76535089, 4.08079712]), 'targetState': array([-0.51720351,  0.0423313 ]), 'effectorPosition': array([-0.78427553, -0.45172042])}
episode index:1375
target Thresh 1.8849298498279263
current state at start:  [-1.33537398  2.02838211]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.33537398,  2.02838211]), 'currentState': array([4.44781133, 1.52838211]), 'targetState': array([ 0.21866041, -0.24654047]), 'effectorPosition': array([ 0.69174527, -1.26739555])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.26609810608271955
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.33537398,  2.02838211]), 'currentState': array([3.78421326, 4.26850899]), 'targetState': array([ 0.21866041, -0.24654047]), 'effectorPosition': array([-0.99796288,  0.38102064])}
episode index:1376
target Thresh 1.8851597601413204
current state at start:  [0.0372066  2.60622786]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.0372066 , 2.60622786]), 'currentState': array([0.50398354, 2.18123927]), 'targetState': array([0.02099372, 0.07255285]), 'effectorPosition': array([-0.02199239,  0.92360999])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2659048612707495
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.0372066 , 2.60622786]), 'currentState': array([4.51477871, 4.6157782 ]), 'targetState': array([0.02099372, 0.07255285]), 'effectorPosition': array([-1.153355  , -0.69054408])}
episode index:1377
target Thresh 1.8853892110936017
current state at start:  [ 0.25354195 -2.13681653]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.25354195, -2.13681653]), 'currentState': array([0.75354195, 4.60785968]), 'targetState': array([ 0.50813358, -1.01329035]), 'effectorPosition': array([ 1.33367005, -0.11245486])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2657118969302047
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.25354195, -2.13681653]), 'currentState': array([3.79587864, 3.28767474]), 'targetState': array([ 0.50813358, -1.01329035]), 'effectorPosition': array([-0.09704005,  0.10901964])}
episode index:1378
target Thresh 1.8856182036025748
current state at start:  [-1.22621112  1.81848415]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.22621112,  1.81848415]), 'currentState': array([4.56914775, 1.31848415]), 'targetState': array([ 0.58613046, -0.01075213]), 'effectorPosition': array([ 0.78003157, -1.37507743])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.26551921245092247
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.22621112,  1.81848415]), 'currentState': array([4.76480641, 5.09678202]), 'targetState': array([ 0.58613046, -0.01075213]), 'effectorPosition': array([-0.85371217, -1.4216781 ])}
episode index:1379
target Thresh 1.8858467385842097
current state at start:  [-2.3010769   1.99597698]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.3010769 ,  1.99597698]), 'currentState': array([4.31622766, 1.49597698]), 'targetState': array([-0.00233478, -0.10642546]), 'effectorPosition': array([ 0.50524391, -1.37630946])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.26532680722450874
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.3010769 ,  1.99597698]), 'currentState': array([4.80447177, 5.0340768 ]), 'targetState': array([-0.00233478, -0.10642546]), 'effectorPosition': array([-0.8236586 , -1.39782797])}
episode index:1380
target Thresh 1.8860748169526467
current state at start:  [1.34983235 2.87188927]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.34983235, 2.87188927]), 'currentState': array([0.86671436, 2.3999787 ]), 'targetState': array([-0.27880471,  0.03438979]), 'effectorPosition': array([-0.34485077,  0.63743179])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2651346806443317
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.34983235, 2.87188927]), 'currentState': array([4.47063315, 4.43391987]), 'targetState': array([-0.27880471,  0.03438979]), 'effectorPosition': array([-1.10711516, -0.47384378])}
episode index:1381
target Thresh 1.8863024396201997
current state at start:  [-1.73656318  2.9311452 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.73656318,  2.9311452 ]), 'currentState': array([4.04662213, 3.1579992 ]), 'targetState': array([ 0.11298026, -0.35615919]), 'effectorPosition': array([-0.01298537,  0.01002741])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.2656664211069624
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.73656318,  2.9311452 ]), 'currentState': array([4.04662213, 3.1579992 ]), 'targetState': array([ 0.11298026, -0.35615919]), 'effectorPosition': array([-0.01298537,  0.01002741])}
episode index:1382
target Thresh 1.8865296074973594
current state at start:  [-1.02374289  2.27054779]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.02374289,  2.27054779]), 'currentState': array([4.76708618, 1.82314779]), 'targetState': array([0.86668986, 0.9731008 ]), 'effectorPosition': array([ 1.00789968, -0.69625784])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2654743268039205
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.02374289,  2.27054779]), 'currentState': array([6.26403506, 4.35025205]), 'targetState': array([0.86668986, 0.9731008 ]), 'effectorPosition': array([ 0.62770111, -0.9473355 ])}
episode index:1383
target Thresh 1.886756321492798
current state at start:  [ 1.12464359 -1.61773323]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.12464359, -1.61773323]), 'currentState': array([1.59656494, 5.16545208]), 'targetState': array([0.86962833, 0.33643443]), 'effectorPosition': array([0.86176805, 1.4604106 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2652825100938021
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.12464359, -1.61773323]), 'currentState': array([5.0683018 , 5.04147769]), 'targetState': array([0.86962833, 0.33643443]), 'effectorPosition': array([-0.42597196, -1.57000301])}
episode index:1384
target Thresh 1.8869825825133715
current state at start:  [-3.28604569  2.57427769]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.28604569,  2.57427769]), 'currentState': array([3.48093678, 2.22243794]), 'targetState': array([-0.47936094,  0.09226668]), 'effectorPosition': array([-0.10640675, -0.88073418])}
done in step count: 17
reward sum = 0.8429431933839268
running average episode reward sum: 0.26569959361964335
{'reset': False, 'endBeforeDone': False, 'stepCount': 18, 'initial state': array([-3.28604569,  2.57427769]), 'currentState': array([4.79525842, 3.94721293]), 'targetState': array([-0.47936094,  0.09226668]), 'effectorPosition': array([-0.69334565, -0.36598339])}
episode index:1385
target Thresh 1.8872083914641242
current state at start:  [1.58064948 1.8917509 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.58064948, 1.8917509 ]), 'currentState': array([2.08064948, 1.3917509 ]), 'targetState': array([-0.09787604,  0.41529299]), 'effectorPosition': array([-1.43382938,  0.54800911])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2655078911711443
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.58064948, 1.8917509 ]), 'currentState': array([4.5509617 , 4.58315192]), 'targetState': array([-0.09787604,  0.41529299]), 'effectorPosition': array([-1.11878079, -0.70041013])}
episode index:1386
target Thresh 1.8874337492482927
current state at start:  [-0.77741991 -1.97547836]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.77741991, -1.97547836]), 'currentState': array([5.89815336, 4.78881833]), 'targetState': array([-0.79481603, -0.67548817]), 'effectorPosition': array([ 0.62305888, -1.32834768])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.26600903617390487
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([-0.77741991, -1.97547836]), 'currentState': array([5.18957505, 4.47096617]), 'targetState': array([-0.79481603, -0.67548817]), 'effectorPosition': array([-0.51305493, -1.12187603])}
episode index:1387
target Thresh 1.887658656767308
current state at start:  [-3.61642785  2.03444651]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.61642785,  2.03444651]), 'currentState': array([3.1631095 , 2.16844054]), 'targetState': array([-1.03472209, -0.10682674]), 'effectorPosition': array([-0.41941636, -0.83588081])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2658173870123963
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.61642785,  2.03444651]), 'currentState': array([5.17228333, 4.74881984]), 'targetState': array([-1.03472209, -0.10682674]), 'effectorPosition': array([-0.43548498, -1.37229677])}
episode index:1388
target Thresh 1.8878831149208004
current state at start:  [ 3.13664056 -1.72995583]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.13664056, -1.72995583]), 'currentState': array([3.63664056, 5.00116828]), 'targetState': array([-0.28123576,  0.11863945]), 'effectorPosition': array([-1.58594103,  0.23314293])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.26562601380360407
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.13664056, -1.72995583]), 'currentState': array([5.06415549, 4.49854499]), 'targetState': array([-0.28123576,  0.11863945]), 'effectorPosition': array([-0.64594708, -1.07625118])}
episode index:1389
target Thresh 1.888107124606603
current state at start:  [ 1.12056597 -1.83163098]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.12056597, -1.83163098]), 'currentState': array([1.62056597, 4.91582668]), 'targetState': array([1.06447941, 0.49656237]), 'effectorPosition': array([0.91836483, 1.24927206])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2654349159519468
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.12056597, -1.83163098]), 'currentState': array([5.66336827, 5.49274029]), 'targetState': array([1.06447941, 0.49656237]), 'effectorPosition': array([ 0.97383039, -1.56802826])}
episode index:1390
target Thresh 1.888330686720755
current state at start:  [-3.60124206  2.8216019 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.60124206,  2.8216019 ]), 'currentState': array([3.12804244, 2.38428682]), 'targetState': array([0.25034548, 0.170865  ]), 'effectorPosition': array([-0.28259371, -0.68319975])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2652440928635557
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.60124206,  2.8216019 ]), 'currentState': array([4.34918302, 4.72579778]), 'targetState': array([0.25034548, 0.170865  ]), 'effectorPosition': array([-1.29471512, -0.59205538])}
episode index:1391
target Thresh 1.888553802157505
current state at start:  [-2.45960661  2.42428977]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.45960661,  2.42428977]), 'currentState': array([4.23825217, 1.97414977]), 'targetState': array([-0.0557124,  0.0944744]), 'effectorPosition': array([ 0.54092526, -0.96041144])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2650535439462687
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.45960661,  2.42428977]), 'currentState': array([4.84636348, 4.61042833]), 'targetState': array([-0.0557124,  0.0944744]), 'effectorPosition': array([-0.86591353, -1.02304722])}
episode index:1392
target Thresh 1.888776471809315
current state at start:  [ 4.13001169 -2.13438323]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.13001169, -2.13438323]), 'currentState': array([3.6651303 , 4.07721294]), 'targetState': array([-0.85965664, -0.75234949]), 'effectorPosition': array([-0.75464932,  0.49382785])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.26486326860962384
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 4.13001169, -2.13438323]), 'currentState': array([1.92772369, 3.22402578]), 'targetState': array([-0.85965664, -0.75234949]), 'effectorPosition': array([0.07596388, 0.03195094])}
episode index:1393
target Thresh 1.888998696566864
current state at start:  [-1.03477689  2.81812901]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.03477689,  2.81812901]), 'currentState': array([4.74840842, 2.31812901]), 'targetState': array([-0.14044614,  0.13076605]), 'effectorPosition': array([ 0.74456372, -0.29369284])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.26467326626485366
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.03477689,  2.81812901]), 'currentState': array([4.91124108, 4.79558396]), 'targetState': array([-0.14044614,  0.13076605]), 'effectorPosition': array([-0.76294352, -1.25861641])}
episode index:1394
target Thresh 1.889220477319051
current state at start:  [0.30506601 2.71071661]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.30506601, 2.71071661]), 'currentState': array([0.80506601, 2.21071661]), 'targetState': array([ 0.08993003, -0.33233879]), 'effectorPosition': array([-0.2990327,  0.8463548])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.26448353632487887
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.30506601, 2.71071661]), 'currentState': array([3.92015541, 4.38844925]), 'targetState': array([ 0.08993003, -0.33233879]), 'effectorPosition': array([-1.15104725,  0.1961697 ])}
episode index:1395
target Thresh 1.8894418149529997
current state at start:  [-1.03233426  1.58936691]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.03233426,  1.58936691]), 'currentState': array([4.7793604 , 1.08936691]), 'targetState': array([ 0.84915248, -0.79818643]), 'effectorPosition': array([ 0.98225608, -1.40045213])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2642940782043023
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.03233426,  1.58936691]), 'currentState': array([4.3946879 , 3.31345853]), 'targetState': array([ 0.84915248, -0.79818643]), 'effectorPosition': array([-0.1670647 ,  0.03942881])}
episode index:1396
target Thresh 1.8896627103540609
current state at start:  [1.10542989 2.10829873]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.10542989, 2.10829873]), 'currentState': array([1.56165105, 1.68461166]), 'targetState': array([-0.14287143,  0.03459271]), 'effectorPosition': array([-0.98538194,  0.89547915])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.264104891319403
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.10542989, 2.10829873]), 'currentState': array([4.37170036, 4.54362101]), 'targetState': array([-0.14287143,  0.03459271]), 'effectorPosition': array([-1.20714587, -0.45482188])}
episode index:1397
target Thresh 1.8898831644058163
current state at start:  [-0.99399655  2.65681665]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.99399655,  2.65681665]), 'currentState': array([4.8216369 , 2.26481323]), 'targetState': array([0.1026104 , 0.02484208]), 'effectorPosition': array([ 0.8033917 , -0.27441149])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2639159750881302
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.99399655,  2.65681665]), 'currentState': array([4.81041373, 4.39509222]), 'targetState': array([0.1026104 , 0.02484208]), 'effectorPosition': array([-0.87818822, -0.7776803 ])}
episode index:1398
target Thresh 1.8901031779900825
current state at start:  [-2.55659573  2.41832417]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.55659573,  2.41832417]), 'currentState': array([4.17381649, 1.94114846]), 'targetState': array([-0.08270692,  0.20949492]), 'effectorPosition': array([ 0.47297321, -1.02586984])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2637273289300972
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.55659573,  2.41832417]), 'currentState': array([4.98314062, 4.22184542]), 'targetState': array([-0.08270692,  0.20949492]), 'effectorPosition': array([-0.70848707, -0.74554359])}
episode index:1399
target Thresh 1.8903227519869144
current state at start:  [ 3.62959771 -1.81550212]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.62959771, -1.81550212]), 'currentState': array([4.12116565, 4.8511795 ]), 'targetState': array([-0.36571219,  0.41077723]), 'effectorPosition': array([-1.45676337, -0.39310459])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2635389522665757
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.62959771, -1.81550212]), 'currentState': array([5.36452845, 3.53685916]), 'targetState': array([-0.36571219,  0.41077723]), 'effectorPosition': array([-0.25924138, -0.29496771])}
episode index:1400
target Thresh 1.8905418872746076
current state at start:  [-3.22679647  2.11170677]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.22679647,  2.11170677]), 'currentState': array([3.55638883, 1.61170677]), 'targetState': array([ 0.30565699, -0.14311083]), 'effectorPosition': array([-0.47510154, -1.30095367])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2633508445204896
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.22679647,  2.11170677]), 'currentState': array([4.70685293, 3.93069004]), 'targetState': array([ 0.30565699, -0.14311083]), 'effectorPosition': array([-0.71134278, -0.29158025])}
episode index:1401
target Thresh 1.8907605847297042
current state at start:  [ 4.12498184 -2.70686973]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.12498184, -2.70686973]), 'currentState': array([4.54189786, 3.92963269]), 'targetState': array([-0.26162252, -0.0442307 ]), 'effectorPosition': array([-0.7487049 , -0.17020138])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.2638762718781783
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.12498184, -2.70686973]), 'currentState': array([4.54189786, 3.92963269]), 'targetState': array([-0.26162252, -0.0442307 ]), 'effectorPosition': array([-0.7487049 , -0.17020138])}
episode index:1402
target Thresh 1.890978845226994
current state at start:  [ 3.66058453 -1.58851067]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.66058453, -1.58851067]), 'currentState': array([3.17328282, 4.78481686]), 'targetState': array([-1.25785992,  0.00441736]), 'effectorPosition': array([-1.10342794,  0.96289975])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.26368819185545683
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.66058453, -1.58851067]), 'currentState': array([2.16745794, 5.29141066]), 'targetState': array([-1.25785992,  0.00441736]), 'effectorPosition': array([-0.17697153,  1.75016907])}
episode index:1403
target Thresh 1.8911966696395193
current state at start:  [-3.20318365  1.6326244 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.20318365,  1.6326244 ]), 'currentState': array([2.67412055, 2.11118472]), 'targetState': array([-0.9409032 , -1.02552566]), 'effectorPosition': array([-0.81985859, -0.54671174])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.2642126304652464
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.20318365,  1.6326244 ]), 'currentState': array([2.67412055, 2.11118472]), 'targetState': array([-0.9409032 , -1.02552566]), 'effectorPosition': array([-0.81985859, -0.54671174])}
episode index:1404
target Thresh 1.8914140588385782
current state at start:  [ 0.07384945 -2.48703032]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.07384945, -2.48703032]), 'currentState': array([0.57078851, 4.29615499]), 'targetState': array([ 0.01452858, -0.68164127]), 'effectorPosition': array([ 0.99541515, -0.44778448])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2640245787709651
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.07384945, -2.48703032]), 'currentState': array([2.91259394, 3.59929875]), 'targetState': array([ 0.01452858, -0.68164127]), 'effectorPosition': array([6.60930985e-05, 4.53721242e-01])}
episode index:1405
target Thresh 1.8916310136937275
current state at start:  [ 3.96309098 -2.78387896]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.96309098, -2.78387896]), 'currentState': array([3.46309098, 3.45876713]), 'targetState': array([ 0.08041278, -0.57637098]), 'effectorPosition': array([-0.14587538,  0.2801419 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.26383679457553766
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.96309098, -2.78387896]), 'currentState': array([3.60648093, 3.90459974]), 'targetState': array([ 0.08041278, -0.57637098]), 'effectorPosition': array([-0.55765108,  0.49346033])}
episode index:1406
target Thresh 1.8918475350727872
current state at start:  [-0.30218011  2.77262189]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.30218011,  2.77262189]), 'currentState': array([2.06882379e-03, 3.27262189e+00]), 'targetState': array([0.9526938 , 0.62680753]), 'effectorPosition': array([ 0.00884234, -0.13063662])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.2643320036838706
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([-0.30218011,  2.77262189]), 'currentState': array([1.15745709, 5.20988207]), 'targetState': array([0.9526938 , 0.62680753]), 'effectorPosition': array([1.39813074, 0.99983923])}
episode index:1407
target Thresh 1.8920636238418431
current state at start:  [-2.05579521  2.06462809]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.05579521,  2.06462809]), 'currentState': array([4.30570044, 1.56462809]), 'targetState': array([-0.25675733, -0.27975342]), 'effectorPosition': array([ 0.52040821, -1.31966347])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.26414426788579964
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.05579521,  2.06462809]), 'currentState': array([3.81005635, 4.93375202]), 'targetState': array([-0.25675733, -0.27975342]), 'effectorPosition': array([-1.56173744,  0.00976558])}
episode index:1408
target Thresh 1.8922792808652502
current state at start:  [-1.73993525 -2.48931358]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.73993525, -2.48931358]), 'currentState': array([5.04325006, 4.29387172]), 'targetState': array([-0.11262155,  0.01736278]), 'effectorPosition': array([-0.67130313, -0.858219  ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2639567985686344
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.73993525, -2.48931358]), 'currentState': array([4.94162676, 4.3328741 ]), 'targetState': array([-0.11262155,  0.01736278]), 'effectorPosition': array([-0.76149432, -0.82412776])}
episode index:1409
target Thresh 1.8924945070056374
current state at start:  [ 2.51847423 -2.19406057]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.51847423, -2.19406057]), 'currentState': array([2.95705563, 4.16302684]), 'targetState': array([-0.560343 ,  0.1467434]), 'effectorPosition': array([-0.3132512 ,  0.92605995])}
done in step count: 66
reward sum = 0.5151371174238033
running average episode reward sum: 0.26413494063874443
{'reset': False, 'endBeforeDone': False, 'stepCount': 67, 'initial state': array([ 2.51847423, -2.19406057]), 'currentState': array([4.84369883, 3.80294911]), 'targetState': array([-0.560343 ,  0.1467434]), 'effectorPosition': array([-0.58129458, -0.28944244])}
episode index:1410
target Thresh 1.892709303123909
current state at start:  [ 3.10789092 -1.75696179]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.10789092, -1.75696179]), 'currentState': array([3.49796521, 4.97220109]), 'targetState': array([-0.28179524,  0.11584927]), 'effectorPosition': array([-1.51509424,  0.46721237])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.26394774365742707
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.10789092, -1.75696179]), 'currentState': array([4.54175023, 4.78949172]), 'targetState': array([-0.28179524,  0.11584927]), 'effectorPosition': array([-1.16544055, -0.89207682])}
episode index:1411
target Thresh 1.8929236700792504
current state at start:  [-4.12278002  2.65883605]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.12278002,  2.65883605]), 'currentState': array([2.66040529, 2.26604973]), 'targetState': array([ 0.38278861, -0.81391865]), 'effectorPosition': array([-0.67401113, -0.51434319])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.26376081182764133
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-4.12278002,  2.65883605]), 'currentState': array([3.79710046, 3.23336174]), 'targetState': array([ 0.38278861, -0.81391865]), 'effectorPosition': array([-0.05919616,  0.07008189])}
episode index:1412
target Thresh 1.8931376087291292
current state at start:  [-0.21016836  2.14926722]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.21016836,  2.14926722]), 'currentState': array([5.61475689, 1.65426799]), 'targetState': array([0.25620066, 0.80410813]), 'effectorPosition': array([1.33695996, 0.21398258])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2635741445864328
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.21016836,  2.14926722]), 'currentState': array([5.14097546, 4.4844621 ]), 'targetState': array([0.25620066, 0.80410813]), 'effectorPosition': array([-0.56434978, -1.10886983])}
episode index:1413
target Thresh 1.8933511199293003
current state at start:  [-3.0458513   2.00596959]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.0458513 ,  2.00596959]), 'currentState': array([3.66869231, 1.97946515]), 'targetState': array([-0.64946467, -0.73046766]), 'effectorPosition': array([-0.05921448, -1.09622871])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2633877413724396
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.0458513 ,  2.00596959]), 'currentState': array([2.93810137, 3.99929966]), 'targetState': array([-0.64946467, -0.73046766]), 'effectorPosition': array([-0.18584156,  0.81062689])}
episode index:1414
target Thresh 1.893564204533809
current state at start:  [1.3167593  1.68712235]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.3167593 , 1.68712235]), 'currentState': array([0.86650945, 1.21158806]), 'targetState': array([-1.23961146,  0.53688796]), 'effectorPosition': array([0.16167045, 1.63613232])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2632016016258866
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.3167593 , 1.68712235]), 'currentState': array([0.73947591, 1.28658521]), 'targetState': array([-1.23961146,  0.53688796]), 'effectorPosition': array([0.29912169, 1.57204543])}
episode index:1415
target Thresh 1.8937768633949938
current state at start:  [ 0.14634518 -2.64174096]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.14634518, -2.64174096]), 'currentState': array([0.64290077, 4.14144435]), 'targetState': array([-0.69138353, -0.28311658]), 'effectorPosition': array([ 0.87225412, -0.39789265])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2630157247885802
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.14634518, -2.64174096]), 'currentState': array([2.49874109, 3.70073202]), 'targetState': array([-0.69138353, -0.28311658]), 'effectorPosition': array([0.19610862, 0.51586578])}
episode index:1416
target Thresh 1.8939890973634907
current state at start:  [-2.86988019  1.78180356]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.86988019,  1.78180356]), 'currentState': array([3.91330512, 1.28180356]), 'targetState': array([-0.47474371, -0.85635921]), 'effectorPosition': array([-0.25252769, -1.58309936])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2628301103039023
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.86988019,  1.78180356]), 'currentState': array([0.95823236, 1.78152818]), 'targetState': array([-0.47474371, -0.85635921]), 'effectorPosition': array([-0.34537887,  1.20928168])}
episode index:1417
target Thresh 1.8942009072882358
current state at start:  [ 4.07117934 -1.98201206]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.07117934, -1.98201206]), 'currentState': array([4.47882907, 4.73684439]), 'targetState': array([-0.26068072,  0.43662564]), 'effectorPosition': array([-1.20965944, -0.76526465])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.26264475761680506
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 4.07117934, -1.98201206]), 'currentState': array([4.90403522, 4.67304586]), 'targetState': array([-0.26068072,  0.43662564]), 'effectorPosition': array([-0.79794903, -1.13340699])}
episode index:1418
target Thresh 1.8944122940164687
current state at start:  [-0.89065195 -1.71655328]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.89065195, -1.71655328]), 'currentState': array([4.91784295, 4.13519496]), 'targetState': array([ 0.31602997, -1.1405212 ]), 'effectorPosition': array([-0.7276851 , -0.61573129])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2624596661738052
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.89065195, -1.71655328]), 'currentState': array([4.01424782, 2.98644956]), 'targetState': array([ 0.31602997, -1.1405212 ]), 'effectorPosition': array([ 0.11064904, -0.10852616])}
episode index:1419
target Thresh 1.894623258393737
current state at start:  [2.13132453 1.73440882]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.13132453, 1.73440882]), 'currentState': array([2.63132453, 1.2834618 ]), 'targetState': array([-0.50519061,  0.2959828 ]), 'effectorPosition': array([-1.58829736, -0.21001323])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2622748354229785
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([2.13132453, 1.73440882]), 'currentState': array([4.89776513, 4.02964747]), 'targetState': array([-0.50519061,  0.2959828 ]), 'effectorPosition': array([-0.69452638, -0.50575523])}
episode index:1420
target Thresh 1.8948338012638986
current state at start:  [-0.4892349   2.16198583]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.4892349 ,  2.16198583]), 'currentState': array([5.52810418, 1.72401954]), 'targetState': array([0.71040008, 0.42190161]), 'effectorPosition': array([1.29439085, 0.13893739])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.26209026481395464
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.4892349 ,  2.16198583]), 'currentState': array([4.50715041, 4.7410434 ]), 'targetState': array([0.71040008, 0.42190161]), 'effectorPosition': array([-1.18825022, -0.80334452])}
episode index:1421
target Thresh 1.8950439234691248
current state at start:  [-2.24712076  1.94888654]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.24712076,  1.94888654]), 'currentState': array([3.70013909, 1.50676647]), 'targetState': array([ 0.59832042, -0.77726857]), 'effectorPosition': array([-0.37342014, -1.41015234])}
done in step count: 19
reward sum = 0.8261686238355866
running average episode reward sum: 0.2624869443913257
{'reset': False, 'endBeforeDone': False, 'stepCount': 20, 'initial state': array([-2.24712076,  1.94888654]), 'currentState': array([3.98970566, 2.75639546]), 'targetState': array([ 0.59832042, -0.77726857]), 'effectorPosition': array([ 0.23335459, -0.30347475])}
episode index:1422
target Thresh 1.8952536258499049
current state at start:  [-0.59842468 -2.07057354]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.59842468, -2.07057354]), 'currentState': array([5.34817662, 4.5564648 ]), 'targetState': array([-0.61931084, -0.19749511]), 'effectorPosition': array([-0.29324652, -1.2662623 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.2629981974170521
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.59842468, -2.07057354]), 'currentState': array([4.89550751, 4.23539109]), 'targetState': array([-0.61931084, -0.19749511]), 'effectorPosition': array([-0.77503051, -0.69361316])}
episode index:1423
target Thresh 1.8954629092450488
current state at start:  [ 3.29095072 -1.91162877]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.29095072, -1.91162877]), 'currentState': array([3.77556321, 4.85460566]), 'targetState': array([-1.1729699 ,  0.69419778]), 'effectorPosition': array([-1.50624568,  0.12124137])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.26281350767167494
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.29095072, -1.91162877]), 'currentState': array([4.62689939, 2.25586238]), 'targetState': array([-1.1729699 ,  0.69419778]), 'effectorPosition': array([ 0.74018919, -0.43205513])}
episode index:1424
target Thresh 1.8956717744916904
current state at start:  [-3.93691896  2.90493678]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.93691896,  2.90493678]), 'currentState': array([2.84626635, 3.26779028]), 'targetState': array([ 0.16677002, -0.60606167]), 'effectorPosition': array([0.02902458, 0.12272852])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2626290771399755
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.93691896,  2.90493678]), 'currentState': array([4.25342109, 3.33516073]), 'targetState': array([ 0.16677002, -0.60606167]), 'effectorPosition': array([-0.18072795,  0.06847749])}
episode index:1425
target Thresh 1.8958802224252909
current state at start:  [-4.24377197  2.47281834]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.24377197,  2.47281834]), 'currentState': array([2.53941334, 1.97281834]), 'targetState': array([-0.0486933 ,  0.08725284]), 'effectorPosition': array([-1.02292662, -0.41359552])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2624449052766235
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-4.24377197,  2.47281834]), 'currentState': array([4.46299818, 4.45220207]), 'targetState': array([-0.0486933 ,  0.08725284]), 'effectorPosition': array([-1.11976424, -0.48125431])}
episode index:1426
target Thresh 1.896088253879642
current state at start:  [ 0.93593634 -3.09205034]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.93593634, -3.09205034]), 'currentState': array([1.43566126, 3.49943254]), 'targetState': array([-0.66758987, -0.21697289]), 'effectorPosition': array([0.3555926 , 0.01557954])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2622609915378172
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.93593634, -3.09205034]), 'currentState': array([2.7832096, 3.6661618]), 'targetState': array([-0.66758987, -0.21697289]), 'effectorPosition': array([0.04975764, 0.51618268])}
episode index:1427
target Thresh 1.8962958696868704
current state at start:  [ 0.02391283 -1.77226055]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.02391283, -1.77226055]), 'currentState': array([5.96568735, 4.99689284]), 'targetState': array([ 0.02727035, -0.24864362]), 'effectorPosition': array([ 0.91703139, -1.3116463 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2620773353812781
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.02391283, -1.77226055]), 'currentState': array([4.15426988, 3.85744086]), 'targetState': array([ 0.02727035, -0.24864362]), 'effectorPosition': array([-0.68666757,  0.13933381])}
episode index:1428
target Thresh 1.8965030706774388
current state at start:  [-0.87688292 -1.84424378]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.87688292, -1.84424378]), 'currentState': array([4.96073624, 3.98414596]), 'targetState': array([-0.07537865, -0.31790634]), 'effectorPosition': array([-0.64124079, -0.50763327])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2618939362662457
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.87688292, -1.84424378]), 'currentState': array([3.28402028, 4.18210526]), 'targetState': array([-0.07537865, -0.31790634]), 'effectorPosition': array([-0.6116697 ,  0.78377545])}
episode index:1429
target Thresh 1.8967098576801524
current state at start:  [-1.06014982 -1.88258242]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.06014982, -1.88258242]), 'currentState': array([5.53553542, 4.45660454]), 'targetState': array([-1.36275858, -0.17711722]), 'effectorPosition': array([-0.11003282, -1.21732657])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.26171079365347205
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.06014982, -1.88258242]), 'currentState': array([5.12375274, 4.62036094]), 'targetState': array([-1.36275858, -0.17711722]), 'effectorPosition': array([-0.54958448, -1.2305123 ])}
episode index:1430
target Thresh 1.8969162315221588
current state at start:  [-1.14109814  2.43449077]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.14109814,  2.43449077]), 'currentState': array([4.65596507, 1.93449077]), 'targetState': array([-0.02138445,  0.07169568]), 'effectorPosition': array([ 0.89676869, -0.69595046])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2615279070052166
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.14109814,  2.43449077]), 'currentState': array([3.28454571, 5.54517876]), 'targetState': array([-0.02138445,  0.07169568]), 'effectorPosition': array([-1.81791812,  0.41808639])}
episode index:1431
target Thresh 1.897122193028954
current state at start:  [-1.69497378 -2.73653007]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.69497378, -2.73653007]), 'currentState': array([5.03603377, 3.07733401]), 'targetState': array([-0.58652832,  0.09579622]), 'effectorPosition': array([0.06153694, 0.01846502])}
done in step count: 40
reward sum = 0.6689717585696803
running average episode reward sum: 0.2618124348345214
{'reset': False, 'endBeforeDone': False, 'stepCount': 41, 'initial state': array([-1.69497378, -2.73653007]), 'currentState': array([4.70117729, 4.05049727]), 'targetState': array([-0.58652832,  0.09579622]), 'effectorPosition': array([-0.79310218, -0.37652164])}
episode index:1432
target Thresh 1.8973277430243838
current state at start:  [-3.15714239  2.76571787]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.15714239,  2.76571787]), 'currentState': array([3.52789517, 3.16512914]), 'targetState': array([ 0.09015664, -0.78957236]), 'effectorPosition': array([-0.00912349,  0.02169568])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.26162973250735144
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.15714239,  2.76571787]), 'currentState': array([4.31554015, 3.12904937]), 'targetState': array([ 0.09015664, -0.78957236]), 'effectorPosition': array([ 0.01153775, -0.00492058])}
episode index:1433
target Thresh 1.897532882330649
current state at start:  [ 1.07581371 -1.73358517]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.07581371, -1.73358517]), 'currentState': array([1.57245603, 4.84796031]), 'targetState': array([ 0.91580146, -0.54909688]), 'effectorPosition': array([0.98893889, 1.13679933])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2614472849951427
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.07581371, -1.73358517]), 'currentState': array([4.23909892, 4.55542363]), 'targetState': array([ 0.91580146, -0.54909688]), 'effectorPosition': array([-1.26369415, -0.30072233])}
episode index:1434
target Thresh 1.897737611768307
current state at start:  [ 1.08087582 -2.18908649]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.08087582, -2.18908649]), 'currentState': array([1.55570698, 4.59233079]), 'targetState': array([ 0.0504947 , -0.00891106]), 'effectorPosition': array([1.00597024, 0.86514966])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2612650917651809
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.08087582, -2.18908649]), 'currentState': array([4.04240567, 5.04379331]), 'targetState': array([ 0.0504947 , -0.00891106]), 'effectorPosition': array([-1.56420051, -0.45168494])}
episode index:1435
target Thresh 1.8979419321562756
current state at start:  [-0.20822767 -1.78173114]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.20822767, -1.78173114]), 'currentState': array([0.27886122, 5.00145417]), 'targetState': array([-0.15590116, -1.24826706]), 'effectorPosition': array([ 1.49925465, -0.56775711])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2610831522862358
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.20822767, -1.78173114]), 'currentState': array([1.07448921, 2.00858125]), 'targetState': array([-0.15590116, -1.24826706]), 'effectorPosition': array([-0.52210659,  0.93783583])}
episode index:1436
target Thresh 1.8981458443118366
current state at start:  [ 0.72504655 -2.21035002]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.72504655, -2.21035002]), 'currentState': array([1.19871116, 4.23149882]), 'targetState': array([-0.07540668, -0.91531285]), 'effectorPosition': array([1.02130363, 0.17833055])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.26090146602855574
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.72504655, -2.21035002]), 'currentState': array([4.19323774, 3.24293628]), 'targetState': array([-0.07540668, -0.91531285]), 'effectorPosition': array([-0.09038576,  0.04574012])}
episode index:1437
target Thresh 1.8983493490506393
current state at start:  [ 3.51645657 -2.95661236]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.51645657, -2.95661236]), 'currentState': array([4.01645657, 2.88471499]), 'targetState': array([0.24505394, 0.40521449]), 'effectorPosition': array([ 0.17394556, -0.18806123])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2607200324638627
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.51645657, -2.95661236]), 'currentState': array([4.41533866, 4.67006643]), 'targetState': array([0.24505394, 0.40521449]), 'effectorPosition': array([-1.2356646 , -0.62330823])}
episode index:1438
target Thresh 1.8985524471867026
current state at start:  [-0.68585728  2.37260389]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.68585728,  2.37260389]), 'currentState': array([5.9112842 , 1.87260389]), 'targetState': array([-0.01054289,  0.03117006]), 'effectorPosition': array([1.00167435, 0.63415722])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2605388510653472
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.68585728,  2.37260389]), 'currentState': array([4.41510862, 4.83567876]), 'targetState': array([-0.01054289,  0.03117006]), 'effectorPosition': array([-1.27782273, -0.78302262])}
episode index:1439
target Thresh 1.8987551395324194
current state at start:  [-0.98371713 -2.12872459]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.98371713, -2.12872459]), 'currentState': array([4.82962089, 4.61748429]), 'targetState': array([-0.05336551, -0.00781775]), 'effectorPosition': array([-0.88278719, -1.01546157])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2603579213076629
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.98371713, -2.12872459]), 'currentState': array([4.44219169, 4.83609398]), 'targetState': array([-0.05336551, -0.00781775]), 'effectorPosition': array([-1.25621075, -0.81774935])}
episode index:1440
target Thresh 1.8989574268985594
current state at start:  [ 1.68543054 -1.73538665]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.68543054, -1.73538665]), 'currentState': array([2.17882414, 4.89577561]), 'targetState': array([0.58738773, 0.19931041]), 'effectorPosition': array([0.13159002, 1.53212433])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.260177242666922
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.68543054, -1.73538665]), 'currentState': array([4.70702215, 4.75565896]), 'targetState': array([0.58738773, 0.19931041]), 'effectorPosition': array([-1.00464856, -1.03787968])}
episode index:1441
target Thresh 1.899159310094272
current state at start:  [ 3.57063771 -2.42236991]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.57063771, -2.42236991]), 'currentState': array([3.98110527, 4.08894571]), 'targetState': array([ 0.0395766 , -0.02089956]), 'effectorPosition': array([-0.8822177 ,  0.23242997])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.25999681462068974
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.57063771, -2.42236991]), 'currentState': array([5.04065968, 4.33051409]), 'targetState': array([ 0.0395766 , -0.02089956]), 'effectorPosition': array([-0.67615708, -0.89302277])}
episode index:1442
target Thresh 1.8993607899270908
current state at start:  [ 1.60805281 -1.58127421]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.60805281, -1.58127421]), 'currentState': array([2.10805281, 5.2019111 ]), 'targetState': array([0.5407521 , 1.27516201]), 'effectorPosition': array([0.00579695, 1.7147521 ])}
done in step count: 15
reward sum = 0.8600583546412884
running average episode reward sum: 0.2604126576837671
{'reset': False, 'endBeforeDone': False, 'stepCount': 16, 'initial state': array([ 1.60805281, -1.58127421]), 'currentState': array([1.74125654, 4.97291804]), 'targetState': array([0.5407521 , 1.27516201]), 'effectorPosition': array([0.73891699, 1.40327662])}
episode index:1443
target Thresh 1.899561867202935
current state at start:  [-3.53707179  2.53618   ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.53707179,  2.53618   ]), 'currentState': array([3.24611352, 2.89542223]), 'targetState': array([-0.75583871,  0.29049534]), 'effectorPosition': array([-0.0045582 , -0.24550701])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2602323165080858
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.53707179,  2.53618   ]), 'currentState': array([5.65042517, 3.48830128]), 'targetState': array([-0.75583871,  0.29049534]), 'effectorPosition': array([-0.15296717, -0.30920639])}
episode index:1444
target Thresh 1.899762542726114
current state at start:  [-3.40245141  1.68175415]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.40245141,  1.68175415]), 'currentState': array([3.38073389, 1.64261535]), 'targetState': array([-1.0121849 ,  0.16045059]), 'effectorPosition': array([-0.66556876, -1.18890859])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.26005222493956814
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.40245141,  1.68175415]), 'currentState': array([5.54883098, 3.98504721]), 'targetState': array([-1.0121849 ,  0.16045059]), 'effectorPosition': array([-0.25179089, -0.77899196])}
episode index:1445
target Thresh 1.8999628172993306
current state at start:  [-1.07803417  2.12849901]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.07803417,  2.12849901]), 'currentState': array([4.70515113, 1.64961378]), 'targetState': array([ 0.18028354, -0.33128211]), 'effectorPosition': array([ 0.99020149, -0.92845531])}
done in step count: 51
reward sum = 0.598956006466161
running average episode reward sum: 0.2602865982324634
{'reset': False, 'endBeforeDone': False, 'stepCount': 52, 'initial state': array([-1.07803417,  2.12849901]), 'currentState': array([4.35467657, 3.31583029]), 'targetState': array([ 0.18028354, -0.33128211]), 'effectorPosition': array([-0.16768525,  0.04651544])}
episode index:1446
target Thresh 1.9001626917236827
current state at start:  [ 2.20182593 -2.87801139]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.20182593, -2.87801139]), 'currentState': array([2.70182593, 3.88281774]), 'targetState': array([ 0.29028495, -0.1241952 ]), 'effectorPosition': array([0.0500535 , 0.72264151])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.26010671806782454
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.20182593, -2.87801139]), 'currentState': array([4.69158832, 3.91159702]), 'targetState': array([ 0.29028495, -0.1241952 ]), 'effectorPosition': array([-0.70185507, -0.26755225])}
episode index:1447
target Thresh 1.9003621667986685
current state at start:  [ 0.97243157 -2.94129635]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.97243157, -2.94129635]), 'currentState': array([1.4413808 , 3.28815474]), 'targetState': array([-0.54982007, -0.78942171]), 'effectorPosition': array([ 0.1462003 , -0.00821551])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.25992708635645173
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.97243157, -2.94129635]), 'currentState': array([1.24760127, 2.6118454 ]), 'targetState': array([-0.54982007, -0.78942171]), 'effectorPosition': array([-0.43562122,  0.29045573])}
episode index:1448
target Thresh 1.900561243322189
current state at start:  [-1.24292101  2.41750678]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.24292101,  2.41750678]), 'currentState': array([4.54026429, 1.95935735]), 'targetState': array([0.22929566, 0.02196998]), 'effectorPosition': array([ 0.80539292, -0.77047261])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.25974770258394897
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.24292101,  2.41750678]), 'currentState': array([4.5794514 , 4.48863225]), 'targetState': array([0.22929566, 0.02196998]), 'effectorPosition': array([-1.06960259, -0.64199828])}
episode index:1449
target Thresh 1.90075992209055
current state at start:  [-3.511975    2.86554871]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.511975  ,  2.86554871]), 'currentState': array([2.89118155, 3.313913  ]), 'targetState': array([ 0.00120731, -1.00959868]), 'effectorPosition': array([0.02814183, 0.16979085])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.25956856623733937
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.511975  ,  2.86554871]), 'currentState': array([3.80171965, 3.04736269]), 'targetState': array([ 0.00120731, -1.00959868]), 'effectorPosition': array([ 0.05419362, -0.07704395])}
episode index:1450
target Thresh 1.900958203898467
current state at start:  [-0.6286293   2.60919242]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.6286293 ,  2.60919242]), 'currentState': array([6.05907413, 2.10919242]), 'targetState': array([ 0.09092632, -0.14167107]), 'effectorPosition': array([0.66585553, 0.72877783])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.25938967680506003
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.6286293 ,  2.60919242]), 'currentState': array([4.74576623, 4.42342727]), 'targetState': array([ 0.09092632, -0.14167107]), 'effectorPosition': array([-0.93414465, -0.74663211])}
episode index:1451
target Thresh 1.9011560895390676
current state at start:  [-0.34376246  2.4567329 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.34376246,  2.4567329 ]), 'currentState': array([5.56698963, 2.00013474]), 'targetState': array([0.09974573, 0.82009352]), 'effectorPosition': array([1.0372481 , 0.30261802])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.25921103377695737
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.34376246,  2.4567329 ]), 'currentState': array([5.09042883, 4.19095086]), 'targetState': array([0.09974573, 0.82009352]), 'effectorPosition': array([-0.62063664, -0.78648259])}
episode index:1452
target Thresh 1.9013535798038945
current state at start:  [-2.74395874  1.7393416 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.74395874,  1.7393416 ]), 'currentState': array([3.03922657, 2.17340503]), 'targetState': array([ 0.17403182, -1.31449672]), 'effectorPosition': array([-0.51512672, -0.77527882])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2590326366442822
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.74395874,  1.7393416 ]), 'currentState': array([4.02302842, 3.05367666]), 'targetState': array([ 0.17403182, -1.31449672]), 'effectorPosition': array([ 0.06529679, -0.05882664])}
episode index:1453
target Thresh 1.9015506754829092
current state at start:  [0.42271715 2.26648611]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.42271715, 2.26648611]), 'currentState': array([0.92271715, 1.8742423 ]), 'targetState': array([0.07790218, 0.87779336]), 'effectorPosition': array([-0.33754329,  1.13509625])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.25954224280890104
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.42271715, 2.26648611]), 'currentState': array([0.92271715, 1.8742423 ]), 'targetState': array([0.07790218, 0.87779336]), 'effectorPosition': array([-0.33754329,  1.13509625])}
episode index:1454
target Thresh 1.9017473773644944
current state at start:  [-1.99618252 -1.97028439]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.99618252, -1.97028439]), 'currentState': array([4.05278259, 4.4345715 ]), 'targetState': array([-0.29574521, -0.27187081]), 'effectorPosition': array([-1.20467229,  0.01580255])}
done in step count: 19
reward sum = 0.8261686238355866
running average episode reward sum: 0.259931676747751
{'reset': False, 'endBeforeDone': False, 'stepCount': 20, 'initial state': array([-1.99618252, -1.97028439]), 'currentState': array([3.93558288, 3.42896353]), 'targetState': array([-0.29574521, -0.27187081]), 'effectorPosition': array([-0.23087776,  0.16944241])}
episode index:1455
target Thresh 1.9019436862354582
current state at start:  [ 1.01682647 -2.39139241]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.01682647, -2.39139241]), 'currentState': array([1.51682647, 4.08898565]), 'targetState': array([ 0.37523294, -0.9361878 ]), 'effectorPosition': array([0.83316542, 0.37179567])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2597531522444902
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.01682647, -2.39139241]), 'currentState': array([3.97943285, 3.14799612]), 'targetState': array([ 0.37523294, -0.9361878 ]), 'effectorPosition': array([-0.00477274,  0.0042691 ])}
episode index:1456
target Thresh 1.9021396028810362
current state at start:  [1.68336173 1.77482481]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.68336173, 1.77482481]), 'currentState': array([1.19865953, 1.3139962 ]), 'targetState': array([-0.91287905,  0.2902233 ]), 'effectorPosition': array([-0.44504656,  1.51983795])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2595748727988866
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.68336173, 1.77482481]), 'currentState': array([2.58967861, 4.49820498]), 'targetState': array([-0.91287905,  0.2902233 ]), 'effectorPosition': array([-0.15819382,  1.24493953])}
episode index:1457
target Thresh 1.9023351280848952
current state at start:  [ 3.85010357 -1.74468819]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.85010357, -1.74468819]), 'currentState': array([4.27933137, 4.58843717]), 'targetState': array([-0.31885094,  0.5591442 ]), 'effectorPosition': array([-1.26848799, -0.37903684])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.25939683790670626
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.85010357, -1.74468819]), 'currentState': array([5.13176244, 4.20569199]), 'targetState': array([-0.31885094,  0.5591442 ]), 'effectorPosition': array([-0.58900143, -0.82613165])}
episode index:1458
target Thresh 1.9025302626291363
current state at start:  [ 2.78646399 -2.83093981]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.78646399, -2.83093981]), 'currentState': array([3.28646399, 3.91813137]), 'targetState': array([0.7998813 , 0.00230509]), 'effectorPosition': array([-0.38482678,  0.65208995])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.25921904706509785
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.78646399, -2.83093981]), 'currentState': array([4.73181667, 4.69655402]), 'targetState': array([0.7998813 , 0.00230509]), 'effectorPosition': array([-0.98056708, -1.00340401])}
episode index:1459
target Thresh 1.902725007294298
current state at start:  [-0.64737485 -2.71615206]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.64737485, -2.71615206]), 'currentState': array([5.2170515 , 3.47071479]), 'targetState': array([ 0.22543433, -0.2765697 ]), 'effectorPosition': array([-0.25696819, -0.20325958])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.2597264312794368
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.64737485, -2.71615206]), 'currentState': array([5.2170515 , 3.47071479]), 'targetState': array([ 0.22543433, -0.2765697 ]), 'effectorPosition': array([-0.25696819, -0.20325958])}
episode index:1460
target Thresh 1.9029193628593593
current state at start:  [0.72599301 1.83178577]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.72599301, 1.83178577]), 'currentState': array([1.22599301, 1.39218876]), 'targetState': array([0.71131806, 0.87984234]), 'effectorPosition': array([-0.52810776,  1.44097922])}
done in step count: 30
reward sum = 0.7397003733882802
running average episode reward sum: 0.2600549555382382
{'reset': False, 'endBeforeDone': False, 'stepCount': 31, 'initial state': array([0.72599301, 1.83178577]), 'currentState': array([1.21070521, 4.49413822]), 'targetState': array([0.71131806, 0.87984234]), 'effectorPosition': array([1.1897297, 0.3892285])}
episode index:1461
target Thresh 1.9031133301017424
current state at start:  [-3.94762882  2.9257046 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.94762882,  2.9257046 ]), 'currentState': array([1.83555649, 3.23849135]), 'targetState': array([-0.59863634, -0.63454465]), 'effectorPosition': array([0.09214848, 0.02984413])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2598770793716594
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.94762882,  2.9257046 ]), 'currentState': array([2.2995132 , 3.52066126]), 'targetState': array([-0.59863634, -0.63454465]), 'effectorPosition': array([0.22879885, 0.2993855 ])}
episode index:1462
target Thresh 1.9033069097973168
current state at start:  [ 3.79589823 -1.94384909]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.79589823, -1.94384909]), 'currentState': array([3.29819471, 4.48052874]), 'targetState': array([-1.27945847, -0.34558333]), 'effectorPosition': array([-0.91257577,  0.84120669])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.25969944637140535
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.79589823, -1.94384909]), 'currentState': array([2.37157183, 4.32661957]), 'targetState': array([-1.27945847, -0.34558333]), 'effectorPosition': array([0.19721769, 1.09934569])}
episode index:1463
target Thresh 1.9035001027204013
current state at start:  [1.69519945 2.78676384]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.69519945, 2.78676384]), 'currentState': array([2.18644549, 2.28676384]), 'targetState': array([ 0.03322111, -0.09038843]), 'effectorPosition': array([-0.81439433, -0.15513391])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.25952205603918443
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.69519945, 2.78676384]), 'currentState': array([4.12059905, 3.92004034]), 'targetState': array([ 0.03322111, -0.09038843]), 'effectorPosition': array([-0.74342321,  0.15268646])}
episode index:1464
target Thresh 1.9036929096437682
current state at start:  [1.88156185 2.44342564]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.88156185, 2.44342564]), 'currentState': array([1.42222918, 1.95472805]), 'targetState': array([-0.45928064, -0.33246766]), 'effectorPosition': array([-0.82440817,  0.75578666])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2593449078780655
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.88156185, 2.44342564]), 'currentState': array([2.54783979, 3.64371345]), 'targetState': array([-0.45928064, -0.33246766]), 'effectorPosition': array([0.16695783, 0.46797162])}
episode index:1465
target Thresh 1.9038853313386452
current state at start:  [ 1.1436538  -1.65750432]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.1436538 , -1.65750432]), 'currentState': array([1.6436538 , 5.07501496]), 'targetState': array([ 0.89104833, -0.23980152]), 'effectorPosition': array([0.83387318, 1.41919584])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.25916800139247337
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.1436538 , -1.65750432]), 'currentState': array([5.92751289, 0.23170323]), 'targetState': array([ 0.89104833, -0.23980152]), 'effectorPosition': array([ 1.92973821, -0.47187267])}
episode index:1466
target Thresh 1.9040773685747194
current state at start:  [ 3.30083366 -2.65445247]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.30083366, -2.65445247]), 'currentState': array([3.77045853, 4.01823932]), 'targetState': array([ 0.10089817, -0.07329947]), 'effectorPosition': array([-0.74345773,  0.40964179])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.25899133608818403
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.30083366, -2.65445247]), 'currentState': array([4.32258216, 4.63695834]), 'targetState': array([ 0.10089817, -0.07329947]), 'effectorPosition': array([-1.27372479, -0.47634745])}
episode index:1467
target Thresh 1.9042690221201402
current state at start:  [0.86931728 2.46468842]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.86931728, 2.46468842]), 'currentState': array([1.0332116 , 2.24014636]), 'targetState': array([-0.99985648,  0.54503023]), 'effectorPosition': array([-0.47926861,  0.72756361])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.25881491147232016
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.86931728, 2.46468842]), 'currentState': array([2.90428246, 4.95638014]), 'targetState': array([-0.99985648,  0.54503023]), 'effectorPosition': array([-0.97865475,  1.23506674])}
episode index:1468
target Thresh 1.9044602927415215
current state at start:  [-0.27815757  2.4966849 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.27815757,  2.4966849 ]), 'currentState': array([0.22184243, 2.04459401]), 'targetState': array([-0.24293524, -0.13566035]), 'effectorPosition': array([0.33461677, 0.9876709 ])}
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.2592360864971851
{'reset': False, 'endBeforeDone': False, 'stepCount': 14, 'initial state': array([-0.27815757,  2.4966849 ]), 'currentState': array([2.76020926, 3.36131053]), 'targetState': array([-0.24293524, -0.13566035]), 'effectorPosition': array([0.05880995, 0.2112426 ])}
episode index:1469
target Thresh 1.9046511812039466
current state at start:  [-2.59579445  2.53228608]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.59579445,  2.53228608]), 'currentState': array([4.15757596, 2.03228608]), 'targetState': array([0.07695003, 0.03236765]), 'effectorPosition': array([ 0.46886417, -0.94318681])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2590597354179353
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.59579445,  2.53228608]), 'currentState': array([4.56284651, 4.44933018]), 'targetState': array([0.07695003, 0.03236765]), 'effectorPosition': array([-1.06506655, -0.58784569])}
episode index:1470
target Thresh 1.9048416882709693
current state at start:  [ 0.11529335 -1.64071311]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.11529335, -1.64071311]), 'currentState': array([0.58386376, 5.1111524 ]), 'targetState': array([ 0.32148294, -0.99066902]), 'effectorPosition': array([ 1.66629688, -0.00358704])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2588836241090176
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.11529335, -1.64071311]), 'currentState': array([3.86617902, 3.34037683]), 'targetState': array([ 0.32148294, -0.99066902]), 'effectorPosition': array([-0.14563854,  0.13481326])}
episode index:1471
target Thresh 1.9050318147046184
current state at start:  [ 1.97977715 -2.52791319]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.97977715, -2.52791319]), 'currentState': array([2.45577412, 4.25527212]), 'targetState': array([ 0.05000844, -0.22094417]), 'effectorPosition': array([0.13595446, 1.0482322 ])}
done in step count: 43
reward sum = 0.6491026283684022
running average episode reward sum: 0.25914871854125904
{'reset': False, 'endBeforeDone': False, 'stepCount': 44, 'initial state': array([ 1.97977715, -2.52791319]), 'currentState': array([3.90214453, 3.67009645]), 'targetState': array([ 0.05000844, -0.22094417]), 'effectorPosition': array([-0.44642761,  0.27125158])}
episode index:1472
target Thresh 1.9052215612653993
current state at start:  [ 0.84817885 -1.86677182]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.84817885, -1.86677182]), 'currentState': array([1.34226005, 4.84980494]), 'targetState': array([0.93144572, 0.75511626]), 'effectorPosition': array([1.22240352, 0.88300477])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.25965167256804705
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.84817885, -1.86677182]), 'currentState': array([1.34226005, 4.84980494]), 'targetState': array([0.93144572, 0.75511626]), 'effectorPosition': array([1.22240352, 0.88300477])}
episode index:1473
target Thresh 1.9054109287122993
current state at start:  [-0.32562307 -1.75301602]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.32562307, -1.75301602]), 'currentState': array([6.19400806, 4.92158268]), 'targetState': array([ 0.61374149, -0.26167676]), 'effectorPosition': array([ 1.11575489, -1.08186576])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2594755181090457
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.32562307, -1.75301602]), 'currentState': array([4.59405498, 6.01191399]), 'targetState': array([ 0.61374149, -0.26167676]), 'effectorPosition': array([-0.49788136, -1.91806574])}
episode index:1474
target Thresh 1.9055999178027878
current state at start:  [0.7713528  2.65355659]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.7713528 , 2.65355659]), 'currentState': array([1.2713528 , 2.15355659]), 'targetState': array([0.55516666, 0.56746886]), 'effectorPosition': array([-0.66514501,  0.6759591 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.259299602503548
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.7713528 , 2.65355659]), 'currentState': array([4.66029545, 4.19862388]), 'targetState': array([0.55516666, 0.56746886]), 'effectorPosition': array([-0.89619854, -0.46250263])}
episode index:1475
target Thresh 1.9057885292928216
current state at start:  [-0.5123918  -1.67595337]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.5123918 , -1.67595337]), 'currentState': array([5.4864247 , 4.91281204]), 'targetState': array([-0.12224189, -0.36833708]), 'effectorPosition': array([ 0.13741091, -1.54249348])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.25912392526607947
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.5123918 , -1.67595337]), 'currentState': array([3.60793014, 3.51811031]), 'targetState': array([-0.12224189, -0.36833708]), 'effectorPosition': array([-0.22788696,  0.29692791])}
episode index:1476
target Thresh 1.9059767639368472
current state at start:  [1.44526236 1.82981453]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.44526236, 1.82981453]), 'currentState': array([0.98658304, 1.32981453]), 'targetState': array([-0.88335224,  0.00835047]), 'effectorPosition': array([-0.12687034,  1.56882639])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2589484859124802
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.44526236, 1.82981453]), 'currentState': array([3.0447313 , 4.35305829]), 'targetState': array([-0.88335224,  0.00835047]), 'effectorPosition': array([-0.55477984,  0.99444649])}
episode index:1477
target Thresh 1.906164622487803
current state at start:  [-1.62652857  2.40174656]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.62652857,  2.40174656]), 'currentState': array([4.21505936, 2.0675311 ]), 'targetState': array([-0.0321417 , -0.00165346]), 'effectorPosition': array([ 0.52291947, -0.87945453])}
done in step count: 69
reward sum = 0.4998370298991989
running average episode reward sum: 0.25911146868919654
{'reset': False, 'endBeforeDone': False, 'stepCount': 70, 'initial state': array([-1.62652857,  2.40174656]), 'currentState': array([5.78290933, 3.57949825]), 'targetState': array([-0.0321417 , -0.00165346]), 'effectorPosition': array([-0.12060538, -0.41733776])}
episode index:1478
target Thresh 1.9063521056971235
current state at start:  [-0.26097019 -2.46026069]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.26097019, -2.46026069]), 'currentState': array([0.21637515, 3.34336445]), 'targetState': array([-0.1934102, -1.3753894]), 'effectorPosition': array([ 0.06283911, -0.19137704])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2589362749983992
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.26097019, -2.46026069]), 'currentState': array([1.7970646 , 5.88854499]), 'targetState': array([-0.1934102, -1.3753894]), 'effectorPosition': array([-0.05676484,  1.96036925])}
episode index:1479
target Thresh 1.9065392143147424
current state at start:  [-0.0115001   2.09305532]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.0115001 ,  2.09305532]), 'currentState': array([0.4884999 , 1.67532893]), 'targetState': array([-0.11343013,  0.30039378]), 'effectorPosition': array([0.32415956, 1.29855147])}
done in step count: 48
reward sum = 0.617290140942288
running average episode reward sum: 0.2591784059889019
{'reset': False, 'endBeforeDone': False, 'stepCount': 49, 'initial state': array([-0.0115001 ,  2.09305532]), 'currentState': array([0.13884357, 3.3369068 ]), 'targetState': array([-0.11343013,  0.30039378]), 'effectorPosition': array([ 0.04568982, -0.18957569])}
episode index:1480
target Thresh 1.9067259490890935
current state at start:  [-3.95552113  2.42633574]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.95552113,  2.42633574]), 'currentState': array([2.82766418, 2.00565313]), 'targetState': array([-0.00586918, -0.00291761]), 'effectorPosition': array([-0.830494  , -0.68389959])}
done in step count: 61
reward sum = 0.5416850759668536
running average episode reward sum: 0.25936915998618615
{'reset': False, 'endBeforeDone': False, 'stepCount': 62, 'initial state': array([-3.95552113,  2.42633574]), 'currentState': array([5.941529  , 3.63512952]), 'targetState': array([-0.00586918, -0.00291761]), 'effectorPosition': array([-0.04628729, -0.48634543])}
episode index:1481
target Thresh 1.9069123107671166
current state at start:  [ 2.83180503 -2.20050407]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.83180503, -2.20050407]), 'currentState': array([3.30069468, 4.13805954]), 'targetState': array([0.12368324, 0.02277718]), 'effectorPosition': array([-0.58397192,  0.75659297])}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.2598105554568322
{'reset': False, 'endBeforeDone': False, 'stepCount': 10, 'initial state': array([ 2.83180503, -2.20050407]), 'currentState': array([0.11499498, 3.50098147]), 'targetState': array([0.12368324, 0.02277718]), 'effectorPosition': array([ 0.103821  , -0.34204868])}
episode index:1482
target Thresh 1.907098300094259
current state at start:  [0.07767086 2.35173314]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.07767086, 2.35173314]), 'currentState': array([0.57767086, 2.77607997]), 'targetState': array([0.3746109 , 0.89786155]), 'effectorPosition': array([-0.13984194,  0.33550403])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.26028964409104877
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([0.07767086, 2.35173314]), 'currentState': array([2.04772119, 4.07545905]), 'targetState': array([0.3746109 , 0.89786155]), 'effectorPosition': array([0.52817711, 0.72908756])}
episode index:1483
target Thresh 1.9072839178144776
current state at start:  [-3.57085881  1.98129296]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.57085881,  1.98129296]), 'currentState': array([3.20608031, 1.48129296]), 'targetState': array([0.00475756, 0.10730475]), 'effectorPosition': array([-1.02293449, -1.0641301 ])}
done in step count: 20
reward sum = 0.8179069375972308
running average episode reward sum: 0.260665396984247
{'reset': False, 'endBeforeDone': False, 'stepCount': 21, 'initial state': array([-3.57085881,  1.98129296]), 'currentState': array([0.22718827, 3.41777326]), 'targetState': array([0.00475756, 0.10730475]), 'effectorPosition': array([ 0.0983411 , -0.25714034])}
episode index:1484
target Thresh 1.907469164670244
current state at start:  [ 2.7337091  -2.40255222]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.7337091 , -2.40255222]), 'currentState': array([3.16825679, 4.26830399]), 'targetState': array([-0.59346932,  0.51895316]), 'effectorPosition': array([-0.59424042,  0.8874766 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.2611632654037862
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.7337091 , -2.40255222]), 'currentState': array([3.16825679, 4.26830399]), 'targetState': array([-0.59346932,  0.51895316]), 'effectorPosition': array([-0.59424042,  0.8874766 ])}
episode index:1485
target Thresh 1.9076540414025456
current state at start:  [-2.18814768  1.82561302]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.18814768,  1.82561302]), 'currentState': array([3.59503763, 1.39703858]), 'targetState': array([-0.35588032, -0.78699983]), 'effectorPosition': array([-0.62288827, -1.39920679])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.26098751623460464
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.18814768,  1.82561302]), 'currentState': array([3.77668201, 3.34992032]), 'targetState': array([-0.35588032, -0.78699983]), 'effectorPosition': array([-0.14010422,  0.15367005])}
episode index:1486
target Thresh 1.9078385487508898
current state at start:  [-1.49222664  1.90695499]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.49222664,  1.90695499]), 'currentState': array([4.38120057, 1.41759919]), 'targetState': array([ 0.22338081, -0.44414735]), 'effectorPosition': array([ 0.55979416, -1.41132126])}
done in step count: 21
reward sum = 0.8097278682212584
running average episode reward sum: 0.2613565413536273
{'reset': False, 'endBeforeDone': False, 'stepCount': 22, 'initial state': array([-1.49222664,  1.90695499]), 'currentState': array([3.76609206, 3.20730265]), 'targetState': array([ 0.22338081, -0.44414735]), 'effectorPosition': array([-0.04014321,  0.05200743])}
episode index:1487
target Thresh 1.908022687453306
current state at start:  [-1.96704145  2.03865181]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.96704145,  2.03865181]), 'currentState': array([3.93453722, 1.84381757]), 'targetState': array([-0.12337651, -0.07820268]), 'effectorPosition': array([ 0.17350587, -1.19608181])}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.26178868216925577
{'reset': False, 'endBeforeDone': False, 'stepCount': 11, 'initial state': array([-1.96704145,  2.03865181]), 'currentState': array([5.15080257, 3.89900158]), 'targetState': array([-0.12337651, -0.07820268]), 'effectorPosition': array([-0.50601359, -0.53917808])}
episode index:1488
target Thresh 1.9082064582463494
current state at start:  [-0.37792185 -2.12844383]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.37792185, -2.12844383]), 'currentState': array([0.12207815, 4.51755719]), 'targetState': array([-0.4023889 , -0.21901535]), 'effectorPosition': array([ 0.91986823, -0.87557947])}
done in step count: 51
reward sum = 0.598956006466161
running average episode reward sum: 0.2620151209364128
{'reset': False, 'endBeforeDone': False, 'stepCount': 52, 'initial state': array([-0.37792185, -2.12844383]), 'currentState': array([3.92025829, 3.70577091]), 'targetState': array([-0.4023889 , -0.21901535]), 'effectorPosition': array([-0.48586793,  0.27180098])}
episode index:1489
target Thresh 1.9083898618651034
current state at start:  [-0.4877394  -2.51148474]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.4877394 , -2.51148474]), 'currentState': array([6.13587238, 3.31837058]), 'targetState': array([-0.02674446,  0.15525715]), 'effectorPosition': array([-0.01039688, -0.17624144])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.2625104128015562
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.4877394 , -2.51148474]), 'currentState': array([6.13587238, 3.31837058]), 'targetState': array([-0.02674446,  0.15525715]), 'effectorPosition': array([-0.01039688, -0.17624144])}
episode index:1490
target Thresh 1.9085728990431827
current state at start:  [-4.05350867  2.77555273]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.05350867,  2.77555273]), 'currentState': array([2.68747888, 2.82976909]), 'targetState': array([-0.28018038, -0.32835561]), 'effectorPosition': array([-0.17791724, -0.25454679])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.26300504029129357
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.05350867,  2.77555273]), 'currentState': array([2.68747888, 2.82976909]), 'targetState': array([-0.28018038, -0.32835561]), 'effectorPosition': array([-0.17791724, -0.25454679])}
episode index:1491
target Thresh 1.9087555705127364
current state at start:  [-1.65661337  2.73929973]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.65661337,  2.73929973]), 'currentState': array([4.35397641, 2.3087024 ]), 'targetState': array([0.58410601, 0.70382446]), 'effectorPosition': array([ 0.57806427, -0.5660048 ])}
done in step count: 14
reward sum = 0.8687458127689782
running average episode reward sum: 0.2634110327661446
{'reset': False, 'endBeforeDone': False, 'stepCount': 15, 'initial state': array([-1.65661337,  2.73929973]), 'currentState': array([1.69871315, 4.09571597]), 'targetState': array([0.58410601, 0.70382446]), 'effectorPosition': array([0.75534928, 0.52230173])}
episode index:1492
target Thresh 1.9089378770044503
current state at start:  [ 1.21299667 -2.50767061]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.21299667, -2.50767061]), 'currentState': array([1.63982553, 4.2755147 ]), 'targetState': array([0.55840524, 0.55502426]), 'effectorPosition': array([0.86413004, 0.63801293])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.2639043944320748
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.21299667, -2.50767061]), 'currentState': array([1.63982553, 4.2755147 ]), 'targetState': array([0.55840524, 0.55502426]), 'effectorPosition': array([0.86413004, 0.63801293])}
episode index:1493
target Thresh 1.909119819247551
current state at start:  [-2.89240732  1.9884912 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.89240732,  1.9884912 ]), 'currentState': array([3.43880957, 2.4884912 ]), 'targetState': array([-0.18614901, -1.13021315]), 'effectorPosition': array([-0.01881658, -0.6412799 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.26439709564062097
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.89240732,  1.9884912 ]), 'currentState': array([3.43880957, 2.4884912 ]), 'targetState': array([-0.18614901, -1.13021315]), 'effectorPosition': array([-0.01881658, -0.6412799 ])}
episode index:1494
target Thresh 1.9093013979698072
current state at start:  [ 0.74241935 -2.21515628]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.74241935, -2.21515628]), 'currentState': array([1.14439975, 4.56802903]), 'targetState': array([0.6288215 , 0.59345646]), 'effectorPosition': array([1.25508521, 0.37019319])}
done in step count: 15
reward sum = 0.8600583546412884
running average episode reward sum: 0.2647955312653706
{'reset': False, 'endBeforeDone': False, 'stepCount': 16, 'initial state': array([ 0.74241935, -2.21515628]), 'currentState': array([1.83462051, 4.17604578]), 'targetState': array([0.6288215 , 0.59345646]), 'effectorPosition': array([0.70232162, 0.69624145])}
episode index:1495
target Thresh 1.9094826138975347
current state at start:  [ 2.36486308 -1.85541121]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.36486308, -1.85541121]), 'currentState': array([2.79144467, 4.92777409]), 'targetState': array([0.32606923, 0.71899696]), 'effectorPosition': array([-0.80496663,  1.33397003])}
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.26521103216139386
{'reset': False, 'endBeforeDone': False, 'stepCount': 13, 'initial state': array([ 2.36486308, -1.85541121]), 'currentState': array([2.03229816, 3.70101541]), 'targetState': array([0.32606923, 0.71899696]), 'effectorPosition': array([0.40729823, 0.37280687])}
episode index:1496
target Thresh 1.9096634677555968
current state at start:  [2.08934028 1.70683301]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.08934028, 1.70683301]), 'currentState': array([1.59290658, 1.21242527]), 'targetState': array([-1.06525589,  0.30374731]), 'effectorPosition': array([-0.96610349,  1.3297152 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2650338704832633
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([2.08934028, 1.70683301]), 'currentState': array([2.56984374, 4.67197232]), 'targetState': array([-1.06525589,  0.30374731]), 'effectorPosition': array([-0.26631479,  1.35950915])}
episode index:1497
target Thresh 1.9098439602674098
current state at start:  [-1.03433549 -2.347444  ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.03433549, -2.347444  ]), 'currentState': array([5.66989143, 3.4357413 ]), 'targetState': array([-0.48470028,  0.23643162]), 'effectorPosition': array([-0.13174733, -0.2618091 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.26552450207840134
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.03433549, -2.347444  ]), 'currentState': array([5.66989143, 3.4357413 ]), 'targetState': array([-0.48470028,  0.23643162]), 'effectorPosition': array([-0.13174733, -0.2618091 ])}
episode index:1498
target Thresh 1.9100240921549434
current state at start:  [-2.85572197  2.56387681]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.85572197,  2.56387681]), 'currentState': array([3.92746334, 2.46943978]), 'targetState': array([ 0.84373829, -0.39543871]), 'effectorPosition': array([ 0.28676852, -0.59396795])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.2660078079475952
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.85572197,  2.56387681]), 'currentState': array([4.42746334, 2.13669447]), 'targetState': array([ 0.84373829, -0.39543871]), 'effectorPosition': array([ 0.67970014, -0.68239241])}
episode index:1499
target Thresh 1.9102038641387258
current state at start:  [-0.13228563 -2.93920409]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.13228563, -2.93920409]), 'currentState': array([0.36771437, 3.33819733]), 'targetState': array([0.89012272, 0.64529324]), 'effectorPosition': array([ 0.08819843, -0.17535703])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2658304694089635
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.13228563, -2.93920409]), 'currentState': array([3.85446188, 4.91842543]), 'targetState': array([0.89012272, 0.64529324]), 'effectorPosition': array([-1.55142668, -0.04731656])}
episode index:1500
target Thresh 1.9103832769378448
current state at start:  [ 3.87524018 -1.89947639]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.87524018, -1.89947639]), 'currentState': array([4.37524018, 3.88370891]), 'targetState': array([-0.51253668,  1.12132678]), 'effectorPosition': array([-0.72478661, -0.02458645])}
done in step count: 28
reward sum = 0.7547192872036326
running average episode reward sum: 0.2661561781483337
{'reset': False, 'endBeforeDone': False, 'stepCount': 29, 'initial state': array([ 3.87524018, -1.89947639]), 'currentState': array([2.74821674, 4.95267817]), 'targetState': array([-0.51253668,  1.12132678]), 'effectorPosition': array([-0.77113083,  1.37161375])}
episode index:1501
target Thresh 1.9105623312699522
current state at start:  [-0.66862785  2.3953421 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.66862785,  2.3953421 ]), 'currentState': array([6.1011356 , 1.92430566]), 'targetState': array([ 0.3525955 , -0.19361462]), 'effectorPosition': array([0.81285392, 0.80429098])}
done in step count: 14
reward sum = 0.8687458127689782
running average episode reward sum: 0.2665573696494127
{'reset': False, 'endBeforeDone': False, 'stepCount': 15, 'initial state': array([-0.66862785,  2.3953421 ]), 'currentState': array([6.05006776, 3.71525677]), 'targetState': array([ 0.3525955 , -0.19361462]), 'effectorPosition': array([ 0.03037868, -0.56501418])}
episode index:1502
target Thresh 1.9107410278512655
current state at start:  [-3.23253818  2.2277348 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.23253818,  2.2277348 ]), 'currentState': array([3.54972469, 1.74667302]), 'targetState': array([0.12517723, 0.1837822 ]), 'effectorPosition': array([-0.36649114, -1.23115454])}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.26698781534324784
{'reset': False, 'endBeforeDone': False, 'stepCount': 10, 'initial state': array([-3.23253818,  2.2277348 ]), 'currentState': array([5.31441024, 3.56892371]), 'targetState': array([0.12517723, 0.1837822 ]), 'effectorPosition': array([-0.29065583, -0.30881865])}
episode index:1503
target Thresh 1.9109193673965712
current state at start:  [0.4472701  2.54025072]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.4472701 , 2.54025072]), 'currentState': array([0.94680829, 2.04025072]), 'targetState': array([ 0.60886045, -0.29277431]), 'effectorPosition': array([-0.40380711,  0.96547412])}
done in step count: 79
reward sum = 0.45204365026647536
running average episode reward sum: 0.26711085778668087
{'reset': False, 'endBeforeDone': False, 'stepCount': 80, 'initial state': array([0.4472701 , 2.54025072]), 'currentState': array([0.17627919, 3.94470046]), 'targetState': array([ 0.60886045, -0.29277431]), 'effectorPosition': array([ 0.42697147, -0.65478811])}
episode index:1504
target Thresh 1.9110973506192277
current state at start:  [-0.75551162 -2.67879341]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.75551162, -2.67879341]), 'currentState': array([6.02767369, 3.17264676]), 'targetState': array([-0.31665251,  0.12434192]), 'effectorPosition': array([-0.00738088, -0.03016293])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.2675978273163907
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.75551162, -2.67879341]), 'currentState': array([6.02767369, 3.17264676]), 'targetState': array([-0.31665251,  0.12434192]), 'effectorPosition': array([-0.00738088, -0.03016293])}
episode index:1505
target Thresh 1.911274978231168
current state at start:  [1.66605182 2.1541129 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.66605182, 2.1541129 ]), 'currentState': array([2.16605182, 1.6541129 ]), 'targetState': array([ 0.0694635 , -0.07367883]), 'effectorPosition': array([-1.33919012,  0.2003232 ])}
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.26800282279825166
{'reset': False, 'endBeforeDone': False, 'stepCount': 14, 'initial state': array([1.66605182, 2.1541129 ]), 'currentState': array([5.56861518, 3.66898999]), 'targetState': array([ 0.0694635 , -0.07367883]), 'effectorPosition': array([-0.22715925, -0.46921095])}
episode index:1506
target Thresh 1.911452250942903
current state at start:  [-1.9123366   1.71269772]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.9123366 ,  1.71269772]), 'currentState': array([4.82144015, 1.27980692]), 'targetState': array([-0.20071191, -0.55590991]), 'effectorPosition': array([ 1.09233   , -1.17499597])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.26782498416334904
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.9123366 ,  1.71269772]), 'currentState': array([4.22734702, 3.51707358]), 'targetState': array([-0.20071191, -0.55590991]), 'effectorPosition': array([-0.35690351,  0.1093488 ])}
episode index:1507
target Thresh 1.911629169463524
current state at start:  [ 2.36118331 -2.80117824]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.36118331, -2.80117824]), 'currentState': array([2.86118331, 3.98200707]), 'targetState': array([0.47836567, 0.13197044]), 'effectorPosition': array([-0.11368982,  0.80793952])}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.26825928105344493
{'reset': False, 'endBeforeDone': False, 'stepCount': 9, 'initial state': array([ 2.36118331, -2.80117824]), 'currentState': array([0.16169773, 3.30470631]), 'targetState': array([0.47836567, 0.13197044]), 'effectorPosition': array([ 0.03924444, -0.15813601])}
episode index:1508
target Thresh 1.9118057345007047
current state at start:  [-1.30950625 -1.85318816]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.30950625, -1.85318816]), 'currentState': array([5.22553085, 4.80052105]), 'targetState': array([-0.10661699, -0.28569708]), 'effectorPosition': array([-0.33369874, -1.43689986])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.2686991790434075
{'reset': False, 'endBeforeDone': False, 'stepCount': 8, 'initial state': array([-1.30950625, -1.85318816]), 'currentState': array([5.52571754, 3.87773437]), 'targetState': array([-0.10661699, -0.28569708]), 'effectorPosition': array([-0.27319441, -0.66575935])}
episode index:1509
target Thresh 1.9119819467607058
current state at start:  [-0.15044882 -2.5031733 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.15044882, -2.5031733 ]), 'currentState': array([0.3139678 , 3.28001201]), 'targetState': array([ 0.68275914, -0.10570181]), 'effectorPosition': array([ 0.05170946, -0.1282789 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2685212325672198
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.15044882, -2.5031733 ]), 'currentState': array([4.52795154, 5.99572191]), 'targetState': array([ 0.68275914, -0.10570181]), 'effectorPosition': array([-0.63797374, -1.87374539])}
episode index:1510
target Thresh 1.9121578069483767
current state at start:  [-1.05131307  1.65620877]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.05131307,  1.65620877]), 'currentState': array([4.74846901, 1.21073233]), 'targetState': array([1.31643526, 0.48347047]), 'effectorPosition': array([ 0.98404686, -1.31769497])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2683435216257458
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.05131307,  1.65620877]), 'currentState': array([4.41950126, 4.74192362]), 'targetState': array([1.31643526, 0.48347047]), 'effectorPosition': array([-1.25424071, -0.69709464])}
episode index:1511
target Thresh 1.9123333157671583
current state at start:  [ 2.50361942 -2.62562759]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.50361942, -2.62562759]), 'currentState': array([2.93520508, 4.10636299]), 'targetState': array([0.60928795, 1.05567141]), 'effectorPosition': array([-0.25282837,  0.89267379])}
done in step count: 27
reward sum = 0.7623427143471035
running average episode reward sum: 0.26867024066855094
{'reset': False, 'endBeforeDone': False, 'stepCount': 28, 'initial state': array([ 2.50361942, -2.62562759]), 'currentState': array([2.39105067, 4.36625075]), 'targetState': array([0.60928795, 1.05567141]), 'effectorPosition': array([0.15837728, 1.13858746])}
episode index:1512
target Thresh 1.9125084739190858
current state at start:  [ 1.85966098 -2.8173116 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.85966098, -2.8173116 ]), 'currentState': array([2.27344829, 3.90709336]), 'targetState': array([-0.11922191, -0.58003598]), 'effectorPosition': array([0.34849301, 0.66066755])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2684926661538989
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.85966098, -2.8173116 ]), 'currentState': array([1.27992385, 1.4814136 ]), 'targetState': array([-0.11922191, -0.58003598]), 'effectorPosition': array([-0.64178179,  1.32915147])}
episode index:1513
target Thresh 1.9126832821047925
current state at start:  [-0.1123056   2.26646299]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.1123056 ,  2.26646299]), 'currentState': array([5.89176335, 1.76646299]), 'targetState': array([-0.31468551,  1.26876536]), 'effectorPosition': array([1.11887497, 0.59939783])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.26831532621588444
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.1123056 ,  2.26646299]), 'currentState': array([4.07902904, 0.76698149]), 'targetState': array([-0.31468551,  1.26876536]), 'effectorPosition': array([-0.45863208, -1.79712937])}
episode index:1514
target Thresh 1.9128577410235112
current state at start:  [0.19091118 1.79473079]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.19091118, 1.79473079]), 'currentState': array([0.58860183, 1.9633609 ]), 'targetState': array([0.48210178, 1.21441868]), 'effectorPosition': array([5.71233098e-04, 1.11125216e+00])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.26879828639660003
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.19091118, 1.79473079]), 'currentState': array([0.58860183, 1.9633609 ]), 'targetState': array([0.48210178, 1.21441868]), 'effectorPosition': array([5.71233098e-04, 1.11125216e+00])}
episode index:1515
target Thresh 1.913031851373078
current state at start:  [-3.56320523  1.9409564 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.56320523,  1.9409564 ]), 'currentState': array([2.21998008, 2.29898958]), 'targetState': array([-0.29897151, -1.35450838]), 'effectorPosition': array([-0.79675198, -0.18477521])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2686209788198213
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.56320523,  1.9409564 ]), 'currentState': array([1.14268064, 1.78026745]), 'targetState': array([-0.29897151, -1.35450838]), 'effectorPosition': array([-0.56103506,  1.12665631])}
episode index:1516
target Thresh 1.9132056138499343
current state at start:  [-4.19931448  2.52786308]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.19931448,  2.52786308]), 'currentState': array([2.58387083, 2.99036129]), 'targetState': array([-1.04512  ,  0.5868481]), 'effectorPosition': array([-0.08941924, -0.12178492])}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.26904006985224643
{'reset': False, 'endBeforeDone': False, 'stepCount': 11, 'initial state': array([-4.19931448,  2.52786308]), 'currentState': array([1.23706737, 1.78196089]), 'targetState': array([-1.04512  ,  0.5868481]), 'effectorPosition': array([-0.66492986,  1.06708519])}
episode index:1517
target Thresh 1.91337902914913
current state at start:  [0.90828352 1.88666483]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.90828352, 1.88666483]), 'currentState': array([1.40828352, 2.38666483]), 'targetState': array([0.2017315 , 0.17400241]), 'effectorPosition': array([-0.63225009,  0.37896943])}
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.2694409136948991
{'reset': False, 'endBeforeDone': False, 'stepCount': 14, 'initial state': array([0.90828352, 1.88666483]), 'currentState': array([6.16107994, 3.32390385]), 'targetState': array([0.2017315 , 0.17400241]), 'effectorPosition': array([-0.00563378, -0.18197163])}
episode index:1518
target Thresh 1.913552097964327
current state at start:  [ 0.57555404 -2.4523831 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.57555404, -2.4523831 ]), 'currentState': array([1.07555404, 4.19659383]), 'targetState': array([ 0.31471405, -0.32799384]), 'effectorPosition': array([1.00622674, 0.03247043])}
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.26985295934372316
{'reset': False, 'endBeforeDone': False, 'stepCount': 12, 'initial state': array([ 0.57555404, -2.4523831 ]), 'currentState': array([6.01917863, 3.63440129]), 'targetState': array([ 0.31471405, -0.32799384]), 'effectorPosition': array([-0.00858664, -0.48776136])}
episode index:1519
target Thresh 1.9137248209878004
current state at start:  [2.3378312  1.57395427]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.3378312 , 1.57395427]), 'currentState': array([2.8378312 , 1.07435573]), 'targetState': array([-0.5012562 ,  0.76341211]), 'effectorPosition': array([-1.67171499, -0.3974502 ])}
done in step count: 14
reward sum = 0.8687458127689782
running average episode reward sum: 0.27024696779992397
{'reset': False, 'endBeforeDone': False, 'stepCount': 15, 'initial state': array([2.3378312 , 1.57395427]), 'currentState': array([1.27570128, 1.7000918 ]), 'targetState': array([-0.5012562 ,  0.76341211]), 'effectorPosition': array([-0.69545591,  1.1218155 ])}
episode index:1520
target Thresh 1.913897198910443
current state at start:  [0.23459638 2.23080841]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.23459638, 2.23080841]), 'currentState': array([0.73459638, 1.77748588]), 'targetState': array([-0.27242819,  0.40072464]), 'effectorPosition': array([-0.06621451,  1.25903675])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.270720178208997
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.23459638, 2.23080841]), 'currentState': array([1.23459638, 2.0305566 ]), 'targetState': array([-0.27242819,  0.40072464]), 'effectorPosition': array([-0.66247396,  0.82076896])}
episode index:1521
target Thresh 1.9140692324217663
current state at start:  [-3.45971731  1.7433101 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.45971731,  1.7433101 ]), 'currentState': array([3.31394231, 1.28597638]), 'targetState': array([-0.20561718, -0.24967376]), 'effectorPosition': array([-1.09741784, -1.16517955])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2705423068698321
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.45971731,  1.7433101 ]), 'currentState': array([5.78926846, 4.39054894]), 'targetState': array([-0.20561718, -0.24967376]), 'effectorPosition': array([ 0.15223821, -1.15939562])}
episode index:1522
target Thresh 1.9142409222099046
current state at start:  [-1.89538774  2.38046678]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.89538774,  2.38046678]), 'currentState': array([4.83672085, 1.88046678]), 'targetState': array([0.19758209, 0.2313193 ]), 'effectorPosition': array([ 1.03130181, -0.57177532])}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.27095848531247096
{'reset': False, 'endBeforeDone': False, 'stepCount': 11, 'initial state': array([-1.89538774,  2.38046678]), 'currentState': array([0.32730946, 3.43659287]), 'targetState': array([0.19758209, 0.2313193 ]), 'effectorPosition': array([ 0.13437648, -0.26141691])}
episode index:1523
target Thresh 1.9144122689616174
current state at start:  [-1.19944953 -2.56590927]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.19944953, -2.56590927]), 'currentState': array([5.52599572, 4.19272044]), 'targetState': array([0.16834138, 0.34508229]), 'effectorPosition': array([-0.23034101, -0.97660539])}
done in step count: 17
reward sum = 0.8429431933839268
running average episode reward sum: 0.2713338033623866
{'reset': False, 'endBeforeDone': False, 'stepCount': 18, 'initial state': array([-1.19944953, -2.56590927]), 'currentState': array([0.48906578, 3.28414718]), 'targetState': array([0.16834138, 0.34508229]), 'effectorPosition': array([ 0.07570029, -0.12065184])}
episode index:1524
target Thresh 1.914583273362292
current state at start:  [0.0317066  2.33216594]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.0317066 , 2.33216594]), 'currentState': array([0.5317066 , 2.03658615]), 'targetState': array([ 0.12037698, -0.08269992]), 'effectorPosition': array([0.02182742, 1.04941237])}
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.2717313031785417
{'reset': False, 'endBeforeDone': False, 'stepCount': 14, 'initial state': array([0.0317066 , 2.33216594]), 'currentState': array([0.08901699, 3.68195234]), 'targetState': array([ 0.12037698, -0.08269992]), 'effectorPosition': array([ 0.18764603, -0.49974151])}
episode index:1525
target Thresh 1.9147539360959462
current state at start:  [-2.99173633  1.9888413 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.99173633,  1.9888413 ]), 'currentState': array([3.73105934, 2.44724319]), 'targetState': array([-0.41200216, -1.23406003]), 'effectorPosition': array([ 0.16326757, -0.66060838])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2715532354831429
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.99173633,  1.9888413 ]), 'currentState': array([1.81135276, 0.79414264]), 'targetState': array([-0.41200216, -1.23406003]), 'effectorPosition': array([-1.09795176,  1.48199023])}
episode index:1526
target Thresh 1.9149242578452312
current state at start:  [ 2.22145643 -2.49407318]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.22145643, -2.49407318]), 'currentState': array([2.72091734, 4.28911212]), 'targetState': array([0.28468217, 0.62490102]), 'effectorPosition': array([-0.16553814,  1.07289165])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.2720302798606916
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.22145643, -2.49407318]), 'currentState': array([2.72091734, 4.28911212]), 'targetState': array([0.28468217, 0.62490102]), 'effectorPosition': array([-0.16553814,  1.07289165])}
episode index:1527
target Thresh 1.915094239291434
current state at start:  [-0.53683638  2.42621905]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.53683638,  2.42621905]), 'currentState': array([6.195126  , 1.96157974]), 'targetState': array([-0.10617547,  0.33651223]), 'effectorPosition': array([0.69800373, 0.86658238])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.27185224957282467
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.53683638,  2.42621905]), 'currentState': array([2.34749322, 5.70681652]), 'targetState': array([-0.10617547,  0.33651223]), 'effectorPosition': array([-0.89991824,  1.69323401])}
episode index:1528
target Thresh 1.9152638811144809
current state at start:  [1.42931829 2.75479795]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.42931829, 2.75479795]), 'currentState': array([1.62817712, 3.02701693]), 'targetState': array([-0.500446  ,  0.31820368]), 'effectorPosition': array([-1.14513067e-01, -1.06414927e-05])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.2723284743932479
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.42931829, 2.75479795]), 'currentState': array([1.62817712, 3.02701693]), 'targetState': array([-0.500446  ,  0.31820368]), 'effectorPosition': array([-1.14513067e-01, -1.06414927e-05])}
episode index:1529
target Thresh 1.9154331839929393
current state at start:  [-3.61971793  2.02512614]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.61971793,  2.02512614]), 'currentState': array([2.30432916, 1.82472435]), 'targetState': array([-0.30646719, -0.7902484 ]), 'effectorPosition': array([-1.22030893, -0.09181626])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.27215048192632424
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.61971793,  2.02512614]), 'currentState': array([1.26497407, 0.52992546]), 'targetState': array([-0.30646719, -0.7902484 ]), 'effectorPosition': array([0.0788453 , 1.92859351])}
episode index:1530
target Thresh 1.9156021486040207
current state at start:  [ 1.34889694 -1.72559731]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.34889694, -1.72559731]), 'currentState': array([1.84889694, 5.0319583 ]), 'targetState': array([ 0.44717714, -0.04231011]), 'effectorPosition': array([0.5521193 , 1.52429646])}
done in step count: 24
reward sum = 0.7856781408072188
running average episode reward sum: 0.27248590169045284
{'reset': False, 'endBeforeDone': False, 'stepCount': 25, 'initial state': array([ 1.34889694, -1.72559731]), 'currentState': array([0.37545173, 3.90340039]), 'targetState': array([ 0.44717714, -0.04231011]), 'effectorPosition': array([ 0.510259  , -0.54079282])}
episode index:1531
target Thresh 1.915770775623584
current state at start:  [ 4.53380222 -2.80572686]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.53380222, -2.80572686]), 'currentState': array([4.03380222, 3.97745845]), 'targetState': array([-0.0693614, -0.0631859]), 'effectorPosition': array([-0.78432491,  0.20919655])}
done in step count: 90
reward sum = 0.4047319726783238
running average episode reward sum: 0.27257222419109767
{'reset': False, 'endBeforeDone': False, 'stepCount': 91, 'initial state': array([ 4.53380222, -2.80572686]), 'currentState': array([4.66796777, 2.70204501]), 'targetState': array([-0.0693614, -0.0631859]), 'effectorPosition': array([ 0.42088928, -0.11385833])}
episode index:1532
target Thresh 1.9159390657261377
current state at start:  [ 3.82575499 -2.87541743]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.82575499, -2.87541743]), 'currentState': array([3.96393181, 3.87873112]), 'targetState': array([ 0.58974721, -0.14566328]), 'effectorPosition': array([-0.66919062,  0.2671963 ])}
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.2729668418028445
{'reset': False, 'endBeforeDone': False, 'stepCount': 14, 'initial state': array([ 3.82575499, -2.87541743]), 'currentState': array([0.54922372, 4.30716043]), 'targetState': array([ 0.58974721, -0.14566328]), 'effectorPosition': array([ 0.99642809, -0.46762532])}
episode index:1533
target Thresh 1.916107019584842
current state at start:  [-0.8618246  -2.23791609]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.8618246 , -2.23791609]), 'currentState': array([5.92136071, 4.54526922]), 'targetState': array([-0.67780238, -0.39909726]), 'effectorPosition': array([ 0.43063026, -1.21732153])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.27278889731666267
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.8618246 , -2.23791609]), 'currentState': array([1.30952829, 1.08431011]), 'targetState': array([-0.67780238, -0.39909726]), 'effectorPosition': array([-0.47491206,  1.64605707])}
episode index:1534
target Thresh 1.916274637871513
current state at start:  [ 1.70406493 -2.31149263]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.70406493, -2.31149263]), 'currentState': array([2.20406493, 4.47169268]), 'targetState': array([0.24589709, 0.2404731 ]), 'effectorPosition': array([0.33214531, 1.18866382])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2726111846799743
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.70406493, -2.31149263]), 'currentState': array([0.17747831, 4.42739959]), 'targetState': array([0.24589709, 0.2404731 ]), 'effectorPosition': array([ 0.87698793, -0.81767819])}
episode index:1535
target Thresh 1.9164419212566237
current state at start:  [-0.91915645 -2.43787338]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.91915645, -2.43787338]), 'currentState': array([5.84238912, 4.34531193]), 'targetState': array([-0.5455157 ,  0.26095573]), 'effectorPosition': array([ 0.18159312, -1.11769694])}
done in step count: 43
reward sum = 0.6491026283684022
running average episode reward sum: 0.27285629629695896
{'reset': False, 'endBeforeDone': False, 'stepCount': 44, 'initial state': array([-0.91915645, -2.43787338]), 'currentState': array([4.68223318, 3.187913  ]), 'targetState': array([-0.5455157 ,  0.26095573]), 'effectorPosition': array([-0.04631507,  0.00032401])}
episode index:1536
target Thresh 1.916608870409308
current state at start:  [ 2.60764364 -2.26117658]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.60764364, -2.26117658]), 'currentState': array([3.08032826, 4.52200872]), 'targetState': array([-0.00224249, -0.02445286]), 'effectorPosition': array([-0.74912678,  1.02973029])}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.2732671783911111
{'reset': False, 'endBeforeDone': False, 'stepCount': 11, 'initial state': array([ 2.60764364, -2.26117658]), 'currentState': array([4.04986886, 2.68907898]), 'targetState': array([-0.00224249, -0.02445286]), 'effectorPosition': array([ 0.28281988, -0.34829745])}
episode index:1537
target Thresh 1.916775485997363
current state at start:  [ 3.94081771 -3.00133079]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.94081771, -3.00133079]), 'currentState': array([4.38949603, 3.66895179]), 'targetState': array([0.31620212, 0.49733965]), 'effectorPosition': array([-0.52035582,  0.03084809])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.27308950142206617
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.94081771, -3.00133079]), 'currentState': array([6.27931169, 4.83452287]), 'targetState': array([0.31620212, 0.49733965]), 'effectorPosition': array([ 1.11797731, -0.99688901])}
episode index:1538
target Thresh 1.9169417686872507
current state at start:  [0.29670632 2.64951164]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.29670632, 2.64951164]), 'currentState': array([0.76034093, 2.14951164]), 'targetState': array([-0.13251542,  0.19365207]), 'effectorPosition': array([-0.24866712,  0.91883996])}
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.27348224445103103
{'reset': False, 'endBeforeDone': False, 'stepCount': 14, 'initial state': array([0.29670632, 2.64951164]), 'currentState': array([4.26076434, 2.9662112 ]), 'targetState': array([-0.13251542,  0.19365207]), 'effectorPosition': array([ 0.1502951 , -0.08995152])}
episode index:1539
target Thresh 1.9171077191441026
current state at start:  [-0.47630328  2.50241679]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.47630328,  2.50241679]), 'currentState': array([5.56833601, 2.3511632 ]), 'targetState': array([0.52058936, 0.39377685]), 'effectorPosition': array([0.68972133, 0.34235088])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.2739540092273615
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.47630328,  2.50241679]), 'currentState': array([5.56833601, 2.3511632 ]), 'targetState': array([0.52058936, 0.39377685]), 'effectorPosition': array([0.68972133, 0.34235088])}
episode index:1540
target Thresh 1.9172733380317204
current state at start:  [-2.01339609  2.34370591]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.01339609,  2.34370591]), 'currentState': array([3.8439345 , 2.09364172]), 'targetState': array([ 0.50069949, -0.39673591]), 'effectorPosition': array([ 0.17753786, -0.98477687])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.2744186724270842
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.01339609,  2.34370591]), 'currentState': array([4.33911022, 2.38869884]), 'targetState': array([ 0.50069949, -0.39673591]), 'effectorPosition': array([ 0.5381022 , -0.50101844])}
episode index:1541
target Thresh 1.9174386260125802
current state at start:  [-2.03641505 -1.9894197 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.03641505, -1.9894197 ]), 'currentState': array([3.78847956, 4.6951229 ]), 'targetState': array([-0.20423544, -0.71485664]), 'effectorPosition': array([-1.38680227,  0.20554564])}
done in step count: 37
reward sum = 0.6894490858690777
running average episode reward sum: 0.2746878231491607
{'reset': False, 'endBeforeDone': False, 'stepCount': 38, 'initial state': array([-2.03641505, -1.9894197 ]), 'currentState': array([3.90206732, 2.48108399]), 'targetState': array([-0.20423544, -0.71485664]), 'effectorPosition': array([ 0.27049863, -0.58946584])}
episode index:1542
target Thresh 1.9176035837478338
current state at start:  [-1.97291868 -2.14037739]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.97291868, -2.14037739]), 'currentState': array([3.85520894, 3.83979829]), 'targetState': array([-0.91498207, -0.69080903]), 'effectorPosition': array([-0.59769408,  0.3328182 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2745098012287789
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.97291868, -2.14037739]), 'currentState': array([2.32280916, 3.59530556]), 'targetState': array([-0.91498207, -0.69080903]), 'effectorPosition': array([0.25098842, 0.37330013])}
episode index:1543
target Thresh 1.9177682118973127
current state at start:  [-0.37199163  2.32694557]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.37199163,  2.32694557]), 'currentState': array([5.55192224, 1.89015179]), 'targetState': array([0.04171314, 1.27116374]), 'effectorPosition': array([1.14468961, 0.24854846])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2743320099067395
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.37199163,  2.32694557]), 'currentState': array([0.1621204, 4.3967837]), 'targetState': array([0.04171314, 1.27116374]), 'effectorPosition': array([ 0.83400428, -0.82683314])}
episode index:1544
target Thresh 1.9179325111195293
current state at start:  [ 2.6429111  -2.22356523]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.6429111 , -2.22356523]), 'currentState': array([3.12725618, 4.50987669]), 'targetState': array([-0.00886383,  0.02263712]), 'effectorPosition': array([-0.78474398,  0.99091628])}
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.2747339556959641
{'reset': False, 'endBeforeDone': False, 'stepCount': 12, 'initial state': array([ 2.6429111 , -2.22356523]), 'currentState': array([4.09184175, 2.64311557]), 'targetState': array([-0.00886383,  0.02263712]), 'effectorPosition': array([ 0.31819447, -0.37699992])}
episode index:1545
target Thresh 1.9180964820716813
current state at start:  [-0.27513466 -2.15630381]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.27513466, -2.15630381]), 'currentState': array([0.09535953, 4.5577832 ]), 'targetState': array([ 0.09470979, -0.73155769]), 'effectorPosition': array([ 0.93624513, -0.90303038])}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.2751531088258036
{'reset': False, 'endBeforeDone': False, 'stepCount': 9, 'initial state': array([-0.27513466, -2.15630381]), 'currentState': array([3.83165606, 2.06755657]), 'targetState': array([ 0.09470979, -0.73155769]), 'effectorPosition': array([ 0.15597811, -1.0111929 ])}
episode index:1546
target Thresh 1.918260125409652
current state at start:  [0.97230973 2.07349643]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.97230973, 2.07349643]), 'currentState': array([1.47230973, 1.79757777]), 'targetState': array([0.01447479, 1.07006548]), 'effectorPosition': array([-0.89345404,  0.86721092])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.27497524644130084
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.97230973, 2.07349643]), 'currentState': array([0.10738046, 4.91101825]), 'targetState': array([0.01447479, 1.07006548]), 'effectorPosition': array([ 1.29549641, -0.84636903])}
episode index:1547
target Thresh 1.9184234417880157
current state at start:  [-1.77411979 -2.33240525]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.77411979, -2.33240525]), 'currentState': array([4.00906552, 4.44178899]), 'targetState': array([ 0.07728361, -0.2299787 ]), 'effectorPosition': array([-1.20881484,  0.06440035])}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.2753877412740155
{'reset': False, 'endBeforeDone': False, 'stepCount': 10, 'initial state': array([-1.77411979, -2.33240525]), 'currentState': array([3.75866232, 2.56038378]), 'targetState': array([ 0.07728361, -0.2299787 ]), 'effectorPosition': array([ 0.18377948, -0.54279463])}
episode index:1548
target Thresh 1.9185864318600376
current state at start:  [-2.9883095   2.17336492]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.9883095 ,  2.17336492]), 'currentState': array([3.60513092, 2.67336492]), 'targetState': array([-0.69100131, -0.86986741]), 'effectorPosition': array([ 0.10551292, -0.45180524])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2752099570640258
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.9883095 ,  2.17336492]), 'currentState': array([2.05515077, 0.0812599 ]), 'targetState': array([-0.69100131, -0.86986741]), 'effectorPosition': array([-1.00157173,  1.72923525])}
episode index:1549
target Thresh 1.9187490962776783
current state at start:  [ 1.35623887 -2.46715405]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.35623887, -2.46715405]), 'currentState': array([1.85623887, 4.23351161]), 'targetState': array([ 0.14810607, -0.60551791]), 'effectorPosition': array([0.69976763, 0.76730634])}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.2756277214107122
{'reset': False, 'endBeforeDone': False, 'stepCount': 9, 'initial state': array([ 1.35623887, -2.46715405]), 'currentState': array([4.15672609, 1.88110611]), 'targetState': array([ 0.14810607, -0.60551791]), 'effectorPosition': array([ 0.44254504, -1.09244982])}
episode index:1550
target Thresh 1.918911435691596
current state at start:  [1.17490737 2.77618025]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.17490737, 2.77618025]), 'currentState': array([1.67490737, 2.41054619]), 'targetState': array([-1.04043839, -0.48467472]), 'effectorPosition': array([-0.6905888 ,  0.18475615])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2754500117257278
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.17490737, 2.77618025]), 'currentState': array([2.06613237, 0.37957371]), 'targetState': array([-1.04043839, -0.48467472]), 'effectorPosition': array([-1.24281298,  1.52087516])}
episode index:1551
target Thresh 1.9190734507511482
current state at start:  [-0.89705318 -2.38007398]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.89705318, -2.38007398]), 'currentState': array([4.96715603, 4.40311133]), 'targetState': array([ 0.37257385, -0.32639907]), 'effectorPosition': array([-0.74649468, -0.91323842])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2752725310480695
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.89705318, -2.38007398]), 'currentState': array([4.37300439, 1.5941092 ]), 'targetState': array([ 0.37257385, -0.32639907]), 'effectorPosition': array([ 0.61755696, -1.25379499])}
episode index:1552
target Thresh 1.9192351421043956
current state at start:  [ 3.32707999 -2.54152054]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.32707999, -2.54152054]), 'currentState': array([3.45106427, 3.37893   ]), 'targetState': array([-0.59043626,  0.64468977]), 'effectorPosition': array([-0.09830653,  0.21540874])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.275739193938573
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.32707999, -2.54152054]), 'currentState': array([3.45106427, 3.37893   ]), 'targetState': array([-0.59043626,  0.64468977]), 'effectorPosition': array([-0.09830653,  0.21540874])}
episode index:1553
target Thresh 1.9193965103981037
current state at start:  [ 4.23077443 -2.50956399]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.23077443, -2.50956399]), 'currentState': array([3.73077443, 4.22916993]), 'targetState': array([ 0.33569772, -0.11633354]), 'effectorPosition': array([-0.93716017,  0.43871026])}
done in step count: 30
reward sum = 0.7397003733882802
running average episode reward sum: 0.2760377532561082
{'reset': False, 'endBeforeDone': False, 'stepCount': 31, 'initial state': array([ 4.23077443, -2.50956399]), 'currentState': array([0.37713577, 3.96104109]), 'targetState': array([ 0.33569772, -0.11633354]), 'effectorPosition': array([ 0.56418394, -0.56253687])}
episode index:1554
target Thresh 1.9195575562777458
current state at start:  [1.01583166 2.56132528]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.01583166, 2.56132528]), 'currentState': array([1.49519048, 3.06132528]), 'targetState': array([0.47141824, 1.16947545]), 'effectorPosition': array([-0.07970896,  0.00926689])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.2764905264051396
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([1.01583166, 2.56132528]), 'currentState': array([2.43430916, 4.06132528]), 'targetState': array([0.47141824, 1.16947545]), 'effectorPosition': array([0.21738765, 0.86062587])}
episode index:1555
target Thresh 1.919718280387506
current state at start:  [ 1.75351572 -2.74092999]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.75351572, -2.74092999]), 'currentState': array([2.25351572, 4.04225532]), 'targetState': array([0.69272405, 0.22108503]), 'effectorPosition': array([0.36901558, 0.78844531])}
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.2768882434538887
{'reset': False, 'endBeforeDone': False, 'stepCount': 12, 'initial state': array([ 1.75351572, -2.74092999]), 'currentState': array([0.8264814 , 4.15697215]), 'targetState': array([0.69272405, 0.22108503]), 'effectorPosition': array([ 0.94522535, -0.2279342 ])}
episode index:1556
target Thresh 1.9198786833702803
current state at start:  [1.51576454 2.50454637]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.51576454, 2.50454637]), 'currentState': array([1.11609683, 2.01711567]), 'targetState': array([-1.26083827, -0.4708957 ]), 'effectorPosition': array([-0.56077253,  0.9067731 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.27671040900080335
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.51576454, 2.50454637]), 'currentState': array([1.63243205, 5.89813469]), 'targetState': array([-1.26083827, -0.4708957 ]), 'effectorPosition': array([0.25620955, 1.9462568 ])}
episode index:1557
target Thresh 1.9200387658676816
current state at start:  [1.17842716 2.08054439]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.17842716, 2.08054439]), 'currentState': array([1.60733557, 1.58054439]), 'targetState': array([0.26750928, 0.21588912]), 'effectorPosition': array([-1.03546005,  0.95306173])}
done in step count: 92
reward sum = 0.3966778064220251
running average episode reward sum: 0.2767874098977361
{'reset': False, 'endBeforeDone': False, 'stepCount': 93, 'initial state': array([1.17842716, 2.08054439]), 'currentState': array([0.89272045, 3.55143184]), 'targetState': array([0.26750928, 0.21588912]), 'effectorPosition': array([ 0.36226412, -0.18545857])}
episode index:1558
target Thresh 1.9201985285200398
current state at start:  [-0.72066974 -2.33216497]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.72066974, -2.33216497]), 'currentState': array([6.06187469, 4.3619285 ]), 'targetState': array([-0.7463638 , -0.05342367]), 'effectorPosition': array([ 0.43448831, -1.06045238])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2766098682621378
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.72066974, -2.33216497]), 'currentState': array([1.79169482, 0.54294301]), 'targetState': array([-0.7463638 , -0.05342367]), 'effectorPosition': array([-0.91080719,  1.69788515])}
episode index:1559
target Thresh 1.9203579719664055
current state at start:  [ 2.97166376 -2.67061707]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.97166376, -2.67061707]), 'currentState': array([3.47166376, 4.09288795]), 'targetState': array([0.59674117, 0.27530153]), 'effectorPosition': array([-0.66061339,  0.63429643])}
done in step count: 24
reward sum = 0.7856781408072188
running average episode reward sum: 0.2769361940778718
{'reset': False, 'endBeforeDone': False, 'stepCount': 25, 'initial state': array([ 2.97166376, -2.67061707]), 'currentState': array([0.91960478, 4.28784611]), 'targetState': array([0.59674117, 0.27530153]), 'effectorPosition': array([ 1.08122068, -0.08457717])}
episode index:1560
target Thresh 1.9205170968445529
current state at start:  [-0.63865312  2.5912511 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.63865312,  2.5912511 ]), 'currentState': array([5.14922963, 2.17456013]), 'targetState': array([ 0.62685841, -0.43671911]), 'effectorPosition': array([ 0.9287778 , -0.04338279])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.27739939959095455
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.63865312,  2.5912511 ]), 'currentState': array([5.14922963, 2.17456013]), 'targetState': array([ 0.62685841, -0.43671911]), 'effectorPosition': array([ 0.9287778 , -0.04338279])}
episode index:1561
target Thresh 1.9206759037909817
current state at start:  [ 3.17921969 -2.07542594]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.17921969, -2.07542594]), 'currentState': array([2.73589873, 4.70775937]), 'targetState': array([-0.43869671,  0.38685552]), 'effectorPosition': array([-0.51992272,  1.31164827])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2772218071456338
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.17921969, -2.07542594]), 'currentState': array([1.0809523 , 0.58445413]), 'targetState': array([-0.43869671,  0.38685552]), 'effectorPosition': array([0.37601924, 1.87793406])}
episode index:1562
target Thresh 1.92083439344092
current state at start:  [ 0.10155206 -2.75786466]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.10155206, -2.75786466]), 'currentState': array([0.60155206, 3.05037152]), 'targetState': array([ 0.35486574, -0.69204871]), 'effectorPosition': array([-0.04812465,  0.07745673])}
done in step count: 81
reward sum = 0.4430479816261725
running average episode reward sum: 0.27732790194696494
{'reset': False, 'endBeforeDone': False, 'stepCount': 82, 'initial state': array([ 0.10155206, -2.75786466]), 'currentState': array([4.18167644, 1.80178839]), 'targetState': array([ 0.35486574, -0.69204871]), 'effectorPosition': array([ 0.44927106, -1.15769979])}
episode index:1563
target Thresh 1.9209925664283263
current state at start:  [-4.24381896  3.11052159]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.24381896,  3.11052159]), 'currentState': array([2.53529043, 3.61052159]), 'targetState': array([ 0.08494534, -0.52073617]), 'effectorPosition': array([0.16881837, 0.43289105])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2771505823165641
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-4.24381896,  3.11052159]), 'currentState': array([0.81361795, 1.33128227]), 'targetState': array([ 0.08494534, -0.52073617]), 'effectorPosition': array([0.14379092, 1.5664563 ])}
episode index:1564
target Thresh 1.9211504233858931
current state at start:  [ 1.49598689 -2.30139146]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.49598689, -2.30139146]), 'currentState': array([1.95176737, 4.38388181]), 'targetState': array([0.14303623, 0.02665439]), 'effectorPosition': array([0.62680202, 0.98074382])}
done in step count: 17
reward sum = 0.8429431933839268
running average episode reward sum: 0.27751211114152724
{'reset': False, 'endBeforeDone': False, 'stepCount': 18, 'initial state': array([ 1.49598689, -2.30139146]), 'currentState': array([0.15336516, 3.57752266]), 'targetState': array([0.14303623, 0.02665439]), 'effectorPosition': array([ 0.15692998, -0.40301056])}
episode index:1565
target Thresh 1.9213079649450484
current state at start:  [-1.06838917  2.4523517 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.06838917,  2.4523517 ]), 'currentState': array([4.71479614, 1.9523517 ]), 'targetState': array([0.16394632, 0.23347044]), 'effectorPosition': array([ 0.92959472, -0.62539969])}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.2779124112461679
{'reset': False, 'endBeforeDone': False, 'stepCount': 11, 'initial state': array([-1.06838917,  2.4523517 ]), 'currentState': array([1.1015518 , 3.45148597]), 'targetState': array([0.16394632, 0.23347044]), 'effectorPosition': array([ 0.29353493, -0.09542026])}
episode index:1566
target Thresh 1.9214651917359584
current state at start:  [0.48757983 2.55227916]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.48757983, 2.55227916]), 'currentState': array([0.98757983, 2.05227916]), 'targetState': array([0.28685105, 0.07648407]), 'effectorPosition': array([-0.44411801,  0.93625388])}
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.27830071530517875
{'reset': False, 'endBeforeDone': False, 'stepCount': 13, 'initial state': array([0.48757983, 2.55227916]), 'currentState': array([0.58441255, 3.58288472]), 'targetState': array([0.28685105, 0.07648407]), 'effectorPosition': array([ 0.31553982, -0.30337022])}
episode index:1567
target Thresh 1.9216221043875306
current state at start:  [0.4932369 2.030646 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.4932369, 2.030646 ]), 'currentState': array([0.9932369 , 2.11215775]), 'targetState': array([0.29280066, 1.12698418]), 'effectorPosition': array([-0.45336406,  0.87398775])}
done in step count: 15
reward sum = 0.8600583546412884
running average episode reward sum: 0.27867173420781655
{'reset': False, 'endBeforeDone': False, 'stepCount': 16, 'initial state': array([0.4932369, 2.030646 ]), 'currentState': array([2.21005159, 4.23816772]), 'targetState': array([0.29280066, 1.12698418]), 'effectorPosition': array([0.38981484, 0.96682616])}
episode index:1568
target Thresh 1.921778703527416
current state at start:  [-1.15417028  2.83224774]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.15417028,  2.83224774]), 'currentState': array([4.6710842 , 2.33224774]), 'targetState': array([-0.19580668,  0.5490076 ]), 'effectorPosition': array([ 0.710416  , -0.33965218])}
done in step count: 38
reward sum = 0.682554595010387
running average episode reward sum: 0.2789291483957086
{'reset': False, 'endBeforeDone': False, 'stepCount': 39, 'initial state': array([-1.15417028,  2.83224774]), 'currentState': array([0.50015484, 3.01162322]), 'targetState': array([-0.19580668,  0.5490076 ]), 'effectorPosition': array([-0.05475197,  0.11777313])}
episode index:1569
target Thresh 1.9219349897820113
current state at start:  [ 1.61551967 -2.5059827 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.61551967, -2.5059827 ]), 'currentState': array([1.99772158, 4.27720261]), 'targetState': array([0.38849267, 0.30277404]), 'effectorPosition': array([0.58589188, 0.9019822 ])}
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.2793160628691611
{'reset': False, 'endBeforeDone': False, 'stepCount': 13, 'initial state': array([ 1.61551967, -2.5059827 ]), 'currentState': array([0.87156569, 3.037272  ]), 'targetState': array([0.38849267, 0.30277404]), 'effectorPosition': array([-0.07619672,  0.07118282])}
episode index:1570
target Thresh 1.9220909637764614
current state at start:  [-0.09176043 -1.72389195]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.09176043, -1.72389195]), 'currentState': array([0.40823957, 4.05929336]), 'targetState': array([ 1.32184283, -0.38369488]), 'effectorPosition': array([ 0.67540445, -0.57317804])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.27913826779413303
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.09176043, -1.72389195]), 'currentState': array([3.27911511, 4.27576624]), 'targetState': array([ 1.32184283, -0.38369488]), 'effectorPosition': array([-0.69589813,  0.8185126 ])}
episode index:1571
target Thresh 1.9222466261346627
current state at start:  [ 0.76878905 -2.86388157]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.76878905, -2.86388157]), 'currentState': array([1.22940406, 3.54852679]), 'targetState': array([0.28760134, 0.37940051]), 'effectorPosition': array([ 0.40029429, -0.05556345])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.2795968312370121
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.76878905, -2.86388157]), 'currentState': array([1.22940406, 3.54852679]), 'targetState': array([0.28760134, 0.37940051]), 'effectorPosition': array([ 0.40029429, -0.05556345])}
episode index:1572
target Thresh 1.9224019774792651
current state at start:  [-1.08393469 -1.81193214]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.08393469, -1.81193214]), 'currentState': array([5.47208778, 4.65046738]), 'targetState': array([-0.11912041, -0.75122991]), 'effectorPosition': array([-0.07756917, -1.36755948])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2794190837282791
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.08393469, -1.81193214]), 'currentState': array([4.3707369 , 0.99886595]), 'targetState': array([-0.11912041, -0.75122991]), 'effectorPosition': array([ 0.27586931, -1.73389982])}
episode index:1573
target Thresh 1.9225570184316738
current state at start:  [ 1.03698631 -2.61702442]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.03698631, -2.61702442]), 'currentState': array([1.52508547, 4.12090484]), 'targetState': array([0.3064022 , 0.35523519]), 'effectorPosition': array([0.84946267, 0.40401223])}
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.27980470366982163
{'reset': False, 'endBeforeDone': False, 'stepCount': 13, 'initial state': array([ 1.03698631, -2.61702442]), 'currentState': array([0.87363042, 3.40272491]), 'targetState': array([0.3064022 , 0.35523519]), 'effectorPosition': array([ 0.21969991, -0.13976908])}
episode index:1574
target Thresh 1.9227117496120532
current state at start:  [0.3741568  2.04589996]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.3741568 , 2.04589996]), 'currentState': array([0.82037386, 1.54589996]), 'targetState': array([-0.08495127,  1.23545101]), 'effectorPosition': array([-0.0322501 ,  1.43134465])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.2802619705246345
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.3741568 , 2.04589996]), 'currentState': array([0.82037386, 1.54589996]), 'targetState': array([-0.08495127,  1.23545101]), 'effectorPosition': array([-0.0322501 ,  1.43134465])}
episode index:1575
target Thresh 1.9228661716393276
current state at start:  [ 0.86624465 -1.83164827]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.86624465, -1.83164827]), 'currentState': array([1.33007044, 3.95153703]), 'targetState': array([0.41620834, 0.04818915]), 'effectorPosition': array([0.77738158, 0.12884273])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.28071865709156046
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.86624465, -1.83164827]), 'currentState': array([1.33007044, 3.95153703]), 'targetState': array([0.41620834, 0.04818915]), 'effectorPosition': array([0.77738158, 0.12884273])}
episode index:1576
target Thresh 1.923020285131186
current state at start:  [-0.77981037  2.31987574]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.77981037,  2.31987574]), 'currentState': array([5.05220309, 1.81987574]), 'targetState': array([-0.09291236, -0.03110992]), 'effectorPosition': array([ 1.16486761, -0.38737538])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2805406490655037
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.77981037,  2.31987574]), 'currentState': array([3.75814587, 2.04298576]), 'targetState': array([-0.09291236, -0.03110992]), 'effectorPosition': array([ 0.07016839, -1.04182625])}
episode index:1577
target Thresh 1.9231740907040822
current state at start:  [-0.48927613 -2.13689635]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.48927613, -2.13689635]), 'currentState': array([6.28194858, 4.36227774]), 'targetState': array([-0.27167153, -0.94136638]), 'effectorPosition': array([ 0.6558355 , -0.94014637])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2803628666516472
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.48927613, -2.13689635]), 'currentState': array([1.33469589, 6.14744361]), 'targetState': array([-0.27167153, -0.94136638]), 'effectorPosition': array([0.59724532, 1.90391714])}
episode index:1578
target Thresh 1.9233275889732389
current state at start:  [-0.83720518  1.57191231]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.83720518,  1.57191231]), 'currentState': array([4.98167821, 1.07191231]), 'targetState': array([0.69382048, 0.73811649]), 'effectorPosition': array([ 1.23980505, -1.1915432 ])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.28077559779873734
{'reset': False, 'endBeforeDone': False, 'stepCount': 8, 'initial state': array([-0.83720518,  1.57191231]), 'currentState': array([1.31144854, 4.50250096]), 'targetState': array([0.69382048, 0.73811649]), 'effectorPosition': array([1.14836433, 0.51435262])}
episode index:1579
target Thresh 1.923480780552649
current state at start:  [-4.18394674  2.58553561]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.18394674,  2.58553561]), 'currentState': array([1.84180494, 2.2132892 ]), 'targetState': array([-0.45376478, -0.69787152]), 'effectorPosition': array([-0.87868093,  0.17185346])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.28059789172418115
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-4.18394674,  2.58553561]), 'currentState': array([1.60282823, 0.08299469]), 'targetState': array([-0.45376478, -0.69787152]), 'effectorPosition': array([-0.14679953,  1.99287876])}
episode index:1580
target Thresh 1.9236336660550795
current state at start:  [-2.98996614  2.09354424]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.98996614,  2.09354424]), 'currentState': array([3.76813425, 2.39293691]), 'targetState': array([-0.45002611, -0.812073  ]), 'effectorPosition': array([ 0.18249316, -0.70815763])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.2810465964099976
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.98996614,  2.09354424]), 'currentState': array([3.29455014, 1.89921885]), 'targetState': array([-0.45002611, -0.812073  ]), 'effectorPosition': array([-0.52532199, -1.03871857])}
episode index:1581
target Thresh 1.9237862460920723
current state at start:  [-0.96838534  2.41829719]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.96838534,  2.41829719]), 'currentState': array([4.81479997, 1.91829719]), 'targetState': array([-0.02154873,  0.60197143]), 'effectorPosition': array([ 1.00271751, -0.55987442])}
done in step count: 75
reward sum = 0.4705866415856499
running average episode reward sum: 0.2811664068051781
{'reset': False, 'endBeforeDone': False, 'stepCount': 76, 'initial state': array([-0.96838534,  2.41829719]), 'currentState': array([2.27438728, 4.25458139]), 'targetState': array([-0.02154873,  0.60197143]), 'effectorPosition': array([0.32298698, 1.00584013])}
episode index:1582
target Thresh 1.923938521273948
current state at start:  [-1.52663873 -1.74361277]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.52663873, -1.74361277]), 'currentState': array([5.18325623, 4.10615406]), 'targetState': array([-1.12584767, -0.69498019]), 'effectorPosition': array([-0.53719245, -0.75622056])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2809887906290536
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.52663873, -1.74361277]), 'currentState': array([1.21845862, 0.13453883]), 'targetState': array([-1.12584767, -0.69498019]), 'effectorPosition': array([0.56117387, 1.91494399])}
episode index:1583
target Thresh 1.9240904922098072
current state at start:  [ 0.52349314 -1.68372834]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.52349314, -1.68372834]), 'currentState': array([0.937011  , 4.68255082]), 'targetState': array([ 0.90690396, -0.86529597]), 'effectorPosition': array([1.37996461, 0.18981627])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.28081139871577765
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.52349314, -1.68372834]), 'currentState': array([5.16667486, 5.15606988]), 'targetState': array([ 0.90690396, -0.86529597]), 'effectorPosition': array([-0.18438063, -1.68063605])}
episode index:1584
target Thresh 1.924242159507534
current state at start:  [0.15329193 2.66473419]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.15329193, 2.66473419]), 'currentState': array([0.54284983, 2.19075481]), 'targetState': array([ 0.05069506, -0.05954926]), 'effectorPosition': array([-0.06168096,  0.91334151])}
done in step count: 24
reward sum = 0.7856781408072188
running average episode reward sum: 0.28112992662876907
{'reset': False, 'endBeforeDone': False, 'stepCount': 25, 'initial state': array([0.15329193, 2.66473419]), 'currentState': array([5.25479599, 3.84734951]), 'targetState': array([ 0.05069506, -0.05954926]), 'effectorPosition': array([-0.43220503, -0.53940437])}
episode index:1585
target Thresh 1.924393523773798
current state at start:  [-0.53602823  2.60968745]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.53602823,  2.60968745]), 'currentState': array([6.06469712, 2.10968745]), 'targetState': array([-0.16631718, -0.22133971]), 'effectorPosition': array([0.66127723, 0.73235459])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2809526694240851
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.53602823,  2.60968745]), 'currentState': array([1.7238377 , 5.03845173]), 'targetState': array([-0.16631718, -0.22133971]), 'effectorPosition': array([0.7349636 , 1.44929637])}
episode index:1586
target Thresh 1.9245445856140562
current state at start:  [ 2.24042612 -2.18718207]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.24042612, -2.18718207]), 'currentState': array([2.614027  , 4.55382518]), 'targetState': array([0.00275449, 0.00093387]), 'effectorPosition': array([-0.23048787,  1.27713545])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.28077563560592245
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.24042612, -2.18718207]), 'currentState': array([2.62967155, 4.81980543]), 'targetState': array([0.00275449, 0.00093387]), 'effectorPosition': array([-0.47824162,  1.40915044])}
episode index:1587
target Thresh 1.9246953456325562
current state at start:  [-1.8850766   2.14638606]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.8850766 ,  2.14638606]), 'currentState': array([4.69789149, 1.6627084 ]), 'targetState': array([ 1.2052781 , -0.00849973]), 'effectorPosition': array([ 0.98250801, -0.92255763])}
done in step count: 56
reward sum = 0.5696012024771592
running average episode reward sum: 0.2809575156858162
{'reset': False, 'endBeforeDone': False, 'stepCount': 57, 'initial state': array([-1.8850766 ,  2.14638606]), 'currentState': array([0.27219665, 5.1913444 ]), 'targetState': array([ 1.2052781 , -0.00849973]), 'effectorPosition': array([ 1.64566392, -0.46205523])}
episode index:1588
target Thresh 1.9248458044323384
current state at start:  [-0.49195051 -2.29679998]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.49195051, -2.29679998]), 'currentState': array([0.00804949, 4.23760969]), 'targetState': array([-0.58308323, -1.17180803]), 'effectorPosition': array([ 0.54999934, -0.88499515])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.28078070164196106
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.49195051, -2.29679998]), 'currentState': array([2.67827815, 4.96695893]), 'targetState': array([-0.58308323, -1.17180803]), 'effectorPosition': array([-0.68734424,  1.42520749])}
episode index:1589
target Thresh 1.9249959626152382
current state at start:  [1.95418879 2.08684137]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.95418879, 2.08684137]), 'currentState': array([2.45418879, 1.67029896]), 'targetState': array([-0.86005882,  0.55040565]), 'effectorPosition': array([-1.3275118 , -0.19757375])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2806041100057083
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.95418879, 2.08684137]), 'currentState': array([2.45360003, 6.12172914]), 'targetState': array([-0.86005882,  0.55040565]), 'effectorPosition': array([-1.43291938,  1.38590423])}
episode index:1590
target Thresh 1.9251458207818883
current state at start:  [ 4.06105582 -2.33235339]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.06105582, -2.33235339]), 'currentState': array([4.56105582, 3.6726349 ]), 'targetState': array([0.09370667, 0.85787354]), 'effectorPosition': array([-0.52140648, -0.05979847])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2804277403576846
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 4.06105582, -2.33235339]), 'currentState': array([3.92149357, 5.78751508]), 'targetState': array([0.09370667, 0.85787354]), 'effectorPosition': array([-1.67086089, -0.98362806])}
episode index:1591
target Thresh 1.9252953795317218
current state at start:  [-1.03494872  2.21408888]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.03494872,  2.21408888]), 'currentState': array([4.74877121, 1.84489765]), 'targetState': array([ 0.38562462, -0.61958084]), 'effectorPosition': array([ 0.98856015, -0.69381914])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.28025159227957047
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.03494872,  2.21408888]), 'currentState': array([4.32632612, 0.40261384]), 'targetState': array([ 0.38562462, -0.61958084]), 'effectorPosition': array([-0.35999376, -1.92626178])}
episode index:1592
target Thresh 1.9254446394629738
current state at start:  [-2.42159302  2.91699148]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.42159302,  2.91699148]), 'currentState': array([3.36159229, 2.61010674]), 'targetState': array([-0.81577656, -0.69850832]), 'effectorPosition': array([-0.02401841, -0.524703  ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2800756653540968
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.42159302,  2.91699148]), 'currentState': array([4.17995628, 1.58925337]), 'targetState': array([-0.81577656, -0.69850832]), 'effectorPosition': array([ 0.363166  , -1.35321782])}
episode index:1593
target Thresh 1.9255936011726842
current state at start:  [ 0.45480812 -2.27647822]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.45480812, -2.27647822]), 'currentState': array([0.95480812, 4.42874033]), 'targetState': array([ 1.36498839, -0.25351679]), 'effectorPosition': array([1.19965977, 0.03310177])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.28052731173718704
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.45480812, -2.27647822]), 'currentState': array([0.95480812, 4.42874033]), 'targetState': array([ 1.36498839, -0.25351679]), 'effectorPosition': array([1.19965977, 0.03310177])}
episode index:1594
target Thresh 1.9257422652567002
current state at start:  [0.48998254 1.59856302]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.48998254, 1.59856302]), 'currentState': array([0.98998254, 2.06485099]), 'targetState': array([0.68736351, 0.83185809]), 'effectorPosition': array([-0.44753433,  0.92266672])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2803514325448753
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.48998254, 1.59856302]), 'currentState': array([0.12217565, 4.20969475]), 'targetState': array([0.68736351, 0.83185809]), 'effectorPosition': array([ 0.62114383, -0.80660023])}
episode index:1595
target Thresh 1.925890632309678
current state at start:  [-1.80741559 -2.61599927]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.80741559, -2.61599927]), 'currentState': array([4.04717123, 4.12991007]), 'targetState': array([-0.03754569, -0.15667848]), 'effectorPosition': array([-0.93473782,  0.16147341])}
done in step count: 55
reward sum = 0.5753547499769285
running average episode reward sum: 0.28053627171619866
{'reset': False, 'endBeforeDone': False, 'stepCount': 56, 'initial state': array([-1.80741559, -2.61599927]), 'currentState': array([0.02721278, 3.8668805 ]), 'targetState': array([-0.03754569, -0.15667848]), 'effectorPosition': array([ 0.2696477 , -0.65625689])}
episode index:1596
target Thresh 1.9260387029250865
current state at start:  [0.81095093 2.22470066]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.81095093, 2.22470066]), 'currentState': array([1.31095093, 1.72470066]), 'targetState': array([-0.3460703 ,  0.40015488]), 'effectorPosition': array([-0.73746235,  1.07217272])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.28036060717536193
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.81095093, 2.22470066]), 'currentState': array([0.43230574, 4.36583894]), 'targetState': array([-0.3460703 ,  0.40015488]), 'effectorPosition': array([ 0.99365277, -0.5773597 ])}
episode index:1597
target Thresh 1.9261864776952078
current state at start:  [-3.54168976  2.35439233]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.54168976,  2.35439233]), 'currentState': array([3.24149555, 2.76929332]), 'targetState': array([-0.94134892, -0.30896253]), 'effectorPosition': array([-0.03188493, -0.36877709])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2801851624900206
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.54168976,  2.35439233]), 'currentState': array([5.28729065, 5.375942  ]), 'targetState': array([-0.94134892, -0.30896253]), 'effectorPosition': array([ 0.21749485, -1.78452673])}
episode index:1598
target Thresh 1.9263339572111418
current state at start:  [-0.84771196  2.29502044]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.84771196,  2.29502044]), 'currentState': array([4.93547335, 1.79502044]), 'targetState': array([ 0.03902739, -0.13527461]), 'effectorPosition': array([ 1.12285316, -0.54267932])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2800099372476879
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.84771196,  2.29502044]), 'currentState': array([5.60907089, 5.30443832]), 'targetState': array([ 0.03902739, -0.13527461]), 'effectorPosition': array([ 0.69928705, -1.62084024])}
episode index:1599
target Thresh 1.926481142062806
current state at start:  [-0.10008057 -2.59927887]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.10008057, -2.59927887]), 'currentState': array([0.3704612 , 4.18390644]), 'targetState': array([-0.34465769, -0.22226014]), 'effectorPosition': array([ 0.77479596, -0.6254952 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2798349310369081
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.10008057, -2.59927887]), 'currentState': array([5.34790915, 5.48314159]), 'targetState': array([-0.34465769, -0.22226014]), 'effectorPosition': array([ 0.42981388, -1.79125954])}
episode index:1600
target Thresh 1.926628032838941
current state at start:  [ 1.54929235 -2.51433756]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.54929235, -2.51433756]), 'currentState': array([2.01979574, 4.26884775]), 'targetState': array([1.15201654, 0.01341   ]), 'effectorPosition': array([0.56592076, 0.90634003])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.27966014344725354
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.54929235, -2.51433756]), 'currentState': array([5.94040191, 4.97309367]), 'targetState': array([1.15201654, 0.01341   ]), 'effectorPosition': array([ 0.85983621, -1.33274329])}
episode index:1601
target Thresh 1.926774630127109
current state at start:  [ 0.16731185 -1.69752129]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.16731185, -1.69752129]), 'currentState': array([5.95049716, 5.0800163 ]), 'targetState': array([ 0.60342653, -0.53951265]), 'effectorPosition': array([ 0.98009991, -1.32597465])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.27948557406932145
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.16731185, -1.69752129]), 'currentState': array([5.34098969, 0.0572598 ]), 'targetState': array([ 0.60342653, -0.53951265]), 'effectorPosition': array([ 1.22135268, -1.58272544])}
episode index:1602
target Thresh 1.9269209345137002
current state at start:  [ 1.73927956 -2.27292574]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.73927956, -2.27292574]), 'currentState': array([1.34052798, 4.50354313]), 'targetState': array([ 0.1656409, -0.0193445]), 'effectorPosition': array([1.13336741, 0.54846731])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2793112224947305
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.73927956, -2.27292574]), 'currentState': array([6.10984872, 5.47303342]), 'targetState': array([ 0.1656409, -0.0193445]), 'effectorPosition': array([ 1.53913679, -1.00490536])}
episode index:1603
target Thresh 1.9270669465839319
current state at start:  [ 1.14546582 -1.8603092 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.14546582, -1.8603092 ]), 'currentState': array([0.65709582, 4.92179467]), 'targetState': array([0.61177535, 0.67088857]), 'effectorPosition': array([ 1.55383784, -0.03667661])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.27913708831611783
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.14546582, -1.8603092 ]), 'currentState': array([6.26835591, 5.80869937]), 'targetState': array([0.61177535, 0.67088857]), 'effectorPosition': array([ 1.88254492, -0.48485053])}
episode index:1604
target Thresh 1.9272126669218526
current state at start:  [0.56608185 2.38599939]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.56608185, 2.38599939]), 'currentState': array([0.06608185, 1.88599939]), 'targetState': array([-0.61531218,  0.49744442]), 'effectorPosition': array([0.62570397, 0.99422103])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2789631711271358
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.56608185, 2.38599939]), 'currentState': array([5.76564444, 5.34101937]), 'targetState': array([-0.61531218,  0.49744442]), 'effectorPosition': array([ 0.97989961, -1.48858046])}
episode index:1605
target Thresh 1.927358096110344
current state at start:  [0.44015616 2.61050126]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.44015616, 2.61050126]), 'currentState': array([0.92965406, 2.11050126]), 'targetState': array([ 0.22715755, -0.24563556]), 'effectorPosition': array([-0.39674838,  0.90267655])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.27878947052244896
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.44015616, 2.61050126]), 'currentState': array([5.18790842, 5.55172625]), 'targetState': array([ 0.22715755, -0.24563556]), 'effectorPosition': array([ 0.20464578, -1.8564809 ])}
episode index:1606
target Thresh 1.927503234731123
current state at start:  [-0.85972486  2.1177374 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.85972486,  2.1177374 ]), 'currentState': array([4.93670618, 1.6323462 ]), 'targetState': array([ 0.4075903 , -0.26279606]), 'effectorPosition': array([ 1.18185823, -0.69295678])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2786159860977306
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.85972486,  2.1177374 ]), 'currentState': array([5.58060021, 6.08856009]), 'targetState': array([ 0.4075903 , -0.26279606]), 'effectorPosition': array([ 1.38696705, -1.42778249])}
episode index:1607
target Thresh 1.9276480833647442
current state at start:  [-0.51774343  1.70629504]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.51774343,  1.70629504]), 'currentState': array([5.34681435, 1.25100466]), 'targetState': array([1.03755673, 0.05340977]), 'effectorPosition': array([ 1.54362459, -0.49594425])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.27844271744965987
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.51774343,  1.70629504]), 'currentState': array([5.99071483, 0.3994394 ]), 'targetState': array([1.03755673, 0.05340977]), 'effectorPosition': array([ 1.95181879, -0.18155363])}
episode index:1608
target Thresh 1.9277926425906025
current state at start:  [0.43774466 2.89554254]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.43774466, 2.89554254]), 'currentState': array([0.92910878, 3.39505798]), 'targetState': array([-0.09932751,  0.43565333]), 'effectorPosition': array([ 0.22000464, -0.12449667])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.27826966417591864
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.43774466, 2.89554254]), 'currentState': array([0.124276  , 5.42017875]), 'targetState': array([-0.09932751,  0.43565333]), 'effectorPosition': array([ 1.73161161, -0.54939357])}
episode index:1609
target Thresh 1.9279369129869348
current state at start:  [ 2.58425994 -2.42971036]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.58425994, -2.42971036]), 'currentState': array([3.03882668, 4.35347495]), 'targetState': array([0.61770296, 1.11041999]), 'effectorPosition': array([-0.54927137,  0.99789058])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.27809682587518825
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.58425994, -2.42971036]), 'currentState': array([5.52263574, 5.81209618]), 'targetState': array([0.61770296, 1.11041999]), 'effectorPosition': array([ 1.05715012, -1.63235494])}
episode index:1610
target Thresh 1.928080895130823
current state at start:  [-1.38831846  1.68016393]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.38831846,  1.68016393]), 'currentState': array([4.39486685, 1.38681785]), 'targetState': array([ 0.43262098, -0.5401657 ]), 'effectorPosition': array([ 0.56464863, -1.43075386])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2779242021471466
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.38831846,  1.68016393]), 'currentState': array([4.7744438 , 1.30711961]), 'targetState': array([ 0.43262098, -0.5401657 ]), 'effectorPosition': array([ 1.04175807, -1.19833386])}
episode index:1611
target Thresh 1.9282245895981958
current state at start:  [-0.20744304  1.96912084]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.20744304,  1.96912084]), 'currentState': array([5.63353204, 1.61387176]), 'targetState': array([0.91261565, 0.08150434]), 'effectorPosition': array([1.36635272, 0.21669333])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.27837213998700566
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.20744304,  1.96912084]), 'currentState': array([5.63353204, 1.61387176]), 'targetState': array([0.91261565, 0.08150434]), 'effectorPosition': array([1.36635272, 0.21669333])}
episode index:1612
target Thresh 1.9283679969638314
current state at start:  [ 1.8457461  -1.84790086]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.8457461 , -1.84790086]), 'currentState': array([1.39055604, 4.84081204]), 'targetState': array([0.06800495, 0.08070677]), 'effectorPosition': array([1.17792376, 0.9320066 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.278199559615036
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.8457461 , -1.84790086]), 'currentState': array([5.20049489, 0.20668716]), 'targetState': array([0.06800495, 0.08070677]), 'effectorPosition': array([ 1.10918032, -1.65140889])}
episode index:1613
target Thresh 1.9285111178013592
current state at start:  [ 1.66229238 -2.74982887]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.66229238, -2.74982887]), 'currentState': array([2.16229238, 4.00266204]), 'targetState': array([0.82202998, 0.5064884 ]), 'effectorPosition': array([0.43541533, 0.71215177])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.27864677178379993
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.66229238, -2.74982887]), 'currentState': array([2.16229238, 4.00266204]), 'targetState': array([0.82202998, 0.5064884 ]), 'effectorPosition': array([0.43541533, 0.71215177])}
episode index:1614
target Thresh 1.928653952683263
current state at start:  [ 4.49105078 -2.92862849]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.49105078, -2.92862849]), 'currentState': array([4.99105078, 3.81927462]), 'targetState': array([0.44811148, 0.7116154 ]), 'effectorPosition': array([-0.54201986, -0.38491309])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.278474235083005
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 4.49105078, -2.92862849]), 'currentState': array([0.50872957, 5.26677188]), 'targetState': array([0.44811148, 0.7116154 ]), 'effectorPosition': array([1.74723685e+00, 9.13553344e-04])}
episode index:1615
target Thresh 1.9287965021808824
current state at start:  [-2.10874302  2.13667867]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.10874302,  2.13667867]), 'currentState': array([3.69246033, 1.64437226]), 'targetState': array([ 0.67913289, -0.58696639]), 'effectorPosition': array([-0.26742471, -1.33471528])}
done in step count: 35
reward sum = 0.7034476949995692
running average episode reward sum: 0.278737213709191
{'reset': False, 'endBeforeDone': False, 'stepCount': 36, 'initial state': array([-2.10874302,  2.13667867]), 'currentState': array([4.57687009, 1.61373398]), 'targetState': array([ 0.67913289, -0.58696639]), 'effectorPosition': array([ 0.86061295, -1.08328039])}
episode index:1616
target Thresh 1.9289387668644156
current state at start:  [-3.63301534  3.04588444]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.63301534,  3.04588444]), 'currentState': array([3.15016997, 3.27890141]), 'targetState': array([-0.32805056,  0.50427243]), 'effectorPosition': array([-0.01058573,  0.13679193])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.2791832636697914
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.63301534,  3.04588444]), 'currentState': array([3.15016997, 3.27890141]), 'targetState': array([-0.32805056,  0.50427243]), 'effectorPosition': array([-0.01058573,  0.13679193])}
episode index:1617
target Thresh 1.9290807473029212
current state at start:  [ 3.93799169 -2.48329769]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.93799169, -2.48329769]), 'currentState': array([3.43799169, 4.29988762]), 'targetState': array([-0.00410334,  0.13054971]), 'effectorPosition': array([-0.84055279,  0.70118952])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2790107152991673
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.93799169, -2.48329769]), 'currentState': array([4.9416064, 1.8753459]), 'targetState': array([-0.00410334,  0.13054971]), 'effectorPosition': array([ 1.0881121 , -0.46506458])}
episode index:1618
target Thresh 1.9292224440643218
current state at start:  [-2.42597648  1.94343964]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.42597648,  1.94343964]), 'currentState': array([4.31027816, 1.44343964]), 'targetState': array([ 0.29871224, -0.44285907]), 'effectorPosition': array([ 0.47171447, -1.42531079])}
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.2793803943033055
{'reset': False, 'endBeforeDone': False, 'stepCount': 14, 'initial state': array([-2.42597648,  1.94343964]), 'currentState': array([4.38455106, 2.22501052]), 'targetState': array([ 0.29871224, -0.44285907]), 'effectorPosition': array([ 0.62521352, -0.62612803])}
episode index:1619
target Thresh 1.9293638577154042
current state at start:  [ 0.86876581 -1.97811112]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.86876581, -1.97811112]), 'currentState': array([1.01033234, 4.56727613]), 'targetState': array([ 0.97973979, -0.4957807 ]), 'effectorPosition': array([1.29281687, 0.1985355 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.27981904838089605
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.86876581, -1.97811112]), 'currentState': array([0.85417243, 4.53442139]), 'targetState': array([ 0.97973979, -0.4957807 ]), 'effectorPosition': array([ 1.28268024, -0.02592589])}
episode index:1620
target Thresh 1.9295049888218232
current state at start:  [-1.015742   -2.27218614]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.015742  , -2.27218614]), 'currentState': array([4.86309791, 4.41210487]), 'targetState': array([ 0.48049463, -1.07438059]), 'effectorPosition': array([-0.83869541, -0.83964682])}
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.28019876411555233
{'reset': False, 'endBeforeDone': False, 'stepCount': 12, 'initial state': array([-1.015742  , -2.27218614]), 'currentState': array([4.36574485, 1.70339354]), 'targetState': array([ 0.48049463, -1.07438059]), 'effectorPosition': array([ 0.63743582, -1.15293434])}
episode index:1621
target Thresh 1.9296458379481036
current state at start:  [-0.9492398   2.09346491]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.9492398 ,  2.09346491]), 'currentState': array([4.83394551, 2.57524085]), 'targetState': array([1.19392898, 0.43178796]), 'effectorPosition': array([ 0.55153048, -0.08992233])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2800260151857647
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.9492398 ,  2.09346491]), 'currentState': array([5.70735352, 5.84351392]), 'targetState': array([1.19392898, 0.43178796]), 'effectorPosition': array([ 1.36593208, -1.39427857])}
episode index:1622
target Thresh 1.929786405657642
current state at start:  [ 1.91043989 -2.39073056]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.91043989, -2.39073056]), 'currentState': array([1.41043989, 4.31356156]), 'targetState': array([ 0.16102163, -0.00063775]), 'effectorPosition': array([1.00735843, 0.45667589])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.27985347913204583
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.91043989, -2.39073056]), 'currentState': array([4.5150362 , 1.99255112]), 'targetState': array([ 0.16102163, -0.00063775]), 'effectorPosition': array([ 0.77885316, -0.75806566])}
episode index:1623
target Thresh 1.9299266925127094
current state at start:  [ 3.87312428 -1.61403593]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.87312428, -1.61403593]), 'currentState': array([4.3258434 , 5.16914938]), 'targetState': array([-0.44017102,  1.05078369]), 'effectorPosition': array([-1.37452708, -0.996374  ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.27968115556115175
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.87312428, -1.61403593]), 'currentState': array([5.52037275, 1.12773866]), 'targetState': array([-0.44017102,  1.05078369]), 'effectorPosition': array([ 1.65704565, -0.3340771 ])}
episode index:1624
target Thresh 1.9300666990744533
current state at start:  [0.37487507 2.3025251 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.37487507, 2.3025251 ]), 'currentState': array([6.15806038, 1.87020171]), 'targetState': array([ 0.27095596, -0.13887972]), 'effectorPosition': array([0.81878255, 0.86005288])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.27950904408080646
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.37487507, 2.3025251 ]), 'currentState': array([5.71012716, 6.1992731 ]), 'targetState': array([ 0.27095596, -0.13887972]), 'effectorPosition': array([ 1.63209289, -1.15292483])}
episode index:1625
target Thresh 1.9302064259029004
current state at start:  [ 0.04477516 -1.8025639 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.04477516, -1.8025639 ]), 'currentState': array([6.15992158, 4.95386813]), 'targetState': array([ 1.14869568, -0.54983047]), 'effectorPosition': array([ 1.11035291, -1.11597251])}
done in step count: 23
reward sum = 0.7936142836436554
running average episode reward sum: 0.27982522196491644
{'reset': False, 'endBeforeDone': False, 'stepCount': 24, 'initial state': array([ 0.04477516, -1.8025639 ]), 'currentState': array([5.42819975, 1.00056601]), 'targetState': array([ 1.14869568, -0.54983047]), 'effectorPosition': array([ 1.64565127, -0.60949468])}
episode index:1626
target Thresh 1.9303458735569579
current state at start:  [-0.51620162 -2.92022043]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.51620162, -2.92022043]), 'currentState': array([5.29732841, 2.86296488]), 'targetState': array([ 0.74728425, -0.7564321 ]), 'effectorPosition': array([0.25060485, 0.11970672])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.2802556305562103
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-0.51620162, -2.92022043]), 'currentState': array([4.36189458, 2.0536194 ]), 'targetState': array([ 0.74728425, -0.7564321 ]), 'effectorPosition': array([ 0.64789514, -0.80726026])}
episode index:1627
target Thresh 1.930485042594417
current state at start:  [-4.24436029  2.52188431]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.24436029,  2.52188431]), 'currentState': array([2.53882502, 2.02191628]), 'targetState': array([-0.12443452, -0.12462654]), 'effectorPosition': array([-0.97483684, -0.42159898])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.28008348336299393
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-4.24436029,  2.52188431]), 'currentState': array([5.88512633, 5.32876881]), 'targetState': array([-0.12443452, -0.12462654]), 'effectorPosition': array([ 1.13840577, -1.36389233])}
episode index:1628
target Thresh 1.9306239335719535
current state at start:  [-0.22187444  2.51629092]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.22187444,  2.51629092]), 'currentState': array([5.56131087, 2.9449022 ]), 'targetState': array([1.16445858, 0.43917295]), 'effectorPosition': array([0.14360713, 0.13393866])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2799115475229921
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.22187444,  2.51629092]), 'currentState': array([5.79380806, 5.12233602]), 'targetState': array([1.16445858, 0.43917295]), 'effectorPosition': array([ 0.80327906, -1.4669234 ])}
episode index:1629
target Thresh 1.930762547045132
current state at start:  [0.64931351 2.93693577]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.64931351, 2.93693577]), 'currentState': array([0.30901954, 2.43839442]), 'targetState': array([0.05469298, 0.03831993]), 'effectorPosition': array([0.02931991, 0.68817476])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2797398226472111
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.64931351, 2.93693577]), 'currentState': array([6.25562483, 4.55039375]), 'targetState': array([0.05469298, 0.03831993]), 'effectorPosition': array([ 0.81119765, -1.00964503])}
episode index:1630
target Thresh 1.9309008835684063
current state at start:  [1.68752993 1.88210415]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.68752993, 1.88210415]), 'currentState': array([2.0993895 , 1.71379063]), 'targetState': array([-0.6662728 ,  0.94950595]), 'effectorPosition': array([-1.2871539,  0.2412879])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2795683083476113
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.68752993, 1.88210415]), 'currentState': array([0.03953845, 5.12212105]), 'targetState': array([-0.6662728 ,  0.94950595]), 'effectorPosition': array([ 1.43352702, -0.86123601])}
episode index:1631
target Thresh 1.9310389436951227
current state at start:  [-2.08675038  2.41978853]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.08675038,  2.41978853]), 'currentState': array([4.24959052, 2.11226355]), 'targetState': array([1.04421466, 0.02750084]), 'effectorPosition': array([ 0.55045328, -0.81621898])}
done in step count: 55
reward sum = 0.5753547499769285
running average episode reward sum: 0.27974955003978613
{'reset': False, 'endBeforeDone': False, 'stepCount': 56, 'initial state': array([-2.08675038,  2.41978853]), 'currentState': array([0.45250508, 4.74219737]), 'targetState': array([1.04421466, 0.02750084]), 'effectorPosition': array([ 1.36318463, -0.44870437])}
episode index:1632
target Thresh 1.931176727977522
current state at start:  [ 3.6662326 -2.406156 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.6662326, -2.406156 ]), 'currentState': array([3.23089747, 4.10238467]), 'targetState': array([-0.71177001, -0.49692263]), 'effectorPosition': array([-0.49852792,  0.77828524])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2795782398438034
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.6662326, -2.406156 ]), 'currentState': array([4.36039803, 2.39708333]), 'targetState': array([-0.71177001, -0.49692263]), 'effectorPosition': array([ 0.54484707, -0.48197584])}
episode index:1633
target Thresh 1.9313142369667413
current state at start:  [ 0.26919212 -2.4493238 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.26919212, -2.4493238 ]), 'currentState': array([0.46558304, 4.2915082 ]), 'targetState': array([1.24557187, 0.09723733]), 'effectorPosition': array([ 0.93824734, -0.55005717])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.2800069557312919
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 0.26919212, -2.4493238 ]), 'currentState': array([0.40441201, 5.21377942]), 'targetState': array([1.24557187, 0.09723733]), 'effectorPosition': array([ 1.70625448, -0.22357604])}
episode index:1634
target Thresh 1.931451471212817
current state at start:  [0.23804129 1.7977823 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.23804129, 1.7977823 ]), 'currentState': array([6.0212266, 1.2977823]), 'targetState': array([-0.17735547,  0.25240865]), 'effectorPosition': array([1.47570216, 0.6013096 ])}
done in step count: 74
reward sum = 0.47534004200570695
running average episode reward sum: 0.28012642550882977
{'reset': False, 'endBeforeDone': False, 'stepCount': 75, 'initial state': array([0.23804129, 1.7977823 ]), 'currentState': array([3.94214827, 3.02433038]), 'targetState': array([-0.17735547,  0.25240865]), 'effectorPosition': array([ 0.07918965, -0.08639266])}
episode index:1635
target Thresh 1.9315884312646863
current state at start:  [-4.22768253  2.29540067]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.22768253,  2.29540067]), 'currentState': array([1.59134836, 1.95501685]), 'targetState': array([-0.11987032, -0.04932008]), 'effectorPosition': array([-0.93974258,  0.60597911])}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.28051358371297086
{'reset': False, 'endBeforeDone': False, 'stepCount': 10, 'initial state': array([-4.22768253,  2.29540067]), 'currentState': array([3.76126562, 2.76253172]), 'targetState': array([-0.11987032, -0.04932008]), 'effectorPosition': array([ 0.15712388, -0.34247189])}
episode index:1636
target Thresh 1.9317251176701893
current state at start:  [0.95103625 2.10078883]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.95103625, 2.10078883]), 'currentState': array([0.45103625, 1.64937794]), 'targetState': array([-0.54583528,  0.7641327 ]), 'effectorPosition': array([0.39479229, 1.29889858])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.28034222538449627
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.95103625, 2.10078883]), 'currentState': array([4.69844797, 2.63529368]), 'targetState': array([-0.54583528,  0.7641327 ]), 'effectorPosition': array([ 0.48314783, -0.13220291])}
episode index:1637
target Thresh 1.9318615309760718
current state at start:  [-0.71917132  3.05451676]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.71917132,  3.05451676]), 'currentState': array([5.08977592, 2.55451676]), 'targetState': array([ 0.34867918, -0.84163326]), 'effectorPosition': array([0.57664823, 0.048465  ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.28077547188914553
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.71917132,  3.05451676]), 'currentState': array([4.60976681, 2.05451676]), 'targetState': array([ 0.34867918, -0.84163326]), 'effectorPosition': array([ 0.82581457, -0.6227988 ])}
episode index:1638
target Thresh 1.9319976717279876
current state at start:  [-1.95758961 -1.73740989]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.95758961, -1.73740989]), 'currentState': array([3.85371073, 4.95471436]), 'targetState': array([-0.68536165, -0.25556073]), 'effectorPosition': array([-1.57297169, -0.0753756 ])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.2811785863964743
{'reset': False, 'endBeforeDone': False, 'stepCount': 7, 'initial state': array([-1.95758961, -1.73740989]), 'currentState': array([0.93056505, 2.82195089]), 'targetState': array([-0.68536165, -0.25556073]), 'effectorPosition': array([-0.22173782,  0.22833363])}
episode index:1639
target Thresh 1.9321335404704996
current state at start:  [-3.87403523  2.04388272]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.87403523,  2.04388272]), 'currentState': array([1.90915008, 1.61219829]), 'targetState': array([-0.54810897, -0.46154741]), 'effectorPosition': array([-1.26068985,  0.57260879])}
done in step count: 16
reward sum = 0.8514577710948755
running average episode reward sum: 0.28152631760665625
{'reset': False, 'endBeforeDone': False, 'stepCount': 17, 'initial state': array([-3.87403523,  2.04388272]), 'currentState': array([3.54227339, 2.13531172]), 'targetState': array([-0.54810897, -0.46154741]), 'effectorPosition': array([-0.09863511, -0.95930089])}
episode index:1640
target Thresh 1.9322691377470829
current state at start:  [ 3.61421614 -1.98640776]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.61421614, -1.98640776]), 'currentState': array([3.11599174, 3.88747355]), 'targetState': array([-0.60151073, -0.05974551]), 'effectorPosition': array([-0.24805123,  0.68519326])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.281940132166311
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([ 3.61421614, -1.98640776]), 'currentState': array([1.16854989, 2.86486619]), 'targetState': array([-0.60151073, -0.05974551]), 'effectorPosition': array([-0.23650758,  0.14196572])}
episode index:1641
target Thresh 1.9324044641001268
current state at start:  [-1.98945248  2.22182204]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.98945248,  2.22182204]), 'currentState': array([3.81089855, 1.72182204]), 'targetState': array([ 0.00162688, -1.32357128]), 'effectorPosition': array([-0.05288049, -1.3024205 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.28237744024659944
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.98945248,  2.22182204]), 'currentState': array([3.81089855, 1.72182204]), 'targetState': array([ 0.00162688, -1.32357128]), 'effectorPosition': array([-0.05288049, -1.3024205 ])}
episode index:1642
target Thresh 1.9325395200709372
current state at start:  [ 1.53555054 -2.25908339]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.53555054, -2.25908339]), 'currentState': array([1.10446239, 4.28628106]), 'targetState': array([0.13276511, 0.39856389]), 'effectorPosition': array([1.07712736, 0.11461623])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2822055732714037
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.53555054, -2.25908339]), 'currentState': array([5.44584904, 0.99094869]), 'targetState': array([0.13276511, 0.39856389]), 'effectorPosition': array([ 1.65766878, -0.58985353])}
episode index:1643
target Thresh 1.9326743061997378
current state at start:  [-0.02493808  1.99627024]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.02493808,  1.99627024]), 'currentState': array([5.76184089, 1.49627024]), 'targetState': array([0.03190263, 0.06253605]), 'effectorPosition': array([1.42837983, 0.32961386])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.2826182195224552
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([-0.02493808,  1.99627024]), 'currentState': array([4.08150349, 2.69596187]), 'targetState': array([0.03190263, 0.06253605]), 'effectorPosition': array([ 0.29045045, -0.33310752])}
episode index:1644
target Thresh 1.9328088230256735
current state at start:  [ 1.40522566 -2.89283129]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.40522566, -2.89283129]), 'currentState': array([0.90522566, 3.89035402]), 'targetState': array([-0.65542887,  0.5793923 ]), 'effectorPosition': array([ 0.70060287, -0.20997713])}
done in step count: 33
reward sum = 0.7177305325982749
running average episode reward sum: 0.2828827254878508
{'reset': False, 'endBeforeDone': False, 'stepCount': 34, 'initial state': array([ 1.40522566, -2.89283129]), 'currentState': array([3.94522921, 3.3958077 ]), 'targetState': array([-0.65542887,  0.5793923 ]), 'effectorPosition': array([-0.20334829,  0.15141823])}
episode index:1645
target Thresh 1.9329430710868116
current state at start:  [ 2.43988067 -2.02135489]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.43988067, -2.02135489]), 'currentState': array([2.52677077, 4.76183042]), 'targetState': array([0.9365777 , 0.94447332]), 'effectorPosition': array([-0.2811391 ,  1.42119788])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.28271086477977797
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.43988067, -2.02135489]), 'currentState': array([6.27221785, 5.38897975]), 'targetState': array([0.9365777 , 0.94447332]), 'effectorPosition': array([ 1.61748937, -0.79749924])}
episode index:1646
target Thresh 1.9330770509201447
current state at start:  [0.16576988 2.05186069]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.16576988, 2.05186069]), 'currentState': array([5.9546268 , 1.55186069]), 'targetState': array([0.01859875, 1.2797788 ]), 'effectorPosition': array([1.28705127, 0.61755004])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2825392127671612
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.16576988, 2.05186069]), 'currentState': array([6.16904459, 6.2422395 ]), 'targetState': array([0.01859875, 1.2797788 ]), 'effectorPosition': array([ 1.98149119, -0.26835862])}
episode index:1647
target Thresh 1.9332107630615922
current state at start:  [ 1.78846388 -1.95915793]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.78846388, -1.95915793]), 'currentState': array([1.28846388, 4.7447985 ]), 'targetState': array([-0.05925692, -0.03847022]), 'effectorPosition': array([1.24752799, 0.71307896])}
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.28290562396797975
{'reset': False, 'endBeforeDone': False, 'stepCount': 13, 'initial state': array([ 1.78846388, -1.95915793]), 'currentState': array([4.01280322, 2.81491533]), 'targetState': array([-0.05925692, -0.03847022]), 'effectorPosition': array([ 0.21146837, -0.24709008])}
episode index:1648
target Thresh 1.933344208046003
current state at start:  [ 2.63579995 -2.73439067]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.63579995, -2.73439067]), 'currentState': array([2.13579995, 4.04879464]), 'targetState': array([ 0.05585145, -0.23732917]), 'effectorPosition': array([0.45972499, 0.74615558])}
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.28326621547739816
{'reset': False, 'endBeforeDone': False, 'stepCount': 14, 'initial state': array([ 2.63579995, -2.73439067]), 'currentState': array([4.16804615, 2.68179177]), 'targetState': array([ 0.05585145, -0.23732917]), 'effectorPosition': array([ 0.32584659, -0.31865693])}
episode index:1649
target Thresh 1.933477386407157
current state at start:  [-3.74301075  2.7718879 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.74301075,  2.7718879 ]), 'currentState': array([2.78842865, 3.13533593]), 'targetState': array([ 0.26342513, -0.16287285]), 'effectorPosition': array([-0.00218235, -0.00586377])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.28370059958923005
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.74301075,  2.7718879 ]), 'currentState': array([2.78842865, 3.13533593]), 'targetState': array([ 0.26342513, -0.16287285]), 'effectorPosition': array([-0.00218235, -0.00586377])}
episode index:1650
target Thresh 1.933610298677768
current state at start:  [ 0.58775681 -1.76502283]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.58775681, -1.76502283]), 'currentState': array([0.14231241, 4.77880119]), 'targetState': array([ 0.30498166, -0.72709923]), 'effectorPosition': array([ 1.19710303, -0.83646347])}
done in step count: 54
reward sum = 0.5811664141181095
running average episode reward sum: 0.2838807727052378
{'reset': False, 'endBeforeDone': False, 'stepCount': 55, 'initial state': array([ 0.58775681, -1.76502283]), 'currentState': array([4.25019697, 1.73583813]), 'targetState': array([ 0.30498166, -0.72709923]), 'effectorPosition': array([ 0.51026358, -1.18787371])}
episode index:1651
target Thresh 1.9337429453894852
current state at start:  [ 0.24419332 -2.88413989]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.24419332, -2.88413989]), 'currentState': array([6.03491331, 2.89904542]), 'targetState': array([-0.43269974, -0.97218694]), 'effectorPosition': array([0.08739148, 0.22561926])}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.28426749420749126
{'reset': False, 'endBeforeDone': False, 'stepCount': 9, 'initial state': array([ 0.24419332, -2.88413989]), 'currentState': array([3.80939076, 1.84431315]), 'targetState': array([-0.43269974, -0.97218694]), 'effectorPosition': array([ 0.02314583, -1.20798422])}
episode index:1652
target Thresh 1.9338753270728954
current state at start:  [-1.30819721 -2.01433014]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.30819721, -2.01433014]), 'currentState': array([4.47498809, 4.76885517]), 'targetState': array([-0.03006282, -0.11153969]), 'effectorPosition': array([-1.21885313, -0.79200342])}
done in step count: 18
reward sum = 0.8345137614500875
running average episode reward sum: 0.28460037156214496
{'reset': False, 'endBeforeDone': False, 'stepCount': 19, 'initial state': array([-1.30819721, -2.01433014]), 'currentState': array([3.85774597, 2.89002028]), 'targetState': array([-0.03006282, -0.11153969]), 'effectorPosition': array([ 0.1396728 , -0.20843964])}
episode index:1653
target Thresh 1.9340074442575261
current state at start:  [ 1.73005343 -2.31771605]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.73005343, -2.31771605]), 'currentState': array([1.2484859 , 4.39743219]), 'targetState': array([0.75695861, 0.67643594]), 'effectorPosition': array([1.12048363, 0.35350484])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.28503289854427183
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.73005343, -2.31771605]), 'currentState': array([1.2484859 , 4.39743219]), 'targetState': array([0.75695861, 0.67643594]), 'effectorPosition': array([1.12048363, 0.35350484])}
episode index:1654
target Thresh 1.9341392974718457
current state at start:  [ 3.74663519 -1.77115657]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.74663519, -1.77115657]), 'currentState': array([3.29390152, 4.01202873]), 'targetState': array([-1.02750136, -0.05643636]), 'effectorPosition': array([-0.46739842,  0.70182075])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2848606732279309
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.74663519, -1.77115657]), 'currentState': array([3.65961287, 2.82910907]), 'targetState': array([-1.02750136, -0.05643636]), 'effectorPosition': array([ 0.11015041, -0.29106855])}
episode index:1655
target Thresh 1.9342708872432672
current state at start:  [1.52177125 2.82467741]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.52177125, 2.82467741]), 'currentState': array([1.07268667, 2.43884909]), 'targetState': array([-0.86328598, -0.00696321]), 'effectorPosition': array([-0.45458217,  0.51692488])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2846886559131797
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.52177125, 2.82467741]), 'currentState': array([3.34076378, 3.11785938]), 'targetState': array([-0.86328598, -0.00696321]), 'effectorPosition': array([ 0.0044193 , -0.02331762])}
episode index:1656
target Thresh 1.9344022140981503
current state at start:  [ 2.18833887 -2.02809434]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.18833887, -2.02809434]), 'currentState': array([1.69491642, 4.75509097]), 'targetState': array([-0.00398336,  0.10541772]), 'effectorPosition': array([0.86231579, 1.15835638])}
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.28505718313004486
{'reset': False, 'endBeforeDone': False, 'stepCount': 12, 'initial state': array([ 2.18833887, -2.02809434]), 'currentState': array([3.53869666, 2.74986354]), 'targetState': array([-0.00398336,  0.10541772]), 'effectorPosition': array([ 0.07780067, -0.38137446])}
episode index:1657
target Thresh 1.9345332785618021
current state at start:  [-1.461887   -2.97479872]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.461887  , -2.97479872]), 'currentState': array([4.33606667, 3.75834584]), 'targetState': array([0.68095173, 0.00920025]), 'effectorPosition': array([-0.60562376,  0.04121298])}
done in step count: 34
reward sum = 0.7105532272722921
running average episode reward sum: 0.2853138152435203
{'reset': False, 'endBeforeDone': False, 'stepCount': 35, 'initial state': array([-1.461887  , -2.97479872]), 'currentState': array([3.78974647, 2.61615651]), 'targetState': array([0.68095173, 0.00920025]), 'effectorPosition': array([ 0.1952799 , -0.48130577])}
episode index:1658
target Thresh 1.934664081158481
current state at start:  [1.18317586 2.54561384]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.18317586, 2.54561384]), 'currentState': array([0.68762034, 2.15732785]), 'targetState': array([-1.27106962,  0.34630303]), 'effectorPosition': array([-0.18356417,  0.92701296])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2851418358491601
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.18317586, 2.54561384]), 'currentState': array([0.00749846, 5.12240927]), 'targetState': array([-1.27106962,  0.34630303]), 'effectorPosition': array([ 1.40546548, -0.90659949])}
episode index:1659
target Thresh 1.9347946224113974
current state at start:  [-0.71555145  2.1129329 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.71555145,  2.1129329 ]), 'currentState': array([5.12213879, 1.62072424]), 'targetState': array([0.16571275, 1.02481085]), 'effectorPosition': array([ 1.29457538, -0.47356122])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2849700636588895
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.71555145,  2.1129329 ]), 'currentState': array([4.4125356 , 3.77122338]), 'targetState': array([0.16571275, 1.02481085]), 'effectorPosition': array([-0.61921251, -0.00926534])}
episode index:1660
target Thresh 1.9349249028427165
current state at start:  [-1.77913971 -2.12972854]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.77913971, -2.12972854]), 'currentState': array([4.08823359, 4.59144228]), 'targetState': array([-0.59181078,  0.16430642]), 'effectorPosition': array([-1.3194308 , -0.13341015])}
done in step count: 29
reward sum = 0.7471720943315961
running average episode reward sum: 0.285248330986206
{'reset': False, 'endBeforeDone': False, 'stepCount': 30, 'initial state': array([-1.77913971, -2.12972854]), 'currentState': array([3.70307133, 3.42556786]), 'targetState': array([-0.59181078,  0.16430642]), 'effectorPosition': array([-0.18307701,  0.21583386])}
episode index:1661
target Thresh 1.93505492297356
current state at start:  [-1.16745801 -2.16115477]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.16745801, -2.16115477]), 'currentState': array([4.62587841, 4.11448098]), 'targetState': array([-0.82369348, -0.89766891]), 'effectorPosition': array([-0.86118947, -0.36403766])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.28565467736347067
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([-1.16745801, -2.16115477]), 'currentState': array([2.64685734, 2.1455389 ]), 'targetState': array([-0.82369348, -0.89766891]), 'effectorPosition': array([-0.80017248, -0.52200241])}
episode index:1662
target Thresh 1.9351846833240092
current state at start:  [-1.86603091  2.76966237]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.86603091,  2.76966237]), 'currentState': array([3.9171544 , 2.89268934]), 'targetState': array([ 1.0103358 , -0.85579078]), 'effectorPosition': array([ 0.15046367, -0.19746989])}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.28602673232296877
{'reset': False, 'endBeforeDone': False, 'stepCount': 11, 'initial state': array([-1.86603091,  2.76966237]), 'currentState': array([5.28634542, 0.71491732]), 'targetState': array([ 1.0103358 , -0.85579078]), 'effectorPosition': array([ 1.5034811 , -1.11796219])}
episode index:1663
target Thresh 1.935314184413105
current state at start:  [-3.30101905  2.02038399]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.30101905,  2.02038399]), 'currentState': array([3.46663102, 1.65410379]), 'targetState': array([ 0.04946646, -0.3352811 ]), 'effectorPosition': array([-0.55054676, -1.23712408])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.286443843661717
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-3.30101905,  2.02038399]), 'currentState': array([4.41522011, 2.54052365]), 'targetState': array([ 0.04946646, -0.3352811 ]), 'effectorPosition': array([ 0.48941599, -0.33317999])}
episode index:1664
target Thresh 1.9354434267588523
current state at start:  [-3.16196543  1.89271686]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.16196543,  1.89271686]), 'currentState': array([3.61777526, 2.0958295 ]), 'targetState': array([-0.00808669, -0.001802  ]), 'effectorPosition': array([-0.046624  , -0.99766868])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.28686045396582405
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-3.16196543,  1.89271686]), 'currentState': array([3.7013903 , 2.98812823]), 'targetState': array([-0.00808669, -0.001802  ]), 'effectorPosition': array([ 0.07121369, -0.13577097])}
episode index:1665
target Thresh 1.9355724108782204
current state at start:  [-2.6609735   2.29763966]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.6609735 ,  2.29763966]), 'currentState': array([4.09116691, 2.39031336]), 'targetState': array([ 0.11636953, -0.00356845]), 'effectorPosition': array([ 0.39837455, -0.61616979])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.287282506514464
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.6609735 ,  2.29763966]), 'currentState': array([3.7690213 , 2.88499418]), 'targetState': array([ 0.11636953, -0.00356845]), 'effectorPosition': array([ 0.12248709, -0.22467579])}
episode index:1666
target Thresh 1.9357011372871462
current state at start:  [ 1.21091687 -1.75254418]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.21091687, -1.75254418]), 'currentState': array([0.71091687, 4.86876826]), 'targetState': array([ 0.25968377, -0.1177121 ]), 'effectorPosition': array([1.52034654, 0.00563799])}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.2876526922184198
{'reset': False, 'endBeforeDone': False, 'stepCount': 11, 'initial state': array([ 1.21091687, -1.75254418]), 'currentState': array([4.32026115, 2.64259121]), 'targetState': array([ 0.25968377, -0.1177121 ]), 'effectorPosition': array([ 0.39562643, -0.29556389])}
episode index:1667
target Thresh 1.9358296065005356
current state at start:  [ 1.75876015 -2.75804035]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.75876015, -2.75804035]), 'currentState': array([1.26105213, 3.41199814]), 'targetState': array([-0.38314488, -0.64583304]), 'effectorPosition': array([ 0.26548645, -0.04681476])}
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.28800633030641776
{'reset': False, 'endBeforeDone': False, 'stepCount': 14, 'initial state': array([ 1.75876015, -2.75804035]), 'currentState': array([3.63564188, 1.99426304]), 'targetState': array([-0.38314488, -0.64583304]), 'effectorPosition': array([-0.08632569, -1.08198939])}
episode index:1668
target Thresh 1.9359578190322653
current state at start:  [-1.12872636 -2.39277458]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.12872636, -2.39277458]), 'currentState': array([4.71286899, 4.39041073]), 'targetState': array([0.24411279, 0.05110911]), 'effectorPosition': array([-0.94828304, -0.68401149])}
done in step count: 17
reward sum = 0.8429431933839268
running average episode reward sum: 0.28833882692899265
{'reset': False, 'endBeforeDone': False, 'stepCount': 18, 'initial state': array([-1.12872636, -2.39277458]), 'currentState': array([3.65046869, 2.89128256]), 'targetState': array([0.24411279, 0.05110911]), 'effectorPosition': array([ 0.093465  , -0.23150158])}
episode index:1669
target Thresh 1.9360857753951857
current state at start:  [-1.54111171  1.59745477]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.54111171,  1.59745477]), 'currentState': array([4.30815963, 2.09745477]), 'targetState': array([ 0.20923095, -0.61490075]), 'effectorPosition': array([ 0.59920457, -0.7972823 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.28876497134400525
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.54111171,  1.59745477]), 'currentState': array([4.30815963, 2.09745477]), 'targetState': array([ 0.20923095, -0.61490075]), 'effectorPosition': array([ 0.59920457, -0.7972823 ])}
episode index:1670
target Thresh 1.9362134761011225
current state at start:  [-0.02035852  2.65431192]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.02035852,  2.65431192]), 'currentState': array([5.80073284, 2.1852472 ]), 'targetState': array([ 0.78307673, -0.12137212]), 'effectorPosition': array([0.75424433, 0.52734774])}
done in step count: 20
reward sum = 0.8179069375972308
running average episode reward sum: 0.289081633202924
{'reset': False, 'endBeforeDone': False, 'stepCount': 21, 'initial state': array([-0.02035852,  2.65431192]), 'currentState': array([4.35576435, 2.31740612]), 'targetState': array([ 0.78307673, -0.12137212]), 'effectorPosition': array([ 0.57580146, -0.55690585])}
episode index:1671
target Thresh 1.9363409216608787
current state at start:  [1.64695451 2.36785085]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.64695451, 2.36785085]), 'currentState': array([1.17705241, 1.86785085]), 'targetState': array([-1.33312985,  0.0019216 ]), 'effectorPosition': array([-0.6116807 ,  1.02001799])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2889087374892859
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.64695451, 2.36785085]), 'currentState': array([3.12561435, 2.59221911]), 'targetState': array([-1.33312985,  0.0019216 ]), 'effectorPosition': array([-0.15547218, -0.51973532])}
episode index:1672
target Thresh 1.9364681125842365
current state at start:  [ 3.77607378 -1.75691845]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.77607378, -1.75691845]), 'currentState': array([3.29447952, 4.08950989]), 'targetState': array([-0.73132492,  0.05655873]), 'effectorPosition': array([-0.5354562 ,  0.73927985])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2887360484650843
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.77607378, -1.75691845]), 'currentState': array([4.2073543 , 3.27895828]), 'targetState': array([-0.73132492,  0.05655873]), 'effectorPosition': array([-0.12439654,  0.05801002])}
episode index:1673
target Thresh 1.93659504937996
current state at start:  [-2.51436691  1.74423808]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.51436691,  1.74423808]), 'currentState': array([4.2688184 , 2.24423808]), 'targetState': array([-0.23609138, -0.49200551]), 'effectorPosition': array([ 0.54452852, -0.67537296])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.28915496360937043
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-2.51436691,  1.74423808]), 'currentState': array([3.86188273, 2.71904537]), 'targetState': array([-0.23609138, -0.49200551]), 'effectorPosition': array([ 0.20438668, -0.36623966])}
episode index:1674
target Thresh 1.9367217325557966
current state at start:  [-3.49887348  1.78961061]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.49887348,  1.78961061]), 'currentState': array([2.29736793, 1.28961061]), 'targetState': array([-0.36367557, -1.27438141]), 'effectorPosition': array([-1.56675546,  0.31665016])}
done in step count: 29
reward sum = 0.7471720943315961
running average episode reward sum: 0.28942840667248815
{'reset': False, 'endBeforeDone': False, 'stepCount': 30, 'initial state': array([-3.49887348,  1.78961061]), 'currentState': array([4.06532708, 1.47269107]), 'targetState': array([-0.36367557, -1.27438141]), 'effectorPosition': array([ 0.13212974, -1.47595313])}
episode index:1675
target Thresh 1.936848162618479
current state at start:  [-2.8203505   1.74340635]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.8203505 ,  1.74340635]), 'currentState': array([3.91509351, 1.51929169]), 'targetState': array([ 0.42431354, -0.31044868]), 'effectorPosition': array([-0.05458508, -1.44913223])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.28984050189523725
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-2.8203505 ,  1.74340635]), 'currentState': array([3.84541819, 2.49623787]), 'targetState': array([ 0.42431354, -0.31044868]), 'effectorPosition': array([ 0.23591895, -0.58870146])}
episode index:1676
target Thresh 1.9369743400737276
current state at start:  [ 0.70016766 -2.18261718]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.70016766, -2.18261718]), 'currentState': array([0.20016766, 4.56239657]), 'targetState': array([ 0.41658136, -0.47252917]), 'effectorPosition': array([ 1.03018746, -0.79990784])}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.29021790451451734
{'reset': False, 'endBeforeDone': False, 'stepCount': 9, 'initial state': array([ 0.70016766, -2.18261718]), 'currentState': array([3.90023863, 2.2548487 ]), 'targetState': array([ 0.41658136, -0.47252917]), 'effectorPosition': array([ 0.2660385, -0.8156873])}
episode index:1677
target Thresh 1.9371002654262526
current state at start:  [-0.32914108  1.72764818]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.32914108,  1.72764818]), 'currentState': array([5.45404422, 1.28725082]), 'targetState': array([1.30015475, 0.14245298]), 'effectorPosition': array([ 1.57239941, -0.2950979 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.290640897420051
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.32914108,  1.72764818]), 'currentState': array([5.45404422, 1.28725082]), 'targetState': array([1.30015475, 0.14245298]), 'effectorPosition': array([ 1.57239941, -0.2950979 ])}
episode index:1678
target Thresh 1.9372259391797553
current state at start:  [1.14056279 2.64677996]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.14056279, 2.64677996]), 'currentState': array([1.49682267, 3.14677996]), 'targetState': array([0.33606007, 1.24438686]), 'effectorPosition': array([ 0.00517409, -0.00036996])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.29105153416965196
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([1.14056279, 2.64677996]), 'currentState': array([2.27963974, 4.14677996]), 'targetState': array([0.33606007, 1.24438686]), 'effectorPosition': array([0.33880326, 0.9018604 ])}
episode index:1679
target Thresh 1.937351361836931
current state at start:  [-0.51180844  2.01779016]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.51180844,  2.01779016]), 'currentState': array([5.27137686, 1.5715987 ]), 'targetState': array([0.55482442, 0.42914791]), 'effectorPosition': array([ 1.37769491, -0.31678382])}
done in step count: 35
reward sum = 0.7034476949995692
running average episode reward sum: 0.2912970080749079
{'reset': False, 'endBeforeDone': False, 'stepCount': 36, 'initial state': array([-0.51180844,  2.01779016]), 'currentState': array([3.92254614, 3.05338471]), 'targetState': array([0.55482442, 0.42914791]), 'effectorPosition': array([ 0.05925282, -0.06530468])}
episode index:1680
target Thresh 1.9374765338994706
current state at start:  [1.55708111 2.70195918]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.55708111, 2.70195918]), 'currentState': array([1.07266954, 2.25479577]), 'targetState': array([-0.70995169, -0.3790065 ]), 'effectorPosition': array([-0.50499456,  0.69367485])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2911237201462494
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.55708111, 2.70195918]), 'currentState': array([3.76437001, 2.35261352]), 'targetState': array([-0.70995169, -0.3790065 ]), 'effectorPosition': array([ 0.17395867, -0.74873101])}
episode index:1681
target Thresh 1.9376014558680623
current state at start:  [-3.19402058  2.36091707]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.19402058,  2.36091707]), 'currentState': array([3.58916473, 2.80275856]), 'targetState': array([-0.23091748,  0.23458905]), 'effectorPosition': array([ 0.09259334, -0.32425422])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.29153922328528253
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.19402058,  2.36091707]), 'currentState': array([4.08136111, 2.98018314]), 'targetState': array([-0.23091748,  0.23458905]), 'effectorPosition': array([ 0.12209171, -0.1053097 ])}
episode index:1682
target Thresh 1.9377261282423945
current state at start:  [-0.28948886 -1.72845916]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.28948886, -1.72845916]), 'currentState': array([5.49369645, 5.05472615]), 'targetState': array([ 0.7465853 , -1.09890996]), 'effectorPosition': array([ 0.27180929, -1.61167578])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.291936761482974
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([-0.28948886, -1.72845916]), 'currentState': array([5.02705261, 0.75726863]), 'targetState': array([ 0.7465853 , -1.09890996]), 'effectorPosition': array([ 1.18762322, -1.4293289 ])}
episode index:1683
target Thresh 1.9378505515211566
current state at start:  [ 1.88782368 -2.00596698]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.88782368, -2.00596698]), 'currentState': array([1.40666829, 4.46658088]), 'targetState': array([-0.16499032,  0.39364248]), 'effectorPosition': array([1.08053843, 0.58801044])}
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.29229507590861276
{'reset': False, 'endBeforeDone': False, 'stepCount': 12, 'initial state': array([ 1.88782368, -2.00596698]), 'currentState': array([4.10664076, 3.16239847]), 'targetState': array([-0.16499032,  0.39364248]), 'effectorPosition': array([-0.01722596,  0.01166758])}
episode index:1684
target Thresh 1.9379747262020417
current state at start:  [ 1.25444758 -2.16448769]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.25444758, -2.16448769]), 'currentState': array([0.7808952 , 4.60432655]), 'targetState': array([0.05213955, 0.70844919]), 'effectorPosition': array([ 1.33348755, -0.07814386])}
done in step count: 14
reward sum = 0.8687458127689782
running average episode reward sum: 0.2926371831708444
{'reset': False, 'endBeforeDone': False, 'stepCount': 15, 'initial state': array([ 1.25444758, -2.16448769]), 'currentState': array([3.61896387, 3.48751001]), 'targetState': array([0.05213955, 0.70844919]), 'effectorPosition': array([-0.20839268,  0.27393954])}
episode index:1685
target Thresh 1.9380986527817492
current state at start:  [ 2.58784485 -1.73605067]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.58784485, -1.73605067]), 'currentState': array([2.08784485, 5.04713463]), 'targetState': array([-0.34990863,  1.23092002]), 'effectorPosition': array([0.16431753, 1.62174525])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.29246361426030415
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.58784485, -1.73605067]), 'currentState': array([4.30506845, 1.9181995 ]), 'targetState': array([-0.34990863,  1.23092002]), 'effectorPosition': array([ 0.60205499, -0.9780671 ])}
episode index:1686
target Thresh 1.938222331755985
current state at start:  [-1.36512389 -1.84056173]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.36512389, -1.84056173]), 'currentState': array([4.8518698 , 4.89134553]), 'targetState': array([-0.21135022, -0.17889555]), 'effectorPosition': array([-0.81069681, -1.30337118])}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.29283722485909947
{'reset': False, 'endBeforeDone': False, 'stepCount': 9, 'initial state': array([-1.36512389, -1.84056173]), 'currentState': array([3.77542306, 2.45318379]), 'targetState': array([-0.21135022, -0.17889555]), 'effectorPosition': array([ 0.19274604, -0.64678687])}
episode index:1687
target Thresh 1.9383457636194656
current state at start:  [ 2.01280895 -1.79519352]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.01280895, -1.79519352]), 'currentState': array([1.55620951, 4.98799178]), 'targetState': array([0.23637612, 0.48513561]), 'effectorPosition': array([0.98071459, 1.25795587])}
done in step count: 23
reward sum = 0.7936142836436554
running average episode reward sum: 0.293133893732787
{'reset': False, 'endBeforeDone': False, 'stepCount': 24, 'initial state': array([ 2.01280895, -1.79519352]), 'currentState': array([3.70099168, 3.1807934 ]), 'targetState': array([0.23637612, 0.48513561]), 'effectorPosition': array([-0.02144875,  0.03280934])}
episode index:1688
target Thresh 1.9384689488659186
current state at start:  [ 4.17032021 -2.48584406]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.17032021, -2.48584406]), 'currentState': array([3.73658103, 4.29734125]), 'targetState': array([-0.09083148,  0.19778623]), 'effectorPosition': array([-1.00712619,  0.42335519])}
done in step count: 15
reward sum = 0.8600583546412884
running average episode reward sum: 0.29346955060721475
{'reset': False, 'endBeforeDone': False, 'stepCount': 16, 'initial state': array([ 4.17032021, -2.48584406]), 'currentState': array([3.96631804, 3.03957951]), 'targetState': array([-0.09083148,  0.19778623]), 'effectorPosition': array([ 0.0712559 , -0.07294009])}
episode index:1689
target Thresh 1.9385918879880848
current state at start:  [ 1.01913266 -1.65621293]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.01913266, -1.65621293]), 'currentState': array([0.62655215, 5.12697238]), 'targetState': array([0.8718573 , 0.90261347]), 'effectorPosition': array([1.67303249, 0.08111468])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.29329589998555367
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.01913266, -1.65621293]), 'currentState': array([4.60577338, 1.71377989]), 'targetState': array([0.8718573 , 0.90261347]), 'effectorPosition': array([ 0.89292503, -0.95796199])}
episode index:1690
target Thresh 1.9387145814777211
current state at start:  [ 3.66929454 -2.37696188]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.66929454, -2.37696188]), 'currentState': array([4.08548791, 4.40622342]), 'targetState': array([0.11672755, 0.46808553]), 'effectorPosition': array([-1.18201082, -0.00639984])}
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.29364663267137897
{'reset': False, 'endBeforeDone': False, 'stepCount': 13, 'initial state': array([ 3.66929454, -2.37696188]), 'currentState': array([3.94118672, 3.26469765]), 'targetState': array([0.11672755, 0.46808553]), 'effectorPosition': array([-0.09332727,  0.08016065])}
episode index:1691
target Thresh 1.9388370298256017
current state at start:  [-0.90924882  2.41240326]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.90924882,  2.41240326]), 'currentState': array([4.94643802, 2.76613614]), 'targetState': array([0.28053893, 0.66134722]), 'effectorPosition': array([0.37285473, 0.01728329])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2934730826520696
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.90924882,  2.41240326]), 'currentState': array([5.89571176, 4.90680752]), 'targetState': array([0.28053893, 0.66134722]), 'effectorPosition': array([ 0.7340086 , -1.35927315])}
episode index:1692
target Thresh 1.93895923352152
current state at start:  [1.25666898 2.16271298]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.25666898, 2.16271298]), 'currentState': array([0.80085798, 1.66271298]), 'targetState': array([-0.5283374 ,  0.27171287]), 'effectorPosition': array([-0.08272417,  1.3452071 ])}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.29383392671134706
{'reset': False, 'endBeforeDone': False, 'stepCount': 11, 'initial state': array([1.25666898, 2.16271298]), 'currentState': array([3.50098902, 3.33448072]), 'targetState': array([-0.5283374 ,  0.27171287]), 'effectorPosition': array([-0.08478105,  0.17292417])}
episode index:1693
target Thresh 1.939081193054291
current state at start:  [ 4.09103846 -2.07864462]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.09103846, -2.07864462]), 'currentState': array([3.59103846, 3.79475413]), 'targetState': array([-0.52593832, -0.2787288 ]), 'effectorPosition': array([-0.44941707,  0.45792054])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.29366047102851867
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 4.09103846, -2.07864462]), 'currentState': array([4.09196845, 2.30594197]), 'targetState': array([-0.52593832, -0.2787288 ]), 'effectorPosition': array([ 0.41204892, -0.69916043])}
episode index:1694
target Thresh 1.939202908911753
current state at start:  [0.99926472 2.96116301]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.99926472, 2.96116301]), 'currentState': array([1.48064566, 3.38308725]), 'targetState': array([0.0608205 , 0.41177052]), 'effectorPosition': array([0.24079544, 0.00736983])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.29407719051463754
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.99926472, 2.96116301]), 'currentState': array([1.48064566, 3.38308725]), 'targetState': array([0.0608205 , 0.41177052]), 'effectorPosition': array([0.24079544, 0.00736983])}
episode index:1695
target Thresh 1.9393243815807697
current state at start:  [ 0.7825973  -2.49285051]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.7825973 , -2.49285051]), 'currentState': array([1.17295196, 4.23329866]), 'targetState': array([0.2845054, 0.5822195]), 'effectorPosition': array([1.02694267, 0.15311611])}
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.29443170765127913
{'reset': False, 'endBeforeDone': False, 'stepCount': 12, 'initial state': array([ 0.7825973 , -2.49285051]), 'currentState': array([4.01355404, 3.31149921]), 'targetState': array([0.2845054, 0.5822195]), 'effectorPosition': array([-0.13871771,  0.09775609])}
episode index:1696
target Thresh 1.9394456115472316
current state at start:  [ 0.56070954 -1.93645883]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.56070954, -1.93645883]), 'currentState': array([0.24646014, 4.83227185]), 'targetState': array([0.37438148, 0.30656093]), 'effectorPosition': array([ 1.32798563, -0.68967093])}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.2947965194013277
{'reset': False, 'endBeforeDone': False, 'stepCount': 10, 'initial state': array([ 0.56070954, -1.93645883]), 'currentState': array([4.26568923, 2.91024559]), 'targetState': array([0.37438148, 0.30656093]), 'effectorPosition': array([ 0.19528161, -0.1230783 ])}
episode index:1697
target Thresh 1.9395665992960591
current state at start:  [1.0086461  2.48399313]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.0086461 , 2.48399313]), 'currentState': array([1.5086461 , 2.00414027]), 'targetState': array([0.13101669, 0.367691  ]), 'effectorPosition': array([-0.86978479,  0.63534119])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.2952001139128699
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([1.0086461 , 2.48399313]), 'currentState': array([2.5086461, 2.9854915]), 'targetState': array([0.13101669, 0.367691  ]), 'effectorPosition': array([-0.1017666 , -0.11815959])}
episode index:1698
target Thresh 1.9396873453112031
current state at start:  [0.25789116 1.90633688]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.25789116, 1.90633688]), 'currentState': array([6.11678444, 1.4488819 ]), 'targetState': array([0.86291042, 0.2746089 ]), 'effectorPosition': array([1.27052475, 0.79309026])}
done in step count: 96
reward sum = 0.38104711810454966
running average episode reward sum: 0.2952506418729592
{'reset': False, 'endBeforeDone': False, 'stepCount': 97, 'initial state': array([0.25789116, 1.90633688]), 'currentState': array([4.82149564, 2.53156332]), 'targetState': array([0.86291042, 0.2746089 ]), 'effectorPosition': array([ 0.58912537, -0.11691394])}
episode index:1699
target Thresh 1.9398078500756482
current state at start:  [-0.52834519  2.05521933]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.52834519,  2.05521933]), 'currentState': array([5.30355154, 1.55521933]), 'targetState': array([ 0.91688589, -0.01256007]), 'effectorPosition': array([ 1.39620037, -0.28596722])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.2956652003189163
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.52834519,  2.05521933]), 'currentState': array([5.30355154, 1.55521933]), 'targetState': array([ 0.91688589, -0.01256007]), 'effectorPosition': array([ 1.39620037, -0.28596722])}
episode index:1700
target Thresh 1.939928114071413
current state at start:  [ 3.67410621 -2.48258108]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.67410621, -2.48258108]), 'currentState': array([3.1753189 , 3.34444064]), 'targetState': array([-1.04344443, -0.39122422]), 'effectorPosition': array([-0.02728474,  0.20065381])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.29549138185899926
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.67410621, -2.48258108]), 'currentState': array([3.73979847, 2.70209775]), 'targetState': array([-1.04344443, -0.39122422]), 'effectorPosition': array([ 0.16108448, -0.40511531])}
episode index:1701
target Thresh 1.9400481377795542
current state at start:  [-1.19685664  2.16529512]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.19685664,  2.16529512]), 'currentState': array([4.58632866, 2.35325472]), 'targetState': array([ 0.0699261 , -0.36253312]), 'effectorPosition': array([ 0.6664688 , -0.38179753])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.2958994362762384
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.19685664,  2.16529512]), 'currentState': array([4.08632866, 2.80511276]), 'targetState': array([ 0.0699261 , -0.36253312]), 'effectorPosition': array([ 0.23468896, -0.23890506])}
episode index:1702
target Thresh 1.9401679216801666
current state at start:  [ 3.15836454 -2.10332923]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.15836454, -2.10332923]), 'currentState': array([3.63727513, 4.67985608]), 'targetState': array([-0.02921196,  0.0898154 ]), 'effectorPosition': array([-1.32641239,  0.41901771])}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.296262100874716
{'reset': False, 'endBeforeDone': False, 'stepCount': 10, 'initial state': array([ 3.15836454, -2.10332923]), 'currentState': array([3.62857054, 2.89667077]), 'targetState': array([-0.02921196,  0.0898154 ]), 'effectorPosition': array([ 0.08709609, -0.22825804])}
episode index:1703
target Thresh 1.9402874662523857
current state at start:  [-2.79952776  2.80029017]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.79952776,  2.80029017]), 'currentState': array([3.98365755, 3.30029017]), 'targetState': array([ 0.76533758, -0.50233383]), 'effectorPosition': array([-0.12626319,  0.0958629 ])}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.2966189787938088
{'reset': False, 'endBeforeDone': False, 'stepCount': 11, 'initial state': array([-2.79952776,  2.80029017]), 'currentState': array([4.80828441, 1.96967962]), 'targetState': array([ 0.76533758, -0.50233383]), 'effectorPosition': array([ 0.97582232, -0.52056864])}
episode index:1704
target Thresh 1.9404067719743905
current state at start:  [-1.01077858 -2.12688412]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.01077858, -2.12688412]), 'currentState': array([5.51864457, 4.63737266]), 'targetState': array([-0.14374198, -0.66990184]), 'effectorPosition': array([-0.02264706, -1.35999822])}
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.29697013379408144
{'reset': False, 'endBeforeDone': False, 'stepCount': 12, 'initial state': array([-1.01077858, -2.12688412]), 'currentState': array([3.74347924, 2.04052268]), 'targetState': array([-0.14374198, -0.66990184]), 'effectorPosition': array([ 0.05370487, -1.04490727])}
episode index:1705
target Thresh 1.9405258393234035
current state at start:  [-0.879625   -2.96321324]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.879625  , -2.96321324]), 'currentState': array([5.24489088, 3.79206431]), 'targetState': array([0.71329738, 0.39019725]), 'effectorPosition': array([-0.41804421, -0.4833658 ])}
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.29732087712377936
{'reset': False, 'endBeforeDone': False, 'stepCount': 12, 'initial state': array([-0.879625  , -2.96321324]), 'currentState': array([4.54813303, 2.87627714]), 'targetState': array([0.71329738, 0.39019725]), 'effectorPosition': array([ 0.25296289, -0.07739598])}
episode index:1706
target Thresh 1.9406446687756946
current state at start:  [ 1.23643305 -1.96687876]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.23643305, -1.96687876]), 'currentState': array([0.73643305, 4.81630654]), 'targetState': array([0.92958326, 0.70969403]), 'effectorPosition': array([1.4857461 , 0.00444784])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2971466996913694
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.23643305, -1.96687876]), 'currentState': array([4.30856668, 2.71128602]), 'targetState': array([0.92958326, 0.70969403]), 'effectorPosition': array([ 0.34777553, -0.24774265])}
episode index:1707
target Thresh 1.9407632608065817
current state at start:  [-0.02800758  2.8602031 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.02800758,  2.8602031 ]), 'currentState': array([0.36703621, 3.31525718]), 'targetState': array([0.38418453, 0.42512366]), 'effectorPosition': array([ 0.0760468 , -0.15588626])}
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.2974864973045472
{'reset': False, 'endBeforeDone': False, 'stepCount': 14, 'initial state': array([-0.02800758,  2.8602031 ]), 'currentState': array([4.08886531, 3.13050834]), 'targetState': array([0.38418453, 0.42512366]), 'effectorPosition': array([ 0.00896248, -0.00652186])}
episode index:1708
target Thresh 1.940881615890433
current state at start:  [ 3.89965327 -2.06682715]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.89965327, -2.06682715]), 'currentState': array([4.39965327, 4.66738993]), 'targetState': array([-0.04540797,  0.24150105]), 'effectorPosition': array([-1.24435521, -0.60134215])}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.2978416146700851
{'reset': False, 'endBeforeDone': False, 'stepCount': 11, 'initial state': array([ 3.89965327, -2.06682715]), 'currentState': array([4.26478852, 3.1604377 ]), 'targetState': array([-0.04540797,  0.24150105]), 'effectorPosition': array([-0.01706443,  0.00799565])}
episode index:1709
target Thresh 1.9409997345006689
current state at start:  [ 3.56978579 -2.60500107]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.56978579, -2.60500107]), 'currentState': array([4.03160634, 4.17818424]), 'targetState': array([0.00360326, 0.02508465]), 'effectorPosition': array([-0.97775015,  0.16028464])}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.29819631669367497
{'reset': False, 'endBeforeDone': False, 'stepCount': 11, 'initial state': array([ 3.56978579, -2.60500107]), 'currentState': array([4.10058834, 2.72059652]), 'targetState': array([0.00360326, 0.02508465]), 'effectorPosition': array([ 0.28439305, -0.306196  ])}
episode index:1710
target Thresh 1.9411176171097644
current state at start:  [ 2.64163911 -2.47224175]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.64163911, -2.47224175]), 'currentState': array([3.14163911, 4.31094356]), 'targetState': array([-0.31966543,  1.17942699]), 'effectorPosition': array([-0.60929351,  0.92046885])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.2986064883379218
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.64163911, -2.47224175]), 'currentState': array([3.14163911, 4.31094356]), 'targetState': array([-0.31966543,  1.17942699]), 'effectorPosition': array([-0.60929351,  0.92046885])}
episode index:1711
target Thresh 1.9412352641892496
current state at start:  [-0.27546246 -1.77153794]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.27546246, -1.77153794]), 'currentState': array([0.22453754, 5.01164736]), 'targetState': array([ 1.02906024, -0.3337727 ]), 'effectorPosition': array([ 1.47506791, -0.64327127])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.29901618080968706
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.27546246, -1.77153794]), 'currentState': array([0.22453754, 5.01164736]), 'targetState': array([ 1.02906024, -0.3337727 ]), 'effectorPosition': array([ 1.47506791, -0.64327127])}
episode index:1712
target Thresh 1.9413526762097133
current state at start:  [-0.86965442  2.22337153]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.86965442,  2.22337153]), 'currentState': array([4.99428358, 2.58692347]), 'targetState': array([0.12343896, 0.16798686]), 'effectorPosition': array([0.54758043, 0.00249699])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.2994253949481519
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.86965442,  2.22337153]), 'currentState': array([4.99428358, 2.58692347]), 'targetState': array([0.12343896, 0.16798686]), 'effectorPosition': array([0.54758043, 0.00249699])}
episode index:1713
target Thresh 1.9414698536408037
current state at start:  [-3.38548971  2.27403087]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.38548971,  2.27403087]), 'currentState': array([3.3976956 , 2.76166255]), 'targetState': array([0.21151177, 0.14962817]), 'effectorPosition': array([ 0.02495871, -0.37682349])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.2998282972848216
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.38548971,  2.27403087]), 'currentState': array([3.8976956, 2.7290311]), 'targetState': array([0.21151177, 0.14962817]), 'effectorPosition': array([ 0.21405248, -0.34926784])}
episode index:1714
target Thresh 1.9415867969512306
current state at start:  [-0.84440116 -2.15366485]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.84440116, -2.15366485]), 'currentState': array([5.93878415, 4.60435925]), 'targetState': array([-0.64751577, -0.33871842]), 'effectorPosition': array([ 0.50412468, -1.23702015])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.29965347028932027
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.84440116, -2.15366485]), 'currentState': array([3.78442778, 2.7083541 ]), 'targetState': array([-0.64751577, -0.33871842]), 'effectorPosition': array([ 0.17771552, -0.39140177])}
episode index:1715
target Thresh 1.9417035066087673
current state at start:  [-0.24053683  1.73600526]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.24053683,  1.73600526]), 'currentState': array([5.54264848, 1.89167531]), 'targetState': array([0.15509954, 1.21783485]), 'effectorPosition': array([1.14555449, 0.23854415])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.2994788470548859
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.24053683,  1.73600526]), 'currentState': array([5.59194061, 5.98074754]), 'targetState': array([0.15509954, 1.21783485]), 'effectorPosition': array([ 1.31606063, -1.4755375 ])}
episode index:1716
target Thresh 1.9418199830802527
current state at start:  [-3.66122914  2.00375579]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.66122914,  2.00375579]), 'currentState': array([3.04923254, 2.35944364]), 'targetState': array([-1.33996186, -0.09827545]), 'effectorPosition': array([-0.35436429, -0.6749999 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.29930442722550044
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.66122914,  2.00375579]), 'currentState': array([3.89061294, 2.78267389]), 'targetState': array([-1.33996186, -0.09827545]), 'effectorPosition': array([ 0.19251413, -0.30063928])}
episode index:1717
target Thresh 1.9419362268315932
current state at start:  [ 3.68274024 -2.36121351]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.68274024, -2.36121351]), 'currentState': array([4.18274024, 3.62554756]), 'targetState': array([-1.1999177 , -0.17322535]), 'effectorPosition': array([-0.4595523 ,  0.13597163])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.29913021044597454
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.68274024, -2.36121351]), 'currentState': array([3.81006163, 3.00815879]), 'targetState': array([-1.1999177 , -0.17322535]), 'effectorPosition': array([ 0.07547923, -0.10991396])}
episode index:1718
target Thresh 1.9420522383277632
current state at start:  [0.41436994 2.67667665]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.41436994, 2.67667665]), 'currentState': array([0.87519735, 3.01066991]), 'targetState': array([0.35254058, 0.50348518]), 'effectorPosition': array([-0.09473414,  0.09023159])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.2995379299279722
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.41436994, 2.67667665]), 'currentState': array([0.87519735, 3.01066991]), 'targetState': array([0.35254058, 0.50348518]), 'effectorPosition': array([-0.09473414,  0.09023159])}
episode index:1719
target Thresh 1.9421680180328094
current state at start:  [-3.27420179  2.288467  ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.27420179,  2.288467  ]), 'currentState': array([3.45535227, 2.71470818]), 'targetState': array([-0.29547433, -0.08650572]), 'effectorPosition': array([ 0.04242827, -0.42152061])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.29994517531754894
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.27420179,  2.288467  ]), 'currentState': array([3.45535227, 2.71470818]), 'targetState': array([-0.29547433, -0.08650572]), 'effectorPosition': array([ 0.04242827, -0.42152061])}
episode index:1720
target Thresh 1.9422835664098506
current state at start:  [-0.03185802  2.60959654]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.03185802,  2.60959654]), 'currentState': array([0.40430797, 2.3134359 ]), 'targetState': array([0.28274264, 0.08132272]), 'effectorPosition': array([0.00786205, 0.80465433])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.30032905145623723
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([-0.03185802,  2.60959654]), 'currentState': array([2.18960155, 3.13177686]), 'targetState': array([0.28274264, 0.08132272]), 'effectorPosition': array([-0.00802349, -0.00565444])}
episode index:1721
target Thresh 1.9423988839210806
current state at start:  [-4.44268595  2.72234814]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.44268595,  2.72234814]), 'currentState': array([2.28310589, 3.06988285]), 'targetState': array([-0.81732982, -0.13305905]), 'effectorPosition': array([-0.05590712, -0.04488304])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3001546443415704
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-4.44268595,  2.72234814]), 'currentState': array([4.7717347, 2.5077805]), 'targetState': array([-0.81732982, -0.13305905]), 'effectorPosition': array([ 0.60269784, -0.15875721])}
episode index:1722
target Thresh 1.9425139710277692
current state at start:  [ 2.89737276 -2.40317225]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.89737276, -2.40317225]), 'currentState': array([3.38994027, 4.33140019]), 'targetState': array([ 0.28436041, -0.15439802]), 'effectorPosition': array([-0.83706733,  0.74541344])}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.3005106296016645
{'reset': False, 'endBeforeDone': False, 'stepCount': 10, 'initial state': array([ 2.89737276, -2.40317225]), 'currentState': array([4.36123208, 2.43101091]), 'targetState': array([ 0.28436041, -0.15439802]), 'effectorPosition': array([ 0.5292198 , -0.45162076])}
episode index:1723
target Thresh 1.9426288281902655
current state at start:  [0.95872649 1.83927453]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.95872649, 1.83927453]), 'currentState': array([1.45872649, 2.10465286]), 'targetState': array([-0.11622988,  1.23754582]), 'effectorPosition': array([-0.80052355,  0.58433554])}
done in step count: 37
reward sum = 0.6894490858690777
running average episode reward sum: 0.30073623195448784
{'reset': False, 'endBeforeDone': False, 'stepCount': 38, 'initial state': array([0.95872649, 1.83927453]), 'currentState': array([1.34108882, 1.22185543]), 'targetState': array([-0.11622988,  1.23754582]), 'effectorPosition': array([-0.60950986,  1.52062592])}
episode index:1724
target Thresh 1.9427434558679981
current state at start:  [-0.72461594 -2.71617196]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.72461594, -2.71617196]), 'currentState': array([5.5021249 , 3.37338132]), 'targetState': array([ 0.14069465, -0.86742389]), 'effectorPosition': array([-0.14273757, -0.18196665])}
done in step count: 86
reward sum = 0.421334222154768
running average episode reward sum: 0.3008061438328648
{'reset': False, 'endBeforeDone': False, 'stepCount': 87, 'initial state': array([-0.72461594, -2.71617196]), 'currentState': array([2.7907482 , 2.57187836]), 'targetState': array([ 0.14069465, -0.86742389]), 'effectorPosition': array([-0.33370729, -0.45224905])}
episode index:1725
target Thresh 1.9428578545194777
current state at start:  [-0.81113644  2.4957875 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.81113644,  2.4957875 ]), 'currentState': array([4.97204887, 2.9957875 ]), 'targetState': array([0.64614791, 0.03265935]), 'effectorPosition': array([0.14314294, 0.02704819])}
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.30114027759831447
{'reset': False, 'endBeforeDone': False, 'stepCount': 14, 'initial state': array([-0.81113644,  2.4957875 ]), 'currentState': array([4.13905295, 2.78601998]), 'targetState': array([0.64614791, 0.03265935]), 'effectorPosition': array([ 0.2585294 , -0.24138764])}
episode index:1726
target Thresh 1.9429720246022992
current state at start:  [ 1.62547315 -2.0829708 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.62547315, -2.0829708 ]), 'currentState': array([2.1177036 , 4.69753954]), 'targetState': array([0.94568074, 0.198578  ]), 'effectorPosition': array([0.34171683, 1.36144476])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3009659056946675
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.62547315, -2.0829708 ]), 'currentState': array([2.8127495 , 1.87436572]), 'targetState': array([0.94568074, 0.198578  ]), 'effectorPosition': array([-0.97168765, -0.67673225])}
episode index:1727
target Thresh 1.9430859665731433
current state at start:  [-4.11032157  2.10544564]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.11032157,  2.10544564]), 'currentState': array([2.67286373, 2.58364256]), 'targetState': array([-0.13555083,  0.67221291]), 'effectorPosition': array([-0.37448014, -0.40383189])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.30079173561035344
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-4.11032157,  2.10544564]), 'currentState': array([0.41618529, 1.14326389]), 'targetState': array([-0.13555083,  0.67221291]), 'effectorPosition': array([0.92598468, 1.40420995])}
episode index:1728
target Thresh 1.9431996808877774
current state at start:  [0.88416125 2.43087037]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.88416125, 2.43087037]), 'currentState': array([1.38416125, 1.93087037]), 'targetState': array([-0.67651433,  0.19519938]), 'effectorPosition': array([-0.79944366,  0.81006343])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3006177669951942
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([0.88416125, 2.43087037]), 'currentState': array([6.13296958, 5.16020559]), 'targetState': array([-0.67651433,  0.19519938]), 'effectorPosition': array([ 1.2819662 , -1.10569417])}
episode index:1729
target Thresh 1.9433131680010596
current state at start:  [-0.3980148   2.79867507]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.3980148 ,  2.79867507]), 'currentState': array([0.1019852 , 2.29867507]), 'targetState': array([ 0.20338482, -0.08767942]), 'effectorPosition': array([0.25696447, 0.77678465])}
done in step count: 70
reward sum = 0.49483865960020695
running average episode reward sum: 0.3007300334071046
{'reset': False, 'endBeforeDone': False, 'stepCount': 71, 'initial state': array([-0.3980148 ,  2.79867507]), 'currentState': array([0.49132473, 4.02042675]), 'targetState': array([ 0.20338482, -0.08767942]), 'effectorPosition': array([ 0.68241454, -0.5081454 ])}
episode index:1730
target Thresh 1.943426428366938
current state at start:  [ 2.78603477 -1.7975294 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.78603477, -1.7975294 ]), 'currentState': array([3.20854438, 4.92747194]), 'targetState': array([-0.3250806 ,  0.81765095]), 'effectorPosition': array([-1.27607009,  0.89358944])}
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.3010632459949682
{'reset': False, 'endBeforeDone': False, 'stepCount': 14, 'initial state': array([ 2.78603477, -1.7975294 ]), 'currentState': array([2.50748453, 4.34377492]), 'targetState': array([-0.3250806 ,  0.81765095]), 'effectorPosition': array([0.03733826, 1.13046892])}
episode index:1731
target Thresh 1.9435394624384548
current state at start:  [ 3.35134584 -1.73421348]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.35134584, -1.73421348]), 'currentState': array([3.77142221, 4.04897183]), 'targetState': array([-1.13015717,  0.57208782]), 'effectorPosition': array([-0.77454663,  0.41042897])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.3014667891554792
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.35134584, -1.73421348]), 'currentState': array([3.77142221, 4.04897183]), 'targetState': array([-1.13015717,  0.57208782]), 'effectorPosition': array([-0.77454663,  0.41042897])}
episode index:1732
target Thresh 1.9436522706677457
current state at start:  [ 1.69945601 -2.64767627]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.69945601, -2.64767627]), 'currentState': array([2.12075818, 4.06132343]), 'targetState': array([ 0.91757381, -0.52087452]), 'effectorPosition': array([0.47223866, 0.75161292])}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.3018146918016727
{'reset': False, 'endBeforeDone': False, 'stepCount': 11, 'initial state': array([ 1.69945601, -2.64767627]), 'currentState': array([0.24594718, 4.6928096 ]), 'targetState': array([ 0.91757381, -0.52087452]), 'effectorPosition': array([ 1.19434662, -0.73101292])}
episode index:1733
target Thresh 1.9437648535060443
current state at start:  [ 2.9597173  -2.35557895]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.9597173 , -2.35557895]), 'currentState': array([3.4597173 , 4.35143159]), 'targetState': array([ 0.10106359, -0.0519784 ]), 'effectorPosition': array([-0.90700402,  0.68629697])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.30217815815467464
{'reset': False, 'endBeforeDone': False, 'stepCount': 8, 'initial state': array([ 2.9597173 , -2.35557895]), 'currentState': array([0.59966125, 3.71151183]), 'targetState': array([ 0.10106359, -0.0519784 ]), 'effectorPosition': array([ 0.43498887, -0.35622396])}
episode index:1734
target Thresh 1.943877211403682
current state at start:  [ 1.10694101 -2.55198652]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.10694101, -2.55198652]), 'currentState': array([1.60694101, 4.15716752]), 'targetState': array([-0.35753871, -0.36319468]), 'effectorPosition': array([0.83214073, 0.50326812])}
done in step count: 21
reward sum = 0.8097278682212584
running average episode reward sum: 0.30247069401062077
{'reset': False, 'endBeforeDone': False, 'stepCount': 22, 'initial state': array([ 1.10694101, -2.55198652]), 'currentState': array([0.53987812, 3.24809216]), 'targetState': array([-0.35753871, -0.36319468]), 'effectorPosition': array([ 0.05950056, -0.08826728])}
episode index:1735
target Thresh 1.9439893448100904
current state at start:  [-2.5865634   1.83310242]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.5865634 ,  1.83310242]), 'currentState': array([4.15109308, 1.33323778]), 'targetState': array([ 0.12439191, -0.82626343]), 'effectorPosition': array([ 0.16524431, -1.56312354])}
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.3028019442001302
{'reset': False, 'endBeforeDone': False, 'stepCount': 14, 'initial state': array([-2.5865634 ,  1.83310242]), 'currentState': array([5.86424035, 4.64882616]), 'targetState': array([ 0.12439191, -0.82626343]), 'effectorPosition': array([ 0.44951653, -1.29263098])}
episode index:1736
target Thresh 1.9441012541738034
current state at start:  [-3.04679612  2.361421  ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.04679612,  2.361421  ]), 'currentState': array([3.73638919, 1.86988567]), 'targetState': array([-0.50260557, -1.31087569]), 'effectorPosition': array([-0.04875083, -1.18672792])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.3032033247734174
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.04679612,  2.361421  ]), 'currentState': array([3.73638919, 1.86988567]), 'targetState': array([-0.50260557, -1.31087569]), 'effectorPosition': array([-0.04875083, -1.18672792])}
episode index:1737
target Thresh 1.9442129399424586
current state at start:  [-0.8887214   2.07387468]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.8887214 ,  2.07387468]), 'currentState': array([4.94791092, 1.57387468]), 'targetState': array([ 0.71461952, -0.45253681]), 'effectorPosition': array([ 1.20502028, -0.73604988])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.30360424345881815
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.8887214 ,  2.07387468]), 'currentState': array([4.94791092, 1.57387468]), 'targetState': array([ 0.71461952, -0.45253681]), 'effectorPosition': array([ 1.20502028, -0.73604988])}
episode index:1738
target Thresh 1.944324402562799
current state at start:  [ 4.40486153 -2.60174544]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.40486153, -2.60174544]), 'currentState': array([4.90320318, 3.20063754]), 'targetState': array([-0.06443393, -0.30221672]), 'effectorPosition': array([-0.05760904, -0.01290286])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.3040047010531489
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.40486153, -2.60174544]), 'currentState': array([4.90320318, 3.20063754]), 'targetState': array([-0.06443393, -0.30221672]), 'effectorPosition': array([-0.05760904, -0.01290286])}
episode index:1739
target Thresh 1.9444356424806757
current state at start:  [-1.19934319  2.35049159]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.19934319,  2.35049159]), 'currentState': array([4.6029964 , 2.81828941]), 'targetState': array([1.22658686, 0.48848689]), 'effectorPosition': array([ 0.31014517, -0.08618396])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3043710662533488
{'reset': False, 'endBeforeDone': False, 'stepCount': 7, 'initial state': array([-1.19934319,  2.35049159]), 'currentState': array([1.20861612, 4.74065033]), 'targetState': array([1.22658686, 0.48848689]), 'effectorPosition': array([1.29907905, 0.60737864])}
episode index:1740
target Thresh 1.9445466601410482
current state at start:  [-4.56154041  2.85842216]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.56154041,  2.85842216]), 'currentState': array([2.2216449, 3.2546452]), 'targetState': array([0.23640655, 0.1797307 ]), 'effectorPosition': array([0.08588214, 0.07342703])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.30477062336635663
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.56154041,  2.85842216]), 'currentState': array([2.2216449, 3.2546452]), 'targetState': array([0.23640655, 0.1797307 ]), 'effectorPosition': array([0.08588214, 0.07342703])}
episode index:1741
target Thresh 1.944657455987987
current state at start:  [-0.07560869 -1.7427807 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.07560869, -1.7427807 ]), 'currentState': array([6.2185208 , 4.04040461]), 'targetState': array([ 0.79500192, -1.10060473]), 'effectorPosition': array([ 0.32610055, -0.80534348])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.30516972174559526
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.07560869, -1.7427807 ]), 'currentState': array([6.2185208 , 4.04040461]), 'targetState': array([ 0.79500192, -1.10060473]), 'effectorPosition': array([ 0.32610055, -0.80534348])}
episode index:1742
target Thresh 1.9447680304646762
current state at start:  [1.27977977 2.73162397]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.27977977, 2.73162397]), 'currentState': array([1.76181785, 2.23469915]), 'targetState': array([ 0.45893376, -0.47667647]), 'effectorPosition': array([-0.84613753,  0.22728952])}
done in step count: 69
reward sum = 0.4998370298991989
running average episode reward sum: 0.30528140694820777
{'reset': False, 'endBeforeDone': False, 'stepCount': 70, 'initial state': array([1.27977977, 2.73162397]), 'currentState': array([5.83162698, 4.06792679]), 'targetState': array([ 0.45893376, -0.47667647]), 'effectorPosition': array([ 0.01037296, -0.89350726])}
episode index:1743
target Thresh 1.9448783840134136
current state at start:  [-3.43732281  2.50552255]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.43732281,  2.50552255]), 'currentState': array([3.3458625 , 2.03083733]), 'targetState': array([-0.65246417, -0.15383556]), 'effectorPosition': array([-0.36269268, -0.99019409])}
done in step count: 27
reward sum = 0.7623427143471035
running average episode reward sum: 0.3055434833859365
{'reset': False, 'endBeforeDone': False, 'stepCount': 28, 'initial state': array([-3.43732281,  2.50552255]), 'currentState': array([4.63899579, 4.35013888]), 'targetState': array([-0.65246417, -0.15383556]), 'effectorPosition': array([-0.97992608, -0.57531423])}
episode index:1744
target Thresh 1.9449885170756136
current state at start:  [0.96990971 2.61364397]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.96990971, 2.61364397]), 'currentState': array([1.36692292, 2.11364397]), 'targetState': array([-0.92441907,  0.03834543]), 'effectorPosition': array([-0.74063222,  0.64676983])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.3059244321060592
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([0.96990971, 2.61364397]), 'currentState': array([2.63060147, 1.58295017]), 'targetState': array([-0.92441907,  0.03834543]), 'effectorPosition': array([-1.35066509, -0.38909732])}
episode index:1745
target Thresh 1.9450984300918086
current state at start:  [-3.6833727   1.68854534]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.6833727 ,  1.68854534]), 'currentState': array([3.03851712, 1.30697792]), 'targetState': array([-1.29261752,  0.2528378 ]), 'effectorPosition': array([-1.35341024, -0.83055294])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.30574921765468116
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.6833727 ,  1.68854534]), 'currentState': array([3.64663115, 6.05118407]), 'targetState': array([-1.29261752,  0.2528378 ]), 'effectorPosition': array([-1.83811217, -0.75349856])}
episode index:1746
target Thresh 1.9452081235016505
current state at start:  [-0.57879287 -2.78985553]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.57879287, -2.78985553]), 'currentState': array([6.16107145, 2.99332978]), 'targetState': array([ 0.49946507, -1.15343618]), 'effectorPosition': array([0.02888302, 0.1452839 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.30557420379225714
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.57879287, -2.78985553]), 'currentState': array([4.58697714, 0.66543715]), 'targetState': array([ 0.49946507, -1.15343618]), 'effectorPosition': array([ 0.38907435, -1.8498419 ])}
episode index:1747
target Thresh 1.9453175977439137
current state at start:  [ 0.46618815 -2.79366286]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.46618815, -2.79366286]), 'currentState': array([6.28116783, 3.02216916]), 'targetState': array([-0.22190707,  0.68631576]), 'effectorPosition': array([0.00736286, 0.11912522])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.30539939017452705
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.46618815, -2.79366286]), 'currentState': array([3.68029165, 1.73752763]), 'targetState': array([-0.22190707,  0.68631576]), 'effectorPosition': array([-0.21001536, -1.27435231])}
episode index:1748
target Thresh 1.9454268532564947
current state at start:  [0.77468939 2.45836783]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.77468939, 2.45836783]), 'currentState': array([1.24163826, 1.95836783]), 'targetState': array([-0.5521905 , -0.25455691]), 'effectorPosition': array([-0.67504801,  0.88793461])}
done in step count: 70
reward sum = 0.49483865960020695
running average episode reward sum: 0.3055077030787155
{'reset': False, 'endBeforeDone': False, 'stepCount': 71, 'initial state': array([0.77468939, 2.45836783]), 'currentState': array([4.39491843, 4.20153391]), 'targetState': array([-0.5521905 , -0.25455691]), 'effectorPosition': array([-0.98827491, -0.21322772])}
episode index:1749
target Thresh 1.9455358904764162
current state at start:  [ 1.05405105 -2.17678359]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.05405105, -2.17678359]), 'currentState': array([0.83401289, 4.52472258]), 'targetState': array([0.16177044, 0.78451724]), 'effectorPosition': array([ 1.27418297, -0.05765591])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.30533312724838485
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.05405105, -2.17678359]), 'currentState': array([3.60100525, 1.17233044]), 'targetState': array([0.16177044, 0.78451724]), 'effectorPosition': array([-0.83540413, -1.44156501])}
episode index:1750
target Thresh 1.9456447098398266
current state at start:  [-2.15426726  2.59298552]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.15426726,  2.59298552]), 'currentState': array([3.98185108, 2.09298552]), 'targetState': array([-0.09453309, -0.02315769]), 'effectorPosition': array([ 0.31110344, -0.95166019])}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.30567524543671176
{'reset': False, 'endBeforeDone': False, 'stepCount': 11, 'initial state': array([-2.15426726,  2.59298552]), 'currentState': array([4.67384151, 3.50610654]), 'targetState': array([-0.09453309, -0.02315769]), 'effectorPosition': array([-0.35876239, -0.05191544])}
episode index:1751
target Thresh 1.9457533117820043
current state at start:  [ 0.9468573  -2.15863594]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.9468573 , -2.15863594]), 'currentState': array([1.38986799, 4.60851828]), 'targetState': array([1.32232507, 0.28252784]), 'effectorPosition': array([1.13966097, 0.70271248])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.3060715495203666
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.9468573 , -2.15863594]), 'currentState': array([1.38986799, 4.60851828]), 'targetState': array([1.32232507, 0.28252784]), 'effectorPosition': array([1.13966097, 0.70271248])}
episode index:1752
target Thresh 1.9458616967373565
current state at start:  [ 2.86669884 -1.95246466]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.86669884, -1.95246466]), 'currentState': array([3.30401371, 4.83072065]), 'targetState': array([-0.50372718,  0.5261325 ]), 'effectorPosition': array([-1.26391765,  0.79913928])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.3064449234282272
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([ 2.86669884, -1.95246466]), 'currentState': array([4.19775505, 3.8166313 ]), 'targetState': array([-0.50372718,  0.5261325 ]), 'effectorPosition': array([-0.65193397,  0.11668976])}
episode index:1753
target Thresh 1.9459698651394237
current state at start:  [-2.09279895 -1.94134053]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.09279895, -1.94134053]), 'currentState': array([4.65791736, 3.86426447]), 'targetState': array([-0.2714229 , -0.85024421]), 'effectorPosition': array([-0.67401894, -0.21357873])}
done in step count: 17
reward sum = 0.8429431933839268
running average episode reward sum: 0.3067507947337892
{'reset': False, 'endBeforeDone': False, 'stepCount': 18, 'initial state': array([-2.09279895, -1.94134053]), 'currentState': array([5.01699925, 4.40097671]), 'targetState': array([-0.2714229 , -0.85024421]), 'effectorPosition': array([-0.70005546, -0.94716196])}
episode index:1754
target Thresh 1.9460778174208793
current state at start:  [-0.06930597  2.89190719]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.06930597,  2.89190719]), 'currentState': array([0.37739063, 2.39190719]), 'targetState': array([0.17113785, 0.31668554]), 'effectorPosition': array([-0.0018657,  0.73225  ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.3071458085259636
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.06930597,  2.89190719]), 'currentState': array([0.37739063, 2.39190719]), 'targetState': array([0.17113785, 0.31668554]), 'effectorPosition': array([-0.0018657,  0.73225  ])}
episode index:1755
target Thresh 1.9461855540135327
current state at start:  [1.33805045 1.84185265]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.33805045, 1.84185265]), 'currentState': array([1.80159551, 1.34185265]), 'targetState': array([-0.53461188,  0.29547943]), 'effectorPosition': array([-1.22875386,  0.97162839])}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.30749112255726074
{'reset': False, 'endBeforeDone': False, 'stepCount': 10, 'initial state': array([1.33805045, 1.84185265]), 'currentState': array([4.42466095, 3.81919058]), 'targetState': array([-0.53461188,  0.29547943]), 'effectorPosition': array([-0.66384247, -0.03393256])}
episode index:1756
target Thresh 1.9462930753483303
current state at start:  [-0.86602826  1.90716023]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.86602826,  1.90716023]), 'currentState': array([4.92228263, 1.850897  ]), 'targetState': array([ 1.17715467, -0.36203949]), 'effectorPosition': array([ 1.09069141, -0.50743221])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.3078852653446499
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.86602826,  1.90716023]), 'currentState': array([4.92228263, 1.850897  ]), 'targetState': array([ 1.17715467, -0.36203949]), 'effectorPosition': array([ 1.09069141, -0.50743221])}
episode index:1757
target Thresh 1.9464003818553577
current state at start:  [0.72606225 2.5116284 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.72606225, 2.5116284 ]), 'currentState': array([1.19760455, 2.84270714]), 'targetState': array([0.13069701, 1.05207056]), 'effectorPosition': array([-0.25802351,  0.1486384 ])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.3082620649661831
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([0.72606225, 2.5116284 ]), 'currentState': array([2.66673438, 4.30154521]), 'targetState': array([0.13069701, 1.05207056]), 'effectorPosition': array([-0.11499813,  1.08995843])}
episode index:1758
target Thresh 1.9465074739638413
current state at start:  [-1.72690515 -1.87104206]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.72690515, -1.87104206]), 'currentState': array([5.03708549, 3.91214324]), 'targetState': array([-0.65249197, -0.32330485]), 'effectorPosition': array([-0.57002023, -0.48992079])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.30865532132492884
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.72690515, -1.87104206]), 'currentState': array([5.03708549, 3.91214324]), 'targetState': array([-0.65249197, -0.32330485]), 'effectorPosition': array([-0.57002023, -0.48992079])}
episode index:1759
target Thresh 1.9466143521021493
current state at start:  [ 0.5870584  -1.66898181]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.5870584 , -1.66898181]), 'currentState': array([1.0527024, 5.1142035]), 'targetState': array([ 0.60655769, -0.01177387]), 'effectorPosition': array([1.48847227, 0.75274714])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.30847994898326697
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.5870584 , -1.66898181]), 'currentState': array([4.28014849, 0.89295625]), 'targetState': array([ 0.60655769, -0.01177387]), 'effectorPosition': array([ 0.02568306, -1.80376398])}
episode index:1760
target Thresh 1.9467210166977944
current state at start:  [ 0.28774244 -1.89413469]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.28774244, -1.89413469]), 'currentState': array([0.78774244, 4.86595024]), 'targetState': array([ 0.37764217, -0.15530443]), 'effectorPosition': array([1.51377351, 0.12002778])}
done in step count: 36
reward sum = 0.6964132180495735
running average episode reward sum: 0.3087002404478134
{'reset': False, 'endBeforeDone': False, 'stepCount': 37, 'initial state': array([ 0.28774244, -1.89413469]), 'currentState': array([5.43525555, 2.28407125]), 'targetState': array([ 0.37764217, -0.15530443]), 'effectorPosition': array([0.79578534, 0.24103526])}
episode index:1761
target Thresh 1.9468274681774353
current state at start:  [-0.24638286  1.92961716]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.24638286,  1.92961716]), 'currentState': array([0.25361714, 2.2285363 ]), 'targetState': array([0.60564178, 0.19537913]), 'effectorPosition': array([0.17767526, 0.86358076])}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.3090383118635688
{'reset': False, 'endBeforeDone': False, 'stepCount': 11, 'initial state': array([-0.24638286,  1.92961716]), 'currentState': array([4.84540701, 2.63131749]), 'targetState': array([0.60564178, 0.19537913]), 'effectorPosition': array([ 0.50099798, -0.06148761])}
episode index:1762
target Thresh 1.9469337069668782
current state at start:  [-0.91182892  2.82504052]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.91182892,  2.82504052]), 'currentState': array([5.03970148, 3.32159001]), 'targetState': array([0.58765605, 0.74156988]), 'effectorPosition': array([-0.1643283 , -0.07285518])}
done in step count: 34
reward sum = 0.7105532272722921
running average episode reward sum: 0.3092660571360638
{'reset': False, 'endBeforeDone': False, 'stepCount': 35, 'initial state': array([-0.91182892,  2.82504052]), 'currentState': array([0.02566073, 1.91086545]), 'targetState': array([0.58765605, 0.74156988]), 'effectorPosition': array([0.64203981, 0.95952091])}
episode index:1763
target Thresh 1.947039733491078
current state at start:  [ 2.19418956 -2.80875773]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.19418956, -2.80875773]), 'currentState': array([2.67526109, 3.97442757]), 'targetState': array([0.02569257, 0.16262819]), 'effectorPosition': array([0.04036241, 0.80796579])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.30909073624199573
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.19418956, -2.80875773]), 'currentState': array([5.36077082, 0.30011938]), 'targetState': array([0.02569257, 0.16262819]), 'effectorPosition': array([ 1.4164402 , -1.37996361])}
episode index:1764
target Thresh 1.947145548174141
current state at start:  [-2.02227505  2.98546559]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.02227505,  2.98546559]), 'currentState': array([4.74080275, 2.69807614]), 'targetState': array([-0.59363095,  0.400291  ]), 'effectorPosition': array([ 0.4316939 , -0.08452147])}
done in step count: 46
reward sum = 0.6298236312032323
running average episode reward sum: 0.3092724545960814
{'reset': False, 'endBeforeDone': False, 'stepCount': 47, 'initial state': array([-2.02227505,  2.98546559]), 'currentState': array([0.57950225, 2.23650871]), 'targetState': array([-0.59363095,  0.400291  ]), 'effectorPosition': array([-0.1107295,  0.8674675])}
episode index:1765
target Thresh 1.9472511514393267
current state at start:  [ 0.09565012 -2.73944197]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.09565012, -2.73944197]), 'currentState': array([0.55246959, 3.39613708]), 'targetState': array([-0.83428011, -1.10528699]), 'effectorPosition': array([ 0.15957304, -0.1974341 ])}
done in step count: 22
reward sum = 0.8016305895390459
running average episode reward sum: 0.30955125308698905
{'reset': False, 'endBeforeDone': False, 'stepCount': 23, 'initial state': array([ 0.09565012, -2.73944197]), 'currentState': array([4.45226274, 4.84258521]), 'targetState': array([-0.83428011, -1.10528699]), 'effectorPosition': array([-1.24877352, -0.83679277])}
episode index:1766
target Thresh 1.9473565437090474
current state at start:  [-3.98009251  2.89892821]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.98009251,  2.89892821]), 'currentState': array([2.77140285, 2.61954708]), 'targetState': array([-0.64302518, -0.67845396]), 'effectorPosition': array([-0.30458529, -0.41668439])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.3099419994066908
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.98009251,  2.89892821]), 'currentState': array([2.77140285, 2.61954708]), 'targetState': array([-0.64302518, -0.67845396]), 'effectorPosition': array([-0.30458529, -0.41668439])}
episode index:1767
target Thresh 1.947461725404873
current state at start:  [-4.07734137  1.89535181]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.07734137,  1.89535181]), 'currentState': array([2.70584394, 1.44947128]), 'targetState': array([-0.48562706,  0.16761669]), 'effectorPosition': array([-1.43525893, -0.42671659])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.30976669284594044
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-4.07734137,  1.89535181]), 'currentState': array([5.11518766, 1.02852296]), 'targetState': array([-0.48562706,  0.16761669]), 'effectorPosition': array([ 1.38228373, -1.05899045])}
episode index:1768
target Thresh 1.94756669694753
current state at start:  [-0.01267721 -2.63117242]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.01267721, -2.63117242]), 'currentState': array([0.44604139, 3.24223796]), 'targetState': array([ 0.09709311, -1.0143524 ]), 'effectorPosition': array([ 0.04791024, -0.08846207])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3095915844836759
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.01267721, -2.63117242]), 'currentState': array([4.14579098, 4.25678854]), 'targetState': array([ 0.09709311, -1.0143524 ]), 'effectorPosition': array([-1.05825616,  0.00952462])}
episode index:1769
target Thresh 1.947671458756905
current state at start:  [ 3.39247131 -1.98052096]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.39247131, -1.98052096]), 'currentState': array([3.89247131, 3.91487391]), 'targetState': array([-0.53332492,  0.14538046]), 'effectorPosition': array([-0.68447015,  0.31663132])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.30998164573538006
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.39247131, -1.98052096]), 'currentState': array([3.89247131, 3.91487391]), 'targetState': array([-0.53332492,  0.14538046]), 'effectorPosition': array([-0.68447015,  0.31663132])}
episode index:1770
target Thresh 1.9477760112520452
current state at start:  [ 2.16898481 -2.68974923]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.16898481, -2.68974923]), 'currentState': array([2.6461849 , 4.09343608]), 'targetState': array([-0.43646115,  0.50797862]), 'effectorPosition': array([0.01785424, 0.91614189])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.3103712664887762
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.16898481, -2.68974923]), 'currentState': array([2.6461849 , 4.09343608]), 'targetState': array([-0.43646115,  0.50797862]), 'effectorPosition': array([0.01785424, 0.91614189])}
episode index:1771
target Thresh 1.947880354851161
current state at start:  [-3.38832524  2.1509286 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.38832524,  2.1509286 ]), 'currentState': array([3.37844653, 1.78923403]), 'targetState': array([ 0.18206929, -1.11773068]), 'effectorPosition': array([-0.5323568 , -1.13277836])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.31075480414877127
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-3.38832524,  2.1509286 ]), 'currentState': array([3.87844653, 1.39214198]), 'targetState': array([ 0.18206929, -1.11773068]), 'effectorPosition': array([-0.21092641, -1.52017139])}
episode index:1772
target Thresh 1.9479844899716263
current state at start:  [ 0.13673909 -2.11336638]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.13673909, -2.11336638]), 'currentState': array([0.63673909, 3.91018902]), 'targetState': array([ 0.11482394, -1.21250011]), 'effectorPosition': array([ 0.63933197, -0.39176584])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.3111052331074618
{'reset': False, 'endBeforeDone': False, 'stepCount': 8, 'initial state': array([ 0.13673909, -2.11336638]), 'currentState': array([4.03422006, 1.19278537]), 'targetState': array([ 0.11482394, -1.21250011]), 'effectorPosition': array([-0.13516717, -1.64920436])}
episode index:1773
target Thresh 1.9480884170299824
current state at start:  [-2.13559945  2.21360237]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.13559945,  2.21360237]), 'currentState': array([3.64758585, 1.75584618]), 'targetState': array([ 0.29290588, -0.05914499]), 'effectorPosition': array([-0.23735224, -1.25525808])}
done in step count: 14
reward sum = 0.8687458127689782
running average episode reward sum: 0.31141957390772196
{'reset': False, 'endBeforeDone': False, 'stepCount': 15, 'initial state': array([-2.13559945,  2.21360237]), 'currentState': array([4.55751736, 3.3240982 ]), 'targetState': array([ 0.29290588, -0.05914499]), 'effectorPosition': array([-0.18188366,  0.01158686])}
episode index:1774
target Thresh 1.9481921364419374
current state at start:  [ 1.27321696 -2.39208554]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.27321696, -2.39208554]), 'currentState': array([1.72601759, 3.76396095]), 'targetState': array([ 0.63937601, -0.49493752]), 'effectorPosition': array([0.54696505, 0.27537066])}
done in step count: 39
reward sum = 0.6757290490602831
running average episode reward sum: 0.3116248186824558
{'reset': False, 'endBeforeDone': False, 'stepCount': 40, 'initial state': array([ 1.27321696, -2.39208554]), 'currentState': array([4.40831992, 2.57182608]), 'targetState': array([ 0.63937601, -0.49493752]), 'effectorPosition': array([ 0.46739156, -0.31223597])}
episode index:1775
target Thresh 1.948295648622369
current state at start:  [0.70345511 2.96662913]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.70345511, 2.96662913]), 'currentState': array([1.19531139, 2.4744365 ]), 'targetState': array([-0.82000787,  0.123849  ]), 'effectorPosition': array([-0.49701446,  0.42638908])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.31201241732058504
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.70345511, 2.96662913]), 'currentState': array([1.19531139, 2.4744365 ]), 'targetState': array([-0.82000787,  0.123849  ]), 'effectorPosition': array([-0.49701446,  0.42638908])}
episode index:1776
target Thresh 1.9483989539853261
current state at start:  [-1.74202047 -2.41820907]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.74202047, -2.41820907]), 'currentState': array([5.02312216, 3.36497624]), 'targetState': array([-0.57878349,  0.25896664]), 'effectorPosition': array([-0.20332423, -0.09139105])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.3123995797193917
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.74202047, -2.41820907]), 'currentState': array([5.02312216, 3.36497624]), 'targetState': array([-0.57878349,  0.25896664]), 'effectorPosition': array([-0.20332423, -0.09139105])}
episode index:1777
target Thresh 1.9485020529440304
current state at start:  [1.35732517 2.69248956]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.35732517, 2.69248956]), 'currentState': array([1.85732517, 2.51782174]), 'targetState': array([-1.29292599,  0.08422692]), 'effectorPosition': array([-0.61351007,  0.01555987])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.31278068231797473
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([1.35732517, 2.69248956]), 'currentState': array([2.35732517, 2.11240644]), 'targetState': array([-1.29292599,  0.08422692]), 'effectorPosition': array([-0.94818883, -0.26439606])}
episode index:1778
target Thresh 1.948604945910878
current state at start:  [-0.71444671  1.63049387]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.71444671,  1.63049387]), 'currentState': array([5.11326443, 1.13049387]), 'targetState': array([ 1.22292666, -0.12823749]), 'effectorPosition': array([ 1.38944739, -0.96013651])}
done in step count: 44
reward sum = 0.6426116020847181
running average episode reward sum: 0.3129660847461741
{'reset': False, 'endBeforeDone': False, 'stepCount': 45, 'initial state': array([-0.71444671,  1.63049387]), 'currentState': array([0.5338229 , 4.20395433]), 'targetState': array([ 1.22292666, -0.12823749]), 'effectorPosition': array([ 0.88625368, -0.49084967])}
episode index:1779
target Thresh 1.9487076332974405
current state at start:  [ 3.97793813 -2.22560251]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.97793813, -2.22560251]), 'currentState': array([4.46419738, 3.60073334]), 'targetState': array([-0.256609 , -0.1990662]), 'effectorPosition': array([-0.45503941,  0.00847438])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.31335205885586725
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.97793813, -2.22560251]), 'currentState': array([4.46419738, 3.60073334]), 'targetState': array([-0.256609 , -0.1990662]), 'effectorPosition': array([-0.45503941,  0.00847438])}
episode index:1780
target Thresh 1.948810115514468
current state at start:  [1.34791978 1.6447088 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.34791978, 1.6447088 ]), 'currentState': array([1.79500958, 1.14853056]), 'targetState': array([-0.12760029,  1.07433561]), 'effectorPosition': array([-1.202791  ,  1.17172963])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3131761172169813
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.34791978, 1.6447088 ]), 'currentState': array([5.10397159, 4.42047804]), 'targetState': array([-0.12760029,  1.07433561]), 'effectorPosition': array([-0.61338518, -1.02381294])}
episode index:1781
target Thresh 1.948912392971889
current state at start:  [1.18976332 2.20508843]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.18976332, 2.20508843]), 'currentState': array([1.66384695, 1.70508843]), 'targetState': array([-0.78451828,  0.80603205]), 'effectorPosition': array([-1.06718516,  0.77028448])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.3135615402712928
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.18976332, 2.20508843]), 'currentState': array([1.66384695, 1.70508843]), 'targetState': array([-0.78451828,  0.80603205]), 'effectorPosition': array([-1.06718516,  0.77028448])}
episode index:1782
target Thresh 1.949014466078814
current state at start:  [1.24809231 2.71988679]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.24809231, 2.71988679]), 'currentState': array([1.73194655, 2.21988679]), 'targetState': array([-0.83486613, -0.09772564]), 'effectorPosition': array([-0.84977772,  0.26259027])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.3139465309946403
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.24809231, 2.71988679]), 'currentState': array([1.73194655, 2.21988679]), 'targetState': array([-0.83486613, -0.09772564]), 'effectorPosition': array([-0.84977772,  0.26259027])}
episode index:1783
target Thresh 1.9491163352435352
current state at start:  [ 3.41061032 -2.98589885]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.41061032, -2.98589885]), 'currentState': array([3.88001081, 2.79728646]), 'targetState': array([-0.23549236,  0.61719923]), 'effectorPosition': array([ 0.18380367, -0.28913055])}
done in step count: 26
reward sum = 0.7700431458051551
running average episode reward sum: 0.3142021905320902
{'reset': False, 'endBeforeDone': False, 'stepCount': 27, 'initial state': array([ 3.41061032, -2.98589885]), 'currentState': array([0.41943042, 2.64774801]), 'targetState': array([-0.23549236,  0.61719923]), 'effectorPosition': array([-0.0839115 ,  0.48158588])}
episode index:1784
target Thresh 1.9492180008735296
current state at start:  [0.36487405 1.67874396]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.36487405, 1.67874396]), 'currentState': array([0.84395562, 1.17874396]), 'targetState': array([0.49199407, 0.5665892 ]), 'effectorPosition': array([0.22783355, 1.64689514])}
done in step count: 15
reward sum = 0.8600583546412884
running average episode reward sum: 0.3145079923047004
{'reset': False, 'endBeforeDone': False, 'stepCount': 16, 'initial state': array([0.36487405, 1.67874396]), 'currentState': array([1.65235196, 3.53565782]), 'targetState': array([0.49199407, 0.5665892 ]), 'effectorPosition': array([0.37642517, 0.10766755])}
episode index:1785
target Thresh 1.9493194633754598
current state at start:  [ 3.35777881 -2.64725426]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.35777881, -2.64725426]), 'currentState': array([3.85777881, 3.15776062]), 'targetState': array([0.11120225, 1.35769019]), 'effectorPosition': array([-0.0107126,  0.0121094])}
done in step count: 64
reward sum = 0.525596487525562
running average episode reward sum: 0.3146261829515206
{'reset': False, 'endBeforeDone': False, 'stepCount': 65, 'initial state': array([ 3.35777881, -2.64725426]), 'currentState': array([2.62060883, 4.34894693]), 'targetState': array([0.11120225, 1.35769019]), 'effectorPosition': array([-0.09377865,  1.1314674 ])}
episode index:1786
target Thresh 1.949420723155176
current state at start:  [ 0.05593901 -2.40994546]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.05593901, -2.40994546]), 'currentState': array([0.53593343, 3.46864197]), 'targetState': array([-0.54041983,  0.18179809]), 'effectorPosition': array([ 0.20961823, -0.24914143])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.3149985801630754
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 0.05593901, -2.40994546]), 'currentState': array([1.52809989, 2.701837  ]), 'targetState': array([-0.54041983,  0.18179809]), 'effectorPosition': array([-0.42126931,  0.11322871])}
episode index:1787
target Thresh 1.9495217806177172
current state at start:  [-2.28876166  2.36760879]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.28876166,  2.36760879]), 'currentState': array([3.5113871 , 1.89908809]), 'targetState': array([-0.25310574,  0.29495888]), 'effectorPosition': array([-0.2896489 , -1.12749747])}
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.3153131900304333
{'reset': False, 'endBeforeDone': False, 'stepCount': 14, 'initial state': array([-2.28876166,  2.36760879]), 'currentState': array([4.96238249, 3.36637567]), 'targetState': array([-0.25310574,  0.29495888]), 'effectorPosition': array([-0.20974203, -0.07951912])}
episode index:1788
target Thresh 1.9496226361673137
current state at start:  [ 0.29964726 -2.43061376]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.29964726, -2.43061376]), 'currentState': array([0.76211144, 3.35257155]), 'targetState': array([-0.18272602, -1.08897474]), 'effectorPosition': array([ 0.16063212, -0.13617838])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3151369389460116
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.29964726, -2.43061376]), 'currentState': array([2.10321188, 6.20534931]), 'targetState': array([-0.18272602, -1.08897474]), 'effectorPosition': array([-0.94670064,  1.76002913])}
episode index:1789
target Thresh 1.9497232902073875
current state at start:  [ 4.17066378 -2.40346302]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.17066378, -2.40346302]), 'currentState': array([4.67066378, 3.37972229]), 'targetState': array([0.17242158, 0.49245582]), 'effectorPosition': array([-0.23685725, -0.01835506])}
done in step count: 39
reward sum = 0.6757290490602831
running average episode reward sum: 0.31533838705222067
{'reset': False, 'endBeforeDone': False, 'stepCount': 40, 'initial state': array([ 4.17066378, -2.40346302]), 'currentState': array([1.79094768, 3.7162261 ]), 'targetState': array([0.17242158, 0.49245582]), 'effectorPosition': array([0.49533556, 0.27542604])}
episode index:1790
target Thresh 1.9498237431405554
current state at start:  [ 0.24149689 -1.81903264]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.24149689, -1.81903264]), 'currentState': array([0.72616914, 4.26745263]), 'targetState': array([1.093273  , 0.00841449]), 'effectorPosition': array([ 1.02526383, -0.29670393])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.3157206660097571
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.24149689, -1.81903264]), 'currentState': array([0.72616914, 4.26745263]), 'targetState': array([1.093273  , 0.00841449]), 'effectorPosition': array([ 1.02526383, -0.29670393])}
episode index:1791
target Thresh 1.9499239953686287
current state at start:  [ 2.02178974 -2.10289082]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.02178974, -2.10289082]), 'currentState': array([2.50360928, 3.68029449]), 'targetState': array([1.34276258, 0.11056982]), 'effectorPosition': array([0.19177719, 0.49645818])}
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.31603417067325557
{'reset': False, 'endBeforeDone': False, 'stepCount': 14, 'initial state': array([ 2.02178974, -2.10289082]), 'currentState': array([0.70565239, 4.81250054]), 'targetState': array([1.34276258, 0.11056982]), 'effectorPosition': array([ 1.48254855, -0.0440298 ])}
episode index:1792
target Thresh 1.950024047292617
current state at start:  [ 2.7717921  -2.79573123]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.7717921 , -2.79573123]), 'currentState': array([3.25797741, 3.47764905]), 'targetState': array([ 0.55709532, -0.31221195]), 'effectorPosition': array([-0.09385233,  0.32104018])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.31640453644532845
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 2.7717921 , -2.79573123]), 'currentState': array([4.21358763, 3.04710221]), 'targetState': array([ 0.55709532, -0.31221195]), 'effectorPosition': array([ 0.08072001, -0.04905184])}
episode index:1793
target Thresh 1.9501238993127274
current state at start:  [-0.40076977 -1.99057048]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.40076977, -1.99057048]), 'currentState': array([6.27759037, 3.81156565]), 'targetState': array([ 0.17412541, -1.10195881]), 'effectorPosition': array([ 0.21268394, -0.6221645 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.31678558185422184
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.40076977, -1.99057048]), 'currentState': array([6.27759037, 3.81156565]), 'targetState': array([ 0.17412541, -1.10195881]), 'effectorPosition': array([ 0.21268394, -0.6221645 ])}
episode index:1794
target Thresh 1.950223551828369
current state at start:  [ 3.2011464 -2.6708518]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.2011464, -2.6708518]), 'currentState': array([3.7011464 , 3.45074077]), 'targetState': array([ 0.53770435, -0.23145792]), 'effectorPosition': array([-0.20167386,  0.23268316])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.31715511634901056
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 3.2011464, -2.6708518]), 'currentState': array([4.37151075, 2.68887438]), 'targetState': array([ 0.53770435, -0.23145792]), 'effectorPosition': array([ 0.37856514, -0.24117544])}
episode index:1795
target Thresh 1.9503230052381513
current state at start:  [-1.20903627 -2.00356362]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.20903627, -2.00356362]), 'currentState': array([5.48635705, 3.77962169]), 'targetState': array([-1.06407516, -0.49173333]), 'effectorPosition': array([-0.2884394 , -0.55701006])}
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.3174720594199277
{'reset': False, 'endBeforeDone': False, 'stepCount': 13, 'initial state': array([-1.20903627, -2.00356362]), 'currentState': array([4.23335482, 4.24226475]), 'targetState': array([-1.06407516, -0.49173333]), 'effectorPosition': array([-1.04328973, -0.07451485])}
episode index:1796
target Thresh 1.9504222599398884
current state at start:  [-1.31918715  1.98424849]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.31918715,  1.98424849]), 'currentState': array([4.46399816, 1.48424849]), 'targetState': array([0.55517832, 0.07742753]), 'effectorPosition': array([ 0.69858599, -1.29802052])}
done in step count: 23
reward sum = 0.7936142836436554
running average episode reward sum: 0.31773702448627367
{'reset': False, 'endBeforeDone': False, 'stepCount': 24, 'initial state': array([-1.31918715,  1.98424849]), 'currentState': array([4.06993044, 2.6943969 ]), 'targetState': array([0.55517832, 0.07742753]), 'effectorPosition': array([ 0.28730136, -0.33783326])}
episode index:1797
target Thresh 1.950521316330599
current state at start:  [-0.00630162 -1.58530775]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.00630162, -1.58530775]), 'currentState': array([0.48968318, 4.80379085]), 'targetState': array([ 0.01302914, -0.12951036]), 'effectorPosition': array([ 1.43141313, -0.36552121])}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.31807351373540693
{'reset': False, 'endBeforeDone': False, 'stepCount': 9, 'initial state': array([-0.00630162, -1.58530775]), 'currentState': array([4.35965385, 3.29884157]), 'targetState': array([ 0.01302914, -0.12951036]), 'effectorPosition': array([-0.15122232,  0.04252201])}
episode index:1798
target Thresh 1.950620174806509
current state at start:  [-1.25427936  2.5537309 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.25427936,  2.5537309 ]), 'currentState': array([4.52890594, 2.05510741]), 'targetState': array([ 0.06908613, -0.49022743]), 'effectorPosition': array([ 0.77263621, -0.68690299])}
done in step count: 37
reward sum = 0.6894490858690777
running average episode reward sum: 0.31827994818350797
{'reset': False, 'endBeforeDone': False, 'stepCount': 38, 'initial state': array([-1.25427936,  2.5537309 ]), 'currentState': array([3.76645402, 2.88280641]), 'targetState': array([ 0.06908613, -0.49022743]), 'effectorPosition': array([ 0.12269523, -0.22703145])}
episode index:1799
target Thresh 1.9507188357630525
current state at start:  [-3.98167686  2.65045682]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.98167686,  2.65045682]), 'currentState': array([2.76982342, 2.29120381]), 'targetState': array([-0.65424453,  0.50833601]), 'effectorPosition': array([-0.59006781, -0.57657442])}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.3186055604761887
{'reset': False, 'endBeforeDone': False, 'stepCount': 11, 'initial state': array([-3.98167686,  2.65045682]), 'currentState': array([4.1989314 , 3.57438911]), 'targetState': array([-0.65424453,  0.50833601]), 'effectorPosition': array([-0.41061822,  0.12569727])}
episode index:1800
target Thresh 1.9508172995948734
current state at start:  [-2.01545207  1.96573553]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.01545207,  1.96573553]), 'currentState': array([4.2627694 , 1.46573553]), 'targetState': array([ 0.28515942, -1.13016535]), 'effectorPosition': array([ 0.41544587, -1.42728413])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.3189839027524373
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.01545207,  1.96573553]), 'currentState': array([4.2627694 , 1.46573553]), 'targetState': array([ 0.28515942, -1.13016535]), 'effectorPosition': array([ 0.41544587, -1.42728413])}
episode index:1801
target Thresh 1.9509155666958269
current state at start:  [ 0.90369863 -2.70614678]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.90369863, -2.70614678]), 'currentState': array([1.40369863, 3.75441443]), 'targetState': array([-0.15726886, -0.05970195]), 'effectorPosition': array([0.5974325 , 0.08377289])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.31933462758437275
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([ 0.90369863, -2.70614678]), 'currentState': array([3.87250681, 3.76111266]), 'targetState': array([-0.15726886, -0.05970195]), 'effectorPosition': array([-0.52598143,  0.30826779])}
episode index:1802
target Thresh 1.951013637458982
current state at start:  [-2.06358122  1.9376675 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.06358122,  1.9376675 ]), 'currentState': array([4.71960409, 1.4376675 ]), 'targetState': array([-0.23103612, -1.38907349]), 'effectorPosition': array([ 0.99929838, -1.12555524])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3191575146461673
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.06358122,  1.9376675 ]), 'currentState': array([3.50101242, 3.88969219]), 'targetState': array([-0.23103612, -1.38907349]), 'effectorPosition': array([-0.48921896,  0.54286173])}
episode index:1803
target Thresh 1.9511115122766214
current state at start:  [ 2.08006431 -2.27025131]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.08006431, -2.27025131]), 'currentState': array([2.55358673, 3.512934  ]), 'targetState': array([ 0.74156363, -0.24072923]), 'effectorPosition': array([0.14457145, 0.33972957])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3189805980637692
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.08006431, -2.27025131]), 'currentState': array([2.54598521, 3.41820023]), 'targetState': array([ 0.74156363, -0.24072923]), 'effectorPosition': array([0.12174168, 0.24739466])}
episode index:1804
target Thresh 1.9512091915402447
current state at start:  [-3.86967571  2.32594657]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.86967571,  2.32594657]), 'currentState': array([2.91350959, 1.82832504]), 'targetState': array([0.05659096, 0.14692055]), 'effectorPosition': array([-0.94466023, -0.77345586])}
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.3192900387424037
{'reset': False, 'endBeforeDone': False, 'stepCount': 14, 'initial state': array([-3.86967571,  2.32594657]), 'currentState': array([2.14662896, 3.8198025 ]), 'targetState': array([0.05659096, 0.14692055]), 'effectorPosition': array([0.40571821, 0.52725565])}
episode index:1805
target Thresh 1.9513066756405693
current state at start:  [-1.07179944  2.06188431]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.07179944,  2.06188431]), 'currentState': array([4.85403021, 1.65536004]), 'targetState': array([1.20328218, 0.65756333]), 'effectorPosition': array([ 1.11569267, -0.76570487])}
done in step count: 49
reward sum = 0.611117239532865
running average episode reward sum: 0.31945162633974056
{'reset': False, 'endBeforeDone': False, 'stepCount': 50, 'initial state': array([-1.07179944,  2.06188431]), 'currentState': array([1.26734782, 5.16795933]), 'targetState': array([1.20328218, 0.65756333]), 'effectorPosition': array([1.28726469, 1.10584753])}
episode index:1806
target Thresh 1.9514039649675314
current state at start:  [-2.03674174  2.24766115]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.03674174,  2.24766115]), 'currentState': array([4.19728932, 1.82511056]), 'targetState': array([ 0.00036161, -0.21995153]), 'effectorPosition': array([ 0.47356618, -1.12808313])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3192748407136533
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.03674174,  2.24766115]), 'currentState': array([2.38873346, 4.21150983]), 'targetState': array([ 0.00036161, -0.21995153]), 'effectorPosition': array([0.22041983, 0.99550054])}
episode index:1807
target Thresh 1.9515010599102887
current state at start:  [ 2.66989588 -1.77429922]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.66989588, -1.77429922]), 'currentState': array([3.14402678, 4.34053566]), 'targetState': array([0.22190228, 1.30179272]), 'effectorPosition': array([-0.63892317,  0.93010309])}
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.3195885077661989
{'reset': False, 'endBeforeDone': False, 'stepCount': 13, 'initial state': array([ 2.66989588, -1.77429922]), 'currentState': array([2.056834  , 5.33439513]), 'targetState': array([0.22190228, 1.30179272]), 'effectorPosition': array([-0.02071331,  1.77901784])}
episode index:1808
target Thresh 1.9515979608572207
current state at start:  [-0.80869216  2.49670342]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.80869216,  2.49670342]), 'currentState': array([4.97449314, 2.06803668]), 'targetState': array([ 0.09569618, -0.50603259]), 'effectorPosition': array([ 0.98440085, -0.27740072])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.31941184192442656
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.80869216,  2.49670342]), 'currentState': array([2.27034037, 3.82000254]), 'targetState': array([ 0.09569618, -0.50603259]), 'effectorPosition': array([0.33759457, 0.57348646])}
episode index:1809
target Thresh 1.9516946681959317
current state at start:  [1.67274869 2.25060179]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.67274869, 2.25060179]), 'currentState': array([1.39127165, 1.75060179]), 'targetState': array([-0.8891153,  0.7316626]), 'effectorPosition': array([-0.82143805,  0.98364789])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.3197878574813744
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.67274869, 2.25060179]), 'currentState': array([1.39127165, 1.75060179]), 'targetState': array([-0.8891153,  0.7316626]), 'effectorPosition': array([-0.82143805,  0.98364789])}
episode index:1810
target Thresh 1.9517911823132512
current state at start:  [-0.71336251  2.12890475]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.71336251,  2.12890475]), 'currentState': array([6.0698228 , 1.62890475]), 'targetState': array([0.00323446, 0.15424537]), 'effectorPosition': array([1.13195558, 0.77622492])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.31961127666553707
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.71336251,  2.12890475]), 'currentState': array([1.99805617, 4.87946579]), 'targetState': array([0.00323446, 0.15424537]), 'effectorPosition': array([0.4141416, 1.4700639])}
episode index:1811
target Thresh 1.9518875035952357
current state at start:  [1.66634766 2.1998903 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.66634766, 2.1998903 ]), 'currentState': array([1.20318461, 1.73189573]), 'targetState': array([-1.03835979,  0.29169602]), 'effectorPosition': array([-0.61936427,  1.1382359 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.31943489075126247
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.66634766, 2.1998903 ]), 'currentState': array([2.18992975, 5.20208817]), 'targetState': array([-1.03835979,  0.29169602]), 'effectorPosition': array([-0.13462281,  1.70956065])}
episode index:1812
target Thresh 1.9519836324271704
current state at start:  [ 1.51192763 -2.41757415]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.51192763, -2.41757415]), 'currentState': array([2.00668707, 3.36561116]), 'targetState': array([ 0.92079538, -0.02166537]), 'effectorPosition': array([0.19082713, 0.11644644])}
done in step count: 46
reward sum = 0.6298236312032323
running average episode reward sum: 0.3196060924834478
{'reset': False, 'endBeforeDone': False, 'stepCount': 47, 'initial state': array([ 1.51192763, -2.41757415]), 'currentState': array([1.58771381, 4.12676719]), 'targetState': array([ 0.92079538, -0.02166537]), 'effectorPosition': array([0.82568279, 0.46131615])}
episode index:1813
target Thresh 1.9520795691935706
current state at start:  [ 1.53119217 -2.03056364]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.53119217, -2.03056364]), 'currentState': array([2.03119217, 3.82410021]), 'targetState': array([0.02336282, 0.23509796]), 'effectorPosition': array([0.46553934, 0.48092207])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.31998117181504454
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.53119217, -2.03056364]), 'currentState': array([2.03119217, 3.82410021]), 'targetState': array([0.02336282, 0.23509796]), 'effectorPosition': array([0.46553934, 0.48092207])}
episode index:1814
target Thresh 1.952175314278184
current state at start:  [ 2.63489679 -2.61125857]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.63489679, -2.61125857]), 'currentState': array([3.13489679, 3.20626351]), 'targetState': array([-0.30905693,  1.272402  ]), 'effectorPosition': array([-0.00165766,  0.06463834])}
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.32029323996926
{'reset': False, 'endBeforeDone': False, 'stepCount': 13, 'initial state': array([ 2.63489679, -2.61125857]), 'currentState': array([2.56552005, 5.00046164]), 'targetState': array([-0.30905693,  1.272402  ]), 'effectorPosition': array([-0.55457339,  1.50354848])}
episode index:1815
target Thresh 1.9522708680639904
current state at start:  [-0.52507452  2.04734693]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.52507452,  2.04734693]), 'currentState': array([5.25811078, 1.6267402 ]), 'targetState': array([0.68787984, 0.12765894]), 'effectorPosition': array([ 1.34342915, -0.28873644])}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.32061487479031703
{'reset': False, 'endBeforeDone': False, 'stepCount': 11, 'initial state': array([-0.52507452,  2.04734693]), 'currentState': array([2.30222291, 3.81587566]), 'targetState': array([0.68787984, 0.12765894]), 'effectorPosition': array([0.3184721 , 0.57988441])}
episode index:1816
target Thresh 1.9523662309332057
current state at start:  [-0.88552969  2.05759836]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.88552969,  2.05759836]), 'currentState': array([5.84174962, 1.62137614]), 'targetState': array([0.8138442 , 0.74281545]), 'effectorPosition': array([1.2851191 , 0.49734536])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.3209887796473394
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.88552969,  2.05759836]), 'currentState': array([5.84174962, 1.62137614]), 'targetState': array([0.8138442 , 0.74281545]), 'effectorPosition': array([1.2851191 , 0.49734536])}
episode index:1817
target Thresh 1.9524614032672811
current state at start:  [ 2.88241592 -2.61036331]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.88241592, -2.61036331]), 'currentState': array([2.38241592, 4.172822  ]), 'targetState': array([-0.93694205, -0.17981308]), 'effectorPosition': array([0.23781844, 0.9570336 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3208122181623849
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 2.88241592, -2.61036331]), 'currentState': array([2.26702539, 5.44098388]), 'targetState': array([-0.93694205, -0.17981308]), 'effectorPosition': array([-0.49587442,  1.75663099])}
episode index:1818
target Thresh 1.9525563854469061
current state at start:  [-3.488405   1.7265016]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.488405 ,  1.7265016]), 'currentState': array([2.30353832, 2.1791973 ]), 'targetState': array([-0.49216243, -1.15577962]), 'effectorPosition': array([-0.89655039, -0.23040231])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3206358508077052
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.488405 ,  1.7265016]), 'currentState': array([1.76794685, 5.06313221]), 'targetState': array([-0.49216243, -1.15577962]), 'effectorPosition': array([0.65774769, 1.50151915])}
episode index:1819
target Thresh 1.9526511778520097
current state at start:  [-1.89657523  2.83711444]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.89657523,  2.83711444]), 'currentState': array([3.88661008, 3.31513401]), 'targetState': array([ 1.11971192, -0.78020203]), 'effectorPosition': array([-0.12810992,  0.11674305])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3204596772633054
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.89657523,  2.83711444]), 'currentState': array([2.55557871, 2.26755429]), 'targetState': array([ 1.11971192, -0.78020203]), 'effectorPosition': array([-0.72263396, -0.44082971])}
episode index:1820
target Thresh 1.9527457808617616
current state at start:  [ 1.76446479 -1.91816425]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.76446479, -1.91816425]), 'currentState': array([2.19632393, 4.616724  ]), 'targetState': array([-0.08317908,  0.35522203]), 'effectorPosition': array([0.27735146, 1.31606911])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3202836972098933
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 1.76446479, -1.91816425]), 'currentState': array([1.58780337, 5.09255181]), 'targetState': array([-0.08317908,  0.35522203]), 'effectorPosition': array([0.90515318, 1.38666545])}
episode index:1821
target Thresh 1.952840194854574
current state at start:  [-0.98048626  2.95667894]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.98048626,  2.95667894]), 'currentState': array([4.80269905, 2.45667894]), 'targetState': array([0.12255785, 0.00475816]), 'effectorPosition': array([ 0.65036783, -0.16755422])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.32010791032887803
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.98048626,  2.95667894]), 'currentState': array([1.29551917, 5.56129276]), 'targetState': array([0.12255785, 0.00475816]), 'effectorPosition': array([1.11175206, 1.50503166])}
episode index:1822
target Thresh 1.952934420208103
current state at start:  [0.12858882 2.75088069]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.12858882, 2.75088069]), 'currentState': array([6.04154208, 2.30794633]), 'targetState': array([0.14173618, 0.18332093]), 'effectorPosition': array([0.49546852, 0.64042943])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.3204808626545341
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.12858882, 2.75088069]), 'currentState': array([6.04154208, 2.30794633]), 'targetState': array([0.14173618, 0.18332093]), 'effectorPosition': array([0.49546852, 0.64042943])}
episode index:1823
target Thresh 1.9530284572992498
current state at start:  [-1.7352943  -1.99178885]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.7352943 , -1.99178885]), 'currentState': array([5.047891  , 3.80701422]), 'targetState': array([-0.96874385,  0.33607623]), 'effectorPosition': array([-0.5127264 , -0.40472024])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.32030516042720164
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.7352943 , -1.99178885]), 'currentState': array([1.12990794, 0.6996292 ]), 'targetState': array([-0.96874385,  0.33607623]), 'effectorPosition': array([0.17087959, 1.87108583])}
episode index:1824
target Thresh 1.9531223065041634
current state at start:  [-0.65421042 -2.61169953]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.65421042, -2.61169953]), 'currentState': array([5.96962953, 3.35755449]), 'targetState': array([ 0.3049192 , -0.45626723]), 'effectorPosition': array([-0.04399866, -0.2110039 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.32067759595573464
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.65421042, -2.61169953]), 'currentState': array([5.96962953, 3.35755449]), 'targetState': array([ 0.3049192 , -0.45626723]), 'effectorPosition': array([-0.04399866, -0.2110039 ])}
episode index:1825
target Thresh 1.9532159681982404
current state at start:  [-0.93216505 -1.87818169]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.93216505, -1.87818169]), 'currentState': array([5.74490828, 4.14262943]), 'targetState': array([ 0.34612162, -1.03104221]), 'effectorPosition': array([-0.03623065, -0.95907671])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.3210496235592638
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.93216505, -1.87818169]), 'currentState': array([5.74490828, 4.14262943]), 'targetState': array([ 0.34612162, -1.03104221]), 'effectorPosition': array([-0.03623065, -0.95907671])}
episode index:1826
target Thresh 1.9533094427561277
current state at start:  [ 3.12199019 -2.50048213]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.12199019, -2.50048213]), 'currentState': array([3.51585298, 3.28738799]), 'targetState': array([0.67722905, 1.2388912 ]), 'effectorPosition': array([-0.06298677,  0.13134428])}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.32137390797301557
{'reset': False, 'endBeforeDone': False, 'stepCount': 10, 'initial state': array([ 3.12199019, -2.50048213]), 'currentState': array([1.48605667, 5.07057329]), 'targetState': array([0.67722905, 1.2388912 ]), 'effectorPosition': array([1.04748466, 1.26646145])}
episode index:1827
target Thresh 1.953402730551724
current state at start:  [-3.59694015  2.62400069]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.59694015,  2.62400069]), 'currentState': array([3.18624515, 3.03950491]), 'targetState': array([ 0.28124521, -0.67533758]), 'effectorPosition': array([-0.00065219, -0.10204134])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3211981016776255
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.59694015,  2.62400069]), 'currentState': array([0.83010186, 6.27685308]), 'targetState': array([ 0.28124521, -0.67533758]), 'effectorPosition': array([1.35426081, 1.47171246])}
episode index:1828
target Thresh 1.9534958319581803
current state at start:  [-1.22767542 -1.79674429]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.22767542, -1.79674429]), 'currentState': array([5.55550989, 4.00479445]), 'targetState': array([ 0.02035825, -0.3361932 ]), 'effectorPosition': array([-0.24410777, -0.8002475 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.32156923448151964
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.22767542, -1.79674429]), 'currentState': array([5.55550989, 4.00479445]), 'targetState': array([ 0.02035825, -0.3361932 ]), 'effectorPosition': array([-0.24410777, -0.8002475 ])}
episode index:1829
target Thresh 1.9535887473479026
current state at start:  [-2.7521146   2.36079357]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.7521146 ,  2.36079357]), 'currentState': array([4.03107071, 2.84488401]), 'targetState': array([-0.07089888, -1.04544715]), 'effectorPosition': array([ 0.19957917, -0.21808302])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3213935135883603
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-2.7521146 ,  2.36079357]), 'currentState': array([0.82091632, 0.32730897]), 'targetState': array([-0.07089888, -1.04544715]), 'effectorPosition': array([1.09165765, 1.64380821])}
episode index:1830
target Thresh 1.9536814770925521
current state at start:  [ 0.25694386 -2.13227861]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.25694386, -2.13227861]), 'currentState': array([0.75694386, 3.65090669]), 'targetState': array([0.19098621, 0.12609763]), 'effectorPosition': array([ 0.42708519, -0.26728243])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.3217641342800106
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.25694386, -2.13227861]), 'currentState': array([0.75694386, 3.65090669]), 'targetState': array([0.19098621, 0.12609763]), 'effectorPosition': array([ 0.42708519, -0.26728243])}
episode index:1831
target Thresh 1.9537740215630484
current state at start:  [-0.3074523   2.40673199]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.3074523 ,  2.40673199]), 'currentState': array([0.1925477 , 1.90673199]), 'targetState': array([-0.24077008,  0.62075276]), 'effectorPosition': array([0.4772957 , 1.05493292])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.32158849883553464
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.3074523 ,  2.40673199]), 'currentState': array([1.35308633, 0.30456109]), 'targetState': array([-0.24077008,  0.62075276]), 'effectorPosition': array([0.12925231, 1.97262545])}
episode index:1832
target Thresh 1.9538663811295691
current state at start:  [ 1.46032566 -2.25692117]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.46032566, -2.25692117]), 'currentState': array([1.9236942 , 3.78847213]), 'targetState': array([ 0.19803812, -0.11947208]), 'effectorPosition': array([0.49573212, 0.39788545])}
done in step count: 74
reward sum = 0.47534004200570695
running average episode reward sum: 0.3216723785644872
{'reset': False, 'endBeforeDone': False, 'stepCount': 75, 'initial state': array([ 1.46032566, -2.25692117]), 'currentState': array([1.63812714, 3.48591758]), 'targetState': array([ 0.19803812, -0.11947208]), 'effectorPosition': array([0.33284734, 0.08127456])}
episode index:1833
target Thresh 1.9539585561615531
current state at start:  [ 2.68770402 -2.53295393]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.68770402, -2.53295393]), 'currentState': array([3.16874864, 4.01407142]), 'targetState': array([-0.53359999,  0.79570383]), 'effectorPosition': array([-0.37773527,  0.75594717])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.32204224095349243
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.68770402, -2.53295393]), 'currentState': array([3.16874864, 4.01407142]), 'targetState': array([-0.53359999,  0.79570383]), 'effectorPosition': array([-0.37773527,  0.75594717])}
episode index:1834
target Thresh 1.9540505470277
current state at start:  [-1.27596418  2.2995363 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.27596418,  2.2995363 ]), 'currentState': array([4.65466648, 1.83581696]), 'targetState': array([1.18761835, 0.08013807]), 'effectorPosition': array([ 0.92090012, -0.79251788])}
done in step count: 44
reward sum = 0.6426116020847181
running average episode reward sum: 0.32221693815301894
{'reset': False, 'endBeforeDone': False, 'stepCount': 45, 'initial state': array([-1.27596418,  2.2995363 ]), 'currentState': array([1.10370736, 3.89811551]), 'targetState': array([1.18761835, 0.08013807]), 'effectorPosition': array([ 0.73569869, -0.06552273])}
episode index:1835
target Thresh 1.9541423540959741
current state at start:  [-1.43438576 -2.3120394 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.43438576, -2.3120394 ]), 'currentState': array([5.33041807, 3.47114591]), 'targetState': array([-1.17193282, -0.19746194]), 'effectorPosition': array([-0.23257687, -0.2313741 ])}
done in step count: 96
reward sum = 0.38104711810454966
running average episode reward sum: 0.32224898073469194
{'reset': False, 'endBeforeDone': False, 'stepCount': 97, 'initial state': array([-1.43438576, -2.3120394 ]), 'currentState': array([1.83273494, 2.10364155]), 'targetState': array([-1.17193282, -0.19746194]), 'effectorPosition': array([-0.95939259,  0.25217758])}
episode index:1836
target Thresh 1.9542339777336033
current state at start:  [-2.80837237  2.42619452]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.80837237,  2.42619452]), 'currentState': array([3.97481294, 1.92619452]), 'targetState': array([-0.06111647,  0.08858811]), 'effectorPosition': array([ 0.25535871, -1.11304291])}
done in step count: 18
reward sum = 0.8345137614500875
running average episode reward sum: 0.3225278401689409
{'reset': False, 'endBeforeDone': False, 'stepCount': 19, 'initial state': array([-2.80837237,  2.42619452]), 'currentState': array([0.25701523, 3.30804334]), 'targetState': array([-0.06111647,  0.08858811]), 'effectorPosition': array([ 0.0554828 , -0.15672773])}
episode index:1837
target Thresh 1.9543254183070826
current state at start:  [-1.77659869  1.97017333]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.77659869,  1.97017333]), 'currentState': array([4.03349913, 1.64234063]), 'targetState': array([ 0.67124213, -1.02583617]), 'effectorPosition': array([ 0.19323636, -1.34896002])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.3228964322036695
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.77659869,  1.97017333]), 'currentState': array([4.03349913, 1.64234063]), 'targetState': array([ 0.67124213, -1.02583617]), 'effectorPosition': array([ 0.19323636, -1.34896002])}
episode index:1838
target Thresh 1.954416676182174
current state at start:  [ 2.50720504 -2.60439443]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.50720504, -2.60439443]), 'currentState': array([3.00720504, 3.26885594]), 'targetState': array([-0.43129199,  1.29307822]), 'effectorPosition': array([0.00899106, 0.12685921])}
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.32320284244810255
{'reset': False, 'endBeforeDone': False, 'stepCount': 13, 'initial state': array([ 2.50720504, -2.60439443]), 'currentState': array([2.7210018, 5.0031292]), 'targetState': array([-0.43129199,  1.29307822]), 'effectorPosition': array([-0.78336182,  1.39988113])}
episode index:1839
target Thresh 1.9545077517239093
current state at start:  [-2.08254047 -1.90789453]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.08254047, -1.90789453]), 'currentState': array([3.77864243, 4.87529077]), 'targetState': array([-0.32967758, -0.97752848]), 'effectorPosition': array([-1.52117647,  0.10191497])}
done in step count: 76
reward sum = 0.46588077516979337
running average episode reward sum: 0.3232803848028426
{'reset': False, 'endBeforeDone': False, 'stepCount': 77, 'initial state': array([-2.08254047, -1.90789453]), 'currentState': array([3.66139975, 1.42088936]), 'targetState': array([-0.32967758, -0.97752848]), 'effectorPosition': array([-0.50639269, -1.42907618])}
episode index:1840
target Thresh 1.954598645296591
current state at start:  [ 2.40772038 -2.01908681]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.40772038, -2.01908681]), 'currentState': array([2.84977519, 4.7468076 ]), 'targetState': array([0.65488468, 1.06116107]), 'effectorPosition': array([-0.70315663,  1.25474874])}
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.32358143892462216
{'reset': False, 'endBeforeDone': False, 'stepCount': 14, 'initial state': array([ 2.40772038, -2.01908681]), 'currentState': array([2.28791152, 4.46153213]), 'targetState': array([0.65488468, 1.06116107]), 'effectorPosition': array([0.23604347, 1.20325198])}
episode index:1841
target Thresh 1.9546893572637933
current state at start:  [2.10868924 1.97490491]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.10868924, 1.97490491]), 'currentState': array([2.48029809, 2.18411573]), 'targetState': array([-0.65704329, -0.37944619]), 'effectorPosition': array([-0.83715461, -0.38471038])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.323948658556042
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([2.10868924, 1.97490491]), 'currentState': array([2.48029809, 2.18411573]), 'targetState': array([-0.65704329, -0.37944619]), 'effectorPosition': array([-0.83715461, -0.38471038])}
episode index:1842
target Thresh 1.9547798879883642
current state at start:  [ 2.49728859 -1.88910893]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.49728859, -1.88910893]), 'currentState': array([2.89904765, 4.89407638]), 'targetState': array([0.43796921, 0.83413692]), 'effectorPosition': array([-0.90990982,  1.23832266])}
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.3242538328442461
{'reset': False, 'endBeforeDone': False, 'stepCount': 13, 'initial state': array([ 2.49728859, -1.88910893]), 'currentState': array([2.08313638, 3.80940805]), 'targetState': array([0.43796921, 0.83413692]), 'effectorPosition': array([0.43444704, 0.49081867])}
episode index:1843
target Thresh 1.9548702378324267
current state at start:  [-1.08596111 -1.90984409]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.08596111, -1.90984409]), 'currentState': array([5.67779397, 3.87334122]), 'targetState': array([-0.40855965, -0.85151866]), 'effectorPosition': array([-0.16974808, -0.69510517])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.3246202895509466
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.08596111, -1.90984409]), 'currentState': array([5.67779397, 3.87334122]), 'targetState': array([-0.40855965, -0.85151866]), 'effectorPosition': array([-0.16974808, -0.69510517])}
episode index:1844
target Thresh 1.9549604071573805
current state at start:  [1.64355037 1.9296246 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.64355037, 1.9296246 ]), 'currentState': array([2.14355037, 1.4296246 ]), 'targetState': array([-0.79381777,  0.63808265]), 'effectorPosition': array([-1.45025362,  0.42210305])}
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.3249296217811405
{'reset': False, 'endBeforeDone': False, 'stepCount': 12, 'initial state': array([1.64355037, 1.9296246 ]), 'currentState': array([1.14797661, 2.43207331]), 'targetState': array([-0.79381777,  0.63808265]), 'effectorPosition': array([-0.49507421,  0.48739237])}
episode index:1845
target Thresh 1.955050396323903
current state at start:  [-1.66509261  2.35175838]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.66509261,  2.35175838]), 'currentState': array([5.1180927 , 1.90180021]), 'targetState': array([ 0.0917499 , -0.07737026]), 'effectorPosition': array([ 1.13535003, -0.24697197])}
done in step count: 18
reward sum = 0.8345137614500875
running average episode reward sum: 0.32520566952744007
{'reset': False, 'endBeforeDone': False, 'stepCount': 19, 'initial state': array([-1.66509261,  2.35175838]), 'currentState': array([1.23249069, 3.61453372]), 'targetState': array([ 0.0917499 , -0.07737026]), 'effectorPosition': array([ 0.46611829, -0.04763197])}
episode index:1846
target Thresh 1.9551402056919507
current state at start:  [-1.64908918  1.71435871]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.64908918,  1.71435871]), 'currentState': array([5.13409613, 1.21435871]), 'targetState': array([ 0.58228454, -0.28032501]), 'effectorPosition': array([ 1.40718933, -0.8471683 ])}
done in step count: 17
reward sum = 0.8429431933839268
running average episode reward sum: 0.32548598220954966
{'reset': False, 'endBeforeDone': False, 'stepCount': 18, 'initial state': array([-1.64908918,  1.71435871]), 'currentState': array([1.01130182, 4.05104199]), 'targetState': array([ 0.58228454, -0.28032501]), 'effectorPosition': array([ 0.87361322, -0.09186469])}
episode index:1847
target Thresh 1.9552298356207614
current state at start:  [ 2.84685705 -2.80394016]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.84685705, -2.80394016]), 'currentState': array([3.32767621, 3.91611977]), 'targetState': array([0.59099588, 0.6201142 ]), 'effectorPosition': array([-0.40971674,  0.63453016])}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.32579923767102115
{'reset': False, 'endBeforeDone': False, 'stepCount': 11, 'initial state': array([ 2.84685705, -2.80394016]), 'currentState': array([1.83416837, 4.27251299]), 'targetState': array([0.59099588, 0.6201142 ]), 'effectorPosition': array([0.72412578, 0.78992868])}
episode index:1848
target Thresh 1.9553192864688547
current state at start:  [ 1.48753459 -2.74766604]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.48753459, -2.74766604]), 'currentState': array([1.97656504, 3.34918445]), 'targetState': array([-0.11440116,  0.1816926 ]), 'effectorPosition': array([0.18089348, 0.10108097])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.3261638676127891
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.48753459, -2.74766604]), 'currentState': array([1.97656504, 3.34918445]), 'targetState': array([-0.11440116,  0.1816926 ]), 'effectorPosition': array([0.18089348, 0.10108097])}
episode index:1849
target Thresh 1.9554085585940344
current state at start:  [-2.26817526  2.75217107]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.26817526,  2.75217107]), 'currentState': array([3.5222172 , 3.25217107]), 'targetState': array([ 0.65635161, -1.22831573]), 'effectorPosition': array([-0.04666672,  0.10018657])}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.32647641799516536
{'reset': False, 'endBeforeDone': False, 'stepCount': 11, 'initial state': array([-2.26817526,  2.75217107]), 'currentState': array([4.1207761 , 1.65789735]), 'targetState': array([ 0.65635161, -1.22831573]), 'effectorPosition': array([ 0.31771003, -1.31342243])}
episode index:1850
target Thresh 1.9554976523533891
current state at start:  [ 4.00052353 -2.26847129]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.00052353, -2.26847129]), 'currentState': array([4.40597087, 3.57065796]), 'targetState': array([-0.02983334,  1.12266139]), 'effectorPosition': array([-0.42398547,  0.03906811])}
done in step count: 23
reward sum = 0.7936142836436554
running average episode reward sum: 0.326728788533063
{'reset': False, 'endBeforeDone': False, 'stepCount': 24, 'initial state': array([ 4.00052353, -2.26847129]), 'currentState': array([2.94755562, 3.88990673]), 'targetState': array([-0.02983334,  1.12266139]), 'effectorPosition': array([-0.13095263,  0.71915045])}
episode index:1851
target Thresh 1.9555865681032938
current state at start:  [-3.1001582   2.35187765]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.1001582 ,  2.35187765]), 'currentState': array([3.65653513, 2.75445294]), 'targetState': array([ 0.09908699, -0.65428219]), 'effectorPosition': array([ 0.12152329, -0.36502966])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.32709232590426546
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.1001582 ,  2.35187765]), 'currentState': array([3.65653513, 2.75445294]), 'targetState': array([ 0.09908699, -0.65428219]), 'effectorPosition': array([ 0.12152329, -0.36502966])}
episode index:1852
target Thresh 1.9556753061994119
current state at start:  [-3.46667696  1.82064537]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.46667696,  1.82064537]), 'currentState': array([3.25842556, 2.30157901]), 'targetState': array([-0.95915624, -0.8727961 ]), 'effectorPosition': array([-0.2434782 , -0.77833993])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3269158054909334
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.46667696,  1.82064537]), 'currentState': array([2.06288813, 3.10604523]), 'targetState': array([-0.95915624, -0.8727961 ]), 'effectorPosition': array([-0.03162148, -0.01623479])}
episode index:1853
target Thresh 1.9557638669966955
current state at start:  [-3.03964697  2.49963707]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.03964697,  2.49963707]), 'currentState': array([3.73539685, 2.0020516 ]), 'targetState': array([ 0.0946456 , -0.09767297]), 'effectorPosition': array([ 0.02592689, -1.07856611])}
done in step count: 30
reward sum = 0.7397003733882802
running average episode reward sum: 0.3271384508889363
{'reset': False, 'endBeforeDone': False, 'stepCount': 31, 'initial state': array([-3.03964697,  2.49963707]), 'currentState': array([1.31826042, 3.68038166]), 'targetState': array([ 0.0946456 , -0.09767297]), 'effectorPosition': array([0.53222002, 0.00897333])}
episode index:1854
target Thresh 1.955852250849388
current state at start:  [-0.77117217 -2.80825257]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.77117217, -2.80825257]), 'currentState': array([5.01201314, 3.09177328]), 'targetState': array([ 0.35856256, -1.083155  ]), 'effectorPosition': array([0.04794633, 0.01351321])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3269620959288883
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-0.77117217, -2.80825257]), 'currentState': array([6.10705664, 2.05622104]), 'targetState': array([ 0.35856256, -1.083155  ]), 'effectorPosition': array([0.68014123, 0.77732863])}
episode index:1855
target Thresh 1.9559404581110251
current state at start:  [ 3.47082005 -1.95221769]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.47082005, -1.95221769]), 'currentState': array([2.97117699, 4.83096762]), 'targetState': array([-0.00717293,  0.14327087]), 'effectorPosition': array([-0.93370055,  1.16824877])}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.3272781277993381
{'reset': False, 'endBeforeDone': False, 'stepCount': 10, 'initial state': array([ 3.47082005, -1.95221769]), 'currentState': array([2.84616723, 2.92614127]), 'targetState': array([-0.00717293,  0.14327087]), 'effectorPosition': array([-0.08436223, -0.19779542])}
episode index:1856
target Thresh 1.9560284891344362
current state at start:  [ 0.97443457 -1.78886886]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.97443457, -1.78886886]), 'currentState': array([1.47443457, 4.15259986]), 'targetState': array([ 0.80115349, -0.31430753]), 'effectorPosition': array([0.88855903, 0.38528925])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.32710188755819686
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.97443457, -1.78886886]), 'currentState': array([1.16818116, 1.67907488]), 'targetState': array([ 0.80115349, -0.31430753]), 'effectorPosition': array([-0.56516907,  1.21014451])}
episode index:1857
target Thresh 1.9561163442717449
current state at start:  [-3.76166547  1.72744883]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.76166547,  1.72744883]), 'currentState': array([2.10006946, 2.17120008]), 'targetState': array([-1.28501748, -0.48997058]), 'effectorPosition': array([-0.93185808, -0.04109999])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.3274640501590805
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.76166547,  1.72744883]), 'currentState': array([2.10006946, 2.17120008]), 'targetState': array([-1.28501748, -0.48997058]), 'effectorPosition': array([-0.93185808, -0.04109999])}
episode index:1858
target Thresh 1.956204023874372
current state at start:  [ 3.14118967 -1.90358209]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.14118967, -1.90358209]), 'currentState': array([2.68697042, 4.87530545]), 'targetState': array([-0.24321407,  0.57540263]), 'effectorPosition': array([-0.61084064,  1.39687766])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3272878995134866
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.14118967, -1.90358209]), 'currentState': array([1.19224549, 1.42921119]), 'targetState': array([-0.24321407,  0.57540263]), 'effectorPosition': array([-0.49817731,  1.42619932])}
episode index:1859
target Thresh 1.9562915282930367
current state at start:  [-1.86821425  2.82544901]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.86821425,  2.82544901]), 'currentState': array([4.86907629, 2.32544901]), 'targetState': array([1.12706947, 0.82715857]), 'effectorPosition': array([ 0.76873423, -0.19742419])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.32763360440622125
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-1.86821425,  2.82544901]), 'currentState': array([0.03863603, 0.85431563]), 'targetState': array([1.12706947, 0.82715857]), 'effectorPosition': array([1.62636936, 0.81755259])}
episode index:1860
target Thresh 1.956378857877756
current state at start:  [ 3.04910542 -2.74540861]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.04910542, -2.74540861]), 'currentState': array([2.54910542, 4.0377767 ]), 'targetState': array([-0.75440558, -0.44366683]), 'effectorPosition': array([0.12468317, 0.85747592])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3274575519589315
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 3.04910542, -2.74540861]), 'currentState': array([0.52435057, 2.5189875 ]), 'targetState': array([-0.75440558, -0.44366683]), 'effectorPosition': array([-0.12952764,  0.59874751])}
episode index:1861
target Thresh 1.9564660129778486
current state at start:  [-1.75113169 -2.70990984]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.75113169, -2.70990984]), 'currentState': array([4.93907687, 3.07327547]), 'targetState': array([0.11045314, 0.94928425]), 'effectorPosition': array([0.06704188, 0.01306941])}
done in step count: 21
reward sum = 0.8097278682212584
running average episode reward sum: 0.3277165585734655
{'reset': False, 'endBeforeDone': False, 'stepCount': 22, 'initial state': array([-1.75113169, -2.70990984]), 'currentState': array([2.19616409, 3.84780296]), 'targetState': array([0.11045314, 0.94928425]), 'effectorPosition': array([0.38612802, 0.57380467])}
episode index:1862
target Thresh 1.9565529939419353
current state at start:  [-0.74601945 -2.20893504]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.74601945, -2.20893504]), 'currentState': array([6.01299915, 3.57425027]), 'targetState': array([-0.05290194, -0.03268874]), 'effectorPosition': array([-0.02310929, -0.42866845])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.32807741925055967
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.74601945, -2.20893504]), 'currentState': array([6.01299915, 3.57425027]), 'targetState': array([-0.05290194, -0.03268874]), 'effectorPosition': array([-0.02310929, -0.42866845])}
episode index:1863
target Thresh 1.9566398011179396
current state at start:  [ 2.9094986  -2.21988801]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.9094986 , -2.21988801]), 'currentState': array([2.45374119, 4.56255773]), 'targetState': array([-1.07384369,  0.71210321]), 'effectorPosition': array([-0.02951744,  1.30406524])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3284064979684515
{'reset': False, 'endBeforeDone': False, 'stepCount': 7, 'initial state': array([ 2.9094986 , -2.21988801]), 'currentState': array([1.67286849, 1.27937242]), 'targetState': array([-1.07384369,  0.71210321]), 'effectorPosition': array([-1.08402147,  1.18301742])}
episode index:1864
target Thresh 1.9567264348530906
current state at start:  [ 3.54946072 -2.06632117]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.54946072, -2.06632117]), 'currentState': array([3.13041366, 4.71686414]), 'targetState': array([0.08729441, 0.14620913]), 'effectorPosition': array([-0.99323373,  1.01115629])}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.32872023027382163
{'reset': False, 'endBeforeDone': False, 'stepCount': 10, 'initial state': array([ 3.54946072, -2.06632117]), 'currentState': array([2.6500037 , 2.90945702]), 'targetState': array([0.08729441, 0.14620913]), 'effectorPosition': array([-0.13223936, -0.19015297])}
episode index:1865
target Thresh 1.9568128954939235
current state at start:  [ 0.61457773 -2.660047  ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.61457773, -2.660047  ]), 'currentState': array([1.11457773, 3.13758594]), 'targetState': array([-0.01125516,  0.00477738]), 'effectorPosition': array([-0.00359338,  0.00177239])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.3290799729156899
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.61457773, -2.660047  ]), 'currentState': array([1.11457773, 3.13758594]), 'targetState': array([-0.01125516,  0.00477738]), 'effectorPosition': array([-0.00359338,  0.00177239])}
episode index:1866
target Thresh 1.9568991833862808
current state at start:  [0.77580505 2.77188314]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.77580505, 2.77188314]), 'currentState': array([1.24812227, 2.29980753]), 'targetState': array([-0.13649867, -0.18686682]), 'effectorPosition': array([-0.60147097,  0.55314347])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.3294286713769027
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([0.77580505, 2.77188314]), 'currentState': array([2.20279669, 2.68768853]), 'targetState': array([-0.13649867, -0.18686682]), 'effectorPosition': array([-0.41360367, -0.17733535])}
episode index:1867
target Thresh 1.9569852988753138
current state at start:  [-2.44437567  2.29305757]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.44437567,  2.29305757]), 'currentState': array([4.27431663, 1.83981244]), 'targetState': array([-0.06404069,  0.11462836]), 'effectorPosition': array([ 0.56154937, -1.07382316])}
done in step count: 25
reward sum = 0.7778213593991467
running average episode reward sum: 0.32966871028912015
{'reset': False, 'endBeforeDone': False, 'stepCount': 26, 'initial state': array([-2.44437567,  2.29305757]), 'currentState': array([0.88621952, 3.19891988]), 'targetState': array([-0.06404069,  0.11462836]), 'effectorPosition': array([ 0.04542511, -0.03495812])}
episode index:1868
target Thresh 1.9570712423054852
current state at start:  [-3.07847995  2.09528588]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.07847995,  2.09528588]), 'currentState': array([3.65140736, 1.59528588]), 'targetState': array([-1.15338572, -0.81691442]), 'effectorPosition': array([-0.36359256, -1.34863866])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.32949232253615646
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-3.07847995,  2.09528588]), 'currentState': array([1.07788458, 0.73112541]), 'targetState': array([-1.15338572, -0.81691442]), 'effectorPosition': array([0.23722591, 1.85271982])}
episode index:1869
target Thresh 1.9571570140205687
current state at start:  [0.96930814 2.6683579 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.96930814, 2.6683579 ]), 'currentState': array([1.43917248, 2.22103857]), 'targetState': array([-0.27481711,  0.12047752]), 'effectorPosition': array([-0.73726073,  0.4956694 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.3298508827914847
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.96930814, 2.6683579 ]), 'currentState': array([1.43917248, 2.22103857]), 'targetState': array([-0.27481711,  0.12047752]), 'effectorPosition': array([-0.73726073,  0.4956694 ])}
episode index:1870
target Thresh 1.957242614363651
current state at start:  [1.456368   2.25547257]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.456368  , 2.25547257]), 'currentState': array([1.91397819, 2.30174475]), 'targetState': array([-0.44510309, -0.11106136]), 'effectorPosition': array([-0.81298217,  0.06251272])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.3302090597648725
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.456368  , 2.25547257]), 'currentState': array([1.91397819, 2.30174475]), 'targetState': array([-0.44510309, -0.11106136]), 'effectorPosition': array([-0.81298217,  0.06251272])}
episode index:1871
target Thresh 1.9573280436771339
current state at start:  [-1.9815611  -1.75883865]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.9815611 , -1.75883865]), 'currentState': array([3.8016242 , 5.02434666]), 'targetState': array([-0.68139227, -0.91467508]), 'effectorPosition': array([-1.61598148, -0.04948425])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3300326660363656
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-1.9815611 , -1.75883865]), 'currentState': array([1.53459199, 2.66166184]), 'targetState': array([-0.68139227, -0.91467508]), 'effectorPosition': array([-0.45732602,  0.12961164])}
episode index:1872
target Thresh 1.9574133023027345
current state at start:  [0.21560666 1.88025405]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.21560666, 1.88025405]), 'currentState': array([0.65981174, 1.56318163]), 'targetState': array([0.38893808, 0.10351428]), 'effectorPosition': array([0.18317367, 1.40772037])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.3303693255900035
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([0.21560666, 1.88025405]), 'currentState': array([2.47090307, 3.23940229]), 'targetState': array([0.38893808, 0.10351428]), 'effectorPosition': array([0.05695012, 0.07947191])}
episode index:1873
target Thresh 1.9574983905814873
current state at start:  [-0.50598904  2.68693597]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.50598904,  2.68693597]), 'currentState': array([6.27151988, 2.18693597]), 'targetState': array([0.04868704, 0.08484934]), 'effectorPosition': array([0.43160243, 0.81113587])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.33070562584849333
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([-0.50598904,  2.68693597]), 'currentState': array([1.98833457, 2.81899807]), 'targetState': array([0.04868704, 0.08484934]), 'effectorPosition': array([-0.31071033, -0.08140626])}
episode index:1874
target Thresh 1.957583308853746
current state at start:  [-0.74080889  2.5294414 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.74080889,  2.5294414 ]), 'currentState': array([6.04237642, 2.0294414 ]), 'targetState': array([ 0.01191441, -0.00792858]), 'effectorPosition': array([0.75502793, 0.73787912])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3310364442079875
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([-0.74080889,  2.5294414 ]), 'currentState': array([2.25919111, 3.03251326]), 'targetState': array([ 0.01191441, -0.00792858]), 'effectorPosition': array([-0.08784719, -0.06457084])}
episode index:1875
target Thresh 1.9576680574591836
current state at start:  [ 3.62052499 -1.62180113]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.62052499, -1.62180113]), 'currentState': array([4.12052499, 4.19039751]), 'targetState': array([-0.6719173 ,  0.60382579]), 'effectorPosition': array([-0.99911381,  0.06750421])}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.3313518537230301
{'reset': False, 'endBeforeDone': False, 'stepCount': 9, 'initial state': array([ 3.62052499, -1.62180113]), 'currentState': array([1.51621364, 1.99082006]), 'targetState': array([-0.6719173 ,  0.60382579]), 'effectorPosition': array([-0.87941065,  0.64114948])}
episode index:1876
target Thresh 1.9577526367367946
current state at start:  [-0.2871331  -2.81769514]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.2871331 , -2.81769514]), 'currentState': array([0.17408654, 3.47607337]), 'targetState': array([-0.00711335, -0.00589224]), 'effectorPosition': array([ 0.11144213, -0.31371777])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.3317080860865234
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.2871331 , -2.81769514]), 'currentState': array([0.17408654, 3.47607337]), 'targetState': array([-0.00711335, -0.00589224]), 'effectorPosition': array([ 0.11144213, -0.31371777])}
episode index:1877
target Thresh 1.957837047024896
current state at start:  [-0.88906888 -2.67794984]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.88906888, -2.67794984]), 'currentState': array([5.83835947, 3.10523547]), 'targetState': array([-0.90804348,  0.53048432]), 'effectorPosition': array([0.01623761, 0.03252751])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.3320429571855189
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([-0.88906888, -2.67794984]), 'currentState': array([1.33805465, 1.91295425]), 'targetState': array([-0.90804348,  0.53048432]), 'effectorPosition': array([-0.76337387,  0.86383964])}
episode index:1878
target Thresh 1.9579212886611295
current state at start:  [0.27397104 2.53893285]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.27397104, 2.53893285]), 'currentState': array([0.75602936, 2.03893285]), 'targetState': array([0.11854129, 0.02073359]), 'effectorPosition': array([-0.21295704,  1.02576855])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.33238263576072613
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([0.27397104, 2.53893285]), 'currentState': array([2.25602936, 2.97958734]), 'targetState': array([0.11854129, 0.02073359]), 'effectorPosition': array([-0.13317484, -0.09193928])}
episode index:1879
target Thresh 1.9580053619824616
current state at start:  [-0.96975635 -2.5916487 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.96975635, -2.5916487 ]), 'currentState': array([5.81342896, 3.23341855]), 'targetState': array([0.20859913, 0.13886878]), 'effectorPosition': array([-0.03775168, -0.08367128])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.3327377513800024
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.96975635, -2.5916487 ]), 'currentState': array([5.81342896, 3.23341855]), 'targetState': array([0.20859913, 0.13886878]), 'effectorPosition': array([-0.03775168, -0.08367128])}
episode index:1880
target Thresh 1.9580892673251853
current state at start:  [ 3.51186182 -2.01377094]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.51186182, -2.01377094]), 'currentState': array([3.04198508, 4.7366333 ]), 'targetState': array([-0.64835058,  0.19076282]), 'effectorPosition': array([-0.91975133,  1.09660448])}
done in step count: 16
reward sum = 0.8514577710948755
running average episode reward sum: 0.3330135195988832
{'reset': False, 'endBeforeDone': False, 'stepCount': 17, 'initial state': array([ 3.51186182, -2.01377094]), 'currentState': array([1.17365704, 2.48683989]), 'targetState': array([-0.64835058,  0.19076282]), 'effectorPosition': array([-0.48158124,  0.42624229])}
episode index:1881
target Thresh 1.9581730050249226
current state at start:  [-2.66218642  1.91423783]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.66218642,  1.91423783]), 'currentState': array([4.11179506, 1.41808785]), 'targetState': array([ 0.73903573, -0.56707699]), 'effectorPosition': array([ 0.16430129, -1.50905148])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.33333182556504054
{'reset': False, 'endBeforeDone': False, 'stepCount': 8, 'initial state': array([-2.66218642,  1.91423783]), 'currentState': array([0.90009399, 4.20127315]), 'targetState': array([ 0.73903573, -0.56707699]), 'effectorPosition': array([ 1.00077945, -0.14191173])}
episode index:1882
target Thresh 1.9582565754166243
current state at start:  [-1.84436249 -1.63749271]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.84436249, -1.63749271]), 'currentState': array([4.28489535, 5.11321432]), 'targetState': array([-0.25194703, -1.06362629]), 'effectorPosition': array([-1.41423572, -0.88334259])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.3336700980952768
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-1.84436249, -1.63749271]), 'currentState': array([5.61357401, 4.54442627]), 'targetState': array([-0.25194703, -1.06362629]), 'effectorPosition': array([ 0.04104132, -1.28994862])}
episode index:1883
target Thresh 1.9583399788345721
current state at start:  [ 2.01111944 -2.18976232]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.01111944, -2.18976232]), 'currentState': array([2.51111944, 4.5892352 ]), 'targetState': array([1.11382342, 0.55147085]), 'effectorPosition': array([-0.12346052,  1.31873882])}
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.3339682234435589
{'reset': False, 'endBeforeDone': False, 'stepCount': 12, 'initial state': array([ 2.01111944, -2.18976232]), 'currentState': array([1.72793413, 4.3384173 ]), 'targetState': array([1.11382342, 0.55147085]), 'effectorPosition': array([0.82009158, 0.77254052])}
episode index:1884
target Thresh 1.9584232156123795
current state at start:  [0.0125873  2.36400242]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.0125873 , 2.36400242]), 'currentState': array([0.5125873 , 1.88768906]), 'targetState': array([ 0.31103528, -0.10854067]), 'effectorPosition': array([0.13389817, 1.16569303])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.3343057994523421
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([0.0125873 , 2.36400242]), 'currentState': array([2.0125873 , 3.23957718]), 'targetState': array([ 0.31103528, -0.10854067]), 'effectorPosition': array([0.08638426, 0.04616328])}
episode index:1885
target Thresh 1.958506286082994
current state at start:  [1.4325088  2.81398459]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.4325088 , 2.81398459]), 'currentState': array([1.9325088 , 3.08805297]), 'targetState': array([-0.54686924,  0.90445159]), 'effectorPosition': array([-0.0505584 , -0.01759719])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3341285429308934
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([1.4325088 , 2.81398459]), 'currentState': array([5.13675993, 5.14427719]), 'targetState': array([-0.54686924,  0.90445159]), 'effectorPosition': array([-0.24352025, -1.66669453])}
episode index:1886
target Thresh 1.9585891905786974
current state at start:  [ 0.71500893 -1.73888401]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.71500893, -1.73888401]), 'currentState': array([1.21500893, 4.04740533]), 'targetState': array([0.4866763 , 0.10956489]), 'effectorPosition': array([0.87103733, 0.0848612 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.33448141598710385
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.71500893, -1.73888401]), 'currentState': array([1.21500893, 4.04740533]), 'targetState': array([0.4866763 , 0.10956489]), 'effectorPosition': array([0.87103733, 0.0848612 ])}
episode index:1887
target Thresh 1.9586719294311081
current state at start:  [1.15815418 2.23062889]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.15815418, 2.23062889]), 'currentState': array([1.65815418, 2.62803061]), 'targetState': array([-0.14181537, -0.08092026]), 'effectorPosition': array([-0.50066433,  0.08564517])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.33483391523711065
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.15815418, 2.23062889]), 'currentState': array([1.65815418, 2.62803061]), 'targetState': array([-0.14181537, -0.08092026]), 'effectorPosition': array([-0.50066433,  0.08564517])}
episode index:1888
target Thresh 1.9587545029711813
current state at start:  [ 2.25568891 -2.32949618]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.25568891, -2.32949618]), 'currentState': array([1.82898701, 4.44240809]), 'targetState': array([0.02657709, 0.05502086]), 'effectorPosition': array([0.74459887, 0.9550636 ])}
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.3351258956269884
{'reset': False, 'endBeforeDone': False, 'stepCount': 13, 'initial state': array([ 2.25568891, -2.32949618]), 'currentState': array([0.59575513, 3.4452962 ]), 'targetState': array([0.02657709, 0.05502086]), 'effectorPosition': array([ 0.2056911 , -0.22185635])}
episode index:1889
target Thresh 1.9588369115292112
current state at start:  [ 4.00282673 -2.4966482 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.00282673, -2.4966482 ]), 'currentState': array([3.54778398, 4.24279215]), 'targetState': array([-0.14070675, -0.16070382]), 'effectorPosition': array([-0.85526931,  0.60287712])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.33544173660703075
{'reset': False, 'endBeforeDone': False, 'stepCount': 8, 'initial state': array([ 4.00282673, -2.4966482 ]), 'currentState': array([5.62582553, 3.77912569]), 'targetState': array([-0.14070675, -0.16070382]), 'effectorPosition': array([-0.20819521, -0.59120352])}
episode index:1890
target Thresh 1.9589191554348326
current state at start:  [-0.47023575 -2.5481389 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.47023575, -2.5481389 ]), 'currentState': array([0.02976425, 3.64584551]), 'targetState': array([ 0.53364018, -0.76477712]), 'effectorPosition': array([ 0.13878774, -0.47923538])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.33579316879285465
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.47023575, -2.5481389 ]), 'currentState': array([0.02976425, 3.64584551]), 'targetState': array([ 0.53364018, -0.76477712]), 'effectorPosition': array([ 0.13878774, -0.47923538])}
episode index:1891
target Thresh 1.959001235017021
current state at start:  [-2.46242213  2.70260227]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.46242213,  2.70260227]), 'currentState': array([4.32076317, 2.21715585]), 'targetState': array([ 0.61462117, -0.36703179]), 'effectorPosition': array([ 0.58603879, -0.672302  ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.3361442294858817
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.46242213,  2.70260227]), 'currentState': array([4.32076317, 2.21715585]), 'targetState': array([ 0.61462117, -0.36703179]), 'effectorPosition': array([ 0.58603879, -0.672302  ])}
episode index:1892
target Thresh 1.9590831506040947
current state at start:  [ 3.0084527  -2.09188245]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.0084527 , -2.09188245]), 'currentState': array([3.5084527 , 4.69130285]), 'targetState': array([0.59425677, 1.11921696]), 'effectorPosition': array([-1.2723831 ,  0.58212724])}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.3364444079568394
{'reset': False, 'endBeforeDone': False, 'stepCount': 11, 'initial state': array([ 3.0084527 , -2.09188245]), 'currentState': array([2.2252674 , 4.37913226]), 'targetState': array([0.59425677, 1.11921696]), 'effectorPosition': array([0.34011303, 1.10908905])}
episode index:1893
target Thresh 1.9591649025237161
current state at start:  [-1.69412206 -2.63224571]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.69412206, -2.63224571]), 'currentState': array([5.08906325, 4.15093959]), 'targetState': array([ 0.22350841, -0.13080996]), 'effectorPosition': array([-0.61514766, -0.7461676 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.33678947426731626
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.69412206, -2.63224571]), 'currentState': array([5.56487086, 3.76666577]), 'targetState': array([ 0.22350841, -0.13080996]), 'effectorPosition': array([-0.24274009, -0.56501024])}
episode index:1894
target Thresh 1.9592464911028933
current state at start:  [-1.10091674  2.14027361]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.10091674,  2.14027361]), 'currentState': array([5.67102096, 1.69127882]), 'targetState': array([0.17297195, 0.21379691]), 'effectorPosition': array([1.29051539, 0.30689997])}
done in step count: 18
reward sum = 0.8345137614500875
running average episode reward sum: 0.33705212560619896
{'reset': False, 'endBeforeDone': False, 'stepCount': 19, 'initial state': array([-1.10091674,  2.14027361]), 'currentState': array([1.47947132, 3.58119748]), 'targetState': array([0.17297195, 0.21379691]), 'effectorPosition': array([0.43247952, 0.0558716 ])}
episode index:1895
target Thresh 1.9593279166679807
current state at start:  [-3.45132584  1.80474097]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.45132584,  1.80474097]), 'currentState': array([3.25126761, 1.63172269]), 'targetState': array([-0.85082735, -0.89018041]), 'effectorPosition': array([-0.82421676, -1.09493807])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.3374017816580944
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.45132584,  1.80474097]), 'currentState': array([3.25126761, 1.63172269]), 'targetState': array([-0.85082735, -0.89018041]), 'effectorPosition': array([-0.82421676, -1.09493807])}
episode index:1896
target Thresh 1.9594091795446804
current state at start:  [-3.60842263  1.63299597]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.60842263,  1.63299597]), 'currentState': array([3.08839384, 2.12683884]), 'targetState': array([-0.50166632, -0.96869592]), 'effectorPosition': array([-0.51666609, -0.82304195])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.33775106906892305
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.60842263,  1.63299597]), 'currentState': array([3.08839384, 2.12683884]), 'targetState': array([-0.50166632, -0.96869592]), 'effectorPosition': array([-0.51666609, -0.82304195])}
episode index:1897
target Thresh 1.959490280058044
current state at start:  [0.46037895 2.62692976]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.46037895, 2.62692976]), 'currentState': array([0.92410052, 2.29708964]), 'targetState': array([ 0.31139744, -0.45502991]), 'effectorPosition': array([-0.3942811 ,  0.71856563])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.33808950370060437
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([0.46037895, 2.62692976]), 'currentState': array([1.87184298, 3.22439569]), 'targetState': array([ 0.31139744, -0.45502991]), 'effectorPosition': array([0.07797283, 0.02779683])}
episode index:1898
target Thresh 1.959571218532474
current state at start:  [-0.19620615 -2.23615435]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.19620615, -2.23615435]), 'currentState': array([0.27974791, 3.64690795]), 'targetState': array([ 0.47513813, -0.86125485]), 'effectorPosition': array([ 0.25378148, -0.43075653])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.3384380610972865
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.19620615, -2.23615435]), 'currentState': array([0.27974791, 3.64690795]), 'targetState': array([ 0.47513813, -0.86125485]), 'effectorPosition': array([ 0.25378148, -0.43075653])}
episode index:1899
target Thresh 1.9596519952917244
current state at start:  [-4.16710606  2.06305019]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.16710606,  2.06305019]), 'currentState': array([2.5973723 , 1.56305019]), 'targetState': array([-1.00903265,  0.69283802]), 'effectorPosition': array([-1.37989392, -0.33374377])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.3382599358019721
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([-4.16710606,  2.06305019]), 'currentState': array([1.27393812, 3.86637884]), 'targetState': array([-1.00903265,  0.69283802]), 'effectorPosition': array([0.70750379, 0.04643267])}
episode index:1900
target Thresh 1.959732610658902
current state at start:  [-1.05743313 -2.46143391]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.05743313, -2.46143391]), 'currentState': array([5.69345987, 4.30504266]), 'targetState': array([ 0.38429664, -0.35751352]), 'effectorPosition': array([-0.00879184, -1.09889688])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.33860277644594794
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-1.05743313, -2.46143391]), 'currentState': array([6.19246533, 3.80870966]), 'targetState': array([ 0.38429664, -0.35751352]), 'effectorPosition': array([ 0.15745604, -0.63560222])}
episode index:1901
target Thresh 1.9598130649564685
current state at start:  [-0.88599149  2.39490359]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.88599149,  2.39490359]), 'currentState': array([5.88261673, 1.89490359]), 'targetState': array([-0.08289403, -0.04046222]), 'effectorPosition': array([0.99722626, 0.60713628])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.33892979707347376
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([-0.88599149,  2.39490359]), 'currentState': array([1.59716316, 2.5643444 ]), 'targetState': array([-0.08289403, -0.04046222]), 'effectorPosition': array([-0.54980224,  0.14758893])}
episode index:1902
target Thresh 1.9598933585062412
current state at start:  [-3.075321   2.5192789]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.075321 ,  2.5192789]), 'currentState': array([3.70786431, 2.91600873]), 'targetState': array([ 0.39361632, -0.75229304]), 'effectorPosition': array([ 0.09861804, -0.20235404])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.33924642889287865
{'reset': False, 'endBeforeDone': False, 'stepCount': 7, 'initial state': array([-3.075321 ,  2.5192789]), 'currentState': array([5.67734897, 4.45738018]), 'targetState': array([ 0.39361632, -0.75229304]), 'effectorPosition': array([ 0.06363243, -1.22124652])}
episode index:1903
target Thresh 1.9599734916293945
current state at start:  [-2.72096956  2.54528908]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.72096956,  2.54528908]), 'currentState': array([4.06221575, 2.10039027]), 'targetState': array([-0.01657889, -0.22446151]), 'effectorPosition': array([ 0.38741482, -0.91626626])}
done in step count: 18
reward sum = 0.8345137614500875
running average episode reward sum: 0.33950654829023014
{'reset': False, 'endBeforeDone': False, 'stepCount': 19, 'initial state': array([-2.72096956,  2.54528908]), 'currentState': array([0.41359669, 3.81964653]), 'targetState': array([-0.01657889, -0.22446151]), 'effectorPosition': array([ 0.45465991, -0.48548373])}
episode index:1904
target Thresh 1.9600534646464611
current state at start:  [ 3.47522337 -2.73484803]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.47522337, -2.73484803]), 'currentState': array([3.94156898, 3.07079452]), 'targetState': array([-0.37928198,  0.42256258]), 'effectorPosition': array([ 0.0489985 , -0.05108258])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.33985326401291244
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.47522337, -2.73484803]), 'currentState': array([3.94156898, 3.07079452]), 'targetState': array([-0.37928198,  0.42256258]), 'effectorPosition': array([ 0.0489985 , -0.05108258])}
episode index:1905
target Thresh 1.9601332778773328
current state at start:  [ 1.14594896 -1.9633078 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.14594896, -1.9633078 ]), 'currentState': array([1.61772915, 4.81987751]), 'targetState': array([ 1.1479631 , -0.54765092]), 'effectorPosition': array([0.94118511, 1.15270721])}
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.34014470419667203
{'reset': False, 'endBeforeDone': False, 'stepCount': 12, 'initial state': array([ 1.14594896, -1.9633078 ]), 'currentState': array([6.23821698, 4.89381913]), 'targetState': array([ 1.1479631 , -0.54765092]), 'effectorPosition': array([ 1.13502778, -1.03565669])}
episode index:1906
target Thresh 1.9602129316412629
current state at start:  [ 3.94427024 -2.84439206]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.94427024, -2.84439206]), 'currentState': array([4.25395201, 3.93879325]), 'targetState': array([ 0.59396863, -0.54942086]), 'effectorPosition': array([-0.77486825,  0.04642095])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.34046502163018194
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([ 3.94427024, -2.84439206]), 'currentState': array([0.1426814 , 4.22308727]), 'targetState': array([ 0.59396863, -0.54942086]), 'effectorPosition': array([ 0.6501172 , -0.79832846])}
episode index:1907
target Thresh 1.9602924262568666
current state at start:  [ 3.72899883 -2.2101219 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.72899883, -2.2101219 ]), 'currentState': array([4.22515215, 4.57306341]), 'targetState': array([ 0.00587563, -0.00520021]), 'effectorPosition': array([-1.27823403, -0.2972663 ])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.340800260088447
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 3.72899883, -2.2101219 ]), 'currentState': array([5.22515215, 3.60123679]), 'targetState': array([ 0.00587563, -0.00520021]), 'effectorPosition': array([-0.33565725, -0.30808012])}
episode index:1908
target Thresh 1.9603717620421224
current state at start:  [-0.88794202 -2.47054773]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.88794202, -2.47054773]), 'currentState': array([5.8580074 , 4.16787249]), 'targetState': array([ 0.16315856, -0.43976978]), 'effectorPosition': array([ 0.08625245, -0.97803445])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.3411403332890293
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.88794202, -2.47054773]), 'currentState': array([0.02414035, 3.69445003]), 'targetState': array([ 0.16315856, -0.43976978]), 'effectorPosition': array([ 0.16160444, -0.52137217])}
episode index:1909
target Thresh 1.9604509393143734
current state at start:  [ 0.04401293 -2.126378  ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.04401293, -2.126378  ]), 'currentState': array([0.47091957, 3.66942516]), 'targetState': array([-0.3065613 , -0.29696565]), 'effectorPosition': array([ 0.34979948, -0.38709012])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.34148005039201934
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.04401293, -2.126378  ]), 'currentState': array([0.91731285, 3.18792704]), 'targetState': array([-0.3065613 , -0.29696565]), 'effectorPosition': array([ 0.03742747, -0.02730706])}
episode index:1910
target Thresh 1.960529958390329
current state at start:  [0.47207667 1.7762612 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.47207667, 1.7762612 ]), 'currentState': array([0.88785081, 1.72462704]), 'targetState': array([-0.15040168,  0.4874454 ]), 'effectorPosition': array([-0.23217358,  1.28048662])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.34181941195644006
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([0.47207667, 1.7762612 ]), 'currentState': array([1.26033627, 2.22462704]), 'targetState': array([-0.15040168,  0.4874454 ]), 'effectorPosition': array([-0.63612851,  0.61553023])}
episode index:1911
target Thresh 1.9606088195860656
current state at start:  [ 2.68417069 -2.33672803]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.68417069, -2.33672803]), 'currentState': array([2.18417069, 4.44645728]), 'targetState': array([-0.35879535,  0.10279895]), 'effectorPosition': array([0.36461656, 1.15820469])}
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.3421042265274441
{'reset': False, 'endBeforeDone': False, 'stepCount': 13, 'initial state': array([ 2.68417069, -2.33672803]), 'currentState': array([0.2663539 , 3.12916068]), 'targetState': array([-0.35879535,  0.10279895]), 'effectorPosition': array([-0.00319765,  0.01201361])}
episode index:1912
target Thresh 1.960687523217028
current state at start:  [ 1.70655955 -2.15298099]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.70655955, -2.15298099]), 'currentState': array([2.17309995, 4.58555298]), 'targetState': array([0.01439192, 0.0035373 ]), 'effectorPosition': array([0.32253653, 1.28178696])}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.3424077500339263
{'reset': False, 'endBeforeDone': False, 'stepCount': 9, 'initial state': array([ 1.70655955, -2.15298099]), 'currentState': array([5.67758505, 3.42488816]), 'targetState': array([0.01439192, 0.0035373 ]), 'effectorPosition': array([-0.12634735, -0.25250221])}
episode index:1913
target Thresh 1.960766069598031
current state at start:  [-1.92446063  2.11997595]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.92446063,  2.11997595]), 'currentState': array([4.85872468, 1.61997595]), 'targetState': array([ 0.96064865, -0.79879991]), 'effectorPosition': array([ 1.12676167, -0.79503997])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.3427513196525084
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.92446063,  2.11997595]), 'currentState': array([4.85872468, 1.61997595]), 'targetState': array([ 0.96064865, -0.79879991]), 'effectorPosition': array([ 1.12676167, -0.79503997])}
episode index:1914
target Thresh 1.9608444590432597
current state at start:  [-3.66975134  2.03106569]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.66975134,  2.03106569]), 'currentState': array([3.08157636, 1.53106569]), 'targetState': array([-0.41589659, -0.54177066]), 'effectorPosition': array([-1.09778117, -0.93504913])}
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.34303520140293325
{'reset': False, 'endBeforeDone': False, 'stepCount': 13, 'initial state': array([-3.66975134,  2.03106569]), 'currentState': array([2.0217132 , 2.77046877]), 'targetState': array([-0.41589659, -0.54177066]), 'effectorPosition': array([-0.35608261, -0.09677031])}
episode index:1915
target Thresh 1.9609226918662725
current state at start:  [-0.8805633   2.23739304]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.8805633 ,  2.23739304]), 'currentState': array([5.84514608, 1.73739304]), 'targetState': array([0.13780678, 0.82540942]), 'effectorPosition': array([1.17370651, 0.5392205 ])}
done in step count: 18
reward sum = 0.8345137614500875
running average episode reward sum: 0.3432917142213295
{'reset': False, 'endBeforeDone': False, 'stepCount': 19, 'initial state': array([-0.8805633 ,  2.23739304]), 'currentState': array([2.06524251, 3.90215694]), 'targetState': array([0.13780678, 0.82540942]), 'effectorPosition': array([0.47600837, 0.56966809])}
episode index:1916
target Thresh 1.9610007683800008
current state at start:  [ 2.07475282 -2.59285008]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.07475282, -2.59285008]), 'currentState': array([2.52242072, 4.02022092]), 'targetState': array([0.19133113, 0.6797247 ]), 'effectorPosition': array([0.15217029, 0.83691614])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.34363428505376487
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.07475282, -2.59285008]), 'currentState': array([2.52242072, 4.02022092]), 'targetState': array([0.19133113, 0.6797247 ]), 'effectorPosition': array([0.15217029, 0.83691614])}
episode index:1917
target Thresh 1.9610786888967506
current state at start:  [ 2.31956884 -2.1607199 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.31956884, -2.1607199 ]), 'currentState': array([2.37148706, 4.57421795]), 'targetState': array([-0.61645225, -0.04684517]), 'effectorPosition': array([0.0706077 , 1.31131649])}
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.3439219305017341
{'reset': False, 'endBeforeDone': False, 'stepCount': 12, 'initial state': array([ 2.31956884, -2.1607199 ]), 'currentState': array([0.96387571, 2.5600319 ]), 'targetState': array([-0.61645225, -0.04684517]), 'effectorPosition': array([-0.35746275,  0.44833892])}
episode index:1918
target Thresh 1.961156453728204
current state at start:  [-1.55122752  2.48257818]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.55122752,  2.48257818]), 'currentState': array([5.18663218, 2.06241991]), 'targetState': array([-0.11691364, -0.08976375]), 'effectorPosition': array([ 1.02536942, -0.06709641])}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.34422355778882435
{'reset': False, 'endBeforeDone': False, 'stepCount': 9, 'initial state': array([-1.55122752,  2.48257818]), 'currentState': array([2.66794681, 2.55314225]), 'targetState': array([-0.11691364, -0.08976375]), 'effectorPosition': array([-0.40286888, -0.41724457])}
episode index:1919
target Thresh 1.9612340631854206
current state at start:  [-1.32124073  1.57562784]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.32124073,  1.57562784]), 'currentState': array([5.41555297, 1.12538326]), 'targetState': array([ 1.2295768 , -0.23974152]), 'effectorPosition': array([ 1.61360014, -0.50789364])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.34456510801914264
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.32124073,  1.57562784]), 'currentState': array([5.41555297, 1.12538326]), 'targetState': array([ 1.2295768 , -0.23974152]), 'effectorPosition': array([ 1.61360014, -0.50789364])}
episode index:1920
target Thresh 1.961311517578838
current state at start:  [ 0.10755501 -3.00983972]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.10755501, -3.00983972]), 'currentState': array([0.54804272, 2.86210465]), 'targetState': array([-0.89697311, -0.85859958]), 'effectorPosition': array([-0.11060946,  0.25567936])}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.3448565275750977
{'reset': False, 'endBeforeDone': False, 'stepCount': 11, 'initial state': array([ 0.10755501, -3.00983972]), 'currentState': array([4.30817441, 5.45634346]), 'targetState': array([-0.89697311, -0.85859958]), 'effectorPosition': array([-1.33613812, -1.25265346])}
episode index:1921
target Thresh 1.9613888172182745
current state at start:  [ 0.60097795 -2.19376795]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.60097795, -2.19376795]), 'currentState': array([1.00529858, 3.64356779]), 'targetState': array([-0.11494365, -0.4613325 ]), 'effectorPosition': array([ 0.47235624, -0.15366112])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.34519219015180164
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.60097795, -2.19376795]), 'currentState': array([1.43743282, 3.14356779]), 'targetState': array([-0.11494365, -0.4613325 ]), 'effectorPosition': array([ 0.00195786, -0.0002607 ])}
episode index:1922
target Thresh 1.9614659624129283
current state at start:  [ 3.43671255 -2.60738938]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.43671255, -2.60738938]), 'currentState': array([2.95763407, 4.17579593]), 'targetState': array([-0.8301264 , -0.00655085]), 'effectorPosition': array([-0.32332799,  0.93436466])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.34550227229389685
{'reset': False, 'endBeforeDone': False, 'stepCount': 7, 'initial state': array([ 3.43671255, -2.60738938]), 'currentState': array([4.56706251, 4.347003  ]), 'targetState': array([-0.8301264 , -0.00655085]), 'effectorPosition': array([-1.01721195, -0.50065977])}
episode index:1923
target Thresh 1.9615429534713802
current state at start:  [ 2.16971151 -2.65817101]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.16971151, -2.65817101]), 'currentState': array([2.60318888, 4.1250143 ]), 'targetState': array([ 0.90448836, -0.14260588]), 'effectorPosition': array([0.04407471, 0.94324025])}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.34579749837247786
{'reset': False, 'endBeforeDone': False, 'stepCount': 10, 'initial state': array([ 2.16971151, -2.65817101]), 'currentState': array([0.53616545, 4.34526426]), 'targetState': array([ 0.90448836, -0.14260588]), 'effectorPosition': array([ 1.02791068, -0.47490331])}
episode index:1924
target Thresh 1.9616197907015949
current state at start:  [-0.7365219  -2.02546307]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.7365219 , -2.02546307]), 'currentState': array([6.04666341, 3.75772224]), 'targetState': array([-0.5354112 , -0.13319552]), 'effectorPosition': array([ 0.04334877, -0.60487889])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.3461270061655311
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-0.7365219 , -2.02546307]), 'currentState': array([0.7634781 , 2.75772224]), 'targetState': array([-0.5354112 , -0.13319552]), 'effectorPosition': array([-0.20637459,  0.32088222])}
episode index:1925
target Thresh 1.961696474410921
current state at start:  [-0.7408802   2.77503807]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.7408802 ,  2.77503807]), 'currentState': array([6.04230511, 2.28949157]), 'targetState': array([ 0.15066786, -0.11540245]), 'effectorPosition': array([0.51128835, 0.64944427])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3464410575901077
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([-0.7408802 ,  2.77503807]), 'currentState': array([2.24016597, 2.79634482]), 'targetState': array([ 0.15066786, -0.11540245]), 'effectorPosition': array([-0.30201533, -0.16371782])}
episode index:1926
target Thresh 1.961773004906094
current state at start:  [-3.32713654  1.91217241]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.32713654,  1.91217241]), 'currentState': array([3.45604876, 2.40495908]), 'targetState': array([-0.01113451, -1.38378008]), 'effectorPosition': array([-0.03876585, -0.719047  ])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.34674984798544284
{'reset': False, 'endBeforeDone': False, 'stepCount': 7, 'initial state': array([-3.32713654,  1.91217241]), 'currentState': array([5.54675996, 4.33873466]), 'targetState': array([-0.01113451, -1.38378008]), 'effectorPosition': array([-0.15485993, -1.11623399])}
episode index:1927
target Thresh 1.9618493824932355
current state at start:  [-1.22001697 -1.99597048]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.22001697, -1.99597048]), 'currentState': array([5.56316834, 3.79790546]), 'targetState': array([ 0.11945013, -0.40747151]), 'effectorPosition': array([-0.24617704, -0.59573634])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.34708867067839644
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.22001697, -1.99597048]), 'currentState': array([5.56316834, 3.79790546]), 'targetState': array([ 0.11945013, -0.40747151]), 'effectorPosition': array([-0.24617704, -0.59573634])}
episode index:1928
target Thresh 1.961925607477856
current state at start:  [-0.43152596  1.73283421]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.43152596,  1.73283421]), 'currentState': array([0.06847404, 1.23283421]), 'targetState': array([0.21270497, 0.8386294 ]), 'effectorPosition': array([1.2638946 , 1.03232786])}
done in step count: 17
reward sum = 0.8429431933839268
running average episode reward sum: 0.3473457233081038
{'reset': False, 'endBeforeDone': False, 'stepCount': 18, 'initial state': array([-0.43152596,  1.73283421]), 'currentState': array([2.28528873, 3.97851422]), 'targetState': array([0.21270497, 0.8386294 ]), 'effectorPosition': array([0.34457812, 0.73604478])}
episode index:1929
target Thresh 1.9620016801648557
current state at start:  [-2.22354895  1.97486443]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.22354895,  1.97486443]), 'currentState': array([4.55235371, 1.47486443]), 'targetState': array([-0.19629504, -0.84660355]), 'effectorPosition': array([ 0.80806585, -1.24040284])}
done in step count: 15
reward sum = 0.8600583546412884
running average episode reward sum: 0.34761137752122984
{'reset': False, 'endBeforeDone': False, 'stepCount': 16, 'initial state': array([-2.22354895,  1.97486443]), 'currentState': array([5.69091382, 4.20921464]), 'targetState': array([-0.19629504, -0.84660355]), 'effectorPosition': array([-0.0594576 , -1.01589718])}
episode index:1930
target Thresh 1.9620776008585255
current state at start:  [ 0.73395938 -2.33782251]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.73395938, -2.33782251]), 'currentState': array([1.23395938, 3.4453628 ]), 'targetState': array([-0.16971978, -0.06802666]), 'effectorPosition': array([ 0.29744267, -0.05564856])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.34794922766233743
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.73395938, -2.33782251]), 'currentState': array([1.23395938, 3.4453628 ]), 'targetState': array([-0.16971978, -0.06802666]), 'effectorPosition': array([ 0.29744267, -0.05564856])}
episode index:1931
target Thresh 1.962153369862548
current state at start:  [ 2.95714551 -1.70495481]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.95714551, -1.70495481]), 'currentState': array([3.45714551, 5.0782305 ]), 'targetState': array([-0.1570202 ,  0.72455212]), 'effectorPosition': array([-1.58050159,  0.46635311])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3482613605931023
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([ 2.95714551, -1.70495481]), 'currentState': array([5.95714551, 2.64412379]), 'targetState': array([-0.1570202 ,  0.72455212]), 'effectorPosition': array([0.26766653, 0.41324103])}
episode index:1932
target Thresh 1.9622289874799996
current state at start:  [ 2.93869873 -2.72687397]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.93869873, -2.72687397]), 'currentState': array([3.37190159, 4.05631134]), 'targetState': array([-0.19610805, -0.07102482]), 'effectorPosition': array([-0.56057494,  0.68244319])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.34858315968229364
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 2.93869873, -2.72687397]), 'currentState': array([4.86275049, 3.69079882]), 'targetState': array([-0.19610805, -0.07102482]), 'effectorPosition': array([-0.49409139, -0.22359636])}
episode index:1933
target Thresh 1.9623044540133507
current state at start:  [-0.66323447  2.19122612]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.66323447,  2.19122612]), 'currentState': array([6.11995084, 1.74983966]), 'targetState': array([ 0.12976437, -0.01531911]), 'effectorPosition': array([0.9708986 , 0.83736452])}
done in step count: 16
reward sum = 0.8514577710948755
running average episode reward sum: 0.34884317757857725
{'reset': False, 'endBeforeDone': False, 'stepCount': 17, 'initial state': array([-0.66323447,  2.19122612]), 'currentState': array([1.4422397 , 3.43884727]), 'targetState': array([ 0.12976437, -0.01531911]), 'effectorPosition': array([0.29610178, 0.00594376])}
episode index:1934
target Thresh 1.9623797697644676
current state at start:  [-2.37958656  2.66102325]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.37958656,  2.66102325]), 'currentState': array([4.40359875, 2.16102325]), 'targetState': array([0.13068693, 0.07261946]), 'effectorPosition': array([ 0.6567511 , -0.67496582])}
done in step count: 18
reward sum = 0.8345137614500875
running average episode reward sum: 0.3490941701283817
{'reset': False, 'endBeforeDone': False, 'stepCount': 19, 'initial state': array([-2.37958656,  2.66102325]), 'currentState': array([0.73165088, 3.77215635]), 'targetState': array([0.13068693, 0.07261946]), 'effectorPosition': array([ 0.53699987, -0.31022666])}
episode index:1935
target Thresh 1.9624549350346134
current state at start:  [-3.55029339  2.06537985]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.55029339,  2.06537985]), 'currentState': array([3.23289192, 1.56537985]), 'targetState': array([ 0.01062464, -0.1857015 ]), 'effectorPosition': array([-0.91005787, -1.08748682])}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.349385710974123
{'reset': False, 'endBeforeDone': False, 'stepCount': 10, 'initial state': array([-3.55029339,  2.06537985]), 'currentState': array([1.2684729 , 3.42443602]), 'targetState': array([ 0.01062464, -0.1857015 ]), 'effectorPosition': array([ 0.27826024, -0.04516298])}
episode index:1936
target Thresh 1.9625299501244493
current state at start:  [ 1.19314244 -2.3994991 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.19314244, -2.3994991 ]), 'currentState': array([1.67128169, 3.38368621]), 'targetState': array([ 0.13148705, -0.55922001]), 'effectorPosition': array([0.23560092, 0.0530641 ])}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.3496817145794167
{'reset': False, 'endBeforeDone': False, 'stepCount': 9, 'initial state': array([ 1.19314244, -2.3994991 ]), 'currentState': array([5.60927519, 3.81572654]), 'targetState': array([ 0.13148705, -0.55922001]), 'effectorPosition': array([-0.21861242, -0.62426984])}
episode index:1937
target Thresh 1.9626048153340359
current state at start:  [-1.62301156 -2.18326069]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.62301156, -2.18326069]), 'currentState': array([5.16017375, 3.59992462]), 'targetState': array([-0.69932873, -0.76694698]), 'effectorPosition': array([-0.35414469, -0.28460148])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.35001727613020134
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.62301156, -2.18326069]), 'currentState': array([5.16017375, 3.59992462]), 'targetState': array([-0.69932873, -0.76694698]), 'effectorPosition': array([-0.35414469, -0.28460148])}
episode index:1938
target Thresh 1.9626795309628338
current state at start:  [ 0.58759607 -2.2994463 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.58759607, -2.2994463 ]), 'currentState': array([1.08716751, 4.22422453]), 'targetState': array([ 0.60739725, -0.09023757]), 'effectorPosition': array([1.02881425, 0.05941525])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.35035249156283144
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.58759607, -2.2994463 ]), 'currentState': array([1.08716751, 4.22422453]), 'targetState': array([ 0.60739725, -0.09023757]), 'effectorPosition': array([1.02881425, 0.05941525])}
episode index:1939
target Thresh 1.9627540973097057
current state at start:  [-1.72448859 -1.76859714]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.72448859, -1.76859714]), 'currentState': array([5.05869672, 4.01458816]), 'targetState': array([-0.25633331, -0.68450148]), 'effectorPosition': array([-0.59943262, -0.59633239])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.3506873614125413
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.72448859, -1.76859714]), 'currentState': array([5.05869672, 4.01458816]), 'targetState': array([-0.25633331, -0.68450148]), 'effectorPosition': array([-0.59943262, -0.59633239])}
episode index:1940
target Thresh 1.9628285146729174
current state at start:  [1.93059052 2.10000939]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.93059052, 2.10000939]), 'currentState': array([2.43059052, 1.60000939]), 'targetState': array([-0.4171071 , -0.11939352]), 'effectorPosition': array([-1.38789142, -0.1238531 ])}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.35097262401614576
{'reset': False, 'endBeforeDone': False, 'stepCount': 11, 'initial state': array([1.93059052, 2.10000939]), 'currentState': array([1.14740522, 3.15264024]), 'targetState': array([-0.4171071 , -0.11939352]), 'effectorPosition': array([ 0.01009696, -0.00448322])}
episode index:1941
target Thresh 1.962902783350138
current state at start:  [ 1.56072631 -2.49014424]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.56072631, -2.49014424]), 'currentState': array([2.06072631, 3.76399391]), 'targetState': array([ 0.2132445 , -0.10120581]), 'effectorPosition': array([0.42616875, 0.43979359])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.3512718478698486
{'reset': False, 'endBeforeDone': False, 'stepCount': 8, 'initial state': array([ 1.56072631, -2.49014424]), 'currentState': array([5.55334768, 3.4279791 ]), 'targetState': array([ 0.2132445 , -0.10120581]), 'effectorPosition': array([-0.15799361, -0.23768925])}
episode index:1942
target Thresh 1.9629769036384428
current state at start:  [-1.63194082 -2.39651931]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.63194082, -2.39651931]), 'currentState': array([5.13046446, 3.4159958 ]), 'targetState': array([0.06038219, 0.09654261]), 'effectorPosition': array([-0.23244441, -0.14420608])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.351605727515824
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.63194082, -2.39651931]), 'currentState': array([5.13046446, 3.4159958 ]), 'targetState': array([0.06038219, 0.09654261]), 'effectorPosition': array([-0.23244441, -0.14420608])}
episode index:1943
target Thresh 1.9630508758343126
current state at start:  [ 2.98413141 -2.23668811]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.98413141, -2.23668811]), 'currentState': array([3.47680454, 3.56120202]), 'targetState': array([-0.37872855,  1.2751221 ]), 'effectorPosition': array([-0.2159466 ,  0.35618921])}
done in step count: 21
reward sum = 0.8097278682212584
running average episode reward sum: 0.3518413870532239
{'reset': False, 'endBeforeDone': False, 'stepCount': 22, 'initial state': array([ 2.98413141, -2.23668811]), 'currentState': array([0.94714389, 2.09697337]), 'targetState': array([-0.37872855,  1.2751221 ]), 'effectorPosition': array([-0.41124912,  0.90907195])}
episode index:1944
target Thresh 1.9631247002336365
current state at start:  [-1.93399623 -2.30987274]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.93399623, -2.30987274]), 'currentState': array([4.84641096, 3.47331256]), 'targetState': array([-0.51776081, -0.17156615]), 'effectorPosition': array([-0.31546467, -0.09754385])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.35217463055602427
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.93399623, -2.30987274]), 'currentState': array([4.84641096, 3.47331256]), 'targetState': array([-0.51776081, -0.17156615]), 'effectorPosition': array([-0.31546467, -0.09754385])}
episode index:1945
target Thresh 1.9631983771317123
current state at start:  [ 1.78763576 -2.60640301]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.78763576, -2.60640301]), 'currentState': array([2.28763576, 4.16930171]), 'targetState': array([0.75721142, 0.32214975]), 'effectorPosition': array([0.32793779, 0.92676522])}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.3524583959437184
{'reset': False, 'endBeforeDone': False, 'stepCount': 11, 'initial state': array([ 1.78763576, -2.60640301]), 'currentState': array([1.00445045, 4.3374313 ]), 'targetState': array([0.75721142, 0.32214975]), 'effectorPosition': array([1.12528687, 0.03554099])}
episode index:1946
target Thresh 1.9632719068232474
current state at start:  [ 1.18775039 -2.92729122]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.18775039, -2.92729122]), 'currentState': array([1.67083948, 2.86995912]), 'targetState': array([-0.40759443, -0.19095761]), 'effectorPosition': array([-0.27062595,  0.0096854 ])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.3527909802293149
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.18775039, -2.92729122]), 'currentState': array([1.67083948, 2.86995912]), 'targetState': array([-0.40759443, -0.19095761]), 'effectorPosition': array([-0.27062595,  0.0096854 ])}
episode index:1947
target Thresh 1.9633452896023609
current state at start:  [-1.766824    2.14547848]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.766824  ,  2.14547848]), 'currentState': array([4.99827589, 1.69232567]), 'targetState': array([ 0.54383493, -0.36142273]), 'effectorPosition': array([ 1.20015614, -0.56317352])}
done in step count: 19
reward sum = 0.8261686238355866
running average episode reward sum: 0.3530339872332195
{'reset': False, 'endBeforeDone': False, 'stepCount': 20, 'initial state': array([-1.766824  ,  2.14547848]), 'currentState': array([0.89753989, 4.21945403]), 'targetState': array([ 0.54383493, -0.36142273]), 'effectorPosition': array([ 1.01719078, -0.13746267])}
episode index:1948
target Thresh 1.9634185257625838
current state at start:  [-0.33697276  2.60382027]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.33697276,  2.60382027]), 'currentState': array([0.16302724, 2.69750157]), 'targetState': array([ 0.59709624, -0.39104785]), 'effectorPosition': array([0.02597957, 0.43968396])}
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.3533030929467986
{'reset': False, 'endBeforeDone': False, 'stepCount': 14, 'initial state': array([-0.33697276,  2.60382027]), 'currentState': array([0.15200411, 4.19323935]), 'targetState': array([ 0.59709624, -0.39104785]), 'effectorPosition': array([ 0.62951694, -0.78193633])}
episode index:1949
target Thresh 1.9634916155968611
current state at start:  [ 3.51703105 -2.28264595]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.51703105, -2.28264595]), 'currentState': array([3.99688701, 4.50053936]), 'targetState': array([-0.01003796,  0.00989766]), 'effectorPosition': array([-1.25595127,  0.04526978])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.35362452725810795
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([ 3.51703105, -2.28264595]), 'currentState': array([4.99267961, 3.50053936]), 'targetState': array([-0.01003796,  0.00989766]), 'effectorPosition': array([-0.31994859, -0.15842409])}
episode index:1950
target Thresh 1.9635645593975521
current state at start:  [ 4.02001158 -1.93980733]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.02001158, -1.93980733]), 'currentState': array([4.50112681, 3.84337798]), 'targetState': array([-0.7463668 ,  0.85151801]), 'effectorPosition': array([-0.68078159, -0.09568049])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.3539210115331715
{'reset': False, 'endBeforeDone': False, 'stepCount': 8, 'initial state': array([ 4.02001158, -1.93980733]), 'currentState': array([1.63866732, 1.4624199 ]), 'targetState': array([-0.7463668 ,  0.85151801]), 'effectorPosition': array([-1.06699867,  1.03819201])}
episode index:1951
target Thresh 1.963637357456432
current state at start:  [-3.53846619  1.89901007]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.53846619,  1.89901007]), 'currentState': array([3.24471912, 1.41425343]), 'targetState': array([-0.28550259, -1.0760705 ]), 'effectorPosition': array([-1.04807821, -1.10151745])}
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.3541937901500685
{'reset': False, 'endBeforeDone': False, 'stepCount': 13, 'initial state': array([-3.53846619,  1.89901007]), 'currentState': array([2.90121176, 2.17704381]), 'targetState': array([-0.28550259, -1.0760705 ]), 'effectorPosition': array([-0.6134887, -0.6957415])}
episode index:1952
target Thresh 1.9637100100646934
current state at start:  [ 3.7805725  -2.13684691]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.7805725 , -2.13684691]), 'currentState': array([4.2805725, 4.6463384]), 'targetState': array([-0.72158716, -0.54806031]), 'effectorPosition': array([-1.29712438, -0.4306544 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.35451934376494304
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 3.7805725 , -2.13684691]), 'currentState': array([4.7805725, 4.1463384]), 'targetState': array([-0.72158716, -0.54806031]), 'effectorPosition': array([-0.81047245, -0.52012379])}
episode index:1953
target Thresh 1.9637825175129466
current state at start:  [-4.05269157  1.90661745]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.05269157,  1.90661745]), 'currentState': array([2.73049373, 1.40661745]), 'targetState': array([-0.6900097 , -0.41077685]), 'effectorPosition': array([-1.46075012, -0.43942427])}
done in step count: 11
reward sum = 0.8953382542587164
running average episode reward sum: 0.3547961190517873
{'reset': False, 'endBeforeDone': False, 'stepCount': 12, 'initial state': array([-4.05269157,  1.90661745]), 'currentState': array([1.94730843, 2.64465206]), 'targetState': array([-0.6900097 , -0.41077685]), 'effectorPosition': array([-0.48781673, -0.06280453])}
episode index:1954
target Thresh 1.9638548800912217
current state at start:  [-3.68004748  2.67091367]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.68004748,  2.67091367]), 'currentState': array([3.10313783, 2.21362427]), 'targetState': array([0.51863549, 0.24591458]), 'effectorPosition': array([-0.43101435, -0.78441313])}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.3550819099103203
{'reset': False, 'endBeforeDone': False, 'stepCount': 10, 'initial state': array([-3.68004748,  2.67091367]), 'currentState': array([1.11605015, 4.10456223]), 'targetState': array([0.51863549, 0.24591458]), 'effectorPosition': array([0.92586026, 0.02476212])}
episode index:1955
target Thresh 1.9639270980889687
current state at start:  [ 0.46865186 -2.61294262]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.46865186, -2.61294262]), 'currentState': array([0.93001476, 3.28198077]), 'targetState': array([0.04300426, 0.43223721]), 'effectorPosition': array([ 0.11805136, -0.0757651 ])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.3554065101608774
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([ 0.46865186, -2.61294262]), 'currentState': array([1.43001476, 3.67605509]), 'targetState': array([0.04300426, 0.43223721]), 'effectorPosition': array([0.5239073 , 0.06660326])}
episode index:1956
target Thresh 1.9639991717950602
current state at start:  [-0.83105346 -2.90803734]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.83105346, -2.90803734]), 'currentState': array([5.93492187, 3.00311777]), 'targetState': array([ 0.01788388, -0.0228955 ]), 'effectorPosition': array([0.05610357, 0.12647949])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.3557358885409689
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.83105346, -2.90803734]), 'currentState': array([5.93492187, 3.00311777]), 'targetState': array([ 0.01788388, -0.0228955 ]), 'effectorPosition': array([0.05610357, 0.12647949])}
episode index:1957
target Thresh 1.9640711014977907
current state at start:  [ 2.40741833 -2.02969541]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.40741833, -2.02969541]), 'currentState': array([2.83968686, 4.7534899 ]), 'targetState': array([0.531004  , 0.06219071]), 'effectorPosition': array([-0.69691326,  1.26352309])}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.35602076155370777
{'reset': False, 'endBeforeDone': False, 'stepCount': 10, 'initial state': array([ 2.40741833, -2.02969541]), 'currentState': array([0.5244485 , 3.79578101]), 'targetState': array([0.531004  , 0.06219071]), 'effectorPosition': array([ 0.48341538, -0.42335019])}
episode index:1958
target Thresh 1.9641428874848794
current state at start:  [ 4.34902056 -2.52638304]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.34902056, -2.52638304]), 'currentState': array([4.76358117, 3.78225708]), 'targetState': array([ 0.37062682, -0.38577966]), 'effectorPosition': array([-0.58679816, -0.22862708])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.3563343288015109
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 4.34902056, -2.52638304]), 'currentState': array([6.00033511, 3.92161044]), 'targetState': array([ 0.37062682, -0.38577966]), 'effectorPosition': array([ 0.0813269 , -0.75603167])}
episode index:1959
target Thresh 1.9642145300434701
current state at start:  [-0.7607905   2.01322301]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.7607905 ,  2.01322301]), 'currentState': array([5.94036493, 1.54412423]), 'targetState': array([0.26531832, 0.32633536]), 'effectorPosition': array([1.30295256, 0.59636607])}
done in step count: 15
reward sum = 0.8600583546412884
running average episode reward sum: 0.35659133085551076
{'reset': False, 'endBeforeDone': False, 'stepCount': 16, 'initial state': array([-0.7607905 ,  2.01322301]), 'currentState': array([0.07659736, 3.23737817]), 'targetState': array([0.26531832, 0.32633536]), 'effectorPosition': array([ 0.01188903, -0.09500792])}
episode index:1960
target Thresh 1.9642860294601334
current state at start:  [ 1.84986826 -1.96243848]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.84986826, -1.96243848]), 'currentState': array([2.29783427, 4.81204822]), 'targetState': array([-0.05243407,  0.06397117]), 'effectorPosition': array([0.01264986, 1.48284479])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.35688479032366555
{'reset': False, 'endBeforeDone': False, 'stepCount': 8, 'initial state': array([ 1.84986826, -1.96243848]), 'currentState': array([5.55555439, 3.39407151]), 'targetState': array([-0.05243407,  0.06397117]), 'effectorPosition': array([-0.14247099, -0.20762872])}
episode index:1961
target Thresh 1.964357386020867
current state at start:  [ 3.25425713 -1.6146044 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.25425713, -1.6146044 ]), 'currentState': array([3.71396314, 4.1705214 ]), 'targetState': array([-0.25113881,  1.38250174]), 'effectorPosition': array([-0.8711176 ,  0.45790857])}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.35717320006072173
{'reset': False, 'endBeforeDone': False, 'stepCount': 9, 'initial state': array([ 3.25425713, -1.6146044 ]), 'currentState': array([1.27318772, 1.16020905]), 'targetState': array([-0.25113881,  1.38250174]), 'effectorPosition': array([-0.46630184,  1.606505  ])}
episode index:1962
target Thresh 1.964428600011097
current state at start:  [0.54886607 2.09011577]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.54886607, 2.09011577]), 'currentState': array([1.02542866, 1.68410559]), 'targetState': array([0.05122312, 1.12565577]), 'effectorPosition': array([-0.38937328,  1.27367756])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.3575006716857545
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.54886607, 2.09011577]), 'currentState': array([1.02542866, 1.68410559]), 'targetState': array([0.05122312, 1.12565577]), 'effectorPosition': array([-0.38937328,  1.27367756])}
episode index:1963
target Thresh 1.9644996717156797
current state at start:  [ 3.2437112  -2.41949512]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.2437112 , -2.41949512]), 'currentState': array([3.7437112 , 4.36369018]), 'targetState': array([0.44059423, 0.20094289]), 'effectorPosition': array([-1.07485349,  0.40167098])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.3578126871278697
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([ 3.2437112 , -2.41949512]), 'currentState': array([5.21150717, 3.09856568]), 'targetState': array([0.44059423, 0.20094289]), 'effectorPosition': array([0.03820924, 0.01977596])}
episode index:1964
target Thresh 1.964570601418902
current state at start:  [-2.97294529  2.34054705]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.97294529,  2.34054705]), 'currentState': array([3.79660707, 1.92202093]), 'targetState': array([ 0.24907234, -0.76417342]), 'effectorPosition': array([ 0.05178639, -1.14421254])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.35813950000973843
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-2.97294529,  2.34054705]), 'currentState': array([3.79660707, 1.92202093]), 'targetState': array([ 0.24907234, -0.76417342]), 'effectorPosition': array([ 0.05178639, -1.14421254])}
episode index:1965
target Thresh 1.9646413894044825
current state at start:  [-1.04124517  1.66116735]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.04124517,  1.66116735]), 'currentState': array([5.74194013, 2.0553157 ]), 'targetState': array([ 0.53998887, -1.2299764 ]), 'effectorPosition': array([0.91376321, 0.48318794])}
done in step count: 23
reward sum = 0.7936142836436554
running average episode reward sum: 0.3583610029515665
{'reset': False, 'endBeforeDone': False, 'stepCount': 24, 'initial state': array([-1.04124517,  1.66116735]), 'currentState': array([4.13401078, 1.44918226]), 'targetState': array([ 0.53998887, -1.2299764 ]), 'effectorPosition': array([ 0.21818052, -1.48156211])}
episode index:1966
target Thresh 1.9647120359555736
current state at start:  [ 0.05597379 -2.63377859]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.05597379, -2.63377859]), 'currentState': array([0.54888251, 3.73932943]), 'targetState': array([0.0024454 , 0.00382306]), 'effectorPosition': array([ 0.4415372 , -0.38964354])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.3586872047802642
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.05597379, -2.63377859]), 'currentState': array([0.54888251, 3.73932943]), 'targetState': array([0.0024454 , 0.00382306]), 'effectorPosition': array([ 0.4415372 , -0.38964354])}
episode index:1967
target Thresh 1.9647825413547615
current state at start:  [ 2.54578808 -1.64182457]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.54578808, -1.64182457]), 'currentState': array([3.04578808, 5.14136073]), 'targetState': array([-0.08924962,  0.6060393 ]), 'effectorPosition': array([-1.32245193,  1.04066938])}
done in step count: 7
reward sum = 0.9320653479069899
running average episode reward sum: 0.3589785554627473
{'reset': False, 'endBeforeDone': False, 'stepCount': 8, 'initial state': array([ 2.54578808, -1.64182457]), 'currentState': array([0.26260277, 2.7142154 ]), 'targetState': array([-0.08924962,  0.6060393 ]), 'effectorPosition': array([-0.02073779,  0.42362484])}
episode index:1968
target Thresh 1.9648529058840678
current state at start:  [-0.57766757  2.82051081]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.57766757,  2.82051081]), 'currentState': array([6.18319511, 2.34071589]), 'targetState': array([-0.4032241 ,  0.19495969]), 'effectorPosition': array([0.37407452, 0.68404186])}
done in step count: 13
reward sum = 0.8775210229989678
running average episode reward sum: 0.35924190867124717
{'reset': False, 'endBeforeDone': False, 'stepCount': 14, 'initial state': array([-0.57766757,  2.82051081]), 'currentState': array([5.87331631, 3.33077513]), 'targetState': array([-0.4032241 ,  0.19495969]), 'effectorPosition': array([-0.05857437, -0.17958963])}
episode index:1969
target Thresh 1.9649231298249508
current state at start:  [ 0.62531066 -2.40992974]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.62531066, -2.40992974]), 'currentState': array([1.12531066, 4.31299808]), 'targetState': array([1.29567149, 0.17978063]), 'effectorPosition': array([1.0947198 , 0.15451232])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.35956716658562726
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.62531066, -2.40992974]), 'currentState': array([1.12531066, 4.31299808]), 'targetState': array([1.29567149, 0.17978063]), 'effectorPosition': array([1.0947198 , 0.15451232])}
episode index:1970
target Thresh 1.9649932134583064
current state at start:  [ 3.11201125 -1.8611247 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 3.11201125, -1.8611247 ]), 'currentState': array([3.61201125, 3.9220606 ]), 'targetState': array([-0.5573738 ,  1.28030318]), 'effectorPosition': array([-0.57689771,  0.49600434])}
done in step count: 24
reward sum = 0.7856781408072188
running average episode reward sum: 0.35978335683130036
{'reset': False, 'endBeforeDone': False, 'stepCount': 25, 'initial state': array([ 3.11201125, -1.8611247 ]), 'currentState': array([1.26821407, 1.12871688]), 'targetState': array([-0.5573738 ,  1.28030318]), 'effectorPosition': array([-0.43733106,  1.63229329])}
episode index:1971
target Thresh 1.965063157064469
current state at start:  [-1.59564718 -2.91962306]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.59564718, -2.91962306]), 'currentState': array([5.07011662, 2.93685951]), 'targetState': array([-0.31635351,  0.14243246]), 'effectorPosition': array([0.19774831, 0.05162425])}
done in step count: 14
reward sum = 0.8687458127689782
running average episode reward sum: 0.36004145138299287
{'reset': False, 'endBeforeDone': False, 'stepCount': 15, 'initial state': array([-1.59564718, -2.91962306]), 'currentState': array([5.32418192, 3.57987889]), 'targetState': array([-0.31635351,  0.14243246]), 'effectorPosition': array([-0.2931265 , -0.32111721])}
episode index:1972
target Thresh 1.9651329609232133
current state at start:  [ 1.63150155 -2.43564728]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.63150155, -2.43564728]), 'currentState': array([2.13150155, 4.11294925]), 'targetState': array([ 1.26783349, -0.18864337]), 'effectorPosition': array([0.46746634, 0.80815547])}
done in step count: 23
reward sum = 0.7936142836436554
running average episode reward sum: 0.36026120446574034
{'reset': False, 'endBeforeDone': False, 'stepCount': 24, 'initial state': array([ 1.63150155, -2.43564728]), 'currentState': array([0.77782528, 4.7152709 ]), 'targetState': array([ 1.26783349, -0.18864337]), 'effectorPosition': array([ 1.41622329, -0.00868428])}
episode index:1973
target Thresh 1.965202625313755
current state at start:  [ 1.31728827 -2.22101093]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.31728827, -2.22101093]), 'currentState': array([1.81728827, 3.71096176]), 'targetState': array([ 0.63490689, -0.08139651]), 'effectorPosition': array([0.48431245, 0.28453283])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.36058528693561587
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.31728827, -2.22101093]), 'currentState': array([1.81728827, 3.71096176]), 'targetState': array([ 0.63490689, -0.08139651]), 'effectorPosition': array([0.48431245, 0.28453283])}
episode index:1974
target Thresh 1.9652721505147515
current state at start:  [-3.04548376  2.03390553]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.04548376,  2.03390553]), 'currentState': array([3.73114665, 1.53390553]), 'targetState': array([ 0.06289153, -0.00897312]), 'effectorPosition': array([-0.30623293, -1.40711985])}
done in step count: 9
reward sum = 0.9135172474836408
running average episode reward sum: 0.36086525248526047
{'reset': False, 'endBeforeDone': False, 'stepCount': 10, 'initial state': array([-3.04548376,  2.03390553]), 'currentState': array([1.73794226, 3.41575679]), 'targetState': array([ 0.06289153, -0.00897312]), 'effectorPosition': array([0.26075565, 0.08187073])}
episode index:1975
target Thresh 1.9653415368043035
current state at start:  [-3.11373281  2.28786916]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.11373281,  2.28786916]), 'currentState': array([3.65207032, 1.78786916]), 'targetState': array([-0.81585003, -0.12456196]), 'effectorPosition': array([-0.2074689 , -1.23539974])}
done in step count: 15
reward sum = 0.8600583546412884
running average episode reward sum: 0.3611178805733961
{'reset': False, 'endBeforeDone': False, 'stepCount': 16, 'initial state': array([-3.11373281,  2.28786916]), 'currentState': array([4.45493344, 4.11610142]), 'targetState': array([-0.81585003, -0.12456196]), 'effectorPosition': array([-0.91178719, -0.21329546])}
episode index:1976
target Thresh 1.9654107844599567
current state at start:  [ 1.95348526 -2.40637977]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.95348526, -2.40637977]), 'currentState': array([2.4070552 , 4.36275398]), 'targetState': array([ 0.14145175, -0.03312749]), 'effectorPosition': array([0.14177586, 1.1378883 ])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.3614114376137742
{'reset': False, 'endBeforeDone': False, 'stepCount': 7, 'initial state': array([ 1.95348526, -2.40637977]), 'currentState': array([5.17247499, 3.20497515]), 'targetState': array([ 0.14145175, -0.03312749]), 'effectorPosition': array([-0.05586201, -0.02992378])}
episode index:1977
target Thresh 1.9654798937587017
current state at start:  [ 4.28337628 -3.04639423]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.28337628, -3.04639423]), 'currentState': array([4.76398367, 2.7958681 ]), 'targetState': array([-0.10298384,  0.11581422]), 'effectorPosition': array([ 0.34147899, -0.04161452])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.36173428319637596
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.28337628, -3.04639423]), 'currentState': array([4.76398367, 2.7958681 ]), 'targetState': array([-0.10298384,  0.11581422]), 'effectorPosition': array([ 0.34147899, -0.04161452])}
episode index:1978
target Thresh 1.9655488649769755
current state at start:  [-3.88836821  1.90615949]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.88836821,  1.90615949]), 'currentState': array([2.85837422, 1.44480744]), 'targetState': array([-0.64032559, -1.20113039]), 'effectorPosition': array([-1.35804325, -0.6379892 ])}
done in step count: 2
reward sum = 0.9801
running average episode reward sum: 0.3620467469239169
{'reset': False, 'endBeforeDone': False, 'stepCount': 3, 'initial state': array([-3.88836821,  1.90615949]), 'currentState': array([3.85837422, 0.46788273]), 'targetState': array([-0.64032559, -1.20113039]), 'effectorPosition': array([-1.13053208, -1.58333432])}
episode index:1979
target Thresh 1.9656176983906635
current state at start:  [ 2.4461128  -1.77388405]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.4461128 , -1.77388405]), 'currentState': array([2.9461128 , 5.00930126]), 'targetState': array([-0.10864651,  0.33304089]), 'effectorPosition': array([-1.08221316,  1.18909741])}
done in step count: 4
reward sum = 0.96059601
running average episode reward sum: 0.36234904453153116
{'reset': False, 'endBeforeDone': False, 'stepCount': 5, 'initial state': array([ 2.4461128 , -1.77388405]), 'currentState': array([4.9461128 , 3.51321834]), 'targetState': array([-0.10864651,  0.33304089]), 'effectorPosition': array([-0.33744782, -0.15050744])}
episode index:1980
target Thresh 1.965686394275099
current state at start:  [-3.07487952  2.41797324]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-3.07487952,  2.41797324]), 'currentState': array([3.70830579, 1.91797324]), 'targetState': array([-0.00479388,  0.21239632]), 'effectorPosition': array([-0.05178486, -1.14753183])}
done in step count: 15
reward sum = 0.8600583546412884
running average episode reward sum: 0.36260028598034977
{'reset': False, 'endBeforeDone': False, 'stepCount': 16, 'initial state': array([-3.07487952,  2.41797324]), 'currentState': array([4.7261164 , 3.48956428]), 'targetState': array([-0.00479388,  0.21239632]), 'effectorPosition': array([-0.34013687, -0.06460884])}
episode index:1981
target Thresh 1.965754952905066
current state at start:  [-0.48763433 -2.61563493]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.48763433, -2.61563493]), 'currentState': array([6.28275142, 3.16755038]), 'targetState': array([-0.54177298,  0.30486991]), 'effectorPosition': array([ 0.00032562, -0.02595495])}
done in step count: 1
reward sum = 0.99
running average episode reward sum: 0.3629168347765252
{'reset': False, 'endBeforeDone': False, 'stepCount': 2, 'initial state': array([-0.48763433, -2.61563493]), 'currentState': array([0.46458712, 2.67060747]), 'targetState': array([-0.54177298,  0.30486991]), 'effectorPosition': array([-0.1059729 ,  0.45445174])}
episode index:1982
target Thresh 1.9658233745547988
current state at start:  [-0.28142884  1.74543781]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.28142884,  1.74543781]), 'currentState': array([0.16772959, 1.33280186]), 'targetState': array([ 0.21114942, -0.07183391]), 'effectorPosition': array([1.05617341, 1.16447667])}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.36318988835203314
{'reset': False, 'endBeforeDone': False, 'stepCount': 11, 'initial state': array([-0.28142884,  1.74543781]), 'currentState': array([4.56507195, 3.33427302]), 'targetState': array([ 0.21114942, -0.07183391]), 'effectorPosition': array([-0.19213254,  0.0098028 ])}
episode index:1983
target Thresh 1.9658916594979845
current state at start:  [-8.34461601e-04  2.75224934e+00]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-8.34461601e-04,  2.75224934e+00]), 'currentState': array([0.43464792, 2.25224934]), 'targetState': array([-0.03495802,  0.08662485]), 'effectorPosition': array([0.00862351, 0.86027976])}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.3634626666719207
{'reset': False, 'endBeforeDone': False, 'stepCount': 11, 'initial state': array([-8.34461601e-04,  2.75224934e+00]), 'currentState': array([4.88362393, 3.54370977]), 'targetState': array([-0.03495802,  0.08662485]), 'effectorPosition': array([-0.37205175, -0.14528772])}
episode index:1984
target Thresh 1.9659598080077625
current state at start:  [ 1.71008093 -2.51040553]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 1.71008093, -2.51040553]), 'currentState': array([2.14807091, 4.16941215]), 'targetState': array([-0.03754891,  0.06596127]), 'effectorPosition': array([0.45366969, 0.87224417])}
done in step count: 6
reward sum = 0.941480149401
running average episode reward sum: 0.363753859358434
{'reset': False, 'endBeforeDone': False, 'stepCount': 7, 'initial state': array([ 1.71008093, -2.51040553]), 'currentState': array([4.84523369, 3.251348  ]), 'targetState': array([-0.03754891,  0.06596127]), 'effectorPosition': array([-0.10777304, -0.02047246])}
episode index:1985
target Thresh 1.9660278203567274
current state at start:  [1.34826583 1.78096211]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([1.34826583, 1.78096211]), 'currentState': array([1.7734198 , 1.29588899]), 'targetState': array([-0.56102277,  0.84652306]), 'effectorPosition': array([-1.19862848,  1.05176293])}
done in step count: 91
reward sum = 0.40068465295154054
running average episode reward sum: 0.36377245492419086
{'reset': False, 'endBeforeDone': False, 'stepCount': 92, 'initial state': array([1.34826583, 1.78096211]), 'currentState': array([0.56053186, 2.35787622]), 'targetState': array([-0.56102277,  0.84652306]), 'effectorPosition': array([-0.12822506,  0.75297307])}
episode index:1986
target Thresh 1.966095696816928
current state at start:  [-0.58267359  1.746605  ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.58267359,  1.746605  ]), 'currentState': array([6.20051172, 1.44607382]), 'targetState': array([ 1.09802813, -0.349822  ]), 'effectorPosition': array([1.20249698, 0.89599096])}
done in step count: 26
reward sum = 0.7700431458051551
running average episode reward sum: 0.3639769192879961
{'reset': False, 'endBeforeDone': False, 'stepCount': 27, 'initial state': array([-0.58267359,  1.746605  ]), 'currentState': array([0.23076395, 4.25789627]), 'targetState': array([ 1.09802813, -0.349822  ]), 'effectorPosition': array([ 0.75162497, -0.74635565])}
episode index:1987
target Thresh 1.9661634376598711
current state at start:  [ 0.89393991 -2.18207988]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.89393991, -2.18207988]), 'currentState': array([1.31975543, 4.49975912]), 'targetState': array([0.62766875, 0.77865076]), 'effectorPosition': array([1.1428292 , 0.52142007])}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.36424875286733255
{'reset': False, 'endBeforeDone': False, 'stepCount': 11, 'initial state': array([ 0.89393991, -2.18207988]), 'currentState': array([5.88080814, 1.82778399]), 'targetState': array([0.62766875, 0.77865076]), 'effectorPosition': array([1.06501051, 0.59784279])}
episode index:1988
target Thresh 1.9662310431565195
current state at start:  [ 4.03714431 -2.12920703]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.03714431, -2.12920703]), 'currentState': array([4.50509015, 4.56529684]), 'targetState': array([-1.14792945, -0.65636415]), 'effectorPosition': array([-1.14367532, -0.63157119])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.36456838647574513
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 4.03714431, -2.12920703]), 'currentState': array([4.50509015, 4.56529684]), 'targetState': array([-1.14792945, -0.65636415]), 'effectorPosition': array([-1.14367532, -0.63157119])}
episode index:1989
target Thresh 1.9662985135772957
current state at start:  [ 0.74647894 -1.82663238]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.74647894, -1.82663238]), 'currentState': array([1.21087583, 3.99365115]), 'targetState': array([ 1.24160562, -0.28280193]), 'effectorPosition': array([0.82471107, 0.05460018])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.3648876988443503
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.74647894, -1.82663238]), 'currentState': array([1.21087583, 3.99365115]), 'targetState': array([ 1.24160562, -0.28280193]), 'effectorPosition': array([0.82471107, 0.05460018])}
episode index:1990
target Thresh 1.966365849192081
current state at start:  [-4.64197578  3.10826373]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-4.64197578,  3.10826373]), 'currentState': array([2.06319665, 2.93287316]), 'targetState': array([-0.99143738,  0.34222262]), 'effectorPosition': array([-0.19285117, -0.07883105])}
done in step count: 16
reward sum = 0.8514577710948755
running average episode reward sum: 0.3651320836119296
{'reset': False, 'endBeforeDone': False, 'stepCount': 17, 'initial state': array([-4.64197578,  3.10826373]), 'currentState': array([3.67072113, 4.81976506]), 'targetState': array([-0.99143738,  0.34222262]), 'effectorPosition': array([-1.45763545,  0.29939713])}
episode index:1991
target Thresh 1.9664330502702183
current state at start:  [ 0.90714463 -2.0086505 ]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 0.90714463, -2.0086505 ]), 'currentState': array([1.40714463, 3.77810999]), 'targetState': array([ 0.61458721, -0.96957977]), 'effectorPosition': array([0.61836152, 0.0963721 ])}
done in step count: 99
reward sum = 0.0
running average episode reward sum: 0.36494878437316863
{'reset': False, 'endBeforeDone': False, 'stepCount': 100, 'initial state': array([ 0.90714463, -2.0086505 ]), 'currentState': array([0.38239624, 2.30108315]), 'targetState': array([ 0.61458721, -0.96957977]), 'effectorPosition': array([0.03088464, 0.81540141])}
episode index:1992
target Thresh 1.966500117080512
current state at start:  [-1.32038307 -2.18571236]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.32038307, -2.18571236]), 'currentState': array([5.46280223, 3.64076678]), 'targetState': array([-1.24288172, -0.65266649]), 'effectorPosition': array([-0.26691335, -0.41569321])}
done in step count: 10
reward sum = 0.9043820750088044
running average episode reward sum: 0.3652194483423787
{'reset': False, 'endBeforeDone': False, 'stepCount': 11, 'initial state': array([-1.32038307, -2.18571236]), 'currentState': array([4.17961693, 5.13620548]), 'targetState': array([-1.24288172, -0.65266649]), 'effectorPosition': array([-1.50199336, -0.75266228])}
episode index:1993
target Thresh 1.9665670498912293
current state at start:  [-1.21465549 -1.87064705]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.21465549, -1.87064705]), 'currentState': array([5.56852981, 3.92860647]), 'targetState': array([ 0.20381424, -0.39638761]), 'effectorPosition': array([-0.24206422, -0.72765245])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.3655377936541428
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.21465549, -1.87064705]), 'currentState': array([5.56852981, 3.92860647]), 'targetState': array([ 0.20381424, -0.39638761]), 'effectorPosition': array([-0.24206422, -0.72765245])}
episode index:1994
target Thresh 1.9666338489701016
current state at start:  [ 2.65788851 -2.72506428]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.65788851, -2.72506428]), 'currentState': array([3.15788851, 3.9924519 ]), 'targetState': array([-0.67953404,  0.54305871]), 'effectorPosition': array([-0.35286885,  0.74619625])}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.3658558198227372
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.65788851, -2.72506428]), 'currentState': array([3.15788851, 3.9924519 ]), 'targetState': array([-0.67953404,  0.54305871]), 'effectorPosition': array([-0.35286885,  0.74619625])}
episode index:1995
target Thresh 1.9667005145843253
current state at start:  [ 2.00670654 -1.60257016]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([ 2.00670654, -1.60257016]), 'currentState': array([2.50670654, 4.18061515]), 'targetState': array([0.76630598, 0.3499501 ]), 'effectorPosition': array([0.11430309, 0.98631068])}
done in step count: 5
reward sum = 0.9509900498999999
running average episode reward sum: 0.3661489732446196
{'reset': False, 'endBeforeDone': False, 'stepCount': 6, 'initial state': array([ 2.00670654, -1.60257016]), 'currentState': array([4.97239188, 2.4971705 ]), 'targetState': array([0.76630598, 0.3499501 ]), 'effectorPosition': array([ 0.63210419, -0.03937286])}
episode index:1996
target Thresh 1.966767047000563
current state at start:  [0.31131824 2.42003308]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([0.31131824, 2.42003308]), 'currentState': array([0.81131824, 1.92003308]), 'targetState': array([-0.4269701 , -0.14924021]), 'effectorPosition': array([-0.22848155,  1.12402612])}
done in step count: 8
reward sum = 0.9227446944279201
running average episode reward sum: 0.366427689179113
{'reset': False, 'endBeforeDone': False, 'stepCount': 9, 'initial state': array([0.31131824, 2.42003308]), 'currentState': array([4.80083819, 4.25856327]), 'targetState': array([-0.4269701 , -0.14924021]), 'effectorPosition': array([-0.84565537, -0.63878995])}
episode index:1997
target Thresh 1.9668334464849444
current state at start:  [-0.20621106  2.56148671]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-0.20621106,  2.56148671]), 'currentState': array([0.26425821, 3.03380343]), 'targetState': array([0.80433939, 0.88711182]), 'effectorPosition': array([-0.02249717,  0.105362  ])}
done in step count: 3
reward sum = 0.970299
running average episode reward sum: 0.36672992707241675
{'reset': False, 'endBeforeDone': False, 'stepCount': 4, 'initial state': array([-0.20621106,  2.56148671]), 'currentState': array([1.69875047, 4.5003584 ]), 'targetState': array([0.80433939, 0.88711182]), 'effectorPosition': array([0.86886238, 0.90784761])}
episode index:1998
target Thresh 1.9668997133030675
current state at start:  [-1.67282705  1.89817578]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.67282705,  1.89817578]), 'currentState': array([5.09054758, 1.88687272]), 'targetState': array([ 0.13956722, -1.10523788]), 'effectorPosition': array([ 1.13775318, -0.28954838])}
done in step count: 40
reward sum = 0.6689717585696803
running average episode reward sum: 0.3668811235864224
{'reset': False, 'endBeforeDone': False, 'stepCount': 41, 'initial state': array([-1.67282705,  1.89817578]), 'currentState': array([5.7742321 , 3.93580552]), 'targetState': array([ 0.13956722, -1.10523788]), 'effectorPosition': array([-0.08633356, -0.76867002])}
episode index:1999
target Thresh 1.9669658477199996
current state at start:  [-1.67013547  2.12108222]
at step 0:
{'reset': False, 'endBeforeDone': False, 'stepCount': 1, 'initial state': array([-1.67013547,  2.12108222]), 'currentState': array([5.10542676, 1.62108222]), 'targetState': array([0.03153858, 0.25757662]), 'effectorPosition': array([ 1.28632731, -0.49480567])}
done in step count: 12
reward sum = 0.8863848717161292
running average episode reward sum: 0.36714087546048724
{'reset': False, 'endBeforeDone': False, 'stepCount': 13, 'initial state': array([-1.67013547,  2.12108222]), 'currentState': array([4.75616365, 3.39229227]), 'targetState': array([0.03153858, 0.25757662]), 'effectorPosition': array([-0.24647611, -0.04208719])}

Process finished with exit code 0
